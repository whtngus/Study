{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slim\n",
    "\n",
    "- Keras 와 비슷한 점을 지향\n",
    "- network 구조를 효율적으로 사용하기 위해 만들어짐\n",
    "\n",
    "### 그럼 왜 keras를 안쓸고 slim을 사용할까?\n",
    "\n",
    "- slim의 독특한 특징\n",
    "- slim base의 pre-trained model 이 많음\n",
    "\n",
    "### 실습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# contrib는  Tensorflow 1v 베타  2v부터는 사라짐\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- device 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.contrib.framework.python.ops.variables.variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=True, collections=None, caching_device=None, device=None, partitioner=None, custom_getter=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slim.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# tf\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    weights = tf.Variable(tf.truncated_normal(shape=[10,10,3,3]),name=\"weights\")\n",
    "\n",
    "# slim\n",
    "weights = slim.variable(\"weight\", shape=[10,10,3,3], initializer=tf.truncated_normal_initializer,device=\"/cpu:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable 의 종류\n",
    "1. variable\n",
    "모델을 저장하고 싶을때, save를 통해서 저장이 되는 변수\n",
    "2. local variable\n",
    "session이 살아있는 동안만 존재하는 변수\n",
    "\n",
    "3. slim 은 model variable 을 하나더 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'weights:0' shape=(10, 10, 3, 3) dtype=float32_ref>]\n",
      "[<tf.Variable 'weights:0' shape=(10, 10, 3, 3) dtype=float32_ref>, <tf.Variable 'my_var:0' shape=(10, 10, 3, 3) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "weights = slim.model_variable(\"weights\", shape=[10,10,3,3], initializer=tf.truncated_normal_initializer,device=\"/cpu:0\")\n",
    "weights = slim.variable(\"my_var\", shape=[10,10,3,3], initializer=tf.truncated_normal_initializer,device=\"/cpu:0\")\n",
    "print(slim.get_model_variables()) # 모델 변수 호출\n",
    "print(slim.get_variables()) #모든 변수 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### slim 의 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'repeat_1/conv3_1/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3_1/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3_2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3_2/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3_3/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3_3/biases:0' shape=(256,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 에러가 나는 경우 pip install gast==0.2.2\n",
    "tf.reset_default_graph()\n",
    "net = tf.placeholder(tf.float32,[16,32,32,256])\n",
    "with tf.variable_scope(\"repeat_1\"):\n",
    "    net = slim.conv2d(net,256,[3,3],scope=\"conv3_1\")\n",
    "    net = slim.conv2d(net,256,[3,3],scope=\"conv3_2\")\n",
    "    net = slim.conv2d(net,256,[3,3],scope=\"conv3_3\")\n",
    "    net = slim.max_pool2d(net,[2,2],scope=\"pool2\")\n",
    "# 겹치는 모델 설정을 scope 범위를 사용하여 지정할 수 있음\n",
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"repeat_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'repeat_1/conv3/conv3_1/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_1/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_2/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_3/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_3/biases:0' shape=(256,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "net = tf.placeholder(tf.float32,[16,32,32,256])\n",
    "with tf.variable_scope(\"repeat_1\"):\n",
    "    # + 반복 모델을 for문대신 사용하여 편하게 사용 가능\n",
    "    net = slim.repeat(net,3,slim.conv2d,256,[3,3],scope=\"conv3\")\n",
    "    net = slim.max_pool2d(net,[2,2],scope=\"pool2\")\n",
    "# 겹치는 모델 설정을 scope 범위를 사용하여 지정할 수 있음\n",
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"repeat_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파라미터가 다른경우의 repet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'repeat_1/conv3/conv3_1/weights:0' shape=(3, 3, 256, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_1/biases:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_2/weights:0' shape=(2, 2, 32, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_2/biases:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_3/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_3/biases:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_4/weights:0' shape=(2, 2, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'repeat_1/conv3/conv3_4/biases:0' shape=(64,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "net = tf.placeholder(tf.float32,[16,32,32,256])\n",
    "with tf.variable_scope(\"repeat_1\"):\n",
    "    # + 반복 모델을 for문대신 사용하여 편하게 사용 가능\n",
    "    net = slim.stack(net,slim.conv2d,[(32,[3,3]),(32,[2,2]),(64,[3,3]),(64,[2,2])],scope=\"conv3\")\n",
    "    net = slim.max_pool2d(net,[2,2],scope=\"pool2\")\n",
    "# 겹치는 모델 설정을 scope 범위를 사용하여 지정할 수 있음\n",
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"repeat_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scope\n",
    "layer를 쌓으면서 겹치는 argument가 많은경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "padding = \"SAME\"\n",
    "initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "regularizer = slim.l2_regularizer(0.0005)\n",
    "\n",
    "inputs = tf.placeholder(tf.float32,[16,224,224,3])\n",
    "ner = slim.conv2d(inputs,64,[11,11],4,padding=padding, weights_regularizer=regularizer, weights_initializer=initializer,scope=\"conv1\")\n",
    "ner = slim.conv2d(ner,64,[11,11],128,padding=padding, weights_regularizer=regularizer, weights_initializer=initializer,scope=\"conv2\")\n",
    "ner = slim.conv2d(ner,64,[11,11],256,padding=padding, weights_regularizer=regularizer, weights_initializer=initializer,scope=\"conv3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slim으로 교체\n",
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32,[16,224,224,3])\n",
    "with slim.arg_scope([slim.conv2d],padding=\"SAME\",\n",
    "                  weights_regularizer=slim.l2_regularizer(0.0005),\n",
    "                  weights_initializer=tf.truncated_normal_initializer(stddev=0.01)):\n",
    "    ner = slim.conv2d(inputs,64,[11,11],4,scope=\"conv1\")\n",
    "    ner = slim.conv2d(ner,64,[11,11],128,scope=\"conv2\")\n",
    "    ner = slim.conv2d(ner,64,[11,11],256,scope=\"conv3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scope 는 2중 3중으로도 가능하다 <br>\n",
    "코드 설명 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### slim의 training\n",
    "\n",
    "- loss의 더하기  전부 가져오기 가능\n",
    "ex) <br>\n",
    "slim.losses.get_total_loss(add_regularization_losses=False) <br>\n",
    "\n",
    "- train op 과 update op\n",
    "트레이닝(백프로파게이션)으로 업데이트 하지 않는 파라미터의 경우, tf에서는 control flow를 이용하여 control dependency를 통하여 업데이트를 할 수 있다. <br>\n",
    "-> 난이도가 매우 어려움  <br>\n",
    "slim.learning.create_train_op(total_loss, optimizer) -> 두가지를 동시에 사용 <br>\n",
    "\n",
    "=> Tensorflow v2 에서는 해당 기능이 필요하지 않음 <br>\n",
    "\n",
    "- Fine-Tuning <br>\n",
    "내가 트레이닝한 그래프와 다른사람이 트레이닝한 그래프가 일치하지 않는경우 ... <br>\n",
    "variable restore할지를 결정해야 하기 때문에 variable name을 하나씩 가져와야함  <br>\n",
    "slim 은 여러가지 가져올 수 있는 방법을 제공 <br>\n",
    "slim.get_variables_by_name <br> \n",
    "slim.get_variables_by_suffix <br>\n",
    "get_variables <br>\n",
    "get_variables_to_restore(include=[\" 값 \"])  <br>\n",
    "get_variables_to_restore(exclude=[\" 값 \"]) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
