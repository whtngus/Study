maxparam␞ 이번 글에서는 최대엔트로피모델(Maximum Entropy model)의 파라메터 추정을 살펴보도록 하겠습니다. 이 글은 기본적으로 [이곳]()을 참고하였습니다. 그럼 시작하겠습니다.   ## 모델 정의 최대엔트로피 모델은 다음과 같이 정의됩니다.  $$ { P }_{ \Lambda }(y|x)=\frac { { exp( }\sum _{ i }^{ }{ { \lambda }_{ i }{ f }_{ i }\left( x,y \right) } ) }{ \sum _{ y }^{ }{ { exp( }\sum _{ i }^{ }{ { \lambda }_{ i }{ f }_{ i }\left( x,y \right) } ) } } $$  위 식에서 $f$는 $x$와 $y$가 주어졌을 때 0 또는 1의 값을 반환하는 함수이며, $f_i(x,y)$는 자질벡터의 $i$번째 값을 나타냅니다. $λ$는 $f_i(x,y)$가 얼마나 중요한지 나타내는 가중치입니다. $Λ$는 그 요소가 $\{λ_1, λ_2,...,λ_n\}$인 가중치 벡터입니다.   ## 최대우도추정 최대엔트로피모델 $P_Λ$에 대한 실제 데이터 분포(empirical distribution) $\widetilde{p}(x,y)$의 로그우도 함수는 다음과 같이 정의됩니다.  $$ { L }_{ \tilde { p } }=\sum _{ x,y }^{ }{ \tilde { p } \left( x,y \right) \log { { P }_{ \Lambda } } } \left( y|x \right) $$  자질벡터와 데이터가 주어졌을 때 위 로그우도 함수를 최대화하는 파라메터 $Λ$를 찾는 것이 목적이 됩니다. ${ L }_{ \tilde { p } }$는 1차 도함수가 0인 지점에서 극값을 가지므로, 우리가 구하고자 하는 미지수인 $λ_i$에 대해 각각 편미분을 하여 정리하면 다음과 같습니다.  $$ \frac { \partial { L }_{ \tilde { p } } }{ \partial { \lambda }_{ i } } =\sum _{ x,y }^{ }{ \tilde { p } \left( x,y \right) { f }_{ i }\left( x,y \right) } -\sum _{ x }^{ }{ \tilde { p } \left( x \right) { P }_{ \Lambda }\left( y|x \right) { f }_{ i }\left( x,y \right) } $$  위 식에서 첫번째 항은 실제 데이터 분포에 대한 $f_i(x,y)$의 기대값입니다. 두번째 항은 모델 $P_Λ$에 대한 $f_i(x,y)$의 기대값입니다. 최적의 $λ_i$는 첫번째 항과 두번째 항이 정확히 같을 때 도출되므로, 최대우도추정은 실제 데이터의 확률분포와 모델이 예측하는 확률분포를 같게 만든다는 의미가 됩니다. 위 식은 딥러닝 모델의 손실함수인 크로스엔트로피(cross entropy)와 부호만 다를 뿐 정확히 같습니다. [크로스엔트로피](https://ratsgo.github.io/deep%20learning/2017/09/24/loss/)는 두 확률분포 간 차이를 계산하는 함수입니다. 다시 말해 '우도의 최대화'와 '데이터-모델 두 확률분포 간 차이 최소화'가 본질적으로 동일한 의미를 지닌다는 겁니다.   ## 파라메터 Λ 찾기 우리는 우도를 최대화하는 $Λ$를 구하고 싶습니다. 위 식을 보면 이러한 $Λ$를 구하려면 $P_Λ$를 알아야 합니다. 그런데 $P_Λ$를 계산하려면 $Λ$를 알아야 합니다. 돌고 도는 문제가 되는 셈이죠. 이같은 문제를 해결하기 위해 다음과 같이 새로운 파라메터 $Λ+Δ$를 설정해 보겠습니다.   $$ \Lambda +\Delta =\left\{ { \lambda }_{ 1 }+{ \delta }_{ 1 },{ \lambda }_{ 2 }+{ \delta }_{ 2 },...{ \lambda }_{ n }+{ \delta }_{ n } \right\} $$  처음엔 우도를 최대화하는 $Λ$를 알 수 없으니 랜덤하게 값을 정해줍니다. $L_{ \tilde { p } }(Λ+Δ)-L_{ \tilde { p } }(Λ)$이 0 이상이라면 랜덤하게 정해준 $Λ$보다 $Λ+Δ$가 더 나은 파라메터라고 할 수 있을 것입니다. 몇 가지 수식 정리 과정을 거치면 $ L_{ \tilde { p } }(Λ+Δ)-L_{ \tilde { p } }(Λ)$의 하한(low-bound)은 다음과 같이 도출됩니다.  $$ \begin{align*} { L }_{ \tilde { p } }(\Lambda +\Delta )-{ L }_{ \tilde { p } }(\Lambda )\ge &\sum _{ x,y }^{ }{ \tilde { p } \left( x,y \right) \sum _{ i }^{ }{ { { \delta }_{ i }f }_{ i }\left( x,y \right) } }+ \\ &1-\sum _{ x }^{ }{ \tilde { p } \left( x \right) { P }_{ \Lambda }\left( y|x \right) \sum _{ i }^{ }{ \left( \frac { { f }_{ i }\left( x,y \right) }{ \sum _{ i }^{ }{ { f }_{ i }\left( x,y \right) } } \right) } } exp\left( { \delta }_{ i }\sum _{ i }^{ }{ { f }_{ i }\left( x,y \right) } \right) \end{align*} $$  위 식 우변을 $Β(Δ$\|$Λ)$라고 치환해 보면 $L_{ \tilde { p } }(Λ+Δ)-L_{ \tilde { p } }(Λ)$의 하한은 $Β(Δ$\|$Λ)$이 됩니다. $Λ$는 이미 랜덤하게 값을 정했기 때문에 이미 주어진 값입니다. 다시 말해 $Δ$만 알면 우도를 높일 수 있다고 기대할 수 있다는 이야기입니다. $Β(Δ$\|$Λ)$는 1차 도함수가 0이 되는 지점에서 극값(최대값)을 가지기 때문에 우리가 구하고자 하는 미지수인 $δ_i$에 대해 각각 편미분을 하여 정리하면 다음과 같습니다.  $$ \begin{align*} \frac { \partial Β \left( \Delta |\Lambda \right) }{ \partial { \delta }_{ i } } =&\sum _{ x,y }^{ }{ \tilde { p } \left( x,y \right) { f }_{ i }\left( x,y \right) } \\ &-\sum _{ x }^{ }{ \tilde { p } \left( x \right) \sum _{ }^{ }{ { P }_{ \Lambda }\left( y|x \right) } { f }_{ i }\left( x,y \right) } exp\left( { \delta }_{ i }\sum _{ i }^{ }{ { f }_{ i }\left( x,y \right) } \right) \end{align*} $$  위 식을 보면 exp 안에 있는 미지수 $δ_i$를 제외하면 모두 주어진 상수값이어서 $δ_i$를 구할 수 있습니다. 지금까지 설명한 내용을 알고리즘 형태로 정리하면 다음과 같습니다. 1. $Λ=\{λ_1, λ_2,...,λ_n\}$ 랜덤 초기화 2. $∂Β/∂δ_i=0$인 $δ_i$ 계산 3. $λ_i←λ_i+δ_i$ 4. $Λ$가 수렴할 때까지 2, 3 반복 이와 같은 *iterative scaling algorithm*은 딥러닝에서 많이 쓰이는 그래디언트 디센트와 유사하다는 생각이 듭니다. 그래디언트 디센트는 주어진 데이터와 파라메터를 가지고 손실(loss)에 대한 그래디언트를 구해, 그래디언트의 반대 방향으로 파라메터를 업데이트합니다. 다만 *iterative scaling algorithm*은 '우도 최대화', 그래디언트 디센트는 '손실 최소화'가 목적이기 때문에 파라메터를 업데이트할 때 각각 덧셈, 뺄셈을 해준다는 점에서 다른 것 같습니다.  
plsa␞ 이번 글에서는 말뭉치에 내재해 있는 토픽들을 추론해 내는 확률모델인 **Probabilistic Latent Semantic Analysis(pLSA)**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## LSA pLSA는 기존 **잠재의미분석(Latene Semantic Analysis)**과는 아예 다른 기법이지만 개념을 공유하는게 많아서 먼저 설명해볼까 합니다. LSA에 대한 자세한 내용은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/06/pcasvdlsa/)을 참고하시면 좋을 것 같습니다. 어쨌든 LSA는 말뭉치 행렬 $A$를 다음과 같이 분해하는 걸 말합니다. <a href="http://imgur.com/YnroTPH"><img src="http://i.imgur.com/YnroTPH.png" width="500px" title="source: imgur.com" /></a> LSA 수행 결과로 $n$개 문서가 원래 단어 개수보다 훨씬 작은 $q$차원의 벡터로 표현된 걸 확인할 수 있습니다. 마찬가지로 $m$개 단어는 원래 문서 수보다 훨씬 작은 $q$차원 벡터로 변환됐습니다. $q$가 3이라면 전체 말뭉치가 3개의 토픽으로 분석됐다고도 말할 수 있을 것입니다. 위 그림에서 행렬 $L$의 열벡터는 각각 해당 토픽에 대한 문서들의 분포 정보를 나타냅니다. $R$의 행벡터는 각각 해당 토픽에 대한 단어들의 분포 정보를 나타냅니다. 중간에 대각행렬은 $q$개 토픽 각각이 전체 말뭉치 내에서 얼마나 중요한지 나타내는 가중치가 될 겁니다.  ## pLSA pLSA는 단어와 문서 사이를 잇는, 우리 눈에 보이지 않는 잠재구조가 있다는 가정 하에 단어와 문서 출현 확률을 모델링한 확률모형입니다. pLSA는 아래 그림처럼 **Latent concepts**가 존재하고 이것이 문서와 단어를 연결한다고 가정합니다. 문서들의 주제(토픽)이라고 생각하면 좋을 것 같습니다. <a href="http://imgur.com/hiVmhJc"><img src="http://i.imgur.com/hiVmhJc.png" width="450px" title="source: imgur.com" /></a> 왼쪽부터 차례로 살펴보겠습니다. P(z\|d)는 문서 하나가 주어졌을 때 특정 주제(토픽)가 나타날 확률을 의미합니다. P(w\|z)는 주제가 정해졌을 때 특정 단어가 나타날 확률을 가리킵니다.  예컨대 위 그림 기준에서 네번째 문서는 trade라는 주제로만 구성돼 있습니다. 그런데 trade라는 주제는 economic, imports, trade 따위의 단어를 선호하네요.  결과적으로 네번째 문서에는 economic, imports, trade 등의 단어가 출현할 가능성이 높다고 할 수 있겠습니다. pLSA의 가정에 문제가 없다면 해당 문서에 실제 등장하는 단어의 출현 확률은 높아야 할 겁니다. 그럼 pLSA가 가정하는 단어-문서 생성 과정을 살펴보겠습니다. 아래 그림을 볼까요? <a href="http://imgur.com/BXijX5M"><img src="http://i.imgur.com/BXijX5M.png" width="550px" title="source: imgur.com" /></a> (a) 먼저 보겠습니다. 우선 문서를 뽑습니다. 그 다음 이 문서의 주제를 뽑습니다. 마지막으로 해당 주제별로 단어를 뽑습니다. 사람이 글 쓸 때도 글을 쓰기로 마음을 먹고 나서 주제, 단어를 차례대로 결정하기 때문에 직관적으로 이해가 가능합니다. 그런데 (b)는 좀 이해하기 까다롭습니다. 주제(z)를 뽑은 뒤 이 주제에 해당하는 문서와 단어를 뽑는 방식입니다. pLSA는 바로 이 방식으로 모델이 구성돼 있습니다.  ## LSA와 pLSA LSA는 행렬 인수분해(matrix factorization), pLSA는 확률모형입니다. 아예 그 종류가 다르다고 할 수 있죠. 하지만 개념상 연결되는 부분이 있습니다. 그래서일까요? 이름도 좀 많이 비슷해요. 어쨌든 아래 그림을 보겠습니다. <a href="http://imgur.com/cHbHrOw"><img src="http://i.imgur.com/cHbHrOw.png" width="400px" title="source: imgur.com" /></a>  LSA 결과물인 행렬 $U_k$의 열벡터는 각각 해당 토픽에 대한 문서들의 분포 정보를 나타냅니다. 이는 pLSA의 P(d\|z)에 대응합니다. 행렬 $V_k$의 행벡터는 각각 해당 토픽에 대한 단어들의 분포 정보를 나타냅니다.이는 pLSA의 P(w\|z)에 대응합니다. $Σ_k$의 대각성분은 토픽 각각이 전체 말뭉치 내에서 얼마나 중요한지 나타내는 가중치가 됩니다. 이는 pLSA의 P(z)에 대응합니다. pLSA의 결과물은 확률이기 때문에 각 요소값이 모두 0 이상, 전체 합이 1이 됩니다. 하지만 LSA는 이런 조건을 만족하지 않습니다.  ## pLSA의 목적식 pLSA는 $m$개 단어, $n$개 문서, $k$개 주제(토픽)에 대해 아래 우도함수를 최대화하는 걸 목표로 합니다. $$ \begin{align*} L&=\coprod _{ i=1 }^{ m }{ \coprod _{ j=1 }^{ n }{ { p({ w }_{ i },{ d }_{ j }) }^{ n({ w }_{ i },{ d }_{ j }) } } } \\ &=\coprod _{ i=1 }^{ m }{ \coprod _{ j=1 }^{ n }{ { \left\{ \sum _{ l=1 }^{ k }{ p({ d }_{ j }|{ z }_{ l })p({ z }_{ l })p({ w }_{ i }|z_{ l }) } \right\} }^{ n({ w }_{ i },{ d }_{ j }) } } } \end{align*} $$  위 식에서 $n(w_i,d_j)$는 $j$번째 문서에 $i$번째 단어가 등장한 횟수를 나타냅니다. $p(w_i, d_j)$는 $k$개 주제(토픽)에 대해 summation 형태로 돼 있는데요. 같은 단어라 하더라도 여러 토픽에 쓰일 수 있기 때문입니다. 예컨대 정부(government) 같은 흔한 단어는 정치, 경제, 외교/국방 등 다양한 주제에 등장할 수 있습니다.  ## pLSA의 학습 : EM 알고리즘 **EM알고리즘**은 동시에 최적화할 수 없는 복수의 변수들을 반복적인 방식으로 계산하는 기법입니다. 우선 모든 값을 랜덤으로 초기화합니다. 이후 하나의 파라메터를 고정시킨 다음에 다른 파라메터를 업데이트하고, 이후 단계에선 업데이트된 파라메터로 고정시킨 파라메터를 다시 업데이트합니다. 다음과 같습니다. <a href="http://imgur.com/lNIYsxF"><img src="http://i.imgur.com/lNIYsxF.png" title="source: imgur.com" /></a>  ## 분석 예시 다음과 같은 Term-Document Matrix를 분석해 보겠습니다. |  word  | Doc 1 | Doc 2 | Doc 3 | Doc 4 | Doc 5 | Doc 6 | | :--------: | :---: | :---: | :---: | :---: | :---: | :---: | | Baseball |  1  |  2  |  0  |  0  |  0  |  0  | | Basketball |  3  |  1  |  0  |  0  |  0  |  0  | |  Boxing  |  2  |  0  |  0  |  0  |  0  |  0  | |  Money  |  3  |  3  |  2  |  3  |  2  |  4  | | Interest |  0  |  0  |  3  |  2  |  0  |  0  | |  Rate  |  0  |  0  |  4  |  1  |  0  |  0  | | Democrat |  0  |  0  |  0  |  0  |  4  |  3  | | Republican |  0  |  0  |  0  |  0  |  2  |  1  | |  Cocus  |  0  |  0  |  0  |  0  |  3  |  2  | | President |  0  |  0  |  1  |  0  |  2  |  3  | pLSA 수행 결과로 계산된 P(z)는 다음과 같습니다. | Topic 1 | Topic 2 | Topic 3 | | :-----: | :-----: | :-----: | | 0.456 | 0.281 | 0.263 | P(d\|z)는 다음과 같습니다. 이 결과로 미루어 짐작해볼 때 Topic1은 정치, Topic2는 경제, Topic3는 스포츠인 것 같습니다. | Docs | Topic 1 | Topic 2 | Topic 3 | | :---: | :-----: | :-----: | :-----: | | Doc 1 | 0.000 | 0.000 | 0.600 | | Doc 2 | 0.000 | 0.000 | 0.400 | | Doc 3 | 0.000 | 0.625 | 0.000 | | Doc 4 | 0.000 | 0.375 | 0.000 | | Doc 5 | 0.500 | 0.000 | 0.000 | | Doc 6 | 0.500 | 0.000 | 0.000 | P(w\|z)는 다음과 같습니다. |  Terms  | Topic 1 | Topic 2 | Topic 3 | | :--------: | :-----: | :-----: | :-----: | | Baseball | 0.000 | 0.000 | 0.200 | | Basketball | 0.000 | 0.000 | 0.267 | |  Boxing  | 0.000 | 0.000 | 0.133 | |  Money  | 0.231 | 0.313 | 0.400 | | Interest | 0.000 | 0.312 | 0.000 | |  Rate  | 0.000 | 0.312 | 0.000 | | Democrat | 0.269 | 0.000 | 0.000 | | Republican | 0.115 | 0.000 | 0.000 | |  Cocus  | 0.192 | 0.000 | 0.000 | | President | 0.192 | 0.063 | 0.000 | pLSA 수행 결과로 나온 표들은 겉보기에는 LSA의 행렬 인수분해 결과와 흡사해 보입니다. 하지만 주의할 것은 도출되는 과정 자체가 확률모형을 전제했다는 것입니다.  ## 코드 pLSA를 R로 직접 구현해 봤습니다. 다음과 같습니다. <script src="https://gist.github.com/ratsgo/c25deb6d79f3ab8b0b050af751fbbdb8.js"></script>
word2vec␞ 이번 포스팅에선 요즘 인기를 끌고 있는 단어 임베딩 방법론 가운데 하나인 Word2Vec을 활용해서 문장을 분류하는 방법에 대해 이야기해보려고 합니다. 우선은 뽐뿌, 클리앙, 세티즌 등 휴대폰 리뷰사이트에 있는 스마트폰 리뷰들을 분석해 보려고 하는데요. 어떤 일을 하려고 하는지 한번 예를 들어보죠. > 리뷰1: 발열은 LTE폰의 숙명 ㅠㅠ > 리뷰2: HD촬영기능 하나만으로도 충분히 만족하시리라 봅니다~~ 리뷰1을 작성한 사용자는 **배터리**를 휴대폰의 중요한 기능이라고 생각하는 모양입니다. 리뷰2의 경우엔 **카메라**겠지요. 이렇게 리뷰가 하나 주어졌을 때 해당 리뷰를 작성한 사용자가 휴대폰의 어떤 기능을 중시하는지를 알아맞혀 보고 싶은 겁니다. 다시 말해 휴대폰 리뷰 문장을 '배터리', '카메라', '디자인', '사운드' 따위의 기능(범주)으로 분류(classification)하는 문제가 관심이 되겠습니다. 물론 사람이 리뷰를 하나하나 읽어보면서 확인해도 되지만 21세기를 살아가는 우리는 컴퓨터의 힘을 빌려보죠.   ## Word2Vec으로 단어 임베딩하기 <a href="http://imgur.com/agTBWiT"><img src="http://i.imgur.com/agTBWiT.png" width="500px" title="source: imgur.com" /></a> 2013년 구글에서 개발한 Word2Vec이라는 방법론이 있습니다. 이름 그대로 단어(Word)를 벡터(Vector)로 바꿔주는 방법입니다. 이를 **임베딩(Embedding)**이라고 합니다. Word2Vec을 정확하게 이해하려면 역시 [논문](https://arxiv.org/pdf/1301.3781.pdf)을 읽는 것을 추천하고요, Word2Vec 학습 방식에 관심이 있으신 분은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/)을, **GloVe, Fasttext** 같은 다른 방법론과의 비교에 관심 있으시면 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/11/embedding/)에 한번 들러보셔요. 주지하다시피 Word2Vec의 효과는 놀랍습니다. 단어를 벡터화할 때 단어의 문맥적 의미를 보존하기 때문이죠. 위의 그림처럼 MAN과 WOMAN 사이의 거리는 KING과 QUEEN 거리와 유사합니다. 벡터로 바뀐 단어들은 '유클리디안 거리'니, '코사인 유사도'니 하는 방식들로 그 거리를 잴 수 있고 그 거리가 가까울(작을) 경우 의미가 비슷한 단어라고 해석할 수 있게 됩니다.  말로만 장황하게 얘기하는 것보다는 예를 드는 것이 좋겠네요. 우선 루리웹, 뽐뿌, 세티즌, 클리앙, 플레이웨어즈 5개 사이트에서 총 29만7906개의 리뷰를 수집했습니다. 이후 포스태깅(형태소분석) 작업을 실시했습니다. 대표적인 한국어 포스태거로 [KoNLPy](http://konlpy.org)가 있는데요, 저는 이것 말고 김현중 서울대 박사과정이 개발한 [cohesion tokenizer](https://github.com/lovit/soy/tree/master/tutorials/soy)를 사용했습니다. cohesion tokenizer는 KoNLPy처럼 품사 정보까지 반환하지는 않지만 토크나이징을 분석 대상 코퍼스의 출현 빈도를 학습한 결과를 토대로 토큰을 나눠주기 때문에 분석 품질이 비교적 좋습니다. Word2Vec에 품사정보까지 넣을 필요는 없기도 하고요. 어쨌든 cohesion tokenizer로 토크나이징한 결과물은 다음과 같습니다. > 발열,은,LTE,폰,의,숙명,ㅠㅠ > HD,촬영,기능,하나,만,으로,도,충분히,만족,하시리,라,봅,니다 이렇게 토크나이징한 결과물을 파이썬 gensim 패키지를 활용해 Word2Vec 방법론을 적용합니다. Word2Vec을 적용하는 데 단 두 줄이면 됩니다. ```python # Word2Vec embedding from gensim.models import Word2Vec embedding_model = Word2Vec(tokenized_contents, size=100, window = 2, min_count=50, workers=4, iter=100, sg=1) ``` 위 코드 의미는 다음과 같습니다. 포스태깅된 컨텐츠를 100차원의 벡터로 바꿔라. 주변 단어(window)는 앞뒤로 두개까지 보되, 코퍼스 내 출현 빈도가 50번 미만인 단어는 분석에서 제외해라. CPU는 쿼드코어를 쓰고 100번 반복 학습해라. 분석방법론은 CBOW와 Skip-Gram 중 후자를 선택해라.  그럼 임베딩이 잘 됐는지 확인해볼까요? gensim 패키지가 제공하는 기능 중에 'most_similar'라는 함수가 있습니다. 두 벡터 사이의 코사인 유사도를 구해줍니다. 그 값이 클 수록 비슷한 단어라는 뜻인데, 아래 코드는 '디자인'이라는 단어와 가장 비슷한(코사인 유사도가 큰) 100개 단어를 출력하라는 지시입니다. ```python # check embedding result print(embedding_model.most_similar(positive=["디자인"], topn=100)) ``` Word2Vec 모델이 내뱉는 결과는 아래와 같습니다. > 색감, 그립감, 외형, 색깔, UI, 색깔, 각진, 뒷면, 외관... **"오 생각보다 괜찮다."** 결과물을 처음 보고 느낀 점입니다. 같은 방식으로 '사운드'도 해봤습니다. > 오디오, 음장, 음질, 퀄리티, 헤드, MP3, 스피커... 역시 굿입니다.  ## 단어벡터로 가중치 행렬 만들기 우리가 하고 싶은 작업은 이것입니다.  > 문맥적 정보가 보존된 상태의 단어 벡터 사이의 거리(유사도)를 구하고 이를 가중치 삼아 각 문장별로 스코어를 구한다. 이렇게 구한 스코어를 바탕으로 각 리뷰 문장을 특정 기능에 할당(분류)한다. 뭔가 어렵죠? 앞으로 차근차근 설명해보겠습니다. Word2Vec의 아웃풋은 아래와 같은 단어벡터 행렬입니다. 첫번째 열의 각 요소는 위의 코드 가운데 'min_count' 조건을 만족하는 코퍼스 내 모든 단어가 됩니다. 아래 행렬의 열의 개수는 ''임베딩 차원수(size) + 1(단어가 속한 열)'이 됩니다. 다시 말해 **행벡터**가 각 단어에 대응하는 단어벡터라는 뜻이지요. 하지만 행렬 각 요소의 숫자들은 사람이 이해하기 어렵습니다. 그도 그럴 것이 100차원 벡터공간의 좌표값들이기 때문입니다~~사람은 4차원도 못그리는데 말이죠~~. | -  |  V1  |  V2  |  V3  | ... | | :--: | :----: | :----: | :----: | :--: | | 배터리 | 0.1256 | 0.2211 | 0.5473 | ... | | 발열 | 0.2385 | 0.7562 | 0.8754 | ... | | 은  | 0.2845 | 0.1293 | 0.9483 | ... | | ... | ...  | ...  | ...  | ... |  이를 사람이 이해하기 편하게 **거리행렬(distance matrix)**로 바꿔볼까요? 거리를 재는 방식은 다양하지만 일단은 가장 친숙한 유클리디안 방법을 써보겠습니다. 직각삼각형의 너비와 높이를 알면 피타고라스 정리에 의해 빗변의 길이를 구할 수 있죠? 정확히 그 식을 사용해 100차원 공간 안에 있는 벡터들 사이의 길이를 재는 겁니다. 이렇게 구한 거리행렬은 아래와 같습니다. | -  | 배터리 | 발열 | 은  | ... | | :--: | :--: | :--: | :--: | :--: | | 배터리 | 0  | 1  | 10 | ... | | 발열 | 1  | 0  | 8  | ... | | 은  | 10 | 8  | 0  | ... | | ... | ... | ... | ... | ... | 설명의 편의를 위해 제가 임의의 숫자를 적었습니다만, 위의 거리행렬이 의미하는 바는 이렇습니다. '배터리'와 '배터리' 사이의 거리는 얼마일까요? 정확하게 일치하기 때문에 0입니다. 마찬가지로 '발열'과 '발열', '은'과 '은' 거리도 0입니다. 이런 방식으로 거리행렬의 모든 대각성분은 0이 됩니다.  한편 예시에서는 '배터리'와 '발열' 사이의 거리가 1, '배터리'와 '은'은 10으로 나왔습니다. **그렇다면 '은'보다는 '발열'이 '배터리'와 유사한 단어라고 볼 수 있겠네요.** 이것이 이제 우리가 만들 **가중치 행렬**이 지향하는 핵심 원리입니다. 즉, 특정 쿼리 단어(예를 들어 '배터리')와 거리가 가까운(=의미가 유사한) 단어는 높은 가중치, 그렇지 않은 단어는 낮은 가중치를 가지도록 가중치행렬을 만들어보자는 것입니다. 이를 수식으로 나타내면 다음과 같습니다. $${ W }_{ ij }=exp\left( -\frac { d{ ({ x }_{ i },{ x }_{ j }) }^{ 2 } }{ 2\sigma^{2} } \right) $$ 왜 이렇게 복잡한 수식을 쓰냐고요? 통계학을 전공하신 분이라면 한눈에 알아보셨겠지만, $exp$ 앞의 계수를 제외하면 이는 **정규분포(normal distribution)** 식과 같습니다. 정규분포는 연속 확률 분포의 일종으로 수많은 자연, 사회현상을 설명하는 데 탁월한 분석도구로 정평이 나 있습니다. 위 식 지수의 분자에 $d$는 거리행렬의 '거리'를 의미합니다. 즉 0에서 ∞ 범위를 지니는 들쭉날쭉한 벡터간 거리들을 아주 예쁜 모양의 정규분포로, 그것도 특정 범위로 스케일링까지 해서 반환한다는 얘기입니다.  거리행렬에 위 수식을 적용한 행렬에서 우리가 원하는 특정 쿼리 단어(예를 들어 '배터리'와 '사운드')만 남기고 나머지를 제거한 행렬이 바로 가중치 행렬이 됩니다. 아래와 최종 결과입니다. 다시 한번 가중치행렬의 의미를 곱씹어 보면, 쿼리단어인 '배터리'와 의미가 유사한 '발열'이라는 단어는 높은 가중치(0.9)를, '배터리'와 별 상관이 없는 조사 '은'은 낮은 가중치(0.1)를 갖습니다. 마찬가지로 '사운드' 기준으로 보면 이와 관련이 높은 '음질'이라는 단어는 높은 가중치(0.84)를, 그렇지 않은 나머지 단어들은 낮은 가중치를 갖게 됩니다. | -  | 배터리 | 발열 | 은  | ... | 음질 | ... | | :--: | :--: | :--: | :--: | :--: | :--: | :--: | | 배터리 | 1  | 0.9 | 0.1 | ... | 0.1 | ... | | 사운드 | 0.1 | 0.1 | 0.01 | ... | 0.84 | ... |   ## 가중치 행렬로 문장별 스코어 구하기 이제 처음 우리가 풀려고 했던 문제를 다시 떠올려봅시다. 휴대폰 리뷰 문장을 '배터리', '카메라', '디자인', '사운드' 따위의 기능(범주)으로 분류(classification)하려고 합니다. > 발열,은,LTE,폰,의,숙명,ㅠㅠ 자, 7개 단어로 이뤄진 위 문장의 스코어를 매겨볼까요? 처음 등장한 단어 '발열'의 가중치는 0.9입니다. '은'은 0.1이네요. 이렇게 문장에 등장한 7개 단어에 해당하는 가중치를 가중치행렬에서 Lookup 방식으로 가져올 수 있습니다. 7개 단어 가중치를 모두 더한 값이 바로 이 문장이 '배터리' 기능을 얼마나 중시하는지를 알려주는 지표가 되는 겁니다. 즉, '배터리' 스코어는 '배터리'라는 쿼리 단어와 나머지 단어 사이의 가중치들의 **선형결합(linear combination)**입니다. 그런데 여기서 문제가 하나 있습니다. 문장에 등장한 단어 하나하나마다 가중치행렬에서 Lookup 형식으로 가중치들을 가져오는 건 계산상 너무 비효율적입니다. 위 문장만 해도 단어가 7개 있으므로 무려 7번이나 Lookup을 해야 한다는 얘기입니다. 이를 좀 빠르고 편하게 하는 방법이 없을까요? 이럴 때 **단어문서행렬(Term-Document Matrix)**가 강력한 힘을 발휘합니다. TDM의 행은 '단어', 열은 '문서'가 됩니다. 즉 위 문장을 아래와 같은 행렬로 변환하는 작업입니다. | -  | Doc1 | Doc2 | ... | | :--: | :--: | :--: | :--: | | 발열 | 1  | 0  | ... | | 은  | 1  | 0  | ... | | ... | ... | ... | ... | 위 행렬을 해석하면 이렇습니다. '발열,은,LTE,폰,의,숙명,ㅠㅠ'이라는 Doc1은 '발열'이라는 단어가 문장에 있기 때문에 '발열' 행, 'Doc1' 열의 값은 1이 됩니다. 마찬가지로 '은' 행, 'Doc1' 열도 1입니다. 만약 행에 해당하는 단어가 쓰이지 않은 리뷰(doc)의 요소 값은 0, 쓰였다면 1이 됩니다. 저의 경우 단어 등장여부를 binary로 TDM을 구축했습니다. 즉, '발열'이라는 단어가 한번 쓰였든 두번 쓰였든 그 값을 1로 했다는 뜻입니다. 물론 빈도수 그대로 TDM을 구축해도 될 겁니다. 자, 이제 거의 다 왔습니다!  TDM과 가중치행렬을 **내적(inner product)**해주면 문장별로 스코어를 한방에 구할 수 있습니다. 내적 개념이 생소하거나 헷갈리시는 분이라면 **선형대수학(Linear Algebra)**을 처음부터 파실 필요는 없고, 고등학교 수학 책을 다시 한번 보시면 됩니다. 직관적으로 이해할 수 있도록 아래 예시를 준비했는데요. 우선 말뭉치에 등장하는 전체 단어 수가 7개이고, 우리가 조사하고 싶은 기능은 $f_1$, $f_2$, $f_3$ 이렇게 세 가지가 있다고 가정해보겠습니다. 두번째와 여섯번째 단어로 구성된 리뷰의 각 기능별 스코어는 다음과 같습니다. <a href="http://imgur.com/qyt7w5u"><img src="http://i.imgur.com/qyt7w5u.png" width="600px" title="source: imgur.com" /></a> 보시다시피 기능별 스코어는 TDM에서 1에 해당하는 위치의 가중치행렬 열벡터를 참조(Lookup)해 이를 기능별로 따로 합산하는 방식으로 계산하게 됩니다. 이를 전체 리뷰로 확장하게 되면 전체 내적의 결과는 (쿼리 단어의 수 x 문서의 수) 행렬 형태가 됩니다. 즉, Doc1의 '배터리' 스코어가 이 스코어행렬의 1행 1열에 해당하는 요소가 되는 것이죠. 만약 쿼리 단어를 '배터리'뿐 아니라 '사운드', '카메라' 등까지 지정했다면 같은 방식으로 Doc1의 '사운드' 스코어는 2행 1열, Doc1의 '카메라' 스코어는 3행 1열이 됩니다. 마찬가지로 Doc2의 '배터리', '사운드', '카메라' 스코어는 1행 2열, 2행 2열, 3행 2열이 됩니다.   ## 파일럿 실험 결과 휴대폰 리뷰 29만7906개를 위와 같은 방식으로 스코어를 매겼습니다. 제가 임의로 선정한 쿼리 단어는 '디자인', '화면', '음질', '스펙', '촬영', '운영체제', '배터리' 총 7개입니다. 위의 챕터에도 설명했듯 각 리뷰별로 쿼리단어 수(제 경우엔 7개)에 해당하는 스코어들이 나옵니다. 여기서 가장 높은 값을 지닌 스코어에 해당하는 쿼리단어를 해당 리뷰가 중시하는 기능으로 분류했습니다. 결과(각 기능별 스코어 상위 5개)는 아래와 같습니다. #### 배터리 ``` 케이스 끼웠고요. 발열은 액정위에서 일어나는겁니다. ls 전자꺼 사용 중인데 충전 잘 되네요... 하지만 무선충전에 단점 발열 ㅠㅠ 근데 진짜 꼽을게..............발열뿐 아이패드2는 정말... 발열이라는 것을 몰랐는데... 베가레이서3은진짜 발열,베터리만좋으면 짱인데 ``` #### 촬영 ``` 갤럭시S 2 사진 촬영/ 동영상 촬영 촬영은 기존에 사용중인 SKT 갤투로 찰칵~ 전 카메라 화질과 720p 촬영이 중요한데 어떨런지 3d 촬영이요 헉 그렇게 무겁나요;;;;3D로 영상촬영도 된다던데;;; 잘 나오려나;; ``` #### 디자인 ``` 제가 코 파다 피나면 저 색깔 나오는데.. 아침에 똥 누다가도 가끔 나와요.. 그래서 웬지 친근한 색감 액정색깔차이만 눈에 들어오네요 이거 궁금해서 `색상` `색깔`로 한번씩 검색하니 많이 나오더라구요 미치도록 선명한 대화면 액정과 완전 편리한 UI 아몰레드에 푹 빠져봅시다!! 삼성 핸드폰은 기능은 다 좋은거같은데 ........... 색깔 드럽게 못뽑는다는 .... ``` #### 화면 ``` 갤3 화면 액정이 나갔는지.. 이상한 화면이 뜨는데요... 액정 화면은 몇 인치 인가요? 갤럭시 s3 흰색 화면 잔상 사진만 봐서는 갤스2 화면이 더 좋아보이네요. 갤스는 푸르딩딩한게 촌티나는 색상같아요 아무래도 화면밝기 낮추면 조금이라도 더 버텨주겠죠?ㅋㅋ ``` #### 운영체제 ``` 결국은 운영체제에 따라 갈릴듯. 운영체제가 다르니 비교하기 그렇죠 운영체제가... 달라서.. 운영체제가 쉣이었음 단일 운영체제 바다는 왜 그 모양인가요... ``` #### 사운드 ``` 아레나에서도 이렇게 평했군요. 정말 음질 표현을 너무 잘했네욬ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 음질은안드에서상급이죠 ㅎㅎ 음질은 좋았으니.. 잭꽃아야되지만: 음질은... 제가 막귀라서. 핸드폰 음질 다 똑같은거 아닌가요? 스피커는 저도 공감 ㅋㅋㅋㅋ 음질은 먹는건가여 수준 ``` #### 스펙 ``` 스펙으로만 따져도 옴냐2보다 아이폰이 훨씬 성능이 좋을텐데요... ^^;; 갤투가 하드웨어 스펙이 좋죠 그래서 갤투 이제 os도 같고 그렇군요... 하긴 하드웨어 스펙도 더 낫구 ㅠㅠ 갤럭시는 나올때마다 스펙종결수준이니까요..ㅎㅎ 삼성 스펙만 쩔지... 벤치는 믿을게 못될듯하오 ```  ## 마치며 이상으로 Word2Vec을 활용한 문장 분류 방법을 알아보았습니다. 이 프레임워크를 단순하게 요약하면 다음과 같습니다. 우선 TDM을 구축하고, Word2Vec 기반으로 가중치매트릭스를 생성합니다. <a href="http://imgur.com/JcJx2oe"><img src="http://i.imgur.com/JcJx2oe.png" width="500px" title="source: imgur.com" /></a> 위와 같이 구축한 가중치매트릭스와 TDM을 내적해 스코어를 산출합니다. <a href="http://imgur.com/1ul5rB8"><img src="http://i.imgur.com/1ul5rB8.png" width="500px" title="source: imgur.com" /></a> 이미 눈치 채셨겠지만 어떤 문서가 특정 쿼리 단어와 얼마나 연관성이 있는지 스코어를 낼 수 있습니다. 바꿔 말하면 쿼리 단어를 어떻게 선정하느냐에 따라 다양한 문장분류기를 만들어낼 수 있다는 얘기입니다. 질문이나 지적해주실 내용 있으시면 메일이나 댓글 등으로 해주시면 됩니다. 여기까지 읽어주셔서 감사합니다. 
logistic␞ 이번 글에서는 로지스틱회귀 모델의 계수를 추정하는 방법을 살펴보도록 하겠습니다. 이번 글은 고려대 김성범 교수님 강의와 '밑바닥부터 시작하는 데이터과학(조엘 그루스 지음, 인사이트 펴냄)'을 정리하였음을 먼저 밝힙니다. 로지스틱회귀에 대한 기본적인 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/04/02/logistic/)을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.  ## 최대우도추정법 로지스틱회귀 모델 계수를 추정하기 위해서는 우선 **최대우도추정법(Maximum Likelihood Estimation)** 개념을 먼저 짚고 넘어가야 합니다. 가령 데이터가 임의의 파라메터 $θ$에 의존하는 확률분포를 따르고 표본데이터 $v_1, v_2,...,v_n$이 주어졌다고 해보겠습니다.  우리는 데이터가 발생할 확률 $P(v_1,...,v_n$\|$θ)$를 구하고 싶은데, $θ$를 모르는 상황입니다. 따라서 우리는 [베이즈 규칙](https://ratsgo.github.io/statistics/2017/07/01/bayes/)을 활용해 다음과 같이 $θ$가 발생할 **우도(likelihood)**로 바꿔서 생각할 수 있습니다. 다시 말해 조건절과 결과절을 뒤집어 원하는 값을 구하는 것입니다. $$ L(\theta |{ v }_{ 1 },{ v }_{ 2 },...,{ v }_{ n }) $$ 이 경우 가장 적절한 $θ$는 우도를 최대화해주는 값이 될 것입니다. 다시 말해 관측된 데이터가 발생할 경우를 가장 높게 만들어주는 값이라는 의미입니다.    ## 전제 : 베르누이 분포 로지스틱 회귀는 **베르누이 시행(Bernoulli trial)**을 전제로 하는 모델입니다. 베르누이 시행이란 어떤 실험이 두 가지 결과만을 가지는 실험을 가리킵니다. 베르누이 시행의 결과에 따라 0(실패) 또는 1(성공)의 값을 대응시키는 **확률변수(random variable)**를 베르누이 확률변수라 합니다. 이 확률변수의 확률분포를 베르누이 분포라고 합니다. 베르누이 확률변수 Y의 분포는 아래 표와 같습니다. |  $Y$   |  0  | 1  | | :--------: | :----: | :--: | | $P(Y=y_i)$ | $1- p$ | $p$ | 위 표를 수식으로 정리하면 아래와 같습니다. $$P(Y={ y }_{ i })={ p }^{ { y }_{ i } }{ (1-p) }^{ 1-{ y }_{ i } }\quad ({ y }_{ i }=0,1)$$  베르누이 확률변수 Y에 관한 **우도함수(likelihood function)**는 아래와 같습니다. $$L=\prod _{ i }^{ }{ { p }^{ { y }_{ i } }{ (1-p) }^{ 1-{ y }_{ i } }} $$   ## 로지스틱회귀의 우도함수 학습데이터에 관측치가 $i$개가 있고, 정답 범주가 2개(1 또는 0)뿐인 이항로지스틱 모델의 파라메터 $β$가 주어졌다고 가정해 보겠습니다. 그러면 $i$번째 관측치의 종속변수 $y_i$는 $σ(β^Tx_i)$의 확률로 1, $1-σ(β^Tx_i)$의 확률로 0이 됩니다. 여기에서 $x_i$는 $i$번째 관측치의 독립변수, $σ$는 로지스틱 함수를 가리킵니다. 따라서 로지스틱회귀의 우도함수는 다음과 같이 쓸 수 있습니다.  $$ L=\prod _{ i }^{ }{ { \sigma ({ \beta }^{ T }\overrightarrow { { x }_{ i } } ) }^{ { y }_{ i } }{ \left\{ 1-\sigma ({ \beta }^{ T }\overrightarrow { { x }_{ i } } ) \right\} }^{ 1-{ y }_{ i } } } $$  로지스틱 회귀의 파라메터 $β$는 앞서 언급한 MLE로 구합니다. 로그는 단조 증가함수이므로 **로그 우도함수(log-likelihood function)**를 최대로 하는 회귀계수 $β$는 동시에 우도를 최대화하는 $β$이며 그 역도 성립합니다. 로그 우도함수는 아래와 같이 정리할 수 있습니다. $$ \ln { L } =\sum _{ i }^{ }{ { y }_{ i }\ln { \left\{ \sigma ({ \beta }^{ T }{ \overrightarrow { x_{ i } } }) \right\} } } +\sum _{ i }^{ }{ \left( 1-{ y }_{ i } \right) \ln { \left\{ 1-\sigma ({ \beta }^{ T }{ \overrightarrow { x_{ i } } }) \right\} } } $$  다만 위 로그 우도함수는 추정 대상 파라메터인 회귀계수 $β$에 대해 비선형이기 때문에 선형회귀와 같이 명시적인 해가 존재하지 않습니다. 따라서 **Stochastic Gradient Descent(SGD)** 같은 반복적이고 점진적인 방식으로 해를 구하게 됩니다.   ## Stochastic Gradient Descent SGD는 반복문을 돌 때마다 **개별 데이터 포인트에 대한 그래디언트를 계산**하고 이 그래디언트의 반대 방향으로 파라메터를 업데이트해 함수의 최소값을 구하는 기법입니다. 로지스틱 회귀의 파라메터는 명시적인 해가 존재하지 않기 때문에 이처럼 값을 조금씩 바꿔가면서 최적해를 찾아가는 것입니다.  그런데 우리는 로지스틱 회귀의 로그 우도를 최대화하는 파라메터 $β$를 찾으려는 것이므로 기존 SGD의 반대 방향으로 업데이트를 수행해야 할 것입니다. SGD 관련 메인 파이썬 코드는 다음과 같습니다.  ```python def minimize_stochastic(target_fn, gradient_fn, x, y, theta_0, alpha_0=0.01):   # SGD 방식으로 gradient descent   # minimize_batch보다 훨씬 빠르다   data = zip(x, y)   # theta_0를 초기 theta로   theta = theta_0   # alpha_0를 초기 이동거리(step_size)로   alpha = alpha_0   # 시작할 때의 최소값   min_theta, min_value = None, float("inf")   iterations_with_no_improvement = 0   # 만약 100번 넘게 반복하는 동안 value가 더 작아지지 않으면 멈춤   while iterations_with_no_improvement < 100:     value = sum( target_fn(x_i, y_i, theta) for x_i, y_i in data )     # 새로운 최솟값을 찾았다면     if value < min_value:       # 이 값을 저장       min_theta, min_value = theta, value       # 100번 카운트도 초기화       iterations_with_no_improvement = 0       # 기본 이동거리로 돌아감       alpha = alpha_0     # 만약 최솟값이 줄어들지 않는다면     else:       # 이동거리 축소       alpha *= 0.9       # 100번 카운트에 1을 더함       iterations_with_no_improvement += 1 		     # 반복문이 돌 때마다 in_random_order를 호출하기 때문에     # 매 iter마다 그래디언트를 계산하는 순서가 달라짐     for x_i, y_i in in_random_order(data):       # 각 데이터 포인트에 대해 그래디언트를 계산       gradient_i = gradient_fn(x_i, y_i, theta)       # 기존 theta에서, 학습률(alpha)과 그래디언트를 뺀 것을 업데이트       theta = vector_subtract(theta, scalar_multiply(alpha, gradient_i))   return min_theta # maximize_stochastic = -minimize_stochastic def maximize_stochastic(target_fn, gradient_fn, x, y, theta_0, alpha_0=0.01):   return minimize_stochastic(negate(target_fn),                negate_all(gradient_fn),                x, y, theta_0, alpha_0) # x를 입력하면 -f(x)를 반환해주는 함수 def negate(f):   return lambda *args, **kwargs: -f(*args, **kwargs) # f가 여러 숫자를 반환할 때 모든 숫자를 음수로 변환 def negate_all(f):   return lambda *args, **kwargs: [-y for y in f(*args, **kwargs)] ``` 그러면 이제는 target_fn과 gradient_fn, theta를 정의해야 합니다. target_fn은 목적함수로 로그 우도를 아웃풋으로 산출하는 함수를 의미합니다. 로지스틱회귀 모델의 로그 우도함수는 다음과 같습니다. ```python import math # 로지스틱 함수 def logistic(x):   return 1.0 / (1 + math.exp(-x)) # 로지스틱 함수의 1차 도함수 def logistic_prime(x):   return logistic(x) * (1 - logistic(x)) # i번째 관측치에 대한 로그우도 def logistic_log_likelihood_i(x_i, y_i, beta):   # y_i의 레이블이 1이면   if y_i == 1:     return math.log(logistic(dot(x_i, beta)))   # y_i의 레이블이 0이면   else:     return math.log(1 - logistic(dot(x_i, beta))) # 데이터 전체에 대한 로그우도 (전체 합) def logistic_log_likelihood(x, y, beta):   return sum(logistic_log_likelihood_i(x_i, y_i, beta)        for x_i, y_i in zip(x, y)) ``` 'gradient_fn'은 각 파라메터에 대한 목적함수의 그래디언트를 가리킵니다. 미분 공식을 활용해 로그우도 함수를 $β$에 대해 해석적으로 미분한 식을 코드로 표현한 것입니다. ```python def logistic_log_partial_ij(x_i, y_i, beta, j):   """here i is the index of the data point,   j the index of the derivative"""   return (y_i - logistic(dot(x_i, beta))) * x_i[j]   def logistic_log_gradient_i(x_i, y_i, beta):   """the gradient of the log likelihood   corresponding to the i-th data point"""   return [logistic_log_partial_ij(x_i, y_i, beta, j)       for j, _ in enumerate(beta)]       def logistic_log_gradient(x, y, beta):   return reduce(vector_add,          [logistic_log_gradient_i(x_i, y_i, beta)          for x_i, y_i in zip(x,y)])   ``` 마지막으로 'theta'는 해당 목적함수의 파라메터인데요, 우리 문제에선 $β$를 말합니다. 만약 독립변수가 2개라면 상수항을 포함해 3차원 벡터가 될 것입니다. 이밖에 위 코드 실행에 필요한 함수는 다음과 같습니다. ```python def in_random_order(data):   # Stochastic Gradient Descent 수행을 위한 함수로,   # 한번 반복문을 돌 때마다 임의의 순서로 데이터 포인트를 반환   # 데이터 포인트의 인덱스를 list로 생성   indexes = [i for i, _ in enumerate(data)]   # 이 인덱스를 랜덤하게 섞는다   random.shuffle(indexes)   # 이 순서대로 데이터를 반환한다   for i in indexes:     yield data[i] def vector_subtract(v, w):   """subtracts two vectors componentwise"""   return [v_i - w_i for v_i, w_i in zip(v,w)] def scalar_multiply(c, v):   return [c * v_i for v_i in v] def dot(v, w):   """v_1 * w_1 + ... + v_n * w_n"""   return sum(v_i * w_i for v_i, w_i in zip(v, w)) ```   ## 분석 예시 분석 대상 데이터는 다음과 같습니다. 독립변수는 2개, 독립변수는 범주형 1개(0 또는 1)입니다. ```python data = [(0.7,48000,1),(1.9,48000,0),(2.5,60000,1),(4.2,63000,0),(6,76000,0),(6.5,69000,0),(7.5,76000,0),(8.1,88000,0),(8.7,83000,1),(10,83000,1),(0.8,43000,0),(1.8,60000,0),(10,79000,1),(6.1,76000,0),(1.4,50000,0),(9.1,92000,0),(5.8,75000,0),(5.2,69000,0),(1,56000,0),(6,67000,0),(4.9,74000,0),(6.4,63000,1),(6.2,82000,0),(3.3,58000,0),(9.3,90000,1),(5.5,57000,1),(9.1,102000,0),(2.4,54000,0),(8.2,65000,1),(5.3,82000,0),(9.8,107000,0),(1.8,64000,0),(0.6,46000,1),(0.8,48000,0),(8.6,84000,1),(0.6,45000,0),(0.5,30000,1),(7.3,89000,0),(2.5,48000,1),(5.6,76000,0),(7.4,77000,0),(2.7,56000,0),(0.7,48000,0),(1.2,42000,0),(0.2,32000,1),(4.7,56000,1),(2.8,44000,1),(7.6,78000,0),(1.1,63000,0),(8,79000,1),(2.7,56000,0),(6,52000,1),(4.6,56000,0),(2.5,51000,0),(5.7,71000,0),(2.9,65000,0),(1.1,33000,1),(3,62000,0),(4,71000,0),(2.4,61000,0),(7.5,75000,0),(9.7,81000,1),(3.2,62000,0),(7.9,88000,0),(4.7,44000,1),(2.5,55000,0),(1.6,41000,0),(6.7,64000,1),(6.9,66000,1),(7.9,78000,1),(8.1,102000,0),(5.3,48000,1),(8.5,66000,1),(0.2,56000,0),(6,69000,0),(7.5,77000,0),(8,86000,0),(4.4,68000,0),(4.9,75000,0),(1.5,60000,0),(2.2,50000,0),(3.4,49000,1),(4.2,70000,0),(7.7,98000,0),(8.2,85000,0),(5.4,88000,0),(0.1,46000,0),(1.5,37000,0),(6.3,86000,0),(3.7,57000,0),(8.4,85000,0),(2,42000,0),(5.8,69000,1),(2.7,64000,0),(3.1,63000,0),(1.9,48000,0),(10,72000,1),(0.2,45000,0),(8.6,95000,0),(1.5,64000,0),(9.8,95000,0),(5.3,65000,0),(7.5,80000,0),(9.9,91000,0),(9.7,50000,1),(2.8,68000,0),(3.6,58000,0),(3.9,74000,0),(4.4,76000,0),(2.5,49000,0),(7.2,81000,0),(5.2,60000,1),(2.4,62000,0),(8.9,94000,0),(2.4,63000,0),(6.8,69000,1),(6.5,77000,0),(7,86000,0),(9.4,94000,0),(7.8,72000,1),(0.2,53000,0),(10,97000,0),(5.5,65000,0),(7.7,71000,1),(8.1,66000,1),(9.8,91000,0),(8,84000,0),(2.7,55000,0),(2.8,62000,0),(9.4,79000,0),(2.5,57000,0),(7.4,70000,1),(2.1,47000,0),(5.3,62000,1),(6.3,79000,0),(6.8,58000,1),(5.7,80000,0),(2.2,61000,0),(4.8,62000,0),(3.7,64000,0),(4.1,85000,0),(2.3,51000,0),(3.5,58000,0),(0.9,43000,0),(0.9,54000,0),(4.5,74000,0),(6.5,55000,1),(4.1,41000,1),(7.1,73000,0),(1.1,66000,0),(9.1,81000,1),(8,69000,1),(7.3,72000,1),(3.3,50000,0),(3.9,58000,0),(2.6,49000,0),(1.6,78000,0),(0.7,56000,0),(2.1,36000,1),(7.5,90000,0),(4.8,59000,1),(8.9,95000,0),(6.2,72000,0),(6.3,63000,0),(9.1,100000,0),(7.3,61000,1),(5.6,74000,0),(0.5,66000,0),(1.1,59000,0),(5.1,61000,0),(6.2,70000,0),(6.6,56000,1),(6.3,76000,0),(6.5,78000,0),(5.1,59000,0),(9.5,74000,1),(4.5,64000,0),(2,54000,0),(1,52000,0),(4,69000,0),(6.5,76000,0),(3,60000,0),(4.5,63000,0),(7.8,70000,0),(3.9,60000,1),(0.8,51000,0),(4.2,78000,0),(1.1,54000,0),(6.2,60000,0),(2.9,59000,0),(2.1,52000,0),(8.2,87000,0),(4.8,73000,0),(2.2,42000,1),(9.1,98000,0),(6.5,84000,0),(6.9,73000,0),(5.1,72000,0),(9.1,69000,1),(9.8,79000,1),] ``` 전체 코드를 구동하는 명령은 다음과 같습니다. ```python import random data = map(list, data) # change tuples to lists x = [[1] + row[:2] for row in data] # each element is [1, experience, salary] y = [row[2] for row in data] # each element is paid_account beta_0 = [1, 1, 1] beta_hat = maximize_stochastic(logistic_log_likelihood_i,                 logistic_log_gradient_i,                 x, y, beta_0) ```  
binomial␞ 이번 글에서는 이항분포, 다항분포, 베타분포, 디리클레분포에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 이항분포 성공확률이 $p$인 베르누이시행을 $n$번 반복시행할 때 성공횟수를 나타내는 확률변수 $X$의 분포를 **이항분포(binomial distribution)**이라고 합니다. 이항분포의 확률질량함수는 다음과 같습니다.  $$ p(x)=\begin{pmatrix} n \\ x \end{pmatrix}{ p }^{ x }{ (1-p) }^{ n-x },\quad x=0,1,...n $$  이항분포의 확률질량함수를 시각화하면 다음 그림과 같습니다. (출처 : [위키피디아](https://ko.wikipedia.org/wiki/%EC%9D%B4%ED%95%AD_%EB%B6%84%ED%8F%AC)) <a href="http://imgur.com/7o7SoGn"><img src="http://i.imgur.com/7o7SoGn.png" width="350px" title="source: imgur.com" /></a> $X$의 기대값과 분산은 다음과 같습니다.  $$ E(X)=np\\ Var(X)=np(1-p) $$  ## 베타분포 **베타분포(beta distribution)**란 두 매개변수 $α$와 $β$에 대해 $[0,1]$에서 정의되는 연속확률분포들의 가족을 가리킵니다. 베타분포의 확률밀도함수는 다음과 같습니다.  $$f(x;\alpha ,\beta )=\frac { \Gamma (\alpha +\beta ) }{ \Gamma (\alpha )\Gamma (\beta ) } { x }^{ \alpha -1 }{ (1-x) }^{ \beta -1 }$$  베타분포의 확률밀도함수인 감마함수 $Γ$는 다음과 같이 정의됩니다.  $$\Gamma (n)=(n-1)!$$  $α$, $β$ 값에 따라 베타분포의 모양 또한 달라지는데요. 다음 그림을 참고하시면 좋을 것 같습니다. ([출처](https://books.google.co.kr/books/
about/Doing_Bayesian_Data_Analysis.html?id=ZRMJ-CebFm4C&hl=ko))  <a href="http://imgur.com/lna2sdm"><img src="http://i.imgur.com/lna2sdm.jpg" width="550px" title="source: imgur.com" /></a>   ## 다항분포 **다항분포(Multinomial)**란 여러 개의 값을 가질 수 있는 독립 확률변수들에 대한 확률분포를 가리킵니다. 여러 번의 독립시행에서 각각의 값이 특정 횟수가 나타날 확률을 말합니다.  어떤 시행에서 $k$가지의 값이 나타날 수 있고, 그 값이 나타날 확률을 각각 $p_1, p_2, ...,p_k$라고 할 때 $n$번의 시행에서 $i$번째 값이 $x_i$회 나타날 확률은 다음과 같습니다. 즉 다항분포의 확률질량함수는 아래와 같습니다.  $$ p({ x }_{ 1 },{ x }_{ 2 },...,{ x }_{ k };n,{ p }_{ 1 },...,{ p }_{ k })=\frac { n! }{ { x }_{ 1 }!{ x }_{ 2 }!...{ x }_{ k }! } { p }_{ 1 }^{ { x }_{ 1 } }{ p }_{ 2 }^{ { x }_{ 2 } }...{ p }_{ k }^{ { x }_{ k } } $$  예를 들어보겠습니다. 전체 말뭉치의 단어 개수가 $v$개이고, 첫번째 단어가 말뭉치에 등장할 확률이 $p_{v1}$, 두번째 단어는 $p_{v2}$,...,$v$번째 단어는 $p_{vv}$라고 가정해보겠습니다. 여기에서 말뭉치에서 단어를 $n$개 뽑을 때 첫번째 단어가 나타날 횟수는 $x_1$,...$v$번째 단어는 $x_v$가 됩니다.   ## 디리클레분포 **디리클레분포**란 $k$차원의 실수 벡터 중 벡터의 요소가 양수이며 모든 요소를 더한 값이 1인 경우에 확률값이 정의되는 연속확률분포입니다. 2이상의 자연수 $k$와 양의 상수 $α_1,...,α_k$에 대하여 디리클레분포의 확률밀도함수는 다음과 같이 정의됩니다.  $$ \begin{align*} &{ x }_{ 1 },...,{ x }_{ k }가\quad모두 \quad양의 \quad실수이며 \quad\sum _{ i=1 }^{ k }{ { x }_{ i } } =1을 \quad만족할 \quad때,\\ &f({ x }_{ 1 },...{ x }_{ k };{ \alpha }_{ 1 },...,{ \alpha }_{ k })=\frac { 1 }{ B(\alpha ) } \prod _{ i=1 }^{ k }{ { { x }_{ i } }^{ { \alpha }_{ i }-1 } } \\&그 \quad외의 \quad경우는 \quad0이다. \end{align*} $$  $B(α)$는 다음과 같습니다.  $$ B(\alpha )=\frac { \prod _{ i=1 }^{ k }{ \Gamma ({ \alpha }_{ i }) } }{ \Gamma (\sum _{ i=1 }^{ k }{ { \alpha }_{ i } } ) } $$  3차원 디리클레 분포의 모양은 다음과 같습니다. 왼쪽 위에서부터 시계방향으로 $α$=(6, 2, 2), (3, 7, 5), (6, 2, 6), (2, 3, 4) <a href="http://imgur.com/EcCKDmI"><img src="http://i.imgur.com/EcCKDmI.png" width="400px" title="source: imgur.com" /></a>  ## 켤레사전분포 사후확률 분포 $p(θ$\|$x)$가 사전확률 분포 $p(θ)$와 같은 가족군으로 묶일 때 그 사후확률/사전확률을 모두 묶어 **켤레분포(conjugate distributions)**, 그 사전확률 분포를 **켤레사전분포(Conjugate prior distribution)**라고 합니다. 사전확률과 사후확률이 동일한 분포를 따른다면 계산이 매우 편해지기 때문에 베이즈 통계학에서 많이 쓴다고 합니다. 그 관계를 따지면 다음과 같습니다. | 우도 |   켤레사전분포    |    사후확률분포    |     파라메터의 의미     | | :--: | :---------------: | :----------------: | :------------------------: | | 이항분포 | 베타분포 $Beta(α​,β)$ | 베타분포 $Beta(α',β')$ | 성공횟수 : $α-1$, 실패횟수 : $β-1$ | | 다항분포 | 디리클레분포 $Dir(α)$ | 디리클레분포 $Dir(α')$ | $i$번째 범주가 나타날 횟수 : $α_i-1$ |
parsing␞ 이번 글은 한국어 기본문을 **통사원자(syntactic atom)**로 구성된 계층구조로 분석하는 **파싱(parsing)** 방법에 대해 살펴보도록 하겠습니다. 이 글은 국어 기본문의 문법 구조를 밝힌 [박진호(1994)](http://snu-primo.hosted.exlibrisgroup.com/primo_library/libweb/action/display.do;jsessionid=34C21F62737C42FF119900F21267FE7C?tabs=viewOnlineTab&ct=display&fn=search&doc=82SNU_INST21481461470002591&indx=1&recIds=82SNU_INST21481461470002591&recIdxs=0&elementId=0&renderMode=poppedOut&displayMode=full&frbrVersion=&frbg=&&dscnt=0&scp.scps=scope%3A%2882SNU_SSPACE%29%2Cscope%3A%2882SNU_INST%29%2Cscope%3A%2882SNU_COURSE%29%2Cscope%3A%2882SNU_ROSETTA%29%2Cprimo_central_multiple_fe&tb=t&vid=82SNU&mode=Basic&srt=rank&tab=all&prefLang=ko_KR&dum=true&vl(freeText0)=%EB%B0%95%EC%A7%84%ED%98%B8%20%ED%86%B5%EC%82%AC%EC%A0%81%20%EA%B2%B0%ED%95%A9%EA%B4%80%EA%B3%84%EC%99%80%20%EB%85%BC%ED%95%AD%EA%B5%AC%EC%A1%B0&dstmp=1492745945406)를 정리했음을 먼저 밝힙니다. 자연언어처리라는 목적을 위해 원저작의 내용을 상당히 단순화했다는 점 또한 먼저 말씀드립니다. 그럼 시작하겠습니다.  ## 기본 원리 우선 아래 예문을 살펴보겠습니다.  > 철수가 밥을 먹었다 이 문장을 파싱하려면 어떻게 해야할까요? '먹었다'라는 서술어는 의미론적으로 행위주(철수가)와 대상(밥을)을 요구하므로 당장 떠오르는 방법은 아래와 같을 겁니다.  <a href="http://imgur.com/jWuVE3b"><img src="http://i.imgur.com/jWuVE3b.png" width="600px" title="source: imgur.com" /></a> 그런데 자세히 살펴보면 선어말어미 '-었-'은 '철수라는 사람이 밥을 먹은 행위가 과거에 있었다'는 의미를 나타냅니다. 다시 말해 '-었-'은 어간 '먹-'이 아니라 '철수가 밥을 먹-'이라는 큰 단위와 결합했다고 보는게 자연스럽다는 것이지요. 이는 한국어의 다른 문장도 마찬가지입니다. > ㄱ. 어제 철수는 청소를 하고 영희는 빨래를 하였다. > > ㄴ. 지금쯤 철수는 청소를 하고 영희는 빨래를 하겠다. 위 두 문장에서 철수가 청소를 한 시점은 언제일까요? 한국어 화자라면 (ㄱ)은 과거, (ㄴ)은 현재(추측)라는 것을 단번에 알아차릴 수 있을 겁니다.  두 문장 모두 '철수는 청소를 하고'라는 동일한 표현을 썼습니다. 그럼에도 이렇게 의미(시점)가 달라지는 이유는 무엇일까요? 선어말어미 '-었-', '-겠-'이 어간 '하-'가 아니라 '철수는 청소를 하고 영희는 빨래를 하-'라는 큰 단위와 결합했기 때문입니다. 따라서 '철수가 밥을 먹었다'는 문장은 다음과 같이 분석할 수 있습니다. <a href="http://imgur.com/qvR3yiz"><img src="http://i.imgur.com/qvR3yiz.png" width="500px" title="source: imgur.com" /></a> 여기에서 **핵(head)** 개념이 등장합니다. 명사, 동사, 조사, 어미 등 개별 통사원자들이 위 그림처럼 위계적 구조를 가지고 결합한 것이 문장입니다. 두 통사원자가 결합하여 이루는 상위 단위의 통사적(문법적) 성격은 하위 요소의 통사적 성격에 의해 결정됩니다. 대개 둘 중 어느 한 요소가 중심적 역할을 맡게 되는데요, 이 때 중심 역할을 하는 요소를 '핵'이라고 합니다. 박진호(1994)에 따르면 위 문장에서 '철수'라는 명사는 격조사 '-가'와 결합해 (주)격조사구(phrase)가 됩니다. 격조사 '-가'가 핵이라는 이야기입니다. 마찬가지로 (목적)격조사구 '밥을'에서는 '-을'이 핵입니다. '밥을 먹-'이라는 동사구에서는 동사 '먹-'이 핵입니다.  다시 말해 '철수가'는 문장의 주어 역할을, '밥을'은 목적어 역할을, '밥을 먹-'은 동사 역할을 하는데요, 이렇게 결합 이후의 통사적 성격 결정에 중요한 영향을 끼치는 것이 바로 핵이라고 말할 수 있습니다. 박진호(1994)는 한국어 통사원자의 범주를 8개로 나누고 그 기호를 아래와 같이 정의했습니다. 이후 예시에서 이 표기를 따르도록 하겠습니다. | 명사 | 동사 | 격조사 | 문말어미 | 보조사 | 선문말어미 | 관형사 | 부사 | | :--: | :--: | :--: | :--: | :--: | :---: | :--: | :--: | | N  | V  | K  | C  | D  |  I  | ADN | ADV |   ## 국어 기본문의 논항 구조 **논항(argument)**이란 핵과 대비되는 개념으로, 핵이 요구하는 필수적 성분을 일컫는 용어입니다. 예컨대 '먹-'이라는 동사는 '밥' 같은 명사(구)를 반드시 필요로 합니다. 따라서 '밥 먹-'에서 핵은 동사, 논항은 '밥'이 되는 것입니다.   ### 선문말어미 선문말어미는 동사구 하나와 결합하며 선행 동사구(철수 밥 먹)가 핵이 됩니다. 다시 말해 선문말어미는 동사구의 논항입니다. <a href="http://imgur.com/OnISMqi"><img src="http://i.imgur.com/OnISMqi.png" width="300px" title="source: imgur.com" /></a>   ### 문말어미 동사구가 문말어미와 결합할 때는 문말어미가 핵이 됩니다. 다시 말해 동사구는 문말어미의 논항입니다. 동사구와 문말어미가 결합함으로써 **절(節)**이 됩니다. 아래와 같이 '-다'라는 문말어미는 동사구 한 개를 논항으로 가집니다. <a href="http://imgur.com/Cyekxhd"><img src="http://i.imgur.com/Cyekxhd.png" width="250px" title="source: imgur.com" /></a> 그러나 문말어미가 아래와 같이 **연결어미**일 경우에는 선행 동사구 하나, 후행 동사구 하나, 이렇게 두 개의 논항을 가집니다. 연결어미는 선행 동사구와 결합할 때는 핵이 되지만 후행 요소와 결합할 때는 비핵이 됩니다. <a href="http://imgur.com/DsmCBTa"><img src="http://i.imgur.com/DsmCBTa.png" width="250px" title="source: imgur.com" /></a> 문말어미가 **관형사형어미**일 경우 선행 동사구 하나, 후행 명사구 하나, 이렇게 두 개의 논항을 가집니다. 관형사형어미는 선행 동사구와 결합할 때는 핵이 되지만 후행 요소와 결합할 때는 비핵이 됩니다. <a href="http://imgur.com/XkAJIS9"><img src="http://i.imgur.com/XkAJIS9.png" width="250px" title="source: imgur.com" /></a>  ### 조사 (격조사/보조사) 조사는 대체로 개체와 그 개체가 참여하는 사건 사이의 관계를 나타내 줍니다. 관계란 정의상 두 개의 항(term)의 존재를 전제로 하기 때문에 조사는 격조사이든 보조사이든 두 개의 논항을 취합니다.  격조사는 선행 명사구와 결합할 때는 핵이 되지만 후행 동사구와 결합할 때는 비핵이 됩니다. <a href="http://imgur.com/c3NIUnP"><img src="http://i.imgur.com/c3NIUnP.png" width="250px" title="source: imgur.com" /></a> 반면 보조사는 늘 비핵입니다. <a href="http://imgur.com/B0Wm4aa"><img src="http://i.imgur.com/B0Wm4aa.png" width="250px" title="source: imgur.com" /></a>  ### 관형사와 부사 관형사는 후행 명사구 하나, 부사는 후행 동사구 하나를 논항으로 각각 취합니다. 이들은 모두 후행 요소와 결합할 때 비핵이 됩니다. <a href="http://imgur.com/BmIHLiQ"><img src="http://i.imgur.com/BmIHLiQ.png" width="200px" title="source: imgur.com" /></a> <a href="http://imgur.com/DGnPojK"><img src="http://i.imgur.com/DGnPojK.png" width="200px" title="source: imgur.com" /></a>  ### 동사와 명사 동사와 명사는 다른 범주와 달리 논항의 자릿수(개수)가 일률적으로 정해져 있지 않고, 개별 어휘에 따라 다릅니다. 박진호(1994)에 따르면 한국어 동사의 자릿수는 대체로 하나에서 셋이라고 합니다. 대표적 사례는 아래 표와 같습니다. | 어휘 |   자릿수   |    예시    | | :--: | :-----------: | :-------------: | | 죽- |  1개(주체)   |   개가 죽-   | | 먹- |  2개(주체/대상)  |  철수가 밥을 먹-  | | 주- | 3개(주체/수혜자/대상) | 영희가 철수에게 선물을 주- | 명사의 경우 자릿수가 0인 경우가 대다수라고 합니다. 그러나 공부, 연구, 살해 등처럼 행위의 주체와 대상을 논항으로 요구하거나 소문, 사실, 이유처럼 명제를 논항으로 취하는 명사도 꽤 있습니다. 명사와 동사 모두 자신의 논항과 결합할 때 핵이 됩니다.   ## 복잡한 문장 분석하기 이번 항목에서는 지금까지 설명해드린 기본문보다 복잡한 구조를 지닌 문장을 분석해보도록 하겠습니다.  ### 전수 명사구 '내가 살던 집'은 아래와 같이 분석할 수 있습니다. 우선 격조사구 '내가'에 동사 '살-'이 결합해 동사구가 됩니다. 여기에 문말어미(관형사형어미) '-던'이 붙어 절이 됩니다. 마지막으로 '집'이라는 명사와 '내가 살던'이라는 부가어 절이 결합해 '내가 살던 집'이라는 명사구를 이룹니다. <a href="http://imgur.com/VM01xwQ"><img src="http://i.imgur.com/VM01xwQ.png" width="350px" title="source: imgur.com" /></a> 그렇다면 '나의 살던 집'은 어떻게 분석해야 할까요? 아래와 같습니다. <a href="http://imgur.com/DPGh8Ed"><img src="http://i.imgur.com/DPGh8Ed.png" width="400px" title="source: imgur.com" /></a> '나의 살던 집'에서 '나의'는 관형격이므로 동사 '살-' 혹은 동사구 '살던'과는 결합할 수 없고, 명사구 '살던 집'과 결합할 수밖에 없습니다. 동사 '살-'은 행위주역과 장소역을 논항으로 가지는데요, 위 예시에서는 '살-'이 자신의 행위주역 논항에 대한 지배권을 '-던'에, 그리고 다시 '집'에 **전수(inheritance)**했기 때문에 가능한 것입니다.  ### 합류 '철수가 먹은 떡'은 아래와 같이 분석할 수 있습니다. <a href="http://imgur.com/XkAJIS9"><img src="http://i.imgur.com/XkAJIS9.png" width="300px" title="source: imgur.com" /></a> 동사구 '철수가 먹-'은 대상역을 논항으로 가집니다. 문말어미(관형사형어미) '-은'은 선행 동사구와 후행 명사구를 논항으로 가집니다. 이 둘이 결합하면서 '철수가 먹-'의 대상역 논항과 '-은'의 후행 명사구 논항이 **합류(merge)**하는 걸 볼 수 있습니다. 다시 말해 '떡'은 동사구 '철수가 먹-'의 논항이면서, 동시에 문말어미 '-은'의 논항이기도 합니다.  ### 조사 중출 국어에서는 하나의 명사구에 조사가 둘 이상 붙는 것이 가능합니다. 특히 격조사와 보조사가 하나씩 붙는 일은 매우 흔합니다. '철수는 영희만을 사랑한다'에서 '영희만을 사랑하-'를 분석하면 아래와 같습니다. <a href="http://imgur.com/jUKXNcq"><img src="http://i.imgur.com/jUKXNcq.png" width="300px" title="source: imgur.com" /></a>  ### 대등 접속 문장 내에서 명사(구)가 연결되는 경우 아래와 같이 분석할 수 있습니다. <a href="http://imgur.com/8f4nLc3"><img src="http://i.imgur.com/8f4nLc3.png" width="250px" title="source: imgur.com" /></a> 명사(구)를 병렬적으로 나열하는 경우 아래와 같이 분석할 수 있습니다. <a href="http://imgur.com/HVgS8AH"><img src="http://i.imgur.com/HVgS8AH.png" width="500px" title="source: imgur.com" /></a>  ### 안긴 문장(내포문) '철수는 영수에게 일하라고 명령했다'에서 '영수에게 일하라고 명령하-'를 분석하면 아래와 같습니다. <a href="http://imgur.com/2JetXep"><img src="http://i.imgur.com/2JetXep.png" width="450px" title="source: imgur.com" /></a>  ### 이어진 문장(접속문) '철수는 식사를 마치고 집을 나섰다'에서 '식사를 마치고 집을 나서-'를 분석하면 아래와 같습니다. <a href="http://imgur.com/yBMdFvx"><img src="http://i.imgur.com/yBMdFvx.png" width="550px" title="source: imgur.com" /></a>  ### tough 구문 안긴 문장 동사의 목적어 논항이 목적격뿐 아니라 주격으로도 나타나는 일이 있습니다. (a)의 경우 안긴 문장 동사 '잡-'의 목적어 논항이 목적격의 '파리를'로 실현됐는데, (b)는 주격의 '파리가'로 실현됐습니다. 이와 같은 구문을 언어학에서는 **tough 구문**이라고 부릅니다. > (a) 파리를 잡기가 어렵다 > > (b) 파리가 잡기가 어렵다 (a)를 분석하면 아래와 같습니다. <a href="http://imgur.com/TVpuEuo"><img src="http://i.imgur.com/TVpuEuo.png" width="450px" title="source: imgur.com" /></a> (b)를 분석하면 아래와 같습니다. <a href="http://imgur.com/PwQQkn2"><img src="http://i.imgur.com/PwQQkn2.png" width="500px" title="source: imgur.com" /></a> 국어에서는 tough 구문을 허용하는 동사가 많지는 않다고 합니다. '쉽-', '어렵-', '수월하-', '힘들-' 같이 어렵고 힘듬을 나타내는 동사가 대표적입니다. 심리 동사 가운데 '싶-'과 '싫-'도 이 범주에 포함됩니다.  ### 목적어의 인상 구문 '영희는 철수를 바보로 생각한다'에서 '철수를 바보로 생각하-'를 분석하면 아래와 같습니다. <a href="http://imgur.com/WhHJvYn"><img src="http://i.imgur.com/WhHJvYn.png" width="500px" title="source: imgur.com" /></a>  ### 이중주어문 아래 예시의 이중주어문은 각각 다음과 같이 분석할 수 있습니다. > (가) 철수의 손이 크다 > > (나) 철수가 손이 크다 <a href="http://imgur.com/Rq2KSrv"><img src="http://i.imgur.com/Rq2KSrv.png" width="400px" title="source: imgur.com" /></a> <a href="http://imgur.com/dK3td4s"><img src="http://i.imgur.com/dK3td4s.png" width="450px" title="source: imgur.com" /></a>  ## 분석 예시 지금까지 논의한 내용을 바탕으로 아래 문장을 다음과 같이 분석해볼 수 있습니다. > 철수와 영희가 영수에게만 복종하였다 <a href="http://imgur.com/LEBKcIT"><img src="http://i.imgur.com/LEBKcIT.png" width="600px" title="source: imgur.com" /></a>  ## 마치며 이상으로 한국어 파싱의 기본 원칙에 대해 살펴보았습니다. 논문을 읽고 정리하면서 저자의 실력에 여러번 감탄할 수밖에 없었습니다. 영어 파싱에 관해서는 여러 자료들이 많으나 한국어 파싱에 관해서는 이만한 논문이 없다는 생각이 듭니다. 개인적으로 모델만큼 언어학 공부를 많이 해야겠다는 다짐을 또한 하게 됐습니다. 한편 **Recursive Neural Networks**는 이러한 계층구조의 데이터를 입력으로 받는 대표적인 모델인데요, 자세한 내용을 알아보시려면 [이곳](https://ratsgo.github.io/deep%20learning/2017/04/03/recursive/) 방문을 권해드립니다.      
spaces␞ 이번 글에서는 벡터공간, 부분공간, 열공간, 영공간, 차원, 기저, 위수 등 선형대수학의 기본 개념들에 대해 살펴보겠습니다. 이번 글은 고려대 박성빈 교수님 강의와 David C. Lay의 Linear Algebra (4th edition)을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 벡터공간의 정의 다음 조건을 만족하는 벡터 집합 $V$를 **벡터공간(Vector Space)**이라고 합니다. $u, v, w$는 $V$에 속하는 임의의 벡터, $c,d$는 임의의 스칼라입니다. > (1) $u+v∈V$ > > (2) $u+v=v+u$ > > (3) $(u+v)+w=u+(v+w)$ > > (4) $u+0=u$를 만족하는 영벡터가 $V$의 원소이다. > > (5) $u+(-u)=0$을 만족하는 벡터 u가 $V$의 원소이다. > > (6) $cu∈V$ > > (7) $c(u+v)=cu+cv$ > > (8) $(c+d)u=cu+du$ > > (9) $c(du) = (cd)u$ > > (10) $1u = u$ 그러면 벡터공간의 예 몇 가지를 살펴보도록 하겠습니다. 우선 $R^n(n≥2)$는 벡터공간의 자명한 예입니다. 실수는 사칙연산에 대해 닫혀 있고, 항등원과 역원이 존재하므로 (1)~(10)이 모두 성립합니다. 이번엔 최고차항이 $n$차인 **모든** 다항식의 집합 $P_n$은 벡터공간임을 증명해보겠습니다. $p,q$는 $P_n$의 임의의 원소 두 개입니다.  $$ \begin{align*} p(t)&={ a }_{ 0 }+{ a }_{ 1 }t+{ a }_{ 2 }{ t }^{ 2 }+...+{ a }_{ n }{ t }^{ n }\\ q(t)&={ b }_{ 0 }+{ b }_{ 1 }t+{ b }_{ 2 }{ t }^{ 2 }+...+{ b }_{ n }{ t }^{ n } \end{align*} $$ 다항식은 스칼라곱과 교환, 결합법칙이 성립하고, 영벡터(모든 계수가 0)도 원소가 되므로 (1)~(10)이 모두 성립합니다. 따라서 $P_n​$은 벡터공간이 됩니다. 이번엔 모든 **실수치함수(real-valued functions)**로 구성된 집합이 벡터공간임을 살펴보겠습니다. 이 공간의 원소는 다항함수, 삼각함수, 로그함수 등 모든 종류의 실수치함수입니다.  실수치함수도 스칼라곱과 교환, 결합법칙이 성립하고, 영벡터도 원소가 되므로 (1)~(10)이 모두 성립합니다. 따라서 모든 실수치함수로 구성된 집합은 벡터공간이 됩니다.   ## 부분공간 벡터공간 $V$의 부분집합인 $H$가 다음을 만족할 때 **부분공간(subspace)**이라고 합니다. > (1) $V$에 속하는 **영벡터(zero vector)**가 $H$의 원소이다. > > (2) $u, v∈H$, $u+v∈H, v+u∈H$ > > (3) $u∈H$이고 임의의 스칼라 $c$에 대해 $cu∈H$ 예를 들어 보겠습니다. $v_1$과 $v_2$를 $n$차원 벡터, H=span{$v_1, v_2$}라고 두겠습니다. 그러면 $H$는 $R^n$의 부분공간입니다. 왜냐하면 $H$에 영벡터가 포함($0v_1+0v_2$)되어 있고 span의 정의에 의해 덧셈과 스칼라 곱에 닫혀 있기 때문입니다. $v_1$과 $v_2$를 2차원 벡터라고 두면 $H$는 아래 그림처럼 원점을 지나는 평면이 될 겁니다. <a href="http://imgur.com/kp54jVK"><img src="http://i.imgur.com/kp54jVK.png" width="200px" title="source: imgur.com" /></a> 이번엔 H=span{$v_1, kv_1$}이라 두겠습니다($v_1≠0$). 이때 $H$도 $R^n$의 부분공간이 되고, 아래 그림처럼 원점을 지나는 직선이 될 겁니다. <a href="http://imgur.com/LTE5N2v"><img src="http://i.imgur.com/LTE5N2v.png" width="250px" title="source: imgur.com" /></a> 하지만 아래 예처럼 원점을 통과하지 않는 직선은 $R^n$의 부분공간이 될 수 없습니다. 영벡터가 포함되지 않을 뿐더러 덧셈이나 스칼라곱에 닫혀 있지 않기 때문입니다. <a href="http://imgur.com/O0pXBjw"><img src="http://i.imgur.com/O0pXBjw.png" width="500px" title="source: imgur.com" /></a>  부분공간의 예 몇 가지를 더 살펴보겠습니다. $V$에 속하는 영벡터로만 구성된 벡터집합 {0}은 $V$의 **영부분공간(zero subspace)**입니다. 모든 다항식 집합 $P$는 모든 실수치함수 집합 $R$의 부분공간입니다. $P$에는 로그함수나 삼각함수가 원소로 포함되어 있지는 않기 때문에 $P$는 $R$의 부분집합이라고 할 수 있습니다. 아울러 영벡터를 원소로 가지면서 덧셈과 스칼라곱에 닫혀 있습니다. 최고차항이 $n$인 모든 다항식 집합 $P_n$는 $P$의 부분집합입니다. $P_n$에는 $n+1$차 이상의 다항식이 원소로 포함되어 있지는 않기 때문에 $P_n$은 $P$의 부분집합이라고 할 수 있습니다. 아울러 영벡터를 원소로 가지면서 덧셈과 스칼라곱에 닫혀 있습니다. 벡터 $v_1, v_2, …,v_p$가 벡터공간 $V$의 원소라면 이 벡터들의 선형결합으로 만들어진 벡터집합(span{$v_1,...,v_p$})은 $V$의 부분공간이 됩니다. 선형결합의 정의에 의해 영벡터를 포함하고 덧셈과 스칼라곱에 닫혀 있기 때문입니다. 마지막으로 $R^2$는 $R^3$의 부분공간이 아닙니다. 왜냐하면 $R^2$에 속한 벡터는 그 요소가 두 개뿐인데 $R^3$는 세 개여서 부분집합인지 여부조차 따질 수 없기 때문입니다.  ## 열공간 행렬 $A$의 **열공간(column space)**은 행렬 $A$의 열벡터들의 선형결합이 만들어내는 모든 집합을 뜻합니다. 행렬의 크기가 $m * n$일 경우, $A$의 열공간은 $R^m$의 부분공간이 됩니다. $A$의 열벡터들이 $R^m$을 생성(span)할 때에만 $A$의 열공간이 $R^m$이 됩니다.  예를 들어보겠습니다. 아래 그림에서 행렬 $A$의 열공간은 파란색 네모칸과 같습니다. 첫번째 열벡터에 5배를 하고 두번째 열벡터에 3배를 해서 더하면 세번째 열벡터가 되기 때문에 열공간은 아래 그림처럼 평면이 됩니다. 선형시스템 $Ax=b$가 해를 가지려면 벡터 $b$가 $A$의 열공간 안에 존재해야 합니다.  $$ A=\begin{bmatrix} 1 & -3 & -4 \\ -4 & 6 & -2 \\ -3 & 7 & 6 \end{bmatrix},\quad b=\begin{bmatrix} 3 \\ 3 \\ -4 \end{bmatrix} $$ <a href="http://imgur.com/edrPfHk"><img src="http://i.imgur.com/edrPfHk.png" width="200px" title="source: imgur.com" /></a>  ## 열공간의 기저 $R^n$의 부분공간 $H$의 기저란 $H$를 생성하는 선형독립인 벡터 집합을 가리킵니다. 예컨대 아래 그림처럼 각각 $[1,0,0]^T$, $[0,1,0]^T$, $[0,0,1]^T$인 $e_1, e_2, e_3$는 $R^3$의 **표준기저(standard basis)**입니다. <a href="http://imgur.com/qaNsFus"><img src="http://i.imgur.com/qaNsFus.png" width="200px" title="source: imgur.com" /></a> 그러면 다음 가우스행렬 $A$의 열공간의 기저를 찾아보겠습니다.  $$A=\begin{bmatrix} 1 & 0 & -3 & 5 & 0 \\ 0 & 1 & 2 & -1 & 0 \\ 0 & 0 & 0 & 0 & 1 \\ 0 & 0 & 0 & 0 & 0 \end{bmatrix}$$  **주축열(pivot column)**인 첫번째, 두번째, 다섯번째 열벡터는 서로 선형독립입니다. 아울러 세번째 열벡터와 네번째 열벡터는 아래와 같이 각각 첫번째 벡터와 두번째 벡터의 선형결합으로 표시될 수 있습니다.  $$ \begin{align*} \overrightarrow { { a }_{ 3 } } &=-3\overrightarrow { { a }_{ 1 } } +2\overrightarrow { { a }_{ 2 } } \\ \overrightarrow { { a }_{ 4 } } &=5\overrightarrow { { a }_{ 1 } } -1\overrightarrow { { a }_{ 2 } } \end{align*} $$  따라서 $A$의 열공간은 span{$a_1, a_2, a_5$}이며 $A$의 열공간의 기저는 $a_1, a_2, a_5$입니다.   ## 영공간 $Ax=0$의 모든 해 집합을 행렬 $A$의 **영공간(null space)**이라고 합니다. $A$가 $n$개 열을 가졌다면 $A$의 영공간은 $R^n$의 부분공간이 됩니다.  영공간을 **선형변환(linear transformation)** 관점에서 이해할 수도 있습니다. $T$를 $n$차원 벡터 $x$를 $m$차원 영벡터로 변환하는 선형변환으로 둔다면 영공간 $NulA$는 아래 그림처럼 도식화할 수 있습니다. <a href="http://imgur.com/n2Mhi3w"><img src="http://i.imgur.com/n2Mhi3w.png" width="300px" title="source: imgur.com" /></a>  ## 차원과 위수 영공간이 아닌 부분공간 $H$의 **차원(dimension)**은 $H$의 기저의 개수를 가리킵니다. **영부분공간(zero subspace)** {0}의 차원은 0으로 정의됩니다.  행렬 $A$의 **위수(rank)**는 $A$의 열공간의 차원을 가리킵니다. $A$가 $n$개 열로 구성된 행렬일 때 $rank A + dim Nul A = n$를 만족합니다. $R^n$의 $p$차원 부분공간을 $H$라고 둡시다. $H$에 속한 선형독립인 임의의 $p$개 벡터 집합은 $H$의 기저가 됩니다. 아울러 $H$를 생성하는 $H$에 속한 임의의 $p$개의 벡터 집합은 $H$의 기저가 됩니다. 행렬 $A$가 $n*n$ 정방행렬일 때 다음 명제는 서로 동치입니다. > (1) $A$의 열공간은 $R^n$을 생성한다. > > (2) $A$의 열벡터는 $R^n$의 기저이다. > > (3) $A$의 열공간의 차원은 $n$이다. > > (4) $A$의 위수는 $n$이다. > > (5) $A$의 영공간은 {0}이다. > > (6) $A$의 영공간의 차원은 0이다.   ## 열공간 vs 영공간 열공간과 영공간의 차이점은 다음 표와 같습니다. <a href="http://imgur.com/xoMvMcm"><img src="http://i.imgur.com/xoMvMcm.png" title="source: imgur.com" /></a>   ## 좌표계 **좌표계(coordinate systems)**의 정의는 다음과 같습니다. 우선 부분공간 $H$의 기저 집합이 B={$b_1, b_2, …,b_p$}라고 둡시다. $H$에 속한 임의의 $p$차원 벡터 $x$가 가중치 $c_1, c_2,…,c_p$와 B 사이의 선형결합으로 다음과 같이 표시될 때 $[x]_B$를 기저 B에 대한 좌표벡터라고 합니다.  $$ \overrightarrow { x } ={ c }_{ 1 }{ b }_{ 1 }+{ c }_{ 2 }{ b }_{ 2 }+...+{ c }_{ p }{ b }_{ p }\\ { [x] }_{ B }=\begin{bmatrix} { c }_{ 1 } \\ ... \\ { c }_{ p } \end{bmatrix} $$ 예를 들어보겠습니다 $b_1=[3,6,2]^T$, $b_2=[-1,0,1]^T$, $x=[3,12,7]^T$, B={$b_1,b_2$}, H=span{$b_1,b_2$}라고 둡시다. 여기에서 $[x]_B$를 찾아봅시다. $x$가 $H$에 속한 벡터라면 다음의 벡터 방정식의 해가 존재해야 합니다.  $$ \begin{bmatrix} 3 & -1 \\ 6 & 0 \\ 2 & 1 \end{bmatrix}\begin{bmatrix} { c }_{ 1 } \\ { c }_{ 2 } \end{bmatrix}={ c }_{ 1 }\begin{bmatrix} 3 \\ 6 \\ 2 \end{bmatrix}+{ c }_{ 2 }\begin{bmatrix} -1 \\ 0 \\ 1 \end{bmatrix}=\begin{bmatrix} 3 \\ 12 \\ 7 \end{bmatrix} $$ 이를 **확대행렬(augmented matrix)**로 나타난 뒤 기본행연산을 수행하면 다음과 같습니다.  $$ \begin{bmatrix} 3 & -1 & 3 \\ 6 & 0 & 12 \\ 2 & 1 & 7 \end{bmatrix}\sim \begin{bmatrix} 1 & 0 & 2 \\ 0 & 1 & 3 \\ 0 & 0 & 0 \end{bmatrix} $$  따라서 $c_1=2$, $c_2=3$이 됩니다. 이를 직관적으로 나타내면 다음과 같습니다. <a href="http://imgur.com/fublc7R"><img src="http://i.imgur.com/fublc7R.png" width="400px" title="source: imgur.com" /></a>  
frequency␞ 이번 포스팅에서는 **자연언어처리(Natural Language Processing)**의 기본 가정 가운데 하나인 **distributional hypothesis**와 **벡터공간모델(Vector Space Models)**에 대해 알아보도록 하겠습니다. 그 핵심은 '빈도'를 '의미'로 진화시킬 수 있다는 아이디어인데요. 이와 아울러 NLP 분야에서 생각하는 **유사도(similarity)**와 NLP의 기본 절차에 대해서도 이야기해보겠습니다. 이와 관련해 괜찮은 [아티클](http://www.jair.org/media/2934/live-2934-4846-jair.pdf)이 있어 공부 겸 소개 겸 정리를 해볼까 합니다.   ## NLP의 기본 가정 NLP 분야의 기본 가정들을 소개합니다. > VSMs : 문서 집합에 속하는 각각의 문서들을 벡터공간의 벡터로 표현(representation)할 수 있다. 벡터공간에 벡터로 표현된 문서들 사이의 거리가 가깝다면 의미가 유사하다(semantically similar). > distributional hypothesis : 비슷한 맥락에 등장하는 단어들은 유사한 의미를 지니는 경향이 있다. (words that occur in similar contexts tend to have similar meanings) > statistical semantics hypothesis : 언어 사용의 통계적 패턴은 사람들이 의미하는 바를 이해하는 데 쓰일 수 있다. (statistical patterns of human word usage can be used to figure out what people mean) > bag of words hypothesis : 어떤 문서에 출현한 단어들의 빈도는 문서와 쿼리의 관련성을 나타내는 경향이 있다. (the frequencies of words in a document tend to indicate the relevance of the document to a query) 어떤 문서가 쿼리 문서와 유사한 벡터라면 그 의미도 비슷하다. > Latent relation hypothesis : 비슷한 패턴으로 동시에 등장하는 단어쌍은 유사한 의미적 관계를 지니는 경향이 있다. (Pairs of words that co-occur in similar patterns tend to have similar semantic relations) 음, 뭔가 어렵죠? 사실 그 말이 그 말인 것 같고요. 위 내용을 종합해 저만의 언어로 풀어서 이야기하자면, 분석 대상 말뭉치 내 등장하는 단어들의 빈도를 세서 이를 벡터 형태로 바꿀 수 있고, 그 벡터들 간의 거리(유사도)를 잴 수 있으며, 이렇게 구한 거리는 언어학적인 의미를 내포한다는 이야기인 것 같습니다. 바꿔 말하면 컴퓨터는 그저 단어를 '숫자'로 바꿔서 '계산'할 뿐이지만 이 과정에서 자연언어의 '의미'도 '이해'할 수 있다는 가정인 셈이지요.  뒤에서 설명드릴 **단어-문서행렬(Term-Document Matrix)**, **단어-문맥행렬(Word-Context Matrix)**, **페어-패턴행렬(Pair-Pattern Matrix)** 등은 모두 위 가정을 전제로 한 분석 방법론입니다. [**Word2Vec, Glove, Fasttext**](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/11/embedding/) 또한 마찬가지인 것 같습니다. 이들 방법론은 문맥 단어가 주어졌을 때 분석 대상 단어가 등장할 조건부 확률, 혹은 동시에 등장하는 빈도 따위를 보존하는 방식으로 단어를 벡터화하는 데 이 방법론의 대전제가 위의 가정에서 크게 벗어난 것 같지는 않다는 생각에서입니다. 어쨌든 단어의 의미를 숫자로, 언어학을 컴퓨터 사이언스로 문제와 해결방식을 각각 근본적으로 바꿨다는 점에서 괜찮은 아이디어인 것 같습니다~~물론 이 가정이 틀렸다는 게 엄밀하게 증명된다면 다른 얘기겠지만~~.  ## 단어-문서행렬 수학에서 **bag**은 **set**과 유사한 개념입니다. 예컨대 bag {a, a, b, c, c, c}와 bag {c, a, c, b, a, c}는 같습니다. 즉 빈도는 고려하지만 등장 순서는 무시한다는 거죠. 이 때문에 단어-문서행렬을 **bag of words** 기반의 방법론이라고도 합니다. 단어들을 일종의 주머니(bag)에 넣어 둔다는 의미 정도로 해석할 수 있겠는데, 한번 주머니에 들어가면 순서가 뒤죽박죽 섞이기 때문에 이런 용어가 생긴 것 같습니다. 예를 들어 다음과 같은 단어들로 이뤄진 문장이 있다고 칩시다. 그럼 우리는 다음과 같은 단어-문서행렬을 만들 수 있습니다. > 나,는,학교,에,가,ㄴ,다 > 학교,에,가,는,영희 > 나,는,영희,는,좋,다 | -  | doc1 | doc2 | doc3 | | :--: | :--: | :--: | :--: | | 나  | 1  | 0  | 0  | | 는  | 1  | 1  | 2  | | 학교 | 1  | 1  | 0  | | 에  | 1  | 1  | 0  | | 가  | 1  | 1  | 0  | | ㄴ  | 1  | 0  | 0  | | 다  | 1  | 0  | 1  | | 영희 | 0  | 1  | 1  | | 가  | 0  | 0  | 0  | | 좋  | 0  | 0  | 1  |   ## 단어-문맥행렬 주변 단어를 몇 개 볼 지(window size)를 정하고 동시에 등장하는 단어의 빈도수를 세어서 행렬로 바꾸는 방법입니다. window 개념이 있기 때문에 단어-문서행렬과 달리 단어 등장 순서를 약간 고려하긴 합니다. 이 방법론은 **distributional hypothesis**와 밀접한 관련이 있습니다. 예시는 다음과 같습니다(window size = 1). > I enjoy flying > I like NLP > I like deep learning |  -   | I  | like | enjoy | deep | learing | NLP | flying | | :------: | :--: | :--: | :---: | :--: | :-----: | :--: | :----: | |  I   | 0  | 2  |  1  | 0  |  0  | 0  |  0  | |  like  | 2  | 0  |  0  | 1  |  0  | 1  |  0  | | enjoy  | 1  | 0  |  0  | 0  |  0  | 0  |  0  | |  deep  | 0  | 1  |  0  | 0  |  1  | 0  |  1  | | learning | 0  | 0  |  0  | 1  |  0  | 0  |  0  | |  NLP  | 0  | 1  |  0  | 0  |  0  | 0  |  0  | | flying | 0  | 0  |  1  | 0  |  0  | 1  |  0  |   ## 페어-패턴행렬 페어-패턴행렬의 행 벡터는 단어쌍(pairs of words)을 의미합니다. 예컨대 mason:stone, carpenter:word 따위가 되겠죠. 단어쌍에 대응되는 열 벡터는 해당 단어쌍과 함께 나타나는 패턴(patterns)을 뜻합니다. "X cuts Y", "X works with Y" 등입니다. 이 행렬을 제대로 구축해놓으면 특정 패턴(예컨대 X solves Y)와 비슷한 패턴(Y is solved by Y)을 가려낼 수 있습니다.   ## 유사도? **'단어 뜻이 비슷하다'**는 어떤 의미를 지니는 걸까요. 생각해보면 볼수록 알쏭달쏭한 개념입니다. 우선 제가 지금 설명드리고 있는 아티클을 기본으로 해서 제 생각을 정리해 말씀드려 보겠습니다. 단어들끼리는 어떤 관련을 맺고 있습니다. 엄밀히 얘기하면 이 세상에 완벽한 동의어는 없다고 말할 수 있을 정도로요. 심지어 **반의어(antonyms)**들조차 단어 사이의 관련성이 높습니다.  예를 들어 보죠. '춥다'와 '따뜻하다'는 반대되는 말이지 않습니까? 그렇다면 이 둘은 관계가 전혀 없을까요? '기온'을 언급한다는 점에 있어서는 비교적 강한 관계를 지닌다고 말할 수 있겠습니다. '흑'과 '백', '크다'와 '작다'도 마찬가지로 '색상', '크기' 등과 관련해 관계를 맺고 있습니다. 지금 소개해드리고 있는 아티클은 단어 유사성과 관련해 다양한 개념들이 설명하고 있습니다. 우선 **relational similarity**와 **attributional similarity**가 있습니다.'개:멍멍', '개:늑대'가 각각 전자와 후자의 대표 사례입니다. 전자는 단어 사이의 '관계'에, 후자는 '속성'에 방점을 둔 유사성 개념이라고 합니다. **유의어(synonyms)**, **부분어(meronyms)**, **반의어(antonyms)** 등에서 알 수 있듯 모든 단어는 서로 밀접한 관계를 맺고 있습니다. NLP 분야에서는 **상위어(hypernym)**를 공유하는 단어들이 **의미적 유사성(semantic simliarity)**을 지닌다고 정의한다고 합니다. 이 기준에 따르면 '자동차'와 '자전거'는 의미가 비슷한 단어입니다. '교통수단'이라는 상위어를 공유하기 때문입니다. 이 의미적 유사성이라는 개념은 앞서 언급한 attributional simliarity의 특수한 사례입니다. 또한 '벌'과 '꿀'처럼 동시에 빈번하게 같이 등장하는 단어들은 의미적으로 연관이 있을 가능성이 높다는 것이 이 분야의 대표적인 가정입니다. 
algorithm␞ 이번 글에 대해서는 알고리즘(algorithm)의 정의와 기본적인 내용에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 김선욱 교수님과 김황남 교수님 강의, 한글 및 영문 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겟습니다.   ## 알고리즘 정의 알고리즘의 정의는 다음과 같습니다. > **A precisely defined sequence of computational steps** that transform a given input into a desired output. (주어진 입력을 원하는 출력으로 변환하는, **명확하게 정의된 일련의 계산 단계**) 이번엔 다른 정의를 보겠습니다. 제가 보기엔 위의 정의와 거의 비슷해 보입니다. > **A finite list of well-defined instructions** for accomplishing some task. (몇 가지 작업을 수행하기 위해 **잘 정의된 지침의 유한한 목록**)   ## 알고리즘과 DFA 알고리즘은 **유한상태기계(Finite State Machine)**, 이 가운데 특히 **결정적 유한오토마타(Definite Finite Automata)**와 깊은 관련을 맺고 있다고 합니다.  유한상태기계란 컴퓨터 프로그램과 전자 논리 회로를 설계하는 데에 쓰이는 수학적 모델입니다. 이 기계는 한번에 오로지 하나의 상태(state)만을 가지게 되며, 어떤 사건(event)에 의해 한 상태에서 다른 상태로 변화하는데 이를 전이(transition)이라고 합니다. 유한상태기계는 현재 상태로부터 가능한 전이 상태와 이러한 전이를 유발하는 조건들의 집합으로 정의됩니다. 결정적 유한오토마타는 전이가 결정적인(deterministic) 유한상태기계를 의미합니다. 모든 상태는 각각의 가능한 입력에 대해 정확히 하나의 변환된 상태만을 가질 수 있습니다. (반면 비결정적 유한오토마타라면 여러 상태를 가질 수 있습니다) . 결정적 유한오토마타의 개념도는 다음과 같습니다. (출처 : 영문 위키피디아)  <a href="https://imgur.com/cuYu6jx"><img src="https://i.imgur.com/cuYu6jx.png" width="400px" title="source: imgur.com" /></a>  알고리즘은 초기상태(initial state)에서 시작해 종료상태(end-state)에서 끝납니다. 사전에 명확하게 정의된 절차에 따라 상태가 종료상태를 향해 전이되는 것이죠. 이 일련의 전이 과정이 무한하지 않고 유한하며, 비결정적이지 않고 결정적이라는 점에서 알고리즘은 DFA입니다.   ## 알고리즘과 자료구조 알고리즘과 자료구조(data structure)는 깊은 관련(dependency)을 맺고 있습니다. 현실의 문제를 컴퓨터로 푼다고 할 때 해당 문제의 속성(attribute)을 가장 잘 드러나게끔 자료구조를 만들(거나 선택하)고, 역시 이 문제에 맞는 알고리즘(문제 해결방법) 또한 구현해야 합니다. 어떤 자료구조를 쓰느냐에 따라 알고리즘이 바뀔 것이기 때문에 상황에 따라 최적의 자료구조와 알고리즘을 선택해야겠죠. 이와 관련해 추상자료형(Abstract Data Type)이라는 개념이 있습니다. 자료들과 그 자료들에 대한 연산을 함께 명기한 형태입니다. 자세한 내용은 [이곳](http://ledgku.tistory.com/41)을 참고하시면 좋을 것 같습니다.   ## 알고리즘 개발의 일반적 절차 일반적 절차는 다음과 같습니다. 이 글에서는 2번만을 조금 더 다루고 3번과 4번은 별도 글에 말씀드리도록 하겠습니다. 1. Design a solution : 알고리즘을 처음 **설계**하는 과정입니다. 2. Verify the correctness : 알고리즘 설계가 잘 됐나 수학적으로 **검증**하는 단계입니다. 3. Specify the solution : 의사코드(pseudo-code), 프로그래밍 언어 등으로 **기술**하는 단계입니다. 4. Evluate the solution : 정확도, 계산복잡성 등 **성능**을 평가하는 단계입니다.   ## 알고리즘 검증(verify) 알고리즘을 검증하는 수학적 방법에는 **귀납에 의한 증명(proof by induction)**, **반례에 의한 증명(proof by counter example)**, **귀류법(proof by contradiction)** 세 가지가 있습니다.  ### 귀납에 의한 증명 가장 작은 자연수 1일 때 해당 명제를 만족시킴을 증명한 뒤, 만약 어떤 자연수($n$)가 해당 명제를 만족시킨다고 가정한 뒤 바로 다음 자연수($n+1$) 역시 해당 명제를 만족시킴을 증명하기만 하면 해당 명제는 모든 자연수에 대해 성립한다는 걸 증명할 수 있습니다. 이를 수학적 귀납법(mathmatical induction)이라고 합니다. 예를 들면 다음과 같습니다. > $1+2+...+n=n(n+1)/2$임을 증명하라. > > (1) $n=1$일 때 성립함 : $1 = 1(1+1)/2 $ > > (2) 임의의 $n$에 대해 성립한다고 가정 > > (3) $n+1$일 때도 성립함 : $1+2+..+n+(n+1)=(n+1)(n+2)/2$  ### 반례에 의한 증명 반례란 어떤 명제가 참이 아님을 증명하기 위해서 그 명제가 성립하지 않는 예를 든 것을 말합니다. 예를 들면 다음과 같습니다. > 다음과 같은 피보나치 수열이 있을 때 $F_N<N^2$인가? > > $F_0=1, F_1=1, F_2=2, F_3=3, F_4=5,...,F_i=F_{i-1}+F_{i-2}$ > > 증명) 그렇지 않다. $F_{11}=144$라는 반례가 존재한다.  ### 귀류법 증명하려는 명제의 결론이 거짓이라는 것을 가정하였을 때 모순되는 가정이 나온다는 것을 보여 원래의 명제가 참인 것을 증명하는 방법입니다. 예를 들면 다음과 같습니다. > 소수의 개수가 유한하다고 가정. 이를 $k$라 두자. > > (소수 집합 $P=\{P_1, P_2, ...P_k\}$에서 가장 큰 소수는 $P_k$이다) > > $N=1+P_1P_2...P_k$을 생각해보자. > > 여기에서 $N$은 $P_k$보다 크므로, 소수 집합에 속하지 않는 합성수(소수의 곱으로 이뤄진 자연수)이다. > > 합성수 $N$은 임의의 소수 $p$로 나누어 떨어진다. > > $N/p = P_1P2...P_k/p+1/p$ > > 위 식에서 $1/p$는 어떤 소수로도 나누어 떨어지지 않는다. > > 따라서 $N$은 합성수가 아니거나 집합 $P$ 외에 다른 소수가 존재한다. 그러므로 '소수는 유한하다'는 것은 거짓이다.   ## 계산복잡도 계산을 위한 기초 수학공식 알고리즘의 효율성 측정 기준은 연산시간(time)과 메모리(memory)입니다. 계산복잡도 계산에 자주 쓰이는 수학공식을 정리해보겠습니다. 우선 수열의 합부터 보겠습니다.  $$ \begin{align*} 1+2+3+...+N&=\frac { N(N+1) }{ 2 } \\1+{ 2 }^{ 2 }+{ 3 }^{ 2 }+...+{ N }^{ 2 }&=\frac { N(N+1)(2N+1) }{ 6 }\\1+r+{ r }^{ 2 }+{ r }^{ 3 }+...+{ r }^{ N-1 }&=\frac { (1-{ r }^{ N }) }{ 1-r }  \end{align*} $$  마지막 공식과 관련해 공비($r$)가 1보다 작고 $N$이 충분히 클 때는 $1/(1-r)$에 근사한다고 합니다. 이번엔 로그 공식을 보겠습니다.  $$ \log _{ a }{ b } =x\quad if\quad { a }^{ x }=b\\ \log { (ab) } =\log { a } +\log { b } \\ \log { (a/b) } =\log { a } -\log { b } \\ \log { { a }^{ b } } =b\log { a } \\ \log _{ b }{ a } =\log _{ c }{ a } /\log _{ c }{ b } \\ { a }^{ \log { n } }={ n }^{ \log { a } } $$  지수 공식은 다음과 같습니다.  $$ { a }^{ mn }={ \left( { a }^{ m } \right) }^{ n }={ \left( { a }^{ n } \right) }^{ m }\\ { a }^{ m+n }={ a }^{ m }{ a }^{ n } $$  
beamsearch␞ 이번 글에서는 Recursive Neural Network(RNN)의 학습 과정에서 트리 탐색 기법으로 쓰이는 **Beam seach**에 대해 살펴보도록 하겠습니다. beam search는 RNN 말고도 자연언어처리 분야에서 자주 쓰인다고 하니 이 참에 정리해 두면 유용할 듯합니다. 이번 글은 [Socher et al.(2011)](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi3zKy40drUAhUHW5QKHXkmDxAQFggoMAA&url=http%3A%2F%2Fai.stanford.edu%2F~ang%2Fpapers%2Ficml11-ParsingWithRecursiveNeuralNetworks.pdf&usg=AFQjCNGdAdKAKcsqIBm3eZ2GJzJ_16_lbQ)과 미국 스탠포드 대학 NLP 강의 자료를 참고해 만들었음을 먼저 밝힙니다. Beam Search 예시 부분은 제가 직접 만든 것이니 혹시 오류가 있다면 언제든 알려주시면 감사하겠습니다. 그럼 시작하겠습니다.  ## RNN과 Tree RNN은 응집성이 높은 입력값을 트리 형태로 결합해 가면서 입력값의 구조를 추상화하는 기법입니다. Simple RNN에 대해서는 [이곳](https://ratsgo.github.io/deep%20learning/2017/04/03/recursive/)을, 발전된 형태의 RNN 모델에 대해 살펴보시려면 [이곳](https://ratsgo.github.io/deep%20learning/2017/06/24/RNTN/)을 참고하면 좋을 것 같습니다.  어쨌든 RNN과 트리는 뗄려야 뗄 수 없는 관계를 가집니다. 이미지와 텍스트에 대해 RNN을 적용해보고자 했던 Socher et al.(2011)에도 입력값이 주어졌을 때 트리를 구축하는 방안에 대해 논문의 상당 부분을 할애하고 있습니다. 다음 그림을 볼까요?  <a href="http://imgur.com/GdnUzyQ"><img src="http://i.imgur.com/GdnUzyQ.png" width="300px" title="source: imgur.com" /></a>  Socher et al.(2011)은 우선 입력값의 이웃끼리 결합해 트리를 만들기로 합니다. 이미지를 예로 들면 1번 영역의 이웃은 2번과 3번입니다. 이를 **인접행렬(Adjacency Matrix)**로 나타내면 (1,2), (2,1), (1,3), (3,1) 위치의 요소값이 1이 되어야 할 겁니다. 이렇게 이웃이 될 수 있는 가능한 모든 경우의 수를 고려해 행렬로 나타낸 것이 좌측 두번째 그림이 됩니다. 본 블로그의 관심 주제인 텍스트는 이미지보다는 간단한 편입니다. 어떤 단어의 이웃은 왼쪽 하나, 오른쪽 하나 두개뿐입니다. 예컨대 house의 이웃은 The, has이고 a의 이웃은 has, window입니다. 이를 인접행렬로 그리면 대각성분 위, 아래만 1이고 나머지는 0인 규칙적인 모양이 됩니다. 이웃이 될 수 있는 모든 경우의 수에서 그 가짓수를 하나씩 제거해 **정답 트리 구조(Correct Tree Structure)**로 나아가자는 것이 트리 탐색의 핵심이 됩니다.   ## Greedy Search 트리 탐색의 범위를 이웃으로 한정하긴 했지만 Socher et al.(2011) 방식의 본질은 탐욕적인 탐색이라고 말할 수 있겠습니다. 논문의 예를 확장시켜 그림으로 나타내 보았습니다. 아래 그림에서 $a_i$는 i번째 단어(노드)를 의미합니다. 첫번째 단계에서의 인접행렬은 이웃이 될 수 있는 모든 경우의 수가 포함되어 있습니다. $C$는 이웃들의 쌍으로 이루어진 집합입니다.  <a href="http://imgur.com/CnaEfiQ"><img src="http://i.imgur.com/CnaEfiQ.png" width="350px" title="source: imgur.com" /></a>  RNN 모델이 내놓은 score가 $[a_4,a_5]$가 가장 높았다고 가정해보겠습니다. 다시 말해 모델이 a와 window라는 단어가 응집성이 가장 높다고 판단한 것이지요. 이 둘을 이어서 트리를 만드는 것이 첫번째 과정입니다. 다음 그림처럼요. 아래 그림을 보시면 $[a_4,a_5]$가 결합해 parent node $p_{(4,5)}$가 되었습니다. 여기에 맞춰서 인접행렬과 $C$가 업데이트된 것도 확인가능합니다.  <a href="http://imgur.com/gnPIp8h"><img src="http://i.imgur.com/gnPIp8h.png" width="350px" title="source: imgur.com" /></a>  이번엔 RNN 모델이 출력한 score가 The, house가 가장 높았다고 가정해보겠습니다. 그러면 인접행렬과 $C$는 다음과 같이 업데이트됩니다.  <a href="http://imgur.com/KrbcuPH"><img src="http://i.imgur.com/KrbcuPH.png" width="350px" title="source: imgur.com" /></a>  이번엔 RNN 모델이 has라는 단어와 'a, window'라는 구의 응집성이 가장 높다고 판단했다고 칩시다. 다음 그림과 같이 업데이트됩니다.  <a href="http://imgur.com/hxcl5f5"><img src="http://i.imgur.com/hxcl5f5.png" width="350px" title="source: imgur.com" /></a>  이제는 연결해야 하는 노드가 딱 두 개뿐이므로 이 둘만 연결해주면 아래 그림처럼 트리 탐색 과정이 종료됩니다.  <a href="http://imgur.com/btt5Lb1"><img src="http://i.imgur.com/btt5Lb1.png" width="350px" title="source: imgur.com" /></a>  ## Beam Search 보시다시피 Socher et al.(2011)의 방식은 탐욕적입니다. 이게 찔려선지 Socher et al.(2011)은 텍스트에 대해서는 Beam Search를 적용할 수 있다고 언급했습니다. 논문의 일부를 인용해봤습니다. > Since in a sentence each word only has 2 neighbors, less-greedy search algorithms such as a **bottom-up beam search** can be used. Beam Search란 **최고우선탐색(Best-First Search)** 기법을 기본으로 하되 기억해야 하는 노드 수를 제한해 효율성을 높인 방식입니다. Socher et al.(2011)이 언급했듯 여전히 탐욕적이지만 기존 방식보다는 조금 나은 기법입니다. 다음 예제 그림을 볼까요?  <a href="http://imgur.com/zXpcLHB"><img src="http://i.imgur.com/zXpcLHB.png" width="350px" title="source: imgur.com" /></a>  사용자가 기억해야 하는 노드 수(Beam)를 3으로 정했다고 가정해 봅시다. 그러면 $i$번째 step에서 다음 step에 선택될 수 있는 가능한 모든 경우의 수를 계산해본 뒤 Beam Search의 기본이 되는 알고리즘(예컨대 RNN)이 내놓는 최상위 3개 결과만 취해서 $i+1$번째 step의 결과물로 반환하는 방식입니다. 위 그림의 예시는 상위 노드에서 하위 노드로 분기해 나가는 Top-Down Beam Search입니다.   ## Bottom-Up Beam Search 파싱과 같은 자연언어처리 분야에서는 Top-Down보다는 Bottom-Up Beam Search 기법이 자주 쓰인다고 합니다. 이 기법은 하위 노드에서 상위 노드로 결합해 나가는 방식입니다. 임의의 7개 단어가 있고 이로부터 파싱 트리를 구축해야 하는 상황을 가정해보겠습니다. 사용자가 지정한 Beam은 2라고 두겠습니다. 초기 상태는 다음 그림과 같습니다. 각 단어들은 왼쪽과 오른쪽 이웃 두 개씩만 있기 때문에 다음 step에 선택될 수 있는 가능한 모든 경우의 수는 빨간색 점선과 같습니다. 이 가운데 첫번째-세번째 단어, 세번째-네번째 단어를 결합하는 것이 모델의 판단결과라고 가정해 보겠습니다.  <a href="http://imgur.com/58aA9z6"><img src="http://i.imgur.com/58aA9z6.png" width="300px" title="source: imgur.com" /></a>  두번째 step에선 이들을 잇고 나서 세번째 step에 선택될 수 있는 가능한 모든 경우의 수를 계산해 본 뒤 최적 두 개 결과를 선택합니다.   <a href="http://imgur.com/eK7tzbY"><img src="http://i.imgur.com/eK7tzbY.png" width="300px" title="source: imgur.com" /></a>  세번째 step에서도 지금까지 수행한 작업을 반복합니다.  <a href="http://imgur.com/8xNu0Pu"><img src="http://i.imgur.com/8xNu0Pu.png" width="300px" title="source: imgur.com" /></a>  그런데 다섯번째 단어는 왼쪽 트리, 오른쪽 트리 둘 모두에 속할 수는 없습니다. 이 가운데 score가 좀 더 높은 쪽에 할당되게 됩니다.  <a href="http://imgur.com/fR1DRhH"><img src="http://i.imgur.com/fR1DRhH.png" width="300px" title="source: imgur.com" /></a>  이제 남은 경우의 수는 단 하나뿐이므로 모델이 내놓는 score를 반영할 필요도 없이 트리를 완성하기만 하면 됩니다.  <a href="http://imgur.com/AV6i031"><img src="http://i.imgur.com/AV6i031.png" width="300px" title="source: imgur.com" /></a>
docsim␞ 이번 글에서는 문서 유사도를 측정하는 몇 가지 지표에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 유사도? **유사도(similarity)**란 비슷한 정도를 나타내는 지표를 뜻합니다. 하지만 '비슷하다'는 단어의 어감에서도 알 수 있듯 굉장히 주관적인 지표입니다. 이를 정량화하는 노력이 필요한데요. **자연언어처리(Natural Language Processing)** 분야에서 정의하는 유사도 지표의 속성 몇 가지를 나열해 보도록 하겠습니다. > (1) 두 객체간 유사성은 둘이 공유하는 속성이 많을 수록 증가한다. > > (2) 개별 속성은 서로 독립(independent)이며, 추가가 가능하다. > > (3) 각 속성이 갖는 추상화 레벨이 동일해야 한다. > > (4) 유사성은 개념구조(conceptual structure)를 설명하는 데 충분해야 한다. (1)은 직관적으로 이해가 가능할 것 같고요. (2)의 경우 예컨대 한 문서가 하나의 객체이고 이 문서가 5개 변수로 이뤄져 있다면 각 변수는 서로 **무상관(uncorrelated)**이라는 뜻이 됩니다. 이 문서를 **벡터공간(vector space)**에 표현했을 때 각 변수에 대응하는 **기저(basis)**는 서로 수직이라는 말로도 이해할 수 있을 것 같습니다. 아울러 변수를 6개, 7개... 이렇게 추가도 가능합니다. (3)의 경우 각 변수가 커버하는 개념 영역이 비슷해야 한다는 취지로 받아들이면 될 것 같습니다. 예컨대 첫번째 변수가 '자동차'인데, 두번째 변수가 '아반떼'라면 해당 변수들로부터 추출한 유사도가 정확성을 갖기 어려울 것입니다. (4)는 유사도가 높은 객체들은 의미적으로도 비슷하다는 뜻으로 해석됩니다. 문서 간 유사도를 측정하는 지표는 여럿 제안되었습니다만, 대체로 **단어(word, term)** 수준의 방법론들입니다. 두 문서에 겹치는 단어가 많을수록 유사도가 높다는 결과를 내놓는 식입니다. 단어 수준의 유사도 측정은 (1) 문서 길이 (2) 동시 등장 단어 (3) 흔한/희귀한 단어 (4) 출현 빈도 등을 어떻게 처리하는지에 따라 다양한 방법론이 있습니다. 이번 글은 이와 관련한 여섯가지 측정 지표에 대해 살필 예정입니다.  ## Notation 앞으로 설명해드릴 여섯가지 지표를 계산하는 데 쓰이는 표현들에 대해 정리해보도록 하겠습니다. 1. $x_{ik}$는 $i$번째 문서에 $k$번째 단어가 몇번 등장했는지 빈도를 나타냅니다. 2. $t_{ik}$는 $x_{ik}$가 0 이상이면 1, 그렇지 않으면 0의 값을 갖습니다. 3. $a_{ij}$, $b_{ij}$, $c_{ij}$, $d_{ij}$는 $t$를 바탕으로 구하는데요. 각각 아래 표와 같습니다. 아래 표에서 Y는 어떤 단어가 해당 문서에 쓰인 경우를, N은 쓰이지 않은 경우를 뜻합니다. $a_{ij}$, $b_{ij}$, $c_{ij}$, $d_{ij}$는 각각에 해당하는 단어 수를 나타냅니다. | $Doc_i$\|\|$Doc_j$ |  Y   |  N   | | :----------------: | :------: | :------: | |     Y     | $a_{ij}$ | $b_{ij}$ | |     N     | $c_{ij}$ | $d_{ij}$ |  ## 예시 table 아래 표는 앞으로 설명드릴 지표에 대한 이해를 돕기 위한 예시입니다.  | $x_{ik}$(빈도) |  $Doc_1$  |  $Doc_2$  |  $Doc_3$  | | :----------: | :----------: | :----------: | :----------: | |  $Term_1$  | 3(=$x_{11}$) | 0(=$x_{21}$) | 2(=$x_{31}$) | |  $Term_2$  | 0(=$x_{12}$) | 0(=$x_{22}$) | 1(=$x_{32}$) | |  $Term_3$  | 5(=$x_{13}$) | 3(=$x_{23}$) | 0(=$x_{33}$) | |  $Term_4$  | 0(=$x_{14}$) | 2(=$x_{24}$) | 1(=$x_{34}$) | |  $Term_5$  | 0(=$x_{15}$) | 1(=$x_{25}$) | 2(=$x_{35}$) |  아래 표는 등장여부를 binary로 표시한 결과입니다. 같은 말뭉치에서 도출된 표입니다. | $t_{ik}$(binary) |  $Doc_1$  |  $Doc_2$  |  $Doc_3$  | | :--------------: | :----------: | :----------: | :----------: | |   $Term_1$   | 1(=$t_{11}$) | 0(=$t_{21}$) | 1(=$t_{31}$) | |   $Term_2$   | 0(=$t_{12}$) | 0(=$t_{22}$) | 1(=$t_{32}$) | |   $Term_3$   | 1(=$t_{13}$) | 1(=$t_{23}$) | 0(=$t_{33}$) | |   $Term_4$   | 0(=$t_{14}$) | 1(=$t_{24}$) | 1(=$t_{34}$) | |   $Term_5$   | 0(=$t_{15}$) | 1(=$t_{25}$) | 1(=$t_{35}$) |  Doc1과 Doc2에 대해 $a_{12},b_{12},c_{12},d_{12}$를 각각 구해보겠습니다. Doc1에는 등장했는데 Doc2에는 등장하지 않은 단어는 Term1 하나뿐이므로 $b_{12}$은 1입니다. Doc1에는 등장하지 않았는데 Doc2에 나온 단어는 Term4와 Term5 두 개이므로 $c_{12}$는 2입니다. 두 문서 모두 등장한 단어는 Term3 하나, 두 문서에 모두 나오지 않은 단어는 Term2 하나이므로 $a_{12}$, $d_{12}$는 각각 1입니다. | $Doc_1$\|\|$Doc_2$ |   Y    |   N    | | :----------------: | :----------: | :----------: | |     Y     | 1(=$a_{12}$) | 1(=$b_{12}$) | |     N     | 2(=$c_{12}$) | 1(=$d_{22}$) |  ## common features model $i$번째 문서와 $j$번째 문서에 동시에 등장한 단어수를 전체 단어수로 나누어 구합니다. 보통 전체 말뭉치에 등장하는 단어수가 10만개에 육박하기 때문에 $d_{ij}$가 매우 큽니다. 따라서 이처럼 계산하는 유사도는 대체로 0에 가까운 작은 값을 지닙니다. 계산방법과 예시는 아래와 같습니다. $${ s }_{ ij }^{ common }=\frac { { a }_{ ij } }{ { a }_{ ij }+{ b }_{ ij }+{ c }_{ ij }+{ d }_{ ij } } $$ | common | Doc1 | Doc2 | Doc3 | | :----: | :--: | :--: | :--: | | Doc1 | -  | 1/5 | 1/5 | | Doc2 |   | -  | 2/5 | | Doc3 |   |   | -  |  ## ratio model common features model에서 $d_{ij}$를 빼고 계산한 유사도입니다. $${ s }_{ ij }^{ ratio }=\frac { { a }_{ ij } }{ { a }_{ ij }+{ b }_{ ij }+{ c }_{ ij } } $$ | ratio | Doc1 | Doc2 | Doc3 | | :---: | :--: | :--: | :--: | | Doc1 | -  | 1/4 | 1/5 | | Doc2 |   | -  | 2/5 | | Doc3 |   |   | -  |  ## simple matching coefficient common features model의 식에서 분자와 분모에 $d_{ij}$를 반영해 구한 유사도입니다. common features model보다는 값이 큰 경향이 있습니다. $${ s }_{ ij }^{ smc }=\frac { { a }_{ ij }+{ d }_{ ij } }{ { a }_{ ij }+{ b }_{ ij }+{ c }_{ ij }+{ d }_{ ij } } $$ | SMC | Doc1 | Doc2 | Doc3 | | :--: | :--: | :--: | :--: | | Doc1 | -  | 2/5 | 1/5 | | Doc2 |   | -  | 2/5 | | Doc3 |   |   | -  |  ## jaccard similarity jaccard similarity는 아래와 같이 구합니다. ratio model과 본질적으로 유사하다고 합니다. $${ s }_{ ij }^{ jaccard }=\frac { \sum _{ k }^{ }{ min({ x }_{ ik },{ x }_{ jk }) } }{ \sum _{ k }^{ }{ max({ x }_{ ik },{ x }_{ jk }) } } $$ | jaccard | Doc1 | Doc2 | Doc3 | | :-----: | :--: | :--: | :--: | | Doc1  | -  | 3/11 | 2/12 | | Doc2  |   | -  | 2/9 | | Doc3  |   |   | -  |  ## overlap similarity overlap simliarity는 아래와 같이 구합니다. $${ s }_{ ij }^{ overlap }=\frac { \sum _{ k }^{ }{ min({ x }_{ ik },{ x }_{ jk }) } }{ min(\sum _{ k }^{ }{ { x }_{ ik } } ,\sum _{ k }^{ }{ { x }_{ jk } } ) } $$ | overlap | Doc1 | Doc2 | Doc3 | | :-----: | :--: | :--: | :--: | | Doc1  | -  | 3/6 | 2/6 | | Doc2  |   | -  | 2/6 | | Doc3  |   |   | -  |  ## cosine similarity cosine similarity는 아래와 같이 구합니다. 예시로 제시된 table을 행렬로, 각각의 문서에 해당하는 열을 벡터로 놓고 두 벡터를 아래와 같이 내적하게 되면 두 벡터가 이루는 각도(유사도)가 됩니다. 일반적으로 문서 유사도 계산시 가장 많이 쓰이는 방법입니다. $${ s }_{ ij }^{ cosine }=\frac { \sum _{ k }^{ }{ ({ x }_{ ik }\times { x }_{ jk }) } }{ \sqrt { (\sum _{ k }^{ }{ { x }_{ ik }^{ 2 } } )(\sum _{ k }^{ }{ { x }_{ jk }^{ 2 } } ) } } $$ | common | Doc1 | Doc2 | Doc3 | | :----: | :--: | :----: | :----: | | Doc1 | -  | 0.6875 | 0.3254 | | Doc2 |   |  -  | 0.3380 | | Doc3 |   |    |  -  |
syntax␞ 이번 글에서는 한국어 **통사론(syntax)**의 기본 개념과 한국어 통사론이 다루는 통사 단위(문법 단위)에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 통사론 통사론이란 둘 이상의 단어(word)가 결합하여 구(phrase), 절(clause), 문장(sentence)을 형성하는 원리를 탐구하는 분야입니다. 이 때 '단어, 구, 절, 문장'을 **통사단위**라고 합니다. 한국어 통사론이 다루는 최소의 통사 단위는 단어이고 최대 통사 단위는 문장이 됩니다.  다만 이는 편의적인 기술일 뿐이고, 국어 통사론 연구자들은 단어 이하의 단위인 용언의 활용어미까지 통사 단위로 보고 연구한다고 합니다. 활용어미는 교착어인 한국어에서는 단어의 일부분이기 때문입니다. 또한 [생성문법](https://ratsgo.github.io/korean%20linguistics/2017/04/30/genegram/)의 영향을 많이 받은 현대의 통사론은 문장이라는 최종 결과물을 분석하기보다는 작은 통사 단위를 결합하여 큰 통사 단위를 형성하는 원리를 탐구하는 데 집중합니다.   ## 통사론의 분석 방법 통사론에서는 문법 단위의 각 성분들이 계층적으로 구성을 이룬다고 전제하고, 크게 두 조각으로 분석한 뒤 각각을 다시 더 작은 단위로 분석하는 방식을 이용합니다. 이때 어떤 문법 단위가 모여 보다 큰 문법 단위가 됐을 때 이 큰 단위를 **구성**, 이 구성을 이루고 있는 작은 단위들 각각을 **구성요소(성분)**이라고 합니다. 예컨대 다음과 같습니다.  <a href="https://imgur.com/oSALjv9"><img src="https://i.imgur.com/oSALjv9.png" width="400px" title="source: imgur.com" /></a>   ## 통사단위 통사론이 살피는 통사단위를 예문과 함께 보겠습니다. > (가) **단어** : 민수 > > (나) **구** : 내 친구 민수 > > (다) **절(단문)** : 민수가 학교에 갔다. > > (라) **절(복문)** : 민수가 학교에 가면 엄마는 청소를 한다. (가)는 **단어(單語)**입니다. 단어란 문장에서 홀로 쓰일 수 있는 말 중 가장 작은 단위입니다. 문장에서 쓰일 때 그 구성요소가 분리되지 않는 성질을 가집니다. 예컨대 (가)의 '민수'를 '민'과 '수'로 나눌 수 없고, 그렇게 되면 그 의미가 사라집니다. (나)는 '민수'를 꾸며주는 말이 앞에 와서 (가)가 확장된 **구(句)**입니다. 구는 단어들이 모여 이루어진, 그러나 주어와 서술어가 갖추어지지 않은 단위입니다. 둘 이상의 단어가 모여 주변어-중심어의 관계로 맺어지거나, 혹은 중심어만으로 절이나 문장의 일부분을 이룹니다. (다)에서 비로소 주어와 서술어가 함께 나타나고 있는데 이와 같은 구성을 **절(節)**이라고 합니다. (다)와 같이 하나의 절이 하나의 문장이 되는 경우도 있고, (라)와 같이 두 개 이상의 절이 하나의 문장을 이루는 경우도 있습니다. (다)를 단문(홑문장), (라)를 복문(겹문장)이라고 부릅니다. 그러나 띄어쓰기 단위인 '어절'은 통사단위가 아닙니다. 아래 예문을 보겠습니다. > 내 친구 민수가 도로 건너편의 학교에 갔다. 위 문장의 주어는 '내 친구 민수'라는 구에 조사 '-가'가 붙은 구조로 분석할 수 있습니다. 다시 말해 어절 개념과 상관 없이 더 큰 통사단위가 만들어진 것입니다.   ## 어휘범주, 구 범주 다음 예문을 보겠습니다. > (A) 민수-가 빵-을 먹었다. > > (B) [내 친구 민수]-가 [어제 산 빵]-을 먹었다. (A)의 '민수'와 (B)의 '내 친구 민수'는 문장에서의 문법적 역할이 같습니다. 마찬가지로 '빵'과 '어제 산 빵'도 그렇습니다. 이처럼 명사와 명사구의 문법적 역할이 동일하므로 명사 단독으로 쓰이나 명사구로 쓰이나 모두 같은 문법적 범주라는 이야기입니다. 이와 관련해 명사는 원칙적으로 언제라도 명사구로 확장되어 쓰일 수 있다고 합니다. 따라서 (A)에서 '민수', '빵'이라는 명사가 단독으로 쓰였지만, '민수'와 '빵'은 명사구 '내 친구 민수', '어제 산 빵'과 같이 명사구와 같은 자격을 지니는 것으로 보아야 합니다. 다시 말해 얼핏 보면 그냥 명사인 것 같아도 내재해 있는 문법적 역할은 명사구라는 이야기입니다. 이는 생성문법에서 비롯된 생각으로, 생성문법에서는 어떤 어휘 범주 X가 단독으로 쓰여도 구 범주 XP와 같은 자격을 가지는 것으로 일관되게 기술합니다.   ## 절(節) 판정 기준 주어와 서술어가 실현되어야 절이라고 말할 수 있습니다. 그런데 어떤 구성은 절인지 아닌지 판별하는 것도 까다롭습니다. 예문을 보겠습니다. > (ㄱ) 빵을 먹으면서 민수가 학교에 간다. > > (ㄴ) A: 철수는 밥을 먹었니? B: 응, 먹었어. > > (ㄷ) 불이야! (ㄱ)에서 서술어 '간다'의 주어는 '민수가'로 나와 있으나 '먹으면서'의 주어는 나와 있지 않습니다. (ㄴ)의 B의 대답에서도 맥락상 분명히 알 수 있는 '철수가'가 생략되어 있습니다. 그러나 이들 생략된 주어는 무엇인지 확인할 수 있다는 점에서 없지만 있는 것으로 보아야 합니다. 따라서 이 경우에는 '빵을 먹으면서'와 '먹었어'를 절로 봐야 합니다. 이와는 대조적으로 (ㄷ)은 전형적인 무주어문입니다. 무주어문은 서술어가 '이다'일 경우 성립하는 것으로서 절로 이뤄지지 않은 특수한 종류의 문장입니다.   ## 문장 문장이란 생각이나 감정을 말과 글로 표현할 때 완결된 내용을 나타내는 최소의 독립적 형식 단위입니다. 크게 **체계문(system sentence)**과 **사용문(text sentence)**으로 나뉩니다. 체계문은 해당 언어의 문법 원리에 따라 구성된 문장이고 사용문은 실제 사용되는 모습 그대로의 문장을 가리킵니다. 예문을 보겠습니다. > (a) 영희가 소설을 읽는다. > > (b) A: 영희가 무엇을 읽니? B: 응, 소설. > > (b') 응, 영희가 소설을 읽어. > > (c) 아버지는 신문을 읽고 (아버지는) 회사에 출근하셨다. (a)는 한국어의 문법 원리에 따라 문장을 끝맸는 종결어미까지 갖춘 '주어+목적어+서술어' 구성의 문장으로서 체계문에 해당합니다. 체계문은 원칙적으로 실제 언어생활에서 사용문으로도 쓰일 수 있습니다. 그러나 (b)의 대답 "응, 소설."이라는 문장은 (b')와 같은 체계문에서 담화 맥락상 불필요한 성분을 모두 생략한 사용문입니다. (a)와 (b)-A와 같이 필요한 성분이 문법 원리에 따라 완전하게 구성된 문장을 **완전문(full sentence)**이라 하고 (b)-B와 같이 실제 상황의 필요에 따라 완전문의 일부를 생략한 문장을 **소형문(minor sentence)**이라 합니다. 완전문은 체계문일 수도 있고 사용문일 수도 있으나 소형문은 사용문으로만 성립합니다.
generate␞ 이번 글에서는 말뭉치 빈도 정보를 바탕으로 문장을 생성하는 모델에 대해 살펴보도록 하겠습니다. 이 글은 '밑바닥부터 시작하는 데이터 과학(조엘 그루스 지음, 인사이트 펴냄)'을 기본으로 하되 목적에 맞게 파이썬 코드를 적절히 수정했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 데이터 불러오기 이광수 장편소설 '무정'을 분석 대상으로 삼았습니다. 소설 원문을 내려받아 어절 단위로 나누어 list 형태로 불러들이는 코드는 다음 한줄이면 됩니다. ```python document = open('text', 'r', encoding='utf-8').read().split() ```   ## 바이그램 모델 학습 말뭉치를 두 개 단어씩 슬라이딩해 학습을 먼저 수행해 줍니다. 다음과 같습니다. ```python from collections import defaultdict bigram_transitions = defaultdict(list) for prev, current in zip(document, document[1:]):   bigram_transitions[prev].append(current) ``` 학습 결과 일부는 다음과 같습니다. > '말하기' : ['미안한', '싫은', '어려운'] > > '나갈': ['길을', '방향을', '것', '길이나'] > > ...  ## 바이그램 모델 예측 초기 단어를 랜덤으로 선택한 뒤, 이 정보와 학습 결과를 바탕으로 단어 30개를 예측하는 함수는 다음과 같습니다. ```python import random def generate_using_bigrams(cut=30):   idx = 0   current = random.choice(list(bigram_transitions.keys()))   result = []   while True:     next_word_candidates = bigram_transitions[current]     current = random.choice(next_word_candidates)     result.append(current)     if idx == cut:       return " ".join(result)     idx += 1 ``` 예측 결과 일부는 다음과 같습니다. > (1) 되었다. 그러나 이 회화를 하며 웃는다. 목사의 뜻을 먼저 더러워졌다’ 하는 것이 아니다. 형식이나 선형에게 대한 처지와 같음이 아닐까. 아까, ‘제가 먹을 것도 생각하였다. 그러나 그것은 내서 무엇 하러 살아왔는고, 하는 > > (2) 떨어지는 수가 없는 것 모양으로 깨끗한 영혼과 자기의 지금 살아서 우리와 같은 하등 인종으로 알던 것이 매우 양심에 괴롭게 하십니까?” 형식은 모자와 말하는 모양이 생각에만 떠나와도 큰 남자와 같이 자라나던 형식이란 > > (3) 오랫동안 가물었으므로 대동강물은 꿈에 보던 시와 소설의 기억이 떠나왔던지 모르거니와 적어도 오 리(五里)나 되는 처녀가 처음 보는 눈에는 늘 심로를 하시면서 무엇하러 거기 가서 선 십여 년 지나온 생각이 있다. 계향은   ## 트라이그램 모델 학습 이번엔 단어를 세 개씩 슬라이딩해서 보는 트라이그램 모델을 학습해보겠습니다. 코드는 다음과 같습니다. ```python trigrams = zip(document, document[1:], document[2:]) trigram_transitions = defaultdict(list) ``` 학습 결과 일부는 다음과 같습니다. > ('벌떡', '일어나'): ['모기장을', '방에', '시퍼런', '방', '달려오더니', '문을'] > > ('가만히', '고개를'): ['숙였다.', '숙이고', '돌린다.'] > > ...   ## 트라이그램 모델 예측 트라이그램 모델로 단어 30개를 예측하는 함수는 다음과 같습니다. ```python def generate_using_trigrams(cut=30):   idx = 0   prev, current = random.choice(list(trigram_transitions.keys()))   result = [current]   while True:     next_word_candidates = trigram_transitions[(prev, current)]     next_word = random.choice(next_word_candidates)     prev, current = current, next_word     result.append(current)     if idx == cut:       return " ".join(result)     idx += 1 ``` 예측 결과 일부는 다음과 같습니다. > (1) 나는 살려고 난 것 같지를 아니해요. 아버지와 두 오라비를 건져 내려고 기생이 된 것이라. 영채가 평양 감옥에 흙물 옷을 입으신 부친의 얼굴을 대하기는 하였사오나, 무섭게 여윈 그 얼굴을 보았다. 이제 보니 선형이나 > > (2) 생각에 자기의 지아비는 극히 깨끗하고 점잖은 사람이라야 할 터인데 그러한 소리를 염치없이 하는 형식은 죄인인 듯하다. 더러운 기생에게 하던 버릇을 내게다가 했구나 하고 선형은 정면으로 형식을 본다. 형식은 자기의 변명을 할 기회가 > > (3) 그는 조선인 교육계에 대하여 항상 불만한 생각을 품는다. 그가 경성교육회라는 것을 설립할 양으로 두어 달을 두고 분주한 것도 이러한 기관을 이용하여 자기의 교육에 대한 이상(理想)을 선전(宣傳)하려 함이었다. 그러나 다른 교사들은 총독부의 고등보통교육령과 
tree␞ 이번 포스팅에선 한번에 하나씩의 설명변수를 사용하여 예측 가능한 규칙들의 집합을 생성하는 알고리즘인 **의사결정나무(Decision Tree)**에 대해 다뤄보도록 하겠습니다. 이번 글은 고려대 강필성 교수님 강의와 김성범 교수님 강의를 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 모델 소개 의사결정나무는 데이터를 분석하여 이들 사이에 존재하는 패턴을 예측 가능한 규칙들의 조합으로 나타내며, 그 모양이 '나무'와 같다고 해서 의사결정나무라 불립니다. 질문을 던져서 대상을 좁혀나가는 '스무고개' 놀이와 비슷한 개념입니다. 한번 예를 들어볼까요? <a href="http://imgur.com/ZKDnzOB"><img src="http://i.imgur.com/ZKDnzOB.png" width="500px" title="source: imgur.com" /></a>  위 예시는 운동경기가 열렸다면 PLAY=1, 그렇지 않으면 PLAY=0으로 하는 이진분류(binary classification) 문제입니다. 모든 사례를 조사해 그림으로 도시하면 위와 같은 그림이 되는 것입니다. 그림을 한번 해석해볼까요? 날씨가 맑고(sunny), 습도(humidity)가 70 이하인 날엔 경기가 열렸습니다. 해당 조건에 맞는 데이터들이 '경기가 열렸다(play 2건)'고 말하고 있기 때문입니다. 반대로 비가 오고(rain) 바람이 부는(windy) 날엔 경기가 열리지 않았습니다. 의사결정나무를 일반화한 그림은 아래와 같습니다. <a href="http://imgur.com/EBKl1I3"><img src="http://i.imgur.com/EBKl1I3.png" width="300px" title="source: imgur.com" /></a> 전체적으로 보면 나무를 뒤집어놓은 것과 같은 모양입니다. 아시다시피 초기지점은 root node이고 분기가 거듭될 수록 그에 해당하는 데이터의 개수는 줄어듭니다. 각 terminal node에 속하는 데이터의 개수를 합하면 root node의 데이터수와 일치합니다. 바꿔 말하면 terminal node 간 교집합이 없다는 뜻입니다. 한편 terminal node의 개수가 분리된 집합의 개수입니다. 예컨대 위 그림처럼 terminal node가 3개라면 전체 데이터가 3개의 부분집합으로 나눠진 셈입니다. 의사결정나무는 **분류(classification)**와 **회귀(regression)** 모두 가능합니다. 범주나 연속형 수치 모두 예측할 수 있다는 말입니다. 의사결정나무의 범주예측, 즉 분류 과정은 이렇습니다. 새로운 데이터가 특정 terminal node에 속한다는 정보를 확인한 뒤 해당 terminal node에서 가장 빈도가 높은 범주에 새로운 데이터를 분류하게 됩니다. 운동경기 예시를 기준으로 말씀드리면 날씨는 맑은데 습도가 70을 넘는 날은 경기가 열리지 않을 거라고 예측합니다.  회귀의 경우 해당 terminal node의 종속변수(y)의 평균을 예측값으로 반환하게 되는데요, 이 때 예측값의 종류는 terminal node 개수와 일치합니다. 만약 terminal node 수가 3개뿐이라면 새로운 데이터가 100개, 아니 1000개가 주어진다고 해도 의사결정나무는 딱 3종류의 답만을 출력하게 될 겁니다. 그렇다면 데이터를 분할한다는 건 정확히 어떤 의미를 지니는걸까요? 설명변수(X)가 3개짜리인 다변량 데이터에 의사결정나무를 적용한다고 가정하고 아래 그림을 보시면 좋을 것 같습니다. <a href="http://imgur.com/THaJKeR"><img src="http://i.imgur.com/THaJKeR.png" width="300px" title="source: imgur.com" /></a> 아무런 분기가 일어나지 않은 상태의 root node는 A입니다. 변수가 3개짜리이니 왼쪽 그래프처럼 3차원 공간에 있는 직육면체를 A라고 상정해도 좋을 것 같네요. A가 어떤 기준에 의해 B와 C로 분할됐다고 생각해 봅시다. 그렇다면 두번째 그림처럼 A가 두 개의 부분집합으로 나뉘었다고 상상해 볼 수 있겠습니다. 마지막으로 B가 D와 C로 분할됐다면, 3번째 줄의 그림처럼 될 겁니다. 이 예시에서 terminal node는 C, D, E 세 개 인데요, 이를 데이터 공간과 연관지어 생각해보면 전체 데이터 A가 세 개의 부분집합으로 분할된 것 또한 알 수 있습니다. D 특성을 갖고 있는 새로운 데이터가 주어졌을 때 의사결정나무는 D 집합을 대표할 수 있는 값(분류=최빈값, 회귀=평균)을 반환하는 방식으로 예측합니다.  ## 불순도/불확실성 의사결정나무는 한번 분기 때마다 변수 영역을 두 개로 구분하는 모델이라고 설명을 드렸는데요, 그렇다면 대체 어떤 기준으로 영역을 나누는 걸까요? 이 글에서는 타겟변수(Y)가 범주형 변수인 분류나무를 기준으로 설명하겠습니다. 결론부터 말씀드리면 분류나무는 구분 뒤 각 영역의 **순도(homogeneity)**가 증가, **불순도(impurity)** 혹은 **불확실성(uncertainty)**이 최대한 감소하도록 하는 방향으로 학습을 진행합니다. 순도가 증가/불확실성이 감소하는 걸 두고 정보이론에서는 **정보획득(information gain)**이라고 합니다. 이번 챕터에서는 어떤 데이터가 균일한 정도를 나타내는 지표, 즉 순도를 계산하는 3가지 방식에 대해 살펴보겠습니다. 우선 그림을 보시죠. <a href="http://imgur.com/heIgkif"><img src="http://i.imgur.com/heIgkif.png" width="300px" title="source: imgur.com" /></a> 먼저 설명드릴 지표는 **엔트로피(entropy)**입니다. m개의 레코드가 속하는 A영역에 대한 엔트로피는 아래와 같은 식으로 정의됩니다. (Pk=A영역에 속하는 레코드 가운데 k 범주에 속하는 레코드의 비율) $$Entropy(A)=-\sum _{ k=1 }^{ m }{ { p }_{ k }\log _{ 2 }{ { (p }_{ k }) } } $$ 이 식을 바탕으로 오렌지색 박스로 둘러쌓인 A 영역의 엔트로피를 구해보겠습니다. 전체 16개(m=16) 가운데 빨간색 동그라미(범주=1)는 10개, 파란색(범주=2)은 6개이군요. 그럼 A 영역의 엔트로피는 다음과 같습니다. $$Entropy(A)=-\frac { 10 }{ 16 } \log _{ 2 }{ (\frac { 10 }{ 16 } ) } -\frac { 6 }{ 16 } \log _{ 2 }{ (\frac { 6 }{ 16 } ) } \approx 0.95$$ 여기서 A 영역에 빨간색 점선을 그어 두 개 부분집합(R1, R2)으로 분할한다고 가정해 봅시다. 두 개 이상 영역에 대한 엔트로피 공식은 아래 식과 같습니다. 이 공식에 의해 분할 수 A 영역의 엔트로피를 아래와 같이 각각 구할 수 있습니다. (Ri=분할 전 레코드 가운데 분할 후 i 영역에 속하는 레코드의 비율) $$Entropy(A)=\sum _{ i=1 }^{ d }{ { R }_{ i } } \left( -\sum _{ k=1 }^{ m }{ { p }_{ k }\log _{ 2 }{ { (p }_{ k }) } } \right) $$ $$Entropy(A)=0.5\times \left( -\frac { 7 }{ 8 } \log _{ 2 }{ (\frac { 7 }{ 8 } ) } -\frac { 1 }{ 8 } \log _{ 2 }{ (\frac { 1 }{ 8 } ) } \right) +0.5\times \left( -\frac { 3 }{ 8 } \log _{ 2 }{ (\frac { 3 }{ 8 } ) } -\frac { 5 }{ 8 } \log _{ 2 }{ (\frac { 5 }{ 8 } ) } \right) \approx 0.75$$ 그럼 분기 전과 분기 후의 엔트로피가 어떻게 변화했는지 볼까요? 분기 전 엔트로피가 0.95였는데 분할한 뒤에 0.75가 됐군요. 0.2만큼 엔트로피 감소(=불확실성 감소=순도 증가=정보획득)한 걸로 봐서 의사결정나무 모델은 분할한 것이 분할 전보다 낫다는 판단 하에 데이터를 두 개의 부분집합으로 나누게 됩니다. 다시 한번 말씀드리지만 의사결정나무는 구분 뒤 각 영역의 순도(homogeneity)가 증가/불확실성(엔트로피)가 최대한 감소하도록 하는 방향으로 학습을 진행합니다. 순도와 관련해 부연설명을 드리면 A 영역에 속한 모든 레코드가 동일한 범주에 속할 경우(=불확실성 최소=순도 최대) 엔트로피는 0입니다. 반대로 범주가 둘뿐이고 해당 개체의 수가 동일하게 반반씩 섞여 있을 경우(=불확실성 최대=순도 최소) 엔트로피는 0.5의 값을 갖습니다. 엔트로피 외에 불순도 지표로 많이 쓰이는 **지니계수(Gini Index)** 공식은 아래와 같습니다. $$G.I(A)=\sum _{ i=1 }^{ d }{ { \left( { R }_{ i }\left( 1-\sum _{ k=1 }^{ m }{ { p }_{ ik }^{ 2 } } \right) \right) } } $$ 아래는 범주가 두 개일 때 한쪽 범주에 속한 비율(p)에 따른 불순도의 변화량을 그래프로 나타낸 것입니다. 보시다시피 그 비율이 0.5(두 범주가 각각 반반씩 섞여 있는 경우)일 때 불순도가 최대임을 알 수가 있습니다. **오분류오차(misclassification error)**는 따로 설명드리지 않은 지표인데요, 오분류오차는 엔트로피나 지니계수와 더불어 불순도를 측정할 수 있긴 하나 나머지 두 지표와 달리 미분이 불가능한 점 때문에 자주 쓰이지는 않는다고 합니다. <a href="http://imgur.com/n3MVwHW"><img src="http://i.imgur.com/n3MVwHW.png" width="500px" title="source: imgur.com" /></a>  ## 모델 학습 의사결정나무의 학습 과정은 입력 변수 영역을 두 개로 구분하는 **재귀적 분기(recursive partitioning)**와 너무 자세하게 구분된 영역을 통합하는 **가지치기(pruning)** 두 가지 과정으로 나뉩니다. 우선 재귀적 분기 먼저 살펴보겠습니다.  ### 재귀적 분기 아래와 같이 24개 가정을 대상으로 소득(income), 주택크기(Lot size), 잔디깎기 기계 구입 여부(Ownership)를 조사한 데이터가 있습니다. 이를 토대로 소득과 주택크기를 설명변수(X), 기계 구입 여부를 종속변수(Y)로 하는 분류나무 모델을 학습시켜 보겠습니다. <a href="http://imgur.com/tNBkISS"><img src="http://i.imgur.com/tNBkISS.png" width="500px" title="source: imgur.com" /></a> 우선 이를 한 변수 기준(예컨대 주택 크기)으로 정렬합니다. 이후 가능한 모든 분기점에 대해 엔트로피/지니계수를 구해 분기 전과 비교해 정보획득을 조사합니다. 예컨대 아래 표 기준으로 보시면 분기지점을 첫 레코드와 나머지 23개 레코드로 두고, 1번 레코드와 2~24번 레코드 간의 엔트로피를 구한 뒤 이를 분기 전 엔트로피와 비교해 정보획득을 조사합니다. 그 결과는 아래와 같습니다. <a href="http://imgur.com/XgIfBPX"><img src="http://i.imgur.com/XgIfBPX.png" width="300px" title="source: imgur.com" /></a> $$ \begin {align*} 분기\quad전\quad 엔트로피&=-\frac { 1 }{ 2 } \log _{ 2 }{ (\frac { 1 }{ 2 } ) } -\frac { 1 }{ 2 } \log _{ 2 }{ (\frac { 1 }{ 2 } ) } =1\\분기\quad후\quad엔트로피 &=\frac { 1 }{ 24 } \left( -\log _{ 2 }{ 1 } \right) +\frac { 23 }{ 24 } \left( -\frac { 12 }{ 23 } \log _{ 2 }{ (\frac { 12 }{ 23 } ) } -\frac { 11 }{ 23 } \log _{ 2 }{ (\frac { 11 }{ 23 } ) } \right) \approx 0.96\\ 정보획득&=1-0.96=0.04 \end{align*} $$ 이후 분기 지점을 두번째 레코드로 두고 처음 두 개 레코드와 나머지 22개 레코드 간의 엔트로피를 계산한 뒤 정보획득을 알아봅니다. 이렇게 순차적으로 계산한 뒤, 이번엔 다른 변수인 소득을 기준으로 정렬하고 다시 같은 작업을 반복합니다. 모든 경우의 수 가운데 정보획득이 가장 큰 변수와 그 지점을 택해 첫번째 분기를 하게 됩니다. 이후 또 같은 작업을 반복해 두번째, 세번째... 이렇게 분기를 계속 해 나가는 과정이 바로 의사결정나무의 학습입니다. 그렇다면 1회 분기를 위해 계산해야 하는 경우의 수는 총 몇 번일까요? 개체가 $n$개, 변수가 $d$개라고 할 때 경우의 수는 $d(n-1)$개가 됩니다. 분기를 하지 않는 경우를 제외하고 모든 개체와 변수를 고려해 보는 것입니다.  ### 가지치기 의사결정나무 모델 학습의 또다른 축은 **가지치기(pruning)**입니다. 모든 terminal node의 순도가 100%인 상태를 **Full tree**라고 하는데요. 이렇게 Full tree를 생성한 뒤 적절한 수준에서 terminal node를 결합해주어야 합니다. 왜냐하면 분기가 너무 많아서 학습데이터에 **과적합(overfitting)**할 염려가 생기기 때문입니다.  의사결정나무의 분기 수가 증가할 때 처음에는 새로운 데이터에 대한 오분류율이 감소하나 일정 수준 이상이 되면 오분류율이 되레 증가하는 현상이 발생한다고 합니다. 이러한 문제를 해결하기 위해서는 검증데이터에 대한 오분류율이 증가하는 시점에서 적절히 가지치기를 수행해줘야 합니다.  마치 나뭇가지를 잘라내는 것과 같다는 의미에서 이러한 용어가 붙었습니다. 매우 직관적이죠. 가지치기 개념도는 아래와 같습니다. 다만 가지치기는 데이터를 버리는 개념이 아니고 분기를 합치는(merge) 개념으로 이해해야 합니다. <a href="http://imgur.com/MVFcKwz"><img src="http://i.imgur.com/MVFcKwz.png" width="600px" title="source: imgur.com" /></a> 재귀적 분기를 설명해 드릴 때 들었던 잔디깎기 기계 구입 여부 데이터를 의사결정나무로 학습한 결과물입니다. 왼쪽이 Full tree, 오른쪽이 가지치기를 한 결과를 시각화한 것입니다. 왼쪽 그림을 보시면 모든 terminal node의 불순도는 0임을 확인할 수 있습니다.  하지만 terminal node가 너무 많으면 새로운 데이터에 대한 예측 성능인 **일반화(generalization)** 능력이 매우 떨어질 염려가 있습니다. terminal node를 적절하게 합쳐주면 오른쪽 그림과 같은 결과가 나오는 걸 확인할 수 있습니다. <a href="http://imgur.com/5zhZIAw"><img src="http://i.imgur.com/5zhZIAw.png" width="600px" title="source: imgur.com" /></a> 마지막으로 가지치기의 **비용함수(cost function)**를 살펴보겠습니다. 의사결정나무는 이 비용함수를 최소로 하는 분기를 찾아내도록 학습됩니다. 아래와 같이 정의됩니다.  $$CC(T)=Err(T)+\alpha \times L(T)$$ *CC(T)=의사결정나무의 비용 복잡도(=오류가 적으면서 terminal node 수가 적은 단순한 모델일 수록 작은 값)* *ERR(T)=검증데이터에 대한 오분류율* *L(T)=terminal node의 수(구조의 복잡도)* *Alpha=ERR(T)와 L(T)를 결합하는 가중치(사용자에 의해 부여됨, 보통 0.01~0.1의 값을 씀)*  ## 마치며 이상으로 의사결정나무에 대해 살펴보았습니다. 의사결정나무는 계산복잡성 대비 높은 예측 성능을 내는 것으로 정평이 나 있습니다. 아울러 변수 단위로 설명력을 지닌다는 강점을 가지고 있습니다. 다만 의사결정나무는 **결정경계(decision boundary)**가 데이터 축에 수직이어서 비선형(non-linear) 데이터 분류엔 적합하지 않습니다.  이같은 문제를 극복하기 위해 등장한 모델이 바로 [랜덤포레스트](https://ratsgo.github.io/machine%20learning/2017/03/17/treeensemble/)인데요, 같은 데이터에 대해 의사결정나무를 여러 개 만들어 그 결과를 종합해 예측 성능을 높이는 기법입니다.  의사결정나무든 랜덤포레스트는 R이나 Python 등 주요 언어에서 모두 패키지 형태로 쉽고 간편하게 사용을 할 수가 있으니 한번쯤은 실험을 해보시면 좋을 것 같습니다. 질문이나 의견 있으시면 이메일이나 댓글로 부탁드립니다. 여기까지 읽어주셔서 감사드립니다.
LDA␞ 이번 글에서는 말뭉치로부터 토픽을 추출하는 **토픽모델링(Topic Modeling)** 기법 가운데 하나인 **잠재디리클레할당(Latent Dirichlet Allocation, LDA)**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 모델 개요 LDA란 주어진 문서에 대하여 각 문서에 어떤 주제들이 존재하는지에 대한 확률모형입니다. LDA는 토픽별 단어의 분포, 문서별 토픽의 분포를 모두 추정해 냅니다. LDA의 개략적인 도식은 다음과 같습니다. <a href="http://imgur.com/r5e5qvs"><img src="http://i.imgur.com/r5e5qvs.png" width="600px" title="source: imgur.com" /></a> 우선 LDA는 특정 토픽에 특정 단어가 나타날 확률을 내어 줍니다. 예컨대 위 그림에서 노란색 토픽엔 gene이라는 단어가 등장할 확률이 0.04, dna는 0.02, genetic은 0.01입니다. 이 노란색 토픽은 대략 '유전자' 관련 주제라는 걸 알 수 있네요.  이번엔 문서를 보겠습니다. 주어진 문서를 보면 파란색, 빨간색 토픽에 해당하는 단어보다는 노란색 토픽에 해당하는 단어들이 많네요. 따라서 위 문서의 메인 주제는 노란색 토픽(유전자 관련)일 가능성이 큽니다. 이렇듯 문서의 토픽 비중 또한 LDA의 산출 결과물입니다.  위 그림 우측에 있는 'Topic proportions & assignments'가 LDA의 핵심 프로세스입니다. LDA는 문서가 생성되는 과정을 확률모형으로 모델링한 것이기 때문인데요. 글쓰기를 예로 들면 이렇습니다.  우선 글감 내지 주제를 정해야 합니다. 이후 실제 글을 작성할 때는 어떤 단어를 써야할지 결정합니다. LDA도 마찬가지입니다. 우선 말뭉치로부터 얻은 토픽 분포로부터 토픽을 뽑습니다. 이후 해당 토픽에 해당하는 단어들을 뽑습니다. 이것이 LDA가 가정하는 문서 생성 과정입니다. 이제 반대 방향으로 생각해보겠습니다. 현재 문서에 등장한 단어들은 어떤 토픽에서 뽑힌 단어들일까요? 이건 명시적으로 알기는 어렵습니다. 말뭉치에 등장하는 단어들 각각에 꼬리표가 달려있는 건 아니니까요.  그런데 LDA는 이렇게 말뭉치 이면에 존재하는 정보를 추론해낼 수 있습니다. LDA에 **잠재(Latent)**라는 이름이 붙은 이유입니다. LDA의 학습은 바로 이러한 잠재정보를 알아내는 과정입니다.  ## 모델 아키텍처 LDA의 아키텍처, 즉 LDA가 가정하는 문서생성과정은 다음과 같습니다. $D$는 말뭉치 전체 문서 개수, $K$는 전체 토픽 수(하이퍼 파라메터), $N$은 $d$번째 문서의 단어 수를 의미합니다. 네모칸은 해당 횟수만큼 반복하라는 의미이며 동그라미는 변수를 가리킵니다. 화살표가 시작되는 변수는 조건, 화살표가 향하는 변수는 결과에 해당하는 변수입니다. 우리가 관찰 가능한 변수는 $d$번째 문서에 등장한 $n$번째 단어 $w_{d,n}$이 유일합니다(음영 표시). 우리는 이 정보만을 가지고 하이퍼파라메터(사용자 지정) $α,β$를 제외한 모든 잠재 변수를 추정해야 합니다. 앞으로 이 글에서는 이 그림을 기준으로 설명할 예정이기 때문에 잘 기억해두시면 좋을 것 같습니다. <a href="http://imgur.com/CEGcfoM"><img src="http://i.imgur.com/CEGcfoM.png" title="source: imgur.com" /></a> LDA의 문서생성과정은 다음과 같습니다. 이는 저도 정리 용도로 남겨두는 것이니 스킵하셔도 무방합니다. > (1) Draw each per-corpus topic distributions $ϕ_k$~$Dir(β)$ for $k∈${$1,2,...K$} > > (2) For each document, Draw per-document topic proportions $θ_d$~$Dir(α)$ > > (3) For each document and each word, Draw per-word topic assignment $z_{d,n}$~$Multi(θ_d)$ > > (4) For each document and each word, Draw observed word $w_{d,n}$~$Multi(ϕ_{z_{d,n},n})$  ## LDA 모델의 변수 우선 각 변수를 설명하겠습니다. $ϕ_k$는 $k$번째 토픽에 해당하는 벡터입니다. 말뭉치 전체의 단어 개수만큼의 길이를 가졌습니다. 예컨대 $ϕ_1$은 아래 표에서 첫번째 열입니다. 마찬가지로 $ϕ_2$는 두번째, $ϕ_3$은 세번째 열벡터입니다. $ϕ_k$의 각 요소값은 해당 단어가 $k$번째 토픽에서 차지하는 비중을 나타냅니다. $ϕ_k$의 각 요소는 확률이므로 모든 요소의 합은 1이 됩니다(아래 표 기준으로는 열의 합이 1). |  Terms  | Topic 1 | Topic 2 | Topic 3 | | :--------: | :-----: | :-----: | :-----: | | Baseball | 0.000 | 0.000 | 0.200 | | Basketball | 0.000 | 0.000 | 0.267 | |  Boxing  | 0.000 | 0.000 | 0.133 | |  Money  | 0.231 | 0.313 | 0.400 | | Interest | 0.000 | 0.312 | 0.000 | |  Rate  | 0.000 | 0.312 | 0.000 | | Democrat | 0.269 | 0.000 | 0.000 | | Republican | 0.115 | 0.000 | 0.000 | |  Cocus  | 0.192 | 0.000 | 0.000 | | President | 0.192 | 0.063 | 0.000 | 그런데 아키텍처를 자세히 보면 $ϕ_k$는 하이퍼파라메터 $β$에 영향을 받는 걸 알 수 있습니다. 이는 LDA가 토픽의 단어비중 $ϕ_k$이 디리클레분포를 따른다는 가정을 취하기 때문입니다. LDA 기법에 디리클레라는 이름이 붙은 이유이기도 합니다. 디리클레분포 관련 자세한 내용은 [이곳](https://ratsgo.github.io/statistics/2017/05/28/binomial/)을 참고하시면 좋을 것 같습니다. $θ_d$는 $d$번째 문서가 가진 토픽 비중을 나타내는 벡터입니다. 전체 토픽 개수 $K$만큼의 길이를 가집니다. 예컨대 $θ_1$은 아래 표에서 첫번째 행벡터, $θ_5$는 다섯번째 행벡터가 됩니다. $θ_d$의 각 요소값은 $k$번째 토픽이 해당 $d$번째 문서에서 차지하는 비중을 나타냅니다. $θ_d$는 확률이므로 모든 요소의 합은 1이 됩니다(아래 표 기준으로는 행의 합이 1). | Docs | Topic 1 | Topic 2 | Topic 3 | | :---: | :-----: | :-----: | :-----: | | Doc 1 | 0.400 | 0.000 | 0.600 | | Doc 2 | 0.000 | 0.600 | 0.400 | | Doc 3 | 0.375 | 0.625 | 0.000 | | Doc 4 | 0.000 | 0.375 | 0.625 | | Doc 5 | 0.500 | 0.000 | 0.500 | | Doc 6 | 0.500 | 0.500 | 0.000 | $θ_d$ 역시 하이퍼파라메터 $α$에 영향을 받습니다. 이는 LDA가 문서의 토픽비중 $θ_d$이 디리클레분포를 따른다는 가정을 취하기 때문입니다.  이번엔 $z_{d,n}$에 대해 살펴보겠습니다. $z_{d,n}$은 $d$번째 문서 $n$번째 단어가 어떤 토픽에 해당하는지 할당해주는 역할을 합니다. 예컨대 세번째 문서의 첫번째 단어는 'Topic2'일 가능성이 높겠네요. Topic1과 2가 뽑힐 확률이 각각 0.375, 0.625이거든요.  $w_{d,n}$은 문서에 등장하는 단어를 할당해주는 역할을 합니다. $ϕ_k$와 $z_{d,n}$에 동시에 영향을 받습니다. 의미는 이렇습니다. 직전 예시에서 $z_{3,1}$은 실제로 Topic2에 할당됐다고 칩시다. 이제 $ϕ_2$를 봅시다. 그러면 $w_{3,1}$은 Money가 될 가능성이 높겠네요. Topic2의 단어 분포 가운데 Money가 0.313으로 가장 높거든요.  ## LDA의 inference 지금까지 LDA가 가정하는 문서생성과정과 잠재변수들이 어떤 역할을 하는지 설명했습니다. 이제는 $w_{d,n}$를 가지고 잠재변수를 역으로 추정하는 **inference** 과정을 살펴보겠습니다. 다시 말해 LDA는 토픽의 단어분포와 문서의 토픽분포의 결합으로 문서 내 단어들이 생성된다고 가정합니다. LDA의 inference는 실제 관찰가능한 문서 내 단어를 가지고 우리가 알고 싶은 토픽의 단어분포, 문서의 토픽분포를 추정하는 과정입니다. 여기에서 LDA가 가정하는 문서생성과정이 합리적이라면 해당 확률과정이 우리가 갖고 있는 말뭉치를 제대로 설명할 수 있을 것입니다. 바꿔 말해 토픽의 단어분포와 문서의 토픽분포의 결합확률이 커지도록 해야 한다는 이야기입니다. 확률과정과 결합확률을 각각 그림과 수식으로 나타내면 다음과 같습니다. ($z_{d,n}$:per-word topic assignment, $θ_d$:per-document topic proportions, $ϕ_k$:per-corpus topic distributions) <a href="http://imgur.com/ArQyvuO"><img src="http://i.imgur.com/ArQyvuO.png" title="source: imgur.com" /></a>  $$ \begin{align*} p(&{ \phi }_{ 1:K },{ \theta }_{ 1:D },{ z }_{ 1:D },{ w }_{ 1:D })=\\ &\prod _{ i=1 }^{ K }{ p({ \phi }_{ i }|\beta ) } \prod _{ d=1 }^{ D }{ p({ \theta }_{ d }|\alpha ) } \left\{ \prod _{ n=1 }^{ N }{ p({ z }_{ d,n }|{ \theta }_{ d })p(w_{ d,n }|{ \phi }_{ 1:K },{ z }_{ d,n }) } \right\} \end{align*} $$  위 수식에서 사용자가 지정한 하이퍼파라메터 $α,β$와 우리가 말뭉치로부터 관찰가능한 $w_{d,n}$을 제외한 모든 변수가 미지수가 됩니다. 따라서 우리는 $p(z,ϕ,θ$\|$w)$를 최대로 만드는 $z,ϕ,θ$를 찾아야 합니다. 이것이 LDA의 inference입니다. 그런데 분모에 해당하는 $p(w)$를 단번에 구할 수 없기 때문에 **깁스 샘플링** 같은 기법을 사용하게 됩니다. 깁스 샘플링 관련 자세한 내용은 [이곳](https://ratsgo.github.io/statistics/2017/05/31/gibbs/)을 참고하시면 좋을 것 같습니다.  ## LDA와 깁스 샘플링 LDA에서는 나머지 변수는 고정시킨 채 한 변수만을 변화시키되, 불필요한 일부 변수를 샘플링에서 제외하는 **collapsed gibbs sampling** 기법을 씁니다. LDA에서는 $p(z,ϕ,θ$\|$w)$를 구할 때 $ϕ,θ$를 계산에서 생략합니다. 깁스 샘플링으로 구한 $z$로 계산할 수가 있게 되거든요. 어쨌든 LDA의 깁스 샘플링 과정을 나타낸 수식은 다음과 같습니다.  $$ p({ z }_{ i }=j|{ z }_{ -i },w) $$  위 식의 의미는 이렇습니다. 말뭉치가 주어졌기 때문에 $w$는 우리가 이미 알고 있는 값입니다. $z$는 각 단어가 어떤 토픽에 할당돼 있는지를 나타내는 변수인데요. $z_{-i}$는 $i$번째 단어의 토픽 정보를 제외한 모든 단어의 토픽 정보를 가리킵니다. 식 전체적으로는 $w$와 $z_{-i}$가 주어졌을 때 문서의 $i$번째 단어의 토픽이 $j$일 확률을 뜻합니다. 아래 그림을 볼까요?  <a href="http://imgur.com/Olo5Tta"><img src="http://i.imgur.com/Olo5Tta.png" width="400px" title="source: imgur.com" /></a>  위 그림에서 $z_i$는 record라는 단어가 속하는 토픽입니다. 깁스 샘플링을 위해 토픽 정보를 지워 놓았습니다. 나머지 단어에 대한 토픽 정보는 그대로 씁니다. 이것이 바로 $z_{-i}$입니다. 이 상태의 정보를 토대로 record라는 단어가 어떤 토픽에 속할지 할당하는 것이 LDA의 깁스 샘플링 과정입니다. 이해를 돕기 위해 그림 하나 더 보겠습니다.  <a href="http://imgur.com/T9DG4PH"><img src="http://i.imgur.com/T9DG4PH.gif" title="source: imgur.com" /></a> 위 그림은 이렇게 이해하면 됩니다. 각 행은 문서를 나타냅니다. 동그라미는 각 문서에 속한 단어들입니다. 동그라미 안의 숫자들은 토픽 ID입니다. 처음엔 랜덤하게 뿌려 놓습니다. 첫번째 깁스 샘플링 대상인 첫번째 문서의 첫번째 단어 $z_{0,0}$의 토픽 정보를 지웁니다. 나머지 단어들의 토픽정보를 토대로 가장 그럴싸한 토픽 ID를 새로 뽑았습니다. 예시 그림에선 3이네요. 이번엔 $z_{0,1}$ 차례입니다. 첫번째 문서의 두번째 단어 $z_{0,1}$의 토픽 정보를 지웁니다. 새로 뽑은 $z_{0,0}$을 포함한 나머지 단어들의 토픽정보를 토대로 가장 그럴싸한 토픽 ID를 또 새로 뽑습니다. 1입니다.  이런 식으로 문서 내 모든 단어와 말뭉치 내 모든 문서에 대해 깁스 샘플링을 반복하면 어느 순간부터는 모든 단어에 대한 토픽 할당 정보가 수렴하게 됩니다.    ## 실제 계산과정 몇 가지 수식 정리 과정을 거치면 $d$번째 문서 $i$번째 단어의 토픽 $z_{d,i}$가 $j$번째에 할당될 확률은 다음과 같이 쓸 수 있습니다.  $$ p({ z }_{d, i }=j|{ z }_{ -i },w)=\frac { { n }_{ d,k }+{ \alpha }_{ k } }{ \sum _{ i=1 }^{ K }{ ({ n }_{ d,i }+{ \alpha }_{ i }) } } \times \frac { { v }_{ k,{ w }_{ d,n } }+{ \beta }_{ { w }_{ d,n } } }{ \sum _{ j=1 }^{ V }{ ({ v }_{ k,j }+{ \beta }_{ j }) } }=AB $$  위 수식의 표기를 정리한 표는 다음과 같습니다.  |    표기    |          내용          | | :-------------: | :--------------------------------------: | |  $n_{d,k}$  |   $k$번째 토픽에 할당된 $d$번째 문서의 단어 빈도    | | $v_{k,w_{d,n}}$ | 전체 말뭉치에서 $k$번째 토픽에 할당된 단어 $w_{d,n}$의 빈도 | |  $w_{d,n}$  |     $d$번째 문서에 $n$번째로 등장한 단어     | |   $α_k$   |   문서의 토픽 분포 생성을 위한 디리클레 분포 파라메터    | |   $β_k$   |   토픽의 단어 분포 생성을 위한 디리클레 분포 파라메터    | |    $K$    |       사용자가 지정하는 토픽 수       | |    $V$    |      말뭉치에 등장하는 전체 단어 수       | |    $A$    |   $d$번째 문서가 $k$번째 토픽과 맺고 있는 연관성 정도   | |    $B$    | $d$번째 문서의 $n$번째 단어($w_{d,n}$)가 $k$번째 토픽과 맺고 있는 연관성 정도 |  예를 들어보겠습니다. 우선 아래와 같이 단어 5개로 구성된 문서 doc1이 있고, 각 단어마다 토픽 $z_i$도 이미 할당돼 있다고 가정해 보겠습니다(초기엔 랜덤하게 할당을 하니 이렇게 가정하는 게 무리가 없습니다). 토픽 수는 사용자가 3개로 지정해 놓은 상태입니다.  | Doc1의 $i$번째 단어의 토픽 $z_{1,i}$ |  3   |  2  |  1  |  3  |  1  | | :--------------------------: | :------: | :---: | :---: | :----: | :----: | |  Doc1의 $n$번째 단어 $w_{1,n}$  | Etruscan | trade | price | temple | market |  말뭉치에 등장하는 모든 단어들을 대상으로 각각의 단어들이 어떤 토픽에 속해 있는지를 일일이 세어서 만든 표도 다음과 같다고 가정하겠습니다(이 표 역시 초기엔 랜덤 할당을 합니다)  |  구분  | Topic1 | Topic2 | Topic3 | | :------: | :----: | :----: | :----: | | Etruscan |  1  |  0  |  35  | | market |  50  |  0  |  1  | | price  |  42  |  1  |  0  | | temple |  0  |  0  |  20  | | trade  |  10  |  8  |  1  | |  ...  | ...  | ...  | ...  |  이제 깁스 샘플링을 할 차례입니다. $p(z_{1,2})$를 구해 보겠습니다. $z_{1,-2}$, 즉 첫번째 문서의 두번째 단어의 토픽($z_2$) 정보를 지운 상태에서, 나머지 단어들의 토픽 할당 정보를 활용해 계산하게 됩니다.  | $z_{1,i}$ |  3   |  ?  |  1  |  3  |  1  | | :-------: | :------: | :---: | :---: | :----: | :----: | | $w_{d,n}$ | Etruscan | trade | price | temple | market |  위 표를 보면 $z_{1,2}$를 지우고 나니 첫번째 문서엔 1번/3번 토픽이 각각 절반씩 있는 걸 확인할 수 있습니다. 바꿔 말해 $n_{1,1}=2$, $n_{1,3}=2$라는 것이죠. $α$는 사용자가 지정하는 하이퍼파라메터로 깁스 샘플링 과정에서 변하는 값이 아니므로 $A$의 크기는 $n_{1,1}$과 $n_{1,3}$에 영향을 받을 겁니다. 즉, $z_{1,2}$가 2번 토픽이 될 확률은 0이고, 1번/3번은 같습니다. $A$는 아래 그림과 같이 이해할 수 있습니다.  <a href="http://imgur.com/zItjMJ9"><img src="http://i.imgur.com/zItjMJ9.png" width="400px" title="source: imgur.com" /></a>  이번엔 수식의 오른쪽 부분인 $B$를 보겠습니다. 전체 말뭉치를 대상으로 단어들의 토픽 할당 정보를 조사한 표는 다음과 같다고 칩시다. 여기서 주의할 점은 깁스 샘플링을 수행하면서 trade의 토픽 정보를 지웠으므로 단어별 토픽 분포 표에서 $v_{2,trade}$가 1이 줄어든다는 사실입니다.  |  구분   | Topic1 | Topic2 | Topic3 | | :-------: | :----: | :-----: | :----: | | Etruscan |  1  |  0  |  35  | | market  |  50  |  0  |  1  | |  price  |  42  |  1  |  0  | | temple  |  0  |  0  |  20  | | **trade** | **10** | **8-1** | **1** | |  ...  | ...  |  ...  | ...  |  어쨌든 위 표를 보면 우리의 관심인 trade라는 단어의 토픽은 Topic1일 가능성이 제일 높겠네요. 전체 말뭉치에서 trade의 토픽은 1번, 2번, 3번 순으로 많거든요. 바꿔 말해 $v_{1,trade}=10$, $v_{2,trade}=7$, $v_{3,trade}=1$입니다. $B$에 적용된 $β$ 역시 샘플링 과정에서 바뀌는 과정이 아니므로 $B$의 크기는 $v_k$에 가장 많은 영향을 받을 겁니다. 이를 그림으로 나타내면 다음과 같습니다.  <a href="http://imgur.com/c4TaEw3"><img src="http://i.imgur.com/c4TaEw3.png" width="400px" title="source: imgur.com" /></a>  $p(z_{1,2})$는 $A$와 $B$의 곱으로 도출됩니다. $A$와 $B$를 각각 직사각형의 높이와 너비로 둔다면, $p(z_{1,2})$는 아래와 같이 직사각형의 넓이로 이해할 수 있습니다.  <a href="http://imgur.com/AzeeBUd"><img src="http://i.imgur.com/AzeeBUd.png" width="400px" title="source: imgur.com" /></a> 이 계산 예시에서 $z_{1,2}$는 Topic1에 할당될 가능성이 제일 큽니다. 하지만 Topic3에 할당될 가능성도 Topic1에 비해선 작지만 아주 없는 건 아닙니다. 확률적인 방식으로 토픽을 할당하기 때문입니다. 어쨌든 결과적으로 $z_{1,2}$이 Topic1에 할당됐다고 가정해 보겠습니다. 그러면 Doc1의 토픽 분포($θ_1$)와 첫번째 토픽의 단어 분포($ϕ_1$)가 각각 다음과 같이 바뀝니다.  | $z_{1,i}$ |  3   | **1** |  1  |  3  |  1  | | :-------: | :------: | :---: | :---: | :----: | :----: | | $w_{d,n}$ | Etruscan | trade | price | temple | market | |  구분   | Topic1 | Topic2 | Topic3 | | :-------: | :------: | :----: | :----: | | Etruscan |  1   |  0  |  35  | | market  |  50  |  0  |  1  | |  price  |  42  |  1  |  0  | | temple  |  0   |  0  |  20  | | **trade** | **10+1** |  7  |  1  | |  ...  |  ...  | ...  | ...  |  이런 방식으로 모든 문서, 모든 단어에 대해 깁스 샘플링을 수행하면 모든 단어마다 토픽을 할당해줄 수가 있게 됩니다. 이 과정에서 $ϕ,θ$ 또한 자연스럽게 구할 수 있습니다. 보통 1000회~1만회 반복 수행하면 그 결과가 수렴한다고 합니다.   ## 디리클레 파라메터의 역할 $d$번째 문서에 $i$번째로 등장하는 단어의 토픽이 $j$번째일 확률을 다시 쓰면 다음과 같습니다.  $$p({ z }_{d, i }=j|{ z }_{ -i },w)=\frac { { n }_{ d,k }+{ \alpha }_{ k } }{ \sum _{ i=1 }^{ K }{ ({ n }_{ d,i }+{ \alpha }_{ i }) } } \times \frac { { v }_{ k,{ w }_{ d,n } }+{ \beta }_{ { w }_{ d,n } } }{ \sum _{ i=1 }^{ V }{ { v }_{ k,j }+{ \beta }_{ j } } }=AB$$  $A$는 $d$번째 문서가 $k$번째 토픽과 맺고 있는 연관성 강도를 나타냅니다. $B$는 $d$번째 문서의 $n$번째 단어($w_{d,n}$)가 $k$번째 토픽과 맺고 있는 연관성의 강도를 가리킵니다. 그러면 여기에서 $α$ 값은 어떤 역할을 할까요? 이전 예시에서 첫번째 문서에 Topic2에 할당된 단어들이 하나도 없었습니다($n_{1,2}=0$). 원래대로라면 첫번째 문서가 Topic2와 맺고 있는 연관성 강도, 즉 $A$는 0이어야 할 겁니다. 이렇게 되면 $z_{d,i}$가 Topic2가 될 확률 또한 0이게 됩니다. 하지만 사용자가 지정하는 하이퍼파라메터 $α$ 존재 덕분에 $A$가 아예 0으로 되는 일을 막을 수 있게 됩니다. 일종의 smoothing 역할을 한다는 것이죠. 따라서 $α$가 클수록 토픽들의 분포가 비슷해지고, 작을 수록 특정 토픽이 크게 나타나게 됩니다. 이는 $β$가 $B$에서 차지하는 역할과 대동소이합니다. 아래는 디리클레 파라메터 변화에 따른 토픽 분포의 변화를 직관적으로 나타난 그림입니다. <a href="http://imgur.com/zgXrEKI"><img src="http://i.imgur.com/zgXrEKI.png" title="source: imgur.com" /></a>   ## 최적 토픽 수 찾기 LDA의 토픽수 $K$는 사용자가 지정하는 하이퍼파라메터입니다. 최적 토픽수 또한 여러 실험을 통해 구해야 하는 미지수라는 이야기입니다. 최적 토픽수를 구하는 데 쓰는 **Perplexity** 지표가 있어 소개합니다. LDA는 문서가 생성되는 과정을 확률모형으로 가정합니다. LDA로부터 추정된 토픽 정보($z$)를 활용해 계산한 각 단어의 발생확률이 클수록 학습 말뭉치가 생성되는 과정을 제대로 설명하는 것이라는 얘기입니다. 최적 토픽 수를 찾기 위한 방법도 이 아이디어를 차용합니다.  우선 깁스 샘플링으로 구한 $ϕ,θ$를 활용해 전체 문서, 모든 단어의 발생 확률 $p(w)$를 식으로 쓰면 다음과 같습니다. $p(w)$는 말뭉치에 등장한 모든 단어의 발생확률을 종합적으로 따지기 때문에 곱으로 연결되지만, 이를 로그를 취한 결과가 아래 식입니다.  $$ \log { \left\{ p(w) \right\} } =\sum _{ d=1 }^{ D }{ \sum _{ j=1 }^{ V }{ { n }^{ jd }\log { \left[ \sum _{ k=1 }^{ K }{ { \theta }_{ k }^{ d }{ \phi }_{ k }^{ j } } \right] } } } $$  $log(p(w))$ 개념은 이렇습니다. 첫번째 문서 세번째 단어가 'King'이라고 칩시다. 이 단어가 첫번째 문서에 나타난 빈도가 3이라고 하면 $n^{31}=3$입니다. 여기에 토픽의 단어분포 정보인 $ϕ$와 문서의 토픽 비중 정보인 $θ$를 element-wise 곱 방식으로 계산하게 됩니다. 그런데 'King'이라는 단어는 하나의 토픽에만 있는게 아니고 여러 토픽에 걸쳐 있을 수 있습니다. 흔한 단어일 경우 더욱 그렇겠지요. 그래서 모든 토픽에 대해 합을 계산하게 됩니다. 위 정보를 활용한 Perplexity 지표는 다음과 같이 구합니다.  $$ Perplexity(w)=exp\left[ -\frac { log\left\{ p(w) \right\} }{ \sum _{ d=1 }^{ D }{ \sum _{ j=1 }^{ V }{ { n }^{ jd } } } } \right] $$  $p(w)$는 클수록 좋은 inference이므로 $exp(-log(p(w)))$는 작을수록 좋을 겁니다. 따라서 아래 그림처럼 토픽 수 $K$를 바꿔가면서 Perplexity를 구한 뒤 가장 작은 값을 내는 $K$를 최적의 토픽수로 삼으면 됩니다.   <a href="http://imgur.com/NkL1d93"><img src="http://i.imgur.com/NkL1d93.png" width="350px" title="source: imgur.com" /></a> 
word2vecpos␞ 이번 글에서는 **Word2Vec**으로 임베딩한 단어 벡터가 **품사**의 종류와 어떤 연관을 맺고 있는지 살펴보도록 하겠습니다. 그럼 시작하겠습니다.  ## 품사와 분포 한국어 품사를 분류할 때 가장 결정적인 기준은 바로 **기능(function)**이라고 합니다. 기능이란 해당 단어가 문장 내에서 어떤 역할을 하는지 나타내는 개념입니다. 그런데 한국어에서는 단어의 기능이 **분포(distribution)**와 매우 밀접한 관련을 맺고 있다고 합니다. 분포란 단어의 등장 순서나 위치를 말합니다. 이와 관련 자세한 내용은 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/04/21/wordclass/)을 참고하시면 좋을 것 같습니다. Word2Vec은 단어를 벡터로 바꾸는 **임베딩(Embedding)** 기법입니다. 특히 **Skip-Gram(SG)**의 경우 중심단어로 주변단어를 더 잘 예측하기 위해 단어벡터들을 조금씩 업데이트하면서 학습이 이뤄지는 구조입니다. 다시 말해 Word2Vec은 단어벡터를 만들 때 주변 단어의 분포 정보를 활용한다는 것이지요. 이와 관련 자세한 내용은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/)을 참고하시면 좋을 것 같습니다. 어쨌든 제가 세운 가정을 다시 정리하면 아래와 같습니다. > (1) 한국어 품사 분류의 가장 중요한 기준은 기능이다. > > (2) 한국어 단어의 기능은 분포와 밀접한 관련이 있다. > > (3) Word2Vec은 말뭉치의 분포 정보를 학습에 반영한다. > > (4) Word2Vec으로 임베딩된 단어 벡터엔 품사 정보가 내재해 있을 것이다. > > (5) 같은 품사에 해당하는 단어 벡터는 서로 유사할 것이다.  ## 실험 설계 이번 실험에 사용한 말뭉치는 영화 리뷰 사이트 '왓챠'에서 수집한 655만306개의 리뷰입니다. 여기에 **Branching Entropy(이하 BE)**와 **Cohesion Probability(이하 CP)** 기법을 적용해 각각 학습했습니다. BE와 CP는 모두 말뭉치를 글자 단위로 빈도를 세어서 단어일 가능성을 점수로 나타내는 기법인데요. BE는 단어의 외부 정보, CP는 단어의 내부 정보를 점수화한다는 점에 차이가 있습니다.  BE에 대해 자세히 살펴보시려면 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/05/06/BranchingEntropy/)을, CP에 관해서는 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/05/05/cohesion/)을 참고하세요. 아울러 코모란 형태소 분석기를 사용해 토크나이징을 한 뒤 실험을 수행한 결과를 보시려면 [이곳](https://ratsgo.github.io/natural%20language%20processing/2017/05/11/word2vecpos2/)을 참고하시면 좋을 것 같습니다. 어쨌든 BE와 CP를 동시에 고려해 단어 점수 표를 만들고, 이를 바탕으로 말뭉치에 **tokenize**를 수행했습니다. 토크나이저 함수는 김현중 서울대 박사과정이 만든 토크나이저를 약간 커스터마이징했습니다. 아래와 같습니다.  ```python all_tokenized_contents = [] for review in reviews:   tmp = [tokenize(token) for token in review.split()]   tmp = flatten(tmp)   all_tokenized_contents.append(tmp) ############################################# # functions                 # ############################################# def tokenize(word, max_l_length=10):   if (not word) or (len(word) <= 2):     return word   score = []   for e in range(2, min(len(word), max_l_length)+1):     subword = word[:e]     _, branching = branching_dict.get(subword, (0, 0))     cohesion, _, _, _ = cohesion_dict.get(subword, (0, 0, 0, 0))     # (word, cohesion * branching entropy, length)     score.append((subword, cohesion * branching, e))   result1 = sorted(score, key=lambda x:(x[1], x[2]), reverse=True)[0][0]   if len(result1) < len(word):     result2 = word.replace(result1, "")     if len(result2) > 2:       result2 = cpbe_tokenize(result2)     return [result1, result2]   return result1   def flatten(tokens, basestring = str):   result = []   for token in tokens:     if hasattr(token, "__iter__") and not isinstance(token, basestring):       result.extend(flatten(token))     else:       result.append(token)   return result ```  토크나이징한 결과물의 일부는 아래와 같습니다.  |      처리 전      |         처리 후          | | :------------------------: | :-------------------------------------: | | 지금도 가슴 한 켠에서 상영되고 있는 그런 영화 | 지금, 도, 가슴, 한, 켠에, 서, 상영, 되고, 있는, 그런, 영화 | | 마지막 장면은 책을 읽으며 상상했던 그대로였다 | 마지막, 장면, 은, 책을, 읽으며, 상상, 했던, 그대로, 였다  | |   화려한 의상과 소품 인테리어    |     화려한, 의상, 과, 소품, 인테리어      | |  억지스러운 반전에 씁쓸하고 슬픈 이야기  |    억지스러운, 반전, 에, 씁쓸하고, 슬픈, 이야기    | |  핀처가 세운 야심에 루니 마라가 차지한다  |  핀처, 가, 세운, 야심, 에, 루니, 마라, 가, 차지, 한다  |  이렇게 토크나이징을 수행한 말뭉치에 Word2Vec 기법을 적용했습니다. 하이퍼파라메터 조합은 아래와 같습니다. > **embedding 차원 수** : 100 > > **window 크기** : 3 > > **min_count** : 100 > > **Skip-Gram 적용**  ## 실험 결과1 (종결어미) 우선 **종결어미**를 중심으로 실험 결과를 살펴보겠습니다. 앞으로 나열할 표는 해당 단어벡터와 **코사인 유사도**가 가장 높은 단어들 100개 리스트입니다. ### -다 <p class="message"> 다ㅋㅋ, 다ㅠㅠ, 다ㅠ, 다ㅜ, 다ㅎ, 다고, 다ㅡ, 다ㅋㅋㅋ, 다라는, 다ㅋ, 다ㅎㅎ, 다는, 다ㅋㅋㅋㅋㅋ, 다ㅋㅋㅋㅋ, 다더, 다던, 다구, 얌, 다며, 다면, 다란, 었다, 다던데, 다네, 다지만, 다거나, 다아, 다라고, 다의, 다와, 다잉, 에요, 구먼, 예요, 구만, 닷, 닼ㅋㅋㅋ, 다기, 라능, 었당, 엿다, 였다, 로구나, 죠, 었겠지, 다도, 에여, 야ㅠㅠ, 었군, 였음, 지요, 었음, 겠지, 였군, 었지만, 거든요, 더라, 단다, 노병은, 듯하다, 다에, 것같다, 거늘, 었는데, 란다, 라해도, 다라, 었달까, 엇다, 군, 더라도, 엇음, 랍니다, 야라는, 었더라, 였어, 구나, 었네, 다길래, 희안한, 었구나, 지ㅋ, 닼ㅋㅋ, 였어요, 었죠, 다진, 었으나, 였당, 지만, 네, 네요, 시다, 었잖아, 더군, 여, 엿는데, 군요, 로다, 었습니다, 당 </p> <br> ### -요 <p class="message"> 요ㅠㅠ, 요ㅎㅎ, 요ㅜ, 요ㅋㅋ, 요ㅠ, 요ㅎ, 효, 욤, 봐요, 요라, 욥, 염, 욧, 졌네, 봐, 부다, 봉가, 아뇨, 요로, 싶네요, 져요, 저는, 야해, 에요, 신가, 보오, 지네요, ㅜㅠ, 봅니다, HO, 야지, 그럼, 야돼, 썽, ㅎㅎ, 싶당, 지더라, 가요, 집니다, at, 나요, 싶습니다, 해요, 있답니다, 시벌, 암튼, 야징, 흑흑, 저처럼, 님, 요가, ㅎ, 찌, ㅜㅜ, 있잖아, 잘지내, 에여, 줄께, ㅠㅠ, 진다, 주세요, 제가, 쪙, 께요, 본데, 여, 쪄, 야됨, ㅇㅅ, 시다, 질거야, 졌다, 해여, 줘요, 님도, 미안해요, 해용, 있습니까, 아ㅏㅏ, 줄게요, 할아부지, 싶네, ㅠ, 8ㅅ8, ㅜ, 요를, 죄송해요, 예요, 씨, 야되, 보네, 죠, 주신, 여튼, 씀, 서요, 응, 어요, 진거, ㅅ </p> <br> ### -구나 <p class="message"> 구만, 군, 구먼, 군요, 겠구나, 었구나, 겠지, 거구나, 네, 거니, 죠, 네요, 지요, 네ㅋㅋ, 었군, 단다, 단걸, 지ㅋ, 당, 더라, 거늘, 네ㅠㅠ, 였구나, 네여, 을까, 달까, 었나, 었지, 넹, 건가, 건만, 했구나, 었네, 였군, 지라는, 더라는, 대요, 거죠, 도다, 답니다, 더군요, 냐, 잖아, 쟈나, 거야, 거다, 었는데, 는가, 가보다, 나보다, 겠죠, 거겠지, 네ㅋ, 드만, 갑다, 네ㅋㅋㅋ, 자나, 는대, 어, 냐만은, 거든요, 오랜만이네, 많구나, 더이다, 하구나, 어라, 을줄이야, 건데, 을꺼야, 지ㅠㅠ, 거였어, 노라, 음, 나봄, 거지, 아냐, 지ㅠ, 댜, 지ㅜ, 당ㅋ, 더군, 말인가, 닼ㅋㅋ, 습니다, 있구나, 걸까, 더냐, 쪄, 거든, 거냐, 어요, 지뭐, 음을, 었을까, 겟지, 지ㅋㅋㅋ, 으려나, 나, 겠나, 나봐 </p> <br> ### -군 <p class="message"> 군요, 구만, 구나, 구먼, 네요, 당, 죠, 네, 네여, 더라, 넹, 더군요, 지ㅋ, 달까, 단다, 지요, 겠지, 소, 더라는, 겠구나, 더군, 습니다, 네ㅋㅋ, 답니다, 네ㅠㅠ, 당ㅋ, 음, 긴함, 었군, 네ㅋ, 대요, 슴, 슴다, 자나, 었구나, 따, 지라는, 도다, 드만, 어요, 네용, 더이다, 거늘, 음ㅎㅎ, 읍니다, 더만, 냐만은, 건만, 어, 으려나, 는가, 는뎅, 습니까, 엌ㅋㅋㅋ, 었는데, 내요, 거든요, 거니, 겠죠, 긔, 긴하지만, 는디, 쟈나, 든데, 잖아, 네ㅋㅋㅋ, 냐, 나요, 겠군, 더냐, 음ㅋ, 음ㅎ, 을까, 단걸, 나ㅋㅋ, 닼ㅋㅋ, 겠지만, 겟지, 다잉, 다던데, 댜, 였군, 지ㅋㅋ, 국, 닼ㅋㅋㅋㅋㅋㅋ, 나보다, 나ㅠ, 긴한데, 겠네, 드라, 나뿐인가, 다ㅋㅋ, 거보면, 거죠, 음ㅋㅋㅋㅋ, 러시아, 닼ㅋㅋㅋ, 법, 닼ㅋㅋㅋㅋ, 말입니다 </p> <br> ### -네 <p class="message"> 더라, 넹, 네요, 네ㅋㅋ, 네ㅋ, 네ㅠㅠ, 네ㅋㅋㅋ, 더이다, 네여, 구만, 더만, 당, 잖아, 네용, 죠, 긔, 더군요, 거든요, 겠지, 더라는, 군, 거든, 구먼, 었네, 자나, 습니다, 쟈나, 어요, 냐, 는디, 음ㅎ, 엌ㅋㅋㅋ, 음ㅋㅋㅋㅋㅋㅋ, 구나, 드만, 군요, 쟈냐, 던데, 도다, 든데, 어, 지뭐, 닼ㅋㅋㅋㅋ, 당ㅋ, 어ㅋㅋㅋ, 음ㅎㅎ, 긴함, 더군, 음, 닼ㅋㅋㅋㅋㅋㅋ, 졍, 거늘, 구요, 따, 닼ㅋㅋ, 니깐, 나봄, 댜, 얔ㅋㅋㅋ, 음ㅋㅋㅋㅋ, 나보다, 지요, 던가, 겠죠, 겠네, 겠어, 음ㅋ, 엉, 구, 아ㅋㅋ, 나봐, 슴, 긴하지만, 느냐, 슴다, 나요, 는뎅, 었죠, 지ㅋ, 는데, 더니, 는줄, 어라, 겠니, 었는데, 앜ㅋㅋㅋㅋ, 을꺼야, 건만, 닼ㅋㅋㅋ, 읍니다, 소, 내요, 나봐요, 더냐, 겠냐, 을거야, 긴하, 는대, 어ㅠ, 긴한데 </p> <br> ### -마 <p class="message"> 마요, 마라, 마셈, 말아라, 맙시다, 말자, 마세요, 말아요, 할아, 말라고, 줘, 작작, 마세, 제발, 말기, 말길, 말라, 말구, 말어, 건들지마, 말던가, 만요, 말아, 주오, 말것, 마소, 해줘, 마도, 그만, 다오, 않겠습니다, 줘요, 아르, 쉬세요, 않니, 미츠, 아오, 둬, 주세요, 내버려둬, 것좀, 말란, 그랬어요, 해라, 말라는, 말아야, 지마, 말지어다, 루, 마로, 해봐, 않어, 에잇, 나대, 해주세요, 않으, 들아, 와라, 님아, 됐잖아, 놔, 머니, 아씨, 않겠, 마오, 씨바, 욧, 오, ㅆ, 함부로, 않아도, 죄짓고, 해줘요, 마들, 소서, 얘들아, 말지, 마시, 말걸, 하지말고, 세요, 징한, 못했습니다, 말고, 힝, 못함, 데어, 않겠다, 러면, 쉬게, 년아, 말거, 시팔, 혀, 나카, 씨발, 못햇다, 노노, 미라, 하십 </p> <br> ### -냐 <p class="message"> 냐고, 더냐, 던가, 죠, 맞냐, 잖아, 었냐, 냐가, 좋냐, 겠는가, 얔ㅋㅋㅋ, 네, 냐는, 더라, 겠냐, 라구요, 거늘, 겠나, 구만, 야ㅋㅋ, 겠니, 자나, 겠어, 냐면, 느냐, 겠지, 냐를, 이냐, 었니, 냐의, 란말, 다냐, 쟈나, 구먼, 지요, 냔, 거든, 뭔데, 었잖아, 되냐, 네ㅋ, 더라는, 지ㅋ, 드만, 죄야, 었을까, 중헌디, 참나, 었나, 야이, 었네, 려나, 었더라, 네ㅠㅠ, 냐만은, 나요, 하냐, 겠습니, 란다, 었지, 냐며, 을줄이야, 뭐냐, 뭐여, 거든요, 뭐요, 로다, 넹, 는가, 란말이, 입니까, 니까, 십니까, 더만, 라구, 이딴게, 라더니, 든, 겟네, 뭐야, 묻자, 겠어요, 었군, 했냐, 었구나, 지ㅋㅋㅋ, 야ㅠㅠ, 봤냐, 네ㅋㅋㅋ, 나봐요, 을까, 네ㅋㅋ, 느니, 죽느, 되든, 니라, 긔, 방탄유리, 구나, 였군 </p> <br> ### -니 <p class="message"> 니ㅠㅠ, 니요, 길래, 니깐, 면, 느니, 하니, 뇨, 더니, 는게, 구, 구요, 던데, 능, 곤, 니까, 했더니, 든가, 며, 한들, 면야, 기보단, 던가, 려니, 시고, 고는, 맙소사, 시니, 면서, 다보니, 깐, 셨나, 게다가, 라구, 는거, 하하하하하하, 는건, 니라, 려나, 는데, 더만, 십니까, 셔서, 는거야, 는걸, 겠나, 해야하나, 네ㅠㅠ, 냐, 거기다, 오, 보니, 대다, 했는데, 와아, 랬지, 말어, 리라, 고보면, 고보니, 네, 기엔, 라니, 고, 셨어요, 겠어, 하하, 니만, 기에, 리라고, 그런데, 려면, 되니, 네ㅋ, 랴, 못해, 지마, 세요, 젠장, 있으니, 제길, 싶었는데, 고서, 고도, 시면, 아아, 하더라도, 왔더니, 핳, 더구나, 누, 고선, 메, 우니, 아놔, 오니, 시오, 든데, 앗, 않습니 </p> <br> ### -까 <p class="message"> 까요, 까나, 깐, 텐데, 려나, 까라는, 꺼같다, 꺼야, 테니, 꺼같, 꼬, 라나, 까봐, 껄, 테니까, 을까, 줄이야, 런지, 련지, 꺼에요, 았을까, 땐, 울까, 있나, 있을까, 있겠습니까, 꺼다, 테지, 질까, 없으니, 쏘냐, 좋냐, 꺼면, 으려나, 있으려나, 으니, 습니까, 게요, 겠나, 때엔, 테다, 때는, 진데, 은데, 래, 찌, 됐지, 됬지, 법하, 어ㅠ, 꺼, 테고, 없겠지, 랴, 래요, 때, 리가, 냐, 있겠는가, 졍, 까를, 있으니, 을라, 같냐, 없겠, 수록, 거란, 있었을까, 거다, 을꺼야, 을거야, 될까, 을듯, 을거, 지경, 거야, 때다, 을지, 줄텐데, 지라도, 때의, 았나, 수있, 줄은, 겠네, 있겠구나, 었니, 는뎅, 뿐인데, 됐잖아, 거라고, 없겠다, 없죠, 있겠, 때랑, 겁니다, 때에는, 겠는가, 있겠지, 냐고 </p> <br> ### -랴 <p class="message"> 겠는가, 있겠는가, 리오, 십니까, 있으, 있겠습니까, 므로, 리라, 어떠하, 리, 겠냐, 어떠, 냐고, 겠니, 려나, 렴, 려면, 겠습니, 시라, 겠나, 까요, 세요, 련다, 쏘냐, 신가, 리란, 겠어, 잊으, 든, 던간에, 냐, 리라고, 더냐, 던가, 있냐, 노니, 시오, 든지, 니깐, 없으, 리라는, 셨다, 어찌, 었으, 시니, 시죠, 어떻고, 시겠, 니까, 셨나, 든간에, 어쩌, 됬든, 하랴, 까, 죠, 시다, 겠소, 신다면, 누, 있을까, 시고, 있나, 되든, 셨어요, 없겠지만, 습니까, 은가, 하겠는가, 리나, 않으, 련지, 저쩌고, 없으니, 셨는, 셔, 어떠냐, 래요, 꼬, 없습니다, 있습니까, 느냐에, 겠어요, 던지, 려구, 너희는, 시는, 말인가, 려한다, 시나, 며, 느냐, 라구, 니, 대수, 려니, 없군, 너라, 시길, 누가 </p> <br> ### -라 <p class="message"> 라고, 라서, 라하, 여서, 라며, 라길, 라할, 래서, 라곤, 라네, 니까, 여, 라구, 라니, 야, 라지만, 어서, 야라, 작이라, 다라고, 이라, 리라, 거라, 에요, 라구요, 라능, 라면, 라해, 니깐, 라라, 랄까, 야ㅠㅠ, 었기에, 예요, 라는, 란다, 랬다, 시라, 라거, 일거라, 라도, 다고, 엿다, 라해도, 라를, 에여, 기에, 라그, 얌, 랍니다, 얍, 그런지, 라지, 라의, 다라, 였기에, 왔기에, 일것이, 라가, 란, 이니, 이라고, 라던, 라와, 야지, 란걸, 겠거니, 아무리, 을거라고, 라기엔, 란건, 주라, 였단, 닷, 므로, 뭐니, 여야만, 칭할, 보더, 줘서, 였다, 야가, 있느, 지뭐, 얔ㅋㅋㅋ, 야겠다, 래, 자랑스럽게, 였으니, 랬지, 이기에, 진다고, 사극이라, 졌으, 문에, 꺼라, 엿음, 이제는, 였구나, 그래서 </p> <br> ### -지 <p class="message"> 지가, 지도, 지를, 지ㅠ, 려하지, 지ㅜ, 지ㅋㅋㅋ, 지는, 지ㅠㅠ, 진, 지ㅋ, 지요, 겠어, 겠냐, 되지, 냐고, 겠는가, 그렇지, 하지, 지않, 띄지, 지라는, 철들지, 죠, 리지, 징, 겠지, 키지, 지ㅋㅋ, 녹슬지, 입지, 시지, 었는지, 기란, 려나, 울지, 죽지, 는지, 달지, 겠군, 지지, 지의, 는가를, 냐, 겟음, 좋지, 겟어, 겠니, 거나, 보지, 구만, 쉽지, 디, 구애받지, 묻지, 하질, 스럽지, 오지, 되, 남지, 네ㅋ, 보질, 답지, 돋지, 느냐, 있지, 질, 늦지, 던가, 긴했, 려는지, 겠지만, 늙지, 넹, 겠나, 끼지, 잃지, 더냐, 겠음, 들지, 화하지, 뛰지, 겠구나, 단걸, 더라도, 나진, 지이, 겠다, 살진, 었지, 나지, 네요, 면서도, 는진, 많지, 줄지, 벗지, 겠죠, 닮지, 겟네 </p> <br> ### -고 <p class="message"> 고도, 고는, 고만, 며, 기보다, 고선, 고들, 을거라고, 는거, 던가, 구, 면서, 기보단, 고나, 곤, 을거라, 는건, 고싶다, 고서, 다고, 고라, 거나, 다라고, 는걸, 라고, 는것, 는게, 면서도, 었고, 던데, 고야, 는데, 느니, 니, 더니, 부시고, 혹자는, 을때가, 는듯, 구요, 든가, 그렇다고, 는거야, 지만, 듯이, 면, 다못해, 기고, 튀고, 그러면서, 어라, 게끔, 다보니, 맞고, 게하는, 겠소, 길래, 능, 기까지, 유치하다, 자고, 기만, 때리고, 야하고, 자부, 하고, 고가, 기전에, 헌데, 지않고, 을만, 기도, 었으나, 죽이고, 겠냐, 고싶, 지못, 우고, 나고, 었냐, 려는지는, 을거라는, 으라, 지말, 겠구나, 었나, 는구, 던걸, 었는지, 던영화, 더만, 았나, 었더라, 까놓고, 파헤치고, 냐고, 롭다고, 뛰고, 심각하게, 물론 </p> <br> ### -며 <p class="message"> 면서, 면서도, 하며, 기보단, 거나, 고, 기보다, 도록, 고도, 고선, 니, 려한다, 듯이, 느라, 다보니, 려하는, 리라, 므로, 다보면, 기위해, 십니까, 이며, 던가, 다니, 느냐에, 든가, 게된다, 려다, 게함, 지말, 느니, 걸으면서, 게한다, 내며, 기에, 가며, 시고, 되, 곤, 던지, 게하는, 하면서, 셔서, 셨나, 느냐, 기전에, 공유하며, 리며, 기엔, 다못해, 쓰며, 기전, 려는, 시니, 시던, 련다, 기에는, 려고, 러, 지않고, 려면, 기까지의, 려하지만, 않으며, 안으, 다가, 리면서, 신듯, 여, 게끔, 기만, 리만치, 타며, 던, 그러면서, 치며, 더니, 않고, 더라도, 고싶다, 신다, 기에도, 못하고, 려, 려던, 랴, 기까지, 우며, 되며, 쥐며, 길래, 키며, 바밤, 자마, 시는, 시길, 려나, 낌없이, 세요, 게한 </p> <br>  ## 실험결과2 (조사) 종결어미와 같은 방식으로 조사도 분석했습니다. ### -이 <p class="message"> 은, 이야말로, 이었는데, 이영화가, 이란, 홀이, 스완이, 이었을까, 쇼가, 성이, 이었다, 타이틀이, 이미지가, 내레이션이, 이였다, 체가, 이라, 이죠, 미가, 조커가, 후광이, 이었는지, 을, 이다, 품이, 흥이, 이가, 애정이, 이여서, 신이, 이라는, 갈증이, s가, 이였는데, 샘이, 이였을까, 화가, 이었구나, 가위손이, 2가, 시퀀스가, 수명이, 강박이, 기준이, 우울함이, 향이, 유쾌함이, 등이, 포가, 으로, 전체가, 이었던, 수퍼맨이, 고뇌가, 이라도, 이랑, 드래곤길들이기, 표가, 이었고, 이었지만, 실이, 이라고, 1이, 이구나, r가, 눙물이, 후가, 스러움이, 입담이, 스카이폴이, 정사씬이, 토토가, 이랄까, 이었음, 수다가, 후유증이, 이군, 배경음악이, 이나, 잭슨이, 이라면, 3이, 조페시, 이프온리, 들이, 이론이, 이잇, 그림자가, 이였어, 가가, 유치함이, 다움이, 싱이, 거인이, 3가, 업이, 씬이, 과, 감각이, 불협화음이 </p> <br> ### -가 <p class="message"> 는, 체가, 와, 를, 퀸이, 로가, 터가, 라인이, 디가, 노튼이, 관이, 후가, 트가, 애가, 젠버그가, 스가, y가, 이미지가, 링이, 마인드가, 시그널이, 아저씨가, 2가, 맨이, 보스가, 즈가, 물이, 쇼가, 3가, 력이, 파가, 역할이, 활약이, 색이, 공리가, 파커가, 립이, 틱이, 크가, 활이, 레저가, 핏이, 존슨이, 4가, 아빠가, 인어가, 들이, 하녀가, 부재가, 오빠가, 팀이, 이정현은, 트랙이, 너가, 등이, 로, 가수가, 키튼이, 맥도, s가, 아줌마가, 류가, 색깔이, 그루가, 엘레, 춤이, 자매가, 건이, 곰이, 무게감이, 와는, 성우가, 악역이, 주제의식이, 그레이가, 였기에, 대결이, 였을까, 언이, 포가, 브가, 위가, 형이, 쉽이, 빨이, 벨이, 더프, 짐이, 콘이, 노가, e가, 마녀가, 사만다가, 제다이가, 프가, 극이, 강철중은, 이영화가, 조커가, 담이 </p> <br> ### -께서 <p class="message"> 시던, 께, 님이, 셨다, 감사합니다, 들께, 님, 님께서, 하셨던, 셨던, 주신, 교수님이, 선생님, 신다, 시는, 님은, 쌤이, 고맙습니다, 님들, 선생님이, 존경합니다, 저희, 셨어요, 님께, 분들이, 하신, 많으셨습니다, 셨는, 하셨다, 세요, 셔서, 신, 목사님, 사마, 말씀, 오신, 분들, 드린다, 강사, 교수님, 어머니가, 수고하셨습니다, 안녕하세요, 왈, 님도, 어머님, 시면, 님을, 하신다, 오셨, 계신, 하시고, 지망, 하사, 께는, 주셨, 어머니, 시고, 분께, 하셨어요, 가셨, 주셔서, 아버님, 말씀을, 학교에서, 하십니, 가신, 님의, 주시는, 표합니다, 국어, 죄송해요, 만수무강, 하셔서, 존경하는, 분이, 선배, 느님, 두분이, 놓으, 표함, 제가, 1학년, 담임, 십니, 할아버지, 죄송합니다, 저는, 계셨, 부장, 하심, 저에게, 시죠, 왕년에, 계실, 않겠습니다, 님에게, 보셨, 계시, 시다 </p> <br> ### -에서 <p class="message"> 에선, 들에서, 안에서, 판에서, 로부터, 내에서, 씬에서, 이후에, 속에서, 여기서, 가에서, 상에서, 왕국에서, 사에서, 감옥에서, 거기서, 데서, 이후로, 부분에서, 계에서, 역에서, 1에서, 물에서, 신에서, 끝에서, 공항에서, 곳에서, 이후, 룸에서, 무대에서, 로에서, 책에서, 밑에서, 전편에서, 그곳에서, 동굴에서, 전작에서, 속, 2에서, 아래에서, 지점에서, 나라에서, 바닥에서, 삶에서, 중심에서, 판, 위에서, 작에서, 2편에서, 어둠속에서, 어로, 편에서, 거리에서, 사극에서, 함에서, 어디서, 에, 들로부터, 쪽에서, 에까지, 최근에, 이후부터, 병점, 그늘에서, 오면서, 이후의, 2관, 직전에, 땅에서, 통하여, 스카이폴에서, 드디어, 오디션, 크레딧에서, 극에서, 예전에, 모습에서, 스크린에서, 통해, 원에서, 앞에서, 상륙작전, 호텔에서, 3단, 에나, 부산에서, 시장에서, 꿈속에서, 점에서, 올나잇, 장에서, 속의, 길에서, 한가운데서, 방에서, 이전에, 한복판에, 통에서, 로, 진가 </p> <br> ### -을 <p class="message"> 등을, 들을, 만을, 사를, 링을, 고뇌를, 업을, 접점을, 우울함을, 씬을, 계를, 미를, 의식을, 권을, 이를, 그를, 식을, 팀을, 이라도, 시각을, 성을, 미래를, 코드를, 관점을, 이미지를, 열망을, 아름다움을, 섬을, 그것을, 신을, 으로, 스러움을, 향을, 아련함을, 모순을, 전설을, 먼을, 진을, 위대함을, 단어를, 가를, 미학을, 은, 무언가를, 해전을, 멋을, 것을, 대상을, 심을, 잔인함을, 재앙을, 자유를, 흔적을, 인연을, 상품을, 트라우마를, 꿈을, 그림자를, 가치를, 판을, 감성을, 자를, 원을, 론을, 것들을, 중력을, 즐거움을, 한계를, 스를, 전을, 감을, 이었음을, 시선을, 1을, 관념을, 위치를, 달을, 물을, 흐름을, 인격을, 공간을, 기술을, 대를, 슬픔을, 본질을, 감정을, 진정성을, 인을, 이순신을, 포를, 비극을, 력을, y를, 인들을, 요소를, 기록을, 가능성을, 임을, 여인을, 유산을 </p> <br> ### -를 <p class="message"> 룰, 릉, 물을, 둘을, 디를, 들을, 이것을, 2를, 급을, 즈를, 트를, 신화를, 1을, 왕을, 학을, 이영화를, 용을, 극을, 등을, 작을, 씬을, 접점을, 먼을, 이미지를, 즘을, 세계관을, 스러움을, 류를, 상품을, 전체를, 로를, 론을, 그를, 팀을, 계를, 람을, 나치를, 만을, 영활, 가, 뎀을, 체를, 유산을, 력을, 스를, 건을, 의식을, 편을, 전설을, 터를, 3를, 사를, 곰을, 이를, 바를, 칸을, 진을, 크를, 셋을, 전통을, 신을, 4를, 색을, 감을, 본을, 그녀를, 인을, 형을, 아름다움을, 미래를, 프를, 그림을, 락을, 맨을, 명성을, 대를, 인물을, 퍼를, 범을, 감성을, 훈을, 것들을, 7을, 무언가를, 야를, 장점을, 분을, 그림자를, 자를, 일생을, 대상을, 생애를, 관점을, 라를, 호를, 와, 괴담을, 인들을, 우를, 적을 </p> <br> ### -에 <p class="message"> 에만, 들에, 신에, 그에, 에는, 사상에, 물에, 등에, 업에, 에까지, 씬에, 론에, 쇼에, 화에, 에도, 감에, 관에, 선에, 곡에, 성에, 향에, 춤에, 본에, 작에, 진에, 상에, 도에, 책에, 즈에, 력에, 거기에, 로움에, 함에, 림에, 수에, 사에, 학에, 자에, 것에, 매체에, 빨에, 속에, 열풍에, 님에, 계에, 기술력에, 락에, 3에, 삶에, 면에, 다움에, 2에, 거에, 트에, 움에, 전체에, 힘에, 로에, 경에, 애에, 병에, 시장에, 판에, 4에, 1에, 홀에, 질에, 쪽에, 극에, 편에, 서에, 씨에, 색에, 이론에, 옷에, 스러움에, 글에, 에다, 권에, 팀에, 심에, 에의, 법에, 미에, 증에, 돈에, 뇌에, 꿈에, 가에, 디에, 나에, 엔, 공에, 치에, 값에, 형에, 식에, 자본에, 사물에, 프에 </p> <br> ### -에게 <p class="message"> 들에게, 한테, 그에게, 그들에게, 씨에게, 그녀에게, 님께, 들한테, 에겐, 님에게, 자신에게, 형에게, 둘에게, 들께, 님에, 당신에게, 아들에게, 이에게, 아이들에게, 내게, 나에게, 서로에게, 누군가에게, 한테는, 팬에게, 자식에게, 소년에게, 께, 사람들에게, 소녀에게, 이들에게, 톰에게, 역에, 들에게는, 부모에게, 아내에게, 한텐, 테, 존에게, 신에게, 관객들에게, 세대에게, 딸에게, 남에게, 자에게, 팬들에게, 관객에게, 애한테, 저에게, 가에게, 자들에게, 나한테, 들에겐, 타인에게, 마츠코에게, 남편에게, 분께, 사에게, 존경하는, 한명의, 팀에, 인류에게, 어른들에게, 로부터, 그대에게, 팀에게, 진에게, 삶에, 개인에게, 역의, 아낌없, 너에게, 신께, 상대에게, 말에, 제게, 분들에게, 놈에게, 들에, 네게, 계에, 들로부터, 약사에게, 님께서, 이기에, 세상에, 베푸, 불쌍한, 것에, 수에, 에의, 구하려, 대중들에게, 대중에게, 역을, 대우를, 답고, 연인에게, 그리하여, 잭에게 </p> <br> ### -께 <p class="message"> 들께, 분께, 께는, 께서, 분들에게, 님께, 드린다, 분들, 감사합니다, 시던, 님에게, 말씀, 주신, 들에게, 씨에게, 저희, 존경합니다, 부모님, 드립니다, 감사하고, 분들이, 선생님, 말씀을, 노고에, 묵념, 어머님, 게요, 표합니다, 고맙습니다, 한테, 표함, 진에게, 드려, 고마움을, 감사, 에게, 아버님, 셔서, 애도, 수고하셨습니다, 님들, 진심으로, 들한테, 저에게, 황석희, 힘내세요, 자분, 하셨던, 인사를, 죄송, 않겠습니다, 많으셨습니다, 하셨다, 시고, 께요, 외할머니, 교수님, 님이, 선배, 보셨으면, 어머니, 하신다, 주셔서, 셨다, 시면, 만수무강, 격려, 고마웠어, 하셔서, 보냅니다, 수고했다, 할머니, 교수님이, 님, 신께, 스럽습니다, 표하, 두분이, 존경, 쌤이, 세대에게, 십니까, 할아버지, 수고했어요, 쉬세요, 감사하다, 세요, 셨으면, PAUL, 선생님이, 이들에게, 남깁니다, 주시는, 할아부지, 인사, 신, 여보, 아드님, 고마워, 장군님 </p> <br> ### -한테 <p class="message"> 에게, 들한테, 애한테, 테, 씨에게, 들에게, 님께, 형에게, 님에게, 한테는, 나한테, 쌍으로, 싶냐, 께, 맞자, 오빠가, 꼬셔, 혼나, 들한, 들께, 형한, 개객끼, 둘에게, 한텐, 말좀, 쟤, 쌤, 때리고, 왈, 거보고, 싸라, 명치, 자신에게, 때메, 자식에게, 님에, 아내에게, 혼내, 사줘, 첨에, 불쌍한, 자나깨나, 새끼, 잘듣, 역에, 퍼주, 그녀에게, 불쌍하다, 패고, 맨날, 니뮤, 이거보고, 걔가, 안듣는, 패주고, 착해, 깝치, 살다살다, 남편에게, 죄송해요, 뻑, 아씨, 보러갔다가, 님이, 힝, 놈에게, 겨, 미안해, 서에, 그에게, 불쌍해서, 놈아, 역인, 안듣, 미안해요, 개한, 남친이, 쨩, 핵귀, 다짜고짜, 러냐, 줄라, 볼매, 안늙, 아들에게, 에겐, 너한테, 아놔, 마누라, 그나저나, 으휴, 덕통사고, 빨에, 개객, 건들지마, 약사에게, 교수님이, 다메요, 협박, 남에게 </p> <br> ### -더러 <p class="message"> 역겨, 징그러, 촌스러, 부담스러, 역겹고, 껄끄러, 무서, 부끄러, 괴로, 불쾌하다, 귀여, 안쓰러, 우스꽝스러, 가벼, 지겨, 괴기스러, 아름다, 불편하고, 싱거, 안무서, 징그럽고, 더럽고, 즐거, 안타까, 울, 얄미, 스러, 두려, 웟다, 황당하다, 웟음, 더러워, 불쾌, 역겨워, 힘겨, 우스, 무거, 조심스러, 섬뜩하다, 불쾌하고, 불편, 시끄러, 잔인하고, 매끄러, 웠다, 웠음, 웠어, 반가, 흥겨, 역겹다, 징그럽다, 어두, 울수, 아쉬, 스러울, 징그러운, 혐오, 꺼림, 당혹스러, 애처로, 불쾌했다, 웠기, 소름끼치고, 이장, 나빴다, 놀라, 징그러워, 거북, 솔직해서, 무서웠다, 나빠, 날카로, 토할, 더럽다, 웠을, 우면, 슬플, 울뿐, 부러, 괴상, 웠어요, 불쾌하, 무섭다, 나쁨, 자극적이고, 뜨거, 무섭고, 짜증나고, 사나, 무섭, 오글거릴, 어지러, 체할, 웡, 찝찝하고, 불편하다, 끔찍, 잔망스러, 우면서, 노골적이 </p> <br> ### -로 <p class="message"> 로만, 로도, 로까지, 물로, 쇼로, 들로, 로는, 로라도, 장으로, 으로, 로써, 똥으로, 관으로, 화로, 감각으로, 등으로, 자로, 로의, 상징으로, 성으로, 감으로, 만으로, 씬으로, 차원으로, 선으로, 극으로, 그림으로, 영상으로, 쯤으로, 중심으로, 희극으로, 수준으로, 편으로, 꿈으로, 로든, 개로, 로나, 표로, 론으로, 실력으로, 로부터, 그래픽으로, 시점으로, 기술력으로, 사건으로, 사극으로, 질로, 감성으로, 컷으로, 시로, 활로, 점으로, 악으로, 분으로, 양으로, 판으로, 를, 력으로, 3로, 인으로, 즈로, 로밖에, 디로, 모습으로, 장편으로, 신으로, 살로, 와, 연극으로, 년으로, 빛으로, 형으로, 너로, 아름다움으로, 담으로, 품으로, 권으로, 맨으로, 로가, 애로, 로를, 2로, 색으로, 색다르게, 톤으로, 춤으로, 번으로, 가, 대상으로, 식으로, 돌로, 통하여, 키로, 사진으로, 로서, 삼아, 것으로, 기법으로, 시각으로, 형식으로 </p> <br> ### -으로 <p class="message"> 아름다움으로, 쇼로, 사극으로, 들로, 유쾌함으로, 선으로, 물로, 신으로, 극으로, 감으로, 사건으로, 로, 이로, 함으로, 씬으로, 것으로, 업으로, 등으로, 양으로, 자로, 감각으로, 남으로, 연극으로, 힘으로, 상징으로, 그림으로, 원으로, 방으로, 도구로, 봄으로, 질로, 성으로, 술로, 을, 분으로, 색으로, 희극으로, 으러, 영웅으로, 나로, 장으로, 대상으로, 이라고, 죄로, 품으로, 결핍으로, 관으로, 시각으로, 표로, 삶으로, 거짓으로, 맨으로, 그것으로, 화로, 만으로, 애로, 금으로, 력으로, 줌으로, 다름으로, 꿈으로, 통해, 이면, 너로, 인으로, 쯤으로, 사진으로, 악으로, 과, 감성으로, 실력으로, 형으로, 0으로, 신념으로, 본으로, 판으로, 편으로, 부로, 그로, 으론, 음으로, 론으로, 곡으로, 모습으로, 법으로, 돈으로, 마로, 기쁨으로, 지로, 영상으로, 빛으로, 지옥으로, 시점으로, 움으로, 춤으로, 이라, 똥으로, 수단으로, 욕으로, 3로 </p> <br> ### -의 <p class="message"> 물의, 이미지의, 무협의, 링의, 즈의, 업의, 리플리의, 들의, 무비의, 춤의, 계의, 로써의, 맨의, 션의, 증의, 홀의, 기의, 누아르의, 슨의, 로의, 터의, 함의, 틱의, 카의, 와의, 단의, 스의, 지성의, 로서의, 돌의, 트의, 형의, 력의, 영웅의, 극의, 지의, 이름의, 쇼의, 사의, 글의, 질의, 화의, 관의, 리의, 시의, 눈의, 브의, 감의, 오의, 이전의, 감각의, 맞바꾼, 에의, 스완의, 드의, e의, 씬의, 아의, 시점의, 애의, 인공지능의, 노의, 최동훈의, 전체의, 전설의, 무성영화의, 끝의, 뺨치는, 시대의, 꿈의, X의, 만의, 파커의, 또다른, 0의, 디의, 1의, 락의, 과의, 이자, 케인의, 말의, 님의, 웨인의, 폭스의, 다의, 것의, 무협영화의, 루크의, 세대의, 해리의, 컨의, 산업의, 지닌, 전성기의, 더의, 도의, 등의, 누벨바그의, s의 </p> <br> ### -과 <p class="message"> 과의, 와, 들과, 감과, 아름다움과, 이랑, 과도, 등과, 이미지와, 그리고, 력과, 과는, 등, 신과, 만남, 관과, 화려함과, 및, 함과, 움과, 호연과, 삶과, 씬과, amp, 절묘한, 고뇌와, 등의, 스러움과, 심과, 유쾌함과, 3박자, 본성과, 화와, 삼위일체, 맨과, 끝과, 통한, 그와, 이라던가, 위트와, 애와, 불신과, 군과, 순수함과, 은, 홀과, 힘과, jihyun님과, 동서양의, 꿈과, 등이, 등등, 성과, 선율과, 접점, 시선과, 끝없는, 불일치, 쇼와, 집념과, 영상미와, 림과, 의, 모성과, 음과, 지식과, 인한, 증과, 지성과, 원과, 시공, 일궈낸, 대비되는, 등으로, 빚어낸, 이나, 이성과, 삼박자, 끊임없는, 미칠듯한, 아픔과, 콜라보, 사이의, 기와, 곡과, 신선함과, 스와, 면과, 아와, 미장센과, 또는, 장예모의, 식과, 미와, 에의, 차의, 빛과, 업의, 아슬한, 비롯한 </p> <br> ### -와 <p class="message"> 과, 등과, 라와, 킹과, 와의, 랑, 와는, 그리고, 이미지와, 력과, 들과, 즈와, amp, 관과, 삼위일체, 씬과, 스와, 신과, 만남, 호연과, 등, 라던가, 더와, 왕과, 및, 와도, 형과, 선율과, 먼과, 드와, 등의, 용과, 그와, 감과, 가, 이은, 애와, 영상미와, 크와, 맨과, 아와, 아름다움과, 등등, 절묘한, 엘레, 원과, 에다가, 힘과, 질과, 로와, 본과, 삼박자, 스러움과, 쇼와, 인물들과, 미장센과, 심과, 로의, 지와, 접점, 트와, 둘과, 존과, 의, 시선과, 점과, 세가지, 향연, 모성과, 위트와, 왕, 프와, 마와, 곡과, 미쟝센과, 삶과, 랑은, 유쾌함과, 법과, 면과, 랑도, 뺨치는, 치와, 로부터, 팀과, ㅆㅅㅌㅊ, 화려함과, 를, 비롯한, 홀과, 하모니, 이름의, 물과, 양대, 기법과, 새와, 통한, 스한, 조합, 화와 </p> <br> ### -하고 <p class="message"> 하면서, 하며, 해보고, 받고, 한건가, 시키고, 할수, 안하고, 하다가, 당하고, 하면서도, 하려고, 한적이, 하구, 해하고, 느끼고, 나누고, 한답시고, 피하고, 하겠다, 되고, 하자는, 듣고, 하지말고, 한듯, 하듯, 숨기고, 하거나, 찾고, 했구나, 한뒤, 햇나, 하여, 원하고, 미워하고, 포기하고, 해놓고, 욕하고, 하려다, 했지, 해버리, 이별하고, 하던, 보여주고, 한걸까, 한척, 하네, 한채, 하자, 했건만, 하듯이, 해지고, 할때, 한거지, 하니까, 의심하고, 하도록, 하러, 얻고, 동경하고, 부르고, 했구, 이루고, 하거, 했나, 하다, 일하고, 뛰고, 한적, 올리고, 떨고, 하려는, 하겠, 짓고, 전하고, 하는, 날리고, 묻고, 할려, 해내고, 내고, 했고, 이해하고, 했었, 하길래, 잘하고, 해서, 까고, 덮고, 하겠지, 할라, 했었나, 했었던, 받아들이고, 하라고, 아끼고, 하게, 하겠어, 하라는, 누르고 </p> <br> ### -보다 <p class="message"> 보단, 들보다, 그것보다, 훨씬, 것보다, 훨, 1편보다, 그보다, 못지않게, 만큼이나, 2보다, 훨신, 낫고, 3보다, 이상으로, 거보다, 작보다, 전작보다, 판보다, 이쪽이, 편보다, 전작들보다, 1보다, 물보다, 원보다, 책보다, 천배, 1탄보다, 2보다는, 이전에, 다음으로, 전편보다, 낫다, 3보단, 백배, 전보다, 본편보다, 2보단, 몇배는, 씬보다, 신보다, 보더, 못지, 때보다, 낫더라, 원스보다, 삶보다, 이것보다, 의외로, 일수록, 쪽이, 그보, 나음, 총보다, 일때가, 상대적으로, 웬만한, 0배, 보가, 것보단, 명량보다, 1보단, 개인적으론, 이후로, 오히려, 돈보다, 비하면, 이외에, 개인적으로, 비해, 왠만한, 뺨치는, 쬐끔, 보기전에, 더, 자보다, 비중이, 만큼, 때문인지, 말보다, 낫네, 들보, gt, 이전의, 보디, 유난히, 낫지만, 치보, 누구보다, 이후에, 바닐라스카이, 전편보단, 무엇보다, 갠적으로, 다웠던, 이상의, 이보다, 다워, 알고보니, 한층 </p> <br> ### -처럼 <p class="message"> 들처럼, 같은, 같았던, 같던, 것처럼, 같이, 같게, 같고, 만큼이나, 같았고, 같았다, 마치, 마냥, 같달까, 다르게, 인것처럼, 제목처럼, 물처럼, 쯤으로, 같구나, 속, 인양, 지듯, 같지, 같다, 답게, 비슷하게, 보듯, 같으면서, 같았, 같아, 창문으로, lt, 같았음, 비처럼, 불꽃처럼, 내음, 총천연색, 겉은, 삶처럼, 같네, 같을까, 달리, 과도, 하듯, 만큼, 꿈처럼, 기계처럼, 같지만, 시베리아, 똑같이, 야생의, 책처럼, 황야의, 같음, 같군, 같진, 들판, 파도처럼, 같을, 그림처럼, 반대로, 같기도, 마찬가지로, 위에서, 느리게, 하듯이, 같으면서도, 랬더니, 곁으로, 같으, 낙엽, 노킹, 인냥, 같구, 봄날의, 톤으로, 무심히, 조차도, 못지않게, 사진처럼, 듯이, 속에서, 섬에서, 그렇게, 개처럼, 판, 공원에서, 마저도, 같으면, 얼핏, 같, 슬프게, 안타깝게, 속으로, 쇼와, 철로, 같냐, 같단, 무취의 </p> <br> ### -만큼 <p class="message"> 만큼이나, 그만큼, 한만큼, 못지않게, 정도로, 만은, 1만큼, 이상으로, 충분히, 엄청나게, 정도, 누구보다, 못지, 크기는, 마저도, 때보다, 들만큼, 마져도, 대단히, 만치, 그보다, 조차도, 만한, 뿐, 위력, 꽤나, 보단, 훨씬, 그이상, 처럼, 이만큼, 보다, 지언정, 짙고, 제법, 만으론, 스케일, 만으로도, 가장, 해전은, 같구, 큰만큼, 커졌지만, 이상의, 큼, 확실히, 엄청, 짧지만, 짧고, 강렬하고, 할만큼, 이것보다, 클수록, 급으로, 무섭도록, 놀랍도록, 다음으로, 위용, 해전씬은, 결코, 단순하지만, 무게는, 뿐이다, 전작들보다, 꽤, 발끝, 작지만, 변함없이, 매우, 마찬가지로, 영향력, 어마어마하게, 수준, 완성도는, 정말, 없을만큼, 조차, 또한, 여러모로, 만하지만, 비례, 1편보다, 강렬함, 상당히, 압도적으로, 무척이나, 크지만, 굉장히, 세련되고, 등은, 여전히, 화려하고, 규모, 하난, 컨데, 이보다, 무척, 전작보다, 여전한, 로도 </p> <br> ### -같이 <p class="message"> 함께, 손잡고, 다같이, 똑같이, 단둘이, 처럼, 비슷하게, 울면서, 밥먹고, 옆에서, 먹으며, 같은, 몰래, 밤새, 집에서, 썸남, 거실에서, 떨며, 마찬가지로, 옹기, 술마시, 같게, 먹으면서, 연달아, 술한, 울고, 공원에서, 부모님이, 모여서, 같구나, 마시며, 애인이, 지하철에서, 술마시고, 울며, 다르게, 같을까, 나란히, 같아서, 붙잡고, 끼리, 셋이, 동생이, 친구, 같았음, 번갈아, 웃으며, 사촌동생, 덩달아, 동시대에, 칭구, 들처럼, 춤추고, 꺅꺅, 멋모르고, 옆, 둘이, 미친듯이, 배구공, 추며, 전학, 연인들이, 들끼리, 맞으며, 같았다, 같아, 신나게, 밤마다, 달리, 같고, 애랑, 웃으면서, 밑에서, 웃고, 해맑게, 친해, 단체로, 친척, 마냥, 내친구, 둘씩, 닮아, 비슷하다, 탁구, 설거지, 조용히, 불끄고, 일행, 남친이, 동생, 모시고, 누워서, 춤을, 밤에, 추석에, 야자, 누워, 빙수, 놀고, 술먹고 </p> <br> ### -아 <p class="message"> 하, 아아, 으아, 아아아, 씨발, 아오, 하아, 아악, 으, ㅅㅂ, 시벌, 앜, 아ㅏㅏ, 어휴, 아아아아, 아ㅋㅋ, 아놔, 아ㅠㅠ, ㅆ, Aㅏ, 젠장, 아아아아아아, 시팔, 아씨, 개좋, 아아아아아아아, 씨바, ㅠㅠ, 와씨, 앜ㅋㅋㅋㅋ, 앙, 오, 으악, 썅, 아아아아아, ㅏㅏ, ㅡㅡ, ㅜㅜ, 어우, 와아, ㅠㅜ, ㅜㅠ, ㅁㅊ, 으앙, ㅏ, ㅆㅂ, 그니, ㅡ, 응, ㅠ, 아유, 어어, 우어, 흑흑, ㅜ, 니미, 우와, 오오, 으어, 내사랑, 제길, 오오오오, ㅏㅏㅏ, 으으, 으윽, 에휴, 헐, 아인, 히익, ㅂㄷㅂㄷ, ㅎㅇ, 오우, ㅅ, ㅁ, 흐엉, 하하하하하하, 글고, 시발, 하하, 흐, ㅇㅁ, 엉, 은데, 샤이, 에잇, 이거, 핳, ㄴ, 윽, 어후, ㄹㄹ, 워후, 얜, 잘잤다, 뭐야, 왜그랬어, ㅋ아, 와아아, 근데, 8ㅅ8 </p> <br> ### -야 <p class="message"> 야만, 야지, 야돼, 야됨, 줘야, 져야, 야했다, 내야, 야되, 여야, 나야, 야ㅠㅠ, 야해, 가야, 야죠, 야된다, 와야, 야하, 야함, 어야, 여야만, 얘들아, 야했, 야한, 줄께, 야할, 욧, 라, 야겠, 야라는, 서야, 둬야, 드려야, 졌어, 줬으면, 냈어야, 이래야, 줬음, 버렸을까, 봐야, 야징, 봤어야, 야될, 야라, 얌, 얍, 해야, 야ㅋㅋ, 왔어, 에요, 되야, 봤자, 랏, 돼야, 년아, 였어, 예요, 에여, 줘라, 니가, 라도, 얔ㅋㅋㅋ, 야했던, 워야, 줬더니, 라구, 남으려면, 야겠다, 줬어, 주었으면, 너넨, 임마, 다오, 배워야, 줍시다, 야하지, 그래, 줄거야, 라며, 졌으면, 그러니까, 넌, 란거, 야하고, 줘요, 타야, 줘, 이겨내야, 니네, 지려, 보아야, 란다, 제맛, 욤, 주세요, 쳐야, 다녀야, 작작, 들아, 너 </p> <br> ### -만 <p class="message"> 들만, 만을, 력만, 로만, 만이, 씩만, 만이라도, 신만, 만은, 씬만, 만하고, 힘만, 거만, 분만, 색만, 화만, 만도, 멋만, 만해, 부만, 맛만, 에만, 증만, 만요, 욕만, 둘만, 진만, 전만, 점만, 함만, 말고, 옷만, 최소한, 것만, 2까지만, 끝만, 마져, 잘라서, 어땟을까, 감만, 주구장창, 거라곤, 판만, 딱, 평만, 마저, 질만, 도만, 면만, 반만, 일만, 엑기스만, 애만, 쫌만, 편만, 이라도, 곡만, 놈만, 춤만, 만해서, 성만, 나머진, 쯤으로, 도, 말만, 겉만, 딴거, 만했, 짓만, 관만, 그뿐, 값을, 승부, 뿐, 나머지는, 만으로, 어땠을까, 만함, 뼈만, 을걸, 큼만, 값으로, 봐줄만, 몸만, 줄창, 만큼, 단지, 하지말고, 짜린데, 그저, 만하, 쯤, 대로, 만보, 마저도, 조차도, 그냥, 만하지만, 재롱잔치, 볼건 </p> <br> ### -도 <p class="message"> 들도, 조차도, 심지어, 조차, 물도, 또한, 력도, 관도, 춤도, 까지, 뭐도, 마저도, 마저, 원도, 좋고, 만은, 씬도, 멋도, 마져도, 자도, 도도, 무엇보다, 은, 함도, 맛도, 감도, 색도, 꿈도, 등은, 그렇고, 디도, 에도, 쩔고, 톤도, 는, 성도, 욕도, 작도, 그렇다고, 딸도, 뭣도, 것도, 로도, 합도, 까진, 집도, 있고, 한것도, 선도, 음도, 물은, 나쁘지도, 셋다, 무엇하나, 트도, 옷도, 만하고, 일도, 책도, 들은, 씨도, 탄탄하고, 지도, 안무서움, 힘도, 만, 결도, 님도, 가, 이것도, 리도, 미도, 스럽지도, 뭣보다, 움도, 뿐더러, 뿐아니라, 누구도, 물론, 들까지, 마도, 암튼, 야하지, 신도, 따윈, 마져, 엿는데, 총도, 더군다나, 잇고, 게다가, 잘하고, 원은, 좋았고, 얘도, 없고, 암것도, 개굿, 랄데가, 싶고 </p> <br> ### -은 <p class="message"> 만은, 신은, 이, 그림체는, 함은, 화는, 들은, 과는, 과, 물은, 끝은, 이라면, 스러움은, 씬은, 캐미는, 해전씬은, 판은, 만남은, 성은, 으론, 크기는, 컷은, 님은, 톰형은, 등은, 1은, 도, 감은, 을, 이니까, 감각은, 음은, 전투씬은, 시퀀스는, 기술은, 왕은, 훈은, 본은, 이나, 해전은, 움은, 류는, 조합은, 힘은, 결과는, 앞엔, 꿈은, 관은, 실력은, 증은, 모습은, 력은, 내용은, 질은, 마모루는, 쇼는, 이든, 이야말로, 2편은, 에선, 이영화는, 신선함은, 선은, 까진, 이란, 색은, 조차도, 길은, 맨은, 극은, 추격씬은, 전은, 원은, 본질은, 면은, 만으론, 합은, 랩은, 방법은, 이라기엔, 편은, 큼은, 재능은, 씬들은, 본인은, 하울은, 과의, 팬은, 그는, 트릭은, 폴은, 첼은, 형은, 춤은, 용은, 영광은, 2는, 이죠, 이라지만, 락은 </p> <br> ### -는 <p class="message"> 는건, 가, 고는, 관은, 로는, 는게, 물은, 력은, 조합은, 합은, 스는, 라는, 2보다는, 빈은, 실력은, 는거, 완은, 2는, 파커는, 도, 이영화는, 강철중은, 옹은, 만은, 4편은, 자체는, 3는, 왕은, 톰형은, 2편은, 2탄은, 극은, 들은, 였단, 카는, 내용은, 젠버그는, 등은, 란, 와는, 이것은, 신은, 를, 정체성은, 란건, 스러움은, 립은, 감은, 포는, 와, 개인적으론, 아담스는, 무어는, 이민기는, 아직까진, 전투장면은, 이정현은, 점은, 로서는, 완성도는, 는걸, 난, 스나이더는, 성은, 씨는, 론, 1보단, 님은, 역은, 상팔자, 형은, 2보단, 그는, 틱은, 즈는, 4는, 감각은, 1은, 이땐, 이번에는, 로서, 뎁은, 장점은, 까진, PS, 언은, 그렇지만, 력만큼은, 캐미는, 이론은, 랑은, 함은, 급은, 맨은, 주온은, 아들은, 껀, 원은, 총격씬은, 이번엔 </p> <br> ### -조차 <p class="message"> 조차도, 마저도, 마저, 따위는, 따윈, 도, 마져, 밖에, 아무것도, 누구도, 무엇하나, 것조차, 미처, 밖엔, 아무도, 좀처럼, 쉬이, 1초도, 따위, 들조차, 한치, 만으로는, 전혀, 외에는, 외엔, 수조차, 1도, 도무지, 쉽사리, 마져도, 앞도, 때문인지, 없인, 만은, 로밖에, 더이상, 한순간도, 도저히, 차마, 끝끝내, 틈도, 만으론, 치도, 아무, 로도, 런, 결코, 심지어, 또한, 말곤, 력으로도, 더는, 만큼이나, 눈꼽만큼도, 애당초, 망정, 절대, 차도, 것밖에, 주체, 함부로, 그마저, 에도, 도통, 이외에, 그저, 만도, 그마저도, 일말의, 역설을, 말도, 만큼, 곤, 래야, 답도, 들을, 도리어, 커녕, 아예, 또는, 없을만큼, 지도, 애초에, 별다른, 만이, 어떠한, 않으면, 만하고, 혹은, 거라곤, 틈은, 언정, 일부러, 라곤, 일도, 특별함을, 채, 그다지, 틈을, 딱히 </p> <br> ### -마저 <p class="message"> 마저도, 마져, 조차도, 조차, 마져도, 들조차, 또한, 감마저, 무엇하나, 도, 까지, 만큼이나, 감까지, 심지어, 들까지, 모조리, 따윈, 전체가, 도리어, 그마저, 따위는, 미칠듯한, 삼위일체, 만은, 들도, 만을, 게다가, 만이, 과, 함까지, 진부함을, 등이, 그마저도, 모두, 함마, 들을, 3박자, 만, 모든, 력까지, 한없이, 숨막힐듯, 화려함과, 경박한, 오히려, 들마, 나까지, 자칫하면, 관객을, 지나친, 퀸의, 풍덩, 늪, 장예모의, 그리고, 비장함이, 정도로, 질만큼, 뿐만, 싹다, 함도, 과도한, 3박자가, 강박, 등은, 을, 시종일관, 만으로는, 들만, 자칫, 영혼을, 자체가, 따위, 스며드는, 버리는, 기운, 부재가, 싹, 지거나, 대신, 만큼, 덩이, 싸그리, 관객들을, 금세, 것조차, 찬물을, 덮어, 것마저, 점차, 이를, 빈틈을, 끝끝내, 넋을, 순식간에, 전락, 젖은, 때문인지, 뭐하나, 력도 </p> <br> ### -까지 <p class="message"> 부터, 심지어, 3박자가, 마저도, 도, 쯤부터, 마저, 직전, 크레딧까지, 들까지, 무엇하나, 까진, 껏, 삼박자, 삼박자가, 력까지, 씬까지, 거기다, 3박자, 게다가, 에까지, 마져, 쯤에, 조차도, 함까지, 크레딧, 거기에, 7편, 했으며, 에다, 전까지, 쯤의, 으로, 만으로, 부로, 3편까지, 에도, 등은, 크래딧, 고루, 부턴, 들부터, 장엄, 백점, 직전에, 쌔끈한, 끌다가, 마져도, 덤으로, 초장, 편까지, 꿀재미, 갖춰, 골고루, 2014년, 깔끔하다, 좋고, 4까지, 만하면, 쯤엔, 결도, 미칠듯한, 한씬, 위트, 덧, 것까지, 완벽, 갈때까지, 더해져, 시퀀스가, 훌륭하고, 클라이막스, 깔끔한, 데다, 쯤이, 삼위일체, 또한, 열까지, 을, 이르, 등등, 3단, 숙모, 종반, 요근래, 이후, 엔딩, 탄력을, 올해, 쌍팔년도, 쌓아온, 모의고사, 등, 1분, 장진감독의, 그리고, 때까지, 오프닝, 모두, 곡으로 </p> <br> ### -부터 <p class="message"> 쯤부터, 부턴, 하자마자, 때부터, 처음, 까지, 시작, 씬부터, 시작해서, 끝까지, 열까지, 애초, 쯤엔, 초장, 5분만에, 첫장면부터, 첨부터, 끝날때까지, 마자, 이후부터, 급격히, 에야, 부에서, 끝만, 벌써, 중반부터, 쭈욱, 도입부, 쭉, 이미, 나올때, 로부터, 이영화의, 넉다운, 터, 부, 후부터, 이후로, 갑자기, 어디서, 이어지는, 중간, 줄곧, 뭐야, 왜이래, 끝의, 부에, 심상치, 이때부터, 그뒤로, 끝인가, 즈음, 어느순간, 일관, 채고, 하더니, 볼줄이야, 첨으로, 흥미로웠는데, 끝냈어야, 결핍으로, Come, 슬슬, 만봐도, 들부터, 했더니, 글러, 오프닝, Color, 끝가지, 나래이션, 보자마자, 가면서, 꺼는, 쯤에, 온통, 중반이후, 만보, 크레딧까지, 에서, 나오면서, 헐, 조차도, 분만에, 멈췄어야, 첫, 출발, 끝났어야, 헉, 인해, 수미쌍관, 끝과, 나왔을때, 마저도, 시놉, 첨, 기승, 끌다가, 언제, 인트로 </p> <br> ### -이나 <p class="message"> 이든, 예나, 이랑, 이라던가, 이라도, 이니, 및, 등은, 나, 이지만, 이라지만, 과, 서편제, 이었고, 이였지만, 이었는데, 은, 업의, 이라면, 등, 등의, 이었나, 이고, 이면, 이었다면, 등등, 이랄까, 이야, 이였다면, 이여서, 투박한, 이었다, 셋트, 상의, 이더라, 이네, 이었으나, 아무래도, 이였, 볼법한, 연스러운, 2나, 이라, 이니까, 지났지만, 이었겠지, 이며, 이, 이다, 이려, 이였는데, 라던가, 촌스러운, 라던지, 이었지만, 인데, 여전하지만, 이였다, 이였고, 이겠지만, 딥임팩트, 용가리, 등을, 벤허, 날것의, 위주의, 제나, 이죠, 암만, 에다가, 이구나, 으려나, 마, 군과, 방의, 이였던, 주객전도, 씨티, 부족했지만, 과의, 이었음, 이냐, 그보, 이당, 씩이나, 그렇고, 방불, 유치했지만, 이해하는데, 원과, 을, 오락실에서, 이던, 기식, 특수, 로나, 애서, 학과, 마와, 화와 </p> <br> ### -나마 <p class="message"> 잠시, 간접적으로, 하여금, 간접, 대리, 떠올리며, 간접체험, 인해, 되었고, 해주었다, 설렘과, 해줬다, 함마, 아델을, 됐습니다, 느낍니다, 엿볼, 해준, 만끽, 유년시절, 간접경험, 공기를, 병을, 억울함을, 냄으로써, 저의, 환멸을, 셔서, 됨으로써, 써, 나또한, 그동안, 읍니다, 기쁨을, 떨림을, 편히, 즐거움을, 보며, 위안을, 주었다, 바라보며, 해줘서, 아픔과, 대리만족, 열망을, 계기가, 내모습을, 경험, 있었고, 되었습니다, 해준다, 아쉬움을, 현장을, 해줌, 쉬세요, 갈증을, 줘서, 생전, 루의, 통해, 애환을, 고통을, 맘껏, 해놔서, 그녀들이, 나설, 천국에서, 잊혀졌던, 터라, 참혹함을, 살았던, 한줌의, 룸을, 심정을, 생활을, 것만으로도, 빌어, 마가렛, 샐러, 잊었던, 불편함을, 겪었던, 됐다, 어린시절, 찼던, 유년, 있도록, 체험, 로그, 되었다, 월터, 경을, 리마, 당혹, 실의, 시켜준다, 평온, 다녀왔다, 아픔을, 차츰 </p> <br> ### -라도 <p class="message"> 든지, 만이라도, 든, 이라도, 로라도, 라면, 여도, 니까, 됐잖아, 야, 최소한, 겠니, 야지, 였더라, 뭐해, 라, 나, 그나마, 좋으니, 만요, 됬지, 뭐든, 것좀, 래도, 라며, 망정이지, 되거, 없든, 뭐, 었더라도, 으련만, 란말, 려면, 였으면, 냐만은, 였으니, 라지만, 던가, 어도, 야죠, 든요, 냐, 라구요, 든간에, 쯤은, 봐준다, 됐지, 망정, 려나, 되든, 란다, 하든, 씩만, 여야만, 더라도, 란게, 거면, 어때, 패, 거든, 란걸, 했어도, 언정, 겨우, 거라면, 겠습니, 쯤, 셋을, 라해도, 랴, 죠, 겠는가, 제발, 생겨도, 번이라도, 쯤이, 없으면, 라능, 랍니다, 룰, 겠지, 란거, 라구, 일단, 랬다, 든가, 지든, 꼭, 었을텐데, 깎음, 니깐, 없어도, 랬는데, 둬, 래요, 라서, 그만, 명만, 없으니, 잔을 </p> <br> ### -이야 <p class="message"> 이네, 이잖아, 이군, 이었어, 이죠, 이다, 이구나, 이었다, 이였어, 이었는데, 이겠지, 이였다, 이여, 일세, 이니, 이예요, 이당, 이더라, 이냐, 이요, 이었구나, 인영화, 이니까, 이었음, 이구, 이었, 이였는데, 이네요, 이라, 이였음, 이였, 이라지만, 이었고, 이지, 이였지만, 이여서, 이었습니다, 이었지만, 이아, 시벌, 이라면, 이엿다, 이고, 이지만, 쓰레, 인데, 와씨, 이오, 임, 뭐람, 임ㅋ, 이였고, 이라고, 헐, 어휴, 이래, 일줄이야, 뭐래, 아냐, 인가보다, 긴데, 이겠, ㅋ아, 이었을까, 참나, 이었으나, 인마, 입니다, 이란, 히익, 어머, 이었던, 이었나, 이었기에, 이었겠지, 입니까, 이든, Aㅏ, 이건, 인거, 모야, 이긴한데, 응, 으악, 도아, 이거, 씨발, 앜, 아ㅏㅏ, 이었다면, 인걸, 개잼, 뭐야, 이겠지만, 밑장빼기, 하하하하하하, 어쩌라고, 콩가루, 이였던, 웡 </p> <br>  ## 품사별 빈도 순위 [김홍규&강범모(2000)](http://www.kyobobook.co.kr/product/detailViewKor.laf?barcode=9788971550519)가 밝힌 한국어 품사별 단어 사용 빈도 순위표는 아래와 같습니다. 이후 이 표에 등장한 단어벡터와 코사인 유사도 기준 가장 비슷한 단어 100개 리스트를 나열할 예정입니다.  | 순위 | 일반명사 | 동사 | 형용사 | 부사 | 감탄사 | | :--: | :--: | :--: | :--: | :--: | :--: | | 1  | 사람 | 하다 | 없다 | 더  | 참  | | 2  | 때  | 있다 | 그렇다 | 다시 | 그래 | | 3  | 일  | 되다 | 같다 | 안  | 아  | | 4  | 말  | 보다 | 어떻다 | 잘  | 뭐  | | 5  | 사회 | 대하다 | 이렇다 | 가장 | 자  | | 6  | 속  | 위하다 | 다르다 | 함께 | 아니 | | 7  | 문제 | 말하다 | 크다 | 바로 | 예  | | 8  | 문화 | 가다 | 많다 | 모두 | 응  | | 9  | 집  | 받다 | 좋다 | 없이 | 글쎄 | | 10 | 경우 | 보이다 | 이러하다 | 다  | 아아 | <br>  ## 실험결과3 (명사) ### 사람 <p class="message"> 한사람, 이들, 사람이, 당신, 사람들은, 사람들의, 주변사람들, 여인, 그사람, 남들, 이과생, 사람들이, 일반인, 여자, 누군가를, 남자, 자들, 자식, 군중, 이웃들, 반려동물, 이들은, 년놈, 동물, 이방인, 노인, 유인원, 딸들, 사람들에게, 생물, 너희들, 세상, 주인공, 서민들, 주위, 상대를, 놈들, 주민들, 애완견, 학생, 인간, 나밖에, 이의, 자들은, 놈도, 사내, 인조인간, 인들, 관객, 누군, 그들, 타인, 이웃, 꾼들, 분들, 연인, 지인들, 주변인들, 손님, 저들, 유괴범, 군인, 영혼, 위인, 이들이, 백성들, 어른들, 개개인, 초식동물, 주인, 이들을, 가들, 부모, 남편, 내것, 맹수, 애인, 민간인, 남정네, 당사자, 아랍인, 외국인, 이에게, 이웃사람, 육식동물, 환경, 이들의, 타인을, 자를, 시민, 그네들, 이들에게, 선생, 지휘관, 자들을, 반려견, 시청자들, 적군, 상대방을, 우리 </p> <br> ### 때 <p class="message"> 떄, 때는, 때의, 땐, 때에, 때야, 때쯤, 때부터, 때에는, 무렵, 을때, 때나, 때면, 때에도, 때마다, 때엔, 때와, 때만, 때인가, 땐가, 때라, 때다, 때처럼, 했을때, 때가, 때였, 할때, 때까지, 때보다, 때도, 테니, 적에, 뿐인데, 때랑, 즈음, 을땐, 을때의, 갈때, 줄이야, 그때, 껄, 수록, 3학년, 비로소, 까봐, 텐데, 적엔, 2학년, 고등학교때, 초등학교, 교실에서, 일때, 적부터, 지라도, 테니까, 까나, 테지, 때를, 올때, 질때, 시절, 줄때, 뻔, 나올때, 초딩때, 왔을때, 뿐이다, 낼때, 중3때, 중학교, 까, 학교에서, 났을때, 나왔을때, 그날, 꺼에요, 릴때, 언젠가, 칠때, 지언정, 을때는, 방에서, 단체로, 실에서, 장에서, 연등, 중학교때, 고딩때, 어릴때, 시기에, 꺼다, 뿐, 문뜩, 대에서, 어릴, 고등학교, 만났을때, 직전에, 졌을때, 나갈때 </p> <br> ### 일 <p class="message"> 였을, 아닐, 일수도, 이었을, 일수, 인, 거일, 일지도, 일것이다, 일것, 일일, 것일, 물일, 뿐일, 같을, 일거, 자일, 이였을, 일뿐, 싫을, 인것, 울, 다울, 기일, 인거, 꿈일, 일듯, 될, 어쩌면, 낳을, 인걸까, 인것을, 였던, 일꺼, 적일, 살, 있을, 인듯, 부끄러울, 기쁠, 비단, 없을, 것인, 나일, 일텐데, 만할, 라할, 었을, 일인, 겪을, 웠을, 일런, 슬플, 2, 일것이, 임, 틀릴, 였으니, 일로, 칭할, 악일, 가일, 생길, 떠오를, 워할, 월, 속일, 행할, 취할, 일만, 임을, 택할, 쉬울, 들일, 원할, 인가보다, 스러울, 믿을, 로울, 였기, 일줄, 일이, 닥칠, 영원할, 삼을, 인건가, 중일, 이겠지, 일임을, 무거울, 이겠, 그에겐, 편할, 뿐일까, 뿐인, 또는, 이었던, 년인, 1일, 뿐임 </p> <br> ### 말 <p class="message"> 말은, 말을, 말이, 한마디, 마디, 말만, 말과, 이말, 그말, 몇마디, 말한, 말인, 얘기, 말도, 말씀, 말밖에, 말들, 제안을, 말입니다, 말야, 소릴, 충고, 좆, 말에, 너나, 수식어가, 대사, 말로, 얘길, 한마디에, 안듣, 한마디가, 외친, 요라, 말들이, 말인지, 얌마, 말보다, 외침, 말처럼, 문자, 개소리, 곰을, 소리, 딴따, 덜도, 짓, 단어가, 평, 아부, 웃프다, 단어, 도완득, 뜻, 말좀, 대답, 염병, 발음, 내뱉는, 말씀을, 두말, 대답을, 사과, 말안, 영어, 안듣는, 문장, 외침이, 말고, 건들지마, 말의, 잘듣, 말하는, 요약, 글자, 참견, 수식, 일을, 설명, 말란, 밖엔, 수식어, 조언, 뭐라, 뜻인, 외치는, 내뱉, 말해주는, 년아, 고백, 인사, 이름, 한마디로, 까불, 슈발, 히셔, 명언, 외칠, 평에, 할일 </p> <br> ### 사회 <p class="message"> 자본주의, 사회의, 계급사회, 제도, 체제, 사회에서, 세태, 체계, 전체주의, 독재, 병폐, 빈부격차, 유주의, 경제, 인종문제, 시스템, 현대사회의, 현시대, 계급, 정치, 윤리, 비판, 부조리한, 공동체, 의료보험, 부조리, 계층, 부패, 관료주의, 미디어, 이데올로기, 약자, 인본주의, 가부장제, 국가, 매스미디어, 다문화, 실태, 현대, 환경, 공리주의, 물질만능주의, 법치, 고령화, 기득권, 인종차별, 식민, 규제, 만연한, 관료, 의료민영화, 부정부패, 물질주의, 집단, 민주주의, 부패와, 현대인들의, 공권력, 가부장적, 질서, 생태, 문명, 시대, 소수자, 중산층의, 종교, 풍자, 외모지상주의, 고발, 내부고발자, 이념, 불합리, 군국주의, 비정규직, 시스템의, 사법, 외교, 외부, 이기주의, 불합리한, 의료, 정부, 생태계, 성차별, 좌파, 현, 획일화, 불평등, 획일, 획일화된, 억압, 민족주의, 상류, 공산주의, 민국의, 소수, 행정, 정치적, 매카시즘, 법률 </p> <br> ### 속 <p class="message"> 속의, 속에, 속에서, 안의, 속엔, 속으로, 안에서, 그림같은, 갇힌, 갖힌, 속을, 밖, 내의, 총천연색, 위의, 비친, 밖의, 감춰진, 이미지와, 진주같은, 안에, 머릿속, 인물들과, 흩뿌려진, 사막의, 펼쳐지는, 둘러싼, 휘말린, 가운데, 공허한, 안과, 너머의, 처럼, 파노라마, 대비되는, 위에서, 곳의, 위에, 눈속, 떠다니는, 오필리아의, 한가운데, 틈에, 꿈속의, 만큼이나, 한공주의, 머릿속에, 담긴, 놓인, 밑에, 그속, 잿빛, 트래비스의, 박힌, 너머로, 져진, 같았던, 묶인, 에서, 심연의, 스며든, 그려지는, 유영하는, 빛, 프레임, 궁전, 섥힌, 덮힌, 이민자의, 소용돌이, 그림자, 회색빛, 사이의, 꿈의, 스코틀랜드의, 이면에, 파묻, 별들의, 녹아있는, 한켠에, 관통하는, 관과, 설원의, 사이에서, 잔혹한, 가득찬, 네모난, 공간, 숨겨진, 갖혀, 투영된, 표류하는, 사이에, 깊숙히, 갇혀, 시리도록, 근현대사의, 장의, 숨어있는, 텅빈 </p> <br> ### 문제 <p class="message"> 이슈, 오류, 제도, 증거, 논의, 원인이, 차이, 병폐, 한계, 윤리, 원인, 인종차별, 고질, 인종문제, 젠더, 화두, 소수자, 사회, 심각한, 딜레마, 빈부격차, 성차별, 견해, 폐해, 관계, 민영화, 체계, 모순이, 결함, 근거, 외모지상주의, 도덕적, 부르주아, 상관관계, 정답, 결함이, 성범죄, 민감한, 성소수자, 공동체, 세태, 의견, 알레고리, 화제, 난제, 이데올로기, 논리, 피해자, 불통, 포비아, 통계, 사회문제를, 이민자, 복지, 기호, 법적, 승패, 인과, 오류가, 인본주의, 인과관계, 구조, 단점, 차별, 대안, 공통분모, 공리주의, 모럴, 외교, 논란이, 도덕성, 불감증, 학적으로, 중요한, 근시, 처벌이, 경우, 약점, 합리, 모순, 태생적, 진로, 갈등, 내부고발자, 오답, 관료주의, 변수, 격차, 다문화, 인권, 미혼모, 가해자, 실태, 경제, 예시, 아동학대, 컴플렉스, 논란, 계급, 사정이 </p> <br> ### 문화 <p class="message"> 이슬람, 다문화, 군국주의, 민족주의, 언어, 지역, 전통, 식민지, 정서, 국가, 식민, 중국, 컨텐츠, 사회, 인들의, 현대, 콘텐츠, 사상의, 인본주의, 아시아, 경제, 실태, 컬쳐, 산업, 기독교, 종교, 관료주의, 프랑스, 인종, 빈부격차, 회관, 제도, 무속, 인종문제, 정서의, 계급, 미디어, 개신교, 업계, 인종차별, 의료보험, 비주류, 서구, 제3세계, 계층, 민족, 세태, 의료, 신세대, 전체주의, 서양, 유럽의, 인도, 카톨릭, 계급사회, 미국, 부르주아, 서양의, 복지, 생태, 한민족, 좌파, 정서와, 유럽, 이국, 1940년대, 물질주의, 제국주의, 매체, 러시아, 문학, 터키, 근현대사, 인들이, 다양성이, 현주소, 아르헨티나, 스페인, 민주화, 오리엔탈리즘, 중동, 사상과, 화폐, 교육, 탄압, 사회의, 유희, 이데올로기, 남미, 노예제도, 공산, 일본, 통치, 일제, 그시대, 파시스트, 전라도, 민주주의, 누벨바그, 동양 </p> <br> ### 집 <p class="message"> 아파트, 집에, 수족관, 마트, 집의, 집과, 집을, 집은, 동네, 창고, 식당, 침대, 냉장고, 횟집, 집이, 근처, 옆, 호텔, 신발, 부엌, 술집, 2층, 골방, 장롱, 집도, 정원, 옷장, 텐트, 방, 가방, 밭, 회사, 집으로, 사무실, 집에서, 백화점, 오두막, 약국, 거실, 산속, 맥도날드, 모텔, 감옥, 서점, 박스, 거실에서, 교실, 옆집, 잔디, 어항, 수조, 창, 근처에, 식탁, 집안, 경비, 집들, 창문, 박물관, 앞, 농장, 네모난, 사장인데, 숲, 지하실, 아쿠아리움, 빙수, 공장, 밭에서, 문방구, 초밥, 옆의, 떡볶이, 주차, 현관, 허름한, 호박, 도깨비, 산골, 고향, 광산, 이집, 밥, 과자, 방안에, 스위스, 도넛, 주방, 지하철, 버스, 주머니, 쇼윈도, 뒤주, 주인, 휴대폰, 세탁기, 방에서, 트렁크, 새우, 섬 </p> <br> ### 경우 <p class="message"> 사례, 부류, 이유가, 요인, 부분이, 경향이, 결함이, 부작용, 점들이, 지점, 부분, 일보다, 점도, 데에는, 데는, 예가, 점이, 많기에, 대다수, 것인데, 일은, 문제, 도움이, 일도, 변수, 사람들이, 나라에서, 것입니다, 확률이, 것도, 법, 점들, 승패, 겁니다, 거일, 팬덤, 점은, 컨텐츠, 법인, 일들이, 대표적인, 것까지, 논란이, 포인트, 분야, 예시, 것일, 대부분, 해외, 쪽에서, 요소들이, 경향, 거고, 단점, 패착, 인기, 가능성이, 이유, 데엔, 맥락, 사회적으로, 듯하다, 평도, 어려움, 체인, 계층, 장점, 여럿, 기업이, 오류가, 박한, 이슈, 많습니다, 것은, 많다, 듯함, 7급공무원, 요소가, 확률은, 결점, 단점이, 간혹, 장애, 평들, 장벽이, 의견, 법이, 거다, 텍스트, 영향, 것부터가, 것이, 것들이, 걸수도, 듯싶다, 약점, 뉘앙스, 글들, 커뮤니티, 결과 </p> <br>  ## 실험결과4 (동사) ### 하다 <p class="message"> 하네요, 하더라, 했다, 하구나, 하네, 하당, 햇다, 하구만, 함, 했음, 하군, 해진다, 하달까, 허다, 해졌다, 하였다, 하죠, 한듯, 한데, 그지없다, 할듯, 했습니다, 해짐, 했겠지, 하단, 할뿐, 했달까, 했었다, 했겠다, 하잖아, 했으며, 해보이는, 하겠지, 했고, 함ㅋㅋ, 함까지, 해지기도, 했더라, 해ㅠ, 했구나, 합니다, 하면서도, 함ㅋ, 해지는, 하겠다, 했네요, 해용, 하긴, 했어요, 했지, 해진, 히다, 했구, 하니, 함ㅋㅋㅋ, 했군, 해, 아찔하다, 하구, 하고, 했네, 하게, 한, 적나라하다, 함을, 했당, 치밀하다, 애매하다, 할수, 하니까, 했어, 했지만, 답답하다, 해지니, 하겠지만, 화려하다, 하다가, 함의, 졸립다, 치열하다, 해지, 심심하다, 하더니, 햇어, 할까, 우울하다, 해질, 한영화, 처절하다, 어색하다, 햇고, 잔인하다, 하였으나, 했으, 하심, 했으나, 하더, 햇지만, 항, 거칠다 </p> <br> ### 있다 <p class="message"> 있었다, 잇다, 있습니다, 있음, 있더라, 있으며, 있죠, 있답니다, 있군, 있네요, 있었습니다, 있음을, 있겠지, 있네, 있는, 있군요, 있지만, 있지, 있듯이, 있엇다, 있단, 있구나, 있고, 있듯, 있었고, 있던, 없다, 있당, 있겠다, 있으니, 있었을까, 있었는데, 있으나, 있기에, 있냐, 있겠지만, 있으려나, 있었던, 있을까, 있나, 있기, 없었다, 있겠구나, 있잖아, 있었을텐데, 잇음, 있기를, 있어, 있었지만, 있었, 넘친다, 있느냐, 있음에도, 없더라, 있소, 있겠는가, 있습니까, 있어서, 있길, 있거든, 잇엇, 많다, 있니, 없단, 있자, 잇는, 있으, 있은, 있더, 잇지, 있을, 있거, 있었으나, 없거든, 있긴, 있더라도, 있, 있건, 없나보다, 담겨있다, 없겠지, 있으면, 없엉, 숨어있다, 있겠습니까, 논다, 있진, 져있다, 없음을, 없겠다, 있겠, 가졌다, 없듯이, 테니까, 없자나, 공존한다, 있었기에, 졌다, 나왔다, 없죠 </p> <br> ### 되다 <p class="message"> 되었다, 된다, 되고, 되었고, 됨, 됐다, 되더, 됬다, 되며, 되면서, 되니, 된, 되네, 되듯, 되버렸다, 되었습니다, 된듯, 되엇다, 되더라, 돼버렸다, 되어버린, 되겠지, 될때, 되다니, 되는, 됩니다, 되지만, 되었을때, 되었지만, 되니까, 되서, 됐으, 되버린, 됐네, 됐지만, 되자, 되던, 되버리, 됐음, 되죠, 됐었다, 됫다, 되기까지, 됐고, 되어, 돼버린, 된건지, 돼있다, 된건, 시킨다, 될듯, 됌, 돼, 됬고, 된것, 될줄, 되지, 되었는데, 되리, 해버렸다, 하려다, 되거나, 돼서, 되가는, 됐던, 될수록, 될거, 됨으로써, 시켰다, 되버, 될뿐, 되겠다, 되기, 어느새, 될까, 되길, 될, 오다, 됐는데, 되려, 될꺼, 되면, 됬지만, 되긴, 됐어, 된게, 되느, 됐나, 되거, 됨을, 됨에, 될뻔, 바뀐다, 되나, 어느순간, 되요, 된걸까, 되네요, 되겠, 나타났다 </p> <br> ### 보다 <p class="message"> 보단, 들보다, 그것보다, 훨씬, 것보다, 훨, 1편보다, 그보다, 못지않게, 만큼이나, 2보다, 훨신, 낫고, 3보다, 이상으로, 거보다, 작보다, 전작보다, 판보다, 이쪽이, 편보다, 전작들보다, 1보다, 물보다, 원보다, 책보다, 천배, 1탄보다, 2보다는, 이전에, 다음으로, 전편보다, 낫다, 3보단, 백배, 전보다, 본편보다, 2보단, 몇배는, 씬보다, 신보다, 보더, 못지, 때보다, 낫더라, 원스보다, 삶보다, 이것보다, 의외로, 일수록, 쪽이, 그보, 나음, 총보다, 일때가, 상대적으로, 웬만한, 0배, 보가, 것보단, 명량보다, 1보단, 개인적으론, 이후로, 오히려, 돈보다, 비하면, 이외에, 개인적으로, 비해, 왠만한, 뺨치는, 쬐끔, 보기전에, 더, 자보다, 비중이, 만큼, 때문인지, 말보다, 낫네, 들보, gt, 이전의, 보디, 유난히, 낫지만, 치보, 누구보다, 이후에, 바닐라스카이, 전편보단, 무엇보다, 갠적으로, 다웠던, 이상의, 이보다, 다워, 알고보니, 한층 </p> <br> ### 대하다 *min_count* 조건(빈도가 100 이하인 단어는 Word2Vec 임베딩에서 제외)에 의해 결과가 나오지 않았습니다. 흔한 단어임에는 틀림 없으나 기본형보다는 활용형으로 자주 쓰이기 때문으로 풀이됩니다. <br> ### 위하다 *min_count* 조건(빈도가 100 이하인 단어는 Word2Vec 임베딩에서 제외)에 의해 결과가 나오지 않았습니다. <br> ### 말하다 *min_count* 조건(빈도가 100 이하인 단어는 Word2Vec 임베딩에서 제외)에 의해 결과가 나오지 않았습니다. <br> ### 가다 <p class="message"> 가면서, 가다가, 가며, 걷다, 가듯, 가더, 간다, 가더라, 가니, 오다, 오며, 뛰다, 풀다, 오면서, 가나, 갈때, 가던, 놓다, 갔다, 치다, 가고, 왔다, 가도, 거슬러, 가는, 하려다, 내다, 가버리, 가네, 서다, 온다, 왔지만, 가서, 가면, 가겠지, 섰다, 갔고, 가자, 갔으, 갈, 오듯, 돌렸다, 간듯, 서서, 잡다, 가버렸다, 가냐, 가보, 오더, 주다, 갈지, 살다가, 갈수, 갔지만, 쓸려, 가느라, 담다, 오지만, 가려는, 다닌다, 어느새, 곧장, 가니까, 갈까, 가거나, 와서, 넘기, 숲속으로, 쫓다, 나간다, 막다른, 오고, 갔네, 하다가, 오듯이, 리다, 허겁지겁, 갈땐, 갑니다, 가더라도, 가기, 천천히, 갔더, 다님, 갔구나, 서둘, 올때, 가지, 달려가는, 나갔다, 왔을때, 가겠다, 비춘다, 가길, 나가다가, 놓고, 가선, 간, 듣다, 타다 </p> <br> ### 받다 <p class="message"> 받았다, 받음, 받고, 받은, 받으, 주다, 받으면, 받는, 받게, 받으며, 받을, 당했다, 받았, 받아, 받지, 받기, 받으려는, 당함, 받았던, 버림, 받겠, 받으러, 듣다, 받던, 상속, 갑니다, 전해진다, 싸다, 조기, 퍼진다, 당해서, 풀다, 온, 울다, 받거나, 주입식, 당하고, 당하는, 주자, 왔다, 당한, 보내는, 해버렸다, 선사한다, 부른다, 전한다, 가한, 받길, 이오, 당하, 빅엿, 기쁘, 한답시고, 받으려고, 받긴, 선사하는, 담다, 표한다, 얻다, 이룩한, 왔습니다, 표함, 먹다, 해대, 주다니, 얻는, 치다, 남기는, 되더, 전파, 후라, 가더, 선사했다, 셀프, 이었겠지, 질렀다, 하려다, 하라, 투수, 어퍼컷, 오는, 모의고사, 건내는, 옴, 당했지만, 값싼, 돌림, 노벨, 날리는, 온다, 전하는, 준다, 안기고, 주거, 보냄, 남긴, 옛다, 날렸다, 마땅하다, 내린다 </p> <br> ### 보이다 *min_count* 조건(빈도가 100 이하인 단어는 Word2Vec 임베딩에서 제외)에 의해 결과가 나오지 않았습니다. <br>  ## 실험결과5 (형용사) ### 없다 <p class="message"> 없었다, 없음, 없더라, 없네, 없구나, 없당, 없네요, 없습니다, 없군, 음슴, 없엉, 없는, 없죠, 없지만, 없겠지, 없었고, 없으나, 없으며, 없나보다, 없고, 없단, 없으니, 없거든, 없겠지만, 없었지만, 없듯이, 없단다, 없겠다, 없었던, 없자나, 없어, 없던, 없달까, 없구, 없을, 없음을, 없으, 없었, 없엇, 없듯, 없더, 없은, 있겠는가, 없기에, 있다, 없었는데, 없, 없겠, 없긴, 없지, 없어서, 없나, 없잖아, 없기는, 없잖, 있나, 있었다, 있겠습니까, 없니, 없냐, 없거나, 있을까, 잇다, 있냐, 많다, 있엇다, 없을만큼, 이렇다, 없게, 도없, 있겠다, 없기, 적다, 있죠, 있겠, 없어도, 안난다, 있었을까, 있군요, 있더라, 있겠지만, 껴진다, 못찾겠다, 있군, 있답니다, 있으려나, 있음, 못느, 쏘냐, 많았다, 있었습니다, 덜하다, 있습니다, 래야, 없으면, 잃었다, 많음, 수없, 안남, 진부하다 </p> <br> ### 그렇다 <p class="message"> 그랬다, 그랬지만, 평범하다, 그렇고, 식상하다, 좋다, 진부하다, 엉성하다, 그렇지, 지겹다, 훌륭하다, 그렇듯, 진부했다, 어설프다, 그렇, 좋긴, 심심하다, 어색하다, 뻔하다, 평타, 무난했다, 그래, 마찬가지, 불편하다, 그렇지만, 멋지다, 참신하다, 논외로, 글쎄, 괜찮았다, 지루했다, 지루하다, 볼만하다, 불친절하다, 볼만했다, 좋지만, 그랬는데, 유치하다, 싫다, 이렇다, 맞다, 그랬듯이, 오글거린다, 잔잔하다, 약하다, 참신했는데, 질린다, 외롭다, 울뿐, 독특하다, 그랬던, 별거없, 좋았다, 신선하다, 신선했다, 멋있다, 슬프다, 좋기, 암만, 구리다, 이뻤다, 참신했다, 촌스럽다, 나아졌다, 나쁘다, 중박, 이니까, 훌륭하지만, 별게, 멋지지만, 졸립다, 작다, 특이하다, 솔직히, 심했다, 허술하다, 즐겁다, 대단했다, 옳다, 예쁘다, 무난하다, 우수하다, 묘하다, 치더라도, 새롭다, 별론데, 화려하다, 싫지만, 이기적이다, 감각적이다, 과하다, 만족스럽다, 피곤하다, 아름답다, 잔인하다, 쏘쏘, 이쁘지만, 신기했다, 서글프다, 억울하다 </p> <br> ### 같다 <p class="message"> 같음, 같습니다, 같네요, 같았다, 같당, 같고, 같네, 같긴, 같아, 같지만, 같았고, 같았던, 거같다, 같애, 같군, 같기도, 같어, 같았음, 같았지만, 것같다, 같았는데, 듯하다, 같, 같아서, 거같음, 같던, 같은, 듯, 같단, 같구, 같진, 것같음, 같달까, 같으면서도, 같으, 같았, 듯싶다, 같냐, 같기, 같구나, 거같은데, 인거같다, 듯ㅋ, 듯ㅎㅎ, 듯ㅠㅠ, 것, 듯ㅋㅋㅋ, 같으면서, 듯했다, 거같고, 뿐임, 같더, 같지, 듯ㅋㅋ, 듯함, 거라는, 처럼, 듯합니다, 거같은, 꺼같다, 거다, 거에요, 인것같다, 뿐이다, 테니까, 같을까, 이다, 것처럼, 거란, 듯하고, 뻔했다, 가싶다, 인듯하다, 거같아, 맞죠, 같으니, 인듯, 테고, 텐데, 가요, 듯한, 같을, 거야, 데ㅠㅠ, 몇안되는, 뎅, 아냐, 것임, 닮았다, 데ㅋㅋㅋ, 듯하지만, 였습니다, 같으면, 거라고, 테지, 이었다, 였다, 거네, 것인데, 데요 </p> <br> ### 어떻다 *min_count* 조건(빈도가 100 이하인 단어는 Word2Vec 임베딩에서 제외)에 의해 결과가 나오지 않았습니다. <br> ### 이렇다 <p class="message"> 저렇, 평범하다, 없다, 그렇다, 진부하다, 왈가왈부, 뭐라, 없습니다, 틀렸다, 틀리다, 그렇지, 범접, 바뀌었다, 어떻, 반댈세, 식상하다, 다르다, 갈린다, 이렇, 딱히, 복잡하다, 전무후무, 뻔하다, 지루하다, 그렇듯, 불완전하다, 동의, 답, 글쎄, 나쁘다, 그러, 무난하다, 장담, 어쩌라고, 그랬다, 없긴, 저러, 음슴, 애매하, 졸립다, 없겠지만, 덜하다, 지겹다, 답이, 없기는, 가능하다, 갈리, 그렇, 허술하, 분분, 다라고, 없더, 고들, 그랬듯이, 말하자면, 감히, 평하, 화라, 무의미하다, 적으, 단하, 부족하다, 졌으, 겉핥기, 어차피, 잊으라, 맞다, 원체, 옳다, 깔끔하다, 독특하다, 뭐니, 없더라, 난해하다, 그다지, 없으, 없당, 어짜피, 주관적인, 지향해야, 따분, 이러, 애매하다, 일것이, 불가능하다, 별로, 담겨있다, 달랐다, 허술하다, 안한다, 평도, 논외로, 별거없, 시시, 불확실, 없었다, 단일, 마션이, 명확하, 색다르 </p> <br> ### 다르다 <p class="message"> 달랐다, 비슷하다, 틀리다, 다르지만, 다르고, 비슷하, 다르, 다르게, 다른, 닮았다, 비슷하지만, 달랐던, 닮아있다, 확연히, 달라, 엄연히, 다름, 달랐, 똑같, 비슷, 틀렸다, 바뀌었다, 정반대, 특이하다, 다를, 과는, 별개, 달랐지만, 맞다, 별개의, 갈린다, 상관없다, 비슷한, 반대로, 달리, 새롭다, 유사하다, 오글거린다, 별개로, 달라지는, 틀린, 틀리, 차원, 흡사, 상관없는, 와는, 평범하다, 상관없이, 어색하다, 거칠다, 낮다, 떨어진다, 동떨어진, 무관, 궤를, 중요하다, 무의미하다, 옳다, 똑같은, 바뀐다, 불완전하다, 신선하다, 비슷해서, 진부하다, 복잡하다, 나아졌다, 독특하다, 사뭇, 틀려, 빠르다, 차이, 닮았, 다름을, 상반된, 마찬가지로, 동일, 2라, 겹친다, 나뉜다, 바뀐다는, 비교, 불가능하다, 안맞, 겹치, 밝다, 바꼈다, 동떨어, 일반적인, 멀다, 상극, 느리다, 안맞는, 동일한, 약하다, 허술하다, 공존한다, 입는다, 급이, 그렇다, 다름이 </p> <br> ### 크다 <p class="message"> 컸다, 컷다, 큰듯, 컸고, 크네, 크긴, 크지만, 컸지만, 적다, 컸기에, 클수록, 컸음, 작다, 크지, 크나, 깊다, 큰, 강했다, 작았다, 크니, 컸던, 커졌다, 큰법, 강하다, 높다, 깊었다, 낮다, 컷던, 큰데, 어마어마하다, 큰만큼, 크고, 많다, 대단했다, 약하다, 클, 크면, 큰지, 심하다, 커진, 커서, 짙다, 크진, 덜하다, 많았다, 강렬했다, 굉장하다, 얕다, 작지, 세다, 무겁다, 스러웠다, 컸나, 컸는, 어마어마, 짧다, 약했다, 길다, 작아서, 심함, 늘었다, 적어서, 크나큰, 커질, 나아졌다, 컸으면, 어마어마하, 넓다, 높음, 적었, 느껴진다, 심했다, 떨어진다, 높았, 깊음, 스럽다, 낮음, 느껴졌다, 진하다, 약해서, 커지, 커졌, 커져, 심하고, 중요하다, 돋보였다, 길었다, 상당, 덜함, 띄었다, 커지고, 커, 크기가, 쎄다, 넓어, 위험하다, 커지는, 대단하다, 덩치, 심한 </p> <br> ### 많다 <p class="message"> 많았다, 많음, 많습니다, 많고, 많았고, 많지만, 많기에, 많았는데, 많네, 많았던, 많아서, 많구나, 많아, 많으니, 많았지만, 많은, 많지, 많긴, 많겠지만, 많았, 적다, 많더라, 많으, 많을, 크다, 심하다, 많기, 거슬린다, 없더라, 컸다, 약하다, 과했다, 강했다, 없다, 컷다, 강하다, 인상적이다, 심했다, 산만하다, 심하고, 있긴한데, 작위적이다, 허술하다, 있다, 길다, 작다, 길었다, 짙다, 높다, 적어서, 많으면, 몇몇, 세다, 인상적이었다, 인상깊었다, 없네요, 낮다, 담겨있다, 큰듯, 빠르다, 짧다, 없습니다, 늘었다, 띄었다, 과하다, 깊다, 친절하다, 숨어있다, 인상깊다, 티나는, 있었다, 멀다, 약했다, 등, 대부분이, 적었, 있었습니다, 찰지다, 작았다, 있긴, 적고, 얕다, 심심하다, 위험하다, 느리다, 없네, 심함, 등등, 어색하다, 멋졌다, 가득하다, 적게, 나아졌다, 없기는, 낫다, 적지, 피곤하다, 나았다, 없었다, 뻔하다 </p> <br> ### 좋다 <p class="message"> 좋음, 좋았다, 좋당, 좋더라, 좋타, 좋네, 좋앗다, 좋네요, 조으다, 조음, 좋구나, 좋았고, 좋습니다, 좋고, 좋드라, 좋던데, 좋구, 좋앙, 멋지다, 좋지만, 훌륭하다, 조타, 인상적이다, 좋군, 좋긴, 멋졌다, 인상적이었다, 귀엽다, 싫다, 인상깊다, 멋있다, 싫었다, 신선하다, 깔끔하다, 편했다, 신선했다, 괜찮았다, 돋보인다, 돋보였다, 일품이다, 예쁘다, 만족스럽다, 흥겹다, 굳, 인상깊었다, 좋으니까, 신기했다, 좋았지만, 맘에, 찰지다, 정겹다, 존좋, 좋앗, 반갑다, 그렇다, 귀여웠다, 참신하다, 유쾌하다, 굿, 좋잖아, 구리다, 어색하다, 반가웠다, 좋, 경쾌하다, 좋았는데, 감각적이다, 아름답다, 곱다, 좋았, 흥미로웠다, 즐겁다, 싫음, 조아, 이뻤다, 독특하다, 설렌다, 좋더, 좋아, 이쁘다, 탁월하다, 조은, 재밋다, 불편하다, 예뻤다, 좋은, 특이하다, 자연스럽다, 아름다웠다, 짱임, 나빴다, 묘하다, 달달하다, 시원시원하다, 색달랐다, 아쉬웠고, 따뜻하다, 웃기다, 즐거웠다, 굿굿 </p> <br> ### 이러하다 *min_count* 조건(빈도가 100 이하인 단어는 Word2Vec 임베딩에서 제외)에 의해 결과가 나오지 않았습니다. <br>  ## 실험결과6 (부사) ### 더 <p class="message"> 훨씬, 더욱, 더더, 덜, 좀더, 훨, 더더더, 훨신, 몇배는, 한층, 천배, 더더욱, 백배, 전보다, 오히려, 원스보다, 때보다, 0배, 배로, 제일, 더한, 스탁, 두배, 가장, 배는, 쫌만, 좀만, 3보다, 알수록, 2보다, 이것보다, 배럴즈, 이보다, 이만큼, 이쪽이, 덜했, 전편보다, 1편보다, 그보다, 나은, 보다, 더보, 젤, 더줌, 더해, 그나마, 그것보다, 1탄보다, 보단, 외려, 울수록, 수록, 전작보다, 얼마나, 으련만, 피그, 나왔더라면, 개인적으론, 5배, 더가, 2보다는, 할수록, 백, 다듬었, 한단계, 명량보다, 더와, 확실히, 그만큼, 일수록, 이라도, 덜하지만, 볼수록, 2배, 워낙, 넘, 상대적으로, 2보단, 조금, 나아, 덜해, 강해진, 덜함, 이상으로, 다빈치코드, 나았, 더했다, 작보다, 덜한, 굉장히, 1보다, 차라리, 쪽이, 덜하, 낫네, 괜시리, 간한, 전작들보다, 무척, 낫더라 </p> <br> ### 다시 <p class="message"> 금, 한번, 또다시, 번, 또, 나중에, 곱씹어, 새롭게, 두번, 몇번이고, 세번, 되짚어, 되돌아, 년뒤에, 찬찬히, 언젠가, 또또, 다신, 번이고, 뒤늦게, 년만에, 되새겨, 두고두고, 곱씹으며, 몇번이나, 매년, 우연히, 쯤, 꺼내, 몇번을, 두세번, 일년, 돌아, 조만, 찾아, 특선으로, 문뜩, 뒤돌아, 번을, 네번, 또보고, 돌이, 새삼, 얼마전, 전으로, 첨으로, 최근에, 번씩, 각잡고, 두번째, 보고, 년후, 째로, 엄두가, 기념으로, 되감, 번이나, 백번, 감회가, 내년에, 기회가, 정주행, 오랫만에, 2번, 느낍니다, 오랜만에, 지우고, 세번째, 켜, 볼때마다, 꼭, 3번째, 광복절, 씻고, 만에, 번은, 매번, 때마다, 그제서야, 이영화를, 해마다, 올때마다, 보라, 곰곰, 복습하고, 몇번, 번쯤은, 서야, 드디어, 언젠간, 공부하고, 번만, 년뒤, 진면목을, 문득, 확인, 김질, 엔에서, 월에, 며칠 </p> <br> ### 안 <p class="message"> 웬만, 못, 안되는, 안봤는데, 안됐다, 안돼, 안된다, 왠만, 안나, 안본, 안가, 안나오는, 안해, 안됬다, 못알아, 안됐, 왠만하면, 안될, 안됨, 안그, 안보고, 안맞아, 안되, 안봐도, 안봅니다, 안해도, 안되지만, 안들어, 안봐, 안하는, 말안, 안되고, 어케, 안되게, 못봐, 안대, 에혀, 적게, 안맞는, 이상하게, 안났다, 안갔, 안와, 나랑, 도저히, 사서, 안봄, 안만, 나중에, 술먹, 못보는데, 못봤다, 뭘해도, 안무서웠, 안되서, 못본, 안봤, 도무지, 안무서워, 만하면, 못보겠, 비만, 뭔말인지, 안맞, 못보는, 안함, 2배속으로, 못봄, 야한거, 안한, 안봤다, 못봤, 당연히, 안됩니다, 안난다, 무서워서, 솔직히, 트포, 안가고, 억울해서, 첨에, 안볼, 해선, 큰일, 열받아서, 안감, 음슴, 울면서, 안한다, 얼추, 족족, 없거나, 계속, 백퍼, 잊어버려, 같이, 애랑, 곱게, 많이, 아나 </p> <br> ### 잘 <p class="message"> 훌륭하게, 적절하게, 제대로, 멋지게, 맛깔나게, 적절히, 탄탄하게, 세련되게, 정확하게, 매끈하게, 섬세하게, 깔끔하게, 감각적으로, 완벽하게, 자알, 똑똑하게, 절묘하게, 매끄럽게, 멋드러, 세심하게, 충실히, 실감나게, 재치있게, 기똥차게, 영리하게, 예쁘게, 명확하게, 완벽히, 충실하게, 정교하게, 맛있게, 명확히, 독특하게, 잘은, 확실하게, 조화롭게, 멋들어, 잘이, 흥미롭게, 성공적으로, 치밀하게, 막히게, 정확히, 자연스럽게, 아기자기하게, 상업적으로, 대충, 감있게, 아름답게, 담백하게, 참신하게, 무난하게, 설득력있게, 이쁘게, 유쾌하게, 얼추, 생생하게, 극적으로, 귀엽게, 흥미진진하게, 잘도, 적나라하게, 세세, 찰지게, 알차게, 있게, 위트있게, 잘만, 재밋게, 넘치게, 절절하게, 잘된, 잘한, 다양하게, 매혹적으로, 어울, 맛나게, 성실히, 자세히, 부드럽게, 잘그, 단적으로, 맞게, 무난히, 솔직하게, 어울렸다, 색다르게, 무섭게, 말끔, 어설프게, 선명하게, 성실하게, 세밀하, 극단적으로, 기발하게, 잇게, 경쾌하게, 잘맞, 열심히, 허술하게 </p> <br> ### 가장 <p class="message"> 제일, 젤, 유일하게, 재일, 무척이나, 젤로, 이토록, 유독, 굉장히, 중에, 몇안되는, 꽤나, 중, 손꼽히는, 이처럼, 다음으로, 더없이, 상당히, 매우, 단연, 단연코, 참으로, 무척, 통틀어, 것중, 유난히, 사상, 유일한, 중에서도, 이다지도, 비교적, 아주, 물중에, 이보다, 얼마나, 이만큼, 최초로, 더, 물중, 만큼이나, 더욱, 누구보다, 꽤, 훨씬, 엄청나게, 이리도, 최고의, 그토록, 놀랍도록, 정말, 드물게, 독창적이고, 대단히, 장예모의, 참, 으뜸, 지독히도, 지극히, 최대의, 못지않게, 단언컨데, 중엔, 유일, 최초의, 들중, 그만큼, 훨신, 꼽힐, 꼽을, 단언컨대, 만큼, 손꼽, 더불어, 제법, 역대, 진정으로, 의외로, 영리하고, 유일무이한, 지나치게, 무엇보다, 꼽는, 압도적으로, 극도로, 여태, 첫, 이렇게, 너무, 모처럼, 외화, 최악의, 개인적으로, 투탑, 위트있고, 요근래, 아이러니하게도, 극히, 것보다, 첫번째, 대체적으로 </p> <br> ### 함께 <p class="message"> 같이, 더불어, 나란히, 손잡고, 수님, 정님과, m님과, 지님, 이희, e님과, 동시대에, 님과, 쌍벽을, 원님, 단둘이, 희님과, 영님, 현님, 진님과, 경님과, o님과, 공유하며, 마찬가지로, 용산에서, 김유, 강민, 동반자, 정혜, 씨름, 산책하는, 이현, 공원에서, 조우, 맞으며, 김우, 먹으며, 다같이, 여의도에서, 맞바꾼, Chan, 동시에, 들으며, 추며, 로에서, 공명, 티몬, 이태, 비슷, 문점에서, 연님과, 김지, 준님과, 한소희님과, 필히, 동행, Moon, 합주, ya, 김태, Pa, 배웅, 일산에서, 김기, 강변에서, 동반, 어깨를, 스노, 백상민님과, Mi, 김진, 상암에서, ae, 흡사, 이강, 럴점에서, 사카모토의, 들으면서, 산책, 맞이, 비슷하다, Le, 술한, 즐겁게, 강영은님과, 바닷가에서, 신촌, GV, 김동, Je, 궤를, Ko, 오가며, 재회, SH, 주님, Da, 춤을, 맞먹는, 공유하는, 정든 </p> <br> ### 바로 <p class="message"> 야말로, 전부, 곧, 진정한, 만약, 아마도, 이곳이, 당장, 이것이, 정녕, 아닐까, 그러니까, 뭐냐, 묘미, 너가, 불현듯, 반드시, 유일한, 너야, 이었구나, 과연, 진정, 뭐임, 아마, 뭐에요, 꼭, 였구나, 트레이, 정수, 만일, 설마, 마치, 나혼자, 당신이, 즉, 꿈인가, 뭔데, 아니라, 빌어먹을, 국익이, 캬, 여담이지만, 드디어, 진짜, 끝자락에, 월에, 뭐니, 이구나, 다움이란, 비로소, 모든, 혹시, 서고, 곧바로, 다야, 시초, 시빌, 이곳, 일거, 나인가, 뭐야, 먼저, 그제, 원하던, 앞과, 이전에, 있소, 보자마자, 반댈세, 어딜가나, 뭡니까, 이자, 시부, 직전에, 찾던, 프렌즈, 궁극, 참교육, 별에서, 빈라덴, 비단, 원래, 즉시, 마자, 우선, 여기에, 진정으로, 명실상부, 꿈인지, 이야말로, 누군가가, 미져리, 정답이, 무엇인지, 아하, 자넨, 서슴없이, 아차, 말구, 매직 </p> <br> ### 모두 <p class="message"> 모든, 또한, 전부, 각각의, 각자, 모조리, 각자의, 대부분의, 3박자, 둘다, 골고루, 각, 대다수, 나머지, 대부분, 한명한명, 두가지, 각의, 각기, 저마다의, 외, 뿐아니라, 수많은, 두마리, 챙긴, 개개인의, 들도, 들까지, 얼라이언스, 두루, 다수, 세명의, 물론, 누구나, 세가지, 자신들의, 무엇보다, 고루, 삼박자, 결핍된, 죄다, 주조연, 싸그리, 각각, 오롯이, 외의, 개성있는, 포함한, 무엇하나, 이외, 곧, 대부분이, 결국, 저마다, 시청자, 들마, 공평하게, 3박자가, 주위, 동시에, 스스로, 마저도, 마져도, 개개인, 싹다, 한마음, 우리, 조화롭게, 당연히, 3명의, 세세한, 진정으로, 총체, 즉, 마저, 둘, 력까지, 누구, 온전히, 주변, 완벽하게, 진정, 왕도, 성까지, 몽땅, 들의, 들조차, 완벽히, 삼박자가, 망자, 외적인, 일그러진, 이동휘, 사카모토의, 양쪽, 아낌없, 주변의, 당대, 선남선녀, 셋은 </p> <br> ### 없이 <p class="message"> 감없이, 안하고, 아무, 틈없이, 아무생각없이, 없고, 정보없이, 런, 없는, 단순하게, 낌없이, 없으며, 없게, 이상으로, 내려놓고, 가볍게, 이유없이, 것없이, 망설임, 배제하고, 기교없이, 웃으면서, 없지만, 부담없이, 비우고, 편하게, 않고, 맘으로, 별생각없이, 웃으며, 없었고, 물흐르듯, 없기에, 무시하고, 없음, 없어서, 정신없이, 대며, 겨를, 쉴새, 별다른, 도없, 없던, 막무가내로, 꾸밈없이, 없었지만, 없으나, 사전정보, 많고, 쉴세없이, 마음으로, 하며, 조용하게, 같이, 없다, 만으로, 놓고, 유쾌하게, 말없이, 모른채, 잔잔하게, 소소하게, 있게, 쉼없이, 내며, 먹으며, 가볍고, 컷으로, 끝도, 하면서, 없었는데, 거없, 먹으면서, 원없이, 날림, 안했는데, 웃으려고, 없더라, 쉬지않고, 없을만큼, 거침없이, 단순하고, 막힘없이, 맘편히, 군더더기, 안들고, 마디로, 무심히, 없듯이, 쉴새없이, 외에는, 없었던, 넘치게, 깔끔하고, 무작정, 틈도, 면으로, 무난하게, 렇지, 상태로 </p> <br> ### 다 <p class="message"> 다ㅋㅋ, 다ㅠㅠ, 다ㅠ, 다ㅜ, 다ㅎ, 다고, 다ㅡ, 다ㅋㅋㅋ, 다라는, 다ㅋ, 다ㅎㅎ, 다는, 다ㅋㅋㅋㅋㅋ, 다ㅋㅋㅋㅋ, 다더, 다던, 다구, 얌, 다며, 다면, 다란, 었다, 다던데, 다네, 다지만, 다거나, 다아, 다라고, 다의, 다와, 다잉, 에요, 구먼, 예요, 구만, 닷, 닼ㅋㅋㅋ, 다기, 라능, 었당, 엿다, 였다, 로구나, 죠, 었겠지, 다도, 에여, 야ㅠㅠ, 었군, 였음, 지요, 었음, 겠지, 였군, 었지만, 거든요, 더라, 단다, 노병은, 듯하다, 다에, 것같다, 거늘, 었는데, 란다, 라해도, 다라, 었달까, 엇다, 군, 더라도, 엇음, 랍니다, 야라는, 었더라, 였어, 구나, 었네, 다길래, 희안한, 었구나, 지ㅋ, 닼ㅋㅋ, 였어요, 었죠, 다진, 었으나, 였당, 지만, 네, 네요, 시다, 었잖아, 더군, 여, 엿는데, 군요, 로다, 었습니다, 당 </p> <br>  ## 실험결과7 (감탄사) ### 참 <p class="message"> 참으로, 정말, 무척, 굉장히, 무척이나, 넘, 매우, 너무, 겁나, 상당히, 꽤나, 몹시, 디게, 꽤, 아주, 되게, 느무, 왜이리, 젤, 느므, 넘넘, 제일, 존나, 왜이렇게, 제법, 엄청, 대체적으로, 왜케, 졸라, 더없이, 어찌나, 증말, 여러모로, 왤케, 막히게, 대단히, 이렇게, 진짜, 너므, 이리도, 의외로, 예쁘고, 참신하고, 무엇보다, 너어무, 신선하고, 희안하게, 어쩐지, 이처럼, 더럽게, 거참, 드럽게, 왜캐, 얼마나, 이쁘고, 넘나, 좋고, 특히, 워낙, 나름, 소름끼치게, 은근히, 좋긴, 유독, 겁내, 독특하고, 썩, 더할나위, 가장, 원체, 젤로, 부럽고, 색다르고, 엄청나게, 어쩜, 은근, 기막히, 어쨌든, 이런, 열라, 더더욱, 어마어마하게, ㅈㄴ, 독특해서, 아무튼, 반갑고, 아따, 은이, 꾀, 훈훈하고, 만큼이나, 말밖, 쫌, 이토록, 유난히, 이래서, 훌륭하고, 특이하고, 훨씬, 이세영 </p> <br> ### 그래 <p class="message"> 그럼, 그러니까, 뭐, 너네, 응, 임마, 니네, 시벌, 어때, 얜, 아, 이건, 이니까, 봤냐, 그냥, 어차피, 봐봐, 그니, 니들은, 울지마, 얘들아, 왜그랬어, 머, 니가, 잖아, 죽였어, 얘는, 어머, 이봐, 그렇다, 니들, 에휴, 걍, ㅆ, 이래야, 하하하하하하, 기냥, 너도, 니깐, 닥치고, 넌, 근데, 아ㅏㅏ, 라구, 만요, 욧, 하, 그렇, 미쳤어, 잘생기면, 좆까, 그랬, 야해, 으음, 다워, 지뭐, 야호, 쳤어, 하니까, 할래, 사줘, 다야, 씨발, 이잖아, 볼래, 막나가, 이거, 어떠냐, 데헷, 이래, 있잖아, ㅏㅏ, 키야, 내버려둬, 느그, 거기, 너넨, 니까, 음음, 러면, 아아, 뿌셔, 하하, 너는, 살거, 했니, 하잖아, 잘했어, 씨바, 저래, 나야, 찍자, 아뇨, 알잖아, 얘, 기야, 너랑, 에잇, 하아, 건들지마 </p> <br> ### 아 <p class="message"> 하, 아아, 으아, 아아아, 씨발, 아오, 하아, 아악, 으, ㅅㅂ, 시벌, 앜, 아ㅏㅏ, 어휴, 아아아아, 아ㅋㅋ, 아놔, 아ㅠㅠ, ㅆ, Aㅏ, 젠장, 아아아아아아, 시팔, 아씨, 개좋, 아아아아아아아, 씨바, ㅠㅠ, 와씨, 앜ㅋㅋㅋㅋ, 앙, 오, 으악, 썅, 아아아아아, ㅏㅏ, ㅡㅡ, ㅜㅜ, 어우, 와아, ㅠㅜ, ㅜㅠ, ㅁㅊ, 으앙, ㅏ, ㅆㅂ, 그니, ㅡ, 응, ㅠ, 아유, 어어, 우어, 흑흑, ㅜ, 니미, 우와, 오오, 으어, 내사랑, 제길, 오오오오, ㅏㅏㅏ, 으으, 으윽, 에휴, 헐, 아인, 히익, ㅂㄷㅂㄷ, ㅎㅇ, 오우, ㅅ, ㅁ, 흐엉, 하하하하하하, 글고, 시발, 하하, 흐, ㅇㅁ, 엉, 은데, 샤이, 에잇, 이거, 핳, ㄴ, 윽, 어후, ㄹㄹ, 워후, 얜, 잘잤다, 뭐야, 왜그랬어, ㅋ아, 와아아, 근데, 8ㅅ8 </p> <br> ### 뭐 <p class="message"> 머, 걍, 그냥, 암튼, 그럼, 그래, 그럭, 어쩌라고, 어쩌라는, 쨌든, 어때, 그거, 이것도, 저냥, 기냥, 흐음, 음음, 뭐가, 어차피, 개망, 아무튼, 여튼, 글쎄, 어떠냐, 응, 원래, 어쩌, 뭐하자는, 이건, 뭐랄까, 어쨌든, 에휴, 저건, 저럭, 어쨋든, 뭐래, 솔직히, 으음, 겟고, 뭔, 이정도면, 다들, 딱히, 에효, 그래도, 그럭저럭, 뭐야, 별거없, 하튼, 할말이, 쩝, 그니, 일단, 어쨌, 흠, 구냥, 얜, 잼이, 안그, 뭐하, 쨋든, 솔까, 근데, 어휴, 흠흠, 다야, ㅋ, 핵노, 거없, ㅇㅇ, 뭣, 하하, 않습니, 니깐, 별게, 깐, 니까, 말구, 시벌, 안무서움, 지뭐, 뭐니, 어떻, 쏘쏘, 쟤가, 뭥미, 뭐다, 저래, 별론데, 어찌됐든, 좋잖아, 머가, 머랄까, 당연히, ㅡㅡ, 볼만, 개막장, 뭐라, 잼난다, 그러니까 </p> <br> ### 자 <p class="message"> 자는, 자와, 고자, 자인가, 자에, 자가, 자의, 자이, 싶어하는, 싶었던, 자들, 세요, 자로, 자하, 자라는, 자였다, 려는, 시길, 싶나, 싶소, 픈, 자들은, 려, 려고, 려한다, 싶었으나, 자였, 싶던, 자니, 자도, 자를, 자에게, 자들의, 자로서의, 싶었다, 싶었, 자라면, 자라고, 자들에게, 싶은, 시라, 려하는, 싶어, 박애, 지말, 자마, 자보다, 범, 않으려, 겐지, 자인지, 소서, 싶구나, 갈팡질팡, 담당, 자다, 싶다, 자로서, 싶냐, 싶, 패배, 려던, 만다, 신대, 자만, 자들이, 왕관을, 고싶다, 열등, 하자, 되라, 강연, 시전, 자일, 전하고, 자들을, 자인, 파, 기전에, 왕, 셈, 하라, 길, 스승은, 지망, 방랑, 신듯, 후원자, 덮으려, 하려, 의뢰, 자만이, 기도, 양, 남으려, 시게, 싶었지만, 러, 반역, 싶고 </p> <br> ### 아니 <p class="message"> 아님, 아니라, 아닙니다, 아냐, 아닌, 아녀, 아닐, 능사는, 반칙이, 급이, 몫이, 였더라, 탓이, 수준이, 아니지만, 아닐지, 어딨, 아님을, 덕분이, 이냐, 짱이, 모양이, 비단, 맞다, 였으, 뿐이, 바뀌, 이것은, 뻥이, 도아, 제쳐두, 덤이, 되버리, 죄라, 변함없, 였어, 나뿐, 에러, 확실하다, 오랜만이, 맞습니다, 였, 인척하, 내것이, 이건, 애시, 이하, 너였, 대상이, 마찬가지, 정상이, 그렇다면, 었어, 나였, 흔치않, 였군, 그건, 개판이, 에요, 최선이, 갑이, 인줄, 줄어들, 안찍, 였으니, 낫겠, 개쩔, 란말이, 란다, 해먹, 야라, 로다, 라해도, 전유물이, 이되, 이아, 차치하, 드물, 일줄, 되버렸, 터이, 였구, 엉망이, 덕이, 원한, 틱하, 였으면, 였네, 싫으, 못됐, 어쩔뻔했, 였었, 올시다, 내스타일, 모독이, 미남이, 였나, 입니까, 못되, 이랬 </p> <br> ### 예 <p class="message"> 사례, 예시, 대표적인, 본보기, 예가, 예이, 표본, 모범, 답안, 격, 예로, 모범답안, 작명, 바람직한, 온고지신, ㄹ, 모범적, 폐해, 정석, 법, 효시, 레시피, 화의, 퍼무비, 한글제목, 방법, 성교육, 중요성, 운수, 합, 전형, 현지화, 조기교육, 드문, 미학, 단적으로, 놈과, 모범적인, 재능낭비, 워너, 교본, 인거같다, 삼위일체, 아더, 가성비, 취지, 한글, 대표, 영리한, 대명사, 뻐, 활용, 바이, 장점을, 표상, 부제, 벗, 작법, 틴무비, 순기능, 의역, 예를, 두유, 인듯하다, 메이드, ㅓ, 끝판왕, 프랜차이즈, 표준, 레어, 아닙니, 법이, 별미, 번역, 밑바, 공식을, 교과서, 례, 최정, 미덕, 망치는, 절한, 망친, 콜라보, 전형적인, 봉, ㅈ, 클리, 삼박자, 톤과, 점과, 라노, 경우, 좋은, 대중영화의, 사용, 것입니다, 전성시대, 프렌차이즈, 리부트 </p> <br> ### 응 <p class="message"> 뭐야, 음음, 시벌, 엥, ㅅㅂ, 헐, 아ㅏㅏ, 오잉, 데헷, 어어, 앜, 으응, ㅇㅅㅇ, 그럼, 어어어, 그래, ㅁ, 아, 으음, 아아아아아, 우오, 씨바, ㅎㅇ, 모야, ㅇㅅ, ㅡㅡ, 히익, 하하하하하하, 하, 참나, 으아, 아놔, ㅇㅇ, 개쩌, 그러니까, 으, 오오오오, 뭐여, ㅇ, ㅆ, 앗, 이럼, 우와, 걍, 시팔, 뭐지, 어쩌라고, 어어어어, ㅆㅂ, ㅋㄱㅋ, 하하, 아아, 하핳, 휴우, 아아아아아아아, ㅏㅏ, 잉, 다야, 오, 읭, 머야, ㅋ, 얜, ㄴ, 우어어, 하하하, 뭐, 아아아아, 뭥미, 아악, 만요, ㅏㅏㅏ, 오오, ㅗ, 힝, 예쓰, 우오오, 으잉, 오오오, 으악, 아씨, 푸슝, 뭐임, 와아아, 젠장, 허허, 구, 헉, 아하, 아아아, 왜이래, 욤, 제길, Aㅏ, 씨발, 트루러브, 아아아아아아, 꺅, ㅅ, 존나 </p> <br> ### 글쎄 <p class="message"> 글세, 솔직히, 그닥, 올시다, 뭐랄까, 그럭저럭, 불호, 어쨋든, 쏘쏘, 빵점, 어쨌든, 아무래도, 뭐, 별루, 적어도, 별로, 보통, 그래도, 별론데, 흐음, 솔찍히, 딱히, 아쉽게도, 볼만했다, 그다지, 글쌔, 그렇다, 그외, 잘모르겠다, 2프로, 머랄까, 노코멘트, 어쨌, 어찌됐든, 애시, ㅍㅌㅊ, ㅂㄹ, 썩, 당초, 참신했는데, 으음, 저냥, 개인적으로, 논외로, 일단, 애초에, 어떻든, 머, 차치하, 괜찮았다, 볼만, 낫배드, 부족하지만, 물론, 뭥미, 어찌되었든, 그럭, 망했지만, 자체는, 애매하다, 어땠, 괜찮았는데, 그냥, 못미치지만, 못느, 모르겠으나, 모르겠고, 나름대로, 부족하다, 그정도, 이작품, 별5개, 괜츈, 기본적으로, 그렇지, 거기까지, 괜찮았지만, 그뿐이, 좋으나, 무교인, 당연히, 별거없, 볼만하다, 나쁘, 괜찬, 면에선, 몰라도, 확실히, 다좋, 정작, 나름, 반댈세, 쫌, 못미친, 무난했다, 그랬다, 진부했다, 나한텐, 알겠지만, 극찬 </p> <br> ### 아아 <p class="message"> 으아, 아아아아, 아아아, 아아아아아아아, 아아아아아, 아, 아악, ㅏㅏ, 아ㅏㅏ, ㅏㅏㅏ, 하, 아아아아아아, 으어어, 하아, 우우우, 앜, 와아아, 앙, ㅁ, 우어어, 오, 으으, 으, ㅜㅠ, 으윽, 으악, 시벌, 흐, 아유, 하하하하하하, ㅠㅠ, 오오, 시팔, ㅜㅜ, Aㅏ, 으앙, 우어, ㅅㅂ, ㅠㅜ, 우오, 흑흑, 오오오오오, 시바, 아놔, 핳, 젠장, 흐엉, 꺅, 씨발, ㅏ, 엉, 으어, ㅜ, ㅁㅊ, 어휴, 아오, 우우, 어어어어, ㅠ, 어어, 아앙, 씨바, 어어어, 우와, 하악, 맙소사, 오오오오, 우아, 내사랑, 우오오, 잉, 크아, 오오오, ㅅ, 8ㅅ8, 하악하악, 어우, 하앍, 띠리, 쨔응, ㅗ, 이이이, 개좋, ㅆㅂ, ㅆ, 오마이, 응, ㅡ, 지져스, 호우, 꺄, ㅂ, 다아, 와아, 쏘리, 썅, 앗, 캬, 헐, 여신님 </p> 
vi␞ 이번 글에서는 **Variational Inference**(변분추론, 이하 VI)에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept VI란 사후확률(posterior) 분포 $p(z$\|$x)$를 다루기 쉬운 확률분포 $q(z)$로 근사(approximation)하는 걸 말합니다. 사후확률 분포를 계산하는게 불가능에 가까울 정도로 어려운 경우가 많기 때문입니다. 가령 다음과 같은 경우입니다. - *marginal probability*, 즉 사후확률의 분모인 $p(x)=Σ_zp(x,z)$를 계산하기 힘든 경우 - *likelihood*, 즉 $p(x$\|$z)$를 더 복잡하게 모델링하고 싶은 경우 - *prior*, 즉 $p(z)$를 더 복잡하게 모델링하고 싶은 경우 VI를 도식화한 그림은 아래와 같습니다. 사후확률 분포를 우리가 익히 알고 있는 정규분포로 근사한 케이스입니다. <a href="https://imgur.com/05LNq0o"><img src="https://i.imgur.com/05LNq0o.png" width="350px" title="source: imgur.com" /></a>  ## KL Divergence 사후확률에 근사한 $q(z)$를 만들기 위해 [쿨백-라이블러 발산(Kullback-Leibler divergence, 이하 KLD)](https://ratsgo.github.io/statistics/2017/09/22/information/) 개념을 활용합니다. KLD는 두 확률분포의 차이를 계산하는 데 사용하는 함수인데요. 사후확률 분포 $p(z$\|$x)$와 $q(z)$ 사이의 KLD를 계산하고, KLD가 줄어드는 쪽으로 $q(z)$를 조금씩 업데이트하는 과정을 반복하면 사후확률을 잘 근사하는 $q^*(z)$를 얻게 될 것이라는 게 VI의 핵심 아이디어입니다. KLD 식을 조금 변형하면 다음과 같이 유도할 수 있습니다.  $$ \begin{align*} { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right) \right) =&\int { q\left( z \right) \log { \frac { q\left( z \right) }{ p\left( z|x \right) } } dz } \\ =&\int { q\left( z \right) \log { \frac { q\left( z \right) p\left( x \right) }{ p\left( x|z \right) p\left( z \right) } } dz } \\ =&\int { q\left( z \right) \log { \frac { q\left( z \right) }{ p\left( z \right) } } dz } +\int { q\left( z \right) \log { p\left( x \right) } dz } -\int { q\left( z \right) \log { p(x|z) } dz } \\ =&{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right) \right) +\log { p\left( x \right) } -{ E }_{ z\sim q\left( z \right) }\left[ \log { p(x|z) } \right] \end{align*} $$  이후 이 글에서는 동전던지기 예제를 바탕으로 VI를 설명하겠습니다.   ## conjugate distribution 동전던지기 실험은 **이항분포**를 따릅니다. 이항분포란 성공확률이 $p$이고, 그 결과가 성공 혹은 실패뿐인 실험을 $n$번 반복시행할 때 성공횟수의 분포를 가리킵니다. 이항분포 파라메터 $p$의 사전확률과 사후확률 모두 베타분포를 따르는데요. 이처럼 사전확률 분포와 사후확률 분포가 같은 가족군으로 묶일 때 그 사후확률/사전확률을 모두 묶어 **켤레분포(conjugate distributions)**라고 합니다. $q(z)$를 $α_q$, $β_q$를 파라메터로 하는 베타분포, 앞면이 관측된 수를 $n_h$, 뒷면을 $n_t$로 둡시다. 이를 아래 식에 대입해 풀면 사후확률 분포 $p(z$\|$x)$에 가장 잘 근사한 $q(z)$는 $α_q+n_h$, $β_q+n_t$를 파라메터로 하는 베타분포가 된다고 합니다. 이와 관련해서는 [이 글](https://ratsgo.github.io/statistics/2017/06/30/bayesinfer/), 수식 유도와 관련해서는 [위키피디아](https://en.wikipedia.org/wiki/Beta_distribution)를 참고하시면 좋을 것 같습니다.    ## Variational Inference with Monte Carlo sampling [몬테카를로 방법(Monte Carlo Method)](https://ratsgo.github.io/statistics/2017/05/31/gibbs/)이란 랜덤 표본을 뽑아 함수의 값을 확률적으로 계산하는 알고리즘을 가리킵니다. 수학이나 물리학 등에 자주 사용되며 계산하려는 값이 **닫힌 형식**(closed form)으로 표현되지 않거나 복잡한 경우에 그 값을 근사적으로 계산하려고 할 때 쓰입니다. 예컨대 특정 확률 분포를 따르는 $x$의 함수값의 기대값은 다음과 같이 $k$개 샘플로 근사하는 것입니다.  $$ \int { p\left( x \right) f\left( x \right) dx } ={ E }_{ x\sim p\left( x \right) }\left[ f(x) \right] \approx \frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ f({ x }_{ i }) \right] }_{ { x }_{ i }\sim p\left( x \right) } } $$  몬테카를로 방법을 KLD에 적용해 식을 정리하면 다음과 같습니다.  $$ \begin{align*} { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right) \right) =&{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right) \right) +\log { p\left( x \right) } -{ E }_{ z\sim q\left( z \right) }\left[ \log { p(x|z) } \right] \\ =&{ E }_{ z\sim q\left( z \right) }\left[ \log { \frac { q\left( z \right) }{ p\left( z \right) } } \right] +\log { p\left( x \right) } -{ E }_{ z\sim q\left( z \right) }\left[ \log { p(x|z) } \right] \\ \approx &\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { \frac { q\left( { z }_{ i } \right) }{ p\left( { z }_{ i } \right) } } \right] }_{ { z }_{ i }\sim q\left( z \right) } } +\log { p\left( x \right) } -\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { p\left( x|{ z }_{ i } \right) } \right] }_{ { z }_{ i }\sim q\left( z \right) } } \\ =&\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { q\left( { z }_{ i } \right) } -\log { p\left( { z }_{ i } \right) } -\log { p\left( x|{ z }_{ i } \right) } \right] }_{ { z }_{ i }\sim q\left( z \right) } } +\log { p\left( x \right) } \end{align*} $$  이렇게 되면 $q(z)$를 설정하는 것이 자유롭게 됩니다. 동전던지기 예제에서는 $q(z)$를 베타분포로 정하는 것이 자연스럽지만, 실제 문제에서는 사후확률 분포에 대해 아무런 정보가 없기 때문에 이렇게 VI를 진행하기 어렵습니다. 하지만 몬테카를로 방법을 이용하게 되면 $q(z)$를 어떤 분포든 사용할 수 있게 됩니다.  예컨대 사후분포에 대한 정보가 없어서 $q(z)$를 정규분포로 정했다고 칩시다. 이 정규분포에서 $K$개의 $z$들을 뽑으면 위 식, 즉 KLD의 근사값을 계산할 수 있게 됩니다. 정규분포의 파라메터는 평균과 분산이므로, 이들을 조금씩 바꿔가면서 KLD 근사값을 최소로 하는 평균과 분산을 구할 수 있을 것입니다. 이렇게 구해진 정규분포가 바로 VI의 결과가 됩니다.   ## Variational Inference with SGD VI에 [그래디언트 디센트(Gradient Descent)](https://ratsgo.github.io/deep%20learning/2017/09/25/gradient/)를 이용할 수도 있습니다. KLD를 줄이는 쪽으로 파라메터를 업데이트한다는 게 핵심 아이디어죠. 이를 **Stochastic Variational Inference**(SVI)라고도 합니다. 어쨌든 이 방식으로 VI를 하려면 KLD 식이 미분 가능해야 합니다. $q(z)$는 정규분포($θ_q=\{μ_q, σ_q\}$), $p(z)$는 베타분포($α$, $β$)라고 두고 KLD 식을 $θ_q$에 대해 미분해 보겠습니다. (추론 대상 파라메터는 $θ_q$)  $$ \begin{align*} \frac { \partial }{ \partial { \theta }_{ q } } { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right) \right) =&\frac { \partial }{ \partial { \theta }_{ q } } { D }_{ KL }\left( q\left( z \right) ||p\left( z \right) \right) +\frac { \partial }{ \partial { \theta }_{ q } } \log { p\left( x \right) } -\frac { \partial }{ \partial { \theta }_{ q } } { E }_{ z\sim q\left( z \right) }\left[ \log { p(x|z) } \right] \\ =&\frac { \partial }{ \partial { \theta }_{ q } } { E }_{ z\sim q\left( z \right) }\left[ \log { q\left( z \right) } -\log { p\left( z \right) } -\log { p(x|z) } \right] \end{align*} $$  위 식 미분을 완료하려면 $d/dθ_q$가 *expectaion* 안으로 들어가야 합니다. 그런데 $q(z)$는 $θ_q$에 의존하는 분포이고 $z$는 $q$에서 뽑기 때문에 $d/dθ_q$가 *expectaion* 안으로 들어갈 수 없음을 확인할 수 있습니다. 이렇게 하면 어떨까요? **$z$ 대신 노이즈($ε$)를 뽑고, 노이즈로부터 $z$를 계산한다.** $q(z)$는 정규분포라고 가정했으므로, $z$는 다음과 같이 쓸 수 있습니다.  $$ z={ \mu }_{ q }+{ \sigma }_{ q }\epsilon ,\quad \epsilon \sim N\left( 0,1 \right) $$  따라서 위의 식은 다음과 같이 전개할 수 있습니다. $E_{ε~N(0,1)}$은 더 이상 $θ_q$에 의존하지 않으므로 $d/dθ_q$가 *expectaion* 안으로 들어갈 수 있습니다. SVI 역시 몬테카를로 방법을 써서 $K$개 샘플로 KLD 함수의 그래디언트를 근사할 수 있습니다. 이 그래디언트의 반대 방향으로 파라메터 $θ_q$를 조금씩 업데이트하면 KLD를 줄일 수 있게 되고, 이를 반복하게 되면 사후확률 분포 $p(z$\|$x)$에 근사하는 $q(z)$를 찾을 수 있습니다.  $$ \begin{align*} \frac { \partial }{ \partial { \theta }_{ q } } { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right) \right) =&\frac { \partial }{ \partial { \theta }_{ q } } { E }_{ \varepsilon \sim N\left( 0,1 \right) }\left[ \log { q\left( { \mu }_{ q }+{ \sigma }_{ q }\varepsilon \right) } -\log { p\left( { \mu }_{ q }+{ \sigma }_{ q }\varepsilon \right) } -\log { p(x|z={ \mu }_{ q }+{ \sigma }_{ q }\varepsilon ) } \right] \\ =&{ E }_{ \varepsilon \sim N\left( 0,1 \right) }\left[ \frac { \partial }{ \partial { \theta }_{ q } } \left\{ \log { q\left( { \mu }_{ q }+{ \sigma }_{ q }\varepsilon \right) } -\log { p\left( { \mu }_{ q }+{ \sigma }_{ q }\varepsilon \right) } -\log { p(x|z={ \mu }_{ q }+{ \sigma }_{ q }\varepsilon ) } \right\} \right] \\ \approx &\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { q\left( { \mu }_{ q }+{ \sigma }_{ q }{ \varepsilon }_{ i } \right) } -\log { p\left( { \mu }_{ q }+{ \sigma }_{ q }{ \varepsilon }_{ i } \right) } -\log { p(x|z={ \mu }_{ q }+{ \sigma }_{ q }{ \varepsilon }_{ i }) } \right] }_{ { \varepsilon }_{ i }\sim N\left( 0,1 \right) } } \end{align*} $$  노이즈($ε$)를 뽑아 VI를 하는 방식은 $z$를 직접 샘플링하는 방식보다 분산(variance)이 적어 유용하다고 합니다.   ## Vatiational EM algorithm 지금까지는, 사전확률함수 $p(z)$와 우도함수 $p(x$\|$z)$를 이미 알고 있다는 전제 하에 VI 과정을 설명해 드렸습니다. 하지만 실제 문제에서는 사전확률과 우도의 파라메터 또한 알고 있지 못하는 경우가 많습니다. 그런데 VI는 사후확률 $p(z$\|$x)$에 근사한 $q(z)$를 찾는 것이 목적이므로 $p(z)$의 파라메터는 임의로 고정시켜도 관계 없다고 합니다. (아래 식에서 상수항인 $\log{p(x)}$에 해당)  따라서 우리는 사후확률 $p(z$\|$x)$에 근사한 $q(z)$의 파라메터를 찾는 것과 동시에, 우도함수 $p(x$\|$z)$의 파라메터 또한 추정해야 합니다. 하지만 이를 단박에 찾기 어렵습니다. 이 때 유용한 방법론이 바로 **EM algorithm**입니다. $q(z)$의 파라메터를 $θ_q$, 우도함수의 파라메터를 $θ_l$라고 둘 때 EM algorithm은 다음과 같은 과정을 수렴할 때까지 반복합니다. - **Expectaion** : $D_{KL}(q(z)$\|\|$p(z$\|$x))$를 줄이는 $θ_q$를 찾는다. (몬테카를로 방법을 활용한 VI, SVI 등 적용) - **Maximization** : *E-step*에서 찾은 $θ_q$를 고정한 상태에서 $\log{p(x)}$의 하한(lower bound)을 최대화하는 $p(x$\|$z)$의 파라메터 $θ_l$를 찾는다. 여기에서 생소한 내용이 *M-step*입니다. 우선 KLD는 다음 식의 우변과 같이 세 개 요소로 분해될 수 있습니다. *E-step*에서는 KLD를 줄이기 위해 $q$만을 업데이트하므로 이 과정에서 $\log{p(x)}$는 변하지 않습니다. 그런데 KLD를 줄이기 위해선 $\log{p(x)}$ 또한 줄여야 할 것입니다.  $$ { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right) \right) ={ D }_{ KL }\left( q\left( z \right) ||p\left( z \right) \right) +\log { p\left( x \right) } -{ E }_{ z\sim q\left( z \right) }\left[ \log { p(x|z) } \right] $$  위 식을 $\log{p(x)}$를 중심으로 정리하면 다음과 같이 쓸 수 있습니다.  $$ \log { p\left( x \right) } ={ E }_{ z\sim q\left( z \right) }\left[ \log { p(x|z) } \right] -{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right) \right) +{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right) \right) $$  KLD는 항상 양수입니다.  $$ { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right) \right) \ge 0 $$  따라서 $\log{p(x)}$의 하한은 다음과 같습니다. $p(x)$는 베이즈 정리에서 *evidence*라고 이름이 붙여진 항인데요. 이 때문에 아래 부등식의 우변을 **Evidence Lower Bound**(ELBO)라고도 부릅니다.   $$ \log { p\left( x \right) } \ge { E }_{ z\sim q\left( z \right) }\left[ \log { p(x|z) } \right] -{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right) \right) $$  위 부등식 우변의 값을 줄이게 된다면 $\log{p(x)}$를 줄이게 되고, 결과적으로 KLD를 줄일 수 있게 됩니다. 따라서 $θ_q$를 고정시킨 채 위 부등식 우변의 값을 줄이는 방향으로 우도함수의 파라메터 $θ_l$를 업데이트하면 우리가 원하는 결과를 얻을 수 있습니다.      
embedding␞ 안녕하세요. 이번 포스팅에서는 단어를 벡터화하는 **임베딩(embedding)** 방법론인 **Word2Vec, Glove, Fasttext**에 대해 알아보고자 합니다. 세 방법론은 대체 어떤 정보를 보존하면서 단어벡터를 만들기에 뛰어난 성능으로 유명세를 탄 것일까요? 저는 이번 포스팅에서 세 방법론이 크고 작은 차이점을 갖고 있지만 **단어 동시 등장 정보(word's of co-occurrence)**를 보존한다는 점에서 빈도수 기반의 기존 방법론들과 본질적으로 다르지 않다는 점을 이야기해보려고 합니다. 자, 이제 시작해 볼까요.  ## Word2vec 개요 Word2Vec은 지난번 [글](https://ratsgo.github.io/natural%20language%20processing/2017/03/08/word2vec/)에서 언급한 것처럼 단어를 벡터로 바꾸는 방법론입니다. 크게 **CBOW(Continuous Bag of Words)**와 **Skip-Gram** 두 가지 방식이 있습니다. 전자는 주변에 있는 단어들을 가지고 중심에 있는 단어를 맞추는 방식이고, 후자는 중심에 있는 단어로 주변 단어를 예측하는 방법입니다. 예를 들어 보겠습니다. > 나는 ______에 간다. 위 문장에 들어갈 수 있는 단어는 다양합니다. '학교'일 수도, '집'일 수도 있죠. '회사'일 수도 있습니다. 이렇듯 주변 단어를 가지고 중심에 있는 단어를 맞춤으로써 단어 벡터들을 만들어 내는 방법이 CBOW입니다. 반대로 아래처럼 '외나무다리' 앞뒤로 어떤 단어가 올지 예측하는 방법은 Skip-Gram입니다. > ______ 외나무다리 ______ '외나무다리' 앞에는 어떤 단어가 올까요? 아마도 '-는'이겠지요. 그 앞에는 '원수'가 오겠고요. '외나무다리' 뒤에는 어떤 단어가 등장할까요? '-에서'와 '만난다'일 가능성이 높겠네요. 우리가 학습시킬 말뭉치에서도 '외나무다리' 뒤에 '-에서', '만난다'는 표현이 나왔다고 칩시다. 그러면 Word2Vec은 '외나무다리'가 '-에서', '만난다'와 어떤 연관이 있다고 보고 이를 감안해서 단어를 벡터로 만들게 됩니다. 여기서 고민해볼 문제가 하나 있습니다. '외나무다리'는 '원수'와 비슷한 표현(단어)이라고 볼 수 있을까요? 정답이 없는 문제입니다만 그렇지 않다고도, 그렇다고도 볼 수 있을 것 같습니다. '외나무다리'는 '원수'와는 그 의미가 정확히 같지는 않지만, 자주 같이 쓰이는 **연어(collocation)**이기 때문입니다.  ## Word2Vec의 목적함수와 코사인 유사도 Word2Vec은 **[Distributional Hypothesis](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/10/frequency/)**에 근거한 방법론입니다. 비슷한 위치에 등장하는 단어들은 그 의미도 유사할 것이라는 전제가 깔려 있죠. 어쨌든 Word2Vec(Skip-Gram)은 아래 식을 최대화하는 걸 목표로 합니다. $$p(o|c)=\frac { exp({ u }_{ o }^{ T }{ v }_{ c }) }{ \sum _{ w=1 }^{ W }{ exp({ u }_{ w }^{ T }{ v }_{ c } } )}$$ 식 좌변의 의미를 곱씹어 볼까요? o는 주변단어(surrounding word), c는 중심단어(context word)입니다. 다시 말해 p(o\|c)는 중심단어(c)가 주어졌을 때 주변단어(o)가 등장할 **조건부확률**을 뜻합니다. 이 식을 최대화하는 것은 중심단어로 주변단어를 잘 맞춘다는 의미입니다. 즉 '외나무다리'가 등장했을 때 '원수'라는 표현이 나올 것이라는 사실을 예측하는 것이지요. Word2Vec 연구진은 p(o\|c)을 위 식 우변과 같이 정의했습니다. $u$와 $v$는 단어벡터들입니다. 예컨대 '외나무다리'라는 중심단어 벡터가 $v_c$, '원수'라는 주변단어 벡터가 $u_o$입니다. 사실 엄밀히 얘기하면 $u$와 $v$는 다른 벡터들입니다.  하지만 임베딩이 잘 되어 있다면 학습 결과로 도출된 $u$, $v$ 가운데 어떤 걸 써도 상관없다고 합니다. 이 때문에 이후 설명에서 큰 차이를 두지 않았습니다. Word2Vec의 학습 과정에 대해 좀 더 알고 싶은 분은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/)을 참고하세요. 식 우변의 분모와 분자를 설명하기 전에 **코사인 유사도**를 설명하는 것이 좋겠습니다. 2차원 평면 위에 반지름이 1인 단위원이 있다고 칩시다. **[코사인(cosine)](https://ko.wikipedia.org/wiki/%EC%82%BC%EA%B0%81%ED%95%A8%EC%88%98)**의 정의에 의해 $cos(θ)$는 아래 그림의 녹색 선의 길이와 같습니다. $A$를 꼭지점으로 하는 직각삼각형의 빗변의 길이는 단위원 반지름인 1이기 때문이죠. <a href="http://imgur.com/zCFB0mS"><img src="http://i.imgur.com/zCFB0mS.png" width="500px" title="source: imgur.com" /></a> 예컨대 $A$가 $B$에 정확히 포개어져 있을 때(θ=0도) $cos(θ)$는 1입니다. 녹색선의 길이가 단위원 반지름과 일치하기 때문입니다. $B$는 고정한 채 $A$가 y축 상단으로 옮겨간다(θ가 0도에서 90도로 증가)고 칩시다. 이때 $cos(θ)$는 점점 감소하여 0이 되게 됩니다. 아래 그림의 경우 빨간색 직선이 x축과 만나는 점이 바로 $cos(θ)$이 됩니다. <a href="http://imgur.com/H8WvWMB"><img src="http://i.imgur.com/H8WvWMB.gif" width="450px" title="source: imgur.com" /></a> $cos(θ)$는 단위원 내 벡터들끼리의 **내적(inner product)**과 같습니다. 내적값이 커진다는 것은 두 벡터가 이루는 θ가 작아진다(**유사도가 높아진다**)는 의미로 받아들일 수 있습니다. 이는 고차원 벡터공간으로도 확대할 수 있습니다. Word2Vec 연구진은 이러한 코사인과 내적의 성질을 목적함수 구축에 적극 활용한 것 같습니다.  그렇다면 위 식 우변을 최대화한다는 말은 어떤 의미를 지니는 걸까요? 분자를 키우고, 분모를 줄이면 최대화 목표를 달성할 수 있겠죠. 우선 분자 부분을 봅시다.  $$exp({ u }_{ o }^{ T }{ v }_{ c })$$ 분자를 증가시킨다는 건 exp의 지수를 크게 한다는 걸 뜻합니다. $exp$의 지수는 두 벡터의 내적값이 됩니다. 이 값이 커진다는 건 앞서 언급했던 것처럼 벡터들 사이의 θ를 줄인다(즉 유사도를 높인다)는 말이 될 것 같습니다. 다시 말해 중심단어(c)와 주변단어(o)를 벡터공간에 뿌릴 때 인근에 위치시킨다(θ를 줄인다=유사도를 높인다)는 의미로 해석할 수 있다는 얘기입니다. 분모 줄이기는 어떻게 받아들여야 할까요? 분모는 아래와 같습니다. $$\sum _{ w=1 }^{ W }{ exp({ u }_{ w }^{ T }{ v }_{ c })}$$ 따라서 분모는 중심단어(c)와 학습 말뭉치 내 모든 단어를 각각 내적한 것의 총합입니다. 분모를 줄이려면 주변에 등장하지 않은 단어와 중심단어와의 내적값은 작아져야 합니다. 즉 중심단어 주변에 등장하지 않은 단어에 해당하는 벡터와 중심단어 벡터 사이의 θ를 키운다(**코사인 유사도를 줄인다**)는 의미가 되겠습니다.  ## Word2Vec과 단어의 '동시 등장 정보' 여기까지 보면 Word2Vec은 빈도수 기반 방법론들과 별 관련이 없는 것도 같습니다. 그러면 Word2Vec이 어떻게 이와 관계를 지니게 되는 것일까요? 그 비밀은 **학습 과정**에 숨겨져 있습니다. 사용자가 주변단어 몇 개를 볼 지(**window**)를 정해주면 Word2Vec은 말뭉치를 window 크기로 슬라이딩하면서 스크린하며 중심단어별로 주변단어들을 보고 각 단어에 해당하는 벡터들의 요소값들을 조금씩 업데이트함으로써 단어를 벡터로 임베딩합니다.  다시 말해 Word2Vec은 window 내에 등장하지 않는 단어에 해당하는 벡터는 중심단어 벡터와 벡터공간상에서 멀어지게끔(**내적값 줄이기**), 등장하는 주변단어 벡터는 중심단어 벡터와 가까워지게끔(**내적값 키우기**) 한다는 것이죠.  그럼 이렇게 생각해보는건 어떨까요? window 내에 등장하지 않으면 **결과값을 줄이고**, 등장할 경우 **결과값을 키우는** 건? 정확히 이 방식으로 작동하는 알고리즘이 오래 전부터 제안돼 왔습니다. 예컨대 주변 단어를 몇 개 볼지를 정하고 동시에 등장하는 단어의 빈도수를 세어서 행렬로 변환한 '[단어-문맥행렬](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/10/frequency/)'이 대표적입니다.  바꿔 말하면 Word2Vec은 기존 count 기반 방법론처럼 자주 같이 등장하는 단어들의 정보(Co-occurrence)를 보존한다는 얘기입니다. [Omer and Yoav(2014)](https://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf)도 Word2Vec은 본질적으로 기존 count 기반의 방법론과 다르지 않다는 점을 논증해 눈길을 끕니다.  ## 그렇다면 GloVe, Fasttext는? [GloVe](http://nlp.stanford.edu/projects/glove/)는 2014년 미국 스탠포드대학 연구팀에서 개발한 단어 임베딩 방법론입니다. GloVe 연구진이 명시적으로 밝혔듯 GloVe가 보존하려는 정보는 단어 동시 등장 여부입니다. GloVe로 임베딩된 단어 벡터끼리의 내적은 동시 등장확률의 로그값과 같습니다. *(their dot product equals the logarithm of the words' probability of co-occurrence)* Word2Vec이 임베딩된 두 단어벡터의 내적이 코사인 유사도라면 GloVe는 동시 등장 확률인 셈이죠. 그럼 GloVe 연구팀이 직접 든 예시를 볼까요? <a href="http://imgur.com/WhWPkMm"><img src="http://i.imgur.com/WhWPkMm.png" width="500px" title="source: imgur.com" /></a> GloVe는 위 표를 기준으로 할 때 P(k\|ice)/P(k\|steam)로 표현되는 **동시 등장 정보 간 비율**을 보존해 단어를 벡터로 바꾸고자 합니다. 예컨대 'solid'라는 단어를 벡터공간에 임베딩할 때 'ice', 'steam' 중 'ice' 쪽에 가깝게 임베딩한다는 이야기이죠. GloVe의 학습 방식을 자세히 살펴보고 싶으신 분은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/09/glove/)을 참고하시면 좋을 것 같습니다. 한편 페이스북이 2016년 발표한 [Fasttext](https://research.fb.com/projects/fasttext/)는 원래 단어를 **부분단어(subword)**의 벡터들로 표현한다는 점을 제외하고는 Word2Vec과 거의 유사합니다. 노이즈가 많은 말뭉치에 강점을 지닌 것으로 알려져 있습니다.  ## 세 방법론의 한계 세 방법론이 '단어 동시 등장 정보'를 보존한다는 점을 논의했습니다. 그렇다면 이들 방법론에 한계점은 없는걸까요? 처음에 든 예시를 다시 들어보겠습니다. > 나는 ___에 간다 위 예시에서 빈칸에는 '학교', '집', '회사' 따위가 모두 들어갈 수 있습니다. '학교', '집', '회사'라는 단어가 위 예시 문장과 같은 경우에서만 쓰였다면 명백히 다른 단어임에도 불구하고 임베딩 벡터 공간에서 세 단어벡터의 유사도가 매우 높게 나타나게 됩니다.  물론 학습 말뭉치가 충분히 크다면 세 단어가 사용된 사례(문장)가 다양하기 때문에 '학교', '집', '회사' 벡터 간 거리가 충분히 멀게(코사인 유사도가 작게) 임베딩이 될 겁니다. 하지만 의미상 아무런 관련이 없어 보이는 단어임에도 벡터공간에 매우 가깝게 임베딩되는 사례가 자주 발생하는 것 같습니다.  한번 예를 들어보겠습니다. 아래는 클리앙, 뽑뿌 등 6개 사이트에서 스크랩핑한 휴대폰 리뷰 29만7906개로 구성된 말뭉치를 Word2Vec으로 임베딩한 결과입니다. 이후 '소프트웨어'라는 단어와 코사인 유사도가 가장 높은 단어 5개를 뽑아봤습니다. > 하드웨어, 0.75 > > OS, 0.68 > > os, 0.63 > > 운영체제, 0.63 > > 발적화, 0.62 'OS', '운영체제', '발적화' 같은 단어가 소프트웨어와 유사하다는 결과는 직관적으로 납득할 만하다고 생각합니다. 하지만 '하드웨어'가 '소프트웨어'랑 가장 비슷하다는 결과는 약간 받아들이기 힘듭니다. Word2Vec은 '하드웨어' 주변단어와 '소프트웨어' 주변단어들이 비슷한 분포를 보이기 때문에 이런 결과를 낸 것 같은데요. Word2Vec이 보존하려는 정보가 '동시등장 여부'이기 때문에 생기는 근본적인 한계가 아닐까 하는 생각이 듭니다.  ## 마치며 단어 벡터를 만들 때 등장 정보를 보존한다는 점에서는 Word2Vec, GloVe, Fast-text가 모두 기존 count 기반의 방법론과 본질적으로 다르지 않습니다. 다만 동시 등장 정보를 벡터로 표현한 결과(representation)가 [잠재의미분석(Latent Semantic Analysis)](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/06/pcasvdlsa/) 등 기존 대비 매우 개선됐기 때문에 최근 들어 크게 각광받고 있는 것 같습니다. 포스팅과 관련돼 의견 있으시면 언제든지 댓글, 메일로 주시면 좋을 것 같습니다. 여기까지 읽어주셔서 감사합니다.
bubblesort␞ 이번 글에서는 **버블정렬(bubble sort)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의와 위키피디아를 정리하였음을 먼저 밝힙니다. 파이썬 코드는 [이곳](http://interactivepython.org/courselib/static/pythonds/SortSearch/TheBubbleSort.html)을 참고하였습니다. 그럼 시작하겠습니다.   ## concepts 버블정렬은 가장 간단하지만 비효율적인 정렬 알고리즘입니다. 이미 정렬되어 있는 데이터에 적합한 기법입니다. 다음과 같은 숫자들에 버블정렬을 적용한다고 칩시다. > 4, 3, 5, 2 이를 배열에 담으면 다음과 같습니다. | index | 0  | 1  | 2  | 3  | | :---: | :--: | :--: | :--: | :--: | | value | 4  | 3  | `5` | `2` | 버블정렬은 오른쪽 끝에서 시작해 오름차순 정렬합니다. 우선 2와 5를 비교합니다(위 표). 왼쪽에 있는 5가 크므로 자리를 바꿔 줍니다(아래 표). | index | 0  | 1  | 2  | 3  | | :---: | :--: | :--: | :--: | :--: | | value | 4  | `3` | `2` | 5  | 이번엔 2와 3을 비교합니다(위 표). 왼쪽에 있는 3이 크므로 자리를 바꿔 줍니다(아래 표). | index | 0  | 1  | 2  | 3  | | :---: | :--: | :--: | :--: | :--: | | value | `4` | `2` | 3  | 5  | 이번엔 2와 4를 비교합니다(위 표). 왼쪽에 있는 4가 크므로 자리를 바꿔 줍니다(아래 표). 포인터가 다 돌았으므로 첫번째 *iteration*이 끝났습니다. | index | 0  | 1  | 2  | 3  | | :---: | :--: | :--: | :--: | :--: | | value | 2  | 4  | `3` | `5` | 이제는 정렬이 끝난 2를 제외하고, `4, 3, 5`를 정렬할 차례입니다. 오른쪽 끝 요소인 5와 3을 비교합니다(위 표). 왼쪽에 있는 3이 작으므로 자리를 바꿀 필요가 없습니다(아래 표). | index | 0  | 1  | 2  | 3  | | :---: | :--: | :--: | :--: | :--: | | value | 2  | `4` | `3` | 5  | 이번엔 3과 4를 비교합니다(위 표). 왼쪽에 있는 4가 크므로 자리를 바꿔 줍니다(아래 표). 이로써 두번째 *iteration*이 끝났습니다. | index | 0  | 1  | 2  | 3  | | :---: | :--: | :--: | :--: | :--: | | value | 2  | 3  | `4` | `5` | 이제는 정렬이 끝난 2와 3을 제외하고, `4, 5`를 정렬할 차례입니다. 마지막으로 5와 4를 비교합니다. 왼쪽에 있는 4가 작으므로 자리를 바꿀 필요가 없습니다. 이로써 모든 정렬이 끝났습니다.   ## 계산복잡성 버블정렬은 큰 원소가 앞쪽으로 이동하면서 마치 거품이 수면으로 올라오는 듯한 모습을 보이기 때문에 이러한 명칭이 붙은 것 같습니다. 정렬 대상 데이터가 $n$개일 때 비교횟수는 다음 표와 같습니다.  | *iteration* | 비교 횟수 | 위치 변경 최대 횟수 | | :---------: | :---: | :---------: | |   1   | $n-1$ |  $n-1$  | |   2   | $n-2$ |  $n-2$  | |   ...   | ... |   ...   | |  $n-2$  | $2$ |   $2$   | |  $n-1$  | $1$ |   $1$   |  버블정렬의 계산복잡성은 비교 횟수 + 위치변경 횟수에 비례합니다. 다음과 같습니다.  $$ \begin{align*} T\left( n \right) =&2\times\sum _{ i=1 }^{ n-1 }{ i } \\ =&2\times\frac { n\left( n-1 \right) }{ 2 } \\ =&O\left( { n }^{ 2 } \right) \end{align*} $$  배열이 모두 순서대로 정렬되어 있는 상태라면 비교만 수행할 뿐 위치변경을 하지 않아도 되기 때문에 조금 더 가벼워질 수는 있을 겁니다. 그러나 아래와 같이 단 하나의 값이라도 제 자리에 있지 않으면 *iteration*마다 위치 변경을 해주어야 하기 때문에 계산복잡성은 여전히 $O(n^2)$이 됩니다. 매우 비효율적입니다. > `6`, `1`, 2, 3, 4, 5 > > 1, `6`, `2`, 3, 4, 5 > > 1, 2, `6`, `3`, 4, 5 > > ...   ## 버블정렬의 특징 위 예시에서도 알 수 있듯 버블정렬은 정렬시 부가 메모리가 필요 없는 *inplace sort* 기법입니다. 아울러 두 값이 같으면 위치를 바꾸지 않기 때문에 *stable sort* 기법입니다.    ## 파이썬 구현 버블정렬의 파이썬 코드는 다음과 같습니다. ```python def bubbleSort(alist):   for passnum in range(len(alist)-1,0,-1):     for i in range(passnum):       if alist[i]>alist[i+1]:         temp = alist[i]         alist[i] = alist[i+1]         alist[i+1] = temp ``` 
words2␞ 이번 포스팅에선 한국어의 조사를 설명한 [지난 글](https://ratsgo.github.io/korean%20linguistics/2017/03/15/words/)에 이어 **어미(語眉)**에 대해 설명해 보려고 합니다. 그중에서도 문장 끝에 붙는 **종결어미**를 중심으로 이야기해보고자 합니다. 한국어 문장은 크게 **평서문, 의문문, 명령문, 청유문**으로 나뉘는데, 종결어미는 문장형을 나누고 **서법(敍法, mood)**을 나타내며 경어법을 관장하는 역할을 합니다. 이번 글 역시 한국어 문법론 대가 이익섭 서울대 명예교수께서 쓰신 ['한국어문법'](http://book.naver.com/bookdb/book_detail.nhn?bid=7028626)을 참고로 했습니다. 이 글의 목차는 다음과 같습니다.   * 목차 {:toc}   # 평서문 어미 ## -다/-는다-/-ㄴ다 **진술** '-다/는다'는 평서문 어미 중 가장 중립적인 어미입니다. 이 어미가 글에서 대표적인 어미로 쓰이는 이유이기도 합니다. 이 어미가 하는 일은 평서문을 진술(statement)해주는 역할입니다. > 날씨가 좋다. > > 한국 사람들은 설날에 떡국을 먹는다. **놀라움** 무엇을 새로 발견하고 스스로 감탄하거나 남에게 크게 외칠 때, 자신의 어떤 특별한 상황을 남에게 과시할 때 씁니다. > 와, 사람 한번 많다! > > 우리 내일 소풍 간다! **의문** > 월드컵도 다 끝났으니 내일부터는 무슨 재미로 산다? > > 그럴 것 없이 내가 간다?  ## -구나/-는구나 **새로운 지각** 어떤 사실을 좀더 여실히 진술하거나 아니면 새로이 지각하였음을 드러내 주는 데 쓰입니다. 대개 감탄 내지 놀라움의 뜻이 동반됩니다. > 오늘 날씨 정말 좋구나. > > 너도 커피를 마시는구나. **짐작** '어디', '무슨'과 같은 의문사와 함께 쓰이면 새로 지각한 사실을 '그런 줄 알겠다' 또는 '그렇게 짐작된다'는 투로 나타냅니다. > 너 어디 아프구나.  ## -군/는군 **새로운 지각 - 혼잣말** 새로 알게 된 일을 혼잣말로 할 때 쓰입니다. 놀라움이나 감탄의 뜻도 아울러 나타냅니다. > 그놈 참 신통하군. > > 올 한 해도 다 가는군. **혼잣말 아닌 '군'** 새로 지각한 사실이라는 의미를 지니면서도 혼잣말이 아닌 말로 쓰일 때도 있습니다. > 누군가 했더니 바로 자네였군. > > 그놈 참 신통하군요.  ## -네 새로 지각한 사실을 놀라움이나 감탄을 섞어 혼잣말로 할 때 쓰입니다. > 벌써 개구리가 나왔네. > > 어머나, 영수가 1등을 했네. **'-네'와 '-군'** 무엇을 새로 지각했다는 느낌, 놀라움이나 감탄도 '-네' 쪽이 더 강합니다. > 벌써 개구리가 나왔네. > > 벌써 개구리가 나왔군. **의문문의 '-네'** '-겠-'을 동반하고 그러리라고 추측되는 일에 대해 그것을 확인하기 위해 묻는 용법으로 쓰입니다. 이때에도 새로 지각했다는 의미는 유지됩니다. > 그러면 이번에도 네가 1등이겠네?  ## -으마/-마 청자에게 어떤 일을 그렇게 하겠다고 약속을 하는 의미를 나타내 줍니다. 낯선 사람 사이에서는 쓰기 어렵고 대개 손아래 사람에게 씁니다. > 내일 다시 오마.  ## -을걸/-ㄹ걸 추측이되 그러리라는 믿음이 있는 추측에 쓰입니다. > 벌써 다들 모였을걸.  ## -을게/ㄹ게, -을래/-ㄹ래 **-을게** 화자가 자기가 할 일에 대한 의지를 나타내 줍니다. 그 의지의 표명이 일종의 약속인 경우가 많습니다. > 내일 아침 일찍 올게. **-을래** 화자가 어떤 일이 하고 싶다는 의사를 나타내 줍니다. 의지의 표현이기보다 희망을 나타낸다고 볼 수 있습니다. 의문문에 쓰일 때는 상대방의 의사를 묻거나 야단치는 용법으로 쓰입니다. > 엄마, 나도 갈래. > > 나 좀 도와줄래? > > 정말 말 안들을래?  ## -을라/-ㄹ라, -는단다/-ㄴ단다/-단다/-란다 **-을라** 어떤 원하지 않는 사태가 벌어질 것을 염려하는 의미를 나타냅니다. 특히 손아래 상대방의 어떤 행동을 미리 경계하는 뜻으로 많이 쓰입니다. 대개 '-겠다'로 쉽게 바꿀 수 있으며 그렇게 해도 의미가 별로 달라지지 않습니다. > 체할라. 천천히 먹어라. **-는단다** '-다'가 풍기는 도식적인 분위기를 완화하여 가까운 손아래 사람에게 사근사근 얘기해주는 듯한 분위기를 만들어줍니다. > 그때 할아버지들은 맨발로 학교를 다녔단다.  # 의문문 어미 ## -으냐/-냐/-느냐, -으니/-니 '-냐'는 '-니'와 함께 의문문의 대표 어미입니다. 일반 대화에선 '-니'가 많이 쓰이고 글에까지 폭넓게 쓰이는 것은 '-냐'입니다. 전자는 청자를 가까이 두고 말하는 느낌인 반면 '-냐'는 어른이 점잖게 말한다는 분위기를 풍기기도 합니다. 둘은 자유롭게 넘나들면서 사용할 수 있지만 일부 제약이 있습니다. > 너 몇 살이냐(/살이니)? > > 얼마나 오래 사느냐(*사니)가 중요한 것이 아니라 어떻게 사느냐(\*사니)가 중요하다.  **-을까/-ㄹ까** 궁금한 것을 드러내는 데 쓰이되 혼잣말에 많이 사용됩니다. 상대방의 동의 여부를 물을 때에도 쓰입니다. > 나는 왜 밤낮 이 모양일까? > > (커피에)설탕 넣을까요?  ## -련 대개 '-겠니?'로 바꿔쓸 수 있는 자리에 쓰입니다. 청자에게 어떤 일을 해줄 의사가 있는지를 물으면서도 그러기를 권유하는 뜻도 있습니다. > 거기 창문 좀 열어 주련?  ## -으랴/-랴, -을쏘냐/-ㄹ쏘냐 **-으랴** 화자가 청자를 위해 어떤 일을 하고자 하면서 청자에게 동의를 묻는 의미로 쓰입니다. 추측되는 상황을 의문문 형식으로 바꾸어 감정적으로 표현하는 데에 쓰이기도 합니다. 속담, 격언 등에서 질문이 아니라 수사적인 효과를 위해 사용되기도 합니다. > 뭐 맛있는 것 사 주랴? > > 이제 와서 발버둥친들 무엇 하랴? > > 공든 탑이 무너지랴? **-을쏘냐** 글에만 쓰이되 그것도 시적인 표현에 한정돼 반어적 용법으로 쓰입니다. > 겉이 검다고 속조차 검을쏘냐?  ## -대, -담 **-대** 어떤 사태가 의외라는 느낌을 물을으로 나타내는 데 쓰입니다. 만족감이나 불만이 섞여 있습니다. > 나 오늘 기분이 왜 이렇게 좋대? > > 얘들이 왜 아직도 못 온대요? **-담** 어떤 사태가 마음에 들지 않아 불평조로 하는 말에 쓰입니다. 의문문에 쓰이나 자문하는 정도에 머무는 아주 가벼운 의문문입니다. > 이렇게 낡은 걸 어디다 쓴담? > > 뭐가 우스워 그리 웃는담?  # 명령문 어미 ## -아라/-어라/-여라 명령문의 간판 어미라 할 만합니다. 가장 전형적인 명령문에 쓰입니다. 부탁이나 허락, 감탄을 나타내기도 합니다. > 여기 좀 앉아라. (명령) > > 감기 조심하여라. (부탁) > > (내일 또 와도 돼요?) 그래, 언제든지 오너라. (허락) > > 아이 추워라. (감탄)  ## -으려무나/려무나, -으렴/-렴 부드러운 명령, 즉 허락에 가까운 상황에 잘 쓰입니다.  > 그렇게 갖고 싶으면 가지려무나. > > 언니만 탓하지 말고 네가 좀 참으려무나.  ## -소서 기원을 나타내며 일상어로는 잘 쓰이지 않습니다. > 부디 오래오래 행복을 누리소서.  # -아/-어, -지 반말체 어미인 '-아'와 '-지'는 어느 한 문장형에 한정되어 쓰이지 않고 평서문, 의문문, 명령문, 청유문 네 문장형에 두루 쓰입니다. 어느 문장형에 쓰이나 공통된 의미를 유지하기는 하나 다른 한편으로는 어느 문장형에 쓰이느냐에 따라 의미의 차이가 생기기도 합니다. ## -아/-어 반말체 어미 중 가장 중립적인 의미이면서 가장 널리 쓰이는 어미입니다. 청자를 가까이 두고 사용합니다. 놀라움 내지 긴박감을 나타내는 특별한 용법으로 쓰일 때도 있습니다. > 나도 가겠어. > > 어디 아파? > > 아이구 깜짝이야. ## -지 **확인질문** 말하려는 상황에 대해 화자나 청자가 이미 '알고 있다', '짐작되는 바가 있다', '그러리라 믿는다'와 같은 전제를 깔고 씁니다. 특히 의문문에서는 순수한 질문이라기보다는 동의해 줄 것을 기대하는 확인 질문의 성격을 띕니다. > 냉장고에 있던 아이스크림 네가 먹었지? **당연한 이야기** > 단풍이야 설악산이 제일이지. **근거있는 짐작** > 편지가 내일에는 오겠지.(/오겠지?) **부드러움** 부드러움을 얹어 권유하는 뜻으로도 쓰입니다. 물론 여기에도 '그렇게 해주리라는 걸 믿는다'는 전제가 깔림으로써 이러한 효과가 나타날 겁니다. > 우리랑 같이 가지. > > 꼼짝 말고 여기 있어! // ??꼼짝 말고 여기 있지! **화자의 의지** > 다 싫다면 내가 가지. **아쉬움** > 나도 좀 부르지.  # 후종결어미 종결어미 뒤에 덧붙어 쓰이는 어미입니다.  ## -고 다른 종결어미에 덧붙어 그 종결어미로 끝난 문장에 제시된 내용을 반문하는 일에 쓰입니다. 좀 의외라는, 또는 불만을 가지고 따지는 듯한 반응을 보이면서 묻는 점이 특징입니다. 혹은 의문문이 아닌 문장에서 종결어미로 끝난 문장에 제시된 내용을 강조하고 다른 말을 못하도록 다그치는 듯한 기능을 합니다. > 비가 온다고? > > 네가 반장이라고? > > 나도 한다면 하는 사람이라고.  ## -니까 '-고'의 의미와 매우 흡사하며 두 어미는 자유롭게 넘나들 수 있습니다. > 왜 벌써 돌아왔냐니까  ## -며, -면서 문장 내용을 청자에게 확인하기 위해 묻는 의미로 쓰입니다. '내가 그 사실을 아는데 사실이냐?'와 같은 의미입니다. 여러 문장형의 종결어미와 어울리면서도 의문문 어미와는 잘 어울리지 않습니다. > 어제 진호와 싸웠다며(/싸웠다면서)? > > *누가 진호와 싸웠냐며?  # 인용어미 ## -단다, -느냔다, -란다, -잔다 타인에게서 얻은 정보를 전달하는 데 쓰인다. > 날씨가 주말부터 풀린단다.(/풀린답니다./풀린다니?/풀린답니까?) ## -대 '-고 한다'의 반말체 어미입니다. 자기가 그런 뜻으로 한 말이 아니었다는 뜻으로도 쓰입니다. > 동대문 시장에 불이 났대. > > 누가 굶겠대?  # 1년치 조간신문의 종결어미 사용 빈도 이상으로 한국어의 종결어미에 관해 알아보았습니다. 조사와 마찬가지로 조선일보, 한겨레, 매일경제 등 10개 주요 조간신문의 2016년 1년치 기사 말뭉치에서 사용빈도를 따져봤습니다. 어미를 분석하려면 **Konlpy** 같은 기존 형태소 분석기로는 원천적으로 분석이 불가(동사 형용사 분석시 어미를 제거하고 기본형만 반환)합니다. 그래서 마침표(.)를 기준으로 문장을 나누고, 문장의 맨 마지막 단어의 맨 끝 음절부터 한글자씩 일일이 세었습니다. 분석 결과는 아래와 같습니다.  | 어미명 |  빈도  | | :--: | :----: | | 했다 | 870632 | | 이다 | 628043 | | 었다 | 232378 | | 니다 | 193316 | | 한다 | 165015 | | 지  | 141173 | | 았다 | 127454 | | 혔다 | 107056 | | 됐다 | 105218 | | 졌다 | 92395 | | 된다 | 91714 | | 였다 | 87645 | | 하다 | 81029 | | 요  | 65256 | | 는다 | 49518 | | 왔다 | 44777 | | 렸다 | 44658 | | 났다 | 40734 | | 인다 | 38357 | | 온다 | 34805 | | 진다 | 27153 | | 까  | 26145 | | 냈다 | 21457 |  보시다시피 뉴스 말뭉치의 종결어미는 '-다/-는다-/-ㄴ다'가 압도적으로 많습니다. 분석 대상인 2016년 1년치 기사 25만7973건 620만9892개 문장 가운데 '-다'로 끝나는 문장은 473만8770개로 전체의 76.3%나 됩니다. 말뭉치에 끼어있는 광고문구 등 일부 노이즈를 제거하면 그 비율은 더 높을 것으로 추정됩니다.  '-다'와 '했다'는 엄밀히 말해 분석 수준이 다르지만 '-다' 계열의 쓰임 양상을 구체적으로 드러내주기 위해 위와 같이 표를 작성했습니다. '-요', '-까'와 같은 어미를 제외하면 모두 '-다' 계열의 평서문 종결어미인 점을 확인할 수 있습니다.  조사 관련 글과 마찬가지로 형태소를 하나하나 정확히 분석한 결과는 아니니 경향성만 확인하는 용도로 보시면 좋을 것 같습니다. 의견이나 질문 있으시면 언제든 댓글이나 메일로 남겨주시기 바랍니다. 여기까지 읽어주셔서 감사드립니다.  
start␞ 이틀 간 기나긴 삽질 끝에 깃헙을 파고 드디어 블로그를 시작하게 됐다. jekyll을 이용한 블로그는 네이버나 티스토리 블로그에 비해 자유도가 높지만 진입장벽 또한 높아서 처음 세팅하는 데 무척 애를 먹었다. 공부한 내용들과 의문점들을 차곡차곡 적어나갈 계획이다. 일단은 자연언어처리, 머신러닝, 언어학 따위의 글들을 적을 것 같다. 초심을 잃지 말아야지.. 
quicksort␞ 이번 글에서는 **퀵 정렬(Quick Sort)** 알고리즘에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아를 정리하였음을 먼저 밝힙니다. 파이썬 코드 구현은 [이곳](https://github.com/TheAlgorithms/Python/blob/master/sorts/quick_sort.py)을 참고하였습니다. 그럼 시작하겠습니다.   ## 개념 퀵 정렬은 분할정복(divide and conquer) 방식으로 작동합니다. 그 절차는 다음과 같습니다. - 리스트 가운데서 하나의 원소를 고릅니다. 이를 피벗(pivot)이라 합니다. - 피벗 앞에는 피벗보다 작은 값, 뒤에는 큰 값이 오도록 하여 리스트를 둘로 분할합니다. - 분할된 두 개 리스트 각각에 재귀적으로 이 과정을 반복합니다.    ## 예시 다음과 같은 리스트를 정렬해보겠습니다. > [5, 3, 7, 6, 2, 1, 4] 첫번째 값(5)을 피벗으로 택해보겠습니다. (마지막 요소 4를 택해도 관계 없습니다) 이 값보다 작은 값들로만 구성된 리스트와 큰 값들로만 구성된 리스트 둘로 분할합니다. 이를 각각 *LESSOR*와 *GREATER*라고 명명해보겠습니다. > LESSOR = [3, 2, 1, 4] > > GREATER = [7, 6] 그리고 나서 LESSOR와 GREATER 각각에 같은 작업을 해당 리스트의 요소 개수가 하나가 될 때까지 재귀적으로 반복합니다.    ## 구현 퀵 정렬을 파이썬으로 구현한 코드는 다음과 같습니다. ```python def quick_sort(ARRAY):   ARRAY_LENGTH = len(ARRAY)   if( ARRAY_LENGTH <= 1):     return ARRAY   else:     PIVOT = ARRAY[0]     GREATER = [ element for element in ARRAY[1:] if element > PIVOT ]     LESSER = [ element for element in ARRAY[1:] if element <= PIVOT ]     return quick_sort(LESSER) + [PIVOT] + quick_sort(GREATER) ```   ## 계산복잡성 퀵 정렬의 계산복잡성은 피벗을 어떻게 선택하느냐에 따라 달라집니다. 최악의 경우는 다음과 같습니다. 다시 말해 피벗의 왼쪽(LESSOR) 요소가 매번 하나인 경우입니다. 이렇게 되면 높이가 $n$, 각 층에서 $n$개의 요소에 대해 정렬을 수행해야 하므로 $O(n^2)$의 계산복잡도를 가지게 됩니다.  <a href="https://imgur.com/v3xPU5E"><img src="https://i.imgur.com/v3xPU5E.png" width="200px" title="source: imgur.com" /></a> 가장 좋은 경우는 다음과 같습니다. 분할 과정이 다음과 같이 균형적이어서, 계산 트리의 높이가 $n$에서 $\log_2{n}$으로 줄어들게 되기 때문입니다. 이렇게 되면 높이가 $\log_2{n}$, 각 층에서 $n$개의 요소에 대해 정렬을 수행해야 하므로 $O(n\log_2{n})$의 계산복잡도를 가지게 됩니다.  <a href="https://imgur.com/hw72vWm"><img src="https://i.imgur.com/hw72vWm.png" width="350px" title="source: imgur.com" /></a>  Average case의 경우에도 퀵 정렬은 $O(n\log{n})$의 계산복잡도를 가진다고 합니다. 아울러 피벗을 선택할 때 정해진 위치가 아니라 랜덤하게 선택하거나, 몇 개 값을 랜덤 샘플링해 이 값들의 중앙값(median)에 가까운 값을 피벗으로 정하면 계산복잡도를 다소 낮추는 데 도움이 된다고 합니다.   ## 퀵 정렬의 특징 설명의 편의를 위해 피봇을 기준으로 작은 값을 왼쪽, 나머지를 오른쪽으로 보내는 과정을 재귀적으로 반복한다고 했습니다만, *original code*는 이보다는 살짝 더 복잡합니다. 정렬 수행 과정에서 별도 저장 공간을 필요로 하지 않는 *in-place sort*를 지향하고자 하기 때문인데요. *original code*의 수행 과정을 보시려면 [이곳](https://www.youtube.com/watch?v=tIYMCYooo3c&feature=share)을 참고하시면 좋을 것 같습니다. 수행과정을 도식화하면 다음 그림과 같습니다. 이 과정에서 같은 값의 상대적 위치가 바뀔 수 있습니다(*unstable sort*).  <a href="https://imgur.com/1BFdNBc"><img src="https://i.imgur.com/1BFdNBc.jpg" width="500px" title="source: imgur.com" /></a>
PCA␞ 이번 글에서는 **차원축소(dimensionality reduction)**와 **변수추출(feature extraction)** 기법으로 널리 쓰이고 있는 **주성분분석(Principal Component Analysis)**에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 강필성 교수님과 역시 같은 대학의 김성범 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 기법 개요 PCA는 데이터의 **분산(variance)**을 최대한 보존하면서 서로 직교하는 새 기저(축)를 찾아, 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간으로 변환하는 기법입니다. 이를 그림([출처](https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues))으로 나타내면 아래와 같습니다. 2차원 공간에 있는 데이터들이 하나의 주성분(PC1)을 새로운 기저로 선형변환된 걸 확인할 수 있습니다. 여기에서 핑크색 표시가 돼 있는 사선축이 원 데이터의 분산을 최대한 보존하는(=데이터가 가장 많이 흩뿌려져 있는) 새 기저입니다. PCA의 목적은 바로 이런 축을 찾는 데 있습니다. <a href="http://imgur.com/Uv2dlsH"><img src="http://i.imgur.com/Uv2dlsH.gif" width="600px" title="source: imgur.com" /></a>  ## Feature Extraction **변수추출(Feature Extraction)**은 기존 변수를 조합해 새로운 변수를 만드는 기법으로, 단순히 일부 중요 변수만을 빼내는 **변수선택(Feature Selection)**과는 대비됩니다. 변수추출에는 기존 변수 가운데 일부만 활용하는 방식이 있고, 모두 쓰는 방식이 있는데 PCA는 후자에 해당합니다. 아울러 PCA는 기존 변수를 **선형결합(linear combination)**해 새로운 변수를 만들어 냅니다.  예컨대 PCA는 변수가 $p$개, 관측치가 $n$개 있는 데이터 $X$(p x n)로 새로운 변수 $z$를 아래와 같이 만드는 과정으로 이해하면 좋을 것 같습니다. 여기에서 벡터 $x_i$는 데이터 행렬 $X$의 $i$번째 변수에 해당하는 행벡터(1 x n)인데요, 이들을 적절히 조합해 새로운 벡터 $z_i$ (1 x n)들을 만들어내는 것입니다.   $$ \begin{align*} \overrightarrow { { z }_{ 1 } } &={ \alpha }_{ 11 }\overrightarrow { { x }_{ 1 } } +{ \alpha }_{ 12 }\overrightarrow { { x }_{ 2 } } +...+{ \alpha }_{ 1p }\overrightarrow { { x }_{ p } } ={ \overrightarrow { { \alpha }_{ 1 } } }^{ T }X\\ \overrightarrow { { z }_{ 2 } } &={ \alpha }_{ 21 }\overrightarrow { { x }_{ 1 } } +{ \alpha }_{ 22 }\overrightarrow { { x }_{ 2 } } +...+{ \alpha }_{ 2p }\overrightarrow { { x }_{ p } } ={ \overrightarrow { { \alpha }_{ 2 } } }^{ T }X\\ &...\\ \overrightarrow { { z }_{ p } } &={ \alpha }_{ p1 }\overrightarrow { { x }_{ 1 } } +{ \alpha }_{ p2 }\overrightarrow { { x }_{ 2 } } +...+{ \alpha }_{ pp }\overrightarrow { { x }_{ p } } ={ \overrightarrow { { \alpha }_{ p } } }^{ T }X \end{align*} $$  사실 위와 같은 식의 선형결합은 **선형변환**으로도 이해할 수 있습니다. 바꿔 말하면 벡터 $z_i$는 $X$를 $α_i$( p x 1)라는 새로운 축에 **사영(projection)**시킨 결과물이라는 것이죠. 선형변환에 대해 살펴보시려면 [이곳](https://ratsgo.github.io/linear%20algebra/2017/03/24/Ldependence/)을, 사영에 대해 보시려면 [이곳](https://ratsgo.github.io/linear%20algebra/2017/10/20/projection/) 방문을 권해 드립니다. 어쨌든 변수추출로 새롭게 만들어진 $z_i$로 구성된 행렬 $Z$는 아래와 같이 적을 수 있습니다.  $$ Z=\begin{bmatrix} \overrightarrow { { z }_{ 1 } } \\ \overrightarrow { { z }_{ 2 } } \\ ... \\ \overrightarrow { { z }_{ p } } \end{bmatrix}=\begin{bmatrix} { \overrightarrow { { \alpha }_{ 1 } } }^{ T }X \\ { \overrightarrow { { \alpha }_{ 2 } } }^{ T }X \\ ... \\ { \overrightarrow { { \alpha }_{ p } } }^{ T }X \end{bmatrix}=\begin{bmatrix} { \overrightarrow { { \alpha }_{ 1 } } }^{ T } \\ { \overrightarrow { { \alpha }_{ 2 } } }^{ T } \\ ... \\ { \overrightarrow { { \alpha }_{ p } } }^{ T } \end{bmatrix}X={ A }^{ T }X $$   ## PCA의 목적과 solution 위 식에서 각 변수와 결합하는 계수들만 알면 PCA를 수행할 수 있게 됩니다. 앞서 설명드렸듯이 PCA의 목적은 원데이터 행렬 $X$의 분산을 최대한 보존하는 데 있기 때문에 $Z$의 분산 또한 최대화되어야 합니다. 그럼 우리가 알고 싶은 미지수인 $p$차원 계수벡터를 $α$, $X$의 **공분산행렬(covariance matrix)**을 $Σ$로 둡시다. 그럼 아래와 같이 식을 쓸 수 있습니다.  $$ \begin{align*} \max _{ \alpha }{ \{ Var(Z)\} } &=\max _{ \alpha }{ \{ Var({ \overrightarrow { \alpha } }^{ T }X)\} } \\ &=\max _{ \alpha }{ \{ { \overrightarrow { \alpha } }^{ T }Var(X)\overrightarrow { \alpha } \} } \\ &=\max _{ \alpha }{ \{ { \overrightarrow { \alpha } }^{ T }\Sigma \overrightarrow { \alpha } \} } \end{align*} $$ 위 식을 만족하는 $α$는 무수히 많을 수 있습니다. 사실 $α$의 크기를 무작정 키우기만 해도 $Z$의 분산을 높일 수가 있게 되거든요. 이 때문에 아래와 같은 제약식을 둡니다.  $$ \left\| \alpha \right\| ={ \overrightarrow { \alpha } }^{ T }\overrightarrow { \alpha } =1 $$  이를 종합해 **라그랑지안 문제**로 변형하겠습니다.  $$ L={ \overrightarrow { \alpha } }^{ T }\Sigma \overrightarrow { \alpha } -\lambda ({ \overrightarrow { \alpha } }^{ T }\overrightarrow { \alpha } -1) $$  최대값을 구하기 위해 $L$을 미지수 $α$로 미분한 식을 0으로 두어 정리하면 아래와 같습니다.  $$ \begin{align*} \frac { \partial L }{ \partial \overrightarrow { \alpha } } =\Sigma \overrightarrow { \alpha } -\lambda \overrightarrow { \alpha } &=0\\ (\Sigma -\lambda )\overrightarrow { \alpha } &=0 \end{align*} $$  **고유벡터(eigenvector)**의 정의에 의해 $α$는 데이터의 공분산행렬 $Σ$의 고유벡터, $λ$는 $Σ$의 고유값이 됩니다. 따라서 원데이터 $X$의 분산을 최대화하는 $α$는 $Σ$의 고유벡터라는 사실을 알 수 있습니다. $Σ$의 고유벡터를 **주성분(Principal Component)**이라고 합니다. 한편 공분산행렬은 **비특이행렬(non-singular matrix)**로 고유값과 고유벡터의 개수가 차원수($p$)만큼 존재한다고 합니다.   ## 공분산행렬 고유벡터의 성질 데이터가 각 변수별로 평균이 0으로 맞춰져 있을 때(centering 작업 이미 수행되어 있다고 가정) 데이터 $X$의 공분산 행렬 $Σ$는 아래와 같이 구합니다.  $$ \Sigma=cov(X)=\frac { 1 }{ n-1 } { X }^{ T }X\propto { X }^{ T }X $$  $X$의 차원수가 p x n이라면, 공분산행렬 $Σ$은 n x n 크기의 **정방행렬(square matrix)**이 됩니다. 또한 $Σ^T=Σ$인 **대칭행렬(symetric matrix)**입니다.  열벡터가 공분산행렬 $Σ$의 고유벡터인 행렬을 $A$, 대각성분이 $Σ$의 고유값이고 대각성분을 제외한 요소값이 0인 행렬을 $Λ$라고 할 때 다음과 같이 식을 쓸 수 있습니다.  $$ \Sigma A=\Lambda A\\ \Sigma =A\Lambda { A }^{ -1 } $$  $Σ$는 대칭행렬이므로 식을 다음과 같이 정리할 수 있습니다.  $$ \begin{align*} { \Sigma }^{ T }=&{ \left( { A }^{ -1 } \right) }^{ T }\Lambda { A }^{ T }\\ =&A\Lambda { A }^{ -1 }=\Sigma \\ \\ \therefore &{ A }^{ -1 }={ A }^{ T } \\ &{ A }^{ T }A=I \end{align*} $$  따라서 공분산행렬 $Σ$의 서로 다른 고유벡터끼리는 서로 **직교(orthogonal)**함을 확인할 수 있습니다. 원데이터를 공분산 행렬의 고유벡터로 사영하기 전에는 변수 간 연관성이 있었더라도 PCA 변환에 의하여 좌표축이 바뀐 데이터들은 서로 **무상관(uncorrelated)**이게 됩니다.    ## 고유값과 새 변수의 분산 $Σ$는 원데이터 $X$의 공분산행렬이고, $Σ$의 가장 큰 고유값과 고유벡터를 각각 $λ_1$, $α_1$이라고 두겠습니다. 이 둘로 만든 새로운 변수 $z_1$와 그 분산은 아래와 같이 쓸 수 있습니다.  $$ \begin{align*} \overrightarrow { { z }_{ 1 } } &={ \overrightarrow { { \alpha }_{ 1 } } }^{ T }X\\ Var(\overrightarrow { { z }_{ 1 } } )&={ \overrightarrow { { \alpha }_{ 1 } } }^{ T }\Sigma \overrightarrow { { \alpha }_{ 1 } } \end{align*} $$  고유벡터의 정의에 의해 아래와 같은 식이 성립합니다.  $$\Sigma \overrightarrow { { \alpha }_{ 1 } } ={ \lambda }_{ 1 }\overrightarrow { { \alpha }_{ 1 } } $$  이를 원식에 대입하고, $α$를 **단위벡터**로 정한 제약식을 원용해 정리하면 다음과 같습니다.  $$ \begin{align*} Var({ z }_{ 1 })&={ \overrightarrow { { \alpha }_{ 1 } } }^{ T }\Sigma \overrightarrow { { \alpha }_{ 1 } } \\ &={ { \overrightarrow { { \alpha }_{ 1 } } }^{ T }\lambda }_{ 1 }\overrightarrow { { \alpha }_{ 1 } } \\ &={ \lambda }_{ 1 }{ \overrightarrow { { \alpha }_{ 1 } } }^{ T }\overrightarrow { { \alpha }_{ 1 } } \\ &={ \lambda }_{ 1 } \end{align*} $$  요컨대 $Σ$의 제1 고유벡터로 만든 새로운 변수 $z_1$의 분산은 그에 해당하는 고유값 $λ_1$이라는 뜻입니다.  이를 확장하여 $Σ$의 $i$번째로 큰 고유값과 고유벡터를 각각 $λ_i$, $α_i$이라고 둡시다. 이들로 만든 새로운 변수 $z_i$의 분산은 그에 해당하는 고유값 $λ_i$가 됩니다. 따라서 $Σ$의 고유값 전체 합과 원데이터 $X$의 분산은 서로 같습니다.   ## PCA 예제 1 다음과 같은 데이터 $X$가 주어졌다고 합시다. 변수는 3개, 관측치는 5개로 구성된 데이터입니다.  | 구분  | $n_1$ | $n_2$ | $n_3$ | $n_4$ | $n_5$ | | :---: | :---: | :---: | :---: | :---: | :---: | | $x_1$ | 0.2 | 0.45 | 0.33 | 0.54 | 0.77 | | $x_2$ | 5.6 | 5.89 | 6.37 | 7.9 | 7.87 | | $x_3$ | 3.56 | 2.4 | 1.95 | 1.32 | 0.98 |  우선 변수(행)별로 평균을 0으로 centering한 행렬 $X'$를 만듭니다.  | 구분  | $n_1$ | $n_2$ | $n_3$ | $n_4$ | $n_5$ | | :---: | :-----: | :-----: | :-----: | :-----: | :-----: | | $x_1$ | -1.1930 | -0.0370 | -0.5919 | 0.3792 | 1.4427 | | $x_2$ | -1.0300 | -0.7647 | -0.3257 | 1.0739 | 1.0464 | | $x_3$ | 1.5012 | 0.3540 | -0.0910 | -0.7140 | -1.0502 |  $X$의 공분산행렬은 다음과 같이 구할 수 있습니다. ($n=5$)  $$ \begin{align*} \Sigma =cov(X)&=\frac { 1 }{ n-1 } X'{ X' }^{ T }\\\\ &=\begin{bmatrix} 0.0468 & 0.1990 & -0.1993 \\ 0.1990 & 1.1951 & -1.0096 \\ -0.1993 & -1.0096 & 1.0225 \end{bmatrix} \end{align*} $$  $Σ$를 고유분해한 결과는 아래와 같습니다. 행렬 $A$는 각각의 열벡터가 $Σ$의 고유벡터로 구성돼 있습니다. 대각행렬 $Λ$는 각각의 대각원소가 $Σ$의 고유값입니다. $λ_1(2.7596)$에 대응하는 고유벡터는 $α_1$($[0.5699,0.5765,-0.5855]^T$)입니다.   $$ \begin{align*} \Sigma A&=A\Lambda \\\\ A&=\begin{bmatrix} \overrightarrow { { \alpha }_{ 1 } } & \overrightarrow { { \alpha }_{ 2 } } & \overrightarrow { { \alpha }_{ 3 } } \end{bmatrix}\\ &=\begin{bmatrix} 0.5699 & 0.7798 & 0.2590 \\ 0.5765 & -0.6041 & 0.5502 \\ -0.5855 & 0.1643 & 0.7938 \end{bmatrix}\\\\ \Lambda &=\begin{bmatrix} { \lambda }_{ 1 } & 0 & 0 \\ 0 & { \lambda }_{ 2 } & 0 \\ 0 & 0 & { \lambda }_{ 3 } \end{bmatrix}\\ &=\begin{bmatrix} 2.7596 & 0 & 0 \\ 0 & 0.1618 & 0 \\ 0 & 0 & 0.0786 \end{bmatrix} \end{align*} $$  그렇다면 우리는 여기에서 가장 큰 고유값에 해당하는 고유벡터로 새로운 변수 $z_1$을 만들 수 있습니다. 아래 식에서 $x_1, x_2, x_3$은 각각 $X'$의 행벡터이고, 이 벡터들 앞에 붙는 계수는 해당하는 고유벡터의 요소값입니다.  $$ \begin{align*} \overrightarrow { { z }_{ 1 } } &={ \overrightarrow { { \alpha }_{ 1 } } }^{ T }X\\ \\ &=\begin{bmatrix} 0.5699 & 0.5765 & -0.5855 \end{bmatrix}\begin{bmatrix} \overrightarrow { { x }_{ 1 } } \\ \overrightarrow { { x }_{ 2 } } \\ \overrightarrow { { x }_{ 3 } } \end{bmatrix}\\ \\ &=0.5699\overrightarrow { { x }_{ 1 } } +0.5765\overrightarrow { { x }_{ 2 } } -0.5855\overrightarrow { { x }_{ 3 } } \\ &=0.5699\begin{bmatrix} -1.1930 & -0.0370 & -0.5919 & 0.3792 & 1.4427 \end{bmatrix}\\ &\quad+0.5765\begin{bmatrix} -1.0300 & -0.7647 & -0.3257 & 1.0739 & 1.0464 \end{bmatrix}\\ &\quad-0.5855\begin{bmatrix} 1.5012 & 0.3540 & -0.0910 & -0.7140 & -1.0502 \end{bmatrix}\\ &=\begin{bmatrix} -2.1527 & -0.6692 & -0.4718 & 1.2533 & 2.0404 \end{bmatrix} \end{align*} $$  여기에서 $z_1$의 첫번째 요소(스칼라) -2.1527의 의미를 곱씹어봅시다. 원데이터의 첫번째 데이터($n_1$)는 [-1.930, -1.0300, 1.5012]였습니다. 이 $n_1$이 첫번째 고유벡터 $α_1$과 내적된 결과가 바로 -2.1527입니다. 축에 해당하는 벡터가 유닛벡터일 때 벡터의 내적과 사영은 동일한 의미를 지닙니다. 따라서 -2.1527은 $n_1$을 $α_1$라는 축에 사영해 $α_1$에서 어디쯤 위치하는지 나타내주는 스칼라값이라고 보면 좋을 것 같습니다. 이를 그림으로 나타내면 다음과 같습니다.  <a href="https://imgur.com/QCncDRd"><img src="https://i.imgur.com/QCncDRd.png" width="400px" title="source: imgur.com" /></a>  $z_1$의 두번째 요소 -0.6692는 원데이터의 두번째 데이터 $n_2$를 $α_1$라는 축에 사영한 결과로 볼 수 있습니다. 마찬가지 방식으로 $z_2, z_3$을 만들어 $Z$를 계산할 수 있습니다.  $$Z={ A }^{ T }X\\\\ \begin{bmatrix} \overrightarrow { z_{ 1 } } \\ \overrightarrow { z_{ 2 } } \\ \overrightarrow { z_{ 3 } } \end{bmatrix}=\begin{bmatrix} { \overrightarrow { \alpha _{ 1 } } }^{ T } \\ { \overrightarrow { \alpha _{ 2 } } }^{ T } \\ { \overrightarrow { \alpha _{ 3 } } }^{ T } \end{bmatrix}X=\begin{bmatrix} -2.1527 & -0.6692 & -0.4718 & 1.2533 & 2.0404 \\ -0.0615 & 0.4912 & -0.2798 & -0.4703 & 0.3204 \\ 0.3160 & -0.1493 & -0.4047 & 0.1223 & 0.1157 \end{bmatrix}$$  그러면 $Z$의 공분산행렬을 구해보겠습니다. 아래와 같습니다.  $$ cov(Z)=\begin{bmatrix} 2.7596 & 0 & 0 \\ 0 & 0.1618 & 0 \\ 0 & 0 & 0.0786 \end{bmatrix} $$  보시다시피 새 변수 $z_1, z_2, z_3$ 사이에 공분산이 0이어서 **무상관(uncorrelated)** 관계가 된 것을 확인할 수 있습니다. 이는 $Σ$의 고유벡터는 서로 직교하는데, $X$가 이 고유벡터를 새로운 축, 즉 주성분으로 하여 선형변환되었기 때문입니다. 아울러 앞선 증명에서 살펴보았든 $z_1$의 분산은 $λ_1$이라는 사실 또한 확인할 수 있습니다. 만약 새 변수로 $z_1$만 남기고 나머지를 생략하게 된다면 아래 식과 같이 원데이터 $X$ 분산의 92%를 보존하면서도 원데이터를 3차원에서 1차원으로 줄일 수 있게 됩니다. 다시 말해 3개 주성분 가운데 첫번째 주성분(PC1)을 선택해도 원데이터의 설명력을 어느 정도 보존할 수 있다는 이야기입니다.  $$ \frac { { \lambda }_{ 1 } }{ { \lambda }_{ 1 }+{ \lambda }_{ 2 }+{ \lambda }_{ 3 } } =\frac { 2.7596 }{ 2.7596+0.1618+0.0786 } =0.920 $$   ## loading plot PCA는 기존 변수를 선형결합하는 과정에서 새 변수를 만들게 되는데요, 선형결합의 계수들을 가지고 시각화를 하면 각 변수별로 중요도를 어림짐작할 수 있습니다. <a href="http://imgur.com/GbxmCRV"><img src="http://i.imgur.com/GbxmCRV.png" width="400px" title="source: imgur.com" /></a> 위 그림의 가로축은 가장 큰 고유값에 해당하는 주성분(PC1)의 계수를 뜻합니다. 세로축은 두번째 주성분(PC2)의 계수입니다. 여기에서 기존 변수 $x_2$는 PC1을 만들 때 상대적으로 중요하지만, PC2에는 그렇지 않음을 알 수 있습니다. $x_3$는 반대로 PC1에는 덜 중요하고, PC2에는 중요함을 알 수 있습니다.    ## PCA 예제 2 이번엔 R로 분석하는 예제를 소개합니다. 내장 데이터인 iris를 대상으로 PCA를 적용해 보기로 했습니다. PCA를 수행한 뒤 **summary** 함수를 쓰면 아래와 같은 표를 얻을 수 있습니다. iris의 독립변수는 네 개이므로 PCA를 수행하면 네 개의 주성분을 얻을 수 있고, 각 축이 전체 데이터의 분산에서 차지하는 비율을 의미합니다.  | 구분  |  PC1  |  PC2  |  PC3   |   PC4   | | :---: | :-------: | :-------: | :--------: | :---------: | | 변수 비율 | 0.7296245 | 0.2285076 | 0.03668922 | 0.005178709 | **2D Score Plot**을 그리면 아래 그림과 같습니다. PC1, PC2 두 개만으로도 전체 데이터 분산의 95.8%를 보존하고 있기 때문에 2차원으로 시각화해도 원 데이터의 모양을 파악하는 데 문제가 없습니다. <a href="http://imgur.com/zGXr2nT"><img src="http://i.imgur.com/zGXr2nT.png" width="300px" title="source: imgur.com" /></a>loading plot은 아래 그림과 같습니다. PC1 기준으로는 'Petal.Length', 'Petal.Width', 'Sepal.Length'가 비교적 중요한 변수임을 확인할 수 있습니다. PC2 입장에서는 'Sepal.Width'가 중요한 변수입니다. <a href="http://imgur.com/NyrHZ9Y"><img src="http://i.imgur.com/NyrHZ9Y.png" width="500px" title="source: imgur.com" /></a> 위 분석에 사용한 R 코드는 아래와 같습니다. ```R library(rgl) library(devtools) install_github("vqv/ggbiplot") library(ggbiplot) # PCA # cor = whether the calculation should use the correlation matrix or the covariance matrix # score = whether the score on each principal component should be calculated pcadata <‐ princomp(iris[,1:4], cor=T, scores=T) # summary plot(pcadata, type='l') summary(pcadata) # 2d score plot ggbiplot(pcadata,groups = iris$Species) # loading plot plot(pcadata$loadings[,1:2], col=c('black','blue','red','green'), pch=16) legend('topleft', 	 c('Sepal.Length','Sepal.Width','Petal.Length','Petal.Width'),   text.col=c('black','blue','red','green')) ```   ## PCA의 절차 지금까지 논의한 내용을 바탕으로 PCA 수행절차를 정리하면 다음과 같습니다. 1. 기존 데이터 $X$의 공분산행렬 계산 2. 공분산행렬의 고유값과 고유벡터 계산 3. 고유값의 크기 순서대로 고유벡터를 나열 4. 정렬된 고유벡터 가운데 일부 선택 5. 해당 고유벡터와 $X$ 내적 PCA는 서로 직교하는 새 기저로 데이터를 변환하기 때문에 변수 간 상관관계가 높은 데이터에 효과가 좋다고 합니다. 데이터 차원축소, 압축에 널리 쓰이고 있습니다.
LM␞ 이번 글에서는 유니그램 모델(unigram model)을 중심으로 **통계적 언어모델(Statistical Language Model, 언어모델)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 정순영 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 정의 언어모델이란 단어 시퀀스에 대한 **확률분포(probability distribution)**를 가리킵니다. 언어모델은 $m$개 단어가 주어졌을 때 $m$개 단어 시퀀스가 나타날 확률, 즉 $P(w_1, w_2, ..., w_m)$을 할당(assign)합니다. 예컨대 다음과 같습니다. > (1) $P(Today\ is\ Wednesday)=0.001$ > > (2) $P(Today\ Wednesday\ is)=0.0000000001$ 언어모델은 **context-dependent** 성격을 지닙니다. 일상적인 대화 말뭉치로 언어모델을 구축했다면 일상 대화가, 수학 컨퍼런스의 말뭉치로 언어모델을 구축했다면 수식 표현이 나타날 확률이 클 겁니다. 다시 말해 언어모델은 학습데이터에 민감합니다.   ## 언어모델의 이점 자연언어에는 기본적으로 불확실성(uncertainties)이 존재합니다. 그런데 언어모델은 이러한 불확실성을 단어 시퀀스의 출현 확률로 정량화(quantify)할 수 있는 장점을 가집니다. 예컨대 언어모델의 힘을 빌리면 앞선 예제에서 **(1)이 나타날 확률은 (2)보다 $10^7$배 크다**고 '숫자'로 말할 수 있게 됩니다. 언어모델이 주어지면, 우리는 확률분포를 가지고 단어의 시퀀스를 뽑을 수(sample) 있습니다. 다시 말해 해당 언어모델로 텍스트를 생성(generation)해낼 수 있다는 뜻입니다. 이런 취지에서 언어모델은 종종 **생성모델(generative model)**이라고도 불리는데요.  예컨대 'John'이라는 단어와 'feels'라는 단어가 주어졌다고 칩시다. 그러면 그 다음 단어는 'happy'일 가능성이 높을까요? 아니면 'habit'일 확률이 클까요? 사실 'happy'와 'habit'은 말소리가 비슷하지만, 언어모델의 힘을 빌리면 그 확률이 높은 'happy'를 뽑게 됩니다. 응답(answer) 생성에 도움이 된다는 이야기입니다.   ## 유니그램 언어모델 가장 단순한 언어모델은 **유니그램 언어모델(unigram language model)**입니다. 각 단어가 서로 독립(independent)이라고 가정합니다. $n$개 단어가 동시에 나타날 확률은 다음과 같습니다.  $$ P\left( { w }_{ 1 },{ w }_{ 2 },...,{ w }_{ n } \right) =\prod _{ i=1 }^{ n }{ P\left( { w }_{ i } \right) } $$  유니그램 모델에서는 단어의 시퀀스를 고려한다기보다는 단어 셋(set)을 상정한다는 것이 더 정확한 표현입니다. 단어 시퀀스의 등장확률이 각 단어 발생확률의 곱으로 정의돼 있기 때문입니다. 다시 말해 각 단어의 등장 순서가 바뀌어도 개별 단어 확률의 곱은 변하지 않는다는 이야기입니다.  유니그램 모델은 다음과 같은 테이블로 구성됩니다. 학습말뭉치에 등장한 각 단어 빈도를 세어서 전체 단어수로 나누어준 것입니다. 물론 확률의 총합은 1이 됩니다. |  단어 $w$  | 확률 $P(w$\|$θ_2)$ | | :---------: | :--------------: | |  text   |    0.2    | |  mining  |    0.1    | | association |    0.01    | | clustering |    0.02    | |   ...   |    ...    | |  food   |   0.00001   | |  total  |    1     | 텍스트마이닝 논문 말뭉치로 학습한, 위와 같은 유니그램 모델 $θ_1$이 주어진 상황에서 'text'와 'mining', 'clustering'이라는 세 개 단어로 구성된 첫번째 문서 $D$의 출현확률을 구해보겠습니다.   $$ \begin{align*} P\left( D|{ \theta }_{ 1 } \right) &=P\left( text\quad mining\quad clustering|{ \theta }_{ 1 } \right) \\ &=P\left( text|{ \theta }_{ 1 } \right) \times P\left( mining|{ \theta }_{ 1 } \right) \times P\left( clustring|{ \theta }_{ 1 } \right) \\ &=0.2\times 0.1\times 0.02=0.0004 \end{align*} $$  유니그램 모델에서는 말뭉치 등장 빈도가 높은 단어가 많이 포함된 문서일 수록 해당 문서의 출현확률이 높아집니다. 바꿔 말해 등장빈도 높은 단어를 해당 문서의 주제(topic)으로 볼 여지가 있다는 얘기입니다. 위 예시에선 'text'를 $D$의 주제로 볼 수도 있습니다. 아울러 당연한 이야기겠지만, 만일 다른 단어로 구성된 문서가 존재한다면 이 유니그램 모델은 해당 문서에 다른 확률을 할당하게 될 겁니다.  이번에는 건강/식이요법 관련 논문 말뭉치로 학습한, 유니그램 모델 $θ_2$가 아래처럼 주어졌다고 가정해 보겠습니다. 그렇다면 $P(D$\|$θ_1)>P(D$\|$θ_2)$일 겁니다. 같은 단어로 구성된 문서라도 모델이 다르면 그 확률값이 크게 달라지게 됩니다(context-dependent). | 단어 $w$  | 확률 $P(w$\|$θ_2)$ | | :-------: | :--------------: | |  food  |    0.25    | | nutrition |    0.1    | | healthy |    0.05    | |  diet  |    0.02    | |  ...  |    ...    | |  text  |   0.00001   | |  total  |    1     |   ## 최대우도추정 언어모델 $θ$를 학습한다는 것은 각각의 단어 $w$의 등장확률을 추정(estimate)한다는 의미입니다. 다시 말해 위와 같은 단어-확률 테이블을 만드는 과정이라고 볼 수 있습니다. 그런데 문제는 우리에게 주어진 데이터(말뭉치)가 모집단 전체를 포괄하는 게 아니라 일부라는 점이라는 사실입니다. 데이터 확보에 한계가 있기 때문입니다. 한정적인 데이터를 바탕으로 그럴듯한 언어모델 $θ$를 추정해내는 것이 관건이 되겠습니다. 통계학에서 모수(파라메터)를 추정하는 데에는 여러가지 기법이 있습니다. 이 가운데 가장 많이 쓰이는 것이 바로 최대우도추정량(the maximum likelihood estimator)입니다. 우도($θ$가 주어졌을 때 관측치가 나타날 확률)를 최대로 만드는(=데이터를 가장 잘 설명하는) 모수 $θ$를 선택하는 것입니다. 바꿔 말해 관측치들이 $θ$라는 분포에서 샘플링됐다고 가정하고, 이를 바탕으로 $θ$를 추정하는 방법인데요. 결과(데이터)를 보고 원인($θ$)을 추정하는 방법이라고 이해하면 좋을 것 같습니다.  우리가 가지고 있는 말뭉치가 $D$, 우리가 추정하려는 언어모델이 $θ$라고 할 때 최대우도추정량은 다음과 같습니다.  $$ \hat { \theta } =arg\max _{ \theta }{ P\left( { D }|{ \theta } \right) } $$  유니그램 모델의 경우 적당한 수식 정리 과정을 거치면 단어 $w$의 우도 $P(w$\|$θ)$가 다음과 같을 때 전체 단어 우도의 곱이 최대가 됩니다. $c(w, D)$는 말뭉치 $D$에 있는 단어 $w$의 빈도, \|$D$\|는 말뭉치 $D$의 전체 단어 개수(중복 포함)입니다.  $$ P\left( { w }|{ \hat { \theta } } \right) =\frac { c\left( w,D \right) }{ \left| D \right| } $$   ## 언어모델의 한계와 극복 노력 언어모델의 단점은 학습말뭉치에 존재하지 않는 단어의 경우 그 확률이 0이 되어 문제가 됩니다. 이미 언급했던 것처럼 학습말뭉치에 의존적이기 때문에 범용적인 모델을 구축하기가 어렵습니다. 아울러 조사, 어미 등 기능적 단어(functional words, 영어의 경우 관사 등)가 우리가 관심이 있는 주제 단어(topic words)보다 훨씬 빈도가 높아 원하는 결과를 내기가 쉽지 않을 수 있습니다.  이같은 문제를 극복하기 위해 평탄화(smoothing) 등 다양한 기법이 제안됐는데요, 그 중 한 가지 방식은 다음과 같습니다.  <a href="https://imgur.com/bVp9A0X"><img src="https://i.imgur.com/bVp9A0X.png" width="500px" title="source: imgur.com" /></a>  
fasttext␞ 이번 글에서는 페이스북에서 개발한 **FastText**를 실전에서 사용하는 방법에 대해 살펴보도록 하겠습니다. FastText는 구글에서 개발한 **Word2Vec**을 기본으로 하되 부분단어들을 임베딩하는 기법인데요. 임베딩 기법과 관련 일반적인 내용은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/11/embedding/)을 참고하시면 좋을 것 같습니다.  ## 함수 설치하기 FastText는 파이썬 gensim 패키지 내에 포함돼 주목을 받았는데요. 이상하게 제 컴퓨터 환경에서는 지속적으로 에러가 나서, 저는 페이스북에서 제공하는 C++ 기반 버전을 사용하였습니다. 이 블로그는 이 버전을 기준으로 설명할 예정입니다. 어쨌든 아래와 같은 터미널 명령어로 fastText를 내려받아 컴파일하면 바로 사용할 수 있는 상태가 됩니다. ```python # 설치하고자 하는 디렉토리에서 다음을 실행 $ git clone https://github.com/facebookresearch/fastText.git $ cd fastText $ make ``` *이 버전은 Mac OS와 Linux 환경에서만 실행 가능합니다*  ## 입력값 준비 FastText의 입력값은 utf-8 인코딩 기반의 텍스트 파일입니다. 라인(line) 하나당 하나의 문서가 되도록 저장해 두면 됩니다. 맥을 쓰는 저는 데스크탑 폴더 밑에 fasttext 폴더를 만들어 여기에 실행파일들을 컴파일 해놓고, 데스크탑 폴더엔 다음과 같은 영화 리뷰를 'kor'라는 이름으로 저장해 두었습니다. > 미친놈을 동경하는 이유 > > 울었다 웃었다 종 잡을 수 없지만 끝나고 나면 2편을 찾게 되는 영화 > > ... > > 어설픈북한말투 일본해표기 이제는 진짜 약빨았나 싶은 두콤비세스와 프랭코 김정은죽인것땜에그나마 별둘줌  ## 단어벡터 학습 C++ 기반의 FastText는 터미널에서 실행 가능합니다. 학습말뭉치 파일과 결과 파일 두 가지만 지정하면 나머지는 FastText가 알아서 해줍니다. 저의 경우 맥 데스크톱 폴더에서 실행했기 때문에 맨 앞에 '/fastText/'라는 경로를 지정했습니다. ```python $ ./fastText/fasttext -input kor -output kor_model ``` 하지만 몇 가지 추가로 옵션을 지정해주면 더욱 좋겠죠. CBOW보다는 SkipGram 모델의 성능이 나은걸로 알려져 있기 때문에 임베딩 기법은 SG를, 단어벡터의 차원수는 100을, 양옆 단어는 세개씩 보되, 말뭉치에 100번 이상 나온 단어들만 임베딩하고 싶다면 다음과 같이 실행하면 됩니다. ```python $ ./fastText/fasttext skipgram -input kor -output kor_model -dim 100 -ws 3 -minCount 100 ``` 다음은 FastText의 파라메터 목록입니다. 여기에서 input, output은 사용자가 지정하지 않으면 실행이 되지 않기 때문에 반드시 입력해주어야 합니다. | parameter     | description               | default  | | :---------------- | :--------------------------------------- | :-------- | | input       | training file path            | mandatory | | output      | output file path             | mandatory | | verbose      | verbosity level             | 2     | | minCount     | minimal number of word occurences    | 5     | | minCountLabel   | minimal number of label occurences    | 0     | | wordNgrams    | max length of word ngram         | 1     | | bucket      | number of buckets            | 2000000  | | minn       | min length of char ngram         | 3     | | maxn       | max length of char ngram         | 6     | | t         | sampling threshold            | 0.0001  | | label       | labels prefix              | []    | | lr        | learning rate              | 0.05   | | lrUpdateRate   | change the rate of updates for the learning rate | 100    | | dim        | size of word vectors           | 100    | | ws        | size of the context window        | 5     | | epoch       | number of epochs             | 5     | | neg        | number of negatives sampled       | 5     | | loss       | loss function {ns, hs, softmax}     | ns    | | thread      | number of threads            | 12    | | pretrainedVectors | pretrained word vectors for supervised learning | []    | | saveOutput    | whether output params should be saved  | 0     | | cutoff      | number of words and ngrams to retain   | 0     | | retrain      | finetune embeddings if a cutoff is applied | 0     | | qnorm       | quantizing the norm separately      | 0     | | qout       | quantizing the classifier        | 0     | | dsub       | size of each sub-vector         | 2     | 어쨌든 실행을 하면 다음과 같은 화면이 뜹니다. 학습 속도가 매우 빨라서 한국어 영화리뷰 50만여건을 학습시키는 데 맥북프로 2015 early 기준으로 5분도 채 안 걸렸던 것 같습니다. <a href="http://imgur.com/ahIQ6PW"><img src="http://i.imgur.com/ahIQ6PW.png" width="500px" title="source: imgur.com" /></a>   ## 학습결과 확인 학습이 끝나면 gensim 패키지의 Word2Vec처럼 파이썬 콘솔에서 결과를 확인할 수 있습니다. 다음과 같이 불러오면 됩니다. ```python from gensim.models import KeyedVectors model = KeyedVectors.load_word2vec_format('kor') ``` 임베딩된 단어의 리스트나 단어벡터를 뽑는 것은 다음과 같이 하면 됩니다. ```python # 단어 리스트 작성 vocab = model.index2word # 전체 단어벡터 추출 wordvectors = [] for v in vocab: 	wordvectors.append(model.wv[v]) ``` 쿼리단어 기준으로 가장 유사한 단어 리스트를 뽑는 것도 gensim의 Word2Vec과 완전히 동일합니다. ```python # '영화'와 가장 유사한 단어 30개 뽑기 model.most_similar('영화', topn=30) ```   ## 파일럿 결과 '영화'와 가장 유사한 단어를 뽑아 봤습니다. 다음과 같습니다. > 영화다, 영화였다, 작품, 영화임, 영화이다, 영화였음, 영화인듯, 영화에요, 영화네요... '쓰레기'와 가장 유사한 단어는 아래와 같습니다. > 시간낭비, 삼류, 최악의, 최악, 아깝다, 쓰레기같은, 병신, 동, 졸작, 쓰레기를, 극혐...
nounad␞ 이번 글에서는 한국어의 9품사 가운데 하나인 관형사에 대해 살펴보도록 하겠습니다. 이번 글은 경희대 이선웅 교수님 강의와 '왜 다시 품사론인가(남기심 외, 커뮤니케이션북스)', '표준국어문법론(남기심&고영근, 탑출판사)'을 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 정의 및 핵심 기능 학교문법에 따르면 **관형사(冠形詞)**란 체언 앞에서 그 체언의 뜻을 분명하게 제한하는 품사입니다. 국어 관형사 가운데는 (1)과 같은 고유어는 얼마되지 않고 (2)와 같은 한자어가 많은 부분을 차지하고 있다고 합니다. > (1) 이 거리에는 **새** 집과 **헌** 집이 서로 이웃해 있다. > > (2) 서울대학교는 **구(舊)** 경성제국대학을 모태로 하여 발족되었다. 관형사는 체언 이외의 품사는 꾸미는 일이 없습니다. 관형사가 나란히 놓여 있을 때는 다음처럼 앞의 관형사가 뒤의 관형사를 꾸미는 것처럼 보일 때가 있습니다. 하지만 아래의 예에서 '저', '이'는 명사구 '새 책'과 '헌 구두'를 꾸미므로 관형사의 궁극적인 수식대상은 명사라고 말할 수 있습니다. > **저** **새** 책이 누구의 책이냐? > > **이** **헌** 구두가 제 것입니다.   ## 종류 학교문법에서 규정하는 관형사에는 **성상관형사(性狀冠形詞)**, **수관형사(數冠形詞)**, **지시관형사(指示冠形詞)** 세 가지 종류가 있습니다. 성상관형사는 꾸밈을 받는 명사의 모양, 성질이나 상태를 나타내는 관형사를 가리킵니다. 수관형사는 주로 단위성 의존명사와 결합하여 사물의 수나 양을 나타내는 관형사입니다. 지시관형사는 특정한 대상을 지시하여 가리키는 관형사입니다. 각각의 예시는 다음과 같습니다. > **성상관형사** : (1) 고유어계 : **새**(집/옷/해..), **헌**(집/옷/책…), **헛**(말/고생/생각…), **옛**(집/말/사람…) (2) 한자어계 : **순(純)**(이익/한국말/유럽산...), **호(好)**(결과/영향...), **구(舊)**(관립 한성고등학교/국제우체국…), **대(大)**(사건/건축/문제...), **장(長)**(거리/기간...), **고(高)**(물가/비행...), **주(主)**(세력/원인...), **정(正)**(교수/교사...), **이(異)**(민족...) > **수관형사** : (1) 한, 두, 세(석/서), 네(넉/너), 다섯(닷), 여섯(엿), 일곱, 여덟, 아홉, 열, 열 한, 열 두, 열 세(석/서), 열 네(넉/너),…,스무… (2) 한두, 두세, 서너, 두서너… (3) 일이(一二), 이삼(二三), 삼사(三四)... (4) 여러, 모든, 온, 온갖, 갖은, 반(半), 전(全) > **지시관형사** : (1) 고유어계 : 이, 그, 저, 요, 고, 조, 이런, 그런, 저런, 다른(他) (2) 한자어계 : **귀(貴)**(가족...), **본(本)**(연구소...), **동(同)**(시험장...), **현(現)**(국무총리...), **전(前)**(교육부장관...), **모(某)**(년/월/일)   ## 특성 관형사로 분류되는 형태 가운데에는 접두사, 어근 등 다른 형태 범주뿐만 아니라 명사, 수사, 형용사, 부사 등 다른 품사와도 쉽게 구별되지 않는 경우가 많습니다. 게다가 그 수도 다른 품사 대비 적습니다. 한국어 이외의 다른 언어에서 나타나지 않는 독특한 단어 부류이기도 하고요. 이 때문에 관형사를 독자 품사로 분리하는 게 적절치 않다는 견해를 가지고 있는 학자들도 꽤 있습니다. 어쨌든 학교문법에서는 관형사를 독자 품사로 설정하고 있는데요. 관형사는 다음과 같은 특징을 가집니다. > **형태적** : 조사나 어미가 결합할 수 없는 불변어이다. > > **통사적** : 명사를 수식하는 기능을 하지만, 자립성이 약해서 문장 안에서 단독으로 쓰이지 못한다. > > **의미적** : 피수식어인 체언의 뜻을 분명하게 제한한다. 하지만 명사라고 해서 모두 관형사의 꾸밈을 받는 것은 아닙니다. 관형사가 고유명사, 의존명사, 추상명사, 대명사 따위를 수식하는 데는 다음과 같이 제약이 따릅니다. > *새 철수 > > *헌 데 > > *그 너   ## 단어형성의 기본 원리 단어는 다음 예시와 같이 그 짜임새가 단일할 수도 있고 복합적일 수도 있습니다.  > (가) **단일어** : 집, 신, 높다... > > (나) **파생어** : 지붕, 덧신, 드높다... > > (다) **합성어** : 집안, 짚신, 높푸르다... (가)와 같이 그 짜임새가 단일한 단어를 **단일어**라고 하고, (나) (다)와 같이 그 짜임새가 복합적인 말을 **복합어**라고 합니다. 복합어의 형성에 나타나는 **실질형태소**를 **어근(root)**이라고 하고 **형식형태소**를 **접사(affix)**라고 합니다. 중심적인 의미가 어휘적인 형태소를 실질형태소, 실질적이지 않고 문법적이면 형식형태소라고 합니다. (나)처럼 실질형태소에 형식형태소가 붙어서 만들어진 말을 **파생어(derived word)**, (다)처럼 실질형태소들의 결합으로 이루어진 말을 **합성어(compound word)**라고 합니다.   ## 관형사 vs 접사 그렇다면 다음의 '맨'은 관형사로 분류해야 할까요? 아니면 접사로 해야할까요? 관형사와 접사 모두 자립성이 약해 다른 단어와 동시에 쓰이고, 같이 나타나는 다른 형태소의 의미를 분명하게 제한한다는 점에서 알쏭달쏭합니다. > (ㄱ) 맨손, 맨주먹, 맨발, 맨머리, 맨몸, 맨밥, 맨입... > > (ㄴ) 맨 꼭대기, 맨 위, 맨 밑, 맨 아래, 맨 끝, 맨 꼬리, 맨 나중, 맨 뒤, 맨 앞, 맨 처음... 외솔 최현배 선생(1894~1970)께서는 어휘적 의미에 집중해 (ㄱ)을 접사, (ㄴ)을 관형사로 분류했습니다. (ㄱ)처럼 '의관이나 또 다른 것으로 꾸미지 아니하다'로 쓰였을 경우 접두사, (ㄴ)처럼 '가장(最)'으로 사용했다면 관형사에 해당한다는 논리입니다. 하지만 이러한 기준은 불분명할 뿐더러 '맨'에만 쓸 수 있어 모든 단어에 공통적으로 적용할 수 없다는 단점이 있습니다. 어휘적 의미 이외에 생각해볼 수 있는 건 '결합제약'입니다. 즉 관형사는 문장에서 다른 명사들과 비교적 자유롭게 결합할 수 있으나 접사는 제한된 어근과만 결합한다는 얘기입니다.  위 예시에서 (ㄱ)의 의미로 '맨'을 쓸 경우 '맨눈', '맨팔'은 되지만 *맨배, *맨코는 말이 성립하지 않는다는 걸 알 수 있습니다. '맨'은 아무 명사에나 붙는 것이 아니어서 결합제약이 크다는 말입니다. 그런데 (ㄴ)의 의미로 '맨'을 사용한다면 '맨 먼저'와 같이 대부분의 명사에 '맨'을 쓸 수 있어 결합제약이 상대적으로 작습니다.  관형사와 접사를 가르는 또다른 기준은 '중간에 다른 단어를 삽입할 수 있는지' 여부가 될 수 있습니다. 중간 삽입이 가능하다면 관형사, 불가능하다면 접사로 나누자는 의견입니다. 아래 예시에서 (ㄱ)은 중간 삽입이 불가능하지만 (ㄴ)은 가능합니다. > (ㄱ) 맨눈 / *맨(좋은)눈 > > (ㄴ) 맨 먼저 / 맨 (처음 온 사람) 먼저 한편 '맨 먼저'를 발음할 때는 '맨'과 '먼저' 사이에 휴지(休止)를 둘 수 있지만 '맨눈'을 발음할 땐 하나의 단위로 소리내는 경우가 많습니다. 이는 중간 삽입 기준과 밀접한 연관을 맺고 있습니다. 요컨대 결합제약과 중간삽입 기준 두 가지를 고려할 때 (ㄱ)은 접사, (ㄴ)은 관형사로 분류할 수 있습니다. 그러나 이러한 기준을 모든 상황에 일률적으로 적용하기는 쉽지 않아서 관형사와 접사의 차이는 결국 국어 화자의 직관에 의존할 수밖에 없는 것 아니냐는 비관적 의견도 일부 있기는 합니다.   ## 관형사 vs 어근 관형사와 어근을 나누는 것도 그리 분명하지 않습니다. 표준국어대사전을 참고해 '새'와 관련된 표제어를 조사해 보았습니다. > 새-것, 새-해, 새-집, 새-색시, 새-봄 사전 편집자는 위 예시에서 '새'와 '것', '해', '집', '색시', '봄'은 그보다 큰 단위의 명사를 형성하는 데 참여하는 어근의 하나로 분석한 것입니다. 바꿔 말해 위 예시들을 '어근(새) + 어근' 구조인 합성어로 보고 표제어로 등록했다는 이야기입니다. 그런데 아래 예시는 표준국어대사전에서 표제어로 등록돼 있지 않은 걸 확인할 수 있습니다. 다시 말해 사전 편집자는 아래 예시들을 '관형사(새) + 명사'의 일반적인 결합구조로 보고 별도 표제어로 등록하지 않은 셈이죠. > 새 신발, 새 구두, 새 책, 새 옷, 새 시계 실제로 문법서나 사전마다 관형사와 어근 구분이 제각기 다르다고 합니다. 그만큼 관형사와 어근을 가리는 게 어렵다는 얘기입니다. 다만 '새해', '새색시'처럼 언중들이 해당 단어를 대부분 한 단위로 인식하고 사용한다면 이때의 '새'를 어근으로 분석하는 것이 그리 비합리적인 처리는 아닐 것입니다.    ## 관형사 vs 용언의 활용형 관형사는 통시적으로 보면 용언 어간과 관형사형 어미의 결합에서 발달한 것으로 보이는 예들이 있습니다. '갖은'이 대표적인 사례입니다. 중세국어에서 동사 '갖-'은 현대국어의 '갖추어지다'라는 뜻으로 사용됐습니다. 여기에 관형사형 어미 '-은'이 붙으면 '갖은'이 됩니다. 만약 중세 시기에 활동하는 국어학자가 있다면 '갖은'은 동사 '갖-'에 관형사형 어미 '-은' 두 개로 분석하고, 사전에는 이 둘만 실었을 것입니다. 그런데 시간이 흘러 현대로 오면서 동사 '갖-'에 '갖추어지다'라는 본래 의미가 사라지고 have의 의미만 남았습니다. 이와 더불어 '골고루 다 갖춘'이라는 뜻을 지닌 '갖은'이라는 단어가 화석처럼 전해졌죠.  현대 국어 화자들은 이러한 '갖은'을 '갖추어지다'는 뜻의 동사 '갖-'과 관형사형 어미 '-은'을 더 이상 구별해낼 수 없습니다. 현대 국어를 연구하는 국어학자들은 이 때문에 관형사로 사전에 등재할 수밖에 없게 된 것이죠. 이때 '갖은'은 조사나 어미가 붙지 않고 활용을 하지 않으며 명사를 수식하는 기능을 갖기 때문에 그 품사는 관형사로 분류되게 됩니다. '갖은' 이외의 비슷한 사례들이 많습니다. 다음과 같습니다. > 몹쓸, 고얀, 헌, 어떤, 어쩐, 긴긴, 어쩐, 허튼, 괜한, 외딴, 아무런, 오랜, 바른, 지난, 이/그/저런... 그러나 이들 중에서도 '헌-헐다', '어떤-어떻다', '아무런-아무렇다', '오랜-오래다', '바른-바르다', '지난-지나다', '이/그/저런-이/그/저렇다'처럼 현대 국어 화자들이 보기에 용언의 기본형이 예상되는 경우가 많아서 이들을 정말 관형사로 분류해야 하는지, 용언의 관형사형으로 봐야 하는지 판단이 쉽지가 않기는 합니다.    ## 관형사 vs 부사 관형사와 부사를 구분해야 할 경우가 있습니다. 예문을 보겠습니다. > **꼭** 30일이 지났다. 위 예문에서 '꼭'이 수식하는 대상은 '30일'이라는 명사입니다. '꼭 지났다'는 말은 성립하지 않아 동사를 수식했다고 보기는 어렵기 때문입니다. 따라서 위 예문에서 '꼭'은 부사가 아니라 관형사 역할을 했다고 볼 수가 있습니다. 표준국어대사전에 따르면 '조금도 어김없이' 등의 의미로 쓰이는 '꼭'의 품사는 부사입니다. 그러면 예문에서 '꼭'의 품사는 무엇일까요? 이와 관련해 국어학계에서는 통일된 의견이 존재하지 않는 상황이라고 합니다.  이번엔 '바로'를 살펴보겠습니다. 다음 문장을 보겠습니다. > 내가 좋아하는 사람은 **바로** 너이다. 위 예문에서 '바로'가 수식하는 대상은 분명하지 않습니다. 한국어를 모국어로 하는 화자라도 '너'라는 명사를 꾸며주는지, '너이다' 서술어를 꾸며주는지 직관적으로 구분해낼 수 없을 정도입니다. 전자에 해당하는게 분명하다면 이때 '바로'는 관형사, 후자라면 부사로 분류할 수 있을텐데 말이죠. '바로'의 품사를 세밀하게 따져보기 위해 다음과 같이 명사(구)로만 해석될 수 있는 통사적 환경을 만들어 봅시다. > **바로** 너를 만났다. 어떤 분은 위 예시를 보고, '너를 바로 만났다'라고도 해석할 수 있지 않느냐고 반문하실지 모르겠습니다. 하지만 이렇게 되면 위 예시의 문장과 그 의미가 달라지게 됩니다. 다시 말해 예문은 '다른 사람 말고 바로 너'를 만났다는 뜻이 되고, '너를 바로 만났다'는 '오래 전도 아니고 지금 바로' 너를 만났다는 뜻이기 때문입니다. 어쨌든 예문의 통사적 환경에서 '바로'가 큰 무리없이 쓰일 수 있는 점을 확인할 수 있습니다. 따라서 예문에서의 '바로'는 관형사라고 해도 큰 무리가 없을 겁니다. 이번에는 정도(degree)를 나타내는 부사와 관형사를 구분해 보겠습니다. 다음 예문은 한국어에서 자연스럽습니다. > (A) 그 사람은 **아주/매우/꽤** 부자이다. 그러면 '아주/매우/꽤'는 부사로 분류해야 할까요? 관형사로 분류해야 할까요? 위 예문에서 이들이 '부자'를 꾸민다면 관형사, '부자이다'라는 서술어를 꾸민다면 부사로 분류하면 됩니다. 하지만 이 예문으로는 명확하지 않습니다. 정확한 판단을 위해 명사(구) 통사환경을 다음과 같이 만들어 봅시다. > 내가 어제 **아주** 부자를 만났어 > > 내가 어제 ***매우** 부자를 만났어 > > 내가 어제 ***꽤** 부자를 만났어 '아주 부자'는 말이 되지만 '매우'와 '꽤'는 그렇지 않음을 확인할 수 있습니다. 그러면 역으로 (A) 예시의 '매우'와 '꽤'는 '부자이다'라는 서술어를 수식하는 부사로 보는 것이 합리적입니다.  아울러 '아주'는 관형사로 보는 것이 타당합니다. '아주' 같은 경우에는 주로 부사로 쓰이나 워낙 자주 쓰이는 단어이기 때문에 체언을 꾸며주는 역할(관형사)까지 하게 된 것으로 보입니다.  이와 비슷하게 통시적인 변화를 겪어서 관형사 역할도 일부 담당하는 부사의 사례로는 '오직'이 있습니다. 다음과 같은 예시가 이 경우에 해당합니다. > **오직** 너만 사랑한다.
operations␞ 이번 포스팅에서는 **머신러닝**, **데이터마이닝** 기초인 **행렬 연산(Matrix Operations)**에 대해 다뤄 보려고 합니다. 연산의 정의 정도를 간단히 다루는 것이니 깊은 내용을 원하시는 분들은 [이곳](http://darkpgmr.tistory.com/103)을 참고 바랍니다. 이번 포스팅은 기본적으로 [고려대 김성범 교수님](http://dmqm.korea.ac.kr/content/page.asp?tID=101&sID=108) 강의를 참고했습니다.  ## 데이터마이닝에서의 행렬 연산 데이터마이닝은 기본적으로 아래와 같은 구조의 데이터를 다룹니다. 계산 편의성을 도모하기 위해 위와 같은 데이터를 행렬로 변환합니다. 그렇게 되면 R, Python 등 각종 언어의 수치해석 라이브러리 도움을 받아 빠르게 연산을 할 수 있게 됩니다. | -  | X1  | X2  | ... | Xp  | | ---- | ---- | ---- | ---- | ---- | | obs1 | x11 | x12 | ... | x1p | | obs2 | x21 | x22 | ... | x2p | | ... | ... | ... | ... | ... | | obsn | xn1 | xn2 | ... | xnp |  ## 벡터(Vector) 위 데이터에서 X1(d1)이라는 열(행)을 하나 떼서 만든 것이라고 생각하면 되겠습니다. 이를 식으로 쓰면 다음과 같습니다. 벡터는 다음과 같은 연산이 가능합니다. $$X=\begin{pmatrix} { x }_{ 1 } \\ { x }_{ 2 } \\ ... \\ { x }_{ n } \end{pmatrix}​$$  ### 스칼라 곱(Scalar Multiplication) $${ c }_{ 1 }=5,\quad Y=\begin{pmatrix} { 1 } \\ { 2 } \\ { 3 } \end{pmatrix}$$ $${ c }_{ 1 }Y=\begin{pmatrix} { 1 } \\ { 2 } \\ { 3 } \end{pmatrix}=5\cdot \begin{pmatrix} { 1 } \\ { 2 } \\ { 3 } \end{pmatrix}=\begin{pmatrix} { 5 } \\ 10 \\ 15 \end{pmatrix}$$  ### 벡터 덧셈(Vector Addition) $$X=\begin{pmatrix} { 1 } \\ 3 \\ 5 \end{pmatrix},\quad Y=\begin{pmatrix} 2 \\ -1 \\ 0 \end{pmatrix}$$ $$X+Y=\begin{pmatrix} { 1 } \\ 3 \\ 5 \end{pmatrix}+\begin{pmatrix} 2 \\ -1 \\ 0 \end{pmatrix}=\begin{pmatrix} 3 \\ -2 \\ 5 \end{pmatrix}$$  ### 벡터의 내적(inner product) $$X=({ x }_{ 1 },{ x }_{ 2 },...,{ x }_{ n }{ ) }^{ T }\\ Y=({ y }_{ 1 },y_{ 2 },...,{ y }_{ n }{ ) }^{ T }\\ <X,Y>={ X }^{ T }Y=\sum _{ i=1 }^{ n }{ { x }_{ i }{ y }_{ i }= } { x }_{ 1 }{ y }_{ 1 }+{ x }_{ 2 }{ y }_{ 2 }+...+{ x }_{ n }{ y }_{ n }$$  ### 벡터의 길이(Length) X가 다음과 같은 벡터로 정의된다면 X의 길이(Lx)는 아래와 같습니다. 2차원 공간에서 삼각형의 빗변을 구하는 피타고라스의 정리를 떠올리시면 쉽게 이해하실 수 있을 겁니다. $$X=({ x }_{ 1 },{ x }_{ 2 },...,{ x }_{ n }{ ) }^{ T }$$ $$Lx=\sqrt { { x }_{ 1 }^{ 2 }+{ x }_{ 2 }^{ 2 }+...+{ x }_{ n }^{ 2 } } =\sqrt { { X }^{ T }X } $$  ### 벡터 간 각도(Angle) 벡터 X와 Y 사이의 각도(θ)는 [코사인 법칙으로 유도](http://wiki.mathnt.net/index.php?title=%EB%B2%A1%ED%84%B0%EC%9D%98_%EB%82%B4%EC%A0%81#.EC.BD.94.EC.82.AC.EC.9D.B8_.EB.B2.95.EC.B9.99.EC.9C.BC.EB.A1.9C.EB.B6.80.ED.84.B0.EC.9D.98_.EC.9C.A0.EB.8F.84)하여 다음과 같이 표현할 수 있습니다. 다시 말해 두 벡터 내적값을 각각의 벡터 길이로 나눠준 값입니다. $$cos(\theta )=\frac { ({ x }_{ 1 }{ y }_{ 1 }+{ x }_{ 2 }{ y }_{ 2 }+...+{ x }_{ n }{ y }_{ n }) }{ Lx\cdot Ly } =\frac { { x }^{ T }y }{ \sqrt { { x }^{ T }x } \cdot \sqrt { { y }^{ T }y } } $$  ### 벡터의 사영(projection) 벡터 x를 y에 사영한 결과는 다음과 같습니다. $$projection\quad of\quad x\quad on\quad y=\frac { { x }^{ T }y }{ { y }^{ T }y } \cdot y$$  ## 행렬(Matrix) 머신러닝, 데이터마이닝에서의 행렬은 위 표의 데이터 행과 열이 각각 행렬로 변환된 것이라고 보면 됩니다. 예컨대 3 x 2 **차원(dimension)**의 행렬 A는 다음과 같이 쓸 수 있습니다.  $$A=\begin{pmatrix} -7 & 2 \\ 0 & 1 \\ 3 & 4 \end{pmatrix}$$  ### 행렬 덧셈(Matrix Addition) $$\begin{pmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{pmatrix}+\begin{pmatrix} 0 & 1 & 0 \\ 2 & -1 & 5 \end{pmatrix}=\begin{pmatrix} 1 & 3 & 3 \\ 6 & 4 & 11 \end{pmatrix}$$  ### 스칼라 곱(Scalar Multiplication) $${ c }_{ 1 }=2,\quad A=\begin{pmatrix} 1 & 0 \\ 2 & 5 \end{pmatrix}$$ $${ c }_{ 1 }\cdot A=\begin{pmatrix} 2 & 0 \\ 4 & 10 \end{pmatrix}$$  ### 전치(transpose) $$A=\begin{pmatrix} 2 & 1 & 3 \\ 0 & 1 & -1 \end{pmatrix},\quad { A }^{ T }=\begin{pmatrix} 2 & 0 \\ 1 & 1 \\ 3 & -1 \end{pmatrix}$$  ### 정방행렬(Square Matrix)과 대칭행렬(Symmetric Matrix) 정방행렬은 행 개수와 열 개수가 같은 행렬이며 대칭행렬은 원래 행렬과 전치가 같은 행렬을 뜻합니다.  ### 행렬 곱셈(Matrix Multiplication) $$A=\begin{pmatrix} 3 & -1 & 2 \\ 4 & 0 & 5 \end{pmatrix},\quad B=\begin{pmatrix} 3 & 4 \\ 6 & -2 \\ 4 & 3 \end{pmatrix}$$ $$A\cdot B=\begin{pmatrix} 11 & 20 \\ 32 & 31 \end{pmatrix}$$  직관적으로 이해할 수 있는 예제 하나 더 첨부했습니다. ([출처](https://www.facebook.com/cpbeg/posts/1673363789639663)) <a href="http://imgur.com/3PVaEXE"><img src="http://i.imgur.com/3PVaEXE.gif" width="400px" title="source: imgur.com" /></a>  ### 역행렬(Inverse) $$AB=BA=I\\ B={ A }^{ -1 },\quad A={ B }^{ -1 }\\ A{ A }^{ -1 }=I$$  ### 행렬식(Determinant) 역행렬 존재여부에 대한 판별식이자 행렬의 부피 역할을 하는 값입니다. 데이터마이닝 분야에선 행렬의 차원수가 아무리 크더라도 행렬식이 스칼라값으로 나오기 때문에 중요하게 취급됩니다. 행렬로 표현된 데이터를 요약한 결과로 해석될 여지가 있기 때문입니다. 자세한 내용은 [이곳](http://darkpgmr.tistory.com/104)을 참고하세요.  ### 행렬의 대각합(trace) **대각합(trace)** 또한 행렬식과 마찬가지로 행렬 차원수에 관계없이 하나의 값을 지니기 때문에 데이터의 의미를 압축 표현했다는 점에서 중요합니다.  ### 정부호행렬(Definite Matrix) 모든 **고유값(eigenvalue)**이 양수인 행렬을 **양의 정부호행렬(Positive Definite Matrix)**이라고 합니다. 모든 고유값이 음수가 아닌 행렬을 **양의 준정부호행렬(Postive Semi-Definite Matrix)**라고 합니다. 아래 예시에선 임의의 벡터 c에 대해 A가 전자, B가 후자입니다. $$A=\begin{pmatrix} 4 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 1 \end{pmatrix}\quad is\quad Postive\quad Definite\quad Matrix$$ $$\because \begin{pmatrix} { c }_{ 1 } & { c }_{ 2 } & { c }_{ 3 } \end{pmatrix}\begin{pmatrix} 4 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 1 \end{pmatrix}\begin{pmatrix} { c }_{ 1 } \\ { c }_{ 2 } \\ { c }_{ 3 } \end{pmatrix}=4{ c }_{ 1 }^{ 2 }+2{ c }_{ 2 }^{ 2 }+{ c }_{ 3 }^{ 2 }\ge 0$$ $$B=\begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}\quad is\quad Postive\quad Semi-Definite\quad Matrix$$ $$\because \begin{pmatrix} { c }_{ 1 } & { c }_{ 2 } \end{pmatrix}\begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}\begin{pmatrix} { c }_{ 1 } \\ { c }_{ 2 } \end{pmatrix}=({ c }_{ 1 }^{ 2 }+{ c }_{ 2 }^{ 2 })\ge 0$$   ## 공분산 행렬(Covariance Matrix) 변수가 여러 개인 **다변량 데이터**에선 변수 간 관련성, 즉 **상관성(correlation)**이 매우 중요한 문제가 됩니다. 확률변수 X의 값이 X의 평균보다 클 때 Y의 값도 Y의 평균보다 커지고, X의 값이 X의 평균보다 작을 때에는 Y의 값도 Y의 평균보다 작아지는 경향이 있으면 표준화된 X와 Y의 곱인 **상관계수(correlation coefficient)**는 양의 값을 가질 가능성이 큽니다. 바꿔 말하면 두 확률변수의 직선 관계가 얼마나 강하고 어떤 방향인지를 나타내는 값이라고 볼 수 있습니다.  확률변수 X와 Y의 상관계수와 **공분산(Covariance)**는 다음과 같이 정의되는데요, 공분산을 X, Y의 표준편차로 나누어 표준화한 값이 X와 Y의 상관관계라고 할 수 있겠습니다. (N=데이터 개수, u1=X의 평균, u2=Y의 평균, s1=X의 표준편차, s2=Y의 표준편차) $$ \begin{align*} \rho &=\frac { 1 }{ N } \sum _{ i=1 }^{ N }{ \left( \frac { { X }_{ i }-{ \mu }_{ 1 } }{ { \sigma }_{ 1 } } \right) \left( \frac { Y_{ i }-{ \mu }_{ 2 } }{ { \sigma }_{ 2 } } \right) } \\ &=E\left[ \left( \frac { { X }-{ \mu }_{ 1 } }{ { \sigma }_{ 1 } } \right) \left( \frac { Y-{ \mu }_{ 2 } }{ { \sigma }_{ 2 } } \right) \right] \\ &=\frac { E\left[ (X-{ \mu }_{ 1 })(Y-{ \mu }_{ 2 }) \right] }{ { \sigma }_{ 1 }{ \sigma }_{ 2 } } \\ &=\frac { Cov(X,Y) }{ { \sigma }_{ 1 }{ \sigma }_{ 2 } } \end{align*} $$ $$ \begin{align*} cov(X,Y)&=E\left[ (X-{ \mu }_{ 1 })(Y-{ \mu }_{ 2 }) \right] \\ &=E\left[ XY-{ \mu }_{ 2 }X-{ \mu }_{ 1 }Y+{ \mu }_{ 1 }{ \mu }_{ 2 } \right] \\ &=E[XY]-{ \mu }_{ 2 }E[X]-{ \mu }_{ 1 }E[Y]+{ \mu }_{ 1 }{ \mu }_{ 2 }\\ &=E[XY]-{ \mu }_{ 2 }{ \mu }_{ 1 }-{ \mu }_{ 1 }{ \mu }_{ 2 }+{ \mu }_{ 1 }{ \mu }_{ 2 }\\ &=E[XY]-{ \mu }_{ 1 }{ \mu }_{ 2 } \end{align*} $$ 공분산 행렬은 행렬의 각 요소가 공분산인 매트릭스를 의미합니다. 임의의 공분산행렬 A를 예를 들어 보겠습니다. $$A=\begin{pmatrix} 2 & 4 \\ 4 & 6 \end{pmatrix}$$ 첫 행은 확률변수 X, 두번째 행은 확률변수 Y에 해당한다고 치면, 마찬가지로 첫번째 열은 X, 두번째 열은 Y를 가리킵니다. 그렇다면 cov(X, X)=var(X)=2가 되겠네요. 역시 cov(Y, Y)=var(Y)=6입니다. cov(X, Y)=cov(Y, X)=4입니다. 그럼 공분산 행렬은 어떻게 구할까요? 아래와 같은 데이터가 있다고 칩시다. | -  | X  | Y  | Z  | | ---- | ---- | ---- | ---- | | obs1 | 1  | 4  | 3  | | obs2 | 2  | 3  | 5  | | obs3 | 3  | 2  | 2  | | obs4 | 4  | 1  | 7  | 위 데이터는 아래와 같이 행렬과 벡터 형태로 바꿀 수 있습니다. $$D= \begin{pmatrix} 1 & 4 & 3 \\ 2 & 3 & 5 \\ 3 & 2 & 2 \\ 4 & 1 & 7 \end{pmatrix}$$ $$X=\begin{pmatrix} 1 \\ 2 \\ 3 \\ 4 \end{pmatrix},\quad Y=\begin{pmatrix} 4 \\ 3 \\ 2 \\ 1 \end{pmatrix},\quad Z=\begin{pmatrix} 3 \\ 5 \\ 2 \\ 7 \end{pmatrix}$$ 위에서 정리한 공분산 공식을 벡터 형태로 바꾸면 다음과 같습니다. $$ \begin{align*} cov(X,Y)&=E[XY]-{ \mu }_{ 1 }{ \mu }_{ 2 }\\ &=\frac { 1 }{ n -1 } \sum _{ i=1 }^{ n }{ { X }_{ i }{ Y }_{ i } } -{ \mu }_{ 1 }{ \mu }_{ 2 }\\ &=\frac { 1 }{ n-1 } <X,Y>-{ \mu }_{ 1 }{ \mu }_{ 2 }\\ \end{align*} $$ 위의 식을 뜯어보면 벡터 X와 Y의 평균이 0으로 centering돼 있다면 cov(X,Y)는 X와 Y의 내적에 (데이터 개수 - 1)로 나눠준 값과 같습니다. 즉 아래처럼 되는 것이죠. $$ \begin{align*} cov(X,Y)&=\frac { 1 }{ 3 } \begin{pmatrix} 1 & 2 & 3 & 4 \end{pmatrix}\begin{pmatrix} 4 \\ 3 \\ 2 \\ 1 \end{pmatrix}-(2.5\times 2.5)\\ &=\frac { 1 }{ 3 } \begin{pmatrix} -1.5 & -0.5 & 0.5 & 1.5 \end{pmatrix}\begin{pmatrix} 1.5 \\ 0.5 \\ -0.5 \\ -1.5 \end{pmatrix} \\&=-1.667 \end{align*} $$ 그럼 데이터 전체의 공분산을 구해볼까요? 앞서 정리한 **행렬 곱셈(Matrix Multiplication)**의 정의에 의해 행렬끼리의 곱셈결과는 각 요소에 해당하는 벡터들끼리의 내적값과 같습니다. 이러한 성질을 이용해 D를 각 변수별(열 기준)로 평균을 0으로 맞춰주고($D'$) 이를 제곱해주면 데이터 전체의 공분산 행렬을 한번에 구할 수 있습니다. $$ \begin{align*} cov(D)&={ \frac { 1 }{ 3 } D' }^{ T }D'\\ &=\frac { 1 }{ 3 } \begin{pmatrix} 1-2.5 & 2-2.5 & 3-2.5 & 4-2.5 \\ 4-2.5 & 3-2.5 & 2-2.5 & 1-2.5 \\ 3-4.25 & 5-4.25 & 2-4.25 & 7-4.25 \end{pmatrix}\begin{pmatrix} 1-2.5 & 4-2.5 & 3-4.25 \\ 2-2.5 & 3-2.5 & 5-4.25 \\ 3-2.5 & 2-2.5 & 2-4.25 \\ 4-2.5 & 1-2.5 & 7-4.25 \end{pmatrix}\\ &=\begin{pmatrix} 1.67 & -1.67 & 1.5 \\ -1.67 & 1.67 & -1.5 \\ 1.5 & -1.5 & 4.92 \end{pmatrix} \end{align*} $$ 위 공분산 행렬의 해석은 이미 설명드린 바와 같습니다. X, Y, Z의 분산은 각각 1.67, 1.67, 4.92입니다. $cov(X,Y)=cov(Y,X)=-1.67$, $cov(Y,Z)=cov(Z,Y)=-1.5$, $cov(X,Z)=cov(Z,X)=1.5$입니다.    ## 독립(independence)과 직교(orthogonality) 확률변수 X의 값이 확률변수 Y의 값에 아무런 영향을 미치지 않는다면 X와 Y는 서로 **독립(independent)**이라고 합니다. 두 변수가 독립이라면 아래와 같은 식이 성립합니다. $$E[XY]=E[X]\cdot E[Y]$$ 두 확률변수 X와 Y가 서로 독립이라면 아래 식에 의해 공분산이 0이 됩니다. 바꿔 말하면 확률변수 X와 Y가 아무런 선형관계가 없다는 뜻입니다. $$cov(X,Y)=E[XY]-E[X]\cdot E[Y]=E[X]\cdot E[Y]-E[X]\cdot E[Y]=0$$ **직교성(Orthogonality)**은 이미 설명드린 **벡터 간 각도**에서 도출된 개념입니다. 90도 직각에 해당하는 코사인값은 0이므로 두 벡터가 직교할 경우 그 내적은 0이 됩니다.  통계학의 '독립', 선형대수학의 '직교성'이라는 개념은 엄밀히 말해 정확히 같지는 않지만 **공분산(covariance)**을 고리로 연결할 수 있게 됩니다. 확률변수(벡터) X와 Y의 평균을 각각 0으로 맞추고 공분산 공식에서 전체 데이터 개수로 나눠주는 부분(1/n)을 무시하면 공분산과 내적 관계를 아래 식처럼 쓸 수가 있습니다. $$cov(X,Y)=<X,Y>$$ 위 식을 지금까지 논의한 걸 바탕으로 해석하면 이렇습니다. 두 확률변수 X와 Y가 서로 독립이면 공분산은 0입니다. X와 Y의 내적 또한 0이 됩니다. 이를 다시 벡터 간 각도와 연관지어 생각하면 그 내적이 0인 두 벡터는 직교한다는 결론을 도출할 수 있게 됩니다. 따라서 '독립'과 '직교성'을 연결지어 생각할 수 있게 된다는 얘기입니다.   ## 그램-슈미트 단위직교화(Gram-Schmidt Orthogonalization) **그램슈미트 단위직교화**는 직교하지 않는 k개의 벡터(x)를 직교하는 k개 벡터(u)로 변환하는 방법입니다. 그림으로 이해하려면 [이곳](http://blog.naver.com/PostView.nhn?blogId=release&logNo=220279427020)을 참고하세요. 데이터마이닝에선 변수들끼리 상관관계를 지니게 되면(즉 서로 독립이지 않으면) 분석의 정확성이 떨어지게 됩니다. 이미 언급했듯이 독립과 직교성은 긴밀한 관계를 지니게 되므로 그램-슈미트 단위직교화를 통해 각 변수를 직교 벡터로 바꿀 경우 변수간 상관관계가 제거됩니다.  $$ \begin{align*} { u }_{ 1 }&={ x }_{ 1 }\\ { u }_{ 2 }&={ x }_{ 2 }-\frac { { x }_{ 2 }^{ T }{ u }_{ 1 } }{ { u }_{ 1 }^{ T }{ u }_{ 1 } } { u }_{ 1 } \\ ...\\ { u }_{ k }&={ x }_{ k }-\frac { { x }_{ k }^{ T }{ u }_{ 1 } }{ { u }_{ 1 }^{ T }{ u }_{ 1 } } { u }_{ 1 }-...-\frac { { x }_{ k }^{ T }{ u }_{ k-1 } }{ { u }_{ k-1 }^{ T }{ u }_{ k-1 } } { u }_{ k-1 } \end{align*} $$ 한번 예를 들어보겠습니다. 다음과 같은 두 벡터가 있다고 합시다. 내적해보면 알겠지만 직교하지 않습니다. $${ X }_{ 1 }=\begin{pmatrix} 4 \\ 0 \\ 0 \\ 2 \end{pmatrix},\quad X_{ 2 }=\begin{pmatrix} 3 \\ 1 \\ 0 \\ -1 \end{pmatrix}$$ 위 식을 바탕으로 u를 만들어 봅시다. $${ u }_{ 1 }={ X }_{ 1 }=\begin{pmatrix} 4 \\ 0 \\ 0 \\ 2 \end{pmatrix}$$ $${ u }_{ 1 }^{ T }{ u }_{ 1 }={ 4 }^{ 2 }+{ 0 }^{ 2 }+{ 0 }^{ 2 }+{ 2 }^{ 2 }=20$$ $$x_{ 2 }^{ T }{ u }_{ 1 }=12+0+0-2=10$$   $$u_{ 2 }=\begin{pmatrix} 3 \\ 1 \\ 0 \\ -1 \end{pmatrix}-\frac { 10 }{ 20 } \begin{pmatrix} 4 \\ 0 \\ 0 \\ 2 \end{pmatrix}=\begin{pmatrix} 1 \\ 1 \\ 0 \\ -2 \end{pmatrix}$$ u1, u2를 각각의 벡터 길이로 나누어 정규화한 것이 그램-슈미트 방법의 최종 결과물이 되겠습니다. $$z_{ 1 }=\frac { 1 }{ \sqrt { 20 } } \begin{pmatrix} 4 \\ 0 \\ 0 \\ 2 \end{pmatrix},\quad z_{ 2 }=\frac { 1 }{ \sqrt { 6 } } \begin{pmatrix} 1 \\ 1 \\ 0 \\ -2 \end{pmatrix}$$  ## 고유값(eigenvalue)과 고유벡터(eigenvector) 고유값과 고유벡터의 개념에 관해서는 [이곳](http://darkpgmr.tistory.com/105)을 참고하세요. 다음 식을 만족하는 람다와 X가 각각 정방행렬 A의 고유값과 고유벡터가 됩니다. 고유값과 고유벡터는 분석대상 데이터 행렬를 잘 표현하는 요약 결과이기 때문에 행렬식, 대각합 등과 더불어 중요한 정보가 되겠습니다. $$AX=\lambda X$$ 간단하게 고유값과 고유벡터를 구해보겠습니다. $$A=\begin{pmatrix} 1 & 0 \\ 0 & 3 \end{pmatrix}$$ $$\left| A-\lambda I \right| =\left| \begin{matrix} 1-\lambda & 0 \\ 1 & 3-\lambda \end{matrix} \right| =(1-\lambda )(3-\lambda )=0\\ \lambda =1\quad or\quad 3$$ 람다가 1일 때 $$AX=1\cdot X=\begin{pmatrix} 1 & 0 \\ 0 & 3 \end{pmatrix}\begin{pmatrix} { X }_{ 1 } & { X }_{ 2 } \end{pmatrix}=\begin{pmatrix} { X }_{ 1 } \\ { X }_{ 2 } \end{pmatrix}$$ $${ X }_{ 1 }={ X }_{ 1 },\quad { X }_{ 1 }+3{ X }_{ 2 }={ X }_{ 2 }\\ \therefore \quad { X }_{ 1 }=-2{ X }_{ 2 }$$ 람다가 3일 때 $$AX=3\cdot X=\begin{pmatrix} 1 & 0 \\ 0 & 3 \end{pmatrix}\begin{pmatrix} { X }_{ 1 } & { X }_{ 2 } \end{pmatrix}=\begin{pmatrix} { 3X }_{ 1 } \\ { 3X }_{ 2 } \end{pmatrix}$$ $${ X }_{ 1 }={ 3X }_{ 1 },\quad { X }_{ 1 }+3{ X }_{ 2 }={ 3X }_{ 2 }\\ \therefore \quad X=\begin{pmatrix} 0 \\ 1 \end{pmatrix}$$  ## 고유값 분해(Spectral Decomposition) 데이터 행렬을 고유값(람다)과 고유벡터(e)로 분해하는 방법입니다. 아래와 같이 정의됩니다. $$A=\sum _{ i=1 }^{ k }{ { \lambda }_{ i }{ e }_{ i }{ e }_{ i }^{ T } } $$ 고유값 분해를 간단하게 해보겠습니다. 행렬 A의 고유값과 고유벡터는 다음과 같습니다. $$A=\begin{pmatrix} 2.2 & 0.4 \\ 0.4 & 2.8 \end{pmatrix}\\ { \lambda }_{ 1 }=3,\quad { \lambda }_{ 2 }=2\\ { e }_{ 1 }=\begin{pmatrix} \frac { 1 }{ \sqrt { 5 } } \\ \frac { 2 }{ \sqrt { 5 } } \end{pmatrix},\quad { e }_{ 2 }=\begin{pmatrix} \frac { 2 }{ \sqrt { 5 } } \\ \frac { -1 }{ \sqrt { 5 } } \end{pmatrix}$$ 그러면 행렬 A는 아래와 같이 다시 쓸 수 있습니다. $$ \begin{align*} A&=\begin{pmatrix} 2.2 & 0.4 \\ 0.4 & 2.8 \end{pmatrix}\\ &=3\begin{pmatrix} \frac { 1 }{ \sqrt { 5 } } \\ \frac { 2 }{ \sqrt { 5 } } \end{pmatrix}\begin{pmatrix} \frac { 1 }{ \sqrt { 5 } } & \frac { 2 }{ \sqrt { 5 } } \end{pmatrix}+2\begin{pmatrix} \frac { 2 }{ \sqrt { 5 } } \\ \frac { -1 }{ \sqrt { 5 } } \end{pmatrix}\begin{pmatrix} \frac { 2 }{ \sqrt { 5 } } & \frac { -1 }{ \sqrt { 5 } } \end{pmatrix} \end{align*} $$    
disciminative␞ 이번 글에서는 **discriminative model** 개념을 [선형회귀](https://ratsgo.github.io/machine%20learning/2017/07/03/regression/)와 [로지스틱회귀](https://ratsgo.github.io/machine%20learning/2017/04/02/logistic/)를 중심으로 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## discriminative model *discriminative model*이란 데이터 $x$가 주어졌을 때 레이블 $y$가 나타날 조건부확률 $p(y$\|$x)$를 반환하는 모델을 가리킵니다. 레이블 정보가 있어야 하기 때문에 지도학습(supervised learning) 범주에 속하며 $x$의 레이블을 잘 구분하는 **결정경계(decision boundary)**를 학습하는 것이 목표가 됩니다. *discriminative model*은 [generative model]()에 비해 가정이 단순하고, 학습데이터 양이 충분하다면 좋은 성능을 내는 것으로 알려져 있습니다. 선형회귀와 로지스틱회귀는 *disciminative model*의 대표적인 예시입니다.   ## 선형회귀 선형회귀는 **제곱오차(squared error)**를 최소화하는 선형식을 찾는 것이 목적입니다. 이 글에서는 선형회귀를 확률모형 관점에서 살펴보겠습니다. 선형회귀는 잔차(error)가 **IID Zero Mean Gaussian**을 따른다고 가정합니다. 다음과 같습니다.  $$ \overrightarrow { e } =\overrightarrow { y } -X\overrightarrow { \beta } ,\quad \overrightarrow { e } \sim N(E(\overrightarrow { e } ),V(\overrightarrow { e } ))\\ E(\overrightarrow { e } )=\begin{bmatrix} 0 \\ 0 \\ ... \\ 0 \end{bmatrix},\quad V(\overrightarrow { e } )={ \sigma }^{ 2 }I $$  잔차와 모델 파라메터 $β$에 대한 로그우도(log-likelihood) 함수는 다음과 같습니다. 아래 로그우도 함수를 최대화하는 $β$가 바로 우리가 찾고자 하는 값입니다.  $$ \begin{align*} l(\overrightarrow { \beta } )=&\log { L(\overrightarrow { \beta } ) } \\ =&\log { \prod _{ i=1 }^{ m }{ \frac { 1 }{ \sqrt { 2\pi } \sigma } exp\left( -\frac { { \left( { y }^{ (i) }-{ \overrightarrow { \beta } }^{ T }{ x }^{ (i) } \right) }^{ 2 } }{ 2{ \sigma }^{ 2 } } \right) } } \\ =&m\log { \frac { 1 }{ \sqrt { 2\pi } \sigma } } -\frac { 1 }{ { \sigma }^{ 2 } } \frac { 1 }{ 2 } \sum _{ i=1 }^{ m }{ { \left( { y }^{ (i) }-{ \overrightarrow { \beta } }^{ T }{ x }^{ (i) } \right) }^{ 2 } } \end{align*} $$  위 식에서 $m$는 데이터 수, $π$는 상수, $σ$는 사용자가 지정하는 하이퍼파라메터로 위의 로그우도 함수 최대화에 영향을 끼치는 값이 아닙니다. 따라서 선형회귀 모델의 로그우도 함수를 최대화하는 것은 제곱오차를 최소화하는 것과 정확히 같은 일이 됩니다.   ## 로지스틱회귀 로지스틱회귀 모델의 손실함수는 **크로스엔트로피(cross entropy)**입니다. 범주가 1일 확률을 $p$, 0일 확률을 $1-p$라고 했을 때 [로지스틱회귀 모델](https://ratsgo.github.io/machine%20learning/2017/04/02/logistic/)은 다음과 같이 정의됩니다($σ$는 시그모이드 함수).  $$ p=\frac { 1 }{ 1+exp\left( -{ \overrightarrow { \beta } }^{ T }x \right) } =\sigma ({ \overrightarrow { \beta } }^{ T }x) $$ 로지스틱회귀의 로그우도 함수는 다음과 같습니다.  $$ \begin{align*} l(\overrightarrow { { \beta } } )=&\log { L(\overrightarrow { { \beta } } ) } \\ =&\log { \prod _{ i }^{ }{ { \sigma (\overrightarrow { { \beta } } ^{ T }{ x }_{ i }) }^{ { y }_{ i } }{ \left\{ 1-\sigma (\overrightarrow { { \beta } } ^{ T }{ x }_{ i }) \right\} }^{ 1-{ y }_{ i } } } } \\ =&\sum _{ i }^{ }{ { y }_{ i }\log { \left\{ \sigma (\overrightarrow { { \beta } } ^{ T }{ x }_{ i }) \right\} } } +\sum _{ i }^{ }{ \left( 1-{ y }_{ i } \right) \log { \left\{ 1-\sigma (\overrightarrow { { \beta } } ^{ T }{ x }_{ i }) \right\} } } \end{align*} $$  최종 도출된 로그우도 함수는 음의 [크로스엔트로피](https://ratsgo.github.io/deep%20learning/2017/09/24/loss/)인 점을 확인할 수 있습니다. 따라서 로지스틱회귀 모델의 로그우도 함수를 최대화하는 것은 크로스엔트로피를 최소화하는 것과 정확히 같은 일이 됩니다.
computeHMMs␞ 이번 글에선 **은닉마코프모델(Hidden Markov Models, HMMs)**의 계산과정과 구현을 다루어 보도록 하겠습니다. 순차적인 데이터를 다루는 데 강점을 지녀 개체명 인식, 포스태깅 등 단어의 연쇄로 나타나는 언어구조 처리에 과거 많은 주목을 받았던 기법입니다. 이 글은 고려대 강필성 교수님 강의와 역시 같은 대학의 정순영 교수님 강의, 서울대 언어학과 신효필 교수님 저서, 위키피디아, [Speech and Language Processing 3rd edition draft](https://web.stanford.edu/~jurafsky/slp3/9.pdf)를 정리했고, [jason2506](https://github.com/jason2506)님의 코드([BSD-licensed](https://opensource.org/licenses/BSD-3-Clause))를 이해하기 쉽게 정리했음을 먼저 밝힙니다. 모델 자체에 대해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/03/18/HMMs/)을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.  ## example 날씨를 은닉마코프모델로 구축한 예시는 다음 그림과 같습니다. <a href="https://imgur.com/lEMDGBC"><img src="https://i.imgur.com/lEMDGBC.png" width="500px" title="source: imgur.com" /></a> 위 그림에 나타난 전이확률 $A$를 행렬 형태로 나타내면 다음과 같습니다. | 구분  | start | HOT | COLD | end | | :---: | :---: | :--: | :--: | :--: | | start |  0  | 0.8 | 0.2 | 0  | | HOT |  0  | 0.6 | 0.3 | 0.1 | | COLD |  0  | 0.4 | 0.5 | 0.1 | | end |  0  | 0  | 0  | 0  | 방출확률 $B$는 다음과 같습니다. | 구분 | HOT | COLD | | :--: | :--: | :--: | | 1  | 0.2 | 0.5 | | 2  | 0.4 | 0.4 | | 3  | 0.4 | 0.1 | 아이스크림 관측치 $O$가 [3, 1, 3, 3, 1]으로 나타났다고 가정해 보겠습니다. 위 표와 같은 $A$, $B$, 즉 $θ$가 주어졌을 때 $O$가 나타날 확률(우도) $P(O$\|$θ)$는 다음과 같이 32가지 경우의 수에 해당하는 모든 확률들의 합입니다. |  상태1(3개)  |  상태2(1개)  |  상태3(3개)  |  상태4(3개)  |  상태5(1개)  | prob×10^7 | | :---------: | :---------: | :---------: | :---------: | :---------: | :-------: | | cold(.2×.1) | cold(.5×.5) | cold(.5×.1) | cold(.5×.1) | cold(.5×.5) |  31.25  | | cold(.2×.1) | cold(.5×.5) | cold(.5×.1) | cold(.5×.1) | hot(.4×.2) |  10   | | cold(.2×.1) | cold(.5×.5) | cold(.5×.1) | hot(.4×.4) | cold(.3×.5) |  60   | | cold(.2×.1) | cold(.5×.5) | hot(.4×.4) | cold(.3×.1) | cold(.5×.5) |  60   | | cold(.2×.1) | hot(.4×.2) | cold(.3×.1) | cold(.5×.1) | cold(.5×.5) |   6   | | hot(.8×.4) | cold(.3×.5) | cold(.5×.1) | cold(.5×.1) | cold(.5×.5) |  300  | | cold(.2×.1) | cold(.5×.5) | cold(.5×.1) | hot(.4×.4) | hot(.6×.2) |  48   | | cold(.2×.1) | cold(.5×.5) | hot(.4×.4) | cold(.3×.1) | hot(.4×.2) |  19.2  | | cold(.2×.1) | hot(.4×.2) | cold(.3×.1) | cold(.5×.1) | hot(.4×.2) |  1.92  | | hot(.8×.4) | cold(.3×.5) | cold(.5×.1) | cold(.5×.1) | hot(.4×.2) |  96   | | cold(.2×.1) | cold(.5×.5) | hot(.4×.4) | hot(.6×.4) | cold(.3×.5) |  288  | | cold(.2×.1) | hot(.4×.2) | cold(.3×.1) | hot(.4×.4) | cold(.3×.5) |  11.52  | | hot(.8×.4) | cold(.3×.5) | cold(.5×.1) | hot(.4×.4) | cold(.3×.5) |  576  | | cold(.2×.1) | hot(.4×.2) | hot(.6×.4) | cold(.3×.1) | cold(.5×.5) |  28.8  | | hot(.8×.4) | cold(.3×.5) | hot(.4×.4) | cold(.3×.1) | cold(.5×.5) |  576  | | cold(.2×.1) | cold(.5×.5) | hot(.4×.4) | hot(.6×.4) | hot(.6×.2) | 230.400 | | cold(.2×.1) | hot(.4×.2) | cold(.3×.1) | hot(.4×.4) | hot(.6×.2) |  9.216  | | hot(.8×.4) | cold(.3×.5) | cold(.5×.1) | hot(.4×.4) | hot(.6×.2) |  460.8  | | cold(.2×.1) | hot(.4×.2) | hot(.6×.4) | cold(.3×.1) | hot(.4×.2) |  9.216  | | hot(.8×.4) | cold(.3×.5) | hot(.4×.4) | cold(.3×.1) | hot(.4×.2) | 184.32  | | hot(.8×.4) | hot(.6×.2) | cold(.3×.1) | cold(.5×.1) | hot(.4×.2) |  46.08  | | cold(.2×.1) | hot(.4×.2) | hot(.6×.4) | hot(.6×.4) | cold(.3×.5) | 138.24  | | hot(.8×.4) | cold(.3×.5) | hot(.4×.4) | hot(.6×.4) | cold(.3×.5) | 2764.8  | | hot(.8×.4) | hot(.6×.2) | cold(.3×.1) | hot(.4×.4) | cold(.3×.5) | 276.48  | | hot(.8×.4) | hot(.6×.2) | hot(.6×.4) | cold(.3×.1) | cold(.5×.5) |  691.2  | | cold(.2×.1) | hot(.4×.2) | hot(.6×.4) | hot(.6×.4) | hot(.6×.2) | 110.592 | | hot(.8×.4) | cold(.3×.5) | hot(.4×.4) | hot(.6×.4) | hot(.6×.2) | 2211.84 | | hot(.8×.4) | hot(.6×.2) | cold(.3×.1) | hot(.4×.4) | hot(.6×.2) | 221.184 | | hot(.8×.4) | hot(.6×.2) | hot(.6×.4) | cold(.3×.1) | hot(.4×.2) | 221.184 | | hot(.8×.4) | hot(.6×.2) | hot(.6×.4) | hot(.6×.4) | cold(.3×.5) | 3317.76 | | hot(.8×.4) | hot(.6×.2) | hot(.6×.4) | hot(.6×.4) | hot(.6×.2) | 2654.208 | 위 32가지 경우의 수에 해당하는 결합확률의 합, 즉 우도는 0.001566021입니다. 이번엔 최적상태열을 구해보겠습니다.  | 항목     | 도출과정                   | | ----------- | ---------------------------------------- | | $v_1(hot)$ | P(hot\|start)×P(3\|hot)         | | $v_1(cold)$ | P(cold\|start)×P(3\|cold)        | | $v_2(hot)$ | max{$v_1$(hot)×P(hot\|hot)×P(1\|hot),$v_1$(cold)×P(hot\|cold)×P(1\|hot)\} | | $v_2(cold)$ | max\{$v_1$(hot)×P(cold\|hot)×P(1\|cold),$v_1$(cold)×P(cold\|cold)×P(1\|cold)\} | | $v_3(hot)$ | max\{$v_2$(hot)×P(hot\|hot)×P(3\|hot),$v_2$(cold)×P(hot\|cold)×P(3\|hot)\} | | $v_3(cold)$ | max\{$v_2$(hot)×P(cold\|hot)×P(3\|cold),$v_2$(cold)×P(cold\|cold)×P(3\|cold)\} | | $v_4(hot)$ | max\{$v_3$(hot)×P(hot\|hot)×P(3\|hot),$v_3$(cold)×P(hot\|cold)×P(3\|hot)\} | | $v_4(cold)$ | max\{$v_3$(hot)×P(cold\|hot)×P(3\|cold),$v_3$(cold)×P(cold\|cold)×P(3\|cold)\} | | $v_5(hot)$ | max\{$v_4$(hot)×P(hot\|hot)×P(1\|hot),$v_4$(cold)×P(hot\|cold)×P(1\|hot)\} | | $v_5(cold)$ | max\{$v_4$(hot)×P(cold\|hot)×P(1\|cold),$v_4$(cold)×P(cold\|cold)×P(1\|cold)\} | | $v_6(end)$ | max\{$v_5$(hot)×P(end\|hot),$v_5$(cold)×P(end\|cold)\} | 위 표를 실제 계산하면 다음과 같습니다. | 항목     | 최적상태(직전) | 비터비 확률                  | | ----------- | -------- | ---------------------------------------- | | $v_1(hot)$ | -    | .8×.4=.32                | | $v_1(cold)$ | -    | .2×.1=.02                | | $v_2(hot)$ | hot   | max(**.32×.6×.2**,.02×.4.×2)=.0384    | | $v_2(cold)$ | hot   | max(**.32×.3×.5**,.02×.5.×5)=.048    | | $v_3(hot)$ | hot   | max(**.0384×.6×.4**,.048×.4.×4)=.009216 | | $v_3(cold)$ | cold   | max(.0384×.3×.1,**.048×.5.×.1**)=.0024  | | $v_4(hot)$ | cold   | max(.009126×.6×.4,**.0024×.4.×4**)=.000384 | | $v_4(cold)$ | hot   | max(**.009126×.3×.1**,.0024×.5.×.1)=.00027378 | | $v_5(hot)$ | hot   | max(**.000384×.6×.2**,.00027378×.4.×2)=.00004608 | | $v_5(cold)$ | cold   | max(.000384×.3×.5,**.00027378×.5.×5**)=.000068445 | | $v_6(end)$ | cold   | max(.00004608×.1,**.000068445×.1**)=.0000068445 | 계산된 위 표를 토대로 backtrace를 하면 다음과 같은 최적상태열을 구할 수 있습니다. > HOT, HOT, HOT, COLD, COLD   ## Define Vars 전이확률 $A$, 방출확률 $B$, 상태집합 $Q$를 정의합니다. 초기 시작확률(*start_prob*) 또한 정의했습니다. ```python class Model(object): 	   # 변수 초기화   def __init__(self, states, symbols, start_prob=None, trans_prob=None, emit_prob=None):     # 상태(states) : hot, cold     self._states = set(states)     # 관측치(observation) : 아이스크림 개수 1, 2, 3     # 포스태깅 등에선 품사 태그(symbol)     self._symbols = set(symbols)     # 시작확률 : p(hot\|start), p(cold\|start)     self._start_prob = _normalize_prob(start_prob, self._states)     # 전이확률 : p(hot\|hot), p(cold\|hot), etc     self._trans_prob = _normalize_prob_two_dim(trans_prob, self._states, self._states)     # 방출확률 : p(3\|hot), etc     self._emit_prob = _normalize_prob_two_dim(emit_prob, self._states, self._symbols) ```   ## Forward Algorithm Forward Algorith은 $j$번째 상태에서 $o_1,...,o_t$가 나타날 전방확률 $α$를 구하는 기법입니다. 다음과 같이 정의됩니다.  $$ { \alpha }_{ t }(j)=\sum _{ i=1 }^{ n }{ { \alpha }_{ t-1 }(i)\times { a }_{ ij } } \times { b }_{ j }({ o }_{ t }) $$  Forward Algorithm을 파이썬 코드로 구현한 결과는 다음과 같습니다. ```python   def _forward(self, sequence):     # sequence : O     # 아이스크림 소비 기록 시퀀스 [3, 1, 3]     sequence_length = len(sequence)     if sequence_length == 0:       return [] 	       # Dynamic Programming     # 앞으로 중간 계산된 값들은 alpha라는 변수에 저장     alpha = [{}]         # 시작 지점의 alpha값 계산 후 alpha[0]에 저장     # alpha[0] = {'hot' : p(hot\|start) * p(3\|hot),     #       'cold' : p(cold\|start) * p(3\|cold)}     # p(3\|cold) : emit_prob('cold', 3)     # sequence[0] : 3     for state in self._states:       alpha[0][state] = self.start_prob(state) * self.emit_prob(state, sequence[0]) 	       # sequence의 두번째 값부터 마지막까지 likelihood 모두 계산     # index : 위 수식에서 t     for index in range(1, sequence_length):       alpha.append({})       for state_to in self._states:         prob = 0         for state_from in self._states:           # += : 위 수식에서 Σ           # alpha[index-1] : 위 수식에서 α_t-1           # state_from : 위 수식에서 i           # state_to : 위 수식에서 j           # trans_prob : 위 수식에서 a_ij           prob += alpha[index - 1][state_from] * \             self.trans_prob(state_from, state_to)         # emit_prob : 위 수식에서 b         # sequence[index] : 위 수식에서 o_t         alpha[index][state_to] = prob * self.emit_prob(state_to, sequence[index])     return alpha ```   ## Backward Probability 전방확률 $α$와 반대 방향으로 계산한 것이 후방확률 $β$입니다. 다음과 같이 정의됩니다.  $$ { \beta }_{ t }(i)=\sum _{ j=1 }^{ n }{ { a }_{ ij } } \times { b }_{ j }({ o }_{ t+1 })\times { \beta }_{ t+1 }(j) $$  다음은 $β$를 구하는 파이썬 코드입니다.  ```python   def _backward(self, sequence):     sequence_length = len(sequence)     if sequence_length == 0:       return []     beta = [{}]     for state in self._states:       beta[0][state] = 1     for index in range(sequence_length - 1, 0, -1):       beta.insert(0, {})       for state_from in self._states:         prob = 0         for state_to in self._states:           prob += beta[1][state_to] * \             self.trans_prob(state_from, state_to) * \             self.emit_prob(state_to, sequence[index])         beta[0][state_from] = prob     return beta ```    ## Viterbi algorithm $v_t(j)$는 $t$번째 시점의 $j$번째 은닉상태의 비터비 확률을 가리킵니다. $t$번째 시점 $j$번째 상태의 backtrace $b_{t_t}(j)$는 다음과 같이 정의됩니다.  $$ { v }_{ t }(j)=\max _{ i } ^{n}{ \left[ { v }_{ t-1 }(i)\times { a }_{ ij }\times { b }_{ j }({ o }_{ t }) \right] }\\{ b }_{ { t }_{ t } }(j)=arg\max _{ i=1 }^n{ \left[ { v }_{ t-1 }(i)\times { a }_{ ij }\times { b }_{ j }({ o }_{ t }) \right] } $$  파이썬 코드로 구현한 결과는 다음과 같습니다. ```python   def decode(self, sequence):     # sequence : O     # sequence_length : T     sequence_length = len(sequence)     if sequence_length == 0:       return [] 	      # delta : 비터비 확률 v     # Dynamic Programming : 중간 계산값 저장해 활용     delta = {}         # 시작 지점의 delta값 계산     for state in self._states:       # start_prob(state) : p(cold\|start) or p(hot\|start)       # sequence[0] : 관측 시퀀스의 첫번째 요소, o_1, '3'       # emit_prob(state, sequence[0]) : p(3\|cold) or p(3\|hot)       delta[state] = self.start_prob(state) * self.emit_prob(state, sequence[0])           # pre : backtrace     pre = []         # sequence의 두번째 값부터 마지막까지 delta, backtrace 모두 계산     # index : 위 수식에서 t     for index in range(1, sequence_length):       # delta_bar : t번째 관측치의 비터비 확률들       # index가 거듭될수록 그 요소가 늘어남       # 다 돌면 sequence_length 길이       delta_bar = {}       # pre_state : t번째 관측치의 backtrace들       # index가 거듭될수록 그 요소가 늘어남       # 다 돌면 sequence_length 길이       pre_state = {}       for state_to in self._states:         max_prob = 0         max_state = None # backtrace 변수         for state_from in self._states:           # state_from : 위 수식에서 i           # state_to : 위 수식에서 j           # delta[state_from] : 직전 상태의 비터비 확률(저장된 값 불러와 계산량 줄임)           # trans_prob : 위 수식에서 a           prob = delta[state_from] * self.trans_prob(state_from, state_to)           # 비터비 확률 수식에서 i에 대해 최대값을 구하는데,           # 방출확률 b는 i에 대해 무관하므로 최대값 연산에서 제외           if prob > max_prob:             # 최대값 저장 : 현재 상태의 비터비 확률             max_prob = prob             # 최대값의 위치 저장 : 현재 상태의 backtrace             max_state = state_from         delta_bar[state_to] = max_prob * self.emit_prob(state_to, sequence[index])         pre_state[state_to] = max_state       # o_2까지의 비터비 확률을 구했다면 o_1 이전의 비터비 확률은 불필요       # o_2의 비터비 확률들의 모음인 delta_bar를 전체 delta에 덮어씌움       delta = delta_bar       # o_2까지의 backtrace를 구했다 하더라도 o_3은 달라질 수 있음       # pre에 pre_state를 append       pre.append(pre_state) 	       # 전체 시퀀스를 대상으로 최대 비터비확률과     # 최대 비터비 확률을 내는 state 찾기     # 현재 delta에는 시퀀스의 마지막 요소(O_T)에     # 해당하는 비터비 확률들이 저장돼 있기 때문     # (state로만 구분되어 있음)     max_state = None     max_prob = 0     for state in self._states:       if delta[state] > max_prob:         max_prob = delta[state]         max_state = state     if max_state is None:       return [] 	      # 최대 비터비 확률을 내는 state가 backtrace의 첫번째 요소     result = [max_state]     # index를 시퀀스의 역방향으로 후진하면서     for index in range(sequence_length - 1, 0, -1):       # index에 해당하는 max_state들을 뽑아내기       # 이는 저 위쪽에서 이미 max_state들을 저장해두었기 때문에 가능       max_state = pre[index - 1][max_state]       # 뽑아낸 max_state들을 result의 첫번째 위치에 저장       result.insert(0, max_state)     return result ```   ## Training 은닉마코프모델의 학습 의사코드는 다음과 같습니다. <a href="https://imgur.com/ukU14ub"><img src="https://i.imgur.com/ukU14ub.png" width="600px" title="source: imgur.com" /></a> 파이썬으로 구현한 결과는 다음과 같습니다. ```python  def learn(self, sequence, smoothing=0):     length = len(sequence)     alpha = self._forward(sequence)     beta = self._backward(sequence)     gamma = []     for index in range(length):       prob_sum = 0       gamma.append({})       for state in self._states:         prob = alpha[index][state] * beta[index][state]         gamma[index][state] = prob         prob_sum += prob       if prob_sum == 0:         continue       for state in self._states:         gamma[index][state] /= prob_sum     xi = []     for index in range(length - 1):       prob_sum = 0       xi.append({})       for state_from in self._states:         xi[index][state_from] = {}         for state_to in self._states:           prob = alpha[index][state_from] * beta[index + 1][state_to] * \             self.trans_prob(state_from, state_to) * \             self.emit_prob(state_to, sequence[index + 1])           xi[index][state_from][state_to] = prob           prob_sum += prob       if prob_sum == 0:         continue       for state_from in self._states:         for state_to in self._states:           xi[index][state_from][state_to] /= prob_sum     states_number = len(self._states)     symbols_number = len(self._symbols)     for state in self._states:       # update start probability       self._start_prob[state] = \         (smoothing + gamma[0][state]) / (1 + states_number * smoothing)       # update transition probability       gamma_sum = 0       for index in range(length - 1):         gamma_sum += gamma[index][state]       if gamma_sum > 0:         denominator = gamma_sum + states_number * smoothing         for state_to in self._states:           xi_sum = 0           for index in range(length - 1):             xi_sum += xi[index][state][state_to]           self._trans_prob[state][state_to] = (smoothing + xi_sum) / denominator       else:         for state_to in self._states:           self._trans_prob[state][state_to] = 0       # update emission probability       gamma_sum += gamma[length - 1][state]       emit_gamma_sum = {}       for symbol in self._symbols:         emit_gamma_sum[symbol] = 0       for index in range(length):         emit_gamma_sum[sequence[index]] += gamma[index][state]       if gamma_sum > 0:         denominator = gamma_sum + symbols_number * smoothing         for symbol in self._symbols:           self._emit_prob[state][symbol] = \             (smoothing + emit_gamma_sum[symbol]) / denominator       else:         for symbol in self._symbols:           self._emit_prob[state][symbol] = 0     ```   ## 코드 실행 원저자의 코드는 [이곳](https://github.com/jason2506/PythonHMM/blob/master/hmm.py), 백업용으로 올려놓은 코드는 [이곳](https://gist.github.com/ratsgo/69376c0575bc34fda5992f66c83e7fad)에 있습니다. 은닉마코프모델을 수동으로 구성(모델이 이미 있는 것으로 전제)해 그 작동을 확인해보고자 한다면 아래와 같이 실행하면 됩니다. (위의 그림 예시와 같으나 end state는 없는 걸로 가정) ```python import hmm states = ('hot', 'cold') symbols = ('1', '2', '3') start_prob = {   'hot' : 0.8,   'cold' : 0.2 } trans_prob = {   'hot': { 'hot' : 0.6, 'cold' : 0.4 },   'cold': { 'hot' : 0.4, 'cold' : 0.6 } } emit_prob = {   'hot': { '1' : 0.2, '2' : 0.4, '3' : 0.4 },   'cold': { '1' : 0.5, '2' : 0.4, '3' : 0.1 } } model = hmm.Model(states, symbols, start_prob, trans_prob, emit_prob) sequence = ['3', '1', '3'] print(model.evaluate(sequence)) # Likelihood 계산 print(model.decode(sequence)) # 최적상태열 추정 ``` EM 알고리즘을 통한 학습은 다음과 같이 합니다. ```python import hmm sequences = [   (state_list1, symbol_list1),   (state_list2, symbol_list2),   ...   (state_listN, symbol_listN)] model = hmm.train(sequences) ```
mergesort␞ 이번 글에서는 **합병정렬(Merge Sort)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의를 정리했고, 코드는 [이곳](http://starblood.tistory.com/entry/merge-sort-in-Python-Python-%EC%9C%BC%EB%A1%9C-merge-sort-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0)을 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 합병정렬 합병정렬은 다음과 같은 방식으로 동작합니다. ([그림 출처](https://ko.khanacademy.org/computing/computer-science/algorithms/merge-sort/a/overview-of-merge-sort))  <a href="https://imgur.com/ood27RZ"><img src="https://i.imgur.com/ood27RZ.png" width="400px" title="source: imgur.com" /></a>  우선 데이터를 잘게 쪼갭니다(divide). 위 예시에선 8개로 쪼갰습니다. 둘씩 크기를 비교해 정렬합니다(conquer). 이를 합칩니다(merge). 이를 더 이상 합칠 array가 없을 때까지 반복합니다. 데이터 개수가 홀수개여서 정확히 둘로 쪼갤 수 없을 때는 왼쪽 배열에 요소 하나를 더 포함시킵니다. 여기에서 $p$는 하위 배열의 시작점, $r$은 끝점입니다. $q$는 하위 배열을 가르는 기준점입니다.    ## 파이썬 구현 합병정렬을 파이썬으로 구현한 코드는 다음과 같습니다. 우선 주어진 리스트를 중간 지점인 mid($q$)를 중심으로 왼쪽 리스트(*leftList*)와 오른쪽 리스트(*rightList*)로 쪼갭니다. *leftList*와 *rightList* 각각에 다시 이 작업을 재귀적으로 적용합니다. 분리된 리스트를 합치는 *merge* 함수는 주어진 두 개 리스트를 크기 순으로 정렬하는 역할을 합니다. 추후 다시 설명하겠습니다. ```python def merge_sort(list):   if len(list) <= 1:     return list   mid = len(list) // 2   leftList = list[:mid]   rightList = list[mid:]   leftList = merge_sort(leftList)   rightList = merge_sort(rightList)   return merge(leftList, rightList) ``` *merge_sort* 함수가 재귀적으로 수행되는 과정은 다음 그림과 같습니다.  <a href="https://imgur.com/3iDfSc3"><img src="https://i.imgur.com/3iDfSc3.gif" width="600px" title="source: imgur.com" /></a>  `14, 7, 3, 12, 9, 11, 6, 2`가 주어졌을 때 *merge_sort* 함수가 돌면서 리스트를 분리하는 과정은 다음과 같습니다. | Iter |  변수명  |      리스트      | | :--: | :-------: | :-----------------------: | | 0  | raw list | 14, 7, 3, 12, 9, 11, 6, 2 | | 1  | leftList |    14, 7, 3, 12    | | 1  | rightList |    9, 11, 6, 2    | | 2  | leftList |      14, 7      | | 2  | rightList |      3, 12      | | 3  | leftList |      14       | | 3  | rightList |       7       | | 4  | leftList |       3       | | 4  | rightList |      12       | | 5  | leftList |      9, 11      | | 5  | rightList |      6, 2      | | 6  | leftList |       9       | | 6  | rightList |      11       | | 7  | leftList |       6       | | 7  | rightList |       2       | 분리된 리스트를 합치는 *merge* 함수는 다음과 같습니다. 위에서 분리한 왼쪽 리스트(*left*)와 오른쪽 리스트(*right*)의 첫번째 요소를 비교해 작은 값을 결과 리스트(*result*)에 저장해 놓고, 해당 값을 해당 리스트에서 지웁니다. 이를 *left*와 *right*의 요소가 하나도 없을 때까지 반복합니다. ```python def merge(left, right):   result = []   while len(left) > 0 or len(right) > 0:     if len(left) > 0 and len(right) > 0:       if left[0] <= right[0]:         result.append(left[0])         left = left[1:]       else:         result.append(right[0])         right = right[1:]     elif len(left) > 0:       result.append(left[0])       left = left[1:]     elif len(right) > 0:       result.append(right[0])       right = right[1:]   return result ``` 우선 *merge* 함수가 1회 돌 때 어떻게 작동하는지 살펴보겠습니다. 예컨대 [3, 7, 12, 14]가 *left*, [2, 6, 9, 11]이 *right*인 상황에서 *merge* 함수는 다음과 같이 동작합니다. 볼드 표시는 비교 대상입니다. | *left*      | *right*     | *result*         | | ---------------- | --------------- | ------------------------- | | **3**, 7, 12, 14 | **2**, 6, 9, 11 |              | | **3**, 7, 12, 14 | **6**, 9, 11  | 2             | | **7**, 12, 14  | **6**, 9, 11  | 2, 3           | | **7**, 12, 14  | **9**, 11    | 2, 3, 6          | | **12**, 14    | **9**, 11    | 2, 3, 6, 7        | | **12**, 14    | **11**     | 2, 3, 6, 7, 9       | | 12, 14      |         | 2, 3, 6, 7, 9, 11     | | 12        |         | 2, 3, 6, 7, 9, 11, 12   | |         |         | 2, 3, 6, 7, 9, 11, 12, 14 | *merge* 함수가 여러 차례 호출되면서 연산하는 과정은 다음과 같습니다. |     병합된 리스트     | | :-----------------------: | |      7, 14      | |      3, 12      | |    3, 7, 12, 14    | |      9, 11      | |      2, 6      | |    2, 6, 9, 11    | | 2, 3, 6, 7, 9, 11, 12, 14 |   ## 합병정렬의 계산복잡성 데이터 개수가 $n$이라고 할 때 이를 정렬하는 데 $cn$의 시간이 걸린다고 칩시다. $c$는 컴퓨팅 파워 등과 관계 있는 어떤 상수를 나타냅니다. 우선 아래 그림을 봅시다.  <a href="https://imgur.com/M6hih5n"><img src="https://i.imgur.com/M6hih5n.png" width="400px" title="source: imgur.com" /></a>  예컨대 위에서부터 세 번째 층의 경우 원래 데이터를 4개로 쪼갰기 때문에 각각은 $cn/4$의 시간이 걸리지만, 데이터 덩어리 역시 4개이기 때문에 이에 해당하는 층의 계산시간은 $4×cn/4=cn$이 됩니다.  전체 층의 수가 $\log_2{n}$이 되는 이유는 $n$에 구체적인 수를 넣어보면 명확해집니다. 예컨대 데이터 개수($n$)가 8개라고 칩시다. 그러면 전체 층의 수는 3이 됩니다. 따라서 상수항($c$)을 무시하고 생각해보면 합병정렬의 계산복잡성은 $O(n\log{n})$(각 층의 계산시간 × 전체 층의 수)가 되는 것입니다. 한편 지금까지 설명해드린 합병정렬은 데이터를 한번 쪼갤 때 반씩 나누는 걸로 정했습니다만, 3개나 4개로 쪼개도 합병정렬을 구현할 수 있습니다.  가령 3개로 쪼갤 경우 전체 층의 수는 $\log_3{n}$이 되는데요. 이는 로그의 성질에 의해 $\log_2{3}×\log_2{n}$과 같습니다. 첫째 항은 상수이므로 매 분기마다 3개씩 쪼개도 합병정렬의 계산복잡성은 $O(n\log{n})$로 동일합니다. 3개로 분기하는 경우 절반씩 나누는 것보다 인덱스 등 관리 비용이 커지므로 알고리즘 실행 환경에 따라 유연하게 대처해야 할 것 같습니다   ## 합병정렬의 특성 합병정렬은 수행 과정에서 리스트를 쪼갰다가 다시 합치는데, 같은 숫자의 경우에는 순서가 뒤바뀌지 않으므로 *stable sort*입니다. 별도 저장 공간이 필요한지 여부(*in-place sort* 여부)는 자료구조를 뭘 쓰느냐에 따라 달라집니다. 우선 연결리스트(linked list)를 쓰는 경우엔 *in-place sort*로 구현할 수 있습니다. 다음과 같이 기존 저장공간에서 포인터만 바꾸는 형식으로 합병정렬을 수행할 수 있는 덕분입니다. 예컨대 데이터를 쪼갤 경우 *head* 포인터를 더 두면 되고, 정렬하려는 경우 *next* 포인터가 가리키는 주소값을 바꿔주면 됩니다.  <a href="https://imgur.com/nbnpk50"><img src="https://i.imgur.com/nbnpk50.png" width="500px" title="source: imgur.com" /></a>  반면 배열을 쓰는 경우에는 다음 그림처럼 정렬된 리스트를 저장해 둘 별도 공간(buffer)이 필요해 *in-place sort*가 아니게 됩니다.  <a href="https://imgur.com/kpDOStz"><img src="https://i.imgur.com/kpDOStz.png" width="400px" title="source: imgur.com" /></a>
candidate␞ 이번 글에서는 소프트맥스 확률을 구할 때 계산량을 줄이는 **Candidate sampling** 기법에 대해 살펴보도록 하겠습니다. 이번 글은 각 논문과 [Quora](https://www.quora.com/What-is-Noise-Contrastive-estimation-NCE)를 정리하였습니다. 혹시 제가 잘못 알고 있거나 틀린 점 있으시면 댓글로 지적해주시면 고맙겠습니다. 그럼 시작하겠습니다.  ## 목적 다범주 분류를 수행하는 딥러닝 모델의 말단에는 소프트맥스 확률과 크로스엔트로피 손실(loss)을 구하는 'Softmax-with-Loss' 계층이 있습니다. 딥러닝 모델의 파라메터 업데이트를 하기 위해서는 손실에 대한 그래디언트를 구해야 하는데요. 3개 범주를 분류하는 모델을 구축한다고 했을 때 Softmax-with-Loss 계층의 손실에 대한 그래디언트는 다음 그림의 적색 화살표와 같습니다.  <a href="https://imgur.com/gyeTKAn"><img src="https://i.imgur.com/gyeTKAn.png" width="400px" title="source: imgur.com" /></a>  위 그림에서 $y_i$는 $i$번째 범주에 대한 소프트맥스 확률입니다. $t_j$는 $j$번째 범주의 실제 정답(1 혹은 0)입니다. 다시 말해 모든 범주에 대해 소프트맥스 확률을 구해야 손실에 대한 그래디언트를 계산할 수 있다는 이야기입니다. 그런데 여기서 범주 수가 10만개가 넘는다면 어떻게 될까요? 소프트맥스 확률값을 구할 때 계산량이 어마어마하게 많아질 겁니다. 특히 자연어의 경우 단어의 수가 적게는 수십만개에서 많게는 수백만개에 이르기 때문에 자연언어처리를 위한 딥러닝 모델을 만들 때 소프트맥스 확률값을 구할 때 계산량을 줄이려는 노력이 계속돼 왔습니다. Candidate sampling이 제안된 배경입니다.   ## 몇 개만 뽑아서 계산하기 가장 간단한 아이디어로는 단어 몇 개만 뽑아서 소프트맥스 확률값을 구하고, 뽑힌 해당 단어들과 해당 단어들에 관계된 파라메터에 대해서만 업데이트하는 겁니다. [On Using Very Large Target Vocabulary for Neural Machine Translation](https://arxiv.org/abs/1412.2007)에서 제안된 방법입니다. 예컨대 문맥 $c$가 주어졌을 때 단어 $w$가 나타날 조건부확률은 다음과 같이 근사화합니다.  $$ \begin{align*} p\left( w|c \right) =\frac { exp\left( { w }^{ T }c \right) }{ \sum _{ w'\in V }^{ }{ exp\left( { w' }^{ T }c \right) } } \\ \approx \frac { exp\left( { w }^{ T }c \right) }{ \sum _{ w'\in V' }^{ }{ exp\left( { w' }^{ T }c \right) } } \end{align*} $$  위 식에서 $V$는 말뭉치 전체의 단어로 이뤄진 집합입니다. $V'$는 $V$에서 $k$개 단어를 뽑은 $V$의 부분집합입니다. 소프트맥스 확률을 구할 때 말뭉치 전체 단어를 고려하지 않고 $k$개 일부 단어들만 고려하기 때문에 계산량을 상당히 많이 줄일 수 있습니다. 논문에 따르면 그 성능도 많이 떨어지지 않는다고 합니다.   ## Negative Sampling [Word2Vec](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)에 쓰인 Negative Sampling은 **Noise Contrasive Estimation**의 단순화된 버전입니다. Negative Sampling은 소프트맥스 확률을 구할 때 계산량을 줄이기 위해 일부 샘플만 뽑아서 계산한다는 점에서는 위 방법과 공통점을 지닙니다. 가장 큰 차이점은 Noise Distribution 개념입니다. Word2Vec의 Negative Sampling에서는 단어 벡터를 학습할 때 Noise(=Negative) 샘플인지 여부를 가리는 이진 분류 문제(binary classification problem)로 접근합니다. Word2Vec 모델에서 Negative 샘플은 사용자가 정한 window 내에 등장하지 않는 단어들(정답=0)입니다. 반면 Positive 샘플(window 내에 등장하는 단어들)은 정답을 1로 놓고 학습을 하는 방식입니다. Word2Vec 학습과정에선 중심단어와 Positive 샘플의 단어벡터들끼리는 유사하게(내적값 상향), 중심 단어와 Negative 샘플의 단어벡터들끼리는 멀게(내적값 하향) 업데이트됩니다. 논문에 따르면 1회 학습시 사용하는 Negative 샘플의 수는 작은 말뭉치일 경우 5~20개, 큰 말뭉치일 경우 2~5개가 적당합니다. 다시 말해 1회 학습시 최대 20개 정도의 단어벡터를 업데이트하는 셈입니다.
list␞ 이번 글에서는 **리스트(List)**와 **연결리스트(Linked List)** 개념에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의를 정리하였음을 먼저 밝힙니다. 파이썬 코드는 [이곳](https://www.codefellows.org/blog/implementing-a-singly-linked-list-in-python/)을 기본으로 하되 조금 수정하였습니다. 그럼 시작하겠습니다.   ## 리스트 리스트란 같은 값이 한번 이상 존재할 수 있고 순서가 있는 일련의 값이 모여있는 추상적 자료형(Abstract Data Type)입니다. 예컨대 리스트 (C, Y, R)은 (Y, C, R)과 다릅니다. 리스트에는 Add, Delete, Access(read/change) 연산이 있습니다.  ### Insert 주어진 리스트의 첫번째 위치에 한 요소를 추가하는 연산의 계산복잡성은 리스트가 $n$개 요소로 구성돼 있을 때 $O(n)$이 됩니다. $n$개 요소 각각의 위치를 오른쪽으로 한 칸씩 모두 옮겨야 하기 때문입니다. $k$번째 위치에 새로운 요소를 추가할 경우 계산복잡성은 $O(n-k)=O(n)$입니다. 한편 주어진 리스트 마지막 위치에 요소를 추가하는 연산은 $O(1)$입니다. 파이썬은 내장함수로 리스트 추가 연산을 제공하는데요. 다음과 같습니다. ```python a = [1, 2, 3] a.insert(0, 4) # [4, 1, 2, 3] ```  ### Delete 주어진 리스트의 첫번째 위치에 한 요소를 삭제하는 연산의 계산복잡성은 리스트가 $n$개 요소로 구성돼 있을 때 $O(n)$이 됩니다. $n-1$개 요소 각각의 위치를 왼쪽으로 한 칸씩 모두 옮겨야 하기 때문입니다. $k$번째 위치에 있는 요소를 삭제할 경우 계산복잡성은 $O(n-k)=O(n)$입니다. 한편 주어진 리스트 마지막 위치의 요소를 삭제하는 연산은 $O(1)$입니다. 파이썬은 내장함수로 리스트 삭제 연산을 제공하는데요. 다음과 같습니다. ```python a = [1, 2, 3] del a[0] #[2, 3] ```  ### Access 주어진 리스트의 특정 위치에 있는 요소값을 읽거나 바꾸는 Access 연산의 계산복잡성은 $O(1)$입니다. 파이썬은 내장함수로 리스트 Access 연산을 제공하는데요. 다음과 같습니다. ```python a = [1, 2, 3] a[0] # 1 a[1] = 4 # [1, 4, 3] ```  ### Scalability issue 리스트라는 자료형의 단점은 요소의 최대 개수를 사전에 정해야 하고, 그 개수를 넘어서는 요소들을 입력할 수 없다는 점입니다. 이를 scalability issue라고 합니다. 실제로 파이썬에서 다음과 같은 명령어를 입력했을 때 에러가 납니다. 앞으로 설명할 연결리스트는 이 단점을 극복한 자료구조입니다. ```python a = [1, 2, 3] a[3] = 1 # IndexError: list assignment index out of range ```    ## 연결리스트 연결리스트란 각 노드가 연결되어 있는 방식으로 데이터가 저장돼 있는 추상적 자료형입니다. 한 노드는 해당 노드의 실제값(value)과 다음 노드의 주소값이 담긴 포인터(pointer)로 구성돼 있습니다. 마지막 노드의 포인터는 Null값을 갖습니다. 다음과 같습니다.  <a href="https://imgur.com/9xW5ltQ"><img src="https://i.imgur.com/9xW5ltQ.png" width="300px" title="source: imgur.com" /></a>  연결리스트는 포인터의 존재 덕분에 리스트의 길이를 사전에 정할 필요가 없습니다. 포인터만 조금 바꿔주면 리스트 요소의 추가가 얼마든지 가능하기 때문입니다. 위의 각 노드를 파이썬으로 구현한 코드는 다음과 같습니다. 각 노드는 개별 클래스로 구성되며 각 노드(클래스)는 실제값(변수명 *data*에 저장)과 포인터(변수명 *next_node*에 저장)로 구성됩니다. ```python class Node(object):   def __init__(self, data=None, next_node=None):     self.data = data     self.next_node = next_node   def set_next(self, new_next):     self.next_node = new_next ```  ### Insert 주어진 연결리스트의 첫번째 위치에 한 요소를 추가하는 연산의 계산복잡성은 리스트가 $n$개 요소로 구성돼 있을 때 $O(1)$이 됩니다. 전체 요소의 인덱스를 변경할 필요 없이 추가할 노드가 가리키는 다음 위치(포인터)를 기존 연결리스트의 첫번째 요소(*head*)에 연결하고, 추가할 새로운 노드를 기존 연결리스트의 첫번째 요소로 정의하기만 하면 되기 때문입니다. 다음과 같습니다. ```python class LinkedList(object):   def __init__(self, head=None):     self.head = head   def insert(self, data):     new_node = Node(data)     # 추가 노드의 다음 위치를 기존 head에 연결     new_node.set_next(self.head)     # 추가 노드를 새로운 head로 정의     self.head = new_node ```  ### Delete 주어진 연결리스트의 첫번째 위치의 요소(*head*)를 삭제하는 연산의 계산복잡성은 리스트가 $n$개 요소로 구성돼 있을 때 $O(1)$이 됩니다. 전체 요소의 인덱스를 변경할 필요 없이 기존 *head*의 다음 다음번 노드의 위치를 저장해 두었다가(*new_head_next_node*), 기존 *head*의 다음 노드의 값을 새로운 *head*의 값으로 하고 *new_head_next_node*를 새로운 *head*의 포인터로 하는 새로운 *head*를 재정의해주기만 하면 되기 때문입니다. 다음과 같습니다. ```python   def delete(self):     new_head_next_node = self.head.next_node.next_node     self.head = Node(self.head.next_node.data)     self.head.next_node = new_head_next_node ```  ### Access 주어진 연결리스트의 특정 위치에 있는 요소값을 읽거나 바꾸는 Access 연산의 계산복잡성은 $O(n)$입니다. 예컨대 $k$번째 위치에 있는 값을 읽으려면 $k$개의 요소를 읽어들여야 하기 때문입니다. *idx*번째 요소에 Access하는 파이썬 코드는 다음과 같습니다. ```python   def access(self, idx):     current = self.head     i = 0     while i < idx:       i += 1       current = current.next_node     return current.data ```  ### 실행 구체적인 실행 결과는 다음과 같습니다. ```python a = LinkedList() a.insert(1) a.insert(2) a.insert(3) a.access(0) # 3 a.delete() a.access(0) # 2 ```  ### 여러 가지 연결리스트 지금까지 설명해드린 연결리스트는 엄밀히 말해 단일연결리스트(singly linked list)입니다. 그런데 다음과 같은 변형이 존재합니다. 각각 이중연결리스트(doubly linked list), 원형연결리스트(circular linked list)입니다.  이중연결리스트는 Head와 Tail 모두 움직일 수 있어 Access 연산시 계산복잡성을 줄일 수 있습니다. 원형연결리스트는 링 버퍼(ring buffer) 등과 같이 메모리 효율성이 중요한 디바이스에서 널리 사용되고 있다고 합니다. <a href="https://imgur.com/3nNhCbh"><img src="https://i.imgur.com/3nNhCbh.png" width="500px" title="source: imgur.com" /></a> <a href="https://imgur.com/eqIJX4z"><img src="https://i.imgur.com/eqIJX4z.png" width="500px" title="source: imgur.com" /></a>
biasvar␞ 이번 글에서는 **Bias-Variance Decomposition**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 수식적 이해 Bias-Variance Decomposition은 **일반화(generalization)** 성능을 높이는 정규화(Regularization), 앙상블(ensemble) 기법의 이론적 배경으로 널리 알려져 있습니다. 학습에 쓰지 않은 미래데이터에 대한 오차의 기대값을 모델의 Bias와 Variance로 분해하는 내용이 골자입니다.  우선 $F*$를 우리가 찾아야 할 궁극의 모델이라고 칩시다. 이를 확률모형으로 나타내면 아래와 같습니다. 여기에서 $σ^2$는 이론적인 오차, natural error를 의미하는데요. 궁극의 모델 $F$의 기대값은 0입니다.  $$y={ F }^{ * }(x)+\varepsilon ,\quad \varepsilon \sim N(0,{ \sigma }^{ 2 })$$  하지만 우리가 항상 $F*$를 찾아낼 수 있는 건 아닙니다. 데이터에 노이즈가 끼어있을 수 있는데다 모든 데이터를 가지고 모델을 만들어낼 수 있는 게 아니기 때문입니다. 우리가 가진 학습데이터에서 찾아낸 모델을 F-hat이라 두겠습니다. 그러면 F-hat은 구축할 때마다 다를 겁니다. 이를 그림으로 나타내면 아래와 같습니다. <a href="http://imgur.com/3m4rZO4"><img src="http://i.imgur.com/3m4rZO4.png" width="350px" title="source: imgur.com" /></a> 우리는 이를 바탕으로 F-bar를 도출해낼 수 있습니다. 여러 모델의 평균치를 나타내는 함수입니다.  $$\overline { F } (x)=E\left[ \hat { { F }_{ i } } (x) \right] $$  우리는 학습데이터로부터 F-hat을 만들었고, 이를 바탕으로 미래데이터 $x_0$을 하나 예측해야 한다고 가정해 보겠습니다. 이 데이터에 대한 오차의 기대값을 수식으로 나타내면 아래와 같습니다.  $$ \begin{align*} Expected\quad MSE&=E\left[ { (y-\hat { F } (x)) }^{ 2 }|x={ x }_{ 0 } \right] \\ &=E\left[ { \left\{ { F }^{ * }({ x }_{ 0 })+\varepsilon -\hat { F } ({ x }_{ 0 }) \right\} }^{ 2 } \right] \\ &=E\left[ { \left\{ { F }^{ * }({ x }_{ 0 })-\hat { F } ({ x }_{ 0 }) \right\} }^{ 2 } \right] +2\left\{ { F }^{ * }({ x }_{ 0 })-\hat { F } ({ x }_{ 0 }) \right\} E\left[ \varepsilon \right] +E\left[ { \varepsilon }^{ 2 } \right] \end{align*} $$  $E(ε)=0$이므로 $Var(ε)=E(ε^2)$입니다. 식을 아래와 같이 변형해 정리할 수 있습니다.  $$ \begin{align*} Expected\quad MSE&=E\left[ { \left\{ { F }^{ * }({ x }_{ 0 })-\hat { F } ({ x }_{ 0 }) \right\} }^{ 2 } \right] +{ \sigma }^{ 2 }\\ &=E\left[ { \left\{ { F }^{ * }({ x }_{ 0 })-\overline { F } ({ x }_{ 0 })+\overline { F } ({ x }_{ 0 })-\hat { F } ({ x }_{ 0 }) \right\} }^{ 2 } \right] +{ \sigma }^{ 2 } \end{align*} $$  여기서 잠깐, 아래 식이 성립함을 알 수 있습니다.-  $$E\left[ \overline { F } ({ x }_{ 0 })-\hat { F } ({ x }_{ 0 }) \right] =\overline { F } ({ x }_{ 0 })-\overline { F } ({ x }_{ 0 })=0$$  이를 활용해 원래 식에 정리하면 다음과 같습니다.  $$ \begin{align*} Expected\quad MSE&=E\left[ { \left\{ { F }^{ * }({ x }_{ 0 })-\overline { F } ({ x }_{ 0 }) \right\} }^{ 2 } \right] +E\left[ { \left\{ \overline { F } ({ x }_{ 0 })-\hat { F } ({ x }_{ 0 }) \right\} }^{ 2 } \right] +{ \sigma }^{ 2 }\\ &={ \left\{ { F }^{ * }({ x }_{ 0 })-\overline { F } ({ x }_{ 0 }) \right\} }^{ 2 }+E\left[ { \left\{ \overline { F } ({ x }_{ 0 })-\hat { F } ({ x }_{ 0 }) \right\} }^{ 2 } \right] +{ \sigma }^{ 2 }\\ &={ Bias }^{ 2 }(\hat { F } ({ x }_{ 0 }))+Var(\hat { F } ({ x }_{ 0 }))+{ \sigma }^{ 2 } \end{align*} $$  위 식의 의미는 이렇습니다. **Bias**는 여러 모델의 예측 평균(F-bar)과 실제 정답($y$)과의 편차입니다. $Var$는 개별모델의 예측값(F-hat)과 여러 모델의 예측 평균(F-bar)과의 편차 제곱의 기대값입니다. 요컨대 임의의 미래데이터 $x_0$의 오차 기대값은 모델의 Bias와 Variance, Natural Error 세 요소로 분해할 수 있습니다.  ## 직관적 이해 Bias와 Variance를 직관적으로 나타낸 그림은 아래와 같습니다. 파란 원의 중심은 True Function $F^*$를 의미합니다. 파란 원은 실제값 $y$가 가질 수 있는 범위를 나타냅니다. 노란 원의 중심(빨간점)은 F-hat의 평균, 즉 F-bar를 의미합니다. 빨간 실선은 F-hat이 예측하는 값의 범위를 가리킵니다. 아래 그림에서도 알 수 있듯 Bias와 Variance가 작을 수록 True Function에 가까워집니다. <a href="http://imgur.com/TMLib2X"><img src="http://i.imgur.com/TMLib2X.png" width="450px" title="source: imgur.com" /></a> 위 그림은 아래처럼 해석할 수도 있습니다. 먼저 표를 보시죠. <a href="http://imgur.com/DxsRMnO"><img src="http://i.imgur.com/DxsRMnO.png" width="600px" title="source: imgur.com" /></a> 우선 왼쪽부터 첫번째 그림을 보면 예측값(파란색 엑스표)의 평균이 과녁(Truth)과 멀리 떨어져 있어 Bias가 크고, 예측값들이 서로 멀리 떨어져 있어 Variance 또한 큰 것을 확인할 수 있습니다. 반면 네번째 그림의 경우 Bias, Variance 모두 작습니다. 네번째 경우가 제일 이상적이라고 할 수 있죠. 두번째 그림의 경우 예측값 평균이 과녁과 그리 멀지 않아 Bias가 작은 걸 확인할 수 있습니다. 반면 세번째 그림은 예측값들이 서로 오밀조밀 모여 있어 Variance가 작은 걸 볼 수 있습니다. 위 그림에서 세번째 그림인 High Bias, Low Variance에 해당하는 사례는 로지스틱 회귀, LDA, K-NN(large k) 등 데이터 노이즈에 비교적 강건한 모델입니다. 위 그림에서 두번째 그림인 Low Bias, High variance에 해당하는 사례는 뉴럴네트워크, SVM, K-NN(small k) 등 튜닝만 잘하면 과녁을 제대로 맞출 수 있는 모델들입니다. **부스팅(boosting)** 등이 Bias를 줄여 성능 향상을 꾀하는 기법입니다. **라쏘회귀(Lasso Regression)** 등 정규화 기법들이 Variance를 줄여 성능 향상을 추구합니다.
words␞ 이번 글에서는 한국어의 조사에 대해 알아보도록 하겠습니다. **자연언어처리** 분야에서 한국어 조사는 분석의 까다로움 때문에 전처리 때 아예 제거되는 **불용어(stopwords)** 취급을 받고 있는데요. 사실 **교착어(첨가어)**인 한국어에서 조사는 문법적, 의미적으로 큰 역할을 하고 있는 형태소입니다. 이 글은 기본적으로 한국어 문법론 대가 이익섭 서울대 명예교수께서 쓰신 ['한국어문법'](http://book.naver.com/bookdb/book_detail.nhn?bid=7028626)을 참고했습니다. 조사의 종류와 용법에 대해 간단히 정리한 후 1년치 조간신문 기사에서 조사가 얼마나 많이 쓰였는지 양적인 통계를 한번 내봤습니다.  이 글의 목차는 다음과 같습니다.   * 목차 {:toc}    # 격조사 **조사(助詞)**는 크게 **격(格)**을 나타내는 격조사와 특수조사로 나뉩니다. 한국어는 조사가 발달한 걸 특징으로 삼을 수 있을 만큼 그 수도 많거니와 그 쓰임도 매우 다양합니다. 우선 격조사를 종류별로 간단히 살펴보겠습니다.   ## 주격조사 주격조사는 한 문장의 주어 자리에 쓰이는 조사입니다. **이/가** : 대표적인 주격조사, 보어 자리에 쓰이기도 합니다 > 비가 온다. 바람이 분다. > > 낙엽송은 상록수가 아니다. **께서** : 주어를 존대하기 위해 쓰는 조사 > 증조할아버지께서 이 비석을 쓰셨답니다. **에서** : 단체나 기관이 주어일 때 쓰는 조사 > 당국에서 책임을 지겠지요.  ## 대격조사 대격조사(對格助詞) '을/를'은 목적어 자리에 쓰이는 조사로 어떤 행위가 미치는 대상을 가리킵니다. 목적격조사라고 불리기도 합니다. > 무슨 선물을 받았니? > > 새해 무슨 좋은 꿈을 꾸셨나요? > > 어디를 그리 바삐 가니? > > 인부들이 나무를 밑동을 잘랐다.  ## 처격조사 처격조사(處格助詞)는 처소(處所)를 나타내 주는 것을 주된 임무로 하는 조사입니다. **에** : 공간적인 범위, 이유 등 꽤 다양한 의미로 쓰이는 처격조사 > 어제는 종일 집에 있었다. (공간적 범위) > > 나팔꽃은 아침에 피었다가 저녁에 진다. (시간적 범위) > > 이 책은 어디에 보낼 거니? (지향점) > > 올림픽은 4년에 한 번씩 열린다. (단위) > > 그 글은 내 마음에 들이 않는다. (추상적 공간) > > 천둥소리에 모두들 깜짝 놀랐다. (이유) > > 생각난 김에, 순식간에, 에 대하여... (관용구) **에게** : '에'와 밀접한 관계에 있는 처격조사, 동물이나 사람처럼 감정이 있는 명사와 결합해 쓰입니다. > 그 편지를 어디에 보냈니? // 그 편지를 누구에게 보냈니? > > 화초에 물 좀 주렴. // 아이들에게 물 좀 주렴. > > 이번 일의 책임은 전적으로 회사에 있습니다. // 이번 일의 책임은 전적으로 저에게 있습니다. **께** : '에게'의 높임말입니다. > 이번 일의 책임은 전적으로 회장님께 있습니다. **한테/더러** : '에게'와 거의 같은 성질을 가진 조사이지만 사용에 일부 제약이 있습니다. > 이걸 누구에게 물어볼까? // 이걸 누구한테 물어볼까? // 이걸 누구 더러 물어볼까? > > 너{한테, 에게, *더러} 무슨 책임이 있겠니? > > 어린 새끼들{한테, ?에게, *더러} 아직 풀은 주지 마라. **에서/에게서/한테서** : '에', '에게', '한테'는 이쪽에서 저쪽으로 가는 방향을, '에서', '에게서', '한테서'는 반대로 저쪽에서 이리로 오는 방향을 가리킵니다. > 선수단이 부산에 왔다. // 선수단이 부산에서 왔다. > > 누나한테 형한테서 편지가 왔다. // 누나한테서 형한테 편지가 왔다. **에/에서** : 한국어를 배우는 외국인이 어려워 하는 것 중 하나가 '에'와 '에서'의 구별입니다. 의미 차이가 그리 선명하게 드러나지 않을 때가 종종 있기 때문입니다. 하지만 둘은 분명 구분해서 써야 합니다. > 이 화분은 거실에 놓읍시다. // 거실에서 뛰지 마라. > > 나는 그 때 제주도에 있었다. // 나는 그때 제주도에서 근무하였다.  ## 구격조사 구격조사(具格助詞)는 무엇을 만들 때 쓰이는 도구나 재료 및 어떤 일을 하는 수단을 나타내 주는 조사입니다. 대표적으로 **로/으로**가 있습니다. > 도끼로 장작을 패 본 일이 있니? (도구) > > 콩으로 메주를 쏜다고 해도 안 믿는구나. (재료) > > 토끼는 꾀로 그 위기를 벗어났다. (수단) > > 가뭄으로 농작물의 피해가 여간 크지 않답니다. (이유)  ## 향격조사 '으로'는 지향점 및 통과지점을 가리키는 데 쓰이는 향격조사(向格助詞)이기도 합니다. > 섬진강은 남쪽으로 흘러 남해로 들어간다. (공간적 지향점) > > 고속도로로 가지 말고 국도로 돌아가자. (공간적 통과지점) > > 이제부터는 우리에게 협조하기로 약속했습니다. (추상적 지향점) > > 형은 입사하자 곧 과장으로 승진하였다. (변화)  ## 자격격조사 **으로** : 대체로 '의 자격으로'로 풀 수 있는 의미로 쓰입니다. > 나는 여기서 사병으로 3년을 근무하였다. > > 새 감독으로 윤 코치가 발탁되었다. **으로서** : 자격을 나타내는 '으로' 뒤에는 '서'를 덧붙여 쓰는 일이 많습니다. 수단을 나타내는 '으로'에 '써'가 결합한 격조사 '으로써'와는 구분해서 써야 합니다. > 학생으로서의 본분을 잊지 말아야 한다. **'으로' 관련 관용구** > 주로, 대체로, 진실로, 정말로, 참으로...  ## 속격조사 속격조사(屬格助詞) **'의'**는 명사와 명사 사이에서 두 명사를 소유주와 소유물의 관계로 묶어 주는 일, 다시 말하면 소속 관계를 나타내 주는 일을 주된 임무로 하는 조사입니다. 하지만 그 쓰임의 범위는 매우 다양합니다. > 누님의 결혼반지 > > 부모님의 꾸중 > > 독서의 계절 > > 이별의 슬픔 > > 하나의 목표 > > 아내와의 약속 > > 자식으로서의 도리  ## 공동격조사 공동격조사(共同格助詞)는 두 명사가 서로 짝이 되어 어떤 일에 관여할 때 그 두 명사를 한 덩어리로 묶어주는 일을 하는 조사입니다. **과/와** : 공동격조사의 대표 > 개관 10주년 특별전 - 고대와 현대의 조화 **하고** : 주로 구어적인 용법에 쓰입니다. > 남희와 명호는(/남희하고 명호는) 어렸을 때부터 이웃에서 오누이처럼 지냈다. 공동격조사는 두 문장을 하나로 묶어주는 역할을 하기도 합니다. 하지만 그 쓰임에 일부 제약이 있습니다. > 나는 사과를 좋아한다. 나는 포도를 좋아한다. // 나는 사과와 포도를 좋아한다. *나는 사과를 포도와 좋아한다.  ## 비교격조사 두 명사의 상태를 비교할 때 쓰이는 비교격조사(比較格助詞)에는 **보다, 처럼, 만큼, 같이**가 있습니다. > 남한의 인구가 북한의 인구보다 많다. > > 바위가 꼭 물개처럼 생겼구나. > > 너도 언니만큼 예쁘구나. > > 주위는 온통 칠흙같이 어두웠다.  ## 호격조사 호격조사(呼格助詞)는 누구를 부를 때 이름이나 호칭 다음에 쓰는 조사로 **아/야**가 있습니다. > 진숙아, 전화 왔어. > > 명호야, 너 뭐 잊은 거 없니? 호격조사는 경어법 면에서는 특히 큰 제약을 받습니다. 손윗사람을 부르는 호칭에는 호격조사를 생략하거나 기도문과 같은 상황에서는 **이여/여, 이시여/시여**를 써서 상대를 최대한으로 높입니다. > 아버님, 저희들 왔어요. > > 주여, 여름은 참으로 찬란하엿습니다.   # 특수조사 특수조사(特殊助詞)는 격을 나타내 주는 것이 아니라 어떤 의미를 나타내주는 조사들을 말합니다.  ## 만 '오직', '오로지', '유일'이라는 뜻을 나타내는 조사입니다. 수량표현과 어울리면 '최소'라는 의미가 붙습니다. > 이 꽃은 그늘에서만 잘 자란다. > > 조금만 참으세요.  ## 도 다른 것에 그것이 포함된다는 뜻을 나타냅니다. '아울러' 정도의 의미입니다. 이외에도 다양한 의미로 쓰입니다. > 이 꽃은 그들에서도 잘 자란다. (아울러) > > 원숭이도 나무에서 떨어지는구나. (특별한 사태) > > 저 사람 고집은 누구도 못 꺾어요. (남김없이 모두) > > 옷을 많이도 입었구나. (강조)  ## 은/는 한국어의 특수조사 중 그 의미를 추출해내기가 가장 까다로운 종류입니다. 주격조사 '이'와 용법을 가려내는 일은 한국어를 배우는 외국인은 물론 국어학자들도 어려워 하는 대목입니다. > 이 꽃은 그늘에서는 잘 자란다. (대조) > > 한글은 소리글자요, 한자는 뜻글자다. (대조) > > 한글은 소리글자다. (대조? 주어?)  ## '은/는'과 주격조사 '이/가' 비교 - 새로 꺼내는 이야기와 이미 알려진 정보  > 시장에 무엇이 새로 나왔을까? // *시장에 무엇은 새로 나왔을까? - 초점(focus)  > 영미가 노래를 더 잘 한다. (영미가 다른 아이보다)  >  > 영미는 노래를 더 잘 한다. (다른 것보다 노래를) - 정의 : '은'이 더 잘 어울립니다  > 지구는 둥글다.  >  > 해는 동쪽에서 떠서 서쪽으로 진다. - 복문의 주어  > 근심이(*근심은) 없는 사람은 하나도 없었다.  >  > 우리가(*우리는) 출발한 시간은 여섯 시 정각이었다. - 화제(topic) : '은'의 의미를 화제로 규정하기도 합니다. 화제란 한 단락의 중심생각을 가리키는 말입니다.  > 훈민정음은 세종이 친히 창제하였다.  >  > 그늘에서는 곡식이 잘 자라지 않는다.   ## 조차, 마저, 까지, 부터 이제부터 설명드릴 '조차', '마저', '까지', '부터'는 '도'와 비슷한 의미로 서로 넘나들며 쓰일 수 있습니다. > 너{도, 조차, 마저, 까지} 나를 못 믿는구나. **조차** : 그것이 기대하는 최소, 최하, 최후의 것임을 제시하면서 거기에서도 기대가 허물어지는 사태에 쓰입니다. 주로 부정문, 평서문에 사용됩니다. > 요즈음은 아이들조차 자기 주장이 강하다. > > *너조차 앉아 쉬어라. > > *너조차 {안 만나고/\*만나고} 갔다고? **마저** : '마지막 하나'라는 어감을 가진 조사입니다. 기대를 어긋나는 일에만 쓴다는 제약을 받지 않는다는 점이 '조차'와는 다릅니다. > 이러다가는 죽을지 모른다는 생각마저 들더라. > > 올 가을에는 막내마저 시집 보내려고요. **까지** : '조차'와 '마저'보다 제약이 덜 합니다. > 드디어 자가용까지 샀다. > > 내친 김에 우승까지 하려무나. **부터** : 여러 후보 중 그것이 처음임을 알리거나 시발점을 나타내주는 조사입니다. > 남 얘기 하지 말고 너부터 똑똑히 하려무나. > > 누구부터 줄까.  ## 이나/나, 이나마/나마, 이라도/라도 **이나/나** : 자기가 바라는 최상의 길은 아니나 이 정도면 자족할 수 있다는 걸 나타내는 조사입니다. 희망을 나타내는 문장에서는 '더 바랄 것이 없다'는 뜻을 함축합니다. 이외에도 다양한 의미로 쓰입니다. > 휴가도 못 가는데 잠이나 실컷 자자. (차선) > > 나도 달나라에나 한번 가 보았으면. (더 바랄 것이 없음) > > 나는 어디에서나 잘 잡니다. (모든 곳) > > 우리 학교가 상을 다섯 개나 탔대. (놀라움) **이나마/나마** : '이나'와 그 의미가 꽤 비슷하면서도 미묘하게 다릅니다. > 선풍기나마(/선풍기나) 하나 있었으면 좋겠어요. > > 우리도 벤츠나(??벤츠나마) 하나 삽시다. **이라도/라도** : '이나', '이나마'와 비슷한 의미이지만 좀 더 절박한 느낌을 줍니다. > 입석이라도 좋으니 태워만 주세요. > > 이런 때일수록 한 푼이라도 아껴야 한다.  ## 이야/야, 이라야/라야 **이야/야** : '강조', '당연히', '겨우' 등 꽤 여러가지 의미로 쓰입니다. 굳이 비교하자면 특수조사 '은'에 가깝습니다. > 나야 이미 알고 있었지. > > 물론 이름이야 알지요. > > 마감일 다 되어서야 겨우 마쳤어. **이라야** : 여러 후보 중 유일하게 어느것 하나가 선택됨을 강조해 나타내는 조사입니다. 비교하자면 '만'에 가깝습니다. 대수롭지 않게 여긴다는 뜻도 나타내 줍니다. > 당신이라야 회사를 살릴 수 있을 거예요. > > 그 사람 업적이라야 뭐 그렇고 그렇지요. // *그 사람 업적이라야 실로 대단하지요.  # 1년치 조간신문의 조사 사용 빈도 조선일보, 한겨레, 매일경제 등 국내 주요 10개 조간신문의 2016년 1년치 기사 25만7973건(총 7484만1451개 어절)을 모았습니다. 조사 사용 빈도를 분석하기 위해 [KoNLPy](http://konlpy.org/en/v0.4.4/) 같은 형태소 분석기를 사용하려고 했으나 분석 결과가 대체로 엄밀하지 않다는 판단 하에 말뭉치를 띄어쓰기 기준으로 단어로 나누고, 여기서 나온 모든 단어를 한글자씩 떼어서 단어의 역순으로 그 빈도를 세었습니다. 아래 표는 지금까지 설명한 조사별 사용 빈도입니다. 형태소를 하나하나 정확히 분석한 결과는 아니니 경향성만 확인하는 용도로 보시면 좋을 것 같습니다. |  조사명  |  빈도수  | | :-----: | :-----: | |  은/는  | 6689232 | |  을/를  | 5837313 | |  이/가  | 4841467 | |  의  | 2585899 | |  에  | 2312260 | | 로/으로  | 2189999 | |  과/와  | 1381267 | |  도  | 1288811 | |  에서  | 856810 | |  만  | 646574 | | 이나/나  | 408129 | |  까지  | 210205 | |  부터  | 185473 | |  에게  | 168642 | |  보다  | 103521 | |  께  | 85295 | |  처럼  | 65723 | | 이라도/라도 | 45397 | | 으로서/로서 | 17806 | |  조차  | 11709 | |  만큼  | 11633 | |  같이  | 11209 | |  마저  | 7724  | | 이나마/나마 | 6061  | | 한테/더러 | 4898  | | 에게서/한테서 | 4465  | |  께서  | 3977  | |  이야  | 2355  | |  이라야  |  98  | 위 표를 보시면 아시겠지만 빈도수 상위 5개 조사(은/는, 을/를, 이/가, 의, 에)가 총 2226만6171번 쓰여 전체의 74.26%를 차지합니다. '께', '께서'와 같이 높임을 나타내는 조사는 거의 사용되지 않은 점 또한 확인 가능합니다. 한국어 자연언어처리를 할 때 별도의 복잡한 전처리 과정 없이 어절 맨끝에 등장하는 '은/는', '을/를', '이/가', '의', '에' 다섯개 조사만 제거해도 **Text Normalization**을 효과적으로 수행할 수 있다는 생각이 듭니다. 의견이나 질문 있으시면 언제든지 댓글, 이메일로 알려주시기 바랍니다. 지금까지 읽어주셔서 감사합니다.
verb␞ 이번 글에서는 **동사(Verb)**와 **형용사(Adjective)**와 관련된 여러 개념들을 살펴보도록 하겠습니다. 이번 글은 경희대 이선웅 교수님 강의와 표준국어문법론을 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 동사의 정의 학교문법에 따르면 동사란 사물의 움직임을 과정적으로 표시하는 품사입니다. 동사 검증의 틀로 흔히 사용되는 것은 '무엇이 어찌한다, 무엇이 무엇을 어찌한다'의 틀에 나타나는 '어찌한다'의 자리를 채울 수 있느냐는 겁니다. 이는 바로 **기능(function)**에 초점을 맞춘 정의라고 할 수 있겠습니다. 동사의 예는 아래와 같습니다. > **구체적인 움직임** : 읽다, 잡다, 자다, 던지다, 뛰다... > > **마음 속으로 일어나는 움직임** : 사랑하다, 믿다, 생각하다... > > **움직임을 지닌 상태** : 자다, 살다, 쉬다, 앓다... > > **자연의 움직임** : 흐르다, 피다, 솟다... 이후 설명은 문법적으로 이해하기 까다로운 동사 개념들 소개한 내용입니다.  ## 자동사와 타동사 목적어가 있는 동사를 **타동사**, 없는 동사를 **자동사**라고 합니다. 이는 어휘 의미에 의해 결정되는 것이 아니고 실현된 문장성분의 종류에 따라 결정됩니다. 예를 들어보겠습니다. | 구분 |  (가)   |  (나)  | | :--: | :--------: | :-------: | | 1  | 철수가 학교에 간다 | 아기가 잔다  | | 2  | 철수가 학교를 간다 | 아기가 잠을 잔다 | (가)-1에서 '학교에'는 부사어, (가)-2의 '학교를'은 목적어로 쓰였는데요. 두 구문의 의미적 차이는 '학교'를 목적지로 생각하느냐, 행위의 대상으로 생각하느냐의 차이뿐입니다. (나)의 '잠'은 **동족목적어(cognate object)**인데요, (나)-1에서처럼 목적어 없이도 문장이 성립합니다. '가-', '자-'는 자동사로도, 타동사로도 쓰일 수 있는 **자타양용동사**라고 합니다. 그런데 1행(자동사 구문)과 2행(타동사 구문)은 의미상 결정적인 차이는 없고, 그저 목적어가 있느냐 없느냐 차이만 있습니다.  이 때문에 이선웅(2012)은 자동사와 타동사 구분은 같은 동사라도 어떤 구문에서 쓰였는지에 따라 판별해야 한다고 주장합니다. 다른 예를 들어보겠습니다. > (ㄱ) 발이 밟혔다. > > (ㄴ) 발을 밟혔다. (ㄱ)에서 '발이'는 '밟혔다'의 주어로 실현됐습니다. (ㄴ)에서 '발을'은 '밟혔다'의 목적어입니다. 따라서 (ㄱ)의 '밟혔다'는 자동사, (ㄴ)은 타동사로 분류됩니다.  ## 중립동사, 능격동사 **중립동사/능격동사**란 타동사로 쓰일 때의 목적어가 자동사의 주어로도 쓰일 수 있는 동사를 가리킵니다. 자타양용동사의 특수한 케이스입니다. 보통의 타동사는 주어와 목적어가 바뀌면 피동 표현으로 바뀐다는 점과 다릅니다. 예를 들어보겠습니다. > (철수가 바위를 밀었다) 바위가 **움직였**다. '움직이-'는 자타양용동사입니다. '바위를 움직였다(타동사)', '바위가 움직였다(자동사)' 모두 가능한 표현입니다. 그런데 타동사로 쓰일 때의 목적어(바위)가 자동사 주어로도 쓰일 수 있음을 확인할 수 있습니다. '움직이-' 외에 '(눈물을)그치-', '(차를)멈추-', '(몸을)다치-' 등의 예가 있습니다. 한국어에서는 대개 의성,의태어가 중립동사 부류에 속합니다. 아래 예문에서 ㄴ과 ㄷ은 어감의 차이는 있을지언정 명제의 내용적 차이는 없습니다. > ㄱ. 거울이 반짝거린다. > > ㄴ. 철수가 거울을 반짝거린다. > > ㄷ. 철수가 거울을 반짝거리게 한다.  ## 비능격동사 아래 두 표현은 형태상으로는 자동사로 쓰였습니다. 하지만 문법적 의미가 미묘하게 다릅니다. 전자는 능동, 후자는 피동입니다. 아기는 [+controller] 속성이 있는 주어로 자신의 행위를 통제할 수 있는 반면 배는 [-controller] 속성으로 스스로 자신의 행위를 제어할 수 없기 때문입니다. > 아기가 **잔다.** > > 배가 **가라앉다.** 바꿔 말하면 위 예시에서 '자-'의 주어는 **행위주역(agent, 어떤 행위의 유발자)** '아기'가 됩니다. 반면 '가라앉-'의 주어는 **대상역(theme, 어떤 행위의 영향을 입는 실체)** '배'가 됩니다. '자-'와 같은 부류처럼 주어가 행위주역인 자동사를 **비능격동사**라고 합니다.  ## 재귀동사 **재귀동사**란 **재귀성분**을 지배하는 동사를 뜻합니다. 재귀성분이란 동지시(co-reference) 명사구를 가진 문장성분을 말합니다. 예를 들어보겠습니다. > **다물-** : A가 {A, \*B}의 입을 ~ > > **감-** : A가 {A, \*B}의 눈을 ~ > > **꿇-** : A가 {A, \*B}의 무릎을 ~ > > **절-** : A가 {A, \*B}의 다리를 ~ > > **삐-** : A가 {A, \*B}의 발목/손목을 ~ > > **가누-** : A가 {A, \*B}의 몸을 ~  위 여섯개 동사는 모두 재귀동사로, 주어의 재귀성분이 필수적으로 요구됩니다. 예컨대 '나는 내 입을 다물었다'는 표현은 가능하지만 '나는 네 입을 다물었다'는 비문이 됩니다.  ## 보조용언, 의존용언 **보조용언**이란 본용언의 뜻을 도와주는 용언을 가리킵니다. 예를 들어보겠습니다. > 감상을 늘 그때마다 적어 둔다. > > 백두산에 오르고 싶다. 위 예시에서 동사 '두-', 형용사 '싶-'을 제거해도 문장이 성립합니다. 다만 의미가 약간 달라졌죠. 이 때 '두-', 싶-'을 보조용언, '적-', '오르-'를 본용언이라고 합니다. > 감상을 늘 그때마다 적는다. > > 백두산에 오른다. 학교문법에서 규정하고 있는 보조동사의 쓰임새 예를 들어보겠습니다. > **진행** : 이제 청소를 다 해 **간다**. 아침 햇빛이 점점 밝아 **온다**. 지금 편지를 쓰고 **있다**. 아버지께서 편지를 쓰고 **계시다**. > > **종결** : 밥을 먹고 **나서** 어디로 가겠느냐? 철수는 마침내 자격증을 얻어 **냈다**. 인수는 들판에 나가 **버렸다**. 기어이 이루어 내고야 **말겠다**. > > **봉사** : 조카에게 종이배를 만들어 **주었다**. 선생님께 원고를 정서해 **드렸다**. > > **시행** : 나도 한 번 입어 **보았다**. > > **보유** : 공책은 책상 위에 얹어 **두었다**. 공책은 책상 위에 얹어 **놓았다**. 그 책을 읽어 **가지고** 오시오. > > **사동** : 누구를 가**게 하느냐**? 그 일을 잘 되**게 만들었다**. > > **피동** : 눈부신 업적이 이루어**졌다**. 나도 가게 **된다**. > > **부정** : 철수는 가**지 아니한다(않는다)**. 철수는 가**지 말아라**. 너는 오**지 못한다**. > > **강세** : 너무 놀려 **대지** 마라. > > **짐작** : 그 꽃은 좋아 **보인다**. > > **당위** : 하루에 꼭 한 알씩 먹**어야 한다.** > > **시인** : 하루에 한 알씩 먹**기는 했다**. 이번에는 보조형용사의 쓰임새 예를 들어보겠습니다. > **희망** : 금강산에 가고 **싶다**. > > **부정** : 오늘은 날씨가 춥**지 아니하다(않다)**. 그 분은 별로 넉넉하**지 못합니다**. > > **추측** : 저 건물이 동다문**인가 보다**. 지금 생각하니 내가 잘못한 것이 아니었**던가 싶다**. > > **상태** : 하루 종일 이곳에 앉**아 있습니다**. 하루 종일 의자에 앉**아 계십니다**. > > **시인** : 그 집이 크**기는 하다**. **의존용언**이란 해당 용언이 문장 내 본용언이기는 하지만 선행 문장 형식에 의존적인 용언을 뜻합니다. 예를 들어보겠습니다. > 그가 귀엽게 **군다**. > > 그가 함부로 **군다**. 동사 '군-'은 위 예시 문장에서 본용언으로 쓰였다는 점에서 보조용언은 아닙니다. 하지만 '귀엽게' 혹은 '함부로'라는 보충어 없이는 문장이 성립하지 않습니다. 따라서 의존용언으로 분류할 수 있습니다.  ## 형용성동사 도원영(2008)은 형용사와 동사 사이 중간 범주로 **형용성동사** 개념을 제시했습니다. 그 기준은 아래와 같습니다. 형용성동사의 예로는 '힘들다', '붐비다' 등이 있습니다. > **의미적 기준** : '어떠하다'의 개념에 해당하여 '어떠하냐?'와 같은 물음의 대상이 된다. > > **형태적 기준** : 형용성동사는 동사 활용과 형용사 활용을 한다. 양용 활용이 아닌 경우에는 '-었다, -ㄴ'으로만 활용한다. > > 형용성동사는 정도부사의 수식을 받을 수 있다.  ## 형용사 학교문법에 따르면 형용사는 사물의 성질이나 상태를 표시하는 품사입니다. 동사가 주체의 움직임을 과정적, 동태적으로 표시하는 것이라면 형용사는 주체의 성질/상태를 상태적, 정지적으로 표시하는 것이라고 할 수 있습니다. 형용사 검증의 틀로 사용되는 것은 '무엇이 어떠하다'의 '어떠하다'의 자리를 채울 수 있느냐는 겁니다. 형용사의 예를 들어보겠습니다.  > **감각** : 검다, 달다, 시끄럽다, 거칠다, 차다, 빠르다, 멀다, 높다... > > **대상에 대한 평가** : 착하다, 모질다, 아름답다, 성실하다... > > **비교** : 같다, 다르다, 낫다... > > **존재** : 있다, 계시다, 없다... > > **화자의 심리 상태** : 고프다, 아프다, 싫다, 좋다...  ## 동사와 형용사 구분 학교문법에서는 동사와 형용사를 다른 품사로 나누고 있습니다만 둘을 구분하지 않는 학자들도 꽤 있습니다. 그만큼 두 품사의 영역이 분명하게 나뉘지 않기 때문입니다. 앞서 형용성동사라는 개념을 제시한 도원영(2008)도 이러한 맥락에서 이해할 수 있습니다. 예컨대 '믿다'라는 단어를 봅시다. 이는 심리 **상태**를 나타내는 말로 동작/작용(동사)이라기보다는 성질/상태(형용사)에 가까운 단어입니다. 그런데 표준국어대사전에서는 동사로 처리하고 있는 걸 아래와 같이 확인할 수 있습니다. <a href="http://imgur.com/6w7Dud7"><img src="http://i.imgur.com/6w7Dud7.png" width="500px" title="source: imgur.com" /></a> 사전 편찬자는 '믿다'를 왜 동사로 분류했을까요? 그건 바로 **과정**적인 속성에 방점을 찍어서 이해했기 때문인듯 합니다. 다시 말해 믿는다는 심리 상태가 바로 당장 주어진 것이 아니라 믿는다는 '행위'가 과거 어느 시점에 시작되어 현재까지 지속되어 온 과정으로 받아들여졌다는 얘기입니다. 하지만 '믿다'를 형용사로 분류하여도 논리적으로 큰 흠결이 없을 것 같기도 합니다. 이처럼 동사와 형용사를 의미로 구분하는 것은 매우 어려운 작업입니다. 이 때문에 동사와 형용사를 구분할 때는 의미보다는 형태적인 기준을 적용하는 경우가 많습니다. 예컨대 아래와 같습니다. > (1) 동작을 나타내는 어미 **-는다/-ㄴ다**와 결합할 수 있으면 동사, 그렇지 않으면 형용사이다. > > (2) 현재 시제 관형사형 어미 **-는**과 결합할 수 있으면 동사, 그렇지 않으면 형용사이다. > > (3) 명령형 어미, 청유형 어미와 결합할 수 있으면 동사, 그렇지 않으면 형용사이다. 그러나 (3)의 경우 주어에 [+controller] 속성이 없으면 동사라 하더라도 명령형, 청유형 어미와 결합할 수 없는 사례가 많습니다. > *바위야, 움직여라. > > *사과야, 움직이자. 최근엔 (3) 조건을 다음과 같이 대체해 분류하는 경향이 있습니다. > **-려고 하다, -고자 하다, -고 싶다** 등과 결합할 수 있으면 동사, 그렇지 않으면 형용사이다. 한편 (1)~(3)을 모두 만족해 동사로 분류되거나 모두 불만족해 형용사로 분류되는 경우는 많지 않다고 합니다. 이럴 때는 다수결로 정하는 것이 보통인데, 대개는 (1) 조건이 중요하게 작용한다고 합니다. 아래 예시에서 (가)가 (나)에 비해 행위의 과정적(progessive) 의미가 강하게 드러나기 때문입니다. > (가) 먹**는다** > > (나) 먹**는**  ## 용언의 범위 학교문법에서는 동사와 형용사를 한 범주로 묶어 **용언**이라고 정의합니다. 두 단어류가 모두 주체를 서술하는 기능을 띄고 있기 때문입니다. 그럼 용언 범주는 어디까지일까요? 예를 들어보겠습니다. > (가) **다른** 의견 > > (나) **지난** 여름 > > (다) **뼈빠지게** 일했다 (가)의 '다른'과 (다)의 '지난'은 관형사(체언을 꾸미는 불변어)로 처리해야 할까요? 아니면 형용사 '다르-', 동사 '지나-'의 활용형으로 보아야 할까요? 이 경우에 학교문법에서는 서술 기능에 방점을 둡니다. 다시 말해 '의견이 다르다', '여름이 지나다'와 같이 해당 단어가 주체를 풀이하는 기능이 있다면 용언 범주로 분류해야 한다는 것이죠. 하지만 '다른', '지난'이 화자들 사이에 매우 많이 쓰인다면 문법적 판단과는 별도로 관형사로 인정할 수도 있습니다. 실제 '다른'은 국립국어원 표준국어대사전에 관형사로 등재된 것을 확인할 수 있습니다. <a href="http://imgur.com/P7aP3QP"><img src="http://i.imgur.com/P7aP3QP.png" width="300px" title="source: imgur.com" /></a> (다)의 경우 '일하느라 뼈빠졌다'와 같은 형태로 쓸 수가 없기 때문에 서술 기능이 있다고 보기 어렵습니다. 따라서 '뼈빠지게'는 그 자체로 부사로 처리하는 것이 합리적일 겁니다.
glove␞ 이번 글에서는 미국 스탠포드대 NLP랩에서 개발한 **GloVe**를 실전에서 사용하는 방법에 대해 살펴보도록 하겠습니다. GloVe와 관련 자세한 내용은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/09/glove/)을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.  ## 함수 설치 본 포스팅은 스탠포드 NLP랩의 원코드(C)를 파이썬으로 옮겨놓은 [이곳](https://github.com/JonathanRaiman/glove)을 기본으로 참고하였습니다. 파이썬 환경이 구축돼 있는 분들의 경우 설치 방법은 간단합니다. 다음 한 줄이면 됩니다. ```python pip install glove ```  ## 공기행렬 구축 GloVe의 입력 데이터는 다음과 같은 **dict** 구조의 **공기행렬(Cooccurrence Matrix)**입니다. ```python cooccur = { 	0: { 		0: 1.0, 		2: 3.5 	}, 	1: { 		2: 0.5 	}, 	2: { 		0: 3.5, 		1: 0.5, 		2: 1.2 	} } ``` GloVe 코드엔 별도로 공기행렬을 만드는 과정이 있지는 않아서 ScikitLearn 패키지의 CountVectorizer 함수를 이용해 공기행렬을 구축하는 코드를 만들었습니다. 다음과 같은데요. GloVe 함수엔 공기정보가 들어있는 dic을 넣게 됩니다. ```python # co-occurrence matrix 만들기 from sklearn.feature_extraction.text import CountVectorizer vectorizer = CountVectorizer(min_df=10, ngram_range=(1,1)) X = vectorizer.fit_transform(corpus) Xc = X.T * X       # co-occurrence matrix Xc.setdiag(0)			 # 대각성분을 0으로 result = Xc.toarray()  # array로 변환 dic = {} for idx1, word1 in enumerate(result): 	tmpdic = {} 	for idx2, word2 in enumerate(word1): 		if word2 > 0: 			tmpdic[idx2] = word2 	dic[idx1] = tmpdic ``` 위 코드에서 raw data에 해당하는 corpus는 다음과 같이 원 텍스트들로 구성된 리스트입니다. 리스트의 각 요소는 개별 문서가 됩니다. 예컨대 다음과 같습니다. > corpus = ['이건 무조건 n차각', > ​		 '미친놈을 동경하는 이유', > ​		 … > > ​		 '울었다 웃었다 종 잡을 수 없지만 끝나고 나면 2편을 찾게 되는 영화'] dic은 단어 ID들로만 구성된 dict이므로 단어 리스트들도 별도로 빼서 가지고 있는게 좋을 겁니다. 그 코드는 다음과 같습니다. ```python # 단어 리스트 작성 import operator vocab = sorted(vectorizer.vocabulary_.items(), key=operator.itemgetter(1)) vocab = [word[0] for word in vocab] ```   ## 단어벡터 학습 입력값을 만들었으니 GloVe 함수에 넣어 학습을 시킬 차례입니다. 학습 코드는 다음과 같습니다. ```python # training import glove model = glove.Glove(dic, d=100, alpha=0.75, x_max=100.0) for epoch in range(25):   err = model.train(batch_size=200, workers=4)   print("epoch %d, error %.3f" % (epoch, err), flush=True) ``` 각 파라메터에 대한 설명은 다음과 같습니다. ### Glove.**init**() - `cooccurence` dict<int, dict<int, float>> : the co-occurence matrix - `alpha` float : (default 0.75) hyperparameter for controlling the exponent for normalized co-occurence counts. - `x_max` float : (default 100.0) hyperparameter for controlling smoothing for common items in co-occurence matrix. - `d` int : (default 50) how many embedding dimensions for learnt vectors - `seed` int : (default 1234) the random seed ### Glove.train - `step_size` float : the learning rate for the model - `workers` int : number of worker threads used for training - `batch_size` int : how many examples should each thread receive (controls the size of the job queue)   ## 단어벡터 추출 및 저장 GloVe를 학습시키는 근본 이유는 임베딩된 단어벡터를 얻는 데 있으므로 학습 종료 뒤 단어벡터를 추출하는 것도 중요할 겁니다. 벡터 추출과 피클 저장 관련 코드는 다음과 같습니다. ```python # 단어벡터 추출 wordvectors = model.W # 저장 import pickle with open('glove', 'wb') as f: 	pickle.dump([vocab,wordvectors],f) ```   ## 유사도 함수 파이썬 gensim 라이브러리에 포함된 Word2Vec 함수엔 'most_similar'라는 기능이 포함돼 있어 매우 편리합니다. 예컨대 '영화'라는 단어를 입력하면 가장 유사한 단어벡터를 뽑아주는 건데요. GloVe엔 이게 없어서 제가 간단히 아래와 같이 만들어봤습니다. ```python # 유사도 계산 함수 from scipy.spatial.distance import cosine def most_similar(word, vocab, vecs, topn=10): 	query = vecs[vocab.index(word)] 	result = [] 	for idx, vec in enumerate(vecs): 		if idx is not vocab.index(word): 			result.append((vocab[idx],1-cosine(query,vec))) 	result = sorted(result,key=lambda x: x[1],reverse=True) 	return result[:topn] ``` 사용법은 다음과 같습니다. word는 코사인 유사도 계산 기준이 되는 쿼리 단어, vocab은 GloVe 학습 결과로 나온 전체 단어, vecs는 임베딩된 전체 단어벡터, topn은 상위 몇 개를 출력할지 결정해주는 파라메터입니다. ```python most_similar(word='영화', vocab=vocab,        vecs=wordvectors, topn=5) ```   ## 파일럿 실험 한국어 영화 리뷰 50만여개를 학습시켜 봤습니다. '영화'와 가장 유사한 단어는 다음과 같습니다. > 영화였다, 영화다, 스토리, 최고의, 하나, 한국, 영화에, 느낌, 마지막, 만든 ,보는, 같은... '쓰레기'와 가장 유사한 단어는 다음과 같습니다. > 이딴, 하긴, 제발, 아깝다, 벗고, 거지, 진심, 성격, 수준, 만들지, 시나리오, 카리스마...
cause␞ 이번 글에서는 한국어의 사동 표현에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 사동문 이 글에서 다룰 사동은 [피동](https://ratsgo.github.io/korean%20linguistics/2017/12/03/voice/)과 더불어 태 범주에 속합니다. **태(態, voice)**란 [의미역](https://ratsgo.github.io/korean%20linguistics/2017/06/04/thetarole/)이 문법적 관계로 실현되는 방식을 가리키는 문법범주입니다. 동사에 붙는 문법적 표지(예컨대 어미)로 표시됩니다. **사동문**이란 애초의 문장에 새 사동주를 추가하고 그 <u>추가된 사동주로 하여금 애초의 문장에 서술된 내용을 일어나게 하는 방식</u>으로 참여자 역할의 관계를 새로 짜는데, 동사에 이것을 알리는 표지가 붙은 문장을 가리킵니다. 사동문을 만들기 위해선 다음 세 가지 절차를 거칩니다. 1. 새로운 주어(사동주 *causer*)를 도입한다. 2. 원래의 주어(피사동주 *causee*)를 강등한다. 3. 동사에 특별한 표지(사동표지)를 첨가한다. 예문과 같습니다. - 동생이 숨었다. → 형이 동생을 숨겼다. 사동문의 짝이 되는 주동문은 형용사문, 자동사문, 타동사문이 모두 가능합니다(이와 반대로 [피동](https://ratsgo.github.io/korean%20linguistics/2017/12/03/voice/)의 경우에는 타동문에서만 가능합니다). 예문과 같습니다. - **형용사문** : 마당이 넓다. → 인부들이 마당을 넓힌다. - **자동사문** : 아기가 잔다. → 진이가 아기를 재운다. - **타동사문** : 아이가 사과를 먹었다. → 진이가 아이에게 사과를 먹였다. '인부들이 마당을 넓힌다'의 경우 인부들이 마당을 넓히도록 누군가에게 시키는 것이 아니라 인무들 스스로 일한다는 의미가 있습니다. 사동 개념과 관련해 '시킴'의 의미가 있어야 사동이라는 오해가 발생할 수 있는데, <u>사동주가 새로 추가 되고 해당 사동주가 사태를 유발하도록 하는 의미로 문장이 재편</u>된다면 모두 사동 범주에 포함된다는 점에 주의해야 합니다. 한편 사동문에 대응하는 주동문이 존재하지 않는 경우도 있습니다. 논란이 있으나 사동문으로 다루는 것이 일반적입니다. 예문과 같습니다. - *짐이 옮았다. / 진이가 짐을 옮겼다.    ## 한국어 사동 표지의 종류 한국어 사동 표지를 종류별로 살펴보겠습니다. 사동 표지 길이에 초점을 맞춰 사동 접미사에 의한 사동을 단형(短型) 사동, 보조동사 구성 `-게 하-`에 의한 사동을 장형(長型) 사동이라고 합니다.  ### 사동 접미사 (단형 사동) 우선 사동 접미사 `-이/히/리/기/우/구/추-`가 있습니다. 다음 예문과 같습니다. - 먹**이**-, 입**히**-, 알**리**-, 맡**기**-, 비**우**-, 솟**구**-, 낮**추**- `-우-` 앞의 모음이 변화는 경우도 있습니다.  - 쓰다 → 씌우다 - 타다 → 태우다 - 서다 → 세우다 한국어의 모든 용언에 사동 접미사가 붙을 수 있는 건 아니고, 일부 동사, 형용사에만 결합할 수 있습니다. 다음 종류의 용언에는 결합이 제약됩니다. - '이기다' 따위의 어간이 'ㅣ' 모음으로 끝나는 용언 - '주다' 따위의 수여동사 - '얻다' 따위의 수혜동사 - '만나다' 따위의 대칭동사 - '하다'로 끝나는 용언 한편 사동사와 피동사의 형태가 동일한 경우도 있습니다. 이 때는 문장 전체 구조를 보고 해당 단어가 사동사인지 피동사인지 구별해야 합니다. 다음 예문과 같습니다. - 그 책이 많이 읽혔다. (피동문) - 형이 동생에게 그 책을 읽혔다. (사동문) - 저 멀리 남산이 보인다. (피동문) - 진이가 아이에게 그림책을 보인다. (사동문)   ### 보조동사 구성 '-게 하-' (장형 사동) 보조동사 구성 `-게 하-`로도 사동문을 만들 수 있습니다. 다음 예문과 같습니다. - 가**게 하**- - 먹**게 하**- 보조동사 구성 `-게 하-`는 분포가 넓습니다. 접미사 사동이 불가능한 동사(*깨닫기다-깨닫게 하다)는 물론 접미사 사동이 가능한 동사 어간(웃기다-웃게 하다)에도 결합합니다.  그러나 피사동주가 추상명사이거나 무정물인 경우에는 결합이 대체로 제약됩니다. 다음 예문과 같습니다. - 네 동생 먹을 것만 **{남기고/\*남게 하고}** 다 먹어도 좋다. 보조동사 구성 `-게 하-`로 만들어진 사동문의 가장 큰 통사적 특징 가운데 하나는 해당 사동문이 주술 관계가 두 번 있는 복문을 이룬다는 점입니다. 다음 예문을 보면 주동문은 단문이었지만, 사동문이 복문이 되었음을 확인할 수 있습니다. - 아이가 밥을 먹는다. → 진이는 [아이가 밥을 먹]게 했다.   ### X시키- 서술성 명사 $X$에 '시키다'가 붙어 사동표현을 만들 수 있습니다. 다음 예문과 같습니다. - 합격시키-, 통과시키-, 입학시키-, 발전시키- `X시키-`는 `-하다` 형에 대응되면서 서술성 명사 일부에만 결합합니다. 가령 선행요소가 어근이거나(예: *구(救)시키다), 동작/의도성이 약할 경우(예: *생각시키다) `-시키다` 형이 성립되지 않습니다. `X하다`와 `X시키다`의 의미가 동일한 경우도 있는데, 이 경우는 `X시키다`가 사동의 기능을 하는 것이 아닙니다. 다음 예문과 같습니다. - 나는 빨간 줄과 파란 줄을 {연결했다/연결시켰다}.     ## 주동문 주어의 강등 양상 주동문을 사동문으로 만들 때 주동문 주어는 문장 내 다른 요소로 강등됩니다. 유형별로 강등 양상이 다른데요. 차례대로 살펴보겠습니다.  ### 단형사동의 경우  주동문이 형용사문, 자동사문인 경우 주동문 주어는 사동문에서 목적어로 바뀝니다. - **형용사문** : **길이** 넓다. → 인부들이 **길을** 넓혔다. - **자동사문** : **아이가** 운다. → 진이가 **아이를** 울렸다.  주동문이 타동사문인 경우 주동문 주어는 사동문에서는 목적어나 여격어로 바뀝니다. - **아이가** 밥을 먹는다. → 진이가 **아이에게** 밥을 먹였다. / 진이가 **아이를** 밥을 먹였다.   ### 장형사동의 경우 주동문의 주어는 [내포절](https://ratsgo.github.io/korean%20linguistics/2017/09/15/advp/)의 주어로 남아 있을 수도 있고, 모절의 여격어나 목적어로 실현될 수도 있습니다. 다음 예문과 같습니다($e_i$는 $i$가 들어갈 자리인데 생략되었다는 의미입니다). - **아이가** 밥을 먹는다.  → 진이는 [**아이가** 밥을 먹]게 했다. (내포절 주어)  → 진이는 **아이$i$에게** [$e_i$ 밥을 먹]게 했다. (모절 여격어, 의사전달 행위에 초점)  → 진이는 **아이$i$를** [$e_i$ 밥을 먹]게 했다. (모절 목적어, 피사동주의 수동성에 초점) '진이는 아이에게 밥을 먹게 했다'의 경우, '아이에게'는 동사 '먹다'의 [논항](https://ratsgo.github.io/korean%20linguistics/2017/07/19/valency/)이 될 수 없습니다. '아이에게 밥을 먹다'라는 문장은 성립하지 않기 때문입니다. 따라서 '아이에게'는 모절인 '진이는 ~게 했다'에 걸린다고 보아야 하며 동사 '하다'와 관련지어 해석해야 합니다. 다시 말해 '아이에게'는 모절의 성분이라는 이야기입니다. 한편 내포절의 주어(아이가)가 생략된 걸 확인할 수 있습니다. '아이에게'가 이미 모절에서 실현됐기 때문입니다. 마찬가지로 '진이는 아이를 밥을 먹게 했다'의 경우, '아이를'은 동사 '먹다'의 논항이 될 수 없습니다. '아이를 밥을 먹다'라는 문장은 성립하지 않기 때문입니다. 따라서 '아이를'은 모절인 '진이는 ~게 했다'에 걸린다고 보아야 하며 동사 '하다'와 관련지어 해석해야 합니다. 한편 내포절의 주어(아이가)가 생략된 걸 확인할 수 있습니다. '아이를'이 이미 모절에서 실현됐기 때문입니다.  주동문 주어를 모절 여격어(아이에게)로 실현할 경우 사동문의 의미가 의사전달 행위에 초점이 맞춰지게 됩니다. 위 예문의 경우 진이가 아이에게 밥을 먹으라는 말을 건넸다는 뉘앙스가 느껴집니다. 반면 모절 목적어(아이를)로 실현할 경우 피사동주의 수동성에 초점이 갑니다. 위 예문의 경우 진이가 아이를 앞에 앉혀두고 밥을 먹도록 시키고 있다는 뉘앙스가 느껴집니다.   ## 단형사동 vs 장형사동 이번엔 단형사동과 장형사동의 차이에 대해 살펴보겠습니다.   ### 통사적 차이 우선 단형사동은 [단문](https://ratsgo.github.io/korean%20linguistics/2017/09/14/comsent/)이고, 장형사동은 [복문](https://ratsgo.github.io/korean%20linguistics/2017/09/14/comsent/)입니다. 다시 말해 장형사동의 `-게 하-`에서 '-게'는 [내포절](https://ratsgo.github.io/korean%20linguistics/2017/09/14/comsent/)을 이끄는 어미라고 볼 수 있습니다. 여기서 파생되는 통사적 차이점들이 꽤 있습니다. 우선 장형사동에서는 피사동주가 내포절의 주어이기 때문에 주격조사 '-가'와 통합될 수 있지만, 단문인 단형사동에서는 피사동주가 주어가 아니므로 '-가'와 통합될 수 없습니다. 부사어가 걸리는 위치도 미묘하게 달라집니다. 단형사동의 경우 부사어는 문장의 주어와 관련지어 해석되고, 장형사동의 경우 부사어는 모절 주어뿐 아니라 내포절 주어에도 관련될 수 있습니다. 다음 예문과 같습니다. - 진이가 아이에게 옷을 **빨리** 입혔다. (빨리 행동(시킴)하는 사람은 진이) - 진이가 아이$i$에게 [$e_i$ 옷을 **빨리** 입]게 했다. (ㄱ. 빨리 행동(시킴)하는 사람은 진이, ㄴ. 빨리 행동(옷 입기)하는 사람은 아이) - 진이가 아이에게 그 책을 **못** 읽혔다. (행동(시킴)을 못한 사람은 진이) - 진이가 아이$i$에게 [$e_i$ 그 책을 **못** 읽]게 했다. (ㄱ. 행동(시킴)을 못한 사람은 진이, ㄴ. 행동(책 읽기)를 못한 사람은 아이) - 진이가 아이에게 **숟가락으로** 밥을 먹인다. (숟가락을 들고 있는 사람은 진이) - 진이가 아이$i$에게 [$e_i$ **숟가락으로** 밥을 먹]게 한다. (ㄱ. 숟가락을 들고 있는 사람은 진이, ㄴ. 숟가락을 들고 있는 사람은 아이) [한국어의 주어](https://ratsgo.github.io/korean%20linguistics/2017/10/01/sentcomp/) 판별법 가운데 하나로 주어 자리에 오는 명사가 존대의 대상이면 서술어인 용언에 [주체경어법](https://ratsgo.github.io/korean%20linguistics/2017/10/30/honorification/)의 선어말어미 '-시-'가 결합합니다. '-시-'는 단형사동에서는 한군데에만 쓰일 수 있지만, 장형사동에서는 두 군데에서 쓰일 수 있습니다. - **선생님께서** 진이에게 책을 읽히**셨**다. (문장의 유일한 주어인 '선생님'을 높임) - **선생님께서** 진이$i$에게 [$e_i$ 책을 읽]게 하**셨**다. (사동주 '선생님'를 높임) - 아이들이 선생님$i$께 [$e_i$ 책을 읽으**시**]게 했다. (피사동주 '선생님'을 높임) - **박 선생님께서** 우리 선생님$i$께 [$e_i$ 책을 읽으**시**]게 하**셨**다. (사동주, 피사동주 모두 높임) [한국어의 주어](https://ratsgo.github.io/korean%20linguistics/2017/10/01/sentcomp/)는 재귀대명사 '자기'의 선행사가 됩니다. 단형사동은 단문, 장형사동은 복문 구조를 이루고 있기 때문에 '자기'의 결속 양상 또한 다릅니다. 다음 예문과 같습니다. - **진이가** 아이에게 **자기** 옷을 입힌다. (진이의 옷을 입힘) - **진이가** 아이$i$에게 [$e_i$ **자기** 옷을 입]게 한다. (ㄱ. 진이의 옷을 입힘, ㄴ. 아이의 옷을 입힘)   ### 의미적 차이 단형사동은 **직접사동**(주어가 행동 주체가 되어 직접 행동)의 의미가 강합니다. 반면 장형사동은 **간접사동**(주어는 지시만 하고 피사동주가 스스로 행동)의 의미가 강합니다. 다음 예문과 같습니다. - 진이가 갓난아이에게 옷을 입혔다. (주어 '진이'가 직접 아이의 옷을 입혀줌) - *진이가 갓난아이에게 옷을 입게 했다. (피사동주 '갓난아이'가 스스로 옷을 입음 → 의미상 비문) 동사에 따라서는 사동주가 직접 행위에 참여할 수 없는 경우도 있어서, 이때는 단형사동이라도 간접사동으로만 해석되는 경우가 있습니다. 예컨대 '읽히다', '웃기다', '울리다'와 같은 경우가 가리키는 사태에서 사동주는 지시만 할 뿐, 읽고 웃고 우는 행위는 피사동주가 스스로 할 수밖에 없기 때문입니다. 하지만 약간의 뉘앙스 차이는 여전히 존재합니다. 예컨대 다음과 같습니다. - **읽히다** : 수업시간에 교사가 학생에게 읽도록 시킨다든지 하는 보다 적극적인 사역. - **읽게 하다** : 읽으라고 책만 사 놓고, 읽는 것은 확인하지 않는다든지 하는 정도로 소극적인 사역. 즉 단형사동이 간접사동으로 해석되더라도, 대응되는 장형사동보다는 더 직접적이고 적극적인 사역을 나타낸다는 것입니다. 그러나 장형사동을 쓸 것인지, 단형사동을 쓸 것인지는 상황에 따라 다를 수 있습니다. 몇 가지 예를 보겠습니다. - (교통사고로 아이를 잃은 부모가 흐느끼며) 내가 아이를 죽였어 : 아이의 죽음에 대한 직접적 행위를 하지 않았음에도 괴로움과 책임감을 느껴서 이렇게 말할 수 있음 - (막 출발하려는 버스를 향해 손을 흔들면서) 저 좀 태워 주세요 : 사동주는 피사동주(화자)를 직접 버스에 오르게 하는 등 직접적인 행동을 할 필요는 없고 그저 버스를 세워 주기만 하면 되지만, 사동주(버스 기사)의 선택이 절대적이므로 단형사동을 씀. - (장애인에게 양보를 하자는 취지에서) 장애인을 먼저 타게 합시다 : 실제로는 장애인의 휠체어를 들어준다든지 해서 사동주가 적극적으로 개입할 수 있지만, 피사동주(장애인)의 자발적 의지를 존중하기 위해 장형사동을 씀. 
bucketsort␞ 이번 글에서는 **버킷 정렬(Bucket sort)** 알고리즘을 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아를 참고해 정리하였음을 먼저 밝힙니다. 파이썬 코드는 [이곳](https://stackoverflow.com/questions/36688805/what-is-this-bucket-sort-implementation-doing)을 참고로 하였습니다. 그럼 시작하겠습니다.   ## concepts 값을 비교하여 정렬하는 기법인 comparison sort의 계산복잡성은 최소 $O(n\log{n})$입니다. 버킷 정렬은 분석 대상 데이터의 분포 특성을 활용해 계산복잡성을 $O(n)$ 수준으로 개선시키려는 것을 목적으로 하고 있습니다. 버킷 정렬은 데이터가 특정 범위 내에 확률적으로 균등하게 분포한다고 가정할 수 있을 때 적용할 만한 기법입니다. 이해를 돕기 위해 다음 그림을 보겠습니다.  <a href="https://imgur.com/bf8nVZt"><img src="https://i.imgur.com/bf8nVZt.png" width="400px" title="source: imgur.com" /></a>  위와 같이 10개의 데이터 $A$가 주어졌을 때 같은 크기의 버킷 $B$를 만듭니다. 만약 $A$의 분포가 균등하다면 각 버킷에는 1~2개의 요소만 속해 있을 것입니다. 이렇게 1~2개 값들만 있는 버킷 하나를 정렬하는 데 필요한 계산복잡성은 $O(1)$이 될 것이고, 이 작업을 $n$개 버킷에 모두 수행한다고 하면 전체적인 계산복잡성은 $O(n)$이 될 것입니다. 이것이 바로 버킷 정렬이 노리는 바입니다. 버킷 정렬의 구체적인 프로세스는 다음과 같습니다. - 데이터 $n$개가 주어졌을 때 데이터의 범위를 $n$개로 나누고 이에 해당하는 $n$개의 버킷을 만든다. - 각각의 데이터를 해당하는 버킷에 집어 넣는다. (C 등에서는 [연결리스트](https://ratsgo.github.io/data%20structure&algorithm/2017/09/30/list/)를 사용하며 새로운 데이터는 연결리스트의 head에 *insert*한다) - 버킷별로 정렬한다. - 이를 전체적으로 합친다.   ## 파이썬 구현 파이썬으로 구현한 버킷 정렬 코드는 다음과 같습니다. 버킷을 중첩 리스트로 구현했고, 각 버킷별로 정렬할 때 [퀵 정렬](https://ratsgo.github.io/data%20structure&algorithm/2017/09/28/quicksort/)을 적용했습니다. ```python def bucket_sort(seq):   # make buckets   buckets = [[] for _ in range(len(seq))]   # assign values   for value in seq:     bucket_index = value * len(seq) // (max(seq) + 1)     buckets[bucket_index].append(value)   # sort & merge   sorted_list = []   for bucket in buckets:     sorted_list.extend(quick_sort(bucket))   return sorted_list def quick_sort(ARRAY):   ARRAY_LENGTH = len(ARRAY)   if( ARRAY_LENGTH <= 1):     return ARRAY   else:     PIVOT = ARRAY[0]     GREATER = [ element for element in ARRAY[1:] if element > PIVOT ]     LESSER = [ element for element in ARRAY[1:] if element <= PIVOT ]     return quick_sort(LESSER) + [PIVOT] + quick_sort(GREATER) ``` 
CNNbackprop␞ 이번 포스팅에서는 **Convolutional Neural Networks(CNN)**의 **역전파(backpropagation)**를 살펴보도록 하겠습니다. 많이 쓰는 아키텍처이지만 그 내부 작동에 대해서는 제대로 알지 못한다는 생각에 저 스스로도 정리해볼 생각으로 이번 글을 쓰게 됐습니다. 수학에 약한지라 최대한 수식은 배제하고 직관적으로 설명해볼까 합니다. 이번 글은 미국 스탠포드대학의 [CS231n 강의](http://cs231n.github.io/optimization-2/)와 [이곳](http://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/)을 많이 참고하였습니다. 그런데 이들 설명도 저한테 확 와닿지 않아서 상당 부분은 제 스타일대로 그림을 다시 그리거나 해석했음을 미리 밝혀둡니다. 그럼 시작하겠습니다.  ## CNN의 forward pass CNN은 필터가 입력데이터를 슬라이딩하면서 지역적 특징(feature)을 추출합니다. 이후 이 특징을 최대값(**Max Pooling**)이나 평균값(**Average Pooling**)으로 압축해 다음 레이어로 보냅니다. 이런 과정을 반복해 분류 등 원하는 결과를 만들어내는 것이 CNN의 일반적인 구조입니다. CNN의 forward pass에 대해서는 이미 많은 글에서 소개된 바 있으므로 이번 포스팅에서는 아래 그림을 인용하는 것으로 설명을 간단히 마치겠습니다.  <a href="http://imgur.com/OXwLhaf"><img src="http://i.imgur.com/OXwLhaf.gif" width="500px" title="source: imgur.com" /></a>  이번 포스팅에서는 아래와 같이 가장 간단한 구조의 CNN을 예시로 설명해보려고 합니다. (CNN은 마지막 레이어에 **Fully Connected Layer(FC)**가 붙는 경우가 많은데, FC에 대한 역전파에 대해서는 이미 잘 정리된 글이 많고 우리의 목적은 CNN의 역전파를 세밀히 살피는 것이므로 여기서는 생략하겠습니다)  <a href="http://imgur.com/OTRhYvV"><img src="http://i.imgur.com/OTRhYvV.png" width="500px" title="source: imgur.com" /></a>  보시다시피 입력값은 3x3 행렬입니다. $x_{ij}$는 각각 입력값의 $i$번째 행, $j$번째 열의 요소를 뜻합니다. 필터(커널) 크기는 2x2입니다. CNN은 필터가 입력벡터를 슬라이딩을 하면서 지역정보를 추출하게 되는데, 스트라이드는 한칸으로 설정했습니다. 바꿔 말해 $x_{11}$, $x_{12}$, $x_{21}$, $x_{22}$가 필터와 합성곱이 되어서 conv 레이어의 1행 1열이 됩니다. 다음번엔 $x_{12}$, $x_{13}$, $x_{22}$, $x_{23}$이 필터와 합성곱이 되어서 conv 레이어의 1행 2열이 됩니다.  필터의 색깔과 위 계산그래프의 화살표 색깔을 맞춰서 보시면 어떻게 연산이 되는지 직관적으로 확인 가능하실 겁니다. 이후 conv 레이어에 최대값이나 평균값을 취해서 정보를 압축(pooling)합니다. 위 그림 기준으로는 2x2 행렬이 2x1 벡터로 바뀐 점을 확인할 수 있습니다. 아래는 이해를 돕기 위해 만든 움짤입니다. 내용은 위 그림과 동일합니다.  <a href="http://imgur.com/uv6KASK"><img src="http://i.imgur.com/uv6KASK.gif" width="500px" title="source: imgur.com" /></a>  ## CNN의 backward pass ### Average Pooling 이번 포스팅의 핵심인 역전파 과정을 살펴보도록 하겠습니다. 바로 뒤 레이어로부터 전파된 그래디언트가 $d_1$, $d_2$라고 칩시다. 그러면 Average Pooling 레이어의 그래디언트 전파 과정은 아래와 같습니다. <a href="http://imgur.com/xaFjFuC"><img src="http://i.imgur.com/xaFjFuC.png" width="350px" title="source: imgur.com" /></a> 위 그림은 CS231n의 계산그래프 형태로 나타낸 것인데요. 현재 지점의 그래디언트는 **미분의 연쇄법칙(chain rule)**에 의해 흘러들어온 그래디언트에 로컬그래디언트를 곱한 것과 같습니다. 평균은 모든 값을 더한 뒤 개체수로 나누어 구하게 되는데요. 만약에 $m$개 요소로 구성돼 있다고 한다면 Average Pooling을 하는 지점의 로컬 그래디언트는 $1/m$이 됩니다. 이를 흘러들어온 그래디언트($d_1$)과 곱해주면 $d_{11}$을 구할 수가 있습니다. $d_{12}$, $d_{21}$, $d_{22}$도 같은 방식으로 구할 수 있습니다.  ### Max Pooling 최대값으로 풀링을 했다고 하면 역전파 과정은 아래와 같습니다. 즉, 최대값이 속해 있는 요소의 로컬 그래디언트는 1, 나머지는 0이기 때문에 여기에 흘러들어온 그래디언트를 곱해 구하게 됩니다. <a href="http://imgur.com/m9gOiuc"><img src="http://i.imgur.com/m9gOiuc.png" width="300px" title="source: imgur.com" /></a>  ### conv layer 자, 이제 이번 글의 핵심인 conv layer의 역전파를 할 차례입니다. 우선 $x_{11}$을 보겠습니다. <a href="http://imgur.com/9oCYz8e"><img src="http://i.imgur.com/9oCYz8e.png" width="600px" title="source: imgur.com" /></a> $x_{11}$은 forward compute pass 과정에서 2x2필터 가운데 빨간색($w_1$) 가중치하고만 합성곱이 수행이 됐습니다. 그렇다면 역전파 때도 마찬가지로 딱 한번의 역전파가 일어나게 되겠네요. 이를 Kapathy의 계산그래프 형태로 나타내면 우측 상단 그림과 같습니다.  즉 $x_{11}$의 그래디언트는 흘러들어온 그래디언트 $d_{11}$에 로컬그래디언트($w_1$)를 곱해서 구할 수 있습니다. (곱셈 연산의 로컬그래디언트는 '상대방 변화량'입니다) 마찬가지로 $w_1$의 그래디언트는 흘러들어온 그래디언트 $d_{11}$에 로컬그래디언트($x_{11}$)를 곱해 계산합니다. 역전파와 관련해 자세한 내용은 [이곳](https://ratsgo.github.io/deep%20learning/2017/05/14/backprop/)을 참고하면 좋을 것 같습니다. 이런 식으로 모든 경우의 수에 대해 계산하면 conv layer의 역전파 수행이 완료됩니다. 아직 헷갈리실 수 있으니 하나 더 예를 들어보겠습니다. $x_{22}$를 한번 보겠습니다. 아래 그림은 계산해야할 경우의 수가 $x_{11}$에 비해 늘었을 뿐 본질적으로 달라진 것은 없습니다.   <a href="http://imgur.com/lxTuzam"><img src="http://i.imgur.com/lxTuzam.png" width="600px" title="source: imgur.com" /></a>  그런데 다 이렇게 하나하나 따져가면서 구하려면 골치가 꽤나 아플 겁니다. conv layer의 역전파를 할 때 약간의 트릭을 쓰면 조금 더 간단히 그래디언트를 구할 수 있게 됩니다. 바로 아래 그림처럼요.  <a href="http://imgur.com/LLBkARW"><img src="http://i.imgur.com/LLBkARW.png" width="700px" title="source: imgur.com" /></a>  흘러들어온 그래디언트 행렬(2x2 크기)을 conv layer를 만들 때 썼던 필터가 슬라이딩하면서 값을 구한다는 겁니다! 대신 필터 요소의 순서를 정반대로 바꿔서요. 예컨대 빨-파-노-초 필터를 초-노-파-빨 필터로 바꿔서 그래디언트행렬에 합성곱을 수행해주면 입력벡터에 대한 그래디언트를 구할 수 있습니다. 가령 $x_{11}$의 그래디언트는 $w_1$(필터에서 빨간색 요소) x $d_{11}$이라고 설명드린 바 있는데요, 위 그림 오른쪽에 좌측 상단을 보시면 이것과 정확히 일치하는 것을 알 수가 있습니다. 마찬가지로 $x_{22}$의 그래디언트도 흘러들어온 그래디언트 행렬에 초-노-파-빨 필터 사이의 합성곱 결과와 동일합니다. 그럼 필터의 그래디언트는 어떻게 구하게 될까요? 흘러들어온 그래디언트 행렬의 첫번째 요소인 $d_{11}$은 $x_{11}$, $x_{12}$, $x_{21}$, $x_{22}$와 연결되어 있는 걸 확인할 수 있습니다. 계산그래프를 그려서 설명드렸던 것처럼 필터의 그래디언트는 흘러들어온 그래디언트($d_{11}$, $d_{12}$, $d_{21}$, $d_{22}$)에 로컬 그래디언트를 곱해서 구하게 되는데요. 각각의 로컬 그래디언트는 합성곱 필터 가중치로 연결된 입력값들이기 때문에 $dw_{11}$은 $x_{11}d_{11}+x_{12}d_{12}+x_{21}d_{21}+x_{22}d_{22}$입니다. 
prime␞ 이번 글에서는 소인수분해 알고리즘에 살펴보도록 하겠습니다. 파이썬 코드는 [이곳](https://gist.github.com/dzhou/2632362)과 [이곳](https://stackoverflow.com/questions/3939660/sieve-of-eratosthenes-finding-primes-python)을 참고하였습니다. 그럼 시작하겠습니다.   ## 소수 찾기 소수란 1과 자기 자신만을 약수로 갖는 수를 가리킵니다. 어떤 숫자 *num*이 소수인지 아닌지 판별하는 가장 간단한 방법은 *num*까지의 모든 숫자를 나누어보는 것입니다. 다음과 같습니다. ```python def check_prime(num):   # prime numbers are greater than 1   if num > 1:     # check for factors     for i in range(2, num):       if (num % i) == 0:         print(num, "is not a prime number")         print(i, "times", num // i, "is", num)         break     else:       print(num, "is a prime number")   # if input number is less than   # or equal to 1, it is not prime   else:     print(num, "is not a prime number") ```   ## 특정 범위 내 소수들 찾기 소수를 발견하면 그 소수의 배수인 모든 수들을 소수 리스트에서 지웁니다. 범위 내 숫자들 중 소수가 아닌 것들을 거르는 과정을 반복하다보면 결국 소수만 남게 됩니다. 이를 에라토스테네스의 체(Sieve of Eratosthenes)라고 합니다. 다음과 같습니다. ```python import math def primeSieve(sieveSize):   # creating Sieve (0~n까지의 slot)   sieve = [True] * (sieveSize+1)   # 0과 1은 소수가 아니므로 제외   sieve[0] = False   sieve[1] = False   # 2부터 (루트 n) + 1까지의 숫자를 탐색   for i in range(2,int(math.sqrt(sieveSize))+1):     # i가 소수가 아니면 pass     if sieve[i] == False:       continue     # i가 소수라면 i*i~n까지 숫자 가운데 i의 배수를     # 소수에서 제외     for pointer in range(i**2, sieveSize+1, i):       sieve[pointer] = False   primes = []   # sieve 리스트에서 True인 것이 소수이므로   # True인 값의 인덱스를 결과로 저장   for i in range(sieveSize+1):     if sieve[i] == True:       primes.append(i)   return primes ``` 위 알고리즘에서 소수 탐색 범위가 $\sqrt{n}$까지인 이유는 약수가 존재하는 숫자의 반이 이 범위에 존재하기 때문에 이 범위를 탐색하는 것만으로도 전체 범위에서 약수의 존재 여부를 확신할 수 있습니다.    ## 소인수분해 에라토스테네스의 체 알고리즘을 활용해 소인수분해를 하는 알고리즘은 다음과 같습니다. ```python # 소인수분해 def get_prime_factors(n):   # n 범위 내의 소수를 구한다   primelist = primeSieve(n)   # 이 소수들 중 n으로 나누어 떨어지는   # 소수를 구하고, 몇 번 나눌 수 있는지 계산   # 예 : n = 8, factors = [(2, 3)]   # 예 : n = 100, fcount = [(2: 2), (5: 2)]   factors = []   for p in primelist:     count = 0     while n % p == 0:       n /= p       count += 1     if count > 0:       factors.append((p, count))   return factors ``` 
order␞ 이번 글에서는 **순서통계량(order statistic)**을 구현하는 알고리즘을 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아를 참고해 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concepts 순서통계량이란 $n$개 표본의 측정값들을 그 크기 순으로 작은 쪽부터 배열한 것을 가리킵니다. 최소값, 최대값, 중앙값(median), 4분위수(quantile) 등이 대표적인 순서통계량입니다. $i$번째 순서통계량은 $n$개 요소 가운데 $i$번째로 작은 값을 가리킵니다. 따라서 최소값은 $i$가 1, 최대값은 $i$가 $n$이 됩니다. $n$이 홀수인 경우에 중앙값의 $i$는 $(n+1)/2$, 짝수인 경우 $n/2$입니다. 순서통계량을 가장 확실하게 구하는 방법은 모든 요소를 정렬하는 것입니다. 카운팅 정렬(counting sort) 같은 일부 특이한 알고리즘을 제외하면, 대부분의 정렬 알고리즘은 두 값을 반복적으로 비교해 정렬 작업을 수행하는 comparison sort입니다. comparison sort 계산복잡성의 하한은 $O(n\log{n})$입니다. (자세한 내용은 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/10/16/countingsort/) 참고) 다시 말해 힙 정렬이나 합병 정렬 같은 $O(n\log{n})$의 알고리즘으로 전체 요소를 정렬해 놓으면 순서통계량 또한 구할 수 있다는 이야기입니다. 하지만 최소값, 최대값, 중앙값만을 알고자 할 때 요소 전체를 정렬할 필요까지는 없습니다. 바꿔 말해 순서통계량을 구하는 알고리즘이 목표로 하는 계산복잡성은 $O(n)$이라는 것입니다.   ## 최대값(최소값) 최대값을 구하는 가장 간단한 알고리즘은 이렇습니다. 우선 *max*라는 변수를 만들고, 이 변수에 첫번째 표본의 값을 집어 넣습니다. 그리고 나머지 $n-1$개 표본과 *max* 변수값을 반복적으로 비교해 큰 값을 다시 *max*에 저장합니다. 따라서 $n-1$회 비교하게 되면 $n$개 표본 가운데 최대값을 뽑아낼 수 있습니다. 따라서 이 알고리즘의 계산복잡성은 $O(n)$이 됩니다. 최소값은 여기에서 작은 값을 취하는 것 말고는 동일한 과정을 거칩니다.  파이썬으로 구현한 코드는 다음과 같습니다. ```python def maximum(list):   max = list[0]   for i in list:     if max < i:       max = i   return max ```   ## 최대값과 최소값 동시에 구하기 최대값을 구하는 데 $n-1$회, 최소값을 구하는 데에도 $n-1$회 비교 연산을 수행해야 합니다. 따라서 최대값과 최소값을 동시에 구하려면 $2n-2$회 비교를 해야 합니다. 이보다 더 낮출 수는 없을까요? 방법이 있습니다. 예컨대 다음과 같은 리스트를 정렬한다고 칩시다. > [1, 4, 10, 6, 3, 2] 우선 출력변수 *result*를 초기화합니다. *result* 첫번째 요소엔 최소값, 두번째 요소엔 최대값을 저장할 예정입니다. > result=(False, False) 정렬 대상 숫자를 순서대로 두 개씩 묶어 소그룹으로 만든 다음 두 개 숫자를 비교합니다. 큰 값을 왼쪽에, 작은 값을 오른쪽에 둡니다. > compare [1, 4] ==> [1, 4] > > compare [10, 6] ==> [6, 10] > > compare [3, 2] ==> [2, 3] 첫번째 소그룹의 왼쪽 값을 *result* 첫번째 요소, 오른쪽 값을 두번째 요소에 저장합니다. > result=(1, 4) 두번째 소그룹의 왼쪽 값(6), *result*의 기존 왼쪽 값(1)을 비교합니다. 작은 값을 *result*의 왼쪽에 저장합니다. 두번째 소그룹의 오른쪽 값(10), *result*의 기존 오른쪽 값(4)을 비교합니다. 큰 값을 *result*의 오른쪽에 저장합니다.  > $\min(1,6)$, $max(4,10)$ > > result=(1,10) 마지막으로 세번째 소그룹의 왼쪽 값(2), *result*의 기존 왼쪽 값(1)을 비교합니다. 작은 값을 *result*의 왼쪽에 저장합니다. 세번째 소그룹의 오른쪽 값(3), *result*의 기존 오른쪽 값(4)을 비교합니다. 큰 값을 *result*의 오른쪽에 저장합니다.  > $\min(1,2)$, $max(10,3)$ > > result=(1,10) 위 방법의 계산복잡성은 다음과 같은 세 가지 단계로 나누어 생각해볼 수 있습니다. 1. 두 개 숫자씩 소그룹으로 나누고 두 숫자 비교 2. 최소값 찾기 : 소그룹의 왼쪽값과 *result*의 왼쪽값 비교 3. 최대값 찾기 : 소그룹의 오른쪽값과 *result*의 오른쪽값 비교 데이터가 $n$개 있을 때 1번 과정에서 비교 연산의 횟수는 $n/2$회입니다. 2번 과정과 3번 과정도 각각 $n/2$회가 됩니다. 따라서 전체적으로는 $1.5n$회 비교 연산을 수행하면 됩니다. 기존 $2n-2$회에서 그 연산의 횟수를 줄인 셈입니다. (물론 Big-O notation 상으로는 둘 모두 $O(n)$으로 같습니다)   ## i번째 작은 값 구하기 $n$개의 숫자 가운데 $i$번째 작은 값은 퀵 정렬(quick sort)을 활용해 효과적으로 구할 수 있습니다. 퀵 정렬은 분기의 기준이 되는 피봇(pivot)값 $k$를 기준으로 작은 값들은 왼쪽, 큰 값들은 오른쪽 리스트로 분기합니다. 이후 분기된 두 리스트 각각에 퀵 정렬을 재귀적으로 수행해 정렬을 완료하는 구조입니다.  그러면 분석 대상 리스트가 $n$개 숫자로 구성돼 있고 피봇보다 큰 값들이 $a$개, 작은 값들이 $b$개라고 칩시다. 우리는 정렬이 아니라 $i$번째 작은 값을 찾는 데에만 관심이 있으므로, $a$가 $i$보다 크다면 $b$개에 대해선 계산할 필요가 전혀 없습니다. 다시 말해 피봇값 $k$보다 작은 값들의 개수($a$)가 $i$개 이상이라면 우리가 찾는 $i$번째 작은 값은 이들 중 하나일 것입니다. 따라서 $k$보다 큰 $b$개의 숫자에 대해선 계산하지 않아도 됩니다. 이를 파이썬으로 구현한 코드는 다음과 같습니다. ```python # i번째(query) 작은 숫자 찾기 def select(ARRAY, query):   # query가 ARRAY의 수보다 크면 에러 출력   if query > len(ARRAY):     print('query error')   else:     ARRAY_LENGTH = len(ARRAY)     if ARRAY_LENGTH <= 1:       return ARRAY[0]     else:       # 피봇을 기준으로 기존 리스트 분리       LESSOR, PIVOT, GREATER = partition(ARRAY)       # query가 LESSOR 다음 index와 일치하면       # i번째 작은 숫자는 바로 피봇값       if query == len(LESSOR):         return PIVOT       # query가 LESSOR 개수보다 작으면       # GREATER는 버리고 LESSOR 안에서만 탐색       elif query < len(LESSOR):         return select(LESSOR, query)       # query가 LESSOR 개수보다 크면       # LESSOR는 버리고 GREATER 안에서만 탐색       else:         return select(GREATER, query) # quick_sort algorithm 일부 변경 def partition(ARRAY):   ARRAY_LENGTH = len(ARRAY)   if ARRAY_LENGTH <= 1:     return ARRAY   else:     # 피봇은 입력데이터의 마지막 요소     PIVOT = ARRAY[-1]     GREATER = [ element for element in ARRAY[:-1] if element > PIVOT ]     LESSER = [ element for element in ARRAY[:-1] if element <= PIVOT ]     return LESSER, PIVOT, GREATER ``` 정렬 대상 리스트가 $n$개 숫자이고 피봇보다 큰 값들이 $a$개, 작은 값들이 $b$개라면 퀵 정렬의 계산복잡성은 다음과 같이 쓸 수 있습니다.  $$ T\left( n \right) =T\left( a \right) +T\left( b \right) +O\left( n \right) $$  위 식 우변 마지막 항이 $O(n)$이 되는 이유는 피봇값 $k$와 리스트의 나머지 $n-1$개 요소 간 비교 연산을 수행해야 하기 때문입니다. 그런데 우리는 정렬이 목표가 아니므로 $k$보다 큰 $b$개의 숫자에 대해선 계산하지 않아도 됩니다. 따라서 $i$번째 작은 값을 구하는 알고리즘의 계산복잡성은 다음과 같이 쓸 수 있습니다.  $$ T\left( n \right) =T\left( a \right) +O\left( n \right) $$  이 알고리즘의 계산복잡성은 피봇을 어떻게 선택하느냐에 따라 달라집니다. 피봇값을 잘못 선택해 매 분기 때마다 아래 그림처럼 이뤄질 경우 각 층에서 피봇값과 리스트의 나머지 요소($k$번 분기시 $n-k$번) 간 비교연산을 수행하고, 이를 높이($n$)만큼 반복 수행해야 하므로 $O(n^2)$의 계산복잡성을 가지게 됩니다.  <a href="https://imgur.com/v3xPU5E"><img src="https://i.imgur.com/v3xPU5E.png" width="200px" title="source: imgur.com" /></a>  반대로 피봇을 잘 선택해 매번 분기 때마다 절반씩 나눌 수 있게 되면 $i$번째 작은 값을 구하는 알고리즘의 계산복잡성은 $O(n)$이 됩니다. 아래 점화식 형태의 계산복잡성 식이 $O(n)$이 되는 이유에 대해서는 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/09/11/recurrence/)을 참고하시면 좋을 것 같습니다.  $$ T\left( n \right) =T\left( n/2 \right) +O\left( n \right) \\ \Rightarrow O\left( n \right) $$   ## pivot을 적절히 선택하기 따라서 $i$번째 작은 값을 찾는 문제를 선형 시간 내에 풀려면 피봇을 적절히 선택해 주어야 합니다. 이와 관련해 아래 그림 같은 아이디어도 있습니다. 방법은 이렇습니다. 전체 데이터를 몇 개 그룹으로 나눕니다. 해당 그룹에서 중앙값을 찾습니다. 여기서 다시 중앙값을 택합니다. 이를 피봇 삼아 분기를 수행하는 것입니다.  <a href="https://imgur.com/G84BXDa"><img src="https://i.imgur.com/G84BXDa.png" width="400px" title="source: imgur.com" /></a> 
senttopic␞ 이번 글에서는 한국어의 주어와 주제에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 문장의 구조를 보는 두 가지 관점 문장의 구조는 단 한 가지의 관점으로만 설명할 수 있는 것은 아닙니다. 다양한 관점에서 여러 가지 형식의 문장 구조를 상정할 수 있는데, 그중 한국어 문장의 구조를 설명하는 데 가장 유용한 관점은 크게 서술어를 중심으로 파악한 **통사구조(syntactic structure)**와 정보 전달의 방식을 중심으로 파악한 **정보구조(information structure)**로 나누어 볼 수 있습니다.    ## 통사구조 전자의 관점은 서술어와 **주어** 사이의 문법적 관계에 주목합니다. 통사구조의 정확한 정의는 다음과 같습니다. > 서술어가 요구하는 성분의 수와 종류의 정보에 따라 구축된 문형과 여러 통사적 원리에 따라 부가된 성분이 형성한 구조 '진이는 밥을 먹어'라는 문장을 이 관점에 입각해 살펴보면 다음과 같이 분석할 수 있습니다.  > [진이는 [밥을] 먹어]]] > > 주어 + 목적어 + 서술어 여기에서 자세히 살펴보면 '목적어-서술어'가 '주어-서술어'보다 더 긴밀한 관계를 맺고 있다는 걸 알 수 있습니다. 서술어가 가리키는 행위(食)가 지속될 수록 대상(rice)은 변화하게 마련이고, 주체가 그 행위를 마치는 순간 대상은 사라집니다. 하지만 주체(진이)는 행위가 종료되더라도 존재합니다. 즉 이 문장에서 서술어는 주어보다는 목적어와 의미적으로 더 큰 관련을 갖고 있다는 것이지요.  이 때문에 [먹어]라는 동사는 [밥을]이라는 명사구(Noun Phrase)와 우선 결합하고, 이후 [밥을 먹어]라는 동사구(Verb Phrase)에 [진이는]이라는 명사구가 결합했다고 보는 것이 자연스럽습니다.   ## 정보구조 후자의 관점은 문장 내 요소들이 얼마나 '정보성'을 가지고 있는지에 주목합니다. 정보구조의 정의는 다음과 같습니다. > 문장에서 정보 전달의 대상(구정보)과 그 주제에 대해 언급하는 내용(신정보)이 실현되는 방식의 구조 정보구조 관점에서 문장 구조를 분석해보겠습니다. > A: 진이는 뭐해? > > B: [진이는] \[밥을 먹어] B에서 [진이는]은 질문한 사람도, 대답하는 사람도 모두 알고 있는 '구정보'입니다. 반면 [밥을 먹어]는 질문자는 모르는 '신정보'입니다.    ### 구정보, 신정보 그렇다면 '정보가 새롭다'는 건 구체적으로 어떤 의미일까요? 크게 두 가지 기준이 있습니다. 첫째는 '언어표현에 대응되는 지시대상(referent)이 청자의 마음 속에서 얼마나 친숙한가'를 놓고 따집니다. 해당 요소가 청자의 마음 속에서 활성화되어 있다면 (지시적)구정보, 화자의 발화를 듣고서야 비로소 활성화되기 시작했다면 (지시적)신정보입니다. 둘째 기준은 문장 내 구조를 놓고 따지는 겁니다. 문장은 대개 $X$와 $Y$ 두 부분으로 나뉘는데, 이 문장은 $X$에 대한 것이고 $Y$는 $X$에 관한 정보를 제공하는 부분입니다. 이 때 $X$는 $Y$와의 관계 속에서 구정보이고, $Y$는 $X$에 대하여 단언되거나 질문되는 새로운 정보입니다. $X$를 주제(topic) 또는 (관계적)구정보, $Y$를 평언(comment) 또는 (관계적)신정보라고 합니다. 이 글에서는 용어를 다음과 같이 쓰겠습니다. 지시적인 구정보/신정보를 언급할 때는 아래 용어들과는 별도로 구분할 예정입니다. > 구정보=관계적 구정보=주제(topic) > > 신정보=관계적 신정보=평언(comment) 한국어에서 극단적으로는 다음 예문처럼 문장 전체가 신정보로만 되어 있는 경우도 있습니다. 정보구조 관점에선 B 문장 전체를 한 단위로 분석합니다. B처럼 구정보와 신정보로 나눌 수 없는 문장을 '제언문'이라 하며, 한국어에서는 제언문의 주어가 '이/가'로 실현됩니다. > A: 무슨 일이야? > > B: [진이가 넘어졌어] 다른 예문을 보겠습니다. > [비가 온다] 위 문장은 ‘비’에 대해 어떤 정보를 언급한다고 하기보다는 비가 온다는 정보 전체를 통째로 언급하는 문장입니다. 위 예문에 주제는 명시돼있지 않지만, 굳이 말하자면 ‘기상 현상’입니다. 위 예문은 기상 현상에 대해 말하는 문장이라는 이야기입니다. 이를 ‘주제+평언’ 구조로 바꾸려면 아래 예문과 같이 한국어에서 주제를 나타내는 데 전형적으로 쓰이는 표지(marker)인 보조사 '-은/는'을 반드시 써야 합니다. 아래 예문에서 ‘비는’이 주제, ‘온다’가 평언이 됩니다. > [비는] \[온다] 한국어에서는 화자가 어떤 대상에 대해 어떤 사실을 언급하려고 한다면, 그 대상은 모두 주제라고 말할 수 있습니다. 예문을 보겠습니다. > (가) [영희는] \[착해요] > > (나) [순희도] \[착해요] (가)의 ‘영희는’은 화자가 언급하려고 하는 대상이므로 주제입니다. 그런데 (나)에서는 ‘-은/는’이 결합되지 않은 ‘순희도’가 주제라고 할 수 있습니다. 다만 ‘순희도’에서는 보조사 ‘-도’가 지닌 also/too의 의미가 덧붙었을 뿐입니다. 다시 말해 주제는 정보구조적 ‘의미’로 파악하는 것이지 표지 '-은/는'으로 파악하는 것이 아니라는 이야기입니다.   ### 주제의 종류 인가주제(ratified topic)이란 이미 이전 담화에서 주제로 확립되어 있는 요소를 가리킵니다. 관계적으로나 지시적으로나 구정보에 해당합니다. 한국어에서 인가주제는 '은/는'으로 표시되거나 아예 생략되는 일이 많습니다. 아래 예문에서 '아이들은'이 인가주제입니다. > A: 아이들은 뭐해? > > B: (아이들은) 밥 먹어. 비인가주제(unratified topic)란 담화에서 현재 발화에 의해 새로 도입되어 이제야 막 주제로서 확립된 요소를 나타냅니다. 관계적으로는 구정보이나, 지시적으로는 신정보에 해당합니다. (1)처럼 '명사+말이야/말이에요/말입니다/말씀입니다/말인데요/말씀인데요 등'으로 실현되거나 (2)처럼 '있잖아(요)/있지/있죠/요'로 실현됩니다. 아래 예문에서 '박 사장'이 비인가주제입니다. > (1) **박 사장** 말이야, 정말 열 받게 만든다. 나를 일하는 기계로 생각하나 봐. > > (2) **박 사장** 있잖아요, 어제 고혈압으로 쓰러졌대요. 대조주제(contrastive topic)는 주제이되 둘 이상이 서로 대조를 이루는 것을 말합니다. 한국어에서 대조주제는 '은/는'으로 실현됩니다. 다음 예문과 같습니다. > A: 영이랑 순이 출산했니? > > B: 응, **영이는** 아들을 낳았고, **순이는** 딸을 낳았어.   ### 초점 초점(focus)은 문장이 나타내는 정보의 핵심을 나타냅니다. 주제와 짝을 이루는 평언 전체가 초점일 수도 있고, 평언 내부의 특정 성분만이 초점일 수도 있습니다. 예문을 보겠습니다. > A: 브라질은 어떤 나라야? > > B: 브라질은 [**축구를 잘해**]. B에서 주제는 '브라질은'이고 평언은 '축구를 잘해'입니다. 하지만 초점은 '축구를 잘해'라는 평언 전체입니다. 다른 예문을 보겠습니다. > C: 축구 어디가 잘하지? > > D: 축구는 [**브라질이** 잘해]. D에서 주제는 '축구는'이고 평언은 '브라질이 잘해'입니다. 하지만 초점은 '브라질이'라는 평언의 일부 성분입니다.    ### 초점의 종류 정보초점(informational focus)이란 주제에 대해 제공되는 정보를 가리킵니다. 한국어에서 정보초점은 '이/가'로 실현됩니다. > A: 이거 **누가** 만들었니? > > B: **진이가** 만들었어. 대조초점(contrastive focus)이란 초점 요소와 대안 집합의 다른 원소들 사이에 대조가 부각되는 경우 해당 초점을 가리킵니다. 여기에서 대안집합이란 어떤 요소가 나타난 위치에 올 수 있는 여러 후보들의 집합입니다. 한국어에서 대조초점은 '은/는'이나 '이/가'로 실현됩니다. > A: 철수 데리러 엄마가 왔어 아빠가 왔어? B: **엄마가** 왔어. > > A: 이번에 시험 친 친구들 중 누가 합격했니? B: **철수는** 합격했어.   ### 주어의 정보적 역할에 따른 표시방식 통사 구조상 주어로 분석될 수 있는 문장성분도 정보구조 관점에서 보면 정보적 역할이 문장마다 달라질 겁니다. 주어의 정보적 역할에 따른 표시방식을 표로 정리하면 다음과 같습니다. | 은/는 |  이/가  | | :---: | :-----: | | 인가 주제 | 정보 초점 | | 대조 주제 | 대조 초점 | | 대조 초점 | 제언문의 주어 | 한편 정보구조상의 주제가 통사 구조상의 주어와 일치하면 일반적으로 주제 표지 ‘-은/는’만을 사용하고 주어 표지 ‘-이/가’는 쓰지 않는다고 합니다.     ## 주어중심언어 주어는 '무엇이 어찌하다', '무엇이 어떠하다', '무엇이 무엇이다'와 같은 문장에서 '무엇이'에 해당하는 걸 말합니다. 즉 주어는 문장의 **통사구조**에서 문장이 나타내는 행위/작용의 주체, 상태/성질이나 정체 밝힘 등의 대상이 언어적으로 나타난 것을 가리킵니다. 한국어에서 주어는 일반적으로 주격조사 '-이/가'가 붙어 표시됩니다.  문법적인 주어가 문장 구성의 중심적인 역할을 하는 언어를 '주어중심언어'라고 합니다. 영어가 대표적인 사례입니다. 주어가 생략되기 어려우며 주어가 의미적으로 굳이 필요 없는 경우에도 허사주어를 반드시 써야 합니다. 다음과 같습니다. > **It** rains (비가 온다)   ## 주제중심언어 한국어는 '주제'도 중요하고 '주어'도 중요한 **주제-주어 동시 부각형 언어(topic-subject prominent language)**라고 합니다. 한국어에서 전형적인 주제 표지인 '-은/는'이 표시되어 문두에 나타난 예시를 몇 가지 살펴보겠습니다. > (ㄱ) **그 책은** 나도 읽어 봤어 > > (ㄴ) **어제는** 하루 종일 집에서 쉬었어 > > (ㄷ) **진이는** 내가 벌써 저녁을 사줬어 > > (ㄹ) **향기는** 장미가 더 좋지 > > (ㅁ) **읽기는** 아무래도 이 책이 더 쉽다 위 예시의 볼드 표시 어절은 모두 통사구조상의 주어로 보기는 어렵습니다. (ㄱ)만 예로 들면 '그 책은'은 통사구조상 목적어로 쓰였습니다. 다른 예를 살펴볼까요? > (ㅂ) (음식점에서 주문할 때) **저는** 짜장면이요 (ㅂ)에서 '나는'은 '짜장면(이다)'의 주어가 아니라는 점을 분명하게 알 수 있습니다. ~~말하는 짜장면이 있을리가 없잖아요.~~ 이 때 '저는'은 주제에 해당하며 실제 주어는 상황 맥락에 따라 생략됐다고 분석하는 것이 매끄럽습니다. (ㅂ)을 통사구조로 분석해 '저는'의 문장성분을 굳이 따지자면 **부사어**에 해당할 것입니다. '나는'을 생략해도 문장이 성립한다는 점을 감안하면 서술어가 요구하는 필수부사어가 아니라는 사실 또한 알 수 있습니다. 주제-주어 동시 부각형 언어인 한국어의 통사적 특징을 몇 가지 살펴보겠습니다. > (1) '주제+평언' 관계에 기초해 조직되는 문장이 많습니다. > > (2) 주제가 될 수 있는 성분에 대한 제약이 적습니다. > > (3) 주제가 문장 구성에서 중심적인 역할을 합니다. > > (4) 주제는 표면상 일정하게 표시됩니다. > > (5) 주어는 생략 가능하고, 허사주어가 필요 없습니다. > > (6) 이중주어 구문이 발달했습니다.   ## 이중주어 문제 한국어에서 무엇을 주어로 해야할지에 대해서는 매우 다양한 이견이 존재한다고 합니다. 대개 아래 예문과 같은 이중주어문의 해석과 관련이 있습니다. > (1) 누나는 눈이 크다. (1)은 정보구조 관점에서 '주제+주어+서술어'로 분석할 수도 있고, 통사구조 관점에서 '주어+[주어+서술어]'로 분석할 수도 있습니다. 후자의 분석에서 [주어+서술어] 형태인 '눈이 크다'는 전체 문장의 서술어로서 절의 형식을 띠고 있으므로 **서술절**이라고 부릅니다.  다른 예문을 보겠습니다. > (2) 나는 호랑이가 무섭다. (2)도 (1)처럼 정보구조 관점에서 '주제+주어+서술어'로 분석할 수도 있고, 통사구조 관점에서 '주어+[주어+서술어]'로 분석할 수도 있습니다. 하지만 여기에서 후자의 분석은 문제가 있습니다.  '무섭다'의 대상은 '호랑이'이고 '나'는 '무섭다'라는 심리상태를 경험하는 사람입니다. 그런데 일반적으로 형용사는 그 성질이나 상태를 지니는 대상이 주어이므로, (2)에서 '나는'은 주어가 될 수 없습니다.  이때 '나는'은 바로 주제가 됩니다. 다시 말해 화자는 '나'라는 대상에 어떤 정보(호랑이가 무섭다)를 전달하고 있다고 분석하는 것이 매끄럽다는 이야기입니다. 그런데 통사구조 관점에서 문장을 분석할 때 '나는'이 주어가 아니라면, '나는'은 대체 어떤 **문장성분(sentence component)**인가 하는 의문이 제기될 수 있습니다. 그런데 정보구조상 주제는 서술어가 요구하는 문장성분이 아닌 경우도 많다는 점에 유의할 필요가 있습니다. 통사구조와 정보구조는 엄밀히 말하면 별개의 개념이기 때문입니다. 따라서 통사구조 관점에서 '나는'의 문장 성분을 굳이 따진다면 부사어 정도로 보아야 할 것입니다. 이의 연장선상에서 아래와 같은 문장은 통사구조보다는 정보구조 틀로 설명하는 것이 편리합니다. 아래 예시에서 '꽃은', '장미가', '생선은'이 주제가 됩니다. > 꽃은 장미가 향기가 좋아요 > > 생선은 도미가 맛있다. 
spectral␞ 이번 글에서는 **그래프(graph)** 기반 군집화 기법인 **Spectral Clustering**에 대해 살펴보도록 하겠습니다. 이 글 역시 고려대 강필성 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 그래프 인접행렬 구축 Spectral Clustering을 수행하려면 원데이터를 그래프로 변환하기 위해 **인접행렬(Adjacency Matrix)**을 만들어야 합니다. Spectral Clustering은 **무방향 가중치 그래프(Undirected Weighted Graph)**를 사용하는데요, 무방향 가중치 그래프와 인접행렬을 직관적으로 비교한 그림은 아래와 같습니다([출처](http://www.thecrazyprogrammer.com/2014/03/representation-of-graphs-adjacency-matrix-and-adjacency-list.html)). <a href="http://imgur.com/zAyiJXm"><img src="http://i.imgur.com/zAyiJXm.jpg" width="300px" title="source: imgur.com" /></a> 원데이터에서 인접행렬을 만들 때는 보통 아래와 같이 **가우시안 커널(Gaussian kernel)**을 많이 사용합니다. 예컨대 벡터로 표현된 하나의 문서를 **노드(node)**라고 둘 때, 문서 간 거리가 멀리 떨어져 있을수록(=유사하지 않을수록) 그 가중치는 줄어듭니다. 아울러 가우시안 커널로 만들어진 인접행렬은 대칭행렬입니다.  $$ { W }_{ ij }=exp\left( -\frac { d{ ({ x }_{ i },{ x }_{ j }) }^{ 2 } }{ 2\sigma^{2} } \right) $$  문서를 그래프로 표현하는 방법에 대해서는 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/07/network/)을, 가우시안 커널로 인접행렬을 만드는 방법에 대해서는 [이곳](https://ratsgo.github.io/natural%20language%20processing/2017/03/08/word2vec/)을 참고하시면 좋을 것 같습니다.  ## 그래프 구축 **fully connected graph**란 모든 노드가 엣지로 연결돼 있는 그래프를 가리킵니다. **ε-neighborhood graph**란 거리가 $ε$보다 가까운 엣지들만 살리고 나머지 엣지는 끊어버린 그래프입니다. **k-nearest neighbor graph**는 각 노드 주변 $k$개 이웃들만 엣지로 연결하고 나머지 엣지는 끊어놓은 그래프입니다. ε-neighborhood graph는 노드의 밀도가 높은 지역에선 엣지가 지나치게 많이 발생하고, 밀도가 낮은 지역에선 엣지가 하나도 없는 노드가 생길 수 있습니다. k-nearest neighbor graph는 끊기는 노드가 발생하진 않지만, 군집이 극단적으로 멀리 떨어져 있는 경우 군집과 군집 사이는 연결되지 않는 경우가 발생할 수 있습니다. 일반적으로 그래프를 구축할 때는 ε-neighborhood graph를 먼저 구축한 뒤 k-nearest neighbor graph를 적용해 엣지가 전혀 없는 노드도 연결해주는 방식을 씁니다. 그럼에도 불구하고 군집 사이가 너무 멀어서 연결 안되는 경우가 발생할 수 있는데 이럴 때는 [minimum spanning tree](https://en.wikipedia.org/wiki/Minimum_spanning_tree) 방법도 자주 사용됩니다.  ## 그래프 컷 지표 그래프 컷은 그래프를 특정 기준에 의해 두 개 이상의 **부그래프(subgraph)**로 나누는 것입니다. 이 부그래프가 바로 Spectral Clustering 기법의 학습 결과물인 군집이 됩니다. 아래와 같은 무방향 가중치 그래프가 주어졌다고 합시다. <a href="http://imgur.com/d8yZTY1"><img src="http://i.imgur.com/d8yZTY1.png" width="400px" title="source: imgur.com" /></a> $Cut(A,B)$는 부그래프 $A$에서 $B$로 향하는 엣지들의 가중치 합입니다. 아래 식과 같습니다. $$Cut(A,B)=\sum _{ i\in A,j\in B }^{ }{ { w }_{ ij } } =0.3$$ $Cut(A,A)$는 $A$에서 $A$로 향하는 엣지들의, $Cut(B,B)$는 $B$에서 $B$로 향하는 엣지들의 가중치 합입니다. $$Cut(A,A)=\sum _{ i\in A,j\in A }^{ }{ { w }_{ ij } } =2.2$$ $$Cut(B,B)=\sum _{ i\in A,j\in B }^{ }{ { w }_{ ij } } =2.3$$ $Vol(A)$는 $A$에 속한 노드에 연결된 엣지들의 모든 가중치 합입니다. 위 그림에서 1번 노드에 연결된 엣지 세 개(0.8+0.6+0.1), 2번 노드에 연결된 엣지 두 개(0.8+0.8), 3번 노드에 연결된 엣지 세 개(0.8+0.6+0.2)를 모두 더한 값입니다. 따라서 $Vol(A)$는 $Cut(A,A)$의 두 배에 $Cut(A,B)$를 더해준 값과 같습니다. 이는 $Vol(B)$도 마찬가지입니다. $$Vol(A)=\sum _{ i\in A }^{ }{ \sum _{ j }^{ }{ { w }_{ ij } } } =4.7$$ $$Vol(B)=\sum _{ i\in B }^{ }{ \sum _{ j }^{ }{ { w }_{ ij } } } =4.9$$  ## Minimum Cut method 이 기법은 원그래프를 $A$와 $B$라는 부그래프로 나눌 때 끊어지는 엣지들의 가중치가 최소가 되도록 합니다. 목적함수는 아래와 같습니다. $$MinCut(A,B)=\min { \frac { 1 }{ 4 } { q }^{ T }(D-W)q } $$ 여기에서 대각행렬 $D$와 벡터 $q$는 아래와 같습니다. $${ D }_{ ii }=\sum _{ j }^{ }{ { w }_{ ij } } \quad ,\quad { D }_{ ij }=0\quad if\quad i\neq j\\ { q }_{ i }=\begin{Bmatrix} 1\quad if\quad i\in A \\ -1\quad if\quad i\in B \end{Bmatrix}$$ $MinCut(A,B)$의 제약조건은 다음과 같습니다. 벡터 ​$q$의 각 요소를 제곱해 모두 더한 ​$q^Tq$가 그래프 전체의 노드수 ​$V$와 일치해야 한다는 겁니다. 벡터 ​$q$의 각 요소는 해당 노드가 ​$A$에 속해 있으면 1, ​$B$에 속해 있으면 -1의 값을 가지기 때문입니다. $$ { q }^{ T }q=\left| V \right| $$ 이해를 돕기 위해 예를 들어보겠습니다. 아래와 같이 무방향 가중치 그래프가 주어졌고, 붉은색 선을 기준으로 부그래프가 두 개로 나뉜다고 합시다. 노드1와 노드2를 부그래프 $A$, 노드3와 노드4를 부그래프 $B$로 두겠습니다. <a href="http://imgur.com/G8QzLZm"><img src="http://i.imgur.com/G8QzLZm.png" width="200px" title="source: imgur.com" /></a> 가중치 행렬 $W$는 아래와 같습니다. $$W=\begin{bmatrix} { w }_{ 11 } & { w }_{ 12 } & 0 & { w }_{ 14 } \\ { w }_{ 21 } & { w }_{ 22 } & { w }_{ 23 } & 0 \\ 0 & { w }_{ 32 } & { w }_{ 33 } & { w }_{ 34 } \\ { w }_{ 41 } & 0 & { w }_{ 43 } & { w }_{ 44 } \end{bmatrix}$$ 대각행렬 $D$는 아래와 같습니다.  $$D=\begin{bmatrix} { w }_{ 11 }+{ w }_{ 12 }+{ w }_{ 14 } & 0 & 0 & 0 \\ 0 & { w }_{ 21 }+{ w }_{ 22 }+{ w }_{ 23 } & 0 & 0 \\ 0 & 0 & { w }_{ 32 }+{ w }_{ 33 }+{ w }_{ 34 } & 0 \\ 0 & 0 & 0 & { w }_{ 41 }+{ w }_{ 43 }+{ w }_{ 44 } \end{bmatrix}$$ $(D-W)q$는 아래와 같습니다.  $$ \begin{align*} (D-W)q&=\begin{bmatrix} { w }_{ 12 }+{ w }_{ 14 } & -{ w }_{ 12 } & 0 & -{ w }_{ 14 } \\ -{ w }_{ 21 } & { w }_{ 21 }+{ w }_{ 23 } & { -w }_{ 23 } & 0 \\ 0 & -{ w }_{ 32 } & { w }_{ 32 }+{ w }_{ 34 } & -{ w }_{ 34 } \\ -{ w }_{ 41 } & 0 & -{ w }_{ 43 } & { w }_{ 41 }+{ w }_{ 43 } \end{bmatrix}\begin{bmatrix} 1 \\ 1 \\ -1 \\ -1 \end{bmatrix}\\ &=\begin{bmatrix} 2{ w }_{ 14 } \\ 2{ w }_{ 23 } \\ -2{ w }_{ 32 } \\ -2{ w }_{ 41 } \end{bmatrix} \end{align*} $$  위 식을 정리하면 아래와 같습니다.  $$\frac { 1 }{ 4 } { q }^{ T }(D-W)q=\frac { 1 }{ 4 } \begin{bmatrix} 1 & 1 & -1 & -1 \end{bmatrix}\begin{bmatrix} 2{ w }_{ 14 } \\ 2{ w }_{ 23 } \\ -2{ w }_{ 32 } \\ -2{ w }_{ 41 } \end{bmatrix}={ w }_{ 14 }+{ w }_{ 23 }$$ 최종적으로 도출된 $w_{14}$와 $w_{23}$은 원그래프에서 두 개 부그래프로 나눠질 때 끊어지는 가중치들입니다. 다시 말해 목적함수에 정의된 $1/4q^T(D-W)q$를 최소화한다는 것은 끊어지는 가중치들을 최소로 하겠다는 의미가 되는 것입니다. 목적함수 $1/4q^T(D-W)q$에 제약조건($q^Tq=V$)을 반영해 라그랑지안 문제로 변환하고, 식을 미지수 $q$로 미분해서 0으로 놓으면 아래와 같이 정리할 수 있습니다. ($q$가 미지수가 되는 이유는 각 노드가 $A$에 속하는지, $B$가 속하는지 정보가 이 벡터에 들어있기 때문입니다)  $$ \begin{align*} \frac { \partial C }{ \partial q } &=\frac { \partial \{ \frac { 1 }{ 4 } { q }^{ T }(D-W)q-\lambda ({ q }^{ t }q-\left| V \right| )\} }{ \partial q } \\ &=\frac { 1 }{ 2 } (D-W)q-\lambda q=0\\ &(D-W)q=\lambda q \end{align*} $$  최종 도출된 식을 보면 우리가 찾고자 하는 $q$는 $D-W$ 행렬의 **고유벡터(eigenvector)**임을 알 수 있습니다. 다만 최소값을 찾는 것이 목적이므로 두번째로 작은 고유값에 해당하는 고유벡터를 취합니다(제일 작은 고유값은 0이기 때문에 무의미한 해입니다). 이 벡터의 각 요소 가운데 양수인 위치의 노드를 부그래프 $A$, 음수인 노드를 $B$로 할당하게 됩니다.  ## Minimum Cut method 적용 예시 예시 그림의 그래프를 인접행렬로 나타내면 다음과 같습니다. <a href="http://imgur.com/d8yZTY1"><img src="http://i.imgur.com/d8yZTY1.png" width="400px" title="source: imgur.com" /></a> | 구분  | $x_1$ | $x_2$ | $x_4$ | $x_3$ | $x_5$ | $x_6$ | | :---: | :---: | :---: | :---: | :---: | :---: | :---: | | $x_1$ |  0  | 0.8 |  0  | 0.6 | 0.1 |  0  | | $x_2$ | 0.8 |  0  |  0  | 0.8 |  0  |  0  | | $x_3$ | 0.6 | 0.8 | 0.2 |  0  |  0  |  0  | | $x_4$ | 0.8 |  0  |  0  | 0.2 | 0.8 | 0.7 | | $x_5$ | 0.1 |  0  | 0.8 |  0  |  0  | 0.8 | | $x_6$ |  0  |  0  | 0.7 |  0  | 0.8 |  0  | 이로부터 $D-W$를 구합니다. 이를 고유분해한 결과가 아래와 같습니다. $Λ$는 $D-W$의 고유값들로 이뤄진 벡터, $V$는 열벡터가 고유벡터인 행렬입니다. $${ \Lambda }^{ T }=\begin{bmatrix} 0.0 & 0.3 & 2.2 & 2.3 & 2.5 & 3.0 \end{bmatrix}\\ X=\begin{bmatrix} 0.4 & 0.2 & 0.1 & 0.4 & -0.2 & -0.9 \\ 0.4 & 0.2 & 0.1 & 0.0 & 0.4 & 0.3 \\ 0.4 & 0.2 & -0.2 & 0.0 & -0.2 & 0.6 \\ 0.4 & -0.4 & 0.9 & 0.2 & -0.4 & -0.6 \\ 0.4 & -0.7 & -0.4 & -0.8 & -0.6 & -0.2 \\ 0.4 & -0.7 & -0.2 & 0.5 & 0.8 & 0.9 \end{bmatrix}$$ 그렇다면 우리가 찾고자 하는 미지수 $q$는 $V$의 두번째 열이 됩니다. 여기에서 양수인 노드1 노드2 노드3은 부그래프 $A$, 음수인 노드4 노드5 노드6은 $B$에 할당하면 Spectral Clustering 절차가 끝납니다. $${ q }^{ T }=\begin{bmatrix} 0.2 & 0.2 & 0.2 & -0.4 & -0.7 & -0.7 \end{bmatrix}$$   ## 다른 방법들 부그래프의 크기를 비슷하게 맞추는 방향으로 자르는 **Ratio Cut**, 엣지 가중치 합을 비슷하게 하여 부그래프를 자르는 **Minmax Cut** 기법이 있습니다. 식은 아래와 같습니다. (여기에서 $A$의 절대값 은 $A$의 노드 수를 뜻합니다) $$RatioCut(A,B)=\min { \{ Cut(A,B)(\frac { 1 }{ \left| A \right| } +\frac { 1 }{ \left| B \right| } )\} } $$ $$MinMaxCut(A,B)=\min { \{ Cut(A,B)(\frac { 1 }{ Cut(A,A) } +\frac { 1 }{ Cut(B,B) } )\} } $$   ## Recursive bi-partitioning 지금까지 설명드린 Spectral Clustering은 원그래프를 두 개의 부그래프로 나누는 기법이었습니다. 그렇다면 여러 개 부그래프로 군집화하려면 어떻게 해야할까요? 지금까지 설명드렸던 기법을 반복적으로 수행하면 됩니다. <a href="http://imgur.com/YZmjGI4"><img src="http://i.imgur.com/YZmjGI4.png" width="500px" title="source: imgur.com" /></a> 
LAsummary2␞ 제 개인적 정리 용도로 업로드하는 글입니다.  <a href="https://imgur.com/7RIR89Z"><img src="https://i.imgur.com/7RIR89Z.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/7X0DlZv"><img src="https://i.imgur.com/7X0DlZv.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/qqGFLYW"><img src="https://i.imgur.com/qqGFLYW.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/OgYB0G3"><img src="https://i.imgur.com/OgYB0G3.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/Qa3cXX1"><img src="https://i.imgur.com/Qa3cXX1.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/hFbgvp3"><img src="https://i.imgur.com/hFbgvp3.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/rL7uJNN"><img src="https://i.imgur.com/rL7uJNN.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/HMR3cAk"><img src="https://i.imgur.com/HMR3cAk.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/vLNKER5"><img src="https://i.imgur.com/vLNKER5.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/vX2q2ua"><img src="https://i.imgur.com/vX2q2ua.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/8DxnGZH"><img src="https://i.imgur.com/8DxnGZH.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/HW3GwTu"><img src="https://i.imgur.com/HW3GwTu.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/BQn5WCR"><img src="https://i.imgur.com/BQn5WCR.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/DSKojme"><img src="https://i.imgur.com/DSKojme.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/gCsnUNb"><img src="https://i.imgur.com/gCsnUNb.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/kmJXJQ9"><img src="https://i.imgur.com/kmJXJQ9.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/MAYuMQr"><img src="https://i.imgur.com/MAYuMQr.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/5N7lUFS"><img src="https://i.imgur.com/5N7lUFS.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/ALykVse"><img src="https://i.imgur.com/ALykVse.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/WcoFMA9"><img src="https://i.imgur.com/WcoFMA9.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/j5iU3ri"><img src="https://i.imgur.com/j5iU3ri.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/OZPVmMT"><img src="https://i.imgur.com/OZPVmMT.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/E5ouUt8"><img src="https://i.imgur.com/E5ouUt8.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/a7HPbBH"><img src="https://i.imgur.com/a7HPbBH.jpg" title="source: imgur.com" /></a> <a href="https://imgur.com/fxXd68U"><img src="https://i.imgur.com/fxXd68U.jpg" title="source: imgur.com" /></a>
thetarole␞ 이번 글에서는 한국어의 **의미역(theta role)**에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의와 이선웅 경희대 교수님이 쓰신 '한국어 문법론의 개념어 연구'를 정리했음을 먼저 밝힙니다.   ## 의미역의 정의 의미역이란 명사구가 서술어와 관련하여 지니는 의미 기능을 가리킵니다. 다시 말해 서술어가 나타내는 사태 속에서 논항이 나타내는 참여자가 수행하는 역할의 유형 혹은 논항이 서술어에 대해 갖는 의미상의 자격, 역할, 지위 따위를 나타냅니다. 예를 들어 보겠습니다. > 가. **학교에서** 운동회를 개최하였다. > > 나. 이 도시의 명칭은 **그 전설에서** 유래하였다. 위 예시에서 논항인 '학교에서'와 '그 전설에서'는 동일한 격조사(-에서)를 쓰고 있지만 서술어 와 관련하여 상이한 의미 기능을 하고 있습니다. 이 때 '학교에서(장소)'와 '그 전설에서(출발점)'가 가지는 의미기능을 의미역이라고 합니다.   ## 한국어 의미역의 종류 한국어 자료를 대상으로 의미역의 종류에 대해 가장 정밀하게 기술한 논의는 홍재성 외(2002)라고 합니다. 이 연구를 정리/보완한 이선웅(2012)의 논의는 다음과 같습니다. > **행위주역(Agent)** : 동사가 행위를 표현할 경우 그 행위를 지배하는 논항이 갖는 의미역 > > **피행위주역(Patient)** : 동사가 행위를 표현할 경우 그 행위로 인해 영향을 입는 논항이 갖는 의미역 > > **경험주역(Experiencer)** : 인지(cognition), 지각(perception), 감정(emotion)을 나타내는 용언의 경우 그 현상의 경험 주체가 되는 논항이 갖는 의미역 > > **동반주역(Companion)** : 독립적으로 역할을 하지 못하고 다른 의미역, 즉 대개 행위주나 대상을 보조하여 그것과 같은 역할을 하는 주체를 나타내는 논항이 갖는 의미역 > > **대상역(Theme)** : 행위나 과정의 영향을 받지만 그 과정을 지배하지는 못하는 논항. 즉 위치, 조건, 상태가 바뀌거나 주어진 상태나 위치에 있는 참여자들을 나타내는 논항이 갖는 의미역 > > **장소역(Location)** : 행위주나 대상이 위치하는 물리적 혹은 추상적 시공간을 나타내는 논항이 갖는 의미역 > > **도착점역(Goal)** : 동사가 표현하는 사건이 물리적 이동을 포함하고 있을 경우 그 끝점, 추상적인 행위나 태도의 의미를 포함하고 있을 경우 그 지향점을 표현하는 논항이 갖는 의미역 > > **결과상태역(Resultant State)** : 동사가 인물의 자격 또는 물질의 성질이나 용도의 변화를 기본 의미로 가질 때, 그러한 변화의 결과를 나타내는 논항이 갖는 의미역 > > **출발점역(Source)** : 동사가 이동이나 변화의 의미를 포함하고 있을 경우 물리적, 추상적 시작 지점을 표현하는 논항이 갖는 의미역 > > **도구역(Instrument)** : 행위, 이동의 의미를 표현하는 동사의 경우 그 방편이나 경로, 재료를 나타내는 논항이 갖는 의미역 > > **영향주역(Effector)** : 동사가 나타내는 사건(행위, 상태)을 비의도적으로 (주로 '이동'이나 '위치'에 의해)유발하는 논항이 갖는 의미역 > > **기준치역(Criterion)** : 평가의 의미를 가진 동사의 경우 평가되는 대상에 상대하여 평가의 기준이 되는 논항이 갖는 의미역 > > **내용역(Contents)** : 발화동사, 사유동사 등의 절 논항이 갖는 의미역 > > **경로역(Path)** : 출발점과 도착점을 함께 명세하는 논항이 지닌 의미역 > > **자격역(Eligibility)** : 술어가 의미하는 어떤 행위의 지속시간동안 어떤 자격으로 그 행위가 이루어졌는지를 나타내는 의미역   ## 분석 예시 예문을 보겠습니다. > **태풍(행위주역)**이 그 마을 전체에 피해를 입히고 지나갔다 > > **아버지(행위주역)**가 **신문(피행위주역)**을 읽으신다. > > **나(경험주역)**는 이곳이 춥다. > > 나는 **애인(동반주역)**과 시내에서 만났다. > > 동생이 **음악(대상역)**을 듣는다. > > **진이(대상역)**는 착하다. > > 김 씨는 **이 공장(장소역)**에서 일한다. > > 아버지가 아들을 **서울(도착점역)**로 보내었다. > > 감독이 골키퍼를 **김병지(결과상태역)**로 바꾸었다. > > 물이 **얼음(결과상태역)**으로 변했다. > > 그 사람은 **러시아(출발점역)**에서 왔습니다. > > 그녀는 늘 **손(도구역)**으로 입을 가리고 웃습니다. > > 철수가 길을 가다가 **전봇대(영향주역)**에 부딪혔다. > > 전봇대가 **태풍(영향주역)**에 쓰러졌다. > > 철수는 **영희(기준치역)**와 닮았다. > > 동생이 **오늘 시험을 본다고(내용역)** 말했다. > > **광화문에서 서울역까지의(경로역)** 행진 > > 철수의 **떠돌이(자격역)** 생활   ## 선택제약 서술어와 논항이 아무렇게나 결합하는 것은 아닙니다. 서술어가 어떤 의미를 가진 요소를 논항으로 선택하는지에서 보이는 제약을 선택제약이라고 합니다. 예컨대 다음 예문은 의미상 비문입니다. > *소나무가 웃는다. > > *나는 권력을 존경한다. 위 예문이 비문이 되는 이유는 '웃다'라는 서술어는 유정명사를 주어로, '존경하다'는 인성명사를 목적어로 취하기 때문입니다. 같은 의미를 지니는 서술어라도 의미가 다른 논항을 취하는 경우도 있습니다. 예문을 보겠습니다. > 눈을 감다. > > 입을 다물다. '감다'와 '다물다'는 모두 '닫다'는 공통된 뜻을 가지고 있지만 이들이 각각 취하는 목적어 명사구의 종류가 다른 걸 확인할 수 있습니다. 
attention␞ 이번 글에서는 딥러닝 모델이 특정 벡터에 주목하게 만들어 모델의 성능을 높이는 기법인 **어텐션(attention)** 매커니즘에 대해 살펴보도록 하겠습니다. 이 글은 미국 스탠포드 대학의 CS224d 강의와 [원 논문](https://arxiv.org/abs/1409.0473)을 정리하였음을 먼저 밝힙니다. 혹시 제가 잘못 알고 있는 점이나 보완할 점 있다면 댓글로 알려주시면 감사하겠습니다. 그럼 시작하겠습니다.  ## 동기 어텐션 매커니즘은 기계번역(machine translation)을 위한 sequence-to-sequence 모델(S2S)에 처음 도입됐습니다. S2S 아키텍처를 간단히 나타낸 그림은 다음과 같습니다. 소스랭귀지($A,B,C$)를 입력으로 해서 벡터로 만드는 앞부분을 인코더(encoder), 인코더가 출력한 벡터를 입력으로 해서 타겟랭귀지($W,X,Y,Z$)를 출력하는 뒷부분을 디코더(decoder)라고 합니다. <a href="https://imgur.com/6mbfPZR"><img src="https://i.imgur.com/6mbfPZR.png" width="500px" title="source: imgur.com" /></a> 그런데 여기에서 소스랭귀지와 타겟랭귀지의 길이가 길어질 수록 모델의 성능이 나빠집니다. $W$를 예측할 때 $A,B,C$ 모두에 집중해 보게 되면 정확도가 떨어질 수 있습니다. 모델로 하여금 '중요한 부분만 집중(attention)하게 만들자'가 어텐션 매커니즘의 핵심 아이디어가 되겠습니다.   ## 핵심 아이디어 예컨대 독일어 "Ich mochte ein bier"를 영어 "I'd like a beer"로 번역하는 S2S 모델을 만든다고 칩시다. 모델이 네번째 단어인 'beer'를 예측할 때 'bier'에 주목하게 만들고자 합니다. 어텐션 매커니즘의 가정은 **인코더가 'bier'를 받아서 벡터로 만든 결과(인코더 출력)는 디코더가 'beer'를 예측할 때 쓰는 벡터(디코더 입력)와 유사할 것**이라는 점입니다.   ## 인코더 계산과정 먼저 인코더 계산과정을 살펴보겠습니다. 인코더는 $i$번째 단어벡터 $x_i$를 받아서 그에 해당하는 히든스테이트 벡터 $h_i$를 만듭니다. 이후 $h_i$가 $i$번째 열벡터가 되도록 행렬 형태로 차곡차곡 쌓아놓습니다. 이 행렬을 $F$라고 정의합시다. 아래 그림은 양방향(bi-directional) 모델을 가정한 것입니다.  <a href="https://imgur.com/CbQjPWo"><img src="https://i.imgur.com/CbQjPWo.png" width="400px" title="source: imgur.com" /></a>   ## 디코더 계산과정 $e_{ij}$는 디코더가 $i$번째 단어를 예측할 때 쓰는 직전 스텝의 히든스테이트 벡터 $s_{i-1}$이 인코더의 $j$번째 열벡터 $h_j$와 얼마나 유사한지를 나타내는 스코어(스칼라)값입니다. 예컨대 어텐션 매커니즘이 제대로 작동한다면 'bier'에 해당하는 디코더 출력 벡터와 'beer'를 예측할 때 쓰이는 인코더 입력벡터의 유사도가 높게 나타날 겁니다. 다음과 같이 정의됩니다.  $$ { e }_{ ij }=a\left( { s }_{ i-1 },{ h }_{ j } \right) $$  위 식에서 $a$는 원 논문에는 alignment model이라 소개돼 있습니다. $s_{i-1}$과 $h_j$ 간 유사도를 잘 뽑아낼 수 있다면 다양한 변형이 가능하다고 합니다. 실제로 $e_{ij}$를 구할 때 쓰이는 $a$는 (1) $F^TVs_{i-1}$ (2) $v^T\tanh{(WF+Vs_{i-1})}$ 등 다양하게 쓰입니다. 여기에서 $v, V, W$ 등은 어텐션을 적용하기 위한 학습 파라메터입니다. $e_{ij}$에 소프트맥스 함수를 적용해 합이 1이 되도록 확률값으로 변환합니다. $T_x$는 디코더 입력 단어의 수를 가리킵니다.  $$ \alpha _{ ij }=\frac { exp\left( { e }_{ ij } \right) }{ \sum _{ k=1 }^{ { T }_{ x } }{ exp\left( { e }_{ ik } \right) } } $$  디코더가 $i$번째 단어를 예측할 때 쓰이는 attention vector $a_i$는 다음과 같이 정의됩니다.  $$ \overrightarrow { \alpha _{ i } } =\left[ { \alpha }_{ i1 },{ \alpha }_{ i2 },...,{ \alpha }_{ i{ T }_{ x } } \right] $$  디코더가 $i$번째 단어를 예측할 때 쓰이는 context vector $c_i$는 다음과 같이 정의됩니다. 인코더의 $j$번째 열벡터를 어텐션 확률값으로 가중합을 한 것이라고 볼 수 있겠습니다.  $$ \overrightarrow { { c }_{ i } } =\sum _{ j=1 }^{ { T }_{ x } }{ { \alpha }_{ ij }{ h }_{ j } } =F \overrightarrow { { \alpha }_{ i } } $$   ## 디코더 계산 예시 디코더에서 계산되는 과정을 나타낸 그림은 다음과 같습니다. alignment model $a$는 디코더가 2번째 단어 'like'를 예측할 때 쓰이는 첫번째 히든스테이트 벡터 $s_1$과 가장 유사한 인코더의 열벡터가 $h_2$라고 판단했습니다. 디코더가 2번째 단어를 예측할 때 쓰이는 attention vector $α_2$를 보면 두번째 요소값이 가장 높기 때문입니다.  <a href="https://imgur.com/4zdzDKL"><img src="https://i.imgur.com/4zdzDKL.png" width="300px" title="source: imgur.com" /></a>  디코더가 2번째 단어를 예측할 때 쓰이는 context vector $c_2$는 인코더 출력벡터들로 구성된 행렬 $F$에 $α_2$를 내적해 구합니다. 인코더 모델은 타겟랭귀지 단어벡터(I'd)와 $c_2$를 concat해서 현시점의 히든스테이트 벡터 $s_i$를 만들어 냅니다.  
wordclass␞ 이번 글에서는 한국어 품사 분류의 기준에 대해 간략히 살펴보고 단어의 **분포(distribution)**가 품사의 의미와 어떤 관계를 맺고 있는지 알아보도록 하겠습니다. 이번 글은 경희대 이선웅 교수님의 강의와 표준국어문법론을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 품사와 품사론 학교문법에 따르면 **품사**란 단어를 문법적 성질의 공통성에 따라 몇 갈래로 묶어 놓은 것입니다. 품사론은 품사의 종류와 성격 등에 관해 연구하는 분야를 뜻하는데요. 예컨대 7차 교육과정의 문법 교과서에 있는 아래와 같은 진술이 품사론의 영역이라고 볼 수 있겠습니다. > 가. '(허리가) 굽다'는 '굽어, 굽어서'로 활용하고 '(불에)굽다'는 '구워, 구워서'로 활용한다. > > 나. 명사 중에는 반드시 그 앞에 꾸며 주는 말, 즉 관형어가 있어야만 문장에 쓰일 수 있는 것들이 있다. > > 다. 국어의 재귀칭에는 '저2, 저희2, 자기, 당신2'가 있다. '가'는 사실 **형태론**의 설명 대상입니다. 단어의 변화 양상에 주목한 문장이기 때문입니다. '나'는 **통사론**이라 말할 수 있습니다. 문장 내 다른 성분과의 문법적 관계를 서술한 문장이거든요. '다'는 단어 수준의 의미에 방점을 둔 **어휘론**의 설명 대상입니다.  이렇듯 품사론은 형태론, 통사론, 어휘론에 흩어져 있는 사실들을 묶어주는 종합적인 학문영역이어서 그 독자성은 적다고 할 수 있겠습니다. 품사론이 독자적으로 보이는 이유는 관습에 따른 착시현상일 뿐 그 내용 하나하나는 형태론적 지식, 통사론적 지식, 어휘론적 지식의 일부라는 이야기입니다.  학교문법에서는 한국어 품사를 9가지로 정의하고 있습니다. 이선웅 교수님에 따르면 그 체계는 아래 표와 같이 정리할 수 있는데요. 품사 분류 기준에 대해 자세히 살펴보시려면 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/04/21/wordclass/)을 참고하시면 좋을 것 같습니다. <a href="http://imgur.com/NXQ4iQp"><img src="http://i.imgur.com/NXQ4iQp.png" width="300px" title="source: imgur.com" /></a>  ## 한국어 품사 분류 기준 **학교문법**에서 제시하는 품사 분류 기준은 세 가지입니다. **기능(function)**, **의미(meaning)**, **형태(form;형식)**가 바로 그것입니다. 우선 기능은 한 단어가 문장 가운데서 다른 단어와 맺는 관계를 가리킵니다. > (1) 이 샘의 깊이가 얼마냐? > > (2) 저 산의 높이가 얼마냐? > > (3) 이 샘이 깊다. > > (4) 저 산이 높다. 위 예시에서 '깊이', '높이'는 문장의 주어로 쓰이고 있고, '깊다', '높다'는 서술어로 사용되고 있습니다. 이처럼 기능이 같은 단어 부류를 일단 같은 품사로 묶을 수 있습니다. 의미란 형식적인 의미를 나타냅니다. > (가) 깊이, 깊다 > > (나) 높이, 높다 위 예시에서 '깊이', '깊다'를 하나로 묶고, '높이', '높다'를 같은 군집으로 넣을 수도 있습니다. 이 때 적용된 기준은 어휘적 의미인데요, 품사 분류에는 어휘적 의미보다는 **형식적 의미**가 중요한 기준이 됩니다. 다시 말해 어떤 단어가 사물의 이름을 나타내느냐, 그렇지 않으면 움직임이나 성질, 상태를 나타내느냐 하는 것입니다. 이렇게 본다면 '깊이'와 '높이'를 한 덩어리로, '깊다'와 '높다'를 다른 덩어리가 될 수 있습니다. 형식이라고 함은 단어의 형태적 특징을 의미합니다. > 철수가 동화를 빨리 읽었다. 위 예시에서 철수, 동화 같은 단어는 변화하지 않습니다. 하지만 '읽었다'는 아래처럼 어미가 붙어 여러 가지 모습으로 변화를 일으킵니다. > 읽었다, 읽는다, 읽는구나, 읽어라...  ## 한국어 품사 분류의 실제 하지만 실제 품사를 분류할 때에는 여러가지 어려움이 따릅니다. 예컨대 의미는 품사 분류시 고려 대상이 될 수 있으나 결정적인 분류 기준은 될 수 없다는 겁니다. 예를 들어보겠습니다. > (a) 공부하다 > > (b) 공부 주지하다시피 (a)는 동사, (b)는 명사로 분류됩니다. 그렇다면 둘 사이에 의미상 큰 차이가 있다고 말할 수 있을까요? (a)의 경우 '하다'가 붙어 행위적인 속성이 더 강조된 느낌이 있기는 하지만 그 의미 차이가 결정적이지는 않은 것 같습니다. 사실 의미를 정확하게 알아내기란 어렵습니다. 예컨대 한국어의 '있다'는 아래처럼 형용사(exist)로도 동사(stay)로도 쓰입니다. 그럼 '있다'의 의미는 어디까지가 형용사 영역이고 어디까지가 동사 영역일까요? 구분하기 쉽지 않은 영역입니다. > 형용사적 용법 : 사과가 세 개 있다. > > 동사적 용법 : 꼼짝 말고 여기 있어라. 한국어 품사 분류시 결정적 기준이 될 수 없는 건 형태도 마찬가지입니다. 이번엔 감탄사로 예를 들어보겠습니다. > (ㄱ) 영수가 학교에 간다. > > (ㄴ) 영수! 조용히 해. (ㄱ)의 영수는 명사, (ㄴ)의 영수는 감탄사로 쓰인 점을 확인할 수 있습니다. 형태는 같지만 의미가 달라졌다는 것이죠.   ## 기능과 분포 한국어 품사를 분류할 때 가장 결정적인 기준은 바로 기능이라고 합니다. 앞선 예에서 (a)와 (b)를 분류할 때는 해당 단어가 문장 내에서 점하는 역할에 초점을 맞춰 본다는 것이죠. (a)의 경우 동작/작용의 기능이 있기 때문에 '동사', (b)는 사물의 이름을 나타내는 기능이 있기 때문에 '명사'로 구분할 수 있게 됩니다. 마찬가지로 (ㄱ)은 사물의 이름으로 쓰였고, (ㄴ)은 문장의 다른 단어들과 문법적 관계가 없기 때문에 각각 명사, 감탄사(독립어)로 분류하게 됩니다. 그런데 한국어에서는 단어의 기능이 분포와 매우 밀접한 관련을 맺고 있다고 합니다. 분포란 단어의 등장 순서나 위치를 말합니다. 이와 관련해 국어학 창시자 격인 최현배 선생(1894~1970)이 쓰신 글을 인용해 보겠습니다. 최현배 선생 또한 기능이 가장 중요한 품사 분류 기준이면서, 기능은 분포와 상당한 관계가 있다고 지적했습니다. > 씨(품사)의 가름(분류)은 그 말법에서의 구실 곧 씨 서로의 관계와 월(文)을 만드는 작용의 관계를 주장(主)으로 삼고, 그에 따르는 형식과 의미를 붙힘(從)으로 삼아, 이 네 가지가 서로 관계하는 양태를 표준으로 삼아 결정하여야 한다. (중략) 씨와 씨의 관계라는 것은 한 씨가 다른 씨와 합하는 일이 잇나 없나, 또 합하는 경우에는 어떠한 자리에서 하는가 하는 것이 그 씨의 뜻과 꼴(형식)에 들어나는 모양을 이름이요. 기능은 단어가 문장 내에서 어떤 역할을 하는지, 분포는 그 단어가 어느 자리에 있는지를 나타냅니다. 비유하자면 최순실 씨가 박근혜정부의 실세(기능)였던 건 박 전 대통령과 자주 만나고 가까이에 있었기(분포) 때문입니다. 이처럼 기능과 분포는 개념적으로 엄밀히 다르지만, 둘 사이에는 밀접한 관련을 지닙니다.   ## 한국어 품사 분류의 일반적 기준 최형용(2013)은 한국어 품사 분류의 일반적인 기준을 아래와 같이 정의했습니다. > **체언(명사)** : 관형사가 그 앞에 올 수 있고 조사가 그 뒤에 올 수 있음 > > **용언(동사/형용사)** : 부사가 그 앞에 올 수 있고 선어말어미가 그 뒤에 올 수 있고 어말어미가 그 뒤에 와야 함 > > **관형사** : 명사가 그 뒤에 와야 함 > > **부사** : 용언, 부사, 절이 그 뒤에 와야 함 > > **조사** : 체언 뒤에 와야 함 > > **어미** : 용언 뒤에 와야 함 > > **감탄사(간투사)** : 특별한 결합 제약 없이 즉 문장 내의 다른 단어와 문법적 관계를 맺지 않고 따로 존재함  ## Distributed Representations와의 접점 [Neural Network Language Model](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/29/NNLM/), [Word2Vec](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/), [GloVe](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/09/glove/) 등 단어를 벡터로 바꾸는 방법론이 제안되었습니다. 이 방법론들의 특징은 학습말뭉치의 단어 분포 정보를 보존하는 방식으로 벡터를 바꾸게 되는데요, 자세한 내용은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/11/embedding/)을 참고하시면 좋을 것 같습니다.  어쨌든 이러한 모델들이 개별 단어의 형식적 의미나 형태를 전혀 고려하지 않음에도 높은 성능을 낼 수 있었던 건 지금까지 설명해드렸던 것처럼 임베딩된 단어벡터들이 분포 정보를 내포하고 있기 때문인 것 같습니다. 이 분포 정보가 단어의 기능이나 형식적 의미와 깊은 연관을 맺고 있기 때문에 임베딩 결과가 사람이 보기에도 그럴싸하게 나온다는 것이죠. 
dijkstra␞ 이번 글에서는 [최단 경로(Shortest Path)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/25/shortestpath/)를 찾는 대표적인 기법 가운데 하나인 다익스트라 알고리즘(Dijkstra's algorithm)을 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님과 역시 같은 대학의 김황남 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept 다익스트라 알고리즘은 [너비우선탐색(BFS)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/19/BFS/)을 기본으로 합니다. 하단 좌측과 같은 그래프를 대상으로 다익스트라 알고리즘을 적용해 보겠습니다. 우선 시작노드를 제외한 모든 노드의 거리정보를 무한대로 초기화합니다. 시작노드 $s$를 탐색하고 있다(*processing*)는 의미로 *gray*를 칠해둡니다.  <a href="https://imgur.com/EKu1v4e"><img src="https://i.imgur.com/EKu1v4e.png" title="source: imgur.com" /></a>  (b)를 보겠습니다. 시작노드 $s$를 기준으로 BFS를 적용합니다. $s$에 바로 이웃한 $t$와 $y$에 대해 거리정보를 업데이트한 뒤 $s$ 방문을 마쳤다는 의미로 *black*을 칠해둡니다. 다음 BFS 적용 대상은 방문하지 않은(*white*) 노드들 가운데 거리가 최소인 노드입니다. $y$가 5로 가장 작군요. $y$를 탐색하고 있다는 의미로 *gray*를 칠해둡니다. (c)를 보겠습니다. $y$에 바로 이웃한 $t,x,z$에 대해 거리정보를 업데이트합니다. 시작노드 $s$와 $t$ 사이의 기존 최단거리는 10이었습니다. 그런데 ($s$와 $y$ 사이의 최단거리)+($y$와 $t$ 사이의 거리)=5+3=8이므로, $s$와 $t$ 사이의 최단거리를 8로 바꾸고, 최단경로를 $y$를 경유하게끔 업데이트합니다([edge relaxation](https://ratsgo.github.io/data%20structure&algorithm/2017/11/25/shortestpath/)). 나머지 $x,z$도 이렇게 수행합니다. 이후 $y$ 방문을 마쳤다는 의미로 *black*을 칠해 둡니다. 다음 BFS 적용 대상은 거리가 7로 가장 작은 미방문 노드인 $z$입니다. 탐색하고 있다는 의미로 *gray*를 칠해 둡니다.  <a href="https://imgur.com/3wBSN7Z"><img src="https://i.imgur.com/3wBSN7Z.png" title="source: imgur.com" /></a>  (d)를 보겠습니다. $z$를 기준으로 BFS를 적용합니다. $z$에 바로 이웃한 $y,x$에 대해 거리정보를 업데이트합니다. $y$는 이미 방문을 마쳤으므로(*black*) 건너뛰고 $x$만 처리합니다. $s$와 $x$ 사이의 기존 최단거리는 14였습니다. 그런데 ($s$와 $z$ 사이의 최단거리)+($z$와 $x$ 사이의 거리)=7+6=13으로 기존보다 작으므로, $s$와 $x$ 사이의 최단거리를 13으로 바꾸고, 최단경로를 $z$를 경유하게끔 업데이트합니다. 이후 $z$ 방문을 마쳤다는 의미로 *black*을 칠해 둡니다. 다음 BFS 적용 대상은 거리가 8로 가장 작은 미방문 노드인 $t$입니다. 탐색하고 있다는 의미로 *gray*를 칠해 둡니다. (e)를 보겠습니다. $t$를 기준으로 BFS를 적용합니다. $t$에 바로 이웃한 $x$에 대해 거리정보를 업데이트합니다. $s$와 $x$ 사이의 기존 최단거리는 13였습니다. 그런데 ($s$와 $t$ 사이의 최단거리)+($t$와 $x$ 사이의 거리)=8+1=9로 기존보다 작으므로, $s$와 $x$ 사이의 최단거리를 9로 바꾸고, 최단경로를 $t$를 경유하게끔 업데이트합니다. 이후 $t$ 방문을 마쳤다는 의미로 *black*을 칠해 둡니다. 다음 BFS 적용 대상은 거리가 9로 가장 작은 미방문 노드인 $x$입니다. 탐색하고 있다는 의미로 *gray*를 칠해 둡니다. 마지막으로 (f)를 보겠습니다. $x$를 기준으로 BFS를 적용합니다. $x$에 바로 이웃한 $z$에 대해 거리정보를 업데이트합니다. 그런데 $z$는 이미 방문을 마쳤으므로 건너뜁니다. 더 이상 처리할 이웃노드가 없으므로 $x$ 탐색을 마치고 *black*을 칠해 둡니다. 이로써 모든 노드 방문을 마쳤습니다. 다익스트라 알고리즘을 종료합니다. 다익스트라 알고리즘의 의사코드는 다음과 같습니다.  <a href="https://imgur.com/7wCKA2E"><img src="https://i.imgur.com/7wCKA2E.png" width="350px" title="source: imgur.com" /></a>   ## 계산복잡성 하나의 노드에 대해 다익스트라 알고리즘을 수행하는 경우를 따져보겠습니다. 미방문노드 가운데 거리가 가장 작은 노드에 BFS를 적용합니다. 거리를 가장 작은 미방문노드를 가려내려면 최악의 경우 노드 전체를 모두 따져봐야 하므로 $O($\|$V$\|$)$입니다. 선택된 노드의 모든 이웃노드들에 대해 최단경로 정보를 업데이트합니다. 한 노드당 엣지의 기대값은 \|$E$\|/\|$V$\|입니다. 다익스트라 알고리즘은 이러한 연산을 전체 노드 수만큼 반복하므로 전체적인 계산복잡성은 $O($\|$V$\|$^2+$\|$E$\|$)$가 됩니다. 보통의 *dense graph*는 엣지의 수가 노드 수의 제곱만큼 있으므로 간략하게 계산복잡성을 적으면 $O($\|$V$\|$^2)$이 됩니다.    ## 단점 다익스트라 알고리즘의 최대 단점은 가중치가 음수인 경우 작동하지 않는다는 점입니다. 이를 도식화한 그림은 다음과 같습니다.  <a href="https://imgur.com/71eZ0Fo"><img src="https://i.imgur.com/71eZ0Fo.png" width="500px" title="source: imgur.com" /></a>  만일 음수인 가중치를 갖는 엣지가 포함된 그래프에 대해 다익스트라 알고리즘을 적용하려고 할 경우, 그래프 전체에서 가장 작은 가중치의 절대값만큼을 모든 엣지 가중치에 더해준 뒤 다익스트라 알고리즘을 적용하고, 적용이 끝난 이후 해당 절대값만큼을 다시 빼서 결과를 내는 방식으로 수행할 수도 있습니다.
josa␞ 이번 글에서는 한국어의 보조사 개념과 그 종류에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 보조사와 '세로관계' 보조사란 명사구 뒤에 붙어 특정한 의미를 덧붙이는 조사를 가리킵니다. [격조사](https://ratsgo.github.io/korean%20linguistics/2017/10/13/josa/)와 달리 보조사는 조사의 형태만으로는 선행 명사구의 문장 성분을 짐작할 수 없습니다. 예문을 보겠습니다. > (1) 진이는 **음식도** 잘해. > > (2) **음식도** 맛있어. (1)에서 '음식도'는 서술어의 목적어로 쓰였습니다. (2)에서는 주어로 사용됐습니다. 하지만 (1), (2) 모두 also 정도의 의미가 추가된 점을 확인할 수 있습니다. 보조사는 이처럼 문장 바깥에 있는 다른 요소와의 의미 관계를 표시합니다. 다른 예문을 보겠습니다. > (3) **진이는** 합격했어. (민이? 순이?) > > (4) **진이만** 합격했어. (민이X, 순이X) > > (5) **진이도** 합격했어. (민이O, 순이O) (3)~(5) 문장을 발화한 화자는 '민이'와 '순이'를 전제하고 말했다고 가정해 봅시다. (3)처럼 썼다면 '민이랑 순이는 모르겠는데, 진이는 합격했어' 정도의 의미를 가집니다. (4)의 경우 '민이랑 순이는 떨어졌는데, 진이는 합격했어' 정도의 뉘앙스입니다. (5)는 '민이, 순이, 진이 모두 합격했어' 정도의 느낌입니다.  (3)~(5) 모두 '민이'나 '순이'를 직접 언급하지는 않았지만 한국어를 모국어로 하는 청자라면 특별한 부가 정보 없이도 위와 같은 해석을 충분히 할 수 있습니다. 이처럼 보조사는 문장 바깥에 있는 다른 요소와의 관계를 표시해 줍니다.  문장을 왼쪽에서 가로로 쓴다고 할 때 문장에서 언급되지 않는 요소(민이, 순이)는 해당 단어(진이)의 아래로 붙는다는 점에 착안해, **보조사는 세로관계를 나타낸다**고 설명하는 경우가 많습니다. 반면 격조사는 문면에 실현된 명사구나 절이 그것의 핵과 어떤 관계에 있는지 가로관계를 나타냅니다.   ## 보조사의 종류 보조사에는 체언, 부사, 연결형 등에 두루 쓰이는 통용보조사, 주로 종결형 뒤에 쓰이는 종결보조사 둘로 나뉩니다. 다음 예문은 통용보조사 '은/는'이 쓰인 예시입니다. 각각 주어, 부사어, 본용언, 어근에 붙어서 대조의 의미를 더하고 있습니다. > 밥**은** 먹었어. > > 철수가 일을 빨리**는** 한다. > > 내가 준 책을 읽어**는** 봤니? > > 이 집은 깨끗**은** 하지만 너무 낡았다. 다음은 종결보조사가 쓰인 예시입니다. > 그걸 어디 쓰게**요**. > > 사고 싶다**마는** 돈이 없구나. > > 봄이 돌아왔네**그려**. > > 좋아 보이는구먼**그래**. 앞으로 통용보조사 몇 가지를 살펴보겠습니다.   ## 은/는 '은/는'은 대조(소극적 배제)를 나타내는 통용보조사입니다. 다른 것을 한편에 전제로 깔고 그쪽과 대조적으로 이야기를 한다는 의미를 나타냅니다. 화자는 가능한 자매 항목에 대해 중립적인 입장을 취합니다. > 이 꽃은 **그늘에서는** 잘 자란다. (양지, 숲, 늪지 등에 대해서는 모르겠음) > > (옷가게에서 옷을 고르다가) A: 이거 어때? B: **예쁘기는** 하다. (값이 적당한지, 내게 어울리는지 등에 대해서는 모르겠음) '은/는'은 문장의 주제를 표시해 줍니다. 주제는 한 문장에서 설명되는 내용의 대상이 되는 부분으로, 대체로 "~로 말할 것 같으면" 정도의 의미로 풀이됩니다. 주제에 관한 자세한 내용은 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/07/11/senttopic/)을 참고하시면 좋을 것 같습니다. > **진이는** 정말 착해. > > **그 책은** 나도 읽어 봤어. > > **어제는** 하루 종일 집에서 쉬었어. > > **진이는** 내가 벌써 저녁을 사 줬어. > > **향기는** 장미가 좋지.   ## 만 다른 것은 말고 유일하게 그것이 선택됨을 나타내는 보조사입니다. > 이 꽃은 **그늘에서만** 잘 자란다. (양지, 숲, 늪지 등에서는 잘 자라지 않는다)   ## 도 다른 것에 더해 그것이 포함됨을 나타내는 보조사입니다. > 이 꽃은 **그늘에서도** 잘 자란다. (양지, 숲, 늪지 등에서도 잘 자란다)   ## 조차 사태 성립 확률이 가장 높은 것이 선택되었음을 나타내는 보조사입니다. 주로 부정문에 사용되어, 사태의 성립 확률이 높은데도 성립되지 않음을 표시합니다. > 진이는 {덧셈, 뺄셈조차/?까지/?마저} 할 줄 모른다. 위 예문에서 '덧셈, 뺄셈'은 사람이라면 보통 누구나 할 수 있을 것으로 기대되는 행위로 쓰였습니다. 이런 맥락에서라면 '조차'가 가장 잘 어울립니다.   ## 마저 사태의 성립 확률이 가장 낮은 것이 선택되었음을 나타냅니다. 주로 긍정문에 사용되어 사태의 성립확률이 낮은데도 성립함을 표시합니다. 주로 그 결과가 화자에게 불리할 때 쓰입니다. > 브루투스, 너마저 나를 배신하다니! > > 그 깍쟁이가 내 ?선물마저 사 왔다.   ## 까지 사태의 성립 확률이 가장 낮은 것이 선택되었음을 나타냅니다. 주로 긍정문에 사용되어 사태의 성립확률이 낮은데도 성립함을 표시합니다. 그 결과가 화자에게 불리하지 않을 때도 쓰입니다. > 브루투스, 너까지 나를 배신하다니! > > 그 깍쟁이가 내 선물까지 사 왔다. 
prob␞ 이번 글에서는 확률론의 기본 개념들을 살펴보도록 하겠습니다. 이 글은 Ian Goodfellow 등이 집필한 Deep Learning Book과 김우철 등이 집필한 일반통계학, 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## Why Probability? 알고리즘은 결정적(deterministic)이고 확실한(certain) 요소들로 구성되지만, 머신러닝은 본질적으로 확률적(stochastic, nondeterministic)이고 불확실한(uncertain) 대상을 다룹니다. 머신러닝 분야에서 발생하는 불확실성에는 다음과 같이 세 종류가 있습니다. - 모델링하려는 시스템 자체에 내재한 불확실성(inherent stochasticity). 예컨대 양자역학에서는 원자의 움직임을 확률적으로 해석, 설명한다. 마찬가지로 머신러닝에서 카드 게임 모델을 만들 때, 카드가 무작위 순서로 섞여 있다고 가정하고 그 random dynamics를 따지게 된다. - 불완전한 관측(incomplete observability). 모델링하려는 시스템이 결정적이라 하더라도 모든 데이터를 관측할 수는 없다. 예컨대 몬티홀 문제에서 게임 참가자는 세 개 문(door) 가운데 하나를 고른다. 한 문 뒤에는 자동차가 있고 나머지 두 문 뒤에는 염소가 있다. 참가자의 선택이 주어졌을 때 결과(outcome)는 결정적이다(참가자 선택과 관계없이 자동차나 염소의 위치가 바뀌지는 않기 때문). 그러나 참가자 입장에서 보면, 결과는 불확실하다. - 불완전한 모델링(incomple modeling). 관측한 정보의 일부를 버려야(discard)하는 모델을 쓸 때, 손실된 정보는 모델 예측의 불확실성을 낳는다. 예컨대 모든 물체의 위치를 정확히 관측할 수 있는 로봇을 만든다고 가정하자. 로봇이 물체들의 미래 위치를 예측할 때 공간을 구분(discretize)하게 된다면, 이러한 구분 자체가 로봇의 위치 예측을 불확실하게 만든다. 각각의 물체는 구분된 셀(discrete cell)과 관계없이 어디에나 존재할 수 있기 때문이다.    ## 확률론 확률론(probability theory)은 사건의 빈도를 분석합니다. 포커 게임을 예로 들어보겠습니다. 이런 종류의 사건은 반복가능하다(repeatable)는 특징이 있습니다. 어떤 확률이 $p$라는 말은, 실험(카드 뽑기)을 무한히 반복하면 관심있는 사건이 나타나는 비율이 $p$라는 이야기입니다. 이 $p$는 사건이 일어날 비율과 직접적인 관련이 있다는 점에서 **frequentist probability**라 불립니다. 아예 다른 종류도 있습니다. 어떤 의사가 환자를 진찰하고 감기에 걸린 환자가 40%라는 결론을 내렸다고 칩시다. 이 경우는 포커게임과 달리 환자들을 무한히 관측할 수 없습니다. 감기와 증상이 유사해보이지만 환자가 걸린 병이 감기가 아닐 수도 있습니다. 이러한 경우 **믿음의 크기(degree of belief)**를 표현하기 위한 방안으로 확률을 씁니다. 다시 말해 환자가 정말 확실 하게 감기에 걸렸다고 판단되는 경우를 1, 그렇지 않다고 생각되는 경우를 0으로 둔다는 것이지요. 이는 확실성의 질적 수준(qualitative levels of certainty)과 관련이 있고 **베이지안 확률**이라 불립니다. 요컨대 확률을 빈도론으로 접근하는 쪽에서는 불확실성을 빈도로 정량화합니다. 반면 베이지안 관점에서는 확률 개념을 빈도가 아닌 믿음의 정도로 고려합니다. 한편 몇 가지 조건을 만족하면 frequentist probability와 베이지안 확률이 동일해 진다고 합니다. 예컨대 특정 조합의 카드를 갖고 있는 사람이 포커 게임에서 이길 확률을 계산하는 과정은 특정 증상이 나타나는 사람이 어떤 질병에 걸렸을 확률을 계산하는 것과 똑같습니다.   ## 확률변수 확률변수(random variable)란 다양한 값(value)을 랜덤(random)하게 가질 수 있는 변수(variable)입니다. 확률변수는 표본공간(sample space)에서 상태공간(state space)으로 보내는 함수(function)이며, 확률적인 과정에 따라 확률변수의 구체적인 값이 결정됩니다. 표본공간이란 어떤 시행(실험)에서 나타날 수 있는 모든 결과들의 모임을, 상태공간이란 해당 확률변수가 취할 수 있는 모든 실수들의 집합을 가리킵니다.  예컨대 동전을 1회 던지는 실험에서 표본공간은 {앞면, 뒷면}이 됩니다. 확률변수 $X$를 동전을 두 번 반복해서 던졌을 때 앞면이 나온 횟수로 정의할 경우 상태공간은 {0, 1, 2}가 됩니다.   ## 확률분포 확률분포(probability distribution)는 개별 확률변수나 확률변수의 집합에 대응하는 확률들의 집합을 가리킵니다. 확률분포는 상태(state)가 얼마나 많이 나타나는가를 나타냅니다.  ### 이산확률변수와 확률질량함수 이산확률변수(discrete random variable)란 상태공간이 유한집합이거나 셈할 수 있는 무한집합인 확률변수를 가리킵니다. 확률질량함수(probability mass function)란 확률변수의 한 상태를 그 상태가 나타날 확률로 대응시켜 주는 함수입니다. 만일 확률변수 $X$가 $x$라는 값일 가능성이 확실하다면 그 확률은 1이 될 겁니다. 해당 확률질량함수를 $P$라 할 때 다음과 같이 씁니다.  $$ P\left( X=x \right) =1 $$  여러 확률변수에 대한 확률분포를 결합확률분포(joint probability distribution)이라 합니다. $P(X=x, Y=y)$는 확률변수 $X$, $Y$가 각각 $x$, $y$일 확률을 의미합니다. $P(x,y)$라 적기도 합니다. 확률변수 $X$에 대한 확률질량함수 $P$는 다음과 같은 조건을 만족해야 합니다. - $P$의 정의역은 $X$의 모든 가능한 상태들로 이뤄진 집합이어야 한다. - $∀x∈X$, $0≤P(x)≤1$. 발생이 불가능한 사건은 그 확률이 0이고 이보다 작은 확률을 가진 상태(state)는 존재하지 않는다. 마찬가지로 발생이 보장돼 있는 사건은 그 확률이 1이고, 이보다 큰 확률을 가진 상태는 존재하지 않는다. - $∑_{x∈X}P(x)=1$. 이 성질을 두고 '정규화되었다(normalize)'고 표현한다. 이 속성을 만족하지 않을 경우, 많은 사건 가운데 하나가 발생할 확률이 1보다 클 수 있다. 균등분포(uniform distribution)를 예로 들어보겠습니다. 균등분포란 각 상태에 해당하는 확률이 동일한 확률분포를 가리킵니다. $k$개의 서로 다른 상태를 가질 수 있고 균등분포를 따르는 이산확률변수 $X$의 확률질량함수는 다음과 같습니다.  $$ P\left( X={ x }_{ i } \right) =\frac { 1 }{ k } $$    ## 베르누이분포 입시에서 합격과 불합격, 스포츠 경기에서 승리와 패배, 사업에서 성공과 실패, 수술 후 환자의 치유 여부 등 우리가 일상 생활에서 자주 접하는 일들은 두 가지의 가능한 결과만을 가질 때가 많습니다. 어떤 실험이 이와 같이 두 가지 가능한 결과만을 가질 경우 이를 베르누이시행(bernoulli trial)이라고 합니다.  일반적으로 베르누이시행에서 시행의 결과는 성공(s) 또는 실패(f)로 나타냅니다. 따라서 베르누이시행의 표본공간은 {성공, 실패}, 상태공간은 {0, 1}로 원소가 각각 두 개인 집합입니다. 성공을 1, 실패를 0으로 대응시키는 함수를 베르누이확률변수(bernoulli random variable)라 하고 이 확률변수의 확률분포를 베르누이분포라고 합니다. 베르누이분포는 다음 표와 같이 표현할 수 있습니다. |  $x$  |  0  | 1  | | :------: | :---: | :--: | | $P(X=x)$ | $1-p$ | $p$ | 좀 더 간단하게는 다음과 같이 표현할 수 있습니다.  $$ P\left( X=x \right) ={ p }^{ x }{ \left( 1-p \right) }^{ x } $$  베르누이분포의 기대값과 분산은 다음과 같습니다.  $$ E\left( X \right) =p\\ Var\left( X \right) =p(1-p) $$  ## 다항분포 다항분포(multinomial distribution)란 $k$개의 서로 다른 상태를 가질 수 있는 하나의 이산확률변수에 대한 확률분포를 가리킵니다. 어떤 시행에서 $k$가지의 값이 나타날 수 있고 그 값이 나타날 확률을 각각 $p_1$, $p_2$, ..., $p_k$라 할 때 $n$번의 시행에서 $i$번째의 값이 $x_i$회 나타날 확률은 다음과 같습니다.  $$ P\left( { x }_{ 1 },,...,{ x }_{ k },{ p }_{ 1 },...,{ p }_{ k },n \right) =\frac { n! }{ { x }_{ 1 }!{ x }_{ 2 }!...{ x }_{ k }! } { p }_{ 1 }^{ { x }_{ 1 } }{ p }_{ 2 }^{ { x }_{ 2 } }...{ p }_{ k }^{ { x }_{ k } } $$  시행을 $n$번 했으므로 $x_1+...+x_k=n$이 되어야 합니다. 그렇지 않은 경우의 확률값은 0으로 정의됩니다.  경우에 따라 다항분포는 값이 나타나는 횟수가 아니라 독립시행에서 나타난 값 자체를 가리키기도 합니다. 엄밀하게는 이러한 분포를 categorical distribution이라 합니다. 예컨대 $k$개 범주를 분류하는 뉴럴네트워크를 만들 때 마지막 층의 출력결과물은 $k$차원의 확률벡터가 될 텐데, 이 벡터의 각 요소값들은 해당 인스턴스가 각각의 범주일 확률을 나타낸다고 볼 수 있겠습니다.  어떤 시행에서 $k$개의 서로 다른 범주가 있고 그 범주가 나타날 확률을 각각 $p_1$, $p_2$, ..., $p_k$라 할 때 1회 시행에서 $i$번째 범주 $c_i$가 나타날 확률은 다음과 같습니다.  $$ P\left( { c }_{ i };{ p }_{ 1 },...,{ p }_{ k } \right) ={ p }_{ i } $$  머신러닝에서 다항분포는 대상이 가질 수 있는 범주(상태)에 대한 확률분포로 쓰입니다. 하지만 각 상태는 숫자로서의 의미는 없습니다. 1번 상태(범주 1)를 숫자 1로 보지 않는다는 겁니다. 이런 이유로 머신러닝에서는 다항분포를 따르는 확률변수의 기대값이나 분산을 대개 계산하지 않습니다.   ## 정규분포 정규분포는 가우스(Gauss, 1777-1855)에 의해 제시된 분포로서 일명 가우스분포(Gauss Distribution)라고 불리며 물리학 실험 등에서 오차에 대한 확률분포를 연구하는 과정에서 발견되었다고 합니다. 가우스 이후 이 분포는 여러 학문 분야에서 이용되었으며, 초기의 통계학자들은 모든 자료의 히스토그램이 정규분포의 형태와 유사하지 않으면 비정상적인 자료라고까지 생각하였다고 합니다. 이러한 이유로 이 분포에 '정규(normal)'라는 이름이 붙게 된 것입니다. 정규분포는 특성값이 연속적인 무한모집단 분포의 일종으로서 평균이 $μ$이고 표준편차가 $σ$인 경우 정규분포의 확률밀도함수(Probability Density Function)는 다음과 같습니다.  $$ N(x;\mu ,{\sigma}^2 )=\frac { 1 }{ \sqrt { 2\pi } \sigma } exp\left( -\frac { { (x-\mu ) }^{ 2 } }{ 2{ \sigma }^{ 2 } } \right) $$  평균이 0이고 분산이 1인 표준정규분포의 밀도곡선은 다음과 같습니다. 평균에 대해 좌우 대칭이고 변곡점과 대칭점 사이의 거리가 표준편차(=1)가 됩니다.  <a href="https://imgur.com/U0fvLnN"><img src="https://i.imgur.com/U0fvLnN.png" width="500px" title="source: imgur.com" /></a>   데이터 분포에 대한 사전지식이 전혀 없을 때 정규분포를 가정하는 것은 다음 두 가지 이유로 꽤 합리적인 선택입니다. 첫째 중심극한정리(central limit theorem) 덕분입니다. 중심극한정리란 동일한 확률분포를 따르는 $n$개의 독립 확률변수의 평균의 분포는 $n$(대개 30 이상)이 충분히 클 때 정규분포에 가까워진다는 정리입니다. 다시 말해 데이터의 분포가 어떤 형태이든 상관없이 30건 이상의 데이터만 있으면 이들 표본의 평균은 근사적으로 정규분포를 따른다는 사실입니다.  둘째 동일한 분산을 가진 모든 확률분포 가운데 정규분포는 최대 불확실성(uncertainty)을 내포하는 좋은 성질을 가지고 있다고 합니다. 정보이론(information theory)에서 엔트로피(entropy)는 어떤 확률변수의 불확실성을 가리킵니다. 엔트로피를 최대로 만드는 확률함수를 유도하면 정규분포 식이 도출된다고 합니다. 따라서 정규분포를 가정할 경우 모델을 만들 때 사전 지식(prior knowledge)을 최대한 배제한다는 의미 또한 지니게 된다는 것입니다. 정규분포가 최대 불확실성을 내포한다는 것과 관련 자세한 내용은 [이곳](http://blog.acronym.co.kr/433)을 참고하시면 좋을 것 같습니다. 중심극한정리를 이항분포(Binomial distribution)과 관련지어 이야기해보겠습니다. 성공확률이 $p$인 베르누이시행을 $n$번 반복시행할 때 성공횟수 $X$의 분포를 이항분포라고 합니다. 이때 이항분포의 평균과 분산은 각각 $np$, $np(1-p)$가 되는데요. 중심극한정리는 $n$이 적당히 크다면 $X$는 원래 정규분포를 따르지 않지만 표본의 분포가 평균이 $np$이고 분산이 $np(1-p)$인 정규분포와 유사해진다는 점을 알려줍니다.  아래 그림은 성공확률이 0.5인 베르누이시행을 100번 반복시행했을 때 성공횟수의 분포를 히스토그램으로 그린 것입니다. 실선은 평균이 50, 분산이 25인 정규분포를 그린 것입니다. 두 모양이 비슷한 것을 알 수 있습니다.  <a href="http://imgur.com/kstUqBK"><img src="http://i.imgur.com/kstUqBK.png" width="400px" title="source: imgur.com" /></a>   ## 지수분포 딥러닝 모델을 만들 때 $x=0$인 지점에서 첨점(sharp point)를 갖는 확률분포가 필요할 수 있습니다. 이를 위해 지수분포를 씁니다. $1_{x≥0}$은 벡터 $x$의 요소 가운데 음수값에 대응하는 확률을 모두 0으로 만들어주는 indicatior function입니다. 지수함수의 식과 그래프는 다음과 같습니다.  $$ p\left( x;\lambda \right) =\lambda { 1 }_{ x\ge 0 }exp\left( -\lambda x \right) $$  <a href="https://imgur.com/OcGLurk"><img src="https://i.imgur.com/OcGLurk.png" width="400px" title="source: imgur.com" /></a>  라플라스분포는 $μ$인 지점에서 첨점을 갖는 확률분포입니다. $γ$는 분포의 모양을 정하는 파라메터입니다. 식과 그래프는 다음과 같습니다.  $$ p\left( x;\mu ,\gamma \right) =\frac { 1 }{ 2\gamma } exp\left( -\frac { \left| x-\mu \right| }{ \gamma } \right) $$  <a href="https://imgur.com/DdOJLl0"><img src="https://i.imgur.com/DdOJLl0.png" width="400px" title="source: imgur.com" /></a>   ## 시그모이드함수 시그모이드함수의 식은 다음과 같습니다.  $$ \sigma \left( x \right) =\frac { 1 }{ 1+exp(-x) } $$  시그모이드함수는 함수값의 범위가 $[0,1]$이기 때문에 베르누이분포의 파라메터(성공확률) $p$를 만드는 데 주로 사용됩니다. 하지만 $x$가 매우 크거나 작을 경우 그래디언트가 0에 가까워지기 때문에 딥러닝 역전파가 잘 안되어 학습속도가 느려지거나 불가능해진다는 단점이 있습니다. 이와 관련해서는 [이곳](https://datascience.stackexchange.com/questions/16911/how-does-sigmoid-saturate-with-large-weights)을 참고하시면 좋을 것 같습니다. 
manning␞ 미국 스탠포드대학의 [Stanford NLP group](https://nlp.stanford.edu/)은 자연어처리 분야에서 손꼽히는 연구실입니다. Chistopher Manning 교수는 1999년 스탠포드에 부임한 이래 stanford NLP group을 이끌면서 많은 업적을 쌓아 왔습니다. 특히 [Foundations of Statistical NLP(1999)](https://nlp.stanford.edu/fsnlp/promo/), [Introduction to Information Retrieval(2008)](http://informationretrieval.org/) 등이 유명합니다. 최근 공부하시는 분들은 [CS224n](http://web.stanford.edu/class/cs224n/) 강의가 익숙할텐데요. 강의자인 Richard Socher 또한 그가 가르친 [20명의 박사](https://nlp.stanford.edu/manning/dissertations/) 가운데 열네번째 제자입니다.  그런 그가 지난 10월 20일 서울 우면동 삼성전자R&D캠퍼스에서 열린 '삼성AI포럼2017'에 참석해 강연을 했습니다. 실제로 이날 행사장엔 청중 1000여 명이 몰려 그의 영향력을 실감할 수 있었습니다. ~~조금 늦게 도착한 저는 통로 사이 바닥에 앉아 강의를 들었...~~ <a href="https://imgur.com/is6JPhi"><img src="https://i.imgur.com/is6JPhi.jpg" width="600px" title="source: imgur.com" /></a> 이 글은 이날 Manning이 한 강연을 제가 이해하는 수준에서 정리한 것입니다. 이 글에 쓰인 그림은 기본적으로 Manning의 발표 원고에서 따 왔으며, 이외의 그림은 출처를 별도로 표기하였습니다. 본 블로그에 강연 내용과 관련된 글이 있다면 해당 단어에 링크로 연결해 두었습니다. 그의 육성 강연을 들을 수 있는 기회를 주신 삼성 관계자 여러분들께 진심으로 감사드립니다. 그럼 시작하겠습니다.   ## BiLSTM Hegemony 이날 Manning 강연의 핵심은 다음과 같습니다. task가 무엇이든지 간에 어텐션(attention)이 적용된 BiLSTM 모델이 최고 성능을 낸다는 이야기입니다.  > The de facto consensus in NLP in 2017 is that no matter what the task, you throw a **BiLSTM** at it, with **attention** if you need information flow, and you get great perfomance! 실제로 이날 Manning이 소개한 stanford NLP group의 최신/최고 연구성과가 모두 BiLSTM이 적용된 모델이었습니다. 그가 언급했던 것처럼 가히 'BiLSTM Hegemony'라 할 만 합니다. 그렇다면 BiLSTM과 attention이 대체 뭐길래, 수십년동안 NLP를 연구해온 그가 침이 마르도록 칭찬하는 것일까요? 차례대로 살펴보겠습니다.   ## BiLSTM with attention vanilla RNN 구조는 다음과 같습니다. [gradient vanishing/exploding 문제](https://ratsgo.github.io/deep%20learning/2017/10/10/RNNsty/)에 취약합니다. 아래 그림(출처 : [Oxford Deep NLP 2017](https://github.com/oxford-cs-deepnlp-2017/lectures))에서 $h_1$의 그래디언트를 구하려면 체인룰에 의해 빨간색 선에 해당하는 그래디언트를 계속 곱해주어야 하기 때문입니다. <a href="https://imgur.com/Q4Un12X"><img src="https://i.imgur.com/Q4Un12X.png" width="500px" title="source: imgur.com" /></a>  [LSTM(Long Short Term Memory)](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)은 cell state를 도입해 그래디언트 문제를 해결하고자 합니다. Manning은 Hochreiter&Schmidhuber(1999), Cho et al.(2014)가 제안한 셀을 LSTM이라고 명명하고, 이날 강연에서 "LSTM는 직전 시점 정보와 현 시점 정보를 더해줌으로써 그래디언트가 효과적으로 흐를 수 있게 한다"고 강조했습니다.  <a href="https://imgur.com/0h3kgMY"><img src="https://i.imgur.com/0h3kgMY.png" width="600px" title="source: imgur.com" /></a>  [vanilla Seq2Seq 모델](https://ratsgo.github.io/natural%20language%20processing/2017/03/12/s2s/)은 다음과 같습니다. 소스 문장을 벡터화하는 인코더(encoder)와 인코딩된 벡터를 타겟 문장으로 변환하는 디코더(decoder) 둘로 구성돼 있습니다. 이 때 인코더, 디코더는 LSTM 셀을 씁니다.   <a href="https://imgur.com/lcGUt9N"><img src="https://i.imgur.com/lcGUt9N.png" width="600px" title="source: imgur.com" /></a>  하지만 문장 길이가 길고 층이 깊으면, 인코더가 압축해야할 정보가 너무 많아서 정보 손실이 일어나고, 디코더는 인코더가 압축한 정보를 초반 예측에만 사용하는 경향을 보입니다. Manning은 "이 때문에 인코더-디코더 사이에 'bottle-neck 문제'가 발생한다"고 언급했습니다. 이에 디코더 예측시 가장 의미 있는 인코더 입력에 주목하게 만드는 [어텐션(attention)](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/10/06/attention/) 매커니즘이 제안됐습니다. 아울러 앞에서 뒤, 뒤에서 앞, 모두 고려하는 양방향(bidirectional) 네트워크 또한 성능 개선에 도움이 된다고 합니다. 아래 그림은 LSTM 셀을 쓰고, 인코더에 양방향 네트워크, 디코더 예측시 어텐션 매커니즘이 적용된 'BiLSTM with attention'을 개념적으로 나타냈습니다.  <a href="https://imgur.com/jO4oAb6"><img src="https://i.imgur.com/jO4oAb6.png" width="600px" title="source: imgur.com" /></a>  BiLSTM with attention은 특히 기계번역에서 좋은 성능을 내 주목을 받았습니다. Manning은 이날 강연에서 그 비결 네 가지를 다음과 같이 설명했습니다. - **종단간(End-to-end) 학습** : 출력값(output)에 대한 손실을 최소화하는 과정에서 모든 파라메터들이 동시에 학습된다. - **[분산표상(distributed representation)](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/29/NNLM/) 사용** : 단어와 구(phrase) 간 유사성을 입력벡터에 내재화해 성능을 개선했다. - **개선된 문맥 탐색(exploitation)** : LSTM, 어텐션 등 덕분에 문장 길이가 길어져도 성능 저하를 막는다. - **자연스런 문장생성 능력** : 다범주 분류에 좋은 성능을 내는 딥러닝 기법을 써서 문장 생성 능력이 큰 폭으로 개선됐다.   ## 연구성과 소개 Manning은 이날 강연에서 Stanford NLP group의 최신 연구성과 몇 가지를 소개했는데요. 이미 언급했던 것처럼 모두 BiLSTM(with attention)이 적용된 모델들입니다.  ### Stanford Attentive Reader [Chen et al.(2016)](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwigx7_p8IHXAhVKFZQKHTuNAv4QFgglMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1606.02858&usg=AOvVaw3fe-2TSwtVJnI5nuPglYdq)은 문맥에서 질의에 대한 응답을 찾는 모델을 구축하는 데 BiLSTM with attention을 적용했습니다. 분석 대상 텍스트 단락(passage)과 질의(question)를 각기 다른 양방향 인코더에 넣어 $p$와 $q$ 벡터를 만듭니다. 단락의 $i$번째 단어에 대한 어텐션 스코어 $α_i$는 $softmax(q^TWp_i)$입니다. 디코더의 output vector $o$는 $Σ_iα_ip_i$입니다. 이를 정답 답변과 비교해 손실을 구하고 역전파 학습이 이뤄지는 구조입니다. 그 개념도는 다음과 같습니다.  <a href="https://imgur.com/5bkWQZf"><img src="https://i.imgur.com/5bkWQZf.png" title="source: imgur.com" /></a>  [Chen et al.(2017)](https://arxiv.org/abs/1704.00051)은 위 연구를 기본으로 하되 위키피디아에서 관련된 단락을 뽑아내는 과정 등이 추가된 형태입니다. 전체적인 프레임워크는 다음과 같습니다.  <a href="https://imgur.com/XayiCqv"><img src="https://i.imgur.com/XayiCqv.png" title="source: imgur.com" /></a>   ### Copy augmented S2S [Eric&Manning(2017)](https://arxiv.org/abs/1701.04024)은 어텐션 스코어가 높은 인코더 입력 단어를 디코더 입력에 복사해 넣어, 이 디코더 입력을 학습시키는 기법을 제안했습니다. 아래 그림을 보겠습니다.  <a href="https://imgur.com/tPDG9hF"><img src="https://i.imgur.com/tPDG9hF.png" width="500px" title="source: imgur.com" /></a>  Eric&Manning(2017)에서는 인코더가 질의, 디코더가 응답을 처리합니다. 정답 응답은 'Buca di Beppo is an restaurant that is'인데, 디코더가 6번째 단어 restaurant를 예측해야 할 때 어텐션 스코어가 가장 높은 인코더 입력 단어는 'Italian'이었다고 가정해 보겠습니다. 그러면 이 모델은 해당 위치에 인코더 입력 단어를 복사하는 방식입니다.   ### tree based models [Tai et al.(2015)](https://arxiv.org/abs/1503.00075)는 트리 구조의 LSTM 아키텍처를 제안했습니다. 아래 그림에서 상단에 있는 모델이 기존의 LSTM 네트워크, 하단이 Tai et al.(2015)가 제안한 모델입니다. <a href="https://imgur.com/usFeUgE"><img src="https://i.imgur.com/usFeUgE.png" width="300px" title="source: imgur.com" /></a> [Dozat&Manning(2017)](https://arxiv.org/abs/1611.01734)은 의존관계 분석(dependency parsing)에 BiLSTM with attention을 적용한 연구입니다. <a href="https://imgur.com/mfPsd8g"><img src="https://i.imgur.com/mfPsd8g.png" title="source: imgur.com" /></a>
LAsummary␞ 최근 선형대수학 중간고사를 보게 됐는데 제 개인적 정리 용도로 업로드하는 글입니다.  <a href="http://imgur.com/mRWTYGn"><img src="http://i.imgur.com/mRWTYGnh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/9nJGUf8"><img src="http://i.imgur.com/9nJGUf8h.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/iVdZNyk"><img src="http://i.imgur.com/iVdZNykh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/xXwcds5"><img src="http://i.imgur.com/xXwcds5h.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/fElGh6g"><img src="http://i.imgur.com/fElGh6gh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/vDcKAk1"><img src="http://i.imgur.com/vDcKAk1h.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/EMGyFbJ"><img src="http://i.imgur.com/EMGyFbJh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/ZMnPZmX"><img src="http://i.imgur.com/ZMnPZmXh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/XwjSFbv"><img src="http://i.imgur.com/XwjSFbvh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/TuoZIrg"><img src="http://i.imgur.com/TuoZIrgh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/BQwUVCn"><img src="http://i.imgur.com/BQwUVCnh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/1ol1LHZ"><img src="http://i.imgur.com/1ol1LHZh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/gJvdCFw"><img src="http://i.imgur.com/gJvdCFwh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/UlszKaC"><img src="http://i.imgur.com/UlszKaCh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/4HdGQsk"><img src="http://i.imgur.com/4HdGQskh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/i2qLMTm"><img src="http://i.imgur.com/i2qLMTmh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/8RadRqw"><img src="http://i.imgur.com/8RadRqwh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/UNidKeK"><img src="http://i.imgur.com/UNidKeKh.jpg" title="source: imgur.com" /></a> <a href="http://imgur.com/wsjp0J0"><img src="http://i.imgur.com/wsjp0J0h.jpg" title="source: imgur.com" /></a> 
bayes␞ 이번 글에서는 베이즈 규칙을 활용해 풀 수 있는 여러 문제를 살펴보도록 하겠습니다. 이 글은 고려대 김성범 교수님 강의와 'Think Bayes(앨런 B. 다우니 지음, 권정민 옮김, 한빛미디어 펴냄)'를 정리했음을 먼저 밝힙니다. 베이지안 추론과 관련해서는 [이곳](https://ratsgo.github.io/statistics/2017/06/30/bayesinfer/)과 [이 글](https://ratsgo.github.io/statistics/2017/07/05/bayes2/), 문서 분류를 위한 나이브 베이지안 분류기와 관련해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/18/naive/)을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.   ## 베이즈 규칙 일반적으로 사건 $A_1$, $A_2$, $A_3$가 서로 배반(mutually exclusive)이고 $A_1$, $A_2$, $A_3$의 합집합이 표본공간(sample space)과 같으면 사건 $A_1$, $A_2$, $A_3$는 표본공간 $S$의 **분할**이라고 정의합니다. 우리가 관심있는 사건 $B$가 나타날 확률을 그림과 식으로 나타내면 다음과 같습니다. <a href="http://imgur.com/jC7FfHv"><img src="http://i.imgur.com/jC7FfHv.png" width="400px" title="source: imgur.com" /></a> $$P(B)=P({ A }_{ 1 }\cap B)+P({ A }_{ 2 }\cap B)+P({ A }_{ 3 }\cap B)$$  $P(B)$를 조건부확률의 정의를 이용해 다시 쓰면 아래와 같습니다. 이를 **전확률 공식(Law of Total Probability)** 또는 베이즈 법칙이라고 합니다. $$P(B)=P({ A }_{ 1 })P(B|{ A }_{ 1 })+P({ A }_{ 2 })P(B|{ A }_{ 2 })+P({ A }_{ 3 })P(B|{ A }_{ 3 })=\sum _{ i=1 }^{ 3 }{ P({ A }_{ i })P(B|{ A }_{ i }) } $$ 보통 $P(A_1)$, $P(A_2)$, $P(A_3)$는 미리 알고 있다는 의미의 **사전확률(prior probability)**로 불립니다. $P(B$\|$A1)$, $P(B$\|$A2)$, $P(B$\|$A3)$는 **우도(likelihood probability)**라 부릅니다. 그럼 우리가 관심있는 사건인 $B$가 $A_1$에 기인했을 조건부확률은 어떻게 구할까요? 바로 아래와 같이 구할 수 있습니다.  $$ \begin{align*} P({ A }_{ 1 }|B)&=\frac { P({ A }_{ 1 })P(B|{ A }_{ 1 }) }{ P(B) } \\ &=\frac { P({ A }_{ 1 })P(B|{ A }_{ 1 }) }{ P({ A }_{ 1 })P(B|{ A }_{ 1 })+P({ A }_{ 2 })P(B|{ A }_{ 2 })+P({ A }_{ 3 })P(B|{ A }_{ 3 }) } \end{align*} $$  $P(A1$\|$B)$는 사건 B를 관측한 후에 그 원인이 되는 사건 $A$의 확률을 따졌다는 의미의 **사후확률(posterior probability)**로 정의됩니다. 사후확률은 사건 $B$의 정보가 더해진, 사전확률의 업데이트 버전 정도라고 생각하면 좋을 것 같습니다. *(Posterior probability is an updated version of prior probability)* 같은 방식으로 $P(A2$\|$B)$, $P(A3$\|$B)$도 구할 수 있습니다.  한번 예를 들어보겠습니다. 어떤 이름모를 질병에 걸린 환자가 전체 인구의 약 1% 정도 되는 것으로 알려져 있다고 칩시다. 그렇다면 전체 인구라는 표본공간에서 질병에 걸릴 확률 **P(D)**는 0.01, 그렇지 않을 확률 **P(~D)**는 0.99입니다. 이것이 바로 우리가 이미 알고 있는 사전확률이 되겠네요.  질병 발생 여부를 측정해주는 테스트의 정확도는 이렇다고 합니다. 진짜 환자를 양성이라고 정확하게 진단할 확률 **P(+\|D)**은 97%, 정상환자를 양성이라고 오진할 확률 **P(+\|~D)**은 6%입니다. 이것이 바로 우도입니다. 그럼 진단테스트 결과 양성이라고 나왔는데 실제 환자일 확률 **P(D\|+)**는 얼마일까요? 이건 우리가 이미 알고 있는 정보를 활용해 아래와 같이 구할 수 있습니다. 이것이 바로 사후확률입니다. 즉 '진단'이라는 사건의 정보를 더해 '질병에 걸릴 확률'이라는 사전확률을 업데이트한거죠.  $$ \begin{align*} P(+)&=P(D\cap +)+P(\sim D\cap +)\\ &=P(D)P(+|D)+P(\sim D)P(+|\sim D)\\ &=0.01\times 0.97+0.99\times 0.06\\ &=0.691\\ P(D|+)&=\frac { P(D)P(+|D) }{ P(+) } \\ &=\frac { 0.01\times 0.97 }{ 0.691 } \\ &=0.014 \end{align*} $$  그런데 왜 이렇게 복잡하게 사후확률을 구하는거냐고요? 실제로 사후확률은 구하기 어려운 경우가 많다고 합니다. 그에 반해 사전확률은 우리가 이미 알고 있는 값이고, 우도는 비교적 계산하기 수월합니다. 그래서 전확률법칙과 사전확률과 우도를 활용해 사후확률을 도출해내는 것이죠.  다시 말해 우리가 알고 싶은 확률을 단박에 계산하기가 까다로울 때 조건과 결과를 뒤집어서 우회적으로 계산하는 것, 이것이 베이즈 모델의 강점이라고 말할 수 있겠습니다.  ## 쿠키 문제 쿠키가 들어 있는 그릇 두 개가 있다고 가정해보겠습니다. 첫번째 그릇에는 바닐라 쿠키 30개와 초콜렛 쿠키 10개가 들어있고, 두번째 그릇에는 두 가지 쿠키가 종류별로 20개씩 들어 있습니다.  어떤 그릇인지 보지 않고 한 그릇에서 임의로 쿠키를 집었는데 바닐라 쿠키였다고 칩시다. 그렇다면 이 때 '이 바닐라 쿠키가 그릇 1에서 나왔을 가능성'은 얼마일까요? 사실 이 확률을 계산하기는 쉽지 않습니다.  그런데 '그릇1에서 바닐라 쿠키가 나올 확률'은 30/40으로 구하기 쉽습니다. 베이즈 규칙을 활용해 조건절과 결과절을 바꾸어 원하는 확률을 구해보겠습니다. 저 아래 표의 첫번째 열을 기준으로 계산한 식과 용어 설명은 다음과 같습니다.  $$ P(H|D)=\frac { P(H)P(D|H) }{ P(D) } =\frac { \frac { 1 }{ 2 } \times \frac { 3 }{ 4 } }{ \frac { 5 }{ 8 } } =\frac { 3 }{ 5 } $$ > $P(H)$ : 어떤 쿠키를 골랐던지 상관없이 그릇1을 골랐을 확률. 문제에서는 그릇을 임의로 선택한 것이므로 0.5라고 가정할 수 있습니다. 이를 데이터를 보기 전의 가설의 확률, 즉 **사전확률**입니다. > > $P(D$\|$H)$ : 그릇1에서 바닐라 쿠키가 나올 확률. 3/4입니다. 이를 데이터가 가설에 포함될 확률, 즉 **우도**입니다. > > $P(D)$ : 바닐라 쿠키를 고를 확률입니다. 각 그릇을 고를 확률이 동일하고 그릇에 동일한 쿠키가 들어있으므로 어떤 그릇을 택하든 바닐라 쿠키를 고를 확률도 같습니다. 두 그릇에 50개 바닐라 쿠키와 30개의 초콜렛 쿠키가 들어있으므로 $P(V)$는 5/8이 됩니다. 이를 어떤 가설에든 포함되는 데이터의 비율, 즉 **한정상수**입니다. > > $P(H$\|$D)$ : 바닐라 쿠키가 그릇1에서 나왔을 확률. 우리가 알고 싶은 확률입니다. 이를 데이터를 확인한 이후의 가설 확률, 즉 **사후확률**입니다. 이는 베이즈 이론을 **통시적(diachronic)**으로 해석한 것으로 가설에 대한 확률이 시간에 따라 새로운 데이터를 접하게 되면서 달라진다, 다시 말해 데이터 $D$의 관점에서 봤을 때 가설 $H$의 확률을 업데이트해 준다는 방식으로 이해하는 것입니다. 여기에서 한정상수 $P(D)$는 다음과 같은 두 가지 조건을 만족할 경우 어떤 가설이든지 같은 값을 지니게 돼 계산을 생략할 수 있습니다.  > **상호배제(mutually exclusive)** : 집합 중 하나의 가설만 참이다 > > **전체포괄(collectively exhaustive)** : 고려 대상 가설 이외에 다른 가설이 전혀 없는 경우 쿠키 문제를 가설별로 표로 나타내면 다음과 같습니다. |    항목    | 가설1(그릇1) | 가설2(그릇2) | | :--------------: | :------: | :------: | |  사전확률 $P(H)$  |  1/2  |  1/2  | | 우도 $P(D$\|$H)$ |  3/4  |  1/2  | |  사전확률 × 우도   |  3/8  |  1/4  | |  한정상수 $P(D)$  |  5/8  |  5/8  | | 사후확률 $P(H$\|$D)$ |  3/5  |  2/5  | 위 표에서 한정상수 $P(D)$ 계산을 생략할 수 있는 이유에 대해 살펴보겠습니다. 사후확률은 사전확률에 우도를 곱한 뒤 한정상수를 나누어 구합니다. 그런데 한정상수가 가설에 상관없이 같은 값을 가진다면 사전확률에 우도를 곱한 걸 모두 더한 값이 1이 되도록 정규화하면 한정상수 계산을 생략해도 동일한 결과가 나옵니다. 위 표에서 사전확률에 우도를 곱한 값은 그릇1이 3/8, 그릇2가 1/4입니다. 이를 모두 더하면 5/8이 되는데요. 이 값이 1이 되도록 정규화를 하려면 그릇1과 그릇2가 가진 값에 8/5를 각각 곱해주면 됩니다. 그런데 이 값은 정확히 사후확률과 일치합니다. 한정상수가 가설에 관계없이 동일하다면 계산을 생략해도 관계 없다는 이야기입니다. 쿠키문제를 파이썬 코드로 풀어보겠습니다.  ```python import thinkbayes as tb class Cookie(tb.Pmf):   """A map from string bowl ID to probablity.""" 	   # 사전확률 정의   def __init__(self, hypos):     """Initialize self.     hypos: sequence of string bowl IDs     """     tb.Pmf.__init__(self)     for hypo in hypos:       # 가설마다 동일한 사전확률(1) 부여       self.Set(hypo, 1)     # 총합이 1이 되도록(확률이 되도록) 정규화     # 가설이 두 개이므로 정규화 결과 가설마다 0.5 사전확률 가짐     self.Normalize()   # 사후확률 구하기   def Update(self, data):     """Updates the PMF with new data.     data: string cookie type     """     for hypo in self.Values():       # 우도 구하기       like = self.Likelihood(data, hypo)       # 사전확률에 우도 업데이트(곱)       self.Mult(hypo, like)     # 사전확률 x 우도 모든 값의 합이 1이 되도록 정규화     # 한정상수가 동일하므로 사후확률 계산에서 생략     self.Normalize()   mixes = {     'Bowl 1':dict(vanilla=0.75, chocolate=0.25),     'Bowl 2':dict(vanilla=0.5, chocolate=0.5),     }   # 우도 함수   def Likelihood(self, data, hypo):     """The likelihood of the data under the hypothesis.     data: string cookie type     hypo: string bowl ID     """     # mixes 데이터 자체가 우도를 나타내고 있으므로     # 그냥 불러오기만 하면 우도함수 정의 끝     mix = self.mixes[hypo]     like = mix[data]     return like # 가설정의 (가설1=그릇1, 가설2=그릇2) hypos = ['Bowl 1', 'Bowl 2'] # 가설에 따른 객체 선언 pmf = Cookie(hypos) # 사후확률 구하기 # 사전확률에 우도 업데이트 + 정규화 pmf.Update('vanilla') # 결과 출력 for hypo, prob in pmf.Items():   print hypo, prob ```   ## M&M 문제 여러 색의 설탕이 입혀진 작은 초콜렛 M&M은 만드는 회사는 시간에 따라 색 조합을 바꿔 왔습니다. 이 회사는 1995년에 파란색을 추가했는데요. 그 전에는 봉지 내 색 조합이 갈색 30%, 노랑 20%, 빨강 20%, 녹색 10%, 주황 10%, 황갈색 10%였습니다. 파란색을 추가한 뒤에는 파랑 24%, 녹색 20%, 주황 16%, 노랑 14%, 빨강 13%, 갈색 13%가 됐습니다. 한 친구가 M&M을 두 봉지 샀는데 각각 생산년도가 1994년, 1996년이라고 칩시다. 생산년도를 알려주지 않고 각 봉지에서 M&M을 하나씩 꺼냈을 때 한 알은 노란색이고 한 알은 녹색이었습니다. 문제입니다. 이 때 노랑 초콜렛이 1994년에 생산한 봉지에서 나왔을 확률은 얼마일까요? 먼저 가설을 만들어보겠습니다. 노란 초콜렛은 봉지1에서 녹색 초콜렛은 봉지2에서 꺼냈다고 칩시다. 이 때 가설은 다음과 같습니다. > **가설1** : 봉지1은 1994년에 생산했고 봉지2는 1996년에 생산했다. > > **가설2** : 봉지1은 1996년에 생산했고 봉지2는 1994년에 생산했다. 이를 쿠키문제와 마찬가지로 표로 만들면 다음과 같습니다. 쿠키문제와 마찬가지로 한정상수가 같은 값이기 때문에 계산을 생략할 수 있습니다. |    항목    |  가설1  |  가설2  | | :--------------: | :-----: | :------: | |  사전확률 $P(H)$  |  1/2  |  1/2  | | 우도 $P(D$\|$H)$ | 0.2×0.2 | 0.14×0.1 | |  사전확률 × 우도   | 0.02  | 0.007  | | 사후확률 $P(H$\|$D)$ | 20/27 |  7/27  |  M&M 문제의 파이썬 풀이는 다음과 같습니다. Think Bayes 저자는 베이즈 규칙을 언제든 사용할 수 있도록 Suite 객체로 캡슐화하였습니다. 쿠키문제의 풀이와 본질적으로 다르지 않다는 얘기입니다. 어쨌든 Suite 객체로 베이즈 문제를 풀 때는 데이터의 우도 값과 우도 함수만 정의해 주면 됩니다. ```python from thinkbayes import Suite  class M_and_M(Suite):   """Map from hypothesis (A or B)   to probability.""" 	   # 1994년 데이터   mix94 = dict(brown=30,         yellow=20,         red=20,         green=10,         orange=10,         tan=10) 	   # 1996년 데이터   mix96 = dict(blue=24,         green=20,         orange=16,         yellow=14,         red=13,         brown=13) 	   # 가설 정의   hypoA = dict(bag1=mix94, bag2=mix96)   hypoB = dict(bag1=mix96, bag2=mix94)   hypotheses = dict(A=hypoA, B=hypoB) 	   # 우도함수 정의   def Likelihood(self, data, hypo):     """Computes the likelihood of the data     under the hypothesis.     hypo: string hypothesis (A or B)     data: tuple of string bag, string color     """     bag, color = data     # 데이터가 우도이므로 참조하기만 하면 됨     mix = self.hypotheses[hypo][bag]     like = mix[color]     return like # 가설과 객체 선언 suite = M_and_M('AB') # 사전확률에 데이터를 반영해 사후확률 계산 suite.Update(('bag1', 'yellow')) suite.Update(('bag2', 'green')) # 결과 출력 suite.Print() ```   ## 주사위 문제 4면체, 6면체, 8면체, 12면체, 20면체 주사위가 든 상자가 있다고 가정해 봅시다. 상자에서 임의로 주사위 하나를 집어서 던졌더니 12가 나왔습니다. 그러면 각 주사위를 선택했을 확률은 어떻게 될까요? 여기에서 사전확률은 주사위를 선택할 확률, 우도는 해당 주사위를 던졌을 때 12가 나올 확률입니다. 이를 표로 나타내면 다음과 같습니다. |    항목    | 4면체 | 6면체 | 8면체 | 12면체 | 20면체 | | :--------------: | :--: | :--: | :--: | :--: | :---: | |  사전확률 $P(H)$  | 1/5 | 1/5 | 1/5 | 1/5 | 1/5 | | 우도 $P(D$\|$H)$ | 0  | 0  | 0  | 1/12 | 1/20 | |  사전확률 × 우도   | 0  | 0  | 0  | 1/60 | 1/100 | | 사후확률 $P(H$\|$D)$ | 0  | 0  | 0  | 5/8 | 3/8 | 파이썬 코드는 다음과 같습니다.  ```python import thinkbayes as tb class Dice(tb.Suite):   # 우도함수 정의   def Likelihood(self, data, hypo):     if hypo < data:       return 0     else:       return 1.0/hypo # 가설정의 및 객체 선언 suite=Dice([4,6,8,12,20]) # 사전확률에 우도 곱해줌 # 우도는 관찰결과(데이터) # 이를 통해 사후확률 계산 suite.Update(12) # 결과 출력 suite.Print() ``` 위 코드의 실행 결과는 다음과 같습니다. > **4** 0.0 > **6** 0.0 > **8** 0.0 > **12** 0.625 > **20** 0.375  ## 기본코드 객체 생성에 쓰인 코드는 thinkbayes.py인데 정리 겸 하단에 첨부하였습니다. 출처는 [이곳](http://greenteapress.com/wp/think-bayes/)입니다.  <script src="https://gist.github.com/ratsgo/b818810b151af8abbf6af009ba913a2c.js"></script>
bayes2␞ 이 글에서는 베이지안 추론에 대해 살펴보도록 하겠습니다. 이 글은 ‘Think Bayes(앨런 B. 다우니 지음, 권정민 옮김, 한빛미디어 펴냄)’를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 기관차 문제 모든 기차의 기관차엔 1부터 $N$까지 일련번호가 붙어 있습니다. 어느 날 60호 기관차를 봤다고 칩시다. 이 때 이 회사가 운영하고 있는 기관차는 총 몇 개일까요? 즉 $N$이 몇인지 추정하는 것이 문제가 되겠습니다. 베이지안 추론법에 따르면 이런 문제는 두 단계로 해결합니다. > (1) **사전확률** : 데이터를 보기 전에 $N$에 대해 알고 있는 것이 무엇인가? > > (2) **우도** : $N$이 특정한 값을 가질 때 관측한 데이터(60호 객차)가 발생할 확률은?   ## 동일 사전확률 가정 사전확률과 관련해 근거는 부족하지만 간단한 가정을 해보겠습니다. 철도를 운영하는 회사는 단 하나이고, 이 회사가 운영 중인 기관차는 일단 1000개라고 칩시다. 또 $N$은 1~1000 사이의 어떤 값이든 동일한 확률로 선택될 수 있다고 보는 겁니다. 이 가정 하에서 우도를 구해봅시다. 이 회사가 운영하고 있는 기관차가 59개 이하라면 60호 기관차를 절대 관측할 수 없습니다. 따라서 $N$이 1~59일 때 우도는 0입니다.  운영 중인 기관차 수가 60개라면 60호 기관차를 관측할 확률은 1/60이 됩니다. 마찬가지로 총 기관차 수가 61개라면 우도는 1/61, 62개라면 1/62… 이런 식으로 우도를 구할 수 있게 됩니다. 베이즈 규칙에 따르면 사후확률(60호 기관차를 관측했을 때 운영 중인 기관차 수 $N$이 나타날 확률)은 사전확률에 우도를 곱해 풀 수 있습니다. 사전확률은 동일하다고 가정했기 때문에 제일 큰 값을 갖는 우도가 전제하는 $N$이 우리의 추정 결과가 될 것입니다.  이 경우 우리는 $N$을 60으로 추정할 수밖에 없게 됩니다. 운영 중인 기관차가 60개일 때 우도가 가장 큰 값을 갖게 되거든요. 그런데 이런 추정은 상식에는 반하는 결과입니다.  다시 말해 60호 기관차를 관측했다고 해서 이 회사가 운영 중인 기관차 수가 60개라고 추정하는 건 너무 단순한 추론이라는 것이지요. 만약 35호 기관차를 관측했다면 같은 방식으로 베이지안 추론을 해보면 총 기관차 수가 35개라는 예측이 나오게 될 겁니다. 이 가정에 따른 결과 표는 다음과 같습니다. 아래 표에서 사후확률은 사전확률에 우도를 곱한 뒤 사후확률 전체 합이 1이 되도록 나누어준 값입니다. | $N$ | 사전확률 |  우도  | 사후확률  | | :--: | :----: | :----: | :-----: | | 1  | 1/1000 |  0  |  0  | | ... | ...  | ...  |     | | 59 | 1/1000 |  0  |  0  | | 60 | 1/1000 | 1/60 | 0.0059 | | ... | ...  | ...  |     | | 1000 | 1/1000 | 1/1000 | 0.00035 | 사후확률의 평균은 $N$에 사후확률을 곱한 뒤 모두 더해주면 됩니다. 그 값은 333.065557입니다.   ## 가정 보완하기 동일 사전확률 가정이 불완전함을 확인했습니다. 이를 보완할 수 있는 방법은 두 가지가 있습니다. (1)이 사전확률, (2)가 우도 쪽을 보완하는 접근기법이 되겠습니다. > (1) 배경지식을 더 확보 > > (2) 데이터를 더 확보   ## 사전확률의 대안 (1)과 관련해 기관차를 1000대나 운영하고 있는 회사가 있고, $N$이 1~1000 사이에 선택될 확률이 동일하다고 전제하는 건 비현실적입니다. 회사의 규모는 현실적으로는 이보다 규모가 훨씬 작을 겁니다. 바꿔 말해 $N$이 1000이 될 확률은 $N$이 1이 될 가능성보다 훨씬 작을 것이라 가정하는 것이 합리적입니다. 이와 관련해 로버트 액스텔이라는 학자는 회사 규모의 분포는 **멱법칙**을 따른다는 사실을 밝혀냈습니다. 이 법칙에 따르면 기관차가 10대 미만인 회사가 1000개일 때, 100대의 기관차를 소유한 회사는 100개, 1000대의 기관차를 운영 중인 회사는 10개, 1만대 기관차를 소유한 회사는 1개입니다.  다시 말해 운영 중인 기관차의 총 개수 $N$이 커질수록 $N$이 선택될 확률, 즉 사전확률이 점차 작아진다는 이야기입니다. 그럼 사전확률을 다시 구해보겠습니다.  우선 $N$의 역수를 취합니다. | $N$  |  역수  | | :----: | :-----: | |  1  |  1  | |  2  |  0.5  | |  3  | 0.33  | |  4  | 0.25  | |  5  |  0.2  | | ...  |  ...  | | **총합** | 7.48547 | 이렇게 구한 역수를 역수의 총합(7.48547)으로 나눠준 것이 각 $N$의 사전확률이 되겠습니다. 다음과 같습니다. | $N$ |     사전확률     | | :--: | :--------------------: | | 1  | 0.13359213049244018  | | 2  | 0.06679606524622009  | | 3  | 0.044530710164146725 | | 4  | 0.033398032623110044 | | 5  | 0.026718426098488037 | | ... |     ...      | | 996 | 0.0001341286450727311 | | 997 | 0.00013399411283093298 | | 998 | 0.00013385985019282582 | | 999 | 0.00013372585634878898 | | 1000 | 0.00013359213049244018 |   ## 관측치 늘리기 동일 사전확률 가정 하에서 60호 기관차 하나만 관측한 뒤에 사후확률의 평균을 구하면 다음과 같습니다. | 상한선 | 사후확률 평균 | | :--: | :-----: | | 500 |  207  | | 1000 |  333  | | 2000 |  552  | 우리는 60호 기관차만 보고 결론을 내린 셈인데요. 데이터를 하나만 보고 결론을 내리는건 너무 성급한 일입니다. 60호 기관차에 이어 30번과 90번 기관차도 봤다고 가정해 보겠습니다. 이 데이터를 사용했을 때 사후확률 평균은 다음과 같습니다. | 상한선 | 사후확률 평균 | | :--: | :-----: | | 500 |  152  | | 1000 |  164  | | 2000 |  171  | 그 차이가 확실히 줄어들어 수렴하는 경향을 보임을 알 수 있습니다. 마지막으로 보완한 사전확률을 토대로 30번, 60번, 90번 기관차를 관측한 뒤의 사후확률 평균을 보겠습니다. | 상한선 | 사후확률 평균 | | :--: | :-----: | | 500 |  131  | | 1000 |  133  | | 2000 |  134  | 상한선이 어떻든 간에 상관없이 사후확률 평균은 134에 수렴한다고 합니다.   ## 파이썬 코드 마지막 사후확률 표를 생성하는 데 쓴 파이썬 코드는 다음과 같습니다. thinkbayes.py는 [이곳](http://greenteapress.com/wp/think-bayes/)에서 내려받을 수 있습니다. ```python import thinkbayes as tb class Train(tb.Suite):   """Represents hypotheses about   how many trains the company has."""   def __init__(self, hypos, alpha=1.0):     """Initializes the hypotheses     with a power law distribution.     hypos: sequence of hypotheses     alpha: parameter of the power law prior     """     tb.Pmf.__init__(self)     for hypo in hypos:       self.Set(hypo, hypo ** (-alpha))     self.Normalize()   def Likelihood(self, data, hypo):     """Computes the likelihood of the data     under the hypothesis.     """     if hypo < data:       return 0     else:       return 1.0 / hypo def Mean(suite):   total = 0   for hypo, prob in suite.Items():     total += hypo * prob   return total def MakePosterior(high, dataset):   hypos = xrange(1, high+1)   suite = Train(hypos)   suite.name = str(high)   for data in dataset:     suite.Update(data)   return suite dataset = [30, 60, 90] for high in [500, 1000, 2000]:   suite = MakePosterior(high, dataset)   print high, suite.Mean() ``` 
FDR␞ 이번 글에서는 **변수선택(Feature Selection)** 기법으로 널리 쓰이고 있는 **False Discovery Rate(FDR)**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 김성범 교수님 강의를 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## FDR의 문제 의식 제품의 '정상', '불량'을 판별하는 이진분류 문제를 푼다고 칩시다. (정상, 불량이든 긍정, 부정이든 어떤 것이든 상관없습니다) 우리가 가진 데이터의 독립변수는 $x_1, x_2, x_3$ 세 개이고 하나의 행(레코드)은 관측치 하나에 대응한다고 가정하겠습니다. 그렇다면 세 변수 가운데 정상, 불량을 판별하는 데 가장 중요한 변수는 무엇일까요? <a href="http://imgur.com/e2T9Rnn"><img src="http://i.imgur.com/e2T9Rnn.png" width="400px" title="source: imgur.com" /></a> 위 예시에서 $x_1$은 정상, 불량 범주를 판별하는 데 전혀 도움이 안 될 것입니다. 반면 $x_2$는 상대적으로 중요할 겁니다. 정상 관측치에선 작은 값(평균 : 10)을, 불량 관측치에선 큰 값(200)을 갖기 때문입니다. $x_3$는 $x_1$보다는 중요한 변수지만 $x_3$보다는 덜 중요한 변수일 겁니다. 지금까지 말씀드린 내용을 이를 수식으로 나타내면 아래와 같습니다. 이 식에 따라 좌변을 계산하면 각각 0, 190, 1.6이 됩니다.  $$ \left| \overline { { x }_{ i,normal } } -\overline { { x }_{ i,abnormal } } \right| \ge \tau $$ 그렇다면 $τ$가 얼마나 커야 유의미(=$x_i$가 중요변수)할까요? 이를 엄밀히 따져 보려면 통계학 기법을 써야 합니다. 다시 말해 **귀무가설(Null Hypothesis)**과 **대립가설(Alternative Hypothesis)**을 아래와 같이 설정하고, 변수마다 각각 **가설검정(Hypothesis Test)**을 실시해야 한다는 것이지요.   $$ { H }_{ 0 }\quad :\quad \left| \overline { { x }_{ i,normal } } -\overline { { x }_{ i,abnormal } } \right| =0\\ { H }_{ 1 }\quad :\quad \left| \overline { { x }_{ i,normal } } -\overline { { x }_{ i,abnormal } } \right| >0 $$  그런데 여기서 문제가 있습니다. 우리는 대개 변수가 100개를 훌쩍 넘는 다변량 데이터를 취급한다는 점입니다. 모든 가설을 동시에 검정하면 $x_i$가 중요하지 않은 변수($H_0$가 참)인데도 중요변수($H_0$를 기각)라는 결과가 나오는 경향이 있습니다. 이를 **다중성(Multiplicity)** 문제라고 합니다.  개별 가설검정의 **유의수준(significance level)**이 0.01, 다시 말해 개별 가설검정의 **신뢰도**가 0.99인 상황에서 가설검정을 실시한다고 합시다. 유의수준이란 귀무가설 $H_0$가 참인데 잘못해서 기각할 확률(**제1종 오류**)의 최대값을 뜻합니다.  그럼 변수가 100개인 다변량 데이터에 대해 변수선택을 하기 위해 100번의 가설검정을 실시한다면 100회 가설검정 전체의 신뢰도는 크게 낮아집니다. 다시 말해 중요하지 않은 변수인데도 중요변수라는 결과가 나올 가능성이 높아진다는 얘기입니다. 아래 표를 볼까요?   | 검정 횟수 |  검정 전체의 신뢰도   | | :---: | :---------------: | |  1  |  $0.99^1=0.99$  | |  2  |  $0.99^2=0.98$  | | 10  | $0.99^{10}=0.90$ | | 100 | $0.99^{100}=0.37$ |  이를 그래프로 나타내면 아래와 같습니다.  <a href="http://imgur.com/wBYsEEw"><img src="http://i.imgur.com/wBYsEEw.png" width="300px" title="source: imgur.com" /></a> FDR은 이러한 다중가설검정 문제를 해결하기 위해 제안된 방법입니다. 물론 개별 유의수준($α$)을 '목표값/변수개수'로 정하고 기존대로 가설검정을 수행하는 기법(**Family-wise Test**)이 제시되기도 했습니다. 예컨대 전체 목표 유의수준이 0.01이고 변수개수가 10개라면 개별 유의수준을 0.001로 놓고 가설검정을 각각 실시하는 방식이죠. 그러나 이 방식은 중요한 변수($H_0$가 거짓)인데도 중요하지 않다($H_0$가 참)는 결론을 내는 경우가 많은 단점이 있다고 합니다.   ## FDR 절차 FDR은 제1종 오류를 최대한 적게 범하면서도 중요한 가설을 최대한 많이 찾을 수 있도록($H_0$ 기각) 한다는 점이 강점입니다. 검정해야할 다중가설(데이터의 변수 개수)이 $m$개일 때 FDR은 아래와 같이 정의됩니다. |  구분   | $H_0$ 채택 | $H_0$ 기각 | Total | | :-------: | :------: | :------: | :---: | | $H_0$가 참 |  $U$  |  $V$  | $m_0$ | | $H_0$가 거짓 |  $T$  |  $S$  | $m_1$ | |  Total  |  $W$  |  $R$  | $m$ | $$ FDR=E\left[ \frac { V }{ V+S } \right] =E\left[ \frac { V }{ R } \right] $$ 위 수식에 정의된 FDR을 해석하면 이렇습니다. FDR은 기각된 귀무가설($H_0$) 가운데 잘못 기각된 가설이 차지하는 비율의 평균으로 사용자가 지정해주는 값입니다. 바꿔 말해 $m$회 가설검정 가운데 각 $H_0$이 참인데 기각된 비율, 즉 검정 전체 유의수준에 가까운 의미라는 뜻입니다. 실제로 FDR 제안자는 FDR을 $α$라고 표기하고 있습니다. 그럼 FDR 절차를 살펴볼까요? 검정해야할 다중가설, 즉 데이터 변수 개수가 15개라고 합시다. 목표로 하는 FDR 값을 0.05로 정해보겠습니다. 우선 각각의 가설에 대해 $p-value$를 구한 뒤 이를 오름차순으로 정렬하고, 순위(rank)를 매깁니다. 아래 표와 같습니다. <a href="http://imgur.com/m40OJEw"><img src="http://i.imgur.com/m40OJEw.png" width="400px" title="source: imgur.com" /></a> $p-value$는 $H_0$이 참일 확률을 의미하므로, $α$를 0.05로 놓고 기존대로 단일 가설검정을 실시했다면 1~9번 변수 가 중요변수라는 결과를 얻었을 겁니다. Family-wise Test 방식대로 '목표 유의수준/변수 개수=0.05/15'로 가설검정을 실시한다면, 그 값이 0.0033이므로 1~3번 변수만 중요하다는 결론을 내렸을 겁니다. FDR 절차에서 $i$는 rank, $m$은 변수 개수, $α$는 사용자가 정한 FDR 값입니다. 예컨대 1번 변수는 $1/15$에 0.05를 곱해 계산합니다. 마찬가지로 2번 변수는 $2/15$에 0.05를 곱해 구합니다.  이 값이 $p-value$보다 큰 변수 랭크의 최대값이 FDR 절차가 뽑은 중요변수의 개수가 됩니다. 위 표 기준으로 설명하자면 이렇습니다. 표 아래쪽부터 시작해 위쪽으로 훑어 가면서 $i/m*α$ 값이 $p-value$보다 큰 지 여부를 검토합니다. 처음으로 $p-value$ 값을 넘어서는 지점은 바로 4번 변수이네요. 따라서 1~4번 변수를 중요한 변수라고 결론을 내게 됩니다. 예제에서도 알 수 있듯 FDR은 단일 가설검정에 비해 제1종 오류가 낮고(비중요 변수 배제), Family-wise Test 방식에 비해 중요한 가설을 많이 찾아낸다는 장점이 있습니다.  ## FDR 예제 그럼 실제 데이터를 가지고 문제를 풀어보겠습니다. UCI data 가운데 하나를 가져왔습니다. 개요는 아래와 같습니다. > **Ionosphere Data Set** > > 데이터 설명 : 전리층(ionosphere)에 대한 레이더 관측치를 모은 데이터 > > 관측치 개수 : 351개 > > 독립변수 : 34개 > > 종속변수 : 전리층의 패턴 유무 (good : 전리층에 특정 패턴 존재, bad : 패턴 없음) 모든 독립변수에 대해 T-test를 수행하였습니다. ($H_0$=두 집단의 평균이 같다, $H_1$=두 집단 평균이 다르다) 변수별 p-value는 아래 표와 같습니다.  | 변수 |  P-value  | 변수 |  P-value  | 변수 |  P-value  | 변수 |  P-value  | | :--: | :----------: | :--: | :----------: | :--: | :----------: | :--: | :----------: | | 1  | 2.303168e-11 | 11 | 3.060316e-03 | 21 | 6.897335e-05 | 31 | 7.025167e-07 | | 2  |   NaN   | 12 | 8.189137e-03 | 22 | 5.051969e-02 | 32 | 5.547445e-01 | | 3  | 2.339468e-15 | 13 | 9.549388e-04 | 23 | 3.350101e-04 | 33 | 3.748258e-06 | | 4  | 5.941660e-02 | 14 | 1.341207e-03 | 24 | 9.191420e-01 | 34 | 2.747245e-01 | | 5  | 3.153540e-15 | 15 | 1.017555e-04 | 25 | 1.162854e-03 |   |       | | 6  | 1.988959e-02 | 16 | 1.507825e-02 | 26 | 9.795861e-01 |   |       | | 7  | 7.577585e-13 | 17 | 1.036061e-01 | 27 | 5.055064e-02 |   |       | | 8  | 6.995369e-04 | 18 | 4.976238e-02 | 28 | 4.980595e-01 |   |       | | 9  | 5.545817e-07 | 19 | 3.255247e-02 | 29 | 2.570992e-05 |   |       | | 10 | 4.515815e-02 | 20 | 5.604890e-01 | 30 | 9.475607e-01 |   |       | Individual Test($α=0.05$) 결과 선택된 중요 변수는 22개입니다. (p-value가 0.05보다 작은 변수 선택) > 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 22, 24, 28, 30, 32 Family-Wise Test($α=0.05$, $α/m$, $m$=전체 변수 개수) 결과 선택된 중요 변수는 15개입니다. (p-value가 0.0015보다 작은 변수 선택) > 1, 3, 5, 7, 8, 9, 13, 14, 15, 21, 23, 25, 29, 31, 33 위 계산결과를 토대로 $α$값을 0.05로 두고 FDR을 수행한 결과는 아래 표와 같습니다. | 변수 ID | rank |  P-value  |  $i/m*α$  | | :---: | :--: | :----------: | :---------: | |  3  | 1  | 2.339468e-15 | 0.001470588 | |  5  | 2  | 3.153540e-15 | 0.002941176 | |  7  | 3  | 7.577585e-13 | 0.004411765 | |  1  | 4  | 2.303168e-11 | 0.005882353 | |  9  | 5  | 5.545817e-07 | 0.007352941 | | 31  | 6  | 7.025167e-07 | 0.008823529 | | 33  | 7  | 3.748258e-06 | 0.010294118 | | 29  | 8  | 2.570992e-05 | 0.011764706 | | 21  | 9  | 6.897335e-05 | 0.013235294 | | 15  | 10 | 1.017555e-04 | 0.014705882 | | 23  | 11 | 3.350101e-04 | 0.016176471 | |  8  | 12 | 6.995369e-04 | 0.017647059 | | 13  | 13 | 9.549388e-04 | 0.019117647 | | 25  | 14 | 1.162854e-03 | 0.020588235 | | 14  | 15 | 1.341207e-03 | 0.022058824 | | 11  | 16 | 3.060316e-03 | 0.023529412 | | 12  | 17 | 8.189137e-03 | 0.025000000 | | 16  | 18 | 1.507825e-02 | 0.026470588 | |  6  | 19 | 1.988959e-02 | 0.027941176 | | 19  | 20 | 3.255247e-02 | 0.029411765 | | 10  | 21 | 4.515815e-02 | 0.030882353 | | 18  | 22 | 4.976238e-02 | 0.032352941 | | 22  | 23 | 5.051969e-02 | 0.033823529 | | 27  | 24 | 5.055064e-02 | 0.035294118 | |  4  | 25 | 5.941660e-02 | 0.036764706 | | 17  | 26 | 1.036061e-01 | 0.038235294 | | 34  | 27 | 2.747245e-01 | 0.039705882 | | 28  | 28 | 4.980595e-01 | 0.041176471 | | 32  | 29 | 5.547445e-01 | 0.042647059 | | 20  | 30 | 5.604890e-01 | 0.044117647 | | 24  | 31 | 9.191420e-01 | 0.045588235 | | 30  | 32 | 9.475607e-01 | 0.047058824 | | 26  | 33 | 9.795861e-01 | 0.048529412 | |  2  | 34 |   NaN   | 0.050000000 | 위 표에서 $i/m*0.05$가 $p-value$보다 크다는 조건을 만족하는 rank의 최대값은 19입니다. 그 결과 19개 변수가 선택됐습니다. > 3, 5, 7, 1, 9, 31, 33, 29, 21, 15, 23, 8, 13, 25, 14, 11, 12, 16, 6 FDR level 변화에 따른 중요 변수 선택 결과는 아래와 같습니다. FDR level이 클 수록 선택되는 변수 개수가 많아지는 경향을 보였습니다.  | FDR level | 선택변수(개) | | :-------: | :-----: | |  0.01  |  16  | |  0.02  |  17  | |  0.03  |  18  | |  0.04  |  19  | |  0.06  |  20  | |  0.08  |  24  | |  0.09  |  25  | |  0.14  |  26  | |  0.35  |  27  | |  0.61  |  28  | |  0.64  |  30  | Ionosphere Data Set을 7:3 비율로 학습셋과 검증셋으로 나누고, 학습셋에 대해 LDA 모델을 적합한 뒤 검증셋을 대상으로 단순정확도를 측정하였습니다. 통계적으로 유의한 일부 변수만으로 구축한 모델은 전체 변수를 모두 사용한 모델의 성능에 크게 뒤지지 않음을 확인할 수 있었습니다. |   구분    |  전체  | Individual | Family-wise | FDR  | | :-----------: | :----: | :--------: | :---------: | :----: | | 학습에 사용된 변수(개) |  33  |   19   |   9   |  14  | |   단순정확도   | 0.8762 |  0.8476  |  0.8286  | 0.8190 | 위 문제를 푸는 데 사용한 R 코드는 아래와 같습니다. ```R # load & split data data <- read.csv('data.csv',header=F) good <- data[which(data[,35] == 'g'),-35] bad <- data[which(data[,35] == 'b'),-35] # T-test Ttest <- c() for (i in 1:dim(good)[2]) {  Ttest[i] <- t.test(good[,i], bad[,i])$p.value } # individual test which(Ttest<0.05)  # family-wise test (패키지 사용) # bonferroni : p-values are multiplied by the number of comparisons family.wise.test=p.adjust(Ttest, method = "bonferroni") which(family.wise.test<0.05) # family-wise test (자작) which(Ttest < 0.05/length(Ttest)) # FDR (패키지 사용) library(fdrtool) fdr <- fdrtool(Ttest, statistic='pvalue', cutoff.method = 'fndr') fdr$param # FDR (자작) fdr.level <- 0.05 var_table <- matrix(0, nrow=length(Ttest),ncol=4) colnames(var_table) <- c('id', 'rank', 'P-value', 'i/m*FDR') var_table[,1] <- c(1:length(Ttest)) var_table[,3] <- Ttest var_table <- var_table[order(var_table[,3]),] var_table[,2] <- c(1:length(Ttest)) var_table[,4] <- var_table[,2] / length(Ttest) * fdr.level max(which(var_table[,3] < var_table[,4])) # 중요 변수 개수 var_table[1:max(which(var_table[,3] < var_table[,4])),1] # 중요 변수 추출 # all variables model library(MASS) data[,35] <- as.numeric(data[,35]) colnames(data)[35] <- 'Target' data <- data[,-2] trn_idx <- sample(1:dim(data)[1], round(0.7*dim(data)[1])) train_data <- data[trn_idx,] test_data <- data[-trn_idx,] allmodel <- lda(Target~.,train_data) # var selection model train_data_good <- train_data[which(train_data$Target == 1),-train_data$Target] train_data_bad <- train_data[which(train_data$Target == 2),-train_data$Target] Ttest <- c() for (i in 1:dim(train_data_good)[2]) {  Ttest[i] <- t.test(train_data_good[,i], train_data_bad[,i])$p.value } family.wise.test=p.adjust(Ttest, method = "bonferroni") individual_model <- lda(Target~.,train_data[,c(which(Ttest<0.05),34)]) familywise_model <- lda(Target~.,train_data[,c(which(family.wise.test<0.05),34)]) # fdr model fdr.level <- 0.05 var_table <- matrix(0, nrow=length(Ttest),ncol=4) colnames(var_table) <- c('id', 'rank', 'P-value', 'i/m*FDR') var_table[,1] <- c(1:length(Ttest)) var_table[,3] <- Ttest var_table <- var_table[order(var_table[,3]),] var_table[,2] <- c(1:length(Ttest)) var_table[,4] <- var_table[,2] / length(Ttest) * fdr.level important_vars <- var_table[1:max(which(var_table[,3] < var_table[,4])),1] fdr_model <- lda(Target~.,train_data[,c(important_vars,34)]) # prediction all <- predict(allmodel, test_data) individual <- predict(individual_model, test_data) familywise <- predict(familywise_model, test_data) fdr <- predict(fdr_model, test_data) # calculate ACC ACC_all <- sum(diag(table(test_data$Target, all$class)))/length(all$class) ACC_indi <- sum(diag(table(test_data$Target, individual$class)))/length(individual$class) ACC_fdr <- sum(diag(table(test_data$Target, fdr$class)))/length(fdr$class) ACC_family <- sum(diag(table(test_data$Target, familywise$class)))/length(familywise$class) ```   ## 반복샘플링 기반 FDR 지금까지 설명해드린 FDR 기법은 우리가 가진 데이터가 특정 **확률분포**를 따르고, 이로부터 적당한 방법을 취해 $p-value$를 계산할 수 있어야만 적용이 가능합니다. 하지만 데이터가 특정 분포를 따르지 않거나, 그 분포를 모른다고 할 때는 $p-value$ 계산이 어렵습니다. 반복샘플링 기반 FDR은 말 그대로 반복샘플링을 통해 분포에 대한 가정없이 $p-value$를 계산할 수 있는 기법입니다. 가정과 절차는 이렇습니다. 특정 변수를 기준으로 관측치를 랜덤하게 섞습니다. 만약 해당 변수가 범주 분류에 의미 있는 변수라면 실제 데이터의 통계량이 관측치를 랜덤하게 섞은 데이터의 통계량보다 훨씬 클 겁니다. 아래 그림처럼요. <a href="http://imgur.com/8qiPD5O"><img src="http://i.imgur.com/8qiPD5O.png" width="400px" title="source: imgur.com" /></a> 통계적 유의성을 확보하기 위해서는 이러한 과정을 충분히 많이 반복해야 합니다. 만약 아래처럼 100번을 반복 수행했다고 가정해보겠습니다. p-value는 아래와 같이 구할 수 있습니다. <a href="http://imgur.com/Tza6hAx"><img src="http://i.imgur.com/Tza6hAx.png" width="500px" title="source: imgur.com" /></a> $$ { p-value }_{ { X }_{ 1 } }=\frac { { T }_{ { x }_{ 1 } }^{ (i) }\quad 중에 \quad{ T }_{ { x }_{ 1 } } 보다\quad 큰\quad값의\quad개수}{ 반복횟수\times변수의\quad수 } =\frac { { T }_{ { x }_{ 1 } }^{ (i) }\quad중에 \quad{ T }_{ { x }_{ 1 } } 보다\quad 큰\quad값의\quad개수 }{ 100\times 2 } \\ { p-value }_{ { X }_{ 2 } }=\frac { { T }_{ { x }_{ 2 } }^{ (i) }\quad 중에\quad{ T }_{ { x }_{ 2 } } 보다\quad 큰\quad값의\quad개수 }{ 반복횟수\times변수의\quad수} =\frac { { T }_{ { x }_{ 2 } }^{ (i) } \quad중에\quad{ T }_{ { x }_{ 2 } } 보다\quad 큰\quad값의\quad개수 }{ 100\times 2 } $$   이렇게 p-value를 구하게 되면 이후 절차는 지금까지 설명해드린 FDR 절차 그대로 따르면 됩니다.  ## 이진분류 이외 문제에 FDR 적용하기 p-value만 구하면 이후엔 FDR 기법을 적용할 수 있습니다. 정규분포를 따르는 데이터의 이진분류 문제의 경우 T-test를 수행하면 p-value를 구할 수 있었고, 특정 데이터 분포를 가정할 수 없는 상황이라면 반복 샘플링 기반으로 p-value를 구할 수 있습니다. 그렇다면 $y$가 연속형 숫자인 회귀 문제에서 중요 변수를 찾아내기 위해 FDR을 적용해야 한다면 p-value를 어떻게 구해야 할까요? 귀무가설과 대립가설을 아래와 같이 설정하고 모든 변수에 대해 가설검정을 실시합니다.  $$ { H }_{ 0 }\quad :\quad { \beta }_{ i }=0\\ { H }_{ 1 }\quad :\quad { \beta }_{ i }\neq 0 $$  p-value는 귀무가설이 맞을 확률을 의미하므로 위 가설검정에서 p-value가 작게 나올 경우 $H_0$는 기각하게 됩니다. 바꿔 말해 $β_i$가 중요하다는 이야기이죠. 선형회귀 모델의 계수들은 **t분포**를 따른다고 합니다. 검정통계량 $t$는 아래와 같이 구합니다. $$ t=\frac { \hat { { \beta }_{ i } } -0 }{ sd\{ \hat { { \beta }_{ i } } \} } $$ 3개 이상의 범주 분류 문제의 경우 p-value를 어떻게 구할까요? 두 가지 방법이 있습니다. 첫번째는 범주 두 개를 한 세트로 묶어서 이진 분류 문제처럼 p-value를 구하는 겁니다. 나머지는 **분산분석(ANOVA)** 기법을 적용하는 것입니다.
CNNs␞ 이번 글에서는 **Convolutional Neural Network**(CNN)의 주요 모델들에 대해 살펴보도록 하겠습니다. 이 글은 [Adit Deshpande 님의 블로그](https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html)와 [이곳](https://medium.com/towards-data-science/an-overview-of-resnet-and-its-variants-5281e2f56035), 그리고 각 논문을 참고해 제 나름대로 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## AlexNet Recurrent Neural Network와 더불어 딥러닝 모델의 양대 산맥으로 주목받고 있는 CNN은 기본적으로 얀 르쿤이 1989년 제안한 [구조](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)를 토대로 하고 있습니다. 컴퓨터 비전 분야의 '올림픽'이라 할 수 있는 ILSVRC(ImageNet Large-Scale Visual Recognition Challenge)의 2012년 대회에서 제프리 힌튼 교수팀의 [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)이 top 5 test error 기준 15.4%를 기록해 2위(26.2%)를 큰 폭으로 따돌리고 1위를 차지했습니다.  여기서 top 5 test error란 모델이 예측한 최상위 5개 범주 가운데 정답이 없는 경우의 오류율을 나타냅니다. 당시 ILSVRC 데이터셋(Image은 1000개 범주 예측 문제였습니다. 어쨌든 AlexNet 덕분에 딥러닝, 특히 CNN이 세간의 주목을 받게 됐습니다. AlexNet 아키텍처의 주요 특징은 다음과 같습니다. <a href="https://imgur.com/CwIvlUW"><img src="https://i.imgur.com/CwIvlUW.png" title="source: imgur.com" /></a> - conv layer, max-pooling layer, dropout layer 5개 - fully connected layer 3개 - nonlinearity function : ReLU - batch stochastic gradient descent AlexNet이 중요한 이유는 의미있는 성능을 낸 첫번째 CNN 아키텍처이자, AlexNet에 쓰인 드롭아웃 등 기법은 이 분야 표준으로 자리잡을 정도로 선도적인 역할을 했기 때문입니다.    ## GoogleNet AlexNet 이후 층을 더 깊게 쌓아 성능을 높이려는 시도들이 계속되었습니다. [VGGNet](http://arxiv.org/pdf/1409.1556v6.pdf)(2014), [GoogleNet](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)(2015) 등이 바로 그것입니다. GoogleNet은 VGGNet보다 구조가 복잡해 널리 쓰이진 않았지만 아키텍처 면에서 주목을 받았습니다. 보통 하나의 conv layer에는 한 가지의 conv filter가 사용됩니다.  GoogleNet 연구진들은 한 가지의 conv filter를 적용한 conv layer를 단순히 깊게 쌓는 방법도 있지만, 하나의 layer에서도 다양한 종류의 filter나 pooling을 도입함으로써 개별 layer를 두텁게 확장시킬 수 있다는 창조적인 아이디어로 후배 연구자들에게 많은 영감을 주었습니다. 이들이 제안한 구조가 바로 **Inception module**입니다. ([그림 출처](https://www.youtube.com/watch?v=VxhSouuSZDY))  <a href="https://imgur.com/VY3BkBR"><img src="https://i.imgur.com/VY3BkBR.png" width="400px" title="source: imgur.com" /></a>  Inception module에서 특히 주목받은 것이 바로 1×1 conv filter입니다. 가령 현재 층 입력데이터 이미지의 차원수가 100×100×60이고, 1×1 conv filter를 20개 사용한다면 데이터의 차원 수는 100×100×20으로 줄어듭니다. 60개 채널(차원)에 달하는 하나의 픽셀이 20차원의 feature space로 선형변환, 차원축소된 것이라고도 볼 수 있겠습니다.   ## ResNet [ResNet](https://arxiv.org/pdf/1512.03385v1.pdf)(2015)은 2015년 ILSVRC에서 오류율 3.6%로 1등을 차지했습니다. 인간의 분류 오차가 5~10% 정도라는 걸 감안하면 놀라운 성적표입니다.  사실 AlexNet이 처음 제안된 이후로 CNN 아키텍처의 층은 점점 더 깊어졌습니다. AlexNet이 불과 5개 층에 불과한 반면 VGGNet은 19개 층, GoogleNet은 22개 층에 달합니다. 하지만 층이 깊어질 수록 역전파되는 그래디언트가 중간에 죽어서 학습이 잘 되지 않는 문제(gradient vanishing)가 발생했습니다. ResNet 저자들이 제시한 아래 학습그래프를 보면 이같은 문제가 뚜렷이 나타납니다. <a href="https://imgur.com/zJm2b5g"><img src="https://i.imgur.com/zJm2b5g.png" width="500px" title="source: imgur.com" /></a> ResNet 저자들의 핵심 아이디어는 다음 그림과 같은 **residual block**입니다. 그래디언트가 잘 흐를 수 있도록 일종의 지름길(shortcut, skip connection)을 만들어 주자는 생각입니다. 이는 forget gate 등을 도입해 이전 스텝의 그래디언트(정보)를 좀 더 잘 흐르게 만드려는 **Long Term Short Memory(LSTM)**의 철학과 본질적으로 유사합니다. <a href="https://imgur.com/fse3Ntq"><img src="https://i.imgur.com/fse3Ntq.png" width="350px" title="source: imgur.com" /></a> ResNet의 성능이 좋은 이유는 그래디언트 문제 말고 또 있습니다. [Veit et al. (2016)](https://arxiv.org/pdf/1605.06431.pdf)은 residual block이 앙상블(ensemble) 모델을 구축한 것과 비슷한 효과를 낸다고 주장했습니다. residual block의 skip connection 덕분에 입력데이터와 그래디언트가 오갈 수 있는 통로가 크게 늘어나기 때문입니다. ($n$개 skip connection이 있다면 $2^n$개의 서로 다른 통로 존재) 이를 직관적으로 나타낸 그림은 아래 그림과 같습니다. <a href="https://imgur.com/CjLtXb0"><img src="https://i.imgur.com/CjLtXb0.png" width="600px" title="source: imgur.com" /></a>   ## DenseNet [DenseNet](https://arxiv.org/pdf/1608.06993.pdf)(2016)은 ResNet에서 한발 더 나아가 전체 네트워크의 모든 층과 통하는 지름길을 만들었습니다. conv-ReLU-conv 사이만 뛰어넘는 지름길을 만들었던 ResNet보다 훨씬 과감한 시도입니다. DenseNet의 전체적인 아키텍처는 다음과 같습니다.  <a href="https://imgur.com/EITg2BX"><img src="https://i.imgur.com/EITg2BX.png" width="500px" title="source: imgur.com" /></a>   ## Region Based CNNs [R-CNN](https://arxiv.org/pdf/1311.2524v5.pdf)(2013), [Fast R-CNN](https://arxiv.org/pdf/1504.08083.pdf)(2015), [Faster R-CNN](http://arxiv.org/pdf/1506.01497v3.pdf)(2015) 등은 object detection 문제를 풀기 위해 제안된 모델들입니다. object detection이란 이미지가 주어졌을 때 해당 이미지 속에 들어있는 오브젝트의 경계(bounding box)를 찾아내는 작업입니다. object detection 문제는 크게 오브젝트의 경계를 찾아내는 작업(region proposal step), 해당 오브젝트가 무엇인지 맞추는 작업(classification step) 둘로 나뉩니다. CNN은 여기에서 이미지의 특성을 추출하는 데 중요한 역할을 합니다. 모델이 거듭될 수록 정확도는 물론 속도도 크게 향상되는 추세입니다.   ## CNNs for NLP 문서분류에서 높은 성능으로 주목받은 CNN 아키텍처는 [Kim(2014)](http://www.aclweb.org/anthology/D14-1181)입니다. 단어벡터들을 붙여서 행렬 형태의 입력값을 만들고, 너비가 단어벡터의 차원수와 일치하는 필터를 씁니다. conv layer가 단 1개뿐이지만 필터를 100개 이상 써서 두텁게 만든 것도 특징입니다. 다음 그림과 같습니다.  <a href="https://imgur.com/JN72JHW"><img src="https://i.imgur.com/JN72JHW.png" width="500px" title="source: imgur.com" /></a>  위 그림에서도 알 수 있듯 Kim(2014)의 단점은 conv filter가 돌 때 이웃단어들을 고려할 수는 있지만, 멀리 떨어져 있는 단어들을 감안하기가 어렵다는 점입니다. 이에 [Kalchbrenner et al.(2014)](http://www.aclweb.org/anthology/P14-1062)는 **dynamic $k$-max pooling** 기법을 제안했는데요. 풀링을 할 때 내림차순으로 $k$개를 선택하되 순서를 보존하는 방식입니다. 아래 그림에서 첫번째 conv layer에선 5개, 두번째 conv layer에선 3개를 풀링한 것입니다. 결과적으로 Recursive Neural Network와 유사한 파싱트리 모양의 구조가 됩니다.  <a href="https://imgur.com/WDVOZIH"><img src="https://i.imgur.com/WDVOZIH.png" width="400px" title="source: imgur.com" /></a>  한편 위의 연구들은 단어 수준에서 문서분류를 수행했는데, 최근엔 글자 수준의 CNN 아키텍처도 제안되고 있습니다. 단어(글자)벡터와 문서의 외부정보를 합쳐서 분류 성능을 높이려는 시도도 제안되고 있습니다. 이와 관련 자세한 내용은 [이곳](https://ratsgo.github.io/natural%20language%20processing/2017/08/16/deepNLP)을 참고하시면 좋을 것 같습니다.
word␞ 이번 글에서는 **단어(word)**에 대해 살펴보겠습니다. 이번 글 역시 이선웅 경희대 교수님 강의와 최형용 이화여대 교수님 저서를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 단어의 정의 19세기 이르러서야 그 개념이 정립된 **형태소(morpheme)**에 비해 단어는 꽤 오래 전부터 논의된 개념입니다. 형태소는 짧은 역사를 가진 데 반해 그 정의가 **의미를 가지는 최소 단위(the minimal unit of meaning)**로 깔끔하게 정리되는 편입니다. 하지만 단어는 오랜 연원을 가지고 있지만 지금도 쉽사리 정의내릴 수 없는 언어 단위라고 합니다. 임홍빈 & 장소원(1995)은 지금까지 제시된 단어에 대한 정의를 아래와 같이 세 가지로 정리하고 그 각각의 문제점에 대해서도 언급하고 있습니다. > 가. 단일한 의미를 가지는 음(音) 결합체 > > 나. 최소의 자립 형식 > > 다. 휴지(休止)가 개입할 수 없고 내부가 분리되지 않는 형식 가의 경우 '애인(愛人)'과 '사랑하는 사람'에서 볼 수 있듯 같은 의미를 가지는 형식이 하나는 단어로, 다른 하나는 단어보다 큰 것으로 판명된다는 점에서 문제가 됩니다. 나의 경우 '책상'과 같은 예에서 '책'과 '상'이라는 더 작은 자립 형식이 분석되어 나온다는 점에서 논란이 될 수 있습니다. 다는 휴지가 개입되지 않음에도 하나의 단어가 아닌 '철수가' 같은 예나 단어이면서도 '깨끗은 하다'처럼 한 단어 내부가 분리되는 경우가 문제라는 점입니다.  ## 음운론적 단어와 문법적 단어 단어에 대한 정의가 이처럼 어려운 이유는 우리가 일반적으로 단어라고 부르는 대상에 너무 많은 개념들이 포함되어 있기 때문입니다. 이와 관련해 [Dixon & Aikhenvald(2002)](https://books.google.co.kr/books?hl=ko&lr=&id=i08dpl-NqpEC&oi=fnd&pg=PP1&dq=word:+a+cross-linguistic+typology&ots=mndixjBBO1&sig=oo-b1JgIut_qFQ7fTKMx0OOiod4)는 단어라는 개념은 아래와 같이 크게 **음운론적 단어**와 **문법적 단어**로 구성돼 있다고 주장했습니다. [박진호(1994)](http://snu-primo.hosted.exlibrisgroup.com/primo_library/libweb/action/display.do;jsessionid=34C21F62737C42FF119900F21267FE7C?tabs=viewOnlineTab&ct=display&fn=search&doc=82SNU_INST21481461470002591&indx=1&recIds=82SNU_INST21481461470002591&recIdxs=0&elementId=0&renderMode=poppedOut&displayMode=full&frbrVersion=&frbg=&&dscnt=0&scp.scps=scope%3A%2882SNU_SSPACE%29%2Cscope%3A%2882SNU_INST%29%2Cscope%3A%2882SNU_COURSE%29%2Cscope%3A%2882SNU_ROSETTA%29%2Cprimo_central_multiple_fe&tb=t&vid=82SNU&mode=Basic&srt=rank&tab=all&prefLang=ko_KR&dum=true&vl(freeText0)=%EB%B0%95%EC%A7%84%ED%98%B8%20%ED%86%B5%EC%82%AC%EC%A0%81%20%EA%B2%B0%ED%95%A9%EA%B4%80%EA%B3%84%EC%99%80%20%EB%85%BC%ED%95%AD%EA%B5%AC%EC%A1%B0&dstmp=1492745945406) 역시 한국어의 단어 개념을 음운론적 단어와 **통사원자(syntactic atom;문법적 단어)**로 구분해야 한다고 밝혔습니다. 음운론적 단어란 하나의 호흡단위로써의 단어 개념입니다. 모국어 화자들이 자연스럽게 끊어 읽는 단위가 바로 음운론적 단어라는 것입니다. 이 때문에 음운론적 단어는 대개 **어절**과 일치합니다. 문법적 단어란 통사론에서 말하는 기초단위들을 뜻합니다. 박진호(1994)에 따르면 명사, 동사, 관형사, 부사, 격조사, 문말어미, 보조사, 선문말어미, 접속사, 감탄사가 여기에 해당합니다. 둘을 구분하면 예컨대 아래와 같습니다. > 철수가 밥을 빨리 먹었다. |  구분  |       내용       | | :-----: | :--------------------------: | | 음운론적 단어 |    철수가, 밥을, 빨리, 먹었다    | | 문법적 단어 | 철수, 가, 밥, 을, 빨리, 먹-, -었-, -다 |  ## 단어의 존재 양상 Dixon & Aikhenvald(2002)은 이를 토대로 단어의 종류를 아래 네 가지로 나눌 수 있다고 보았습니다. > 가. 음운론적 단어와 문법적 단어가 일치하는 경우 > > 나. 음운론적 단어가 두 개 이상의 문법적 단어로 이뤄진 경우 > > 다. 문법적 단어가 두 개 이상의 음운론적 단어로 이뤄진 경우 > > 라. 문법적 단어와 음운론적 단어 사이에 보다 복잡한 관계가 존재하는 경우 '가'의 경우 분석에 큰 어려움이 없습니다. '나'~'라'가 어려운 문제인데요. 대부분의 합성어는 '다'에 해당하는 사례가 됩니다. 합성어는 별개로는 음운론적 단어인 것들이 모여 하나의 문법적 단어를 이루는 경우라 할 수 있기 대문입니다. 예컨대 '책상'이 여기에 해당하는데요, '책상'이라는 명사(문법적 단어)는 '책'과 '상'이라는 두 개의 음운론적 단어가 모여 만들어진 집합체입니다.  '먹을 것'과 '먹어 보다' 같은 사례는 '나'에 해당합니다. 둘 모두 중간에 끊어 읽는 경우가 많지 않기 때문에 각각 하나의 음운론적 단어라고 볼 수 있습니다. 하지만 동사의 활용형에 의존명사와 보조용언이 각각 붙어있으므로 '먹을 것', '먹어 보다' 모두 두 개의 문법적 단어로 구성되어 있는 셈입니다. 이처럼 단어 개념은 복잡 오묘하기 때문에 분석에 주의를 기울여야 합니다.
unsugen␞ 이번 글에서는 비지도학습(unsupervised learning) 기반의 **generative model**을 가우시안믹스처모델(Gaussian Mixture Model, GMM) 중심으로 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## generative model *generative model*이란 데이터 $X$가 생성되는 과정을 두 개의 확률모형, 즉 $p(Y)$, $p(X$\|$Y)$으로 정의하고, 베이즈룰을 사용해 $p(Y$\|$X)$를 간접적으로 도출하는 모델을 가리킵니다. *generative model*은 레이블 정보가 있어도 되고, 없어도 구축할 수 있습니다. 이 글에서는 레이블 정보 없이 구축하는 비지도학습 기반의 *generative model*을 살펴보겠습니다.   ## Gaussian Mixtrue Model GMM은 [선형판별분석]()의 일반화된 버전입니다. GMM을 *generative modeling* 관점에서 분석하면 다음과 같습니다.   $$ p\left( { z }^{ (i) } \right) \sim Multinomial(\phi )\\ p\left( { x }^{ (i) }|{ z }^{ (i) }=j \right) \sim N\left( { \mu }_{ j },{ \Sigma }_{ j } \right) $$  선형판별분석과 가장 큰 차이점은 레이블 $y$가 없는 비지도학습이라는 사실입니다. $y$ 대신 $z$가 등장했습니다. 그런데 $z$는 학습데이터로 주어지지 않은 잠재변수(latent variable)입니다. $z$는 [다항분포](https://ratsgo.github.io/statistics/2017/05/28/binomial/)를 따른다고 가정합니다. 이렇게 뽑힌 $z$가 $j$번째 id일 때 $x$가 나타날 확률은 $j$번째 평균과 분산을 모수로 갖는 정규분포를 따를 것이라 가정합니다. GMM의 로그우도 함수는 다음과 같습니다. 단 여기에서 파라메터 $θ$는 (1)$z$와 관련된 다항분포 파라메터 $Φ$ (2)각 정규분포의 평균 $μ$ (3)정규분포의 분산 $Σ$ 세 가지를 가리킵니다.   $$ \begin{align*} l(\theta )=\sum _{ i }^{ }{ \log { \sum _{ { z }_{ i } }^{ }{ p\left( { x }^{ i },{ z }^{ i },\theta \right) } } } \end{align*} $$  $z$가 학습데이터로 주어진 상황이라면, 우리가 구하고자 하는 각각의 파라메터들에 대해 위 로그우도 함수를 편미분한 결과가 0인 지점에서, 쉽게 파라메터를 추정할 수 있을 것입니다. 그러나 $z$는 잠재변수이기 때문에 위의 로그우도 함수를 최대화하는 파라메터를 단박에 구할 수 없습니다. 이 때문에 **EM 알고리즘**을 다음과 같이 적용합니다. - **Expectation** : 로그우도 함수값의 하한(lower bound)을 구한다. - **Maximization** : E-step에서 구한 로그우도 함수값을 최대화하는 파라메터를 찾는다. 그렇다면 로그우도 함수의 하한은 어떻게 구할까요? **Jensen's inequality**를 이용해 봅시다. 임의의 함수 $f$가 [볼록함수(convex function)](https://ratsgo.github.io/convex%20optimization/2017/12/26/convexfunction/)이고 $x$가 확률변수(random variable)이면 다음이 성립한다고 합니다.  $$ E\left[ f\left( x \right) \right] \ge f\left( E\left[ x \right] \right) $$ <a href="https://imgur.com/5HREVDw"><img src="https://i.imgur.com/5HREVDw.png" width="350px" title="source: imgur.com" /></a>  그런데 로그 함수($f$)는 오목함수(concave function)이므로 위의 부등식 방향이 반대로 적용될 겁니다. 또 여기에서 $z^i$에 대한 임의의 확률분포 $Q_i(z^i)$를 상정해 둡시다. Jensen's inequality와 $Q$를 활용해 GMM의 로그우도함수를 다음과 같이 다시 적을 수 있습니다.  $$ \begin{align*} l(\theta )=&\sum _{ i }^{ }{ \log { \sum _{ { z }_{ i } }^{ }{ p\left( { x }^{ i },{ z }^{ i },\theta \right) } } } \\ =&\sum _{ i }^{ }{ \log { \sum _{ { z }_{ i } }^{ }{ { Q }_{ i }\left( { z }^{ i } \right) \frac { p\left( { x }^{ i },{ z }^{ i },\theta \right) }{ { Q }_{ i }\left( { z }^{ i } \right) } } } } \\ \ge& \sum _{ i }^{ }{ \sum _{ { z }_{ i } }^{ }{ { Q }_{ i }\left( { z }^{ i } \right) \log { \frac { p\left( { x }^{ i },{ z }^{ i },\theta \right) }{ { Q }_{ i }\left( { z }^{ i } \right) } } } } \end{align*} $$  그런데 실제 로그우도는 $Q_i$와 상관이 없기 때문에 가급적 위 부등식이 '='에 가깝게 정할 수 있으면 좋을 겁니다. Jensen's inequality에서 등호는 $f(x)$가 선형(linear)일 때 성립한다고 합니다. 아울러 $Q_i$ 또한 확률분포이므로 그 합이 1이 되어야 합니다. 따라서 다음 두 가지 속성을 만족하도록 $Q_i$를 정하면 좋을 겁니다.  $$ \frac { p\left( { x }^{ i },{ z }^{ i },\theta \right) }{ { Q }_{ i }\left( { z }^{ i } \right) } =c\leftrightarrow { Q }_{ i }\left( { z }^{ i } \right) \propto p\left( { x }^{ i },{ z }^{ i },\theta \right) \\ \sum _{ z }^{ }{ { Q }_{ i }\left( { z } \right) } =1 $$  그런데 $Q_i$를 $z$에 대한 사후확률(posterior)로 정하면 위 두 개 가정을 만족시킬 수 있다고 합니다. 다시 말해 $Q_i(z^i)=p(x^i,z^i,θ)/p(x^i,θ)=p(z^i$\|$x^i,θ)$로 둡니다. 요컨대 GMM의 EM 알고리즘은 고정된 $θ$ 하에서 $Q_i(z^i)$를 구하고, E-step에서 구한 $Q_i(z^i)$ 하에서 로그우도 함수를 최대화하는 $θ$를 구하는 과정을 반복합니다. 이와 관련해 고려대 강필성 교수님의 비즈니스어낼리틱스 강의노트를 참고용으로 올려둡니다.  <a href="https://imgur.com/bv462aT"><img src="https://i.imgur.com/bv462aT.png" title="source: imgur.com" /></a>   ## Latent Dirichlet Allocation 일명 토픽모델링으로도 유명한 [잠재디리클레할당(Latent Dirichlet Allocation, LDA)](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/06/01/LDA/) 또한 비지도학습 기반의 *generative model*입니다. LDA가 가정하는 문서생성과정은 다음과 같습니다.  - Draw each per-corpus topic distributions $ϕ_k$~$Dir(β)$ for $i∈${$1,2,...K$} - For each document, Draw per-document topic proportions $θ_d$~$Dir(α)$ - For each document and each word, Draw per-word topic assignment $z_{d,n}$~$Multi(θ_d)$ - For each document and each word, Draw observed word $w_{d,n}$~$Multi(ϕ_{z_{d,n},n})$  LDA에서는 파라메터 추정 과정에서 [켤레사전분포](https://ratsgo.github.io/statistics/2017/05/28/binomial/)를 가정하고, [깁스 샘플링](https://ratsgo.github.io/statistics/2017/05/31/gibbs/)을 사용합니다.
gan␞ 이번 글에서는 **Generative Adversarial Network**(이하 GAN)에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept Ian Goodfellow가 2014년 제안한 GAN은 생성자(generator, $G$)와 구분자(discirimiator, $D$), 두 네트워크를 적대적(adversarial)으로 학습시키는 비지도 학습 기반 생성모델(unsupervised generative model)입니다. $G$는 *Zero-Mean Gaussian*으로 생성된 $z$를 받아서 실제 데이터와 비슷한 데이터를 만들어내도록 학습됩니다. $D$는 실제 데이터와 $G$가 생성한 가짜 데이터를 구별하도록 학습됩니다. GAN의 궁극적인 목적은 [실제 데이터의 분포](https://ratsgo.github.io/generative%20model/2017/12/17/compare/)에 가까운 데이터를 생성하는 것입니다. GAN을 도식화한 그림은 다음과 같습니다.  <a href="https://imgur.com/6ZPdsM8"><img src="https://i.imgur.com/6ZPdsM8.png" width="500px" title="source: imgur.com" /></a>   ## 목적함수 GAN의 목적함수는 다음과 같습니다. 게임이론 타입의 목적함수로 두 명의 플레이어($G$와 $D$)가 싸우면서 서로 균형점(nash equilibrium)을 찾아가도록 하는 방식입니다.  $$ \min _{ G }{ \max _{ D }{ V\left( D,G \right) } } ={ E }_{ x\sim { p }_{ data }\left( x \right) }\left[ \log { D\left( x \right) } \right] +{ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ \log { \left\{ 1-D\left( G\left( z \right) \right) \right\} } \right] $$  우선 $D$ 입장에서 살펴보겠습니다. 실제 데이터($x$)를 입력하면 높은 확률이 나오도록 하고($D(x)$를 높임), 가짜 데이터($G(z)$)를 입력하면 확률이 낮아지도록($1-D(G(z))$를 낮춤=$D(G(z))$를 높임) 학습됩니다. 다시 말해 $D$는 실제 데이터와 $G$가 만든 가상데이터를 잘 구분하도록 조금씩 업데이트됩니다. 이번엔 $G$를 살펴보겠습니다. *Zero-Mean Gaussian*으로 뽑은 노이즈 $z$를 받아 생성된 가짜 데이터($G(z)$)를 $D$에 넣었을 때, 실제 데이터처럼 확률이 높게 나오도록($1-D(G(z))$를 높임=$D(G(z))$를 낮춤) 학습됩니다. 다시 말해 $G$는 $D$가 잘 구분하지 못하는 데이터를 생성하도록 조금씩 업데이트됩니다. 실제 학습을 진행할 때는 두 네트워크를 동시에 학습시키지 않고 따로따로 업데이트를 합니다. $D$를 학습시킬 때는 $G$를 고정한 상태에서, $G$를 학습시킬 때는 $D$를 고정한 상태에서 진행한다는 이야기이죠.  우선 $D$를 학습하기 위한 목적함수는 다음과 같이 다시 쓸 수 있습니다. 즉 $G$의 파라메터를 고정한 상태에서 실제 데이터 $m$개, $G$가 생성한 가짜 데이터 $m$개를 $D$에 넣고 $V$를 계산한 뒤, $D$에 대한 $V$의 그래디언트를 구하고 $V$를 높이는 방향으로 $D$의 파라메터를 업데이트합니다.  $$ \begin{align*} \max _{ D }{ V\left( D \right) } =&{ E }_{ x\sim { p }_{ data }\left( x \right) }\left[ \log { D\left( x \right) } \right] +{ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ \log { \left\{ 1-D\left( z \right) \right\} } \right] \\ =&\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ \log { D\left( { x }^{ i } \right) } } +\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ \log { \left\{ 1-D\left( G\left( { z }^{ i } \right) \right) \right\} } } \end{align*} $$  $G$의 목적함수는 다음과 같습니다. $D$의 파라메터를 고정한 상태에서 가짜 데이터 $m$개를 생성해 $V$을 계산한 뒤, $G$에 대한 $V$의 그래디언트를 구하고 $V$를 낮추는 방향으로 $G$의 파라메터를 업데이트합니다.  $$ \begin{align*} \min _{ G }{ V\left( G \right) } =&{ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ \log { \left\{ 1-D\left( G\left( z \right) \right) \right\} } \right] \\ =&\frac { 1 }{ m } \sum _{ j=1 }^{ m }{ \log { \left\{ 1-D\left( G\left( { z }^{ j } \right) \right) \right\} } } \end{align*} $$  학습 초기에 $G$가 생성하는 데이터의 품질은 조악할 것입니다. 이 경우 $D$는 확실하게 가짜 데이터라고 잘 구분하게 되겠죠. $D(G(z))$가 0에 가까울 것이라는 이야기입니다.  그런데 목적함수를 잘 보면 *expectation* 안쪽이 $\log{(1-x)}$ 꼴임을 알 수 있습니다. 이 경우 $x$가 0일 때 기울기가 작습니다. 학습 초기 $G$의 파라메터를 팍팍 업데이트해줘야 하는데 그러지 못할 가능성이 크다는 말입니다.  이에 $G$의 목적함수를 아래처럼 살짝 바꿔서 초기 $G$ 학습을 가속화합니다. $\log(x)$의 경우 $x$가 0일 때 기울기가 매우 큽니다.  $$ \min _{ G }{ V\left( G \right) } ={ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ \log { \left\{ 1-D\left( G\left( z \right) \right) \right\} } \right] \\ \Rightarrow -{ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ \log { D\left( G\left( z \right) \right) } \right] $$  ## 학습 몇 가지 수식을 통해 GAN 학습 과정을 좀 더 살펴보도록 하겠습니다. 이상적인 경우, 즉 $G$가 매우 학습이 잘 되었다면 $G$가 *Zero-Mean Gaussian*으로 뽑은 노이즈 $z$를 받아 생성한 데이터와 실제 데이터가 일치할 것입니다($G(z)=x$, $p_g(x)=p_{data}(x)$). 이 경우 최적의 구분자 $D$는 다음과 같이 식을 쓸 수 있습니다.  $$ \begin{align*} D^{ * }=&\max _{ D }{ V\left( D \right) } \\ =&{ E }_{ x\sim { p }_{ data }\left( x \right) }\left[ \log { D\left( x \right) } \right] +{ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ \log { \left\{ 1-D\left( G\left( z \right) \right) \right\} } \right] \\ =&{ E }_{ x\sim { p }_{ data }\left( x \right) }\left[ \log { D\left( x \right) } \right] +{ E }_{ x\sim { p }_{ g }\left( x \right) }\left[ \log { \left\{ 1-D\left( x \right) \right\} } \right] \\ =&\int _{ x }^{ }{ { p }_{ data }\left( x \right) \log { D\left( x \right) } dx } +\int _{ x }^{ }{ { p }_{ g }\left( x \right) \log { \left\{ 1-D\left( x \right) \right\} } dx } \\ =&\int _{ x }^{ }{ { p }_{ data }\left( x \right) \log { D\left( x \right) } +{ p }_{ g }\left( x \right) \log { \left\{ 1-D\left( x \right) \right\} } dx } \end{align*} $$  위 식이 최대화되는 지점은 위 식을 우리가 알고자 하는 $D(x)$로 미분한 값이 0이 되는 지점입니다. 식을 $D(x)$로 미분한 결과를 0으로 만든 식을 $D(x)$로 정리하면 다음과 같습니다. 아래 식에 원래 가정($p_g(x)=p_{data}(x)$)을 대입해 풀면 최적의 구분자 $D$는 1/2로 수렴합니다.  $$ D^{ * }\left( x \right)=\frac { { p }_{ data }\left( x \right) }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) } $$  $D$는 데이터 $x$가 주어졌을 때 실제 데이터($y=1$)일 확률을 의미합니다. 이를 베이즈룰을 이용해 정리하면 최적의 $D$는 사전확률 $p(y=1)$와 $p(y=0)$이 1/2로 서로 같을 때 도출됩니다.  $$ \begin{align*} p\left( y=1|x \right) =&\frac { p\left( x,y=1 \right) }{ p\left( x \right) } \\ =&\frac { p\left( x,y=1 \right) /p\left( y=1 \right) }{ \left\{ p\left( x,y=1 \right) +p\left( x,y=0 \right) \right\} /p\left( y=1 \right) } \\ =&\frac { p\left( x|y=1 \right) }{ p\left( x|y=1 \right) +p\left( x|y=0 \right) } \\ =&\frac { p\left( x|y=1 \right) { 1 }/{ 2 } }{ p\left( x|y=1 \right) { 1 }/{ 2 }+p\left( x|y=0 \right) { 1 }/{ 2 } } \\ =&\frac { p\left( x|y=1 \right) p\left( y=1 \right) }{ p\left( x|y=1 \right) p\left( y=1 \right) +p\left( x|y=0 \right) p\left( y=0 \right) } \end{align*} $$  GAN의 목적함수를 최적의 구분자 $D$를 전제하고 식을 정리하면 다음과 같습니다. 다시 말해 최적의 $D$가 전제된 상황이라면 GAN의 목적함수를 최적화하는 과정은 $p_{data}$와 $p_g$ 사이의 [젠슨-섀넌 다이버전스(Jensen-Shannon divergence)](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence)를 최소화하는 것과 같습니다. 젠슨-섀넌 다이버전스는 두 확률 분포 간 차이를 재는 함수의 일종인데요. **데이터의 분포와 $G$가 생성하는 분포 사이의 차이를 줄인다**고 해석할 수 있습니다.  $$ \begin{align*} \min _{ G }{ V\left( { D }^{ * },G \right) } =&{ E }_{ x\sim { p }_{ data }\left( x \right) }\left[ \log { { D }^{ * }\left( x \right) } \right] +{ E }_{ x\sim { p }_{ g }\left( x \right) }\left[ \log { \left\{ 1-{ D }^{ * }\left( x \right) \right\} } \right] \\ =&{ E }_{ x\sim { p }_{ data }\left( x \right) }\left[ \log { \frac { { p }_{ data }\left( x \right) }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) } } \right] +{ E }_{ x\sim { p }_{ g }\left( x \right) }\left[ \log { \frac { { p }_{ g }\left( x \right) }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) } } \right] \\ =&\int _{ x }^{ }{ { p }_{ data }\left( x \right) \log { \frac { { p }_{ data }\left( x \right) }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) } } dx } +\int _{ x }^{ }{ { p }_{ g }\left( x \right) \log { \frac { { p }_{ g }\left( x \right) }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) } } dx } \\ =&-\log { 4 } +\int _{ x }^{ }{ { p }_{ data }\left( x \right) \log { \frac { 2\cdot { p }_{ data }\left( x \right) }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) } } dx } +\int _{ x }^{ }{ { p }_{ g }\left( x \right) \log { \frac { 2\cdot { p }_{ g }\left( x \right) }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) } } dx } \\ =&-\log { 4 } +\int _{ x }^{ }{ { p }_{ data }\left( x \right) \log { \frac { { p }_{ data }\left( x \right) }{ \frac { { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) }{ 2 } } } dx } +\int _{ x }^{ }{ { p }_{ g }\left( x \right) \log { \frac { { p }_{ g }\left( x \right) }{ \frac { { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) }{ 2 } } } dx } \\ =&-\log { 4 } +KLD\left( { p }_{ data }\left( x \right) ||\frac { { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) }{ 2 } \right) +KLD\left( { p }_{ g }\left( x \right) ||\frac { { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right) }{ 2 } \right) \\ =&-\log { 4 } +2\cdot JSD\left( { p }_{ data }\left( x \right) ||{ p }_{ g }\left( x \right) \right) \end{align*} $$  GAN의 학습과정을 도식화한 그림은 다음과 같습니다. 학습이 진행될 수록 $p_g$(녹색 실선)는 $p_{data}$(검정 점선), $D$(파란 점선)는 1/2로 수렴하는 것을 확인할 수 있습니다.  <a href="https://imgur.com/m4EiZPk"><img src="https://i.imgur.com/m4EiZPk.png" width="600px" title="source: imgur.com" /></a>    ## 단점과 극복방안 GAN의 이론적 배경은 탄탄하지만, 실제 적용에는 많은 문제가 있습니다. 대표적으로 학습이 어렵다는 점을 꼽을 수 있겠습니다. 차례대로 살펴보겠습니다.  ### mode collapsing *mode collapsing*이란 우리가 학습시키려는 모형이 실제 데이터의 분포를 모두 커버하지 못하고 다양성을 잃어버리는 현상을 가리킵니다. 그저 손실(loss)만을 줄이려고 학습을 하기 때문에 $G$가 전체 데이터 분포를 찾지 못하고, 아래 그림처럼 한번에 하나의 *mode*에만 강하게 몰리게 되는 경우입니다. 예컨대 MNIST를 학습한 $G$가 특정 숫자만 생성한다든지 하는 사례가 바로 여기에 속합니다.   <a href="https://imgur.com/l9sDQK6"><img src="https://i.imgur.com/l9sDQK6.png" width="500px" title="source: imgur.com" /></a>  ### 진동 $G$와 $D$가 서로 진동하듯 수렴하지 않는 문제 역시 *mode collapsing* 문제와 관련이 있습니다. <a href="https://imgur.com/AkrWyyG"><img src="https://i.imgur.com/AkrWyyG.png" title="source: imgur.com" /></a>   ### mode collapsing 해결방안 *mode collapsing* 해결방안 가운데 간단하면서 효과적인 것으로 알려진 세 가지는 다음과 같습니다. 모델이 전체 데이터 분포의 경계를 골고루 학습하게 하고, 그것을 계속 기억할 수 있도록 하는 것이 핵심입니다. - **feature matching** : 가짜 데이터와 실제 데이터 사이의 *least square error*를 목적함수에 추가 - **mini-batch discrimination** : 미니배치별로 가짜 데이터와 실제 데이터 사이의 거리 합의 차이를 목적함수에 추가 - **historical averaging** : 배치 단위로 파라메터를 업데이트하면 이전 학습은 잘 잊히게 되므로, 이전 학습 내용을 기억하는 방식으로 학습   ### 힘의 균형 $D$보다 $G$를 학습시키는 것이 일반적으로 어렵습니다. $G$가 학습이 잘 안되어서 둘 사이의 힘의 균형이 깨지는 경우 GAN 학습이 더 이상 진전될 수 없습니다. GAN 연구 초기에는 $G$를 $k$번 업데이트시키고, $D$를 한번 업데이트시키거나, 목적함수 비율을 조절하는 등 밸런스를 맞추기 위해 다양한 방식을 시도하였으나 뾰족한 대안이 되진 못했습니다. 그러나 최근엔 LSGAN, WGAN, F-GAN, EBGAN 등 손실함수를 바꿔서 이 문제를 해결한 연구가 여럿 제안되었습니다.  ### 평가 GAN은 데이터 생성이 목적이기 때문에 정량적인 평가가 어렵습니다. 그럼에도 다음과 같은 세 가지 방식이 널리 쓰입니다. - **정성평가** : 사람이 직접 평가 - **학습된 분류기를 이용** : 기존 뉴럴네트워크를 활용해 *label*이 있는 데이터 셋을 학습시킨다. 동일한 데이터로 GAN을 학습한 후 $G$를 이용해서 새로운 데이터를 생성하고 미리 학습시켜둔 분류기 모델에 넣어 분류를 시행한다. 이 때 (1)생성된 새로운 데이터가 한 범주에 높은 확률로 분류되거나 (2)전체적으로 다양한 범주의 데이터가 생성됐다면 GAN의 성능을 높다고 평가할 수 있다. - **inception score** : $G$가 생성한 데이터의 다양성(개성)을 측정하는 지표로 클 수록 좋다. 
RNTN␞ 이번 글에서는 **Recursive Neural Tensor Network(RNTN)**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의를 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 문제 및 데이터 RNTN은 **Recursive Neural Networks**의 발전된 형태로 [Socher et al.(2013)](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)이 제안한 모델입니다. RNTN의 입력값은 다음과 같이 문장이 단어, 구(phrase) 단위로 **파싱(parsing)**되어 있고 단어마다 긍정, 부정 **극성(polarity)**이 태깅돼 있는 형태입니다. 극성이라는 레이블 정보가 주어져 있는 파싱 트리를 기반으로 단어나 구를 벡터로 임베딩하고, 이 벡터를 기반으로 레이블을 예측하는 모델이 바로 RNTN입니다.  <a href="http://imgur.com/lMRWvaj"><img src="http://i.imgur.com/lMRWvaj.png" width="400px" title="source: imgur.com" /></a>  ## Simple Recursive Neural Network RNTN 아키텍처를 살펴보려면 간단한 형태의 Recursive Neural Network를 먼저 살펴보는 것이 좋겠습니다. 아키텍처를 단순화한 그림은 다음과 같습니다. 'very good'처럼 문법적, 의미적 응집성이 높은 입력값을 트리 형태로 결합하는 것이 Recursive Neural Network의 특징입니다.  <a href="http://imgur.com/fIfsMgi"><img src="http://i.imgur.com/fIfsMgi.png" width="300px" title="source: imgur.com" /></a>  Recursive Neural Network는 **left child node**와 **right child node**를 결합해 **parent node**를 만듭니다. 위 예시 그림 기준으로는 very와 good을 결합해 $p_1$을 만들고, 다시 not과 $p_1$을 결합해 $p_2$를 만드는 방식입니다. Recursive Neural Network의 **순전파(feedforward propagation)** 수식은 다음과 같습니다.  $$ { p }_{ 1 }=g\left( W\begin{bmatrix} b \\ c \end{bmatrix} \right) ,\quad { p }_{ 2 }=g\left( W\begin{bmatrix} b \\ { p }_{ 1 } \end{bmatrix} \right) $$  $[b,c]^T$는 $b$라는 left child node와 $c$라는 right child node를 위, 아래로 붙인(concatenate) 벡터로 left, right child node가 $R^d$차원의 벡터라면 이 둘이 합쳐진 $[b,c]^T$는 $R^{2d}$차원 벡터가 됩니다. 한편 parent node는 $R^d$차원이 되는데요. parent node는 $p_1$처럼 또 다른 child node가 될 수 있기 때문입니다.  $g$는 보통 **하이퍼볼릭탄젠트**를 쓰는데 **비선형성(non-linearity)**을 확보할 수 있는 다른 종류의 함수를 쓸 수도 있다고 합니다. $W$는 $d$ x $2d$ 크기의 행렬로 단어나 node 종류에 관계 없이 그 값을 공유합니다.   ## Matrix-Vector RNN **Matrix-Vector Recursive Neural Network(MV-RNN)**은 simple RNN과 달리 결합하는 단어가 다르면 그 결합 과정 또한 다를 것이라는 전제가 깔려 있는 기법입니다. 그도 그럴 것이 개별 단어는 문법적, 어휘적 성질이 각기 다르고 결합시 구성요소가 다르면 그 합성물 또한 합성의 화학구조가 달라질 것이기 때문에 이러한 특성을 반영하는 것이 어쩌면 당연할 수 있겠습니다. MV-RNN을 단순화한 그림은 다음과 같습니다.  <a href="http://imgur.com/YCem2Rf"><img src="http://i.imgur.com/YCem2Rf.png" width="300px" title="source: imgur.com" /></a>  위 그림에서 $b$는 left child node의 $R^d$차원 단어 벡터입니다. $B$는 이 벡터에 해당하는 $R^{d×d}$ 크기의 행렬입니다. 예컨대 simple RNN 예시 그림 기준으로 보면 $b$는 very에 해당하는 2차원 벡터, $B$는 이 벡터에 해당하는 행렬이 됩니다. MV-RNN에서는 모든 단어, 모든 parent node에 대해 이러한 행렬을 설정해 둡니다. 다시 말해 $p_1$은 $b$와 $c$로 만들어진 parent node라 할 때 $p_1$에 해당하는 행렬 $P_1$도 만든다는 얘기입니다. MV-RNN의 순전파 수식은 다음과 같습니다.  $$ { p }_{ 1 }=g\left( W\begin{bmatrix} Cb \\ Bc \end{bmatrix} \right) ,\quad P_{ 1 }=g\left( { W }_{ M }\begin{bmatrix} B \\ C \end{bmatrix} \right) $$  parent node vector $p_1$을 만드는 과정 먼저 보겠습니다. 우선 left child에 해당하는 단어벡터 $b$에 right child의 행렬 $C$를 내적합니다. right child에 해당하는 단어벡터 $c$에 left child의 행렬 $C$를 내적합니다. 이 결과물에 parent node vector로 합쳐주는 역할을 하는 $W$를 내적하고 비선형성을 획득하는 과정은 simple RNN과 동일합니다.  이번엔 parent node matrix $P_1$을 만드는 과정입니다. left child의 행렬 $B$에 right chlid의 행렬 $C$를 합친 후 parent node matrix로 합쳐주는 역할을 하는 $W_M$를 내적하고 비선형성을 부여한 뒤 $P_1$을 생성합니다. 그러면 각 요소별 차원수를 살펴보겠습니다. parent node vector $p_1$는 $R^d$ 차원의 벡터, $W$는 $R^{d×2d}$ 크기의 행렬입니다. parent node matrix $P_1$은 $R^{d×d}$ 크기의 행렬이며, $W_M$은 $R^{d×2d}$ 크기의 행렬입니다.   ## RNTN MV-RNN은 RNTN의 계산복잡성을 완화하기 위해 제안된 기법입니다. MV-RNN은 말뭉치에 등장하는 모든 단어와 결합 가능한 모든 경우의 수에 해당하는 parent node에 대해 $R^{d×d}$ 크기의 행렬을 생성하기 때문에 꽤 비용이 높은 알고리즘입니다. 이를 개선하기 위해 RNTN은 Tensor 개념을 도입합니다. 이를 단순화한 그림은 다음과 같습니다.  <a href="http://imgur.com/Dlzg9QR"><img src="http://i.imgur.com/Dlzg9QR.png" width="300px" title="source: imgur.com" /></a>  RNTN은 모든 단어와 parent node에 대해 relational matrix를 생성하는 대신 모든 단어와 parent node가 공유하는 Tensor를 설정하는데요. 위 그림에서 $V$가 Tensor를 의미합니다. 그림을 보시면 이 텐서는 2층짜리 행렬이라고 보시면 됩니다. 위, 아래가 겹친 형태라 어쩔 수 없이 둘로 나누어 그려진 걸 확인할 수 있습니다. RNTN의 순전파 수식은 다음과 같습니다.  $$ p=g\left( { \begin{bmatrix} b \\ c \end{bmatrix} }^{ T }{ V }^{ [1:d] }\begin{bmatrix} b \\ c \end{bmatrix}+W\begin{bmatrix} b \\ c \end{bmatrix} \right) $$  이해를 돕기 위해 1층 텐서만 살펴보겠습니다. 그림을 보시면 left child node에 해당하는 단어벡터 $b$와 right child node의 $c$의 차원수는 $R^d$(=2차원)입니다. 1층 텐서의 차원수는 $R^{2d×2d}$입니다. 따라서 Slice of Tensor Layer 가운데 1층의 결과물은 스칼라값 하나가 나오게 됩니다($[b,c]∈R^{1×2d}$, $V∈R^{2d×2d}$, $[b,c]^T∈R^{2d×1}$). 이를 확장해 텐서가 $d$층이라고 가정하면 Slice of Tensor Layer를 계산한 결과는 $R^d$차원의 벡터가 됩니다. 이는 $W$에 $[b,c]^T$를 내적한 Standard Layer의 차원수와 같습니다.  ## Softmax layer 앞서 데이터를 설명해드렸던 것처럼 입력문장엔 모든 단어, 구에 극성 레이블이 태깅돼 있습니다. 단어, 구 단위 분류 문제를 푸는 것과 같다는 얘기입니다. 예컨대 레이블 범주가 긍정, 부정, 중립 3가지라면 3범주 분류 문제가 됩니다. Simple Recursive Neural Network이든, MV-RNN이든, RNTN이든 동일한 Softmax Layer를 씁니다. 식은 다음과 같습니다.  $$ { y }^{ word }=softmax({ W }_{ S }\cdot word) $$  $word$는 $R^d$차원 벡터입니다. 만약 이 $word$가 말단의 child node라면 단어에 해당하는 벡터가 될 것이고 임의의 parent node라면 구로 추상화된 벡터가 될 것입니다. $W_S$의 차원수는 $R^{C×d}$가 됩니다. 여기에서 $C$는 범주 개수입니다. 위 수식의 결과물인 $y^{word}$는 $R^C$차원 벡터가 됩니다. 범주 수만큼의 확률값들이 존재하는 셈이지요. 이를 정답 레이블과 비교해 크로스 엔트로피 오차를 구하고 역전파를 수행해 전체 네트워크를 학습하는 구조입니다.   ## 기법별 학습파라메터 비교 이번에는 기법별로 학습파라메터가 어떻게 다른지 비교해보겠습니다. MV-RNN이 학습파라메터 종류가 많고 크기가 제일 큽니다. simple RNN은 가장 적고, RNTN은 둘의 중간 정도됩니다. | 구분         | simple Recursive Neural Network | MV-RNN                  | RNTN             | | ------------------ | ------------------------------- | ---------------------------------------- | ---------------------------- | | Word Vector    | $d×1$              | $d×1$                  | $d×1$            | | Softmax $W_S$   | $C×d$              | $C×d$                  | $C×d$            | | Compostion Weights | $W:d×2d$            | $W:d×2d$,  $W_M:d×2d$,$A,B,C...:d×d×$\|$v$\| | $W:d×2d$,$V^{[1:d]}:2d×2d×d$ |
gans␞ 이번 글에서는 **Generative Adversarial Network**(이하 GAN)의 발전된 모델들에 대해 살펴보도록 하겠습니다. GAN은 학습이 어려운 점이 최대 단점으로 꼽히는데, 아키텍처나 목적함수를 바꿔서 성능을 대폭 끌어올린 모델들입니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## vanilla GAN [GAN](https://ratsgo.github.io/generative%20model/2017/12/20/gan/)이란 생성자(generator, $G$)와 구분자(discirimiator, $D$), 두 네트워크를 적대적(adversarial)으로 학습시키는 비지도 학습 기반 생성모델(unsupervised generative model)입니다. $G$는 *Zero-Mean Gaussian*으로 생성된 노이즈 $z$를 받아서 실제 데이터와 비슷한 데이터를 만들어내도록 학습됩니다. $D$는 실제 데이터와 $G$가 생성한 가짜 데이터를 구별하도록 학습됩니다. GAN의 궁극적인 목적은 [실제 데이터의 분포](https://ratsgo.github.io/generative%20model/2017/12/17/compare/)에 가까운 데이터를 생성하는 것입니다. GAN을 도식화한 그림은 다음과 같습니다. <a href="https://imgur.com/jNAXwhE"><img src="https://i.imgur.com/jNAXwhE.png" width="200px" title="source: imgur.com" /></a> GAN의 목적함수는 다음과 같습니다. 게임이론 타입의 목적함수로 두 명의 플레이어($G$와 $D$)가 싸우면서 서로 균형점(nash equilibrium)을 찾아가도록 하는 방식입니다.  $$ \min _{ G }{ \max _{ D }{ V\left( D,G \right) } } ={ E }_{ x\sim { p }_{ data }\left( x \right) }\left[ \log { D\left( x \right) } \right] +{ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ \log { \left\{ 1-D\left( G\left( z \right) \right) \right\} } \right] $$  실제 학습을 진행할 때는 두 네트워크를 동시에 학습시키지 않고 따로따로 업데이트를 합니다. 각각의 목적함수는 다음과 같습니다.  $$ \begin{align*} \max _{ D }{ V\left( D \right) } =&{ E }_{ x\sim { p }_{ data }\left( x \right) }\left[ \log { D\left( x \right) } \right] +{ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ \log { \left\{ 1-D\left( z \right) \right\} } \right] \\ =&\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ \log { D\left( { x }^{ i } \right) } } +\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ \log { \left\{ 1-D\left( G\left( { z }^{ i } \right) \right) \right\} } } \\ \min _{ G }{ V\left( G \right) } =&{ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ \log { \left\{ 1-D\left( G\left( z \right) \right) \right\} } \right] \\ =&\frac { 1 }{ m } \sum _{ j=1 }^{ m }{ \log { \left\{ 1-D\left( G\left( { z }^{ j } \right) \right) \right\} } } \end{align*} $$   ## DCGAN **Deep Convolutional GAN**(DCGAN)은 GAN을 개선한 모델입니다. GAN은 학습이 어렵다는 점이 최대 단점인데요. DCGAN은 대부분의 상황에서 안정적으로 학습이 되는 아키텍처로, Deep Generative Model 연구는 DCGAN 등장 이전과 이후로 나뉠 정도로 파급력이 컸습니다. DCGAN 이후 소개된 GAN 논문은 DCGAN 아키텍처에서 크게 벗어나지 않습니다. DCGAN 특징과 아키텍처 개요는 다음과 같습니다.  | 구분              | Generator                | Discriminator      | | :---------------------------- | ---------------------------------------- | ------------------------ | | Pooling Layers        | Not Used. But use strided convolutions instead. | same           | | Batch Normalization      | Use except output layer         | Use except input layer  | | Fully connected hidden layers | Not used                 | Not used         | | Activation function      | ReLU for all layers except for the output, which uses Tanh | LeakyReLU for all layers |  <a href="https://imgur.com/Aoe2KSc"><img src="https://i.imgur.com/Aoe2KSc.png" title="source: imgur.com" /></a>    ## disentangled latent code DCGAN 논문에서는 $G$의 인풋 역할을 하는 $z$ 벡터를 활용해 *semantic* 연산이 가능하다는 점을 언급해 주목을 받았습니다. 예컨대 선글라스를 낀 남자들을 발생시키는 $z_1$에 선글라스를 안 낀 남자에 해당하는 $z_2$를 빼고, 여기에 선글라스를 안 낀 여자들을 발생시키는 $z_3$를 더해 선글라스를 낀 여자들과 관련한 사진을 생성한 것입니다. 이밖에 $z$로 *rotation* 등 다양한 효과를 내어서 이목을 사로 잡았습니다.  <a href="https://imgur.com/5TtAY5v"><img src="https://i.imgur.com/5TtAY5v.png" width="400px" title="source: imgur.com" /></a>  하지만 위 그림이 나타내는 바와 같이 $z$가 속한 벡터공간의 각 차원별 특징은 해석하기 어렵습니다(*entangled*). 위의 DCGAN의 경우 생성된 이미지를 사람이 일일이 확인해 찾은 결과입니다. 이후 해석하기 쉬운(*disentangled*) 특징량(*latent code*)에 의존하는 *Deep Generative Model*이 잇달아 제안됐습니다. 앞으로 설명해 드릴 *conditional GAN*, *InfoGAN*, *ACGAN* 등이 바로 여기에 속합니다.   ## conditional GAN *conditional GAN*에서는 $x$뿐 아니라 데이터의 정답 레이블 정보 $y$를 GAN에 적용한 최초의 시도입니다. 아키텍처는 아래 그림과 같습니다. <a href="https://imgur.com/pSICG3J"><img src="https://i.imgur.com/pSICG3J.png" width="200px" title="source: imgur.com" /></a>   <a href="https://imgur.com/OpTO0Z3"><img src="https://i.imgur.com/OpTO0Z3.png" width="400px" title="source: imgur.com" /></a>  *conditional GAN*의 목적함수를 *vanilla GAN*과 비교해서 보면 $y$가 $D$와 $G$에 추가된 것 외에 같은 점을 확인할 수 있습니다.  $$ \min _{ G }{ \max _{ D }{ V\left( D,G \right) } } ={ E }_{ x\sim { p }_{ data }\left( x \right) }\left[ \log { D\left( x,y \right) } \right] +{ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ \log { \left\{ 1-D\left( G\left( z,y \right), y\right) \right\} } \right] $$  *conditional GAN*과 같이 아키텍처를 구성할 경우 *Zero-Mean Gaussian*으로 생성한 $z$와, 우리가 생성하고 싶은 범주의 레이블 정보에 해당하는 벡터 $y$를 함께 넣어 원하는 데이터를 생성할 수 있게 됩니다. $G$는 $z$뿐 아니라 $y$의 정보도 함께 고려하여 데이터를 생성하기 때문에 $z$가 속한 벡터공간을 해석하기 쉬워졌다는 의미로 받아들여도 되지 않을까 싶습니다.   ## semi-supervised GAN *semi-supervised GAN*은 $D$를 *multinomial classifier*로 구성했습니다. 정답이 있는 실제 데이터는 해당 정답을 맞추도록 $D$가 학습됩니다. 정답이 없는 실제 데이터의 경우 *fake*를 제외하고, 거기에 제일 비슷한 범주가 예측되도록 합니다(예컨대 $K$개 범주가 있다면 예측된 범주 y-hat은 {$1,2,...K$} 가운데 하나가 됨). $G$가 생성한 가짜 데이터의 경우 $D$는 *fake class*로 예측하게 됩니다. 이 아키텍처는 레이블 정보가 일부 데이터에 한정된 *semi-supervised* 환경에서 작동할 수 있고, 범주 정보로 $z$ 공간을 해석할 수 있다는 장점이 있습니다.  <a href="https://imgur.com/YgIWCEf"><img src="https://i.imgur.com/YgIWCEf.png" width="200px" title="source: imgur.com" /></a>   ## ACGAN *Auxiliary Classifier GAN(ACGAN)*은 $D$를 두 개의 *classifier*로 구성했습니다. 하나는 데이터가 실제인지 가짜인지 판별합니다. 나머지 하나는 해당 데이터의 범주를 분류합니다. 이 덕분에 *ACGAN*로 생성된 데이터는 다른 분류기에 넣어도 범주 분류가 잘 된다고 합니다. 바꿔 말해 이치에 맞는 데이터를 만들어낼 수 있다는 얘기죠. $G$는 *conditional GAN*처럼 레이블 정보와 $z$를 합쳐 가짜 데이터를 생성합니다. 아키텍처는 다음과 같습니다.  <a href="https://imgur.com/IUR0e8Q"><img src="https://i.imgur.com/IUR0e8Q.png" width="200px" title="source: imgur.com" /></a>  *ACGAN*의 목적함수는 다음과 같습니다. $L_S$는 기존 GAN의 $D$ 목적함수와 동일합니다. 다시 말해 해당 데이터가 진짜인지 가짜인지 판별해내는 것과 관련이 있습니다. $L_D$는 해당 데이터의 범주를 분류하는 것에 해당합니다. $D$는 $L_S+L_C$를, $G$는 $L_C-L_S$를 최대화하도록 학습됩니다.  $$ \begin{align*} &{ L }_{ S }=E\left[ \log { p\left( S=real|{ X }_{ real } \right) } \right] +E\left[ \log { p\left( S=fake|{ X }_{ fake } \right) } \right] \\ &{ L }_{ C }=E\left[ \log { p\left( C=c|{ X }_{ real } \right) } \right] +E\left[ \log { p\left( C=c|{ X }_{ fake } \right) } \right] \end{align*} $$   ## catGAN *categorical GAN(catGAN)*은 다음과 같은 **조건부 엔트로피(conditional entropy)**를 목적함수로 활용합니다.  $$ \begin{align*} H\left( X|Y \right) &\equiv \sum _{ x\in \chi }^{ }{ p\left( x \right) H\left( Y|X=x \right) } \\ &=-\sum _{ x\in \chi }^{ }{ p\left( x \right) \sum _{ y\in \Psi }^{ }{ p\left( y|x \right) \log { p\left( y|x \right) } } } \end{align*} $$  *catGAN*의 학습 목표를 직관적으로 나타낸 그림은 다음과 같습니다. 우선 $D$ 입장에서 살펴보겠습니다. $D$는 다음 세 가지 과업을 잘 수행하도록 학습됩니다. - $(i)$ 실제 데이터($x$)의 경우 $D$ 스스로 범주 구분을 확실하게 한다. 즉 조건부 [엔트로피(entropy)](https://ratsgo.github.io/statistics/2017/09/22/information/) $H[p(y$\|$x,D)$를 최소화한다. - $(ii)$ 가짜 데이터($G(z)$)의 경우 $D$ 스스로 범주 구분을 잘 하지 못하게 한다. 즉 조건부 엔트로피 $H[p(y$\|$x,G(z))$를 최대화한다. - $(iii)$ $D$ 스스로 $N$개 전체 진짜 데이터를 $K$개 범주에 균등하게 할당하도록 한다. 즉 주변확률 엔트로피 $H[p(y$\|$D)]$를 최대화한다. $G$는 다음 두 가지 과업을 잘 수행하도록 학습됩니다. - $(ii)$ 가짜 데이터($G(z)$)라도 $D$가 범주 구분을 확실하게 하도록 한다. 즉 조건부 엔트로피 $H[p(y$\|$x,G(z))$를 최소화한다. - $(iii)$ $D$가 $M$개 전체 가짜 데이터를 $K$개 범주에 균등하게 할당하도록 한다. 즉 주변확률 엔트로피 $H[p(y$\|$D)]$를 최대화한다.  <a href="https://imgur.com/dpr276J"><img src="https://i.imgur.com/dpr276J.png" width="600px" title="source: imgur.com" /></a>  *catGAN*의 목적함수는 다음과 같습니다.  $$ \begin{align*} { L }_{ D }=&\max _{ D }{ { H }_{ \chi }\left[ p\left( y|D \right) \right] -{ E }_{ x\sim \chi }\left[ H\left[ p\left( y|x,D \right) \right] \right] +{ E }_{ z\sim p\left( z \right) }\left[ H\left[ p\left( y|G\left( z \right) ,D \right) \right] \right] } \\ { L }_{ G }=&\min _{ G }{ -H_{ G }\left[ p\left( y|D \right) \right] +{ E }_{ z\sim p\left( z \right) }\left[ H\left[ p\left( y|G\left( z \right) ,D \right) \right] \right] } \end{align*} $$ 위 식 가운데 $L_D$의 우변 두번째 항은 실제로 다음과 같이 계산됩니다. 다시 말해 레이블이 없는 실제 데이터 $N$개를 $D$에 넣고 계산한 조건부 엔트로피를 가리킵니다.  $$ \begin{align*} { E }_{ x\sim \chi }\left[ H\left[ p\left( y|x,D \right) \right] \right] =&\frac { 1 }{ N } \sum _{ i=1 }^{ N }{ H\left[ p\left( y|x,D \right) \right] } \\ =&\frac { 1 }{ N } \sum _{ i=1 }^{ N }{ -\sum _{ k=1 }^{ K }{ p\left( y=k|{ x }^{ i },D \right) \log { p\left( y=k|{ x }^{ i },D \right) } } } \end{align*} $$  레이블이 있는 데이터를 보유하고 있을 경우 위 항과 별도로 아래와 같은 **크로스엔트로피**(cross entropy)를 추가할 수도 있습니다. 다시 말해 *catGAN*은 (*semi*)*supervised learning* 과업 또한 수행할 수 있다는 이야기입니다.  $$ CE\left[ y,p\left( y|x,D \right) \right] =-\sum _{ i=1 }^{ K }{ { y }_{ i }\log { p\left( y={ y }_{ i }|x,D \right) } } $$  $L_D$ 우변 세번째 항은 실제로 다음과 같이 계산됩니다. 모든 $z$에 대해 조건부 엔트로피를 구할 수 없기 때문에 [몬테카를로 방법](https://ratsgo.github.io/statistics/2017/05/31/gibbs/)을 활용합니다. 즉 $p(z)$로부터 $M$개 $z$를 뽑은 뒤 이를 $G$에 넣어 조건부 엔트로피를 구하는 것입니다. 이 다음부터는 위 항 계산 방식과 동일합니다.  $$ { E }_{ z\sim p\left( z \right) }\left[ H\left[ p\left( y|G\left( z \right) ,D \right) \right] \right] \approx \frac { 1 }{ M } \sum _{ i=1 }^{ M }{ H\left[ p\left( y|G\left( { z }^{ i } \right) ,D \right) \right] } $$  주변확률 엔트로피는 다음과 같이 계산합니다.  $$ { H }_{ \chi }\left[ p\left( y|D \right) \right] =H\left[ \frac { 1 }{ N } \sum _{ i=1 }^{ N }{ p\left( y|x^{ i },D \right) } \right] \\ H_{ G }\left[ p\left( y|D \right) \right] \approx H\left[ \frac { 1 }{ M } \sum _{ i=1 }^{ M }{ p\left( y|G\left( { z }^{ i } \right) ,D \right) } \right] $$   ## InfoGAN *Information GAN(InfoGAN)*은 기존 GAN 목적함수에 **상호정보량(mutual information)**을 추가한 형태입니다. 상호정보량이란 두 확률변수들이 얼마나 의존적(*dependent*)인지 측정하는 지표로, 두 확률변수의 독립성을 [쿨백-라이블러 발산(KLD)](https://ratsgo.github.io/statistics/2017/09/23/MLE/)으로 측정합니다. 서로 독립일 경우 그 값이 0이 됩니다.   $$ I\left( X;Y \right) ={ D }_{ KL }\left( p\left( x,y \right) ||p\left( x \right) p\left( y \right) \right) $$   기존 GAN 목적함수를 $V(D,G)$라고 했을 때 *InforGAN*의 목적함수는 다음과 같습니다.  $$ \min _{ G }{ \max _{ D }{ { V }_{ I }\left( D,G \right) } } =V\left( D,G \right) -\lambda I\left( c;G\left( z,c \right) \right) $$   *InfoGAN*에서는 $G$의 입력 노이즈 $z$를 두 개로 분리했습니다. 노이즈 종류에 대한 설명과 아키텍처를 나타낸 그림은 다음과 같습니다.  - $c$ : *latent code*, 즉 설명 가능한 피처(*semantic features*) - $z$ : *incompressible noise*, 즉 나머지 모든 부분   <a href="https://imgur.com/8hxZ3qc"><img src="https://i.imgur.com/8hxZ3qc.png" width="200px" title="source: imgur.com" /></a>  목적함수에서 확인할 수 있듯 $c$와 $G(z,c)$ 사이의 상호정보량을 최대화한다는 것은, $c$에 의존적인 데이터를 $G$가 생성하도록 한다는 의미입니다. 다시 말해 $c$가 변함에 따라 가짜 데이터 또한 여기에 맞춰 바뀔 수 있도록 학습을 진행한다는 겁니다.  그러나 상호정보량을 단박에 최대화하는 것은 어렵습니다. 이에 [변분추론(Variational Inference)](https://ratsgo.github.io/generative%20model/2017/12/19/vi/)을 수행해 $I(c;G(z,c))$의 하한(lower bound)를 구하여 이렇게 구한 하한을 최대화하는 방식으로 학습을 진행하게 됩니다. 구체적인 전개 과정에 대해서는 [이곳](https://i.imgur.com/BAKuCtc.png)을 참고하면 좋을 것 같습니다.   ## Least Squares GAN *vanilla GAN*에서는 $p(x)$와 $p(z)$ 간의 거리를 KLD로 측정했습니다. 그런데 *Least Squares GAN(LSGAN)*은 이름 그대로 거리 측정 지표로 *least Square*를 씁니다. LSGAN의 목적함수는 다음과 같습니다.  $$ \begin{align*} \min _{ D }{ { V }_{ LSGAN }\left( D \right) } =&\frac { 1 }{ 2 } { E }_{ x\sim { p }_{ data }\left( x \right) }\left[ { \left( D\left( x \right) -b \right) }^{ 2 } \right] +\frac { 1 }{ 2 } { E }_{ z\sim { p }_{ z }\left( z \right) }\left[ { \left( D\left( G\left( z \right) \right) -a \right) }^{ 2 } \right] \\ \min _{ G }{ { V }_{ LSGAN }\left( G \right) } =&\frac { 1 }{ 2 } { E }_{ z\sim { p }_{ z }\left( z \right) }\left[ { \left( D\left( G\left( z \right) \right) -c \right) }^{ 2 } \right] \end{align*} $$  목적함수를 이렇게 만들면 $D$는 진짜 데이터 $x$를 입력받았을 때 $b$를 출력하도록, 가짜 데이터 $G(z)$의 경우 $a$가 되도록 합니다. $G$는 $D$가 가짜 데이터를 받았을 때 $c$를 출력하도록 유도합니다. 이 말은 어떤 의미일까요? 다음 그림을 보면서 생각해 보겠습니다.  <a href="https://imgur.com/nQMYfGT"><img src="https://i.imgur.com/nQMYfGT.png" width="400px" title="source: imgur.com" /></a>  위 그림에서 KLD를 거리 함수로 쓰게 되면 진짜 데이터의 분포 중심과 가짜 데이터의 중심이 같아서 더 이상 최적화하기 어렵습니다. 하지만 가짜 데이터들 가운데서도 실제 데이터와 멀리 떨어져 있는 것이 있을 수 있습니다. 예컨대 핑크색 포인트들이 바로 그런 경우입니다. *least Square*를 쓰게 되면 이러한 데이터들도 실제 데이터의 분포 쪽으로 가깝게 끌어올 수 있게 됩니다. *least Square*는 $x$가 *loss*에 대해 *strictly convex*하기 때문(함수 꼴이 빗살무늬 토기 모양의 그림이 됨)에 유일한 최적해를 가지며 이 점 덕분에 LSGAN이 좀 더 안정적인 학습이 가능하다고 합니다.   ## Wasserstein GAN GAN을 학습하면 $G$가 생성하는 분포 $p_g(x)$가 실제 데이터 분포 $p_{data}(x)$에 근사합니다. 그 이유는 최적의 $D$를 가정했을 때 $G$에 대한 GAN의 목적함수는 $p_g(x)$와 $p_{data}(x)$ 사이의 젠슨-섀넌 다이버전스(Jensen Shannon Divergence) 최소화와 동일하기 때문입니다. 이와 관련해서는 [이곳](https://ratsgo.github.io/generative%20model/2017/12/20/gan/)을 참고하시면 좋을 것 같습니다.  어쨌거나 젠슨-섀넌 다이버전스는 두 확률 분포 간 차이를 측정하는 함수인데요. 불행하게도 언제나 잘 작동하는 건 아닙니다. 다음 예시를 보겠습니다.   $$ { p }_{ real }=\left( 0,y \right) ,y\sim U\left[ 0,1 \right] \\ { p }_{ fake }=\left( \theta ,y \right) ,y\sim U\left[ 0,1 \right] $$  <a href="https://imgur.com/c5SoOxZ"><img src="https://i.imgur.com/c5SoOxZ.png" width="300px" title="source: imgur.com" /></a>  다소 극단적인 설정이긴 하지만 위와 같은 상황에서 젠슨-셰넌 다이버전스는 $θ$가 0일 때만 0, $θ$가 0이 아닌 모든 지점에서 $\log2$의 값을 갖습니다. $θ$가 0에 가까울 수록 두 확률 분포 사이의 차이가 줄어드는 건 분명한데 젠슨-섀넌 다이버전스라는 측정 기법은 이러한 변화를 포착해내지 못한다는 뜻이지요. 이것이 GAN 학습이 잘 안되는 한 원인이 될 수 있겠습니다. 그러나 WGAN에서 제시하는 **Wasserstein Distance**(이하 WDist)는 두 분포 간 차이가 \|$θ$\| 꼴이 되어서 이러한 변화 캐치에 능동적입니다. 다음 그림과 같습니다.  <a href="https://imgur.com/xpFHjNu"><img src="https://i.imgur.com/xpFHjNu.png" width="600px" title="source: imgur.com" /></a>   *WDist*를 직관적으로 설명하면 이렇습니다. $P_r$과 $P_θ$ 사이의 *WDist*는 $P_r$을 $P_θ$로 옮길 때 필요한 양과 거리의 곱을 가리킵니다. 산등성이 전체를 옮기는 것 같다고 하여 *Earth Mover Distance*라고도 불립니다.  <a href="https://imgur.com/JQkxQKV"><img src="https://i.imgur.com/JQkxQKV.png" width="500px" title="source: imgur.com" /></a>  하지만 *WDist*를 바로 계산하는 것은 어렵기 때문에 몇 가지 수학적 증명 과정을 통해 *WDist*를 근사하게 됩니다. 결과적으로 도출된 목적함수는 다음과 같습니다.   $$ \begin{align*} &\max _{ D }{ { V }_{ WGAN }\left( D \right) } ={ E }_{ x\sim { p }_{ data }\left( x \right) }\left[ D\left( x \right) \right] -{ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ D\left( G\left( z \right) \right) \right] \\ &\max _{ G }{ { V }_{ WGAN }\left( G \right) } ={ E }_{ z\sim { p }_{ z }\left( z \right) }\left[ D\left( G\left( z \right) \right) \right] \\ &{ \theta }_{ D }\leftarrow clip\left( -0.01,0.01 \right) \end{align*} $$  위 목적함수가 기존 GAN과의 차이를 보이는 점은 다음과 같습니다. - *log(sigmoid(logits))* 대신 *logits*를 그대로 사용한다. - $D$는 임의의 $k$-lipschitz function이어야 한다. 이에 $D$의 모든 파라메터들을 임의의 $[-c,c]$로 클리핑한다. 이 때 $c$는 작은 상수값. WGAN은 거의 모든 GAN 데이터셋에서 학습이 잘 돼 많은 주목을 받았습니다. WGAN은 $D$와 $G$ 사이의 균형 문제를 걱정할 필요 없이 $D$가 수렴할 때까지 학습을 진행해도 될 정도로 안정적이라고 합니다.
MST␞ 이번 글에서는 **최소신장트리(Minimum Spanning Tree, MST)**를 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님과 역시 같은 대학의 김황남 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept `신장트리(Spanning Tree)`란 (1) 원 그래프의 모든 노드를 포함하고 (2) 모든 노드가 서로 연결되어 있으면서 (3) [트리(Tree)](https://ratsgo.github.io/data%20structure&algorithm/2017/10/21/tree/)의 속성을 만족하는 그래프를 가리킵니다. 예컨대 하단 좌측과 같은 원 그래프의 스패닝트리는 하단 우측과 같이 총 8개의 스패닝트리들을 가질 수 있습니다.   <a href="https://imgur.com/xYkNNxl"><img src="https://i.imgur.com/xYkNNxl.png" width="300px" title="source: imgur.com" /></a>  최소신장트리(MST)는 가능한 신장트리 가운데 엣지 가중치의 합이 최소인 신장트리를 말합니다. 예컨대 하단 좌측과 같은 원 그래프의 MST는 하단 우측과 같습니다.  <a href="https://imgur.com/kITm4WO"><img src="https://i.imgur.com/kITm4WO.png" width="400px" title="source: imgur.com" /></a>  MST는 노드 간 연결성을 보장하면서 노드 사이를 잇는 거리/비용 등을 최소로 하는 그래프를 의미하기 때문에 응용 범위가 넓습니다. 이 글에서는 원 그래프에서 MST를 찾아내는 기법인 **크루스칼 알고리즘(Kruskal's algorithm)**과 **프림 알고리즘(Prim's algorithm)**을 살펴보도록 하겠습니다.   ## 크루스칼 알고리즘 크루스칼 알고리즘은 분석 대상 노드에 연결된 엣지 가운데 가중치가 최소인 엣지를 고르되, 이렇게 추가된 엣지로 그래프가 트리 속성이 깨지지 않는지 여부를 체크하는 방식으로 작동합니다. 이때 가중치가 최소인 엣지를 *light edge*, 추가 엣지로도 트리 속성을 만족하고 있다면 해당 엣지를 *safe*하다고 합니다. 요컨대 크루스칼 알고리즘은 *safe*하고 *light*한 엣지를 반복적으로 찾아가는 기법입니다. 크루스칼 알고리즘의 작동 방식을 예시와 함께 보도록 하겠습니다.  크루스칼 알고리즘은 [디스조인트 셋(disjoint set)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/12/disjointset/)을 기본 자료구조로 활용합니다. (a)와 같이 주어진 그래프가 있다고 칩시다. 우선 모든 노드에 대해 `make-set` 연산을 수행합니다. 이후 모든 엣지를 가중치를 기준으로 오름차순 정렬합니다. 결과(MST)로 반환할 $A$는 공집합으로 초기화해 둡니다. 크루스칼 알고리즘은 가중치가 가장 작은 엣지부터 분석하기 때문에 시작노드를 별도로 설정하지 않습니다. (a)를 보겠습니다. 그래프 모든 엣지 가운데 가중치가 최소(1)인 ($h,g$)가 분석 대상입니다. $h$와 $g$가 서로 다른 셋(`find` 연산으로 확인)이기 때문에 트리 속성을 만족(*safe*)합니다. 따라서 $A$에 분석 대상 엣지 ($h,g$)를 추가하고 $h$가 속한 셋과 $g$가 속한 셋을 합칩니다(`Union` 연산). (b)를 봅시다. 남은 엣지 가운데 가중치가 최소(2)인 ($i,c$)가 분석 대상입니다. $i$와 $c$가 서로 다른 셋이기 때문에 트리 속성을 만족(*safe*)합니다. 따라서 $A$에 분석 대상 엣지 ($i,c$)를 추가하고 $i$가 속한 셋과 $c$가 속한 셋을 합칩니다.  <a href="https://imgur.com/fa72pKX"><img src="https://i.imgur.com/fa72pKX.png" title="source: imgur.com" /></a>  (c)를 봅시다. 남은 엣지 가운데 가중치가 최소(2)인 ($g,f$)가 분석 대상입니다. $g$가 속한 셋과 $f$가 속한 셋이 서로 다르기 때문에 트리 속성을 만족(*safe*)합니다. 따라서 $A$에 분석 대상 엣지 ($g,f$)를 추가하고 $g$가 속한 셋과 $f$가 속한 셋을 합칩니다. (d)를 봅시다. 남은 엣지 가운데 가중치가 최소(4)인 ($a,b$)가 분석 대상입니다. $a$가 속한 셋과 $b$가 속한 셋이 서로 다르기 때문에 트리 속성을 만족(*safe*)합니다. 따라서 $A$에 분석 대상 엣지 ($a,b$)를 추가하고 $a$가 속한 셋과 $b$가 속한 셋을 합칩니다.  <a href="https://imgur.com/vUPYpEh"><img src="https://i.imgur.com/vUPYpEh.png" title="source: imgur.com" /></a>  (e)를 봅시다. 남은 엣지 가운데 가중치가 최소(4)인 ($c,f$)가 분석 대상입니다. $c$가 속한 셋과 $f$가 속한 셋이 서로 다르기 때문에 트리 속성을 만족(*safe*)합니다. 따라서 $A$에 분석 대상 엣지 ($c,f$)를 추가하고 $c$가 속한 셋과 $f$가 속한 셋을 합칩니다. (f)를 봅시다. 남은 엣지 가운데 가중치가 최소(6)인 ($i,g$)가 분석 대상입니다. $i$가 속한 셋과 $g$가 속한 셋이 서로 같기 때문에 트리 속성을 만족하지 않습니다. 바꿔 말해 사이클(cycle)이 존재한다는 이야기입니다. 따라서 ($i,g$)는 건너 뜁니다.   <a href="https://imgur.com/zSVoI77"><img src="https://i.imgur.com/zSVoI77.png" title="source: imgur.com" /></a>  (g)를 봅시다. 남은 엣지 가운데 가중치가 최소(7)인 ($c,d$)가 분석 대상입니다. $c$가 속한 셋과 $d$가 속한 셋이 서로 다르기 때문에 트리 속성을 만족(*safe*)합니다. 따라서 $A$에 분석 대상 엣지 ($c,d$)를 추가하고 $c$가 속한 셋과 $d$가 속한 셋을 합칩니다. (h)를 봅시다. 남은 엣지 가운데 가중치가 최소(7)인 ($i,h$)가 분석 대상입니다. $i$가 속한 셋과 $h$가 속한 셋이 서로 같기 때문에 트리 속성을 만족하지 않습니다. 따라서 ($i,h$)는 건너 뜁니다.   <a href="https://imgur.com/HkDdr9M"><img src="https://i.imgur.com/HkDdr9M.png" title="source: imgur.com" /></a>  (i)를 봅시다. 남은 엣지 가운데 가중치가 최소(8)인 ($a,h$)가 분석 대상입니다. $a$가 속한 셋과 $h$가 속한 셋이 서로 다르기 때문에 트리 속성을 만족(*safe*)합니다. 따라서 $A$에 분석 대상 엣지 ($a,h$)를 추가하고 $a$가 속한 셋과 $h$가 속한 셋을 합칩니다. (j)를 봅시다. 남은 엣지 가운데 가중치가 최소(8)인 ($b,c$)가 분석 대상입니다. $b$가 속한 셋과 $c$가 속한 셋이 서로 같기 때문에 트리 속성을 만족하지 않습니다. 따라서 ($b,c$)는 건너 뜁니다.   <a href="https://imgur.com/G4Ey2Ps"><img src="https://i.imgur.com/G4Ey2Ps.png" title="source: imgur.com" /></a>  (k)를 봅시다. 남은 엣지 가운데 가중치가 최소(9)인 ($d,e$)가 분석 대상입니다. $d$가 속한 셋과 $e$가 속한 셋이 서로 다르기 때문에 트리 속성을 만족(*safe*)합니다. 따라서 $A$에 분석 대상 엣지 ($d,e$)를 추가하고 $d$가 속한 셋과 $e$가 속한 셋을 합칩니다. (l)을 봅시다. 남은 엣지 가운데 가중치가 최소(10)인 ($e,f$)가 분석 대상입니다. $e$가 속한 셋과 $f$가 속한 셋이 서로 같기 때문에 트리 속성을 만족하지 않습니다. 따라서 ($e,f$)는 건너 뜁니다.   <a href="https://imgur.com/SuVi2aI"><img src="https://i.imgur.com/SuVi2aI.png" title="source: imgur.com" /></a>  (m)을 봅시다. 남은 엣지 가운데 가중치가 최소(11)인 ($b,h$)가 분석 대상입니다. $b$가 속한 셋과 $h$가 속한 셋이 서로 같기 때문에 트리 속성을 만족하지 않습니다. 따라서 ($b,h$)는 건너 뜁니다.  (n)을 봅시다. 남은 엣지 가운데 가중치가 최소(14)인 ($d,f$)가 분석 대상입니다. $d$가 속한 셋과 $f$가 속한 셋이 서로 같기 때문에 트리 속성을 만족하지 않습니다. 따라서 ($d,f$)는 건너 뜁니다.   <a href="https://imgur.com/hC7BV7y"><img src="https://i.imgur.com/hC7BV7y.png" title="source: imgur.com" /></a>  모든 엣지에 대해 분석을 마쳤으므로 크루스칼 알고리즘 수행을 종료합니다. 크루스칼 알고리즘의 의사코드는 다음과 같습니다.  <a href="https://imgur.com/uJl8xg8"><img src="https://i.imgur.com/uJl8xg8.png" width="400px" title="source: imgur.com" /></a>  크루스칼 알고리즘의 계산복잡성을 따져보겠습니다. 모든 노드에 대해 `Make-Set` 연산을 수행하므로 초기화에 필요한 계산량은 $O(V)$입니다. 이후 엣지를 중심으로 정렬을 수행하므로 현존하는 알고리즘 가운데 가장 성능 좋은 기법을 쓸 경우 그 계산량은 $O(E\lg{E})$입니다.  이제 반복문을 보겠습니다. 셋에 속한 데이터 수가 $n$개일 때 `Find-Set` , `Union` 연산의 계산복잡성은 모두 $O(\lg{n})$이고, 이를 전체 엣지에 대해 반복 수행하므로 반복문에서 필요한 계산량은 $O(E\lg{E})$입니다. 따라서 크루스칼 알고리즘의 전체적인 계산복잡성은 $O(E\lg{E})$가 됩니다.   ## 프림 알고리즘 프림 알고리즘은 *solution set*과 *non-solution set* 사이를 연결하는 엣지 가운데 가중치가 가장 작은 엣지를 하나 뽑고 이 엣지에 연결된 노드와 해당 엣지를 *solution set*에 넣습니다. 아래 그림에서는 $v$와 ($u,v$)를 $S$에 집어넣는다고 보시면 됩니다.  <a href="https://imgur.com/Zj8gpig"><img src="https://i.imgur.com/Zj8gpig.png" width="300px" title="source: imgur.com" /></a>  이를 *solution set*에 모든 노드가 포함될 때까지 반복수행하면 프림 알고리즘이 종료됩니다. 프림 알고리즘을 예시와 함께 살펴보도록 하겠습니다. (a)와 같은 그래프가 주어졌을 때 우선 자료구조를 초기화합니다. (a)를 먼저 보겠습니다. 노드 $a$에 연결된 엣지 가운데 가중치가 4로 가장 작은 엣지 ($a,b$)를 선택합니다. (b)와 같습니다.  <a href="https://imgur.com/DxfGTGu"><img src="https://i.imgur.com/DxfGTGu.png" title="source: imgur.com" /></a>  (c)를 보겠습니다. (b)에서 선택한 엣지와 관계 있는 노드 {$a,b$}에 연결된 엣지들 가운데 가중치가 8로 가장 작은 ($b,c$)를 선택합니다.  (d)를 보겠습니다. (a)와 (b)에서 선택한 엣지와 관계 있는 노드 {$a,b,c$}에 연결된 엣지들 가운데 가중치가 2로 가장 작은 엣지 ($c,i$)를 선택합니다.  <a href="https://imgur.com/BMom02g"><img src="https://i.imgur.com/BMom02g.png" title="source: imgur.com" /></a>  (e)를 보겠습니다. {$a,b,c,i$}에 연결된 엣지들 가운데 가중치가 4로 가장 작은 엣지 ($c,f$)를 선택합니다. (f)에서는 {$a,b,c,f,i$}에 연결된 엣지들 가운데 가중치가 2로 가장 작은 엣지 ($g,f$)를 선택합니다.  <a href="https://imgur.com/dCr1p6I"><img src="https://i.imgur.com/dCr1p6I.png" title="source: imgur.com" /></a>  (g)에서는 {$a,b,c,f,g,i$}에 연결된 엣지들 가운데 가중치가 1로 가장 작은 엣지 ($g,h$)를 선택합니다. (h)에서는 {$a,b,c,f,g,h,i$}에 연결된 엣지들 가운데 가중치가 7로 가장 작은 엣지 ($c,d$)를 선택합니다. 여기서 주의할 점은 ($h,i$) 또한 그 가중치가 7로 연결되지 않은 엣지 가운데 가장 작은 것은 맞지만, 노드 $h$와 $i$ 모두 이미 선택된 노드들이므로 해당 엣지는 선택에서 배제된다는 것입니다.   <a href="https://imgur.com/Ei6Bej6"><img src="https://i.imgur.com/Ei6Bej6.png" title="source: imgur.com" /></a>  (i)에서는 {$a,b,c,d,f,g,h,i$}에 연결된 엣지들 가운데 가중치가 9로 가장 작은 엣지 ($d,e$)를 선택합니다. 이로써 모든 노드가 MST로 선택됐으므로 프림 알고리즘 수행을 종료합니다.  <a href="https://imgur.com/aFPb2hs"><img src="https://i.imgur.com/aFPb2hs.png" width="400px" title="source: imgur.com" /></a>   프림 알고리즘의 의사코드는 다음과 같습니다.  <a href="https://imgur.com/CnKDYw0"><img src="https://i.imgur.com/CnKDYw0.png" width="400px" title="source: imgur.com" /></a>  프림 알고리즘의 계산복잡성을 따져보겠습니다. 여기서는 최대/최소값을 찾는 데 효율적인 힙(heap)을 쓴다고 가정해 보겠습니다. 위 의사코드에서 *u.key*란 노드 $u$에 연결된 엣지 가중치의 최소값이며 *u.π*란 노드 $u$의 부모노드를 가리킵니다. 우선 모든 노드를 초기화(*non-solution set* $Q$에 모든 노드 삽입 등)하는 데 $O($\|$V$\|$)$만큼의 계산복잡성이 듭니다. 모든 노드 가운데 *key*값이 가장 작은 걸 뽑아내는 *extract-MIN* 연산을 하려면 힙의 말단 노드가 루트 노드까지 자리 이동을 해야 하므로 트리의 높이에 상당하는 $O(lg{V})$만큼의 계산이 필요합니다.  *decrease-KEY(Q, v, w(v,u))* 연산은 노드 $v$의 부모노드가 $u$가 되도록 하고, $v$의 *key*값(=$v$에 연결된 엣지 가중치의 최소값)을 ($u,v$)의 가중치로 업데이트하는 걸 가리킵니다. 힙의 키값을 업데이트하려면 최대 트리의 높이에 상당하는 탐색을 해야 하므로 $O(\lg{V})$만큼의 계산이 필요합니다. 이것을 노드 $u$에 연결된 엣지 수(그 기대값은 $E/V$)만큼 수행해야 하므로 *decrease-KEY* 연산은 $O(E/V\lg{V})$만큼의 계산이 필요합니다. *extract-MIN*과 *decrease-KEY* 연산은 모든 노드에 대해 반복 수행(*non-solution set* $Q$가 공집합이 될 때까지)해야 하므로 프림 알고리즘의 전체적인 계산복잡성은 $O((V+E)\lg{V})$가 됩니다.
HMMs␞ 이번 글에선 **은닉마코프모델(Hidden Markov Models, HMMs)**을 다루어 보도록 하겠습니다. 순차적인 데이터를 다루는 데 강점을 지녀 개체명 인식, 포스태깅 등 단어의 연쇄로 나타나는 언어구조 처리에 과거 많은 주목을 받았던 기법입니다. 이 글은 고려대 강필성 교수님 강의와 역시 같은 대학의 정순영 교수님 강의, 서울대 언어학과 신효필 교수님 저서, 위키피디아, [Speech and Language Processing 3rd edition draft](https://web.stanford.edu/~jurafsky/slp3/9.pdf)를 정리했음을 먼저 밝힙니다. 구체적인 계산 예시와 파이썬 코드 구현은 [이곳](https://ratsgo.github.io/machine%20learning/2017/10/14/computeHMMs/)을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.   ## 마코프 체인 은닉마코프모델은 마코프 체인(Markov chain)을 전제로 한 모델입니다. 마코프 체인이란 마코프 성질(Markov Property)을 지닌 이산확률과정(discrete-time stochastic process)을 가리킵니다. 마코프 체인은 러시아 수학자 마코프가 1913년경에 러시아어 문헌에 나오는 글자들의 순서에 관한 모델을 구축하기 위해 제안된 개념입니다.  한 상태(state)의 확률은 단지 그 이전 상태에만 의존한다는 것이 마코프 체인의 핵심입니다. 즉 한 상태에서 다른 상태로의 전이(transition)는 그동안 상태 전이에 대한 긴 이력(history)을 필요로 하지 않고 바로 직전 상태에서의 전이로 추정할 수 있다는 이야기입니다. 마코프 체인은 아래와 같이 도식화됩니다.  $$P({ q }_{ i }|{ q }_{ 1 },...,{ q }_{ i-1 })=P({ q }_{ i }|{ q }_{ i-1 })$$  날씨를 마코프 체인으로 모델링한 예시는 다음 그림과 같습니다. 아래 마코프 체인에서 각 노드는 상태, 엣지는 전이를 가리킵니다. 엣지 위에 작게 써 있는 $a_{ij}​$는 $i​$번째 상태에서 $j​$번째 상태로 전이할 확률을 나타냅니다. 각 노드별로 전이확률의 합은 1입니다(예컨대 $a_{01}+a_{02}+a_{03}=1​$) 상태에는 일반적인 종류의 상태(예컨대 HOT, COLD, WARM) 이외에 시작(start)과 끝(end) 상태도 있습니다.   <a href="https://imgur.com/iCPKPWz"><img src="https://i.imgur.com/iCPKPWz.png" width="400px" title="source: imgur.com" /></a>   ## 은닉 마코프 모델 은닉마코프모델은 각 상태가 마코프체인을 따르되 은닉(hidden)되어 있다고 가정합니다. 예컨대 당신이 100년 전 기후를 연구하는 학자인데, 주어진 정보는 당시 아이스크림 소비 기록뿐이라고 칩시다. 이 정보만으로 당시 날씨가 더웠는지, 추웠는지, 따뜻했는지를 알고 싶은 겁니다. 우리는 아이스크림 소비 기록의 연쇄를 관찰할 수 있지만, 해당 날짜의 날씨가 무엇인지는 직접적으로 관측하기 어렵습니다. 은닉마코프모델은 이처럼 관측치 뒤에 은닉되어 있는 상태(state)를 추정하고자 합니다. 날씨를 예시로 은닉마코프모델을 도식화한 그림은 다음과 같습니다.  <a href="https://imgur.com/lEMDGBC"><img src="https://i.imgur.com/lEMDGBC.png" width="500px" title="source: imgur.com" /></a>  위 그림에서 $B_1$은 날씨가 더울 때 아이스크림을 1개 소비할 확률이 0.2, 2개 내지 3개 먹을 확률은 각각 0.4라는 걸 나타냅니다. $B_1$은 날씨가 더울 때 조건부확률이므로 HOT이라는 은닉상태와 연관이 있습니다. $B$는 **방출확률(emission probablity)**이라고도 불립니다. 은닉된 상태로부터 관측치가 튀어나올 확률이라는 의미에서 이런 이름이 붙은 것 같습니다.   ## Likelihood 우선 우도(likelihood)부터 계산해 보겠습니다. 우도는 모델 $λ$가 주어졌을 때 관측치 $O$가 나타날 확률 $p(O$\|$λ)$을 가리킵니다. 바꿔 말해 모델 $λ$이 관측치 하나를 뽑았는데 그 관측치가 $O$일 확률입니다. 이렇게 관측된 $O$가 아이스크림 [3개, 1개, 3개]라고 칩시다. 그럼 모델 $λ$가 위의 그림이라고 할 때 이 $O$가 뽑힐 확률은 얼마일까요? 이걸 계산해 보자는 겁니다. 아래 그림을 봅시다.  <a href="https://imgur.com/syZWL5E"><img src="https://i.imgur.com/syZWL5E.png" width="300px" title="source: imgur.com" /></a>  두번째 날짜를 중심으로 보겠습니다. 모델 $λ$를 보면 날씨가 더울 때(hot) 아이스크림을 1개 먹을 확률은 0.2입니다. 그런데 두번째 날이 전날에 이어 계속 더울 확률은 0.6이므로 이를 곱해주어야 둘째 날의 상태확률를 계산할 수 있습니다. 여기에서 마코프 체인을 따른다고 가정하므로 상태확률을 계산할 때는 직전 상태만을 고려합니다. 위 그림을 식으로 나타내면 다음과 같습니다.  $$ \begin{align*} P(3\quad 1\quad 3,hot\quad hot\quad cold)=&P(hot|start)\times P(hot|hot)\times P(cold|hot)\\ &\times P(3|hot)\times P(1|hot)\times P(3|cold)\\=&0.8\times0.6\times0.3\\&\times0.4\times0.2\times0.1 \end{align*} $$  각 날짜별로 날씨가 더울 수도 있고 추울 수도 있습니다. 따라서 $2^3$가지의 경우의 수가 존재합니다. 아래 표와 같습니다. | 상태1 | 상태2 | 상태3 | | :--: | :--: | :--: | | cold | cold | cold | | cold | cold | hot | | cold | hot | cold | | hot | cold | cold | | hot | hot | cold | | cold | hot | hot | | hot | cold | hot | | hot | hot | hot | 따라서 관측치 [3, 1, 3]에 대한 최종적인 우도는 다음과 같이 구합니다.  $$ \begin{align*} P(3\quad 1\quad 3)=&P(3\quad 1\quad 3,cold\quad cold\quad cold)+\\ &P(3\quad 1\quad 3,cold\quad cold\quad hot)+...\\&P(3\quad 1\quad 3,hot\quad hot\quad hot) \end{align*} $$    ## Notation 여기에서 notation을 잠깐 정리하고 넘어가겠습니다. 다음과 같습니다. 저 또한 정리 용도로 남겨두는 것이니 헷갈릴 때만 다시 보시고 스킵하셔도 무방할 것 같습니다. - $Q=\{q_0, q_1, q_2, ..., q_n, q_F\}$ : 상태(state)의 집합(set). $q_0$은 시작상태, $q_F$는 종료상태, $n$은 상태의 개수를 나타낸다. - $A$ : 전이확률 행렬($n×n$). $a_{ij}$는 $i$번째 상태에서 $j$번째 상태로 전이할 확률($Σ_{j=1}^{n}a_{ij}=1$). - $B=b_i(o_t)$ : $i$번째 상태에서 $t$번째 관측치 $o_t$가 나타날 방출확률. - $O=[o_1,o_2,...,o_t,...,o_T]$ : 길이가 $T$인 관측치의 시퀀스. - $α_t(j)=P(o_1,o_2,...,o_t,q_t=j$\|$λ)$ : 모델 $λ$가 주어졌을 때 $j$번째 상태와 $o_1,...,o_t$가 나타날 확률. 전방확률(Forward Probability) - $β_t(j)=P(o_{t+1},o_{t+2},...,o_T,q_t=j$\|$λ)$ : 모델 $λ$가 주어졌을 때 $j$번째 상태와 $o_{t+1},...,o_T$가 나타날 확률. 후방확률(Backward Probability)    ## Compute Likelihood : Forward Algorithm 지금까지 은닉마코프모델의 우도(방출확률)를 계산하는 예시를 보여드렸습니다. 이제 이걸 전체 데이터에 대해 확대해 봅시다. 그런데 여기 문제가 하나 있습니다. 예시에서도 살펴봤듯 계산해야 할 경우의 수가 정말 많다는 겁니다. 가령 $N$개의 은닉상태가 있고 관측치 길이가 $T$라면 우도 계산시 고려해야 할 가짓수가 $N^T$개나 됩니다. 이러한 비효율성을 완화하기 위해 다이내믹 프로그래밍(dynamic programming) 기법을 씁니다. 다이내믹 프로그래밍은 중복되는 계산을 저장해 두었다가 푸는 것이 핵심 원리입니다. 다음 그림을 보겠습니다.  <a href="https://imgur.com/UcXttLx"><img src="https://i.imgur.com/UcXttLx.png" title="source: imgur.com" /></a>  예컨대 아이스크림 3개($o_1$)와 1개($o_2$)가 연속으로 관측됐고 두 번째 시점($t=2$)의 날씨가 추웠을($q_1$) 확률은 $α_2(1)$입니다. 마찬가지로 아이스크림 3개($o_1$)가 관측됐고 첫 번째 시점($t=1$)의 날씨가 추웠을($q_1$) 확률은 $α_1(1)$입니다. 또한 아이스크림 3개($o_1$)가 관측됐고 첫 번째 시점($t=1$)의 날씨가 더웠을($q_2$) 확률은 $α_1(2)$입니다. 각각을 구하는 식은 다음과 같습니다.  $$ \begin{align*} { \alpha }_{ 1 }(1)=&P(cold|start)\times P(3|cold)\\ { \alpha }_{ 1 }(2)=&P(hot|start)\times P(3|hot)\\ { \alpha }_{ 2 }(1)=&{ \alpha }_{ 1 }(1)\times P(cold|cold)\times P(1|cold)\\ &+{ \alpha }_{ 1 }(2)\times P(cold|hot)\times P(1|cold) \end{align*} $$  Forward Algorithm의 핵심 아이디어는 이렇습니다. 중복되는 계산은 그 결과를 어딘가에 저장해 두었다가 필요할 때마다 불러서 쓰자는 겁니다. 위 그림과 수식을 보시다시피 $α_2(1)$를 구할 때 직전 단계의 계산 결과인 $α_1(1)$, $α_1(2)$을 활용하게 됩니다. 이해를 돕기 위한 예시여서 지금은 계산량 감소가 도드라져 보이지는 않지만 데이터가 조금만 커져도 그 효율성은 명백해집니다. $j$번째 상태에서 $o_1,...,o_t$가 나타날 전방확률 $α$는 다음과 같이 정의됩니다.  $$ { \alpha }_{ t }(j)=\sum _{ i=1 }^{ n }{ { \alpha }_{ t-1 }(i)\times { a }_{ ij } } \times { b }_{ j }({ o }_{ t }) $$  $α_t(j)$는 $j$번째 상태와 $t$개의 관측치 시퀀스가 나타날 수 있는, 가능한 경우의 수가 모두 고려되어 합쳐진 확률입니다. 예컨대 위 그림에서 $α_3(2)$의 경우 세번째 시점에 HOT이 되려는데 가능한 경로는 [H, H, H], [H, C, H], [C, H, H], [C, C, H]입니다. 따라서 전방확률을 관측치 시퀀스 끝까지 계산하면 앞서 계산한 우도와 동치가 됩니다.  $$ \begin{align*} P(O|\lambda )=&P\left( { o }_{ 1 },{ o }_{ 2 },...,{ o }_{ T }|\lambda \right) \\ =&P\left( { o }_{ 1 },{ o }_{ 2 },...,{ o }_{ T },{ q }_{ t }={ q }_{ F }|\lambda \right) ={ \alpha }_{ T }\left( { q }_{ F } \right) \end{align*} $$    ## Decoding : Viterbi Algorithm 우리의 두 번째 관심은 모델 $λ$과 관측치 시퀀스 $O$가 주어졌을 때 가장 확률이 높은 은닉상태의 시퀀스 $Q$를 찾는 것입니다. 이를 디코딩(decoding)이라고 합니다. 포스태깅 문제로 예를 들면 단어의 연쇄를 가지고 품사 태그의 시퀀스를 찾는 것입니다. 우리가 은닉마코프모델을 만드려는 근본 목적에 닿아 있는 문제가 됩니다. 은닉마코프모델의 디코딩 과정엔 **비터비 알고리즘(Viterbi Algorithm)**이 주로 쓰입니다.  비터비 알고리즘의 계산 대상인 비터비 확률(Viterbi Probability) $v$는 다음과 같이 정의됩니다. $v_t(j)$는 $t$번째 시점의 $j$번째 은닉상태의 비터비 확률을 가리킵니다.  $$ { v }_{ t }(j)=\max _{ i } ^{n}{ \left[ { v }_{ t-1 }(i)\times { a }_{ ij }\times { b }_{ j }({ o }_{ t }) \right] } $$  자세히 보시면 Forward Algoritm에서 구하는 전방확률 $α$와 디코딩 과정에서 구하는 비터비 확률 $v$를 계산하는 과정이 거의 유사한 것을 확인할 수 있습니다. Forward Algorithm은 각 상태에서의 $α$를 구하기 위해 가능한 모든 경우의 수를 고려해 그 확률들을 더해줬다면(sum), 디코딩은 그 확률들 가운데 최대값(max)에 관심이 있습니다. 디코딩 과정을 설명한 예시 그림은 다음과 같습니다.  <a href="https://imgur.com/MXxxdo7"><img src="https://i.imgur.com/MXxxdo7.png" title="source: imgur.com" /></a>  각 상태에서의 비터비 확률 $v$를 구하는 식은 다음과 같습니다. 전방확률을 계산하는 과정과 비교해서 보면 그 공통점(각 상태에서의 전이확률과 방출확률 간 누적 곱)과 차이점(sum vs max)을 분명하게 알 수 있습니다. 비터비 확률 역시 직전 단계의 계산 결과를 활용하는 다이내믹 프로그래밍 기법을 씁니다.  $$ \begin{align*} v_{ 1 }(1)=&\max { \left[ P(cold|start)\times P(3|cold) \right] } \\ =&P(cold|start)\times P(3|cold)\\ { v }_{ 1 }(2)=&\max { \left[ P(hot|start)\times P(3|hot) \right] } \\ =&P(hot|start)\times P(3|hot)\\ { v }_{ 2 }(1)=&\max { \left[ { v }_{ 1 }(2)\times P(cold|hot)\times P(1|cold),\\ { v }_{ 1 }(1)\times P(cold|cold)\times P(1|cold) \right] } \end{align*} $$  Forward Algorithm과 비터비 알고리즘 사이에 가장 큰 차이점은 비터비에 역추적(backtracking) 과정이 있다는 점입니다. 디코딩의 목적은 비터비 확률이 얼마인지보다 최적 상태열이 무엇인지에 관심이 있으므로 당연한 이치입니다. 위 그림에서 파란색 점선으로 된 역방향 화살표가 바로 역추적을 나타내고 있습니다.  예컨대 2번째 시점 2번째 상태 $q_2$(=HOT)의 backtrace $b_{t_2}(2)$는 $q_2$입니다. $q_2$를 거쳐서 온 우도값(0.32×0.12)이 $q_1$보다 크기 때문입니다. 2번째 시점의 1번째 상태 $q_1$(=COLD)의 backtrace $b_{t_2}(1)$는 $q_2$입니다. 최적상태열은 이렇게 구한 backtrace들이 리스트에 저장된 결과입니다. 예컨대 위 그림에서 아이스크림 [3개, 1개]가 관측됐을 때 가장 확률이 높은 은닉상태의 시퀀스는 [HOT, COLD]가 되는 것입니다. $t$번째 시점 $j$번째 상태의 backtrace는 다음과 같이 정의됩니다.  $$ { b }_{ { t }_{ t } }(j)=arg\max _{ i=1 }^n{ \left[ { v }_{ t-1 }(i)\times { a }_{ ij }\times { b }_{ j }({ o }_{ t }) \right] } $$   ## 모델 학습을 위한 사전 지식 은닉마코프모델의 본격적인 학습에 앞서 학습 과정을 유도하는 데 필요한 용어와 개념 몇 가지 살펴보도록 하겠습니다.   ### 전방확률과 후방확률 은닉마코프모델의 파라메터 학습을 위해서는 후방확률 $β$ 개념을 먼저 짚고 넘어가야 합니다. 전방확률 $α$와 반대 방향으로 계산한 것이 후방확률입니다. 그 식은 각각 다음과 같습니다.  $$ { \alpha }_{ t }(j)=\sum _{ i=1 }^{ n }{ { \alpha }_{ t-1 }(i)\times { a }_{ ij } } \times { b }_{ j }({ o }_{ t })\\ { \beta }_{ t }(i)=\sum _{ j=1 }^{ n }{ { a }_{ ij } } \times { b }_{ j }({ o }_{ t+1 })\times { \beta }_{ t+1 }(j) $$  우선 전방확률 $α$ 먼저 보겠습니다. $α_3(4)$는 다음과 같이 구합니다.  <a href="https://imgur.com/mbBaTch"><img src="https://i.imgur.com/mbBaTch.png" title="source: imgur.com" /></a>  $$ { \alpha }_{ 3 }(4)=\sum _{ i=1 }^{ 4 }{ { \alpha }_{ 2 }(i)\times { a }_{ i4 } } \times { b }_{ 4 }({ o }_{ 3 }) $$  이번엔 후방확률 $β$를 보겠습니다. 위와 같은 위치의 후방확률 $β_3(4)$는 다음과 같이 구합니다.  <a href="https://imgur.com/bP9BdJy"><img src="https://i.imgur.com/bP9BdJy.png" title="source: imgur.com" /></a>  $$ { \beta }_{ 3 }(4)=\sum _{ j=1 }^{ 4 }{ { a }_{ 4j } } \times { b }_{ j }({ o }_{ 4 })\times { \beta }_{ 4 }(j) $$  따라서 $α_3(4)$와 $β_3(4)$를 곱하면 3번째 시점에 4번째 상태일 확률이라는 의미를 가지게 됩니다. 바꿔 말해 $α_3(4)×β_3(4)$는 3번째 시점에 4번째 상태를 지나는 모든 경로에 해당하는 확률의 합을 가리킨다는 겁니다. 이를 도식적으로 나타내면 다음과 같습니다.  <a href="https://imgur.com/3SQDk3b"><img src="https://i.imgur.com/3SQDk3b.png" width="400px" title="source: imgur.com" /></a>  $$ { \alpha }_{ t }\left( j \right) \times { \beta }_{ t }\left( j \right) =P\left( { q }_{ t }=j,O|\lambda \right) $$  따라서 특정 시점 $t$의 전방확률과 후방확률을 곱한 값을 모든 상태에 대해 더해 주면 앞서 계산한 우도와 동치가 됩니다. 후방확률을 관측치 시퀀스 맨 끝부터 처음까지 계산하면 이 또한 앞서 계산한 우도와 같습니다.  $$ \begin{align*} P(O|\lambda )=&P\left( { o }_{ 1 },{ o }_{ 2 },...,{ o }_{ T }|\lambda \right) \\ =&P\left( { o }_{ 1 },{ o }_{ 2 },...,{ o }_{ T },{ q }_{ t }={ q }_{ 0 }|\lambda \right) =\beta _{ 0 }\left( { q }_{ 0 } \right) \\ =&\sum _{ s=1 }^{ n }{ \alpha _{ t }\left( s \right) \times \beta _{ t }\left( s \right) } \end{align*} $$  ### 베이즈 정리 베이즈 정리에 의해 다음과 같은 식이 성립합니다.  $$ \begin{align*} P\left( X|Y,Z \right) =&\frac { P(X,Y,Z) }{ P(Y,Z) } \\ =&\frac { P(X,Y)/P(Z) }{ P(Y,Z)/P(Z) } \\ =&\frac { P(X,Y|Z) }{ P(Y|Z) } \end{align*} $$   ### 방출확률 업데이트와 γ 방출확률 $b$를 업데이트하기 위해 $γ$ 개념을 살펴보도록 하겠습니다. $t$시점에 $j$번째 상태일 확률 $γ_t(j)$는 다음과 같이 정의됩니다. 이는 이미 정의된 식과 베이즈 정리에 의해 다음과 같이 다시 쓸 수 있습니다.  $$ \begin{align*} { \gamma }_{ t }\left( j \right) =&P\left( { q }_{ t }=j|O,\lambda \right) \\ =&\frac { P\left( { q }_{ t }=j,O|\lambda \right) }{ P\left( O|\lambda \right) } \\ =&\frac { { \alpha }_{ t }\left( j \right) \times { \beta }_{ t }\left( j \right) }{ \sum _{ s=1 }^{ n }{ \alpha _{ t }\left( s \right) \times \beta _{ t }\left( s \right) } } \end{align*} $$  $j$번째 상태에서 관측치 $v_k$가 나타날 방출확률 $\hat{b}_j(v_k)$는 다음과 같이 정의됩니다.  $$ { \hat { b } }_{ j }\left( { v }_{ k } \right) =\frac { \sum _{ t=1,s.t.{ o }_{ t }={ v }_{ k } }^{ T }{ { \gamma }_{ t }\left( j \right) } }{ \sum _{ t=1 }^{ T }{ { \gamma }_{ t }\left( j \right) } } $$  위 식의 의미를 해석하면 이렇습니다. 방출확률 $\hat{b}_j(v_k)$의 분모는 $j$번째 상태가 나타날 확률입니다. 분자는 $j$번째 상태이면서 그 때 관측치($o_t$)가 $v_k$일 확률입니다($v_k$가 나타나지 않는 $γ$는 0으로 무시). 분모와 분자 모두에 시그마가 적용된 이유는 방출확률은 시점 $t$와는 무관한 값이기 때문입니다. 어떤 시점이든 $j$번째 상태가 나타날 확률 $γ$가 존재하므로 $T$개 관측치 시퀀스 전체에 걸쳐 모든 시점에 대해 $γ$를 더해주는 것입니다.   ### 전이확률 업데이트와 ξ 전이확률 $a$를 업데이트하기 위해 $ξ$ 개념을 살펴보도록 하겠습니다. $t$시점에 $i$번째 상태이고 $t+1$시점에 $j$번째 상태일 확률 $ξ$는 다음과 같이 정의됩니다. 이 또한 베이즈 정리에 의해 다음과 같이 다시 쓸 수 있습니다.  $$ \begin{align*} { \xi }_{ t }\left( i,j \right) =&P\left( { q }_{ t }=i,{ q }_{ t+1 }=j|O,\lambda \right) \\ =&\frac { P\left( { q }_{ t }=i,{ q }_{ t+1 }=j,O|\lambda \right) }{ P\left( O|\lambda \right) } \end{align*} $$  위 식에서 분자 부분을 이해하기 위해 다음 그림을 보겠습니다. $t$시점에 $i$번째 상태이고 $t+1$시점에 $j$번째 상태인 경우를 도식화한 것입니다.   <a href="https://imgur.com/0QxMZTa"><img src="https://i.imgur.com/0QxMZTa.png" width="500px" title="source: imgur.com" /></a>  지금까지의 정의로 볼 때 $α_t(i)$는 $i$번째 상태 좌측의 모든 path에 해당하는 확률의 합입니다. $β_{t+1}(j)$는 $j$번째 상태 우측의 모든 path에 해당하는 확률의 합입니다. 그런데 이 두 가지 곱만으로는 $i$번째 상태와 $j$번째 상태를 이어주는 path가 존재하지 않습니다. 이를 연결해 주어야 합니다. $i$번째 상태에서 $j$번째 상태로 전이할 확률 $a_{ij}$, $j$번째 상태에서 관측치 $o_{t+1}$를 관측할 방출확률 $b_j(o_{t+1})$까지 곱해주어야 한다는 이야기입니다.  따라서 $t$시점에 $i$번째 상태이고 $t+1$시점에 $j$번째 상태일 확률 $ξ$은 다음과 같이 다시 쓸 수 있습니다.  $$ \begin{align*} { \xi }_{ t }\left( i,j \right) =&\frac { P\left( { q }_{ t }=i,{ q }_{ t+1 }=j,O|\lambda \right) }{ P\left( O|\lambda \right) } \\ =&\frac { { \alpha }_{ t }\times { a }_{ ij }\times { b }_{ j }\left( { o }_{ t+1 } \right) \times { \beta }_{ t+1 }\left( j \right) }{ \sum _{ s=1 }^{ n }{ \alpha _{ t }\left( s \right) \times \beta _{ t }\left( s \right) } } \end{align*} $$  $i$번째 상태에서 $j$번째 상태로 전이할 확률 $\hat{a}_{ij}$는 다음과 같이 정의됩니다.  $$ \hat { a } _{ ij }=\frac { \sum _{ t=1 }^{ T-1 }{ { \xi }_{ t }\left( i,j \right) } }{ \sum _{ t=1 }^{ T-1 }{ \sum _{ k=1 }^{ N }{ { \xi }_{ t }\left( i,k \right) } } } $$  위 식의 의미는 이렇습니다. 분모는 $i$번째 상태에서 전이할 수 있는 모든 path들의 확률들을 더한 값입니다. 분자는 $i$번째 상태에서 $j$번째 상태로 전이할 확률을 가리킵니다. 분모와 분자 모두에 $Σ_{t=1}^{T-1}$가 적용된 이유는 방출확률은 시점 $t$와는 무관한 값이기 때문입니다. 어떤 시점이든 $i$번째 상태에서 다른 상태로 전이할 확률 $ξ_t$가 존재하므로 관측치 시퀀스 전체에 걸쳐 모든 시점에 대해 $ξ_t$를 더해주는 것입니다. 다만 시퀀스 마지막 $T$번째 시점에선 종료상태로 전이될 확률이 1이 되므로 $t$에 대해 1에서 $T-1$까지 더해줍니다.  위 식을 그림으로 도식화하면 아래와 같습니다. 위 식 분모는 굵은 적색 점선 화살표, 분자는 검은색 화살표입니다.  <a href="https://imgur.com/G0FUlgo"><img src="https://i.imgur.com/G0FUlgo.png" title="source: imgur.com" /></a>   ## Training : EM Algorithm 은닉마코프모델의 파라메터는 전이확률 $A$와 방출확률 $B$입니다. 그런데 이 두 파라메터를 동시에 추정하기는 어렵습니다. 지금까지 설명한 날씨 예제를 기준으로 하면, 우리가 관측가능한 것은 아이스크림의 개수뿐이고 궁극적으로 알고 싶은 날씨는 숨겨져 있습니다. 따라서 HOT에서 COLD로 전이할 확률은 물론 날씨가 더울 때 아이스크림을 1개 먹을 방출확률 따위를 모두 한번에 알 수 없습니다. 이럴 때 주로 사용되는 것이 EM 알고리즘입니다. 은닉마코프모델에서는 이를 '바움-웰치 알고리즘' 또는 'Forward, Backward Algorithm'이라고도 부릅니다.   ### E-step 모델 파라메터 $λ$, 즉 전이확률 $A$, 방출확률 $B$를 고정시킨 상태에서 관측치 $O$를 바탕으로 전방확률 $α$와 후방확률 $β$를 업데이트합니다. 이 $α$와 $β$를 바탕으로 $γ$와 $ξ$를 각각 계산합니다.   ### M-step E-step에서 구한 $γ$와 $ζ$를 바탕으로 모델 파라메터 $A$, $B$를 업데이트합니다.   ### pesudo code EM 알고리즘의 의사코드는 다음과 같습니다. 단 아래 코드에서 $γ,ξ$의 분모는 표기가 다를 뿐 해당 관측치의 우도를 나타냅니다.  <a href="https://imgur.com/ukU14ub"><img src="https://i.imgur.com/ukU14ub.png" width="600px" title="source: imgur.com" /></a>  
loss␞ 이번 글에서는 딥러닝 모델의 손실함수에 대해 살펴보도록 하겠습니다. 이 글은 Ian Goodfellow 등이 집필한 Deep Learning Book과 위키피디아, 그리고 하용호 님의 [자료](https://www.slideshare.net/yongho/ss-79607172)를 참고해 제 나름대로 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## Why negative log-likelihood? 딥러닝 모델의 손실함수로 **음의 로그우도(negative log-likelihood)**가 쓰입니다. 어떤 이유에서일까요?  ### 확률론적 접근 딥러닝 모델을 학습시키기 위해 최대우도추정(Maximum Likelihood Estimation) 기법을 씁니다. 주어진 데이터만으로 미지의 최적 모델 파라메터 $θ$를 찾아야 합니다. 입력값 $X$와 파라메터 $θ$가 주어졌을 때 정답 $Y$가 나타날 확률, 즉 우도 $P(Y$\|$X;θ)$를 최대화하는 $θ$가 바로 우리가 찾고 싶은 결과라고 보면 되겠습니다.  그런데 학습데이터 각각의 우도를 스케일해도 전체 *argmax*의 결과는 바뀌지 않으므로 '우도의 곱을 최대'로 만드는 $θ$와 '로그우도의 기대값, 즉 $Σ_xP(y$\|$x)\log{P(y}$\|$x;θ)$를 최대'로 하는 $θ$는 같습니다. 이와 관련해 Deep Learning Book 128페이지에는 다음과 같이 설명돼 있습니다. > The argmax does not change when we rescale the cost function, we can divide by the total number of data to obtain a version of the criterion that is expressed as an expectation with respect to the empirical distribution $P_{data}$ defined by the training data. 다범주 분류를 학습하는 딥러닝 모델의 경우 말단에 다음과 같이 소프트맥스 함수가 적용됩니다. ($f(x)$는 소프트맥스 계층의 입력값)  $$ P({ y }_{ i }|{ x }_{ i };\theta )=\frac { f\left( { x }_{ i } \right) }{ \sum _{ j }^{ }{ exp\left\{ f\left( { x }_{ j } \right) \right\} } } $$ 위 식에서 $f$는 범주 수만큼의 차원을 갖는 벡터로써 unnormalized log probabilities에 해당합니다. 소프트맥스 함수가 취해짐으로써 그 요소의 합이 1이 됩니다. 정답 인덱스에 해당하는 $f$의 요소값을 높인다는 말은 최대우도추정을 수행한다는 의미로 해석할 수 있습니다. 최대우도추정과 관련해서는 [이곳](https://ratsgo.github.io/statistics/2017/09/23/MLE/)을 참고하시면 좋을 것 같습니다.  ### 정보이론의 접근 두 확률분포 $p$와 $q$ 사이의 차이를 계산하는 데에는 크로스 엔트로피(cross entropy)라는 함수가 사용됩니다. 식은 $-Σp(x)\log{q(x)}$입니다. 여기에서 $p$를 우리가 가진 데이터의 분포 $P(Y$\|$X)$, $q$를 모델이 예측한 결과의 분포 $P(Y$\|$X;θ)$로 두겠습니다. 이렇게 되면 크로스 엔트로피는 파라메터 $θ$ 하에서의 음의 로그우도의 기대값이라고 해석할 수 있습니다. 따라서 $-Σ_xP(y$\|$x)\log{P(y}$\|$x;θ)$를 최소화하는 $θ$가 바로 우리가 찾고 싶은 모델이 됩니다. 요컨대 우도의 곱이 최대인 모델을 찾는 것은 로그우도의 기대값이 최대인 모델을 찾는 것과 같으며, 이는 또한 학습데이터의 분포(distribution)와 모델이 예측한 결과의 분포 사이의 차이, 즉 크로스 엔트로피를 최소화하는 것과 동치입니다. 이 때문에 음의 로그우도가 딥러닝 모델의 손실함수가 되는 것입니다. 정보이론과 관련 자세한 내용은 [이곳](https://ratsgo.github.io/statistics/2017/09/22/information/)을 참고하시면 좋을 것 같습니다.    ## 크로스엔트로피 계산 예시 음의 로그우도를 계산하는 예시와 관련 크로스 엔트로피로 설명해 보겠습니다. 우선 딥러닝 모델의 입력값으로 쓰이는 관측치는 이산변수(discrete variable)에 해당하므로 크로스 엔트로피 $H(P,Q)$의 식을 다시 쓰면 다음과 같습니다.  $$ H\left( P,Q \right) =-\sum _{ x }^{ }{ P({ x })\log { Q({ x }) } } $$  예컨대 범주가 2개이고 정답 레이블이 $[1,0]$인 관측치 $x$가 있다고 칩시다. $P$는 우리가 가지고 있는 데이터의 분포를 나타내므로 첫번째 범주일 확률이 1, 두번째 범주일 확률은 0이라고 해석할 수 있습니다. $Q$는 $P$에 근사하도록 만들고 싶은, 딥러닝 학습 대상 분포(모델이 예측하는 분포)입니다. 그런데 모델 학습이 잘 안돼서 $Q$가 $[0,1]^T$로 나왔다고 하면 loss는 다음과 같이 무한대로 치솟게 됩니다.  $$ -P(x)\log { Q(x) } =-\begin{bmatrix} 1 & 0 \end{bmatrix}\begin{bmatrix} \log { 0 } \\ \log { 1 } \end{bmatrix}=-\left( -\infty +0 \right) =\infty $$ 이번엔 학습이 잘 돼서 모델이 정답과 일치하는 $[1,0]$을 예측했다고 하면 loss는 다음과 같이 0이 됩니다.  $$ -P(x)\log { Q(x) } =-\begin{bmatrix} 1 & 0 \end{bmatrix}\begin{bmatrix} \log { 1 } \\ \log { 0 } \end{bmatrix}=-\left( 0+0 \right) =0 $$  단 여기에서 $0\log{0}$은 0으로 취급합니다.    ## negative log-likelihood 장점 손실함수로 음의 로그우도을 쓸 경우 몇 가지 이점이 생긴다고 합니다. 우선 우리가 만드려는 모델에 다양한 확률분포를 가정할 수 있게 돼 유연하게 대응할 수 있게 됩니다. 음의 로그우도로 딥러닝 모델의 손실을 정의하면 이는 곧 두 확률분포 사이의 차이를 재는 함수인 크로스 엔트로피가 되며, 크로스 엔트로피는 비교 대상 확률분포의 종류를 특정하지 않기 때문입니다. 이와 관련 Deep Learning Book 129페이지는 이렇게 서술돼 있습니다. > Any loss consisting of a negative log-likelihood is a cross entropy between the empirical distribution defined by the training set and the probability distribution defined by model. 예컨대 우리가 만들고 싶은 모델을 가우시안 분포로 전제한다면, 크로스 엔트로피 최소화는 우리가 가진 데이터의 분포와 모델의 가우시안 분포 사이의 차이를 최소화한다는 의미입니다. 특히 가우시안 분포를 가정할 때 크로스 엔트로피의 최소화는 **평균제곱오차(Mean Squared Error)**의 최소화와 본질적으로 동일합니다. 이와 관련해 [이곳](https://ratsgo.github.io/statistics/2017/09/23/MLE/)을 참고하시면 좋을 것 같습니다. 아울러 모델을 베르누이 분포로 가정한다면 우리가 가진 데이터의 분포와 모델의 베르누이 분포 간 차이가 최소화하는 방향으로 학습이 이뤄집니다. 이는 다항분포 또한 마찬가지입니다.  한편 딥러닝 모델의 최종 출력을 어떤 숫자 하나(예컨대 영화 관객 수)로 둘 경우 우리가 구축하려는 모델이 정규분포라고 가정하는 것과 깊은 관련을 맺고 있습니다. 최종 출력이 O, X로 이뤄진 이진변수(binary variable)일 경우 모델을 베르누이 분포로 가정하는 것과 사실상 유사합니다. 다범주 분류를 하는 딥러닝 모델은 다항분포를 가정하는 것과 비슷합니다.  위 세 종류 모델의 최종 output node는 각각 Linear unit, Sigmoid unit, Softmax unit이 되며, output node의 출력 분포와 우리가 가진 데이터의 분포 사이의 차이가 곧 크로스 엔트로피가 됩니다. 이 차이만큼을 loss로 보고 이 loss에 대한 그래디언트를 구해 이를 역전파하는 과정이 딥러닝의 학습이 되겠습니다. 바꿔 말하면 각각의 확률분포에 맞는 손실을 따로 정의할 필요가 없이 음의 로그우도만 써도 되고, output node의 종류만 바꾸면 세 개의 확률분포에 대응할 수 있게 된다는 이야기입니다. 매우 편리한 점이죠. 세 종류 간 구분은 다음 그림과 같습니다(출처 : 하용호 님의 [자료](https://www.slideshare.net/yongho/ss-79607172)) 다시 말씀드리지만 셋 모두 손실함수로 음의 로그우도, 즉 크로스 엔트로피를 쓰면 됩니다.  <a href="https://imgur.com/syDsCfH"><img src="https://i.imgur.com/syDsCfH.png" width="500px" title="source: imgur.com" /></a>  크로스 엔트로피를 쓰면 딥러닝 역전파시 그래디언트가 죽는 문제를 어느 정도 해결할 수 있고, 그래디언트를 구하는 과정 역시 비교적 간단하다고 합니다. 우리가 구축하는 모델을 다항분포라고 두고, 최종 output node는 3차원짜리 벡터를 입력으로 받는 소프트맥스, loss는 크로스 엔트로피인 경우를 그림으로 도식화하면 다음과 같습니다.  <a href="http://imgur.com/gyeTKAn"><img src="http://i.imgur.com/gyeTKAn.png" width="400px" title="source: imgur.com" /></a>  Softmax-with-Loss 노드는 $a$를 입력으로 받아서 소프트맥스를 취해 확률값으로 만든 뒤 이를 바탕으로 크로스 엔트로피 Loss $L$을 출력합니다. 반대로 역전파하는 그래디언트는 $y_k-t_k$가 됩니다. 예컨대 정답이 $t_3$이라면 역전파되는 그래디언트는 각각 $y_1, y_2, y_3-1$로 간단하게 구할 수 있습니다. 뿐만 아니라 정답이 아닌 노드의 손실에 대한 그래디언트는 소프트맥스 확률값이고, 정답 레이블에 해당하는 노드의 그래디언트는 여기에서 1을 빼준 값이기 때문에 그래디언트가 완전히 0으로 되는 경우는 많지 않으리라고 기대할 수 있습니다.
SOM␞ 이번 글에서는 **차원축소(dimensionality reduction)**와 **군집화(clustering)**를 동시에 수행하는 기법인 **자기조직화지도(Self-Organizing Map, SOM)**를 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 아키텍처 개요 SOM이란 사람이 눈으로 볼 수 있는 저차원(2차원 내지 3차원) 격자에 고차원 데이터의 각 개체들이 대응하도록 인공신경망과 유사한 방식의 학습을 통해 군집을 도출해내는 기법입니다. 고차원의 데이터 원공간에서 유사한 개체들은 저차원에 인접한 격자들과 연결됩니다. 저차원 격자에서의 유사도는 고차원 입력 공간에서의 유사도를 최대한 보존하도록 학습됩니다.  SOM 아키텍처의 핵심은 대략 아래 그림과 같습니다. <a href="http://imgur.com/ZsAdHxT"><img src="http://i.imgur.com/ZsAdHxT.png" width="400px" title="source: imgur.com" /></a> 위 그림에서 초록색 노드($x_i$)는 $n$차원 입력벡터의 각 요소를 뜻합니다. 주황색 노드($w_j$)는 2차원 격자입니다.  저차원 격자 하나에는 여러 개의 입력벡터들이 속할 수 있습니다. 여기에 속한 입력벡터들끼리는 서로 위치적인 유사도를 가집니다(=가까운 곳에 있음). 그럼 임의의 입력벡터가 주어졌을 때 2차원상 어떤 격자에 속하는지 어떻게 알 수 있을까요? 위 그림 기준으로 $j$번째 격자는 원데이터 공간에 존재하는 $n$차원 벡터 $[w_{j1},w_{j2},...,w_{jn}]$에 대응됩니다.  다시 말해 2차원상 격자가 위 그림처럼 25개라면 그에 해당하는 $n$차원 크기의 격자벡터도 25개 있다는 이야기이죠. 임의의 $n$차원 입력벡터가 들어왔을 때 가장 가까운 격자벡터를 찾습니다. 이것을 **Winning node**라고 합니다. 이 벡터에 대응되는 2차원상 격자에 해당 입력벡터를 할당하면 이것이 바로 군집화가 되는 것입니다. 같은 격자에 할당된 입력벡터라 하더라도 Winning node와의 거리가 제각기 다를 수 있습니다. 이러한 멀고 가까움 또한 표시를 하게 되면 고차원 공간의 원데이터를 2차원 내지 3차원으로 차원을 축소하는 효과까지 낼 수 있습니다. SOM의 결과물 예시는 아래 그림과 같습니다. 고차원 공간의 원데이터가 25개 격자에 각각 할당(군집화)돼 있고, 동일한 격자에 할당된 입력값끼리도 그 위치가 서로 다르게 임베딩된 것을 확인할 수 있습니다. <a href="http://imgur.com/EE8NF6J"><img src="http://i.imgur.com/EE8NF6J.png" width="400px" title="source: imgur.com" /></a>  ## SOM 학습 그렇다면 SOM은 어떻게 학습을 하는 것일까요? 직관적으로 이해해보기 위해 아래 그림을 먼저 살펴보겠습니다. 시각화를 위해 원데이터의 차원수와 격자의 차원수는 모두 2차원으로 두었습니다. 하지만 이는 이해를 돕기 위함일 뿐, 검정색 점이 흩뿌려진 원데이터 공간은 고차원이라고 생각하셔야 합니다. <a href="http://imgur.com/eHUVAtr"><img src="http://i.imgur.com/eHUVAtr.gif" width="400px" title="source: imgur.com" /></a> 위 그림에서 연두색 25개 점은 고차원의 원데이터공간에 대응되는 격자벡터입니다. 처음엔 그 위치를 랜덤으로 초기화합니다. 이후 학습데이터 $x$(검정색 점)를 하나씩 추가해가며 격자벡터의 위치를 $x$의 위치와 비슷해지도록 업데이트합니다(**instance-based learning**).  다만 여기서 주의해야할 것은 격자벡터의 업데이트 폭이 모두 같지는 않다는 점입니다. 현재 주어진 $x$와 그 위치가 가장 가까운 Winning node가 제일 많이 업데이트되고요, 이 노드의 주변 격자벡터들은 그보다 조금 덜 업데이트됩니다. 멀리 떨어진 녀석들은 거의 업데이트가 되지 않도록 합니다. $t$시점의 $j$번째 격자벡터를 업데이트하는 과정을 수식으로 나타내면 아래와 같습니다.   $${ w }_{ j }^{ t+1 }={ w }_{ j }^{ t }+{ \mu }_{ t }{ \lambda }_{ x }^{ j,t }[x-{ w }_{ j }^{ t }]$$  여기에서 $μ$는 일종의 learning rate로 반복 횟수가 커지면 학습 속도를 줄이는 역할을 합니다. λ는 Winning node는 가장 크게, 학습데이터와 멀리 떨어진 격자벡터는 작게 업데이트하도록 합니다(가우시안 분포 활용). 마지막으로 괄호 안의 뺄셈으로 된 부분은 학습데이터 $x$와 격자벡터 간 차이를 의미하는데, 벡터의 덧/뺄셈 결과 역시 벡터이므로 격자벡터가 업데이트되는 **방향**을 결정해줍니다.
war␞ *휴가 기간 '그해 역사가 바뀌다(주경철 지음)'를 읽다가 눈에 띄는 구절이 있어서 정리 용도로 그대로 인용해봤다. ICBM과 핵탄두 소형화에 성공한 김정은이 괌 기지를 날리겠다고 위협하고, 트럼프가 북에 대해 괌을 공격하면 누구도 보지 못한 일이 일어날거라 맞불을 놓고, 중국은 그저 미국 세력의 확장을 막으려고 팔짱끼고 있는 가운데 한반도를 둘러싼 정치 지형을 역사적으로 이해할 수 있는 좋은 글이라는 생각에서다. 2017. 8. 11. 부산*  **강조 표시는 인용자 주, 저작권 등 문제시 자삭하겠습니다.**   임진왜란 당시 우리나라에 들어온 왜군은 우리가 통상 생각하는 것보다 훨씬 더 강력한 군대였습니다. 이들은 강력한 화력에다 사무라이가 함께 운영되는 복합군대였습니다. 그때 들어온 병력 16만명 중 4분의 1이 총을 소지했다고 합니다. 당시 일본 군대는 지역별로 영주가 군대를 모아서 제공했는데, 영주가 부자면 총을 사용하는 사수의 비중이 높고 가난하면 사무라이의 비중이 높은 식이지요. 여기에서 16만명이라는 수치도 주목할 필요가 있습니다. 이는 정말 엄청난 의미를 가진 병력입니다. 한번 비교해봅시다. 거의 같은 시기에 있었던 세계사적으로 중요한 전투로는 1588년 스페인 무적함대(無敵艦隊)의 영국 공격을 들 수 있습니다. 스페인의 펠리페 2세(Felipe II)가 영국의 여왕 엘리자베스를 징치하겠다고 군사를 총집합해 무적함대에 승선시킨 뒤 영국으로 파송했지요. 이때 스페인군의 인원이 3만 명이 안 됩니다. 이렇듯 유럽 역사를 뒤흔든 중요한 전투에 투입된 인원도 3만 명이 안 되는데 일본군 16만 명이 조선 땅에 들어왔다는 것은 보통 전투가 아닙니다. 그야말로 동아시아의 명운이 갈린 전쟁이었던 것입니다. 이런 사실들을 놓고 볼 때 어쨌든 우리가 일본군을 격퇴했다는 것은 실로 대단한 일이 아닐 수 없습니다. 우리는 맨날 조선 군대가 형편없이 패퇴하고 국왕이 도주했다는 식의 이미지만 떠올리지만 세계 최강의 화력을 자랑하는 엄청난 대군을 물리친 성과는 결코 무시할 만한 일이 아닙니다. 심지어 산속에 있던 스님들까지도 뛰쳐나와 게릴라전을 벌이지 않았습니까? 명나라에서도 원군(援軍)을 보냈는데, 원군을 보낸 이유는 단지 조선에 대한 의리 때문만이 아닙니다. 만약 저 막강한 일본 군사력이 조선을 정복한 후 보급로를 확보하여 밀고 올라간다면 명나라의 운명도 장담 못 하는 실정이었기 때문입니다. 이 전쟁의 의미를 다른 각도에서 한번 되새겨봅시다. **일본이라는 강력한 해양세력이 한반도를 통해서 대륙으로 들어가려는 힘이 한반도에서 굴절되었다고 볼 수 있습니다.** 그렇다면 반대 사례는 없을까요? 그러니까 강력한 대륙 세력이 해양으로 들어가려다가 한반도에서 굴절된 경우 말입니다. 몽골 사례를 들 수 있겠네요. 상대적으로 비교해볼 때 몽골군은 세계 역사상 가장 강력한 군대라고 이야기합니다. 몽골이 서쪽으로 진격해 들어갈 때의 기세를 보면 정말 엄청났습니다. 무엇보다 상대편을 철저히 파괴할 때는 차마 말하기 힘든 지독하게 잔인한 모습을 보입니다. 예컨대 러시아에서 전투가 벌어질 때 몽골이 보인 행태는 이렇습니다. 상대방이 항복을 안 하고 계속 버티다가 성이 함락된 경우, 저녁에 살아남은 모든 사람들을 땅에 엎드리게 한 후 그 위에 판자를 깝니다. 그리고 그 위에서 몽골군은 밤새 술을 마시고 놉니다. 승자는 위에서 술을 마시고 패자는 그 아래에서 압사당하는 것이지요. 아침에 판다를 걷어보면 모든 사람이 죽어 있습니다. 그러고는 이 지역에 불을 질러 모든 것을 다 태워 없애버리고 떠납니다. 자신들에게 저항하면 이렇게 된다는 것을 일부러 과시적으로 보여서, 다음 번 적들이 그 소식을 듣고 아예 저항하지 못하도록 하는 의미겠지요. 이토록 강한 세력이 고려로 진격해옵니다. 우리는 오래 버티고 항전하지만 결국 몽골에게 사위의 나라가 된다는 명목으로 그들의 지배를 받기에 이릅니다. 그 후 몽골은 고려를 움직여 해군을 만들어서 일본을 징벌하겠다고 나섭니다. 하지만 우리가 잘 알다시피 이 공격은 실패로 끝납니다. 왜 실패했을까요? 태풍 때문이라고들 이야기합니다. 다시 말해 카미카제(神風, 원래 13세기 몽골의 일본 침공시 몽골 함대를 침몰시킨 태풍을 뜻하나, 이후 2차 세계대전 당시 이름을 날렸던 일본군 자살 특공대를 지칭하게 되었다) 덕분이라고 말하는데, 이것은 곧 신이 도왔다는 의미입니다. 하여튼 일본으로서는 그 강력한 침략군을 태풍이 막아주었으니 천운이라고 할 수 있겠습니다. 역사 교과서에서도 그렇게 이야기하지요. 그런데 여기에서 한번 생각을 바꿔서 이렇게 질문해보지요. 그런 엄청난 세계사적인 사건을 이야기하면서 실패의 원인을 태풍이라고 한다면 너무 단순한 설명 아닐까요? 태풍이 실제 실패의 원인이었다면, 몇 년 쉬어 힘을 모았다가 다시 선단을 만들어서 이번에는 태풍이 안 부는 계절에 공략하면 되는 것 아니겠습니까? 실제로 일본에서는 다시 몽골이 쳐들어올까봐 해안선을 방비하느라고 엄청난 공력을 들였다고 합니다. 그런데 몽골은 다시 일본에 쳐들어가지 못합니다. 왜 그랬을까요? 왜 몽골은 한 두 번의 실패 이후 일본을 정벌하려는 생각을 다시 하지 못했을까요? 고려 때문이라고 보아야 합니다. 고려가 비록 몽골에게 사위의 나라로서 복속하게 되었지만 그렇게 되기까지 걸린 기간이 30년입니다. 몽골 앞에서 30년 동안 버틴 세력은 고려밖에 없습니다. 그러니 천하의 몽골이라고 하더라도 고려를 지배한 이후 동아시아에서는 힘이 소진된 상태였습니다. 그래서 마지막으로 힘을 모아 일본을 공격했다가 실패로 돌아가자 그 이후에는 다시 시도하지 못했다는 것입니다. 이를 두고 최근 일본 학계에서는 "한반도가 일본의 방파제 역할을 해줬다"고 이야기합니다. 이런 사례들을 놓고 한반도의 역사적 의의를 종합적으로 생각해보도록 합시다. **해양 세력이 대륙으로 진출할 때나 혹은 반대로 대륙 세력이 해양으로 진출할 때 모두 한반도가 역사적 필터 역할을 했습니다.** 이와 유사한 역사적 사례가 6.25 전쟁입니다. 중국과 미국의 수교를 뒤에서 실제 조정한 전략가로서 헨리 키신저(Henry Alfred Kissinger)라는 유명한 미국의 정치학자가 있습니다. 그의 저서 '헨리 키신저의 세계 질서(World order)'를 보면 6.25 전쟁에 대한 분석을 하는데, 내용인즉 이렇습니다. 국군과 연합군이 북한군에게 한번 밀렸다가 다시 치고 올라갈 때 "압록강까지 올라가지 말고 평양-원산 선에서 멈추고 그곳에서 영토를 지키고 있어야 한다"는 것입니다. 이것이 무슨 의미일까요? 당시 중국 사정을 생각해봅시다. 중국은 공산 정권이 들어선지 얼마 안 돼 아직 정권이 매우 취약한 상태였습니다. 그리고 일본과 한국, 대만, 필리핀 등지에 미국의 강력한 군사력이 중국을 완전히 포위하고 있는 형국이니, 중국으로서는 심각한 위기감을 느끼는 상태였습니다. 그런데 실제로 한반도에서 전쟁이 발발하더니 미군이 주축이 되어 강력한 기세로 밀고 올라오고 있습니다. 중국 측이 긴장하지 않을 수 없는 상황이지요. 이에 마오쩌둥(毛澤東)이 미국 측에 암시적으로 경고합니다. *"압록강까지 오지 마라. 만약 이곳을 넘어오면 우리가 반드시 거병해서 맞받아칠 수밖에 없다."* 이런 상황에서 공연히 중국을 자극해 중국군을 끌어들일 이유가 없었다는 것입니다. 그러니 평양-원산 선에서 진격을 멈추면 한반도의 80퍼센트를 지배하는 셈이데, 힘이 약해진 북한 정권이 지배하는 나머지 20퍼센트는 결국 흡수됨으로써 통일을 이룰 수 있었으리라는 분석입니다. 물론 키신저의 이런 분석이 꼭 맞는다는 보장은 없고 많은 비판이 가능하겠습니다만, 한번 생각해볼 가치가 있는 주장입니다. 그렇다면 맥아더(Douglas MacArthur) 장군 역시 중국군이 대거 반격을 해오리라는 예상을 할 수 있었을 텐데 끝까지 전진을 명령한 이유는 무엇이었을까요? 사실인지 어떤지는 잘 모르겠으나 나중에 해임되고 나서 인터뷰한 내용을 보면, 그는 이렇게 말했습니다. *"미국이 가지고 있는 원자탄을 만주에 떨어뜨려 초토화시킴으로써 확실하게 끝내줄 생각이었다."* 실제 그런 일이 벌어졌으면 어떻게 됐을까요(한때 핵폭탄을 실제로 사용하기 위해 아홉 발을 괌 기지까지 이송했다고 하니 꼭 빈말만은 아닐 수도 있겠습니다)? 당시에는 중국 뒤에 소련이 있고 소련 역시 이미 핵무기를 가지고 있었으니 한반도는 핵전쟁 무대가 됐을 것입니다. 생각만 해도 아찔한 일입니다. 너무나 위험한 발상을 하고 있었던 것인데, 그렇기에 트루먼(Harry Shippe Truman) 대통령이 맥아더를 원자탄만큼 위험한 인간이라고 칭하며 해임한 것이지요. **이상의 여러 가지 사례를 종합해보면 한반도라고 하는 지형이 해양 세력과 대륙 세력이 만나는 일종의 단층선 역할을 한다는 것을 알 수 있습니다.** 
genegram␞ 이번 글에서는 **변형생성문법(transformational generative grammar)**에 대해 살펴보도록 하겠습니다. 이 글은 [고종석의 언어학 강의 불순한 언어가 아름답다](http://book.naver.com/bookdb/book_detail.nhn?bid=9511771)의 56~60페이지를 그대로 옮겨 왔습니다. 개인적인 정리 용도로 타이핑 겸 긁어왔는데요, 저작권법 등 문제가 될 경우 자삭하겠습니다.  ## 변형생성문법? 흔히 촘스키(Noam Chomsky) 언어학을 변형생성문법이라고 합니다. 도대체 변형생성문법이란 뭘까요? 그리고 그것이 극복했다고 주장하는 구조주의 언어학과는 어떻게 다를까요? 다음 두 문장을 봅시다. > (1) 존경하는 선생님께서 감격스럽게도 제게 꽃을 이만큼이나 보내 오셨어요. > > (2) 존경하는 제자들이 기특하게도 선생님께 꽃을 이만큼이나 보내 왔어요. 이 두 문장은 구조적으로 완전히 같습니다. 적어도 겉보기에는 말이죠. 전통문법에서 흔히 주부(主部)라고 부르는 부분만 살핍시다. 동사의 현재관형형(존경하는)이 명사(선생님/제자들)를 수식하고, 이렇게 만들어진 명사구에 주격표지(께서/이)가 붙어 주어 노릇을 합니다. 그런데 '존경하는 선생님'과 '존경하는 제자들'은 정말 같은 구조를 지녔을까요? 그렇기도 하고 그렇지 않기도 합니다. 그렇다는 것은 그 둘 다 현재관형형 동사 뒤에 수식되는 명사가 이어진다는 점에서입니다. 명사(구)를 'NP'로 나타내고 동사의 현재관형형을 'V-는'으로 나타내면, '존경하는 선생님'과 '존경하는 제자들'은 둘 다 **[V-는 NP]**라는 구조를 지닌 NP(명사구)입니다. 이렇게 겉으로 드러나는 구조를 촘스키는 **표면구조(surface structure)**라고 불렀습니다. 촘스키에 따르면 표면구조는 음성 해석 정보를 지녔습니다. 그런데 촘스키는 이런 표면구조 **저 아래에 누워 있는(underlie)** 또 하나의 구조를 가정합니다. 촘스키가 **심층구조(deep structure)**라고 부르는 이 층위에서는 '존경하는 선생님'과 '존경하는 제자들'의 구조가 서로 다릅니다.  심층구조에서 '존경하는 선생님'은 '선생님을 존경한다'입니다. 다시 말해 **[NP 목적격표지 V-ㄴ다]**의 구조를 지닌 S(문장)입니다. 그러나 '존경하는 제자들'은 심층구조에서 '제자들이 존경한다'입니다. 다시 말해 **[NP 주격표지 V-ㄴ다]**의 구조를 지닌 S입니다.  즉 심층구조에서 '선생님'은 '존경하다'의 목적어인 데 반해, '제자들'은 '존경하다'의 주어입니다. 촘스키에 따르면 심층구조는 의미 해석 정보를 지녔습니다. 서로 다른 심층구조를 지닌 '존경하는 선생님'과 '존경하는 제자들'이 동일한 표면구조를 지니게 되는 것은, **[NP 목적격표지 V-ㄴ다]** 구조의 문장과 **[NP 주격표지 V-ㄴ다]** 구조의 문장을 **[V-는 NP]**라는 동일한 NP(명사구)로 유도하는 규칙이 한국어에 있기 때문입니다. 심층구조에서 표면구조를 유도하는 과정을 '변형'이라고 하고, 그 변형에 쓰인 규칙을 '변형규칙(transformation rule)'이라 합니다. 촘스키 문법을 변형생성문법이라고 부르는 것은 그것이 변형규칙이라는 장치를 사용하는 생성문법이기 때문입니다. 그것을 생성문법이라고 부르는 것은 유한한 규칙들의 집합(구조)을 통해서 무한한 적격(well-formed) 문장들을 생성해내는 모국어 화자의 능력에 이 이론이 관심을 쏟기 때문입니다.  촘스키에 따르면 구조주의 언어학자들은 '존경하는 선생님'과 '존경하는 제자들'의 구조적 다름을 '설명'할 수 없습니다. 그들은 잘해봐야 그 다름을 '관찰'하거나 '기술'할 수 있을 따름입니다. 그런데 일반 언어 이론은 이런 관찰적 타당성(ovservational adequacy)이나 기술적 타당성(descriptive adequacy)을 넘어서는 설명적 타당성(explanatory adequacy)을 지녀야 한다고 촘스키는 말합니다. 물론 자신의 변형생성문법이야말로 그런 설명적 타당성을 지녔다는 거지요.  ## 표면구조와 심층구조 표면구조는 같은데 심층구조는 다른 예로 촘스키가 제시한 가장 유명한 문장은 아래와 같습니다. > (a) John is easy to please (존은 까다롭지 않다) > > (b) John is eager to please (존은 남에게 잘 보이려 한다) 명백히 보이듯 이 두 문장의 표면구조는 같지만 심층구조에서 (a)의 John은 please의 목적어이고, (b)의 John은 please의 주어입니다. 표면구조가 다른데 심층구조가 같은 경우도 있습니다.  > (ㄱ) 나는 당신이 바보라고 생각했어 > > (ㄴ) 나는 당신을 바보로 생각했어 > (ㄱ) I believed you was an idiot > > (ㄴ) I believed you (to be)an idiot 한국어든 영어든 이 문장의 심층구조는 앞쪽 표면구조에 가깝습니다. 그 심층구조에 **인상변형(raising transformation)**이라는 규칙이 적용되면 뒤쪽 표면구조가 유도됩니다. 또 능동문과 피동문도, 동일한 심층구조가 서로 다른 표면구조로 유도된 대표적 예입니다.  ## 변형생성문법의 의의와 한계 촘스키의 변형생성문법은 초기의 표준이론에서 확대표준이론(EST), 지배결속이론(GB), 최소주의프로그램(MP) 등으로 정교화하면서 한 세대 이상 세계 언어학계를 풍미했습니다. 영어권 학계만이 아니라 서유럽, 일본, 중국, 대만, 한국 등지에서 촘스키는 거의 동시에 읽혔습니다. 촘스키 언어학이 이렇게 큰 영향을 끼칠 수 있었던 이유 가운데 하나는 그 이론의 보편 지향성에 있을 겁니다. 촘스키는 수많은 자연언어들의 문법이 표면구조에서는 달라도 심층구조에서는 같으리라 예상했습니다. 말하자면 그의 두드러진 욕망 하나는 보편문법을 수립하는 것이었지요. 이탈리어어나 프랑스어를, 일본어나 중국어나 한국어를 모국어로 삼은 언어학자들이 촘스키 이론을 자신의 가장 익숙한 언어에 적용해보고 싶어 했던 것이 이해됩니다. 그렇지만 촘스키의 변형생성문법도 '사실'이 아니라 하나의 '이론'에 불과하다는 점을 강조하고 싶습니다. 사실 언어라는 현상은 너무나 복잡해서, 언어가 이거다, 또는 저거다, 라고 한마디로 규정할 수 없습니다. 언어는 X다, 라는 명제에서 X는 무수히 많을 수도 있고, 하나도 없을 수도 있습니다. 그만큼 언어의 '본질'에 대한 견해는 연구자들마다 다르다는 겁니다. 
hash␞ 이번 글에서는 **해싱(hashing)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아, 그리고 [스택오버플로우](https://stackoverflow.com/questions/27742285/what-is-primary-and-secondary-clustering-in-hash)와 [고니 님의 블로그](http://dbehdrhs.tistory.com/70)를 참고해 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concepts **해시함수(hash function)**란 데이터의 효율적 관리를 목적으로 임의의 길이의 데이터를 고정된 길이의 데이터로 매핑하는 함수입니다. 이 때 매핑 전 원래 데이터의 값을 **키(key)**, 매핑 후 데이터의 값을 **해시값(hash value)**, 매핑하는 과정 자체를 **해싱(hashing)**라고 합니다.  해시함수는 해쉬값의 개수보다 대개 많은 키값을 해쉬값으로 변환(many-to-one 대응)하기 때문에 해시함수가 서로 다른 두 개의 키에 대해 동일한 해시값을 내는 **해시충돌(collision)**이 발생하게 됩니다. 아래 그림은 이름-전화번호부를 매핑하기 위한 해시함수를 개념적으로 나타냈습니다. 예시의 해시함수는 'John Smith'와 'Sandra Dee'를 모두 '02'로 매핑해 해시충돌을 일으키고 있습니다.  <a href="https://imgur.com/NnEBDcX"><img src="https://i.imgur.com/NnEBDcX.png" title="source: imgur.com" /></a>   ##해시테이블의 장점 해시충돌이 발생할 가능성이 있음에도 해시테이블을 쓰는 이유는 적은 리소스로 많은 데이터를 효율적으로 관리하기 위해서입니다. 예컨대 해시함수로 하드디스크나 클라우드에 존재하는 무한에 가까운 데이터(키)들을 유한한 개수의 해시값으로 매핑함으로써 작은 크기의 캐쉬 메모리로도 프로세스를 관리할 수 있게 됩니다.  색인(index)에 해시값을 사용함으로써 모든 데이터를 살피지 않아도 검색과 삽입/삭제를 빠르게 수행할 수 있습니다. 위 그림의 경우 해시함수에 'Lisa Smith'를 입력하면 02라는 색인이 생성됩니다.  해시함수는 언제나 동일한 해시값을 리턴하고, 해당 색인만 알면 해시테이블의 크기에 상관없이 데이터에 대단히 빠르게 접근할 수 있으며, 색인은 계산이 간단한 함수(상수시간)로 작동하기 때문에 매우 효율적입니다. 다시 말해 해시는 데이터 액세스(삽입, 삭제, 탐색)시 계산복잡성을 $O(1)$을 지향합니다. 해시테이블을 다른 자료구조와 비교해보겠습니다. 이진탐색트리와 그 변형의 경우 메모리를 효율적으로 사용하는 편이지만 데이터 탐색에 소요되는 계산복잡성은 $O(n\log{n})$입니다. 배열(array)의 경우 데이터 탐색에 따른 계산복잡성은 $O(1)$이지만, 메모리를 미리 할당해 둬야 하기 때문에 공간 효율적이라고 말하기 어렵습니다. 해시는 보안 분야에서도 널리 사용된다고 합니다. 키와 해시값 사이에 직접적인 연관이 없기 때문에 해시값만 가지고는 키를 온전히 복원하기 어렵기 때문입니다. 아울러 해시함수는 길이가 서로 다른 입력데이터에 대해 일정한 길이의 출력을 만들 수 있어서 '데이터 축약' 기능도 수행할 수 있습니다. 다만 현재까지 개발된 거의 모든 해시함수는 해시충돌을 일으키는 것으로 확인됐다고 합니다. 물론 해시충돌 자체를 줄이는 것도 의미가 있겠습니다만, 중요한 것은 해시충돌이 해시값 전체에 걸쳐 균등하게 발생하게끔 하는 것입니다. 극단적으로 위 그림에서 모든 키가 02라는 동일한 해시값으로 매핑이 될 경우 데이터를 액세스할 때 비효율성이 커지고, 보안이 취약(서로 다른 키인데도 동일한 해시값)해져 굳이 해시를 도입해 데이터를 관리할 이유가 없어집니다.    ## 해시테이블 해시함수를 사용하여 키를 해시값으로 매핑하고, 이 해시값을 색인(index) 혹은 주소 삼아 데이터의 값(value)을 키와 함께 저장하는 자료구조를 **해시테이블(hash table)**이라고 합니다. 이 때 데이터가 저장되는 곳을 버킷(bucket) 또는 슬롯(slot)이라고 합니다. 해시테이블의 기본 연산은 삽입, 삭제, 탐색(search)입니다. 다음 그림과 같습니다.   <a href="https://imgur.com/EMW1YZP"><img src="https://i.imgur.com/EMW1YZP.png" title="source: imgur.com" /></a>  위 예시 그림 각 버킷에는 데이터가 다음과 같이 저장됩니다. | Index(Hash Value) | Data          | | ----------------- | ---------------------- | | 01        | (Lisa Smith, 521-8976) | | 02        | (John Smith, 521-1234) | | ...        | ...          | 키의 전체 개수와 동일한 크기의 버킷을 가진 해시테이블을 Direct-address table이라고 합니다. 다음 그림과 같습니다.  <a href="https://imgur.com/ySs5La4"><img src="https://i.imgur.com/ySs5La4.png" width="400px" title="source: imgur.com" /></a>  Direct-address table의 장점은 키 개수와 해시테이블 크기가 동일하기 때문에 해시충돌 문제가 발생하지 않는다는 겁니다. 하지만 실제 사용하는 키(actucal key)보다 전체 키(unverse of key)보다 훨씬 많은 경우 사용하지 않는 키들을 위한 공간까지 마련해야 하는 탓에 메모리 효율성이 크게 떨어집니다. 위 그림처럼 1, 9, 4, 0, 7, 6을 위한 버킷은 굳이 만들어놓을 이유가 없습니다.  보통의 경우 Direct-address table보다는 해시테이블 크기($m$)가 실제 사용하는 키 개수($n$)보다 적은 해시테이블을 운용합니다. 다뤄야할 데이터가 정말 많고, 메모리 등 리소스 문제도 생기기 때문입니다. 이 때 $n/m$을 **load factor**($α$)라고 합니다. 해시테이블의 한 버킷에 평균 몇 개의 키가 매핑되는가를 나타내는 지표입니다. Direct-address table의 load factor는 1 이하이며, 1보다 큰 경우 해시충돌 문제가 발생합니다.  해시충돌 문제를 해결하기 위해 다양한 기법들이 고안됐습니다. chining은 해시테이블의 크기를 유연하게 만들고, open addressing은 해시테이블 크기는 고정시키되 저장해 둘 위치를 잘 찾는 데 관심을 둔 구조입니다. 이뿐 아니라 해시함수를 개선하는 접근도 있습니다. 차례대로 살펴보겠습니다.   ## chaining 해시충돌 문제를 해결하기 위한 간단한 아이디어 가운데 하나는 한 버킷당 들어갈 수 있는 엔트리의 수에 제한을 두지 않음으로써 모든 자료를 해시테이블에 담는 것입니다. 해당 버킷에 데이터가 이미 있다면 체인처럼 노드를 추가하여 다음 노드를 가리키는 방식으로 구현(연결리스트)하기 때문에 체인이라는 말이 붙은 것 같습니다. 유연하다는 장점을 가지나 메모리 문제를 야기할 수 있습니다. 아래 그림과 같습니다.  <a href="https://imgur.com/7PTT8dT"><img src="https://i.imgur.com/7PTT8dT.png" title="source: imgur.com" /></a>  위 예시 그림의 해시함수는 'John Smith'와 'Sandra Dee'를 같은 해시값(152)으로 매핑하고 있습니다. 이 경우 해당 해시값에 대응하는 동일한 버킷에 두 개 데이터를 저장해 둡니다. 데이터를 위 그림처럼 연결리스트로 저장해 둘 경우 최근 데이터는 연결리스트의 *head*에 추가합니다(이 경우 $O(1)$, *tail*에 저장할 경우 $O(n)$이 됨, 자세한 내용은 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/09/30/list/) 참고)  ### 삽입, 탐색, 삭제 연산과 계산복잡성 chaining 방식의 계산복잡성을 따져보겠습니다. 삽입(insertion), 탐색(search), 삭제(delete) 세 가지가 있습니다. 본격적인 분석에 앞서 가정을 하나 하겠습니다. 해시테이블의 크기가 $m$, 실제 사용하는 키 개수가 $n$, 해시함수가 키들을 모든 버킷에 균등하게 할당한다고 가정하면, 버킷 하나당 $n/m=α$개의 키들이 존재할 것입니다. 예컨대 위 그림 예시에서 2560개의 키에 해당하는 데이터를 저장한다면 버킷 하나당 10개 데이터가 있다는 얘기입니다. 삽입의 계산복잡성입니다. 예컨대 위 예시그림의 해시함수가 254로 매핑하는 'Mark Zuckerberg'의 전화번호를 새로 추가한다고 칩시다. 'Mark Zuckerberg'라는 키를 해시값 254로 매핑하는 데 $O(1)$이 듭니다. 해당 해시값에 해당하는 연결리스트의 *head*에 이를 추가하는 데 $O(1)$이 듭니다. 따라서 삽입의 계산복잡성은 둘을 합친 $O(1)$입니다. 이번엔 탐색을 살펴보겠습니다. 두 가지로 나눠서 생각해 보겠습니다.  쿼리 키값에 해당하는 데이터가 해시테이블에 존재하지 않는 경우(**unsuccessful search**)입니다. 예컨대 위 예시그림의 해시함수가 152로 매핑하는 'Steve Jobs'의 전화번호를 탐색한다고 가정해 봅시다. 이 경우 키를 해시값으로 바꾸고, 해당 해시값에 해당하는 버킷의 요소들 $α$개를 모두 탐색해봐야 존재하지 않는다는 사실을 알 수 있습니다. 따라서 unsuccessful search의 계산복잡성은 $O(1+α)$가 됩니다. 이번엔 쿼리 키값에 해당하는 데이터가 해시테이블에 존재하는 경우(successful search)입니다. 예컨대 'Sandra Dee'의 전화번호를 위와 같은 해시테이블에서 탐색한다고 가정해 봅시다. 이를 위해선 'Sandra Dee'를 해시값(152)으로 바꾸고 버킷 요소들 가운데 'Sandra Dee'에 해당하는 데이터가 있는지 탐색해봐야 할 겁니다.  Big O notation의 계산복잡성을 따져보기 위해선 최악의 경우를 고려해야 합니다. 해당 버킷의 *tail*에 값이 있는 경우일 겁니다. 데이터가 해시테이블에 존재한다고 가정했으므로 버킷 내 $α$개 요소 가운데 반드시 찾고자 하는 값이 존재합니다. $α-1$개를 비교했는데도 원하는 값을 찾지 못했다면 *tail*값은 따져볼 필요도 없이 찾고자 하는 값이 됩니다. 그런데 버킷의 요소들 평균이 $α$개일 때 successful search는, 요소가 $α-1$개인 버킷을 탐색했는데 찾는 값이 없어서(unsuccessful search), 해당 버킷에 쿼리에 해당하는 데이터를 삽입하여 결과적으로 해당 버킷의 요소 수를 $α$개로 만드는 계산량과 동일합니다. unsuccessful search의 계산복잡성은 $O(1+α)$이므로, successful search의 계산복잡성 또한 이와 같은 $O(1+α)$가 됩니다. 삭제의 계산복잡성은 탐색과 본질적으로 비슷합니다. 우선 쿼리 키값을 해시값으로 매핑하고($O(1)$), 해당 버킷 내에 키값에 해당하는 데이터가 있는지 탐색($O(α)$)해야 하기 때문입니다. 물론 탐색 연산과 비교해 삭제에 드는 계산도 추가적으로 필요하나, 연결리스트로 해시테이블을 구현할 경우 삭제 연산의 계산복잡성은 $O(1)$이므로 무시할 만한 수준입니다.  chaining에서 삽입을 제외한, 탐색/삭제의 계산복잡성은 버킷당 요소 개수의 평균 $α$가 좌지우지하는 구조입니다. 최악의 경우 한 버킷에 모든 데이터가 들어있어 $O(n)$이 될 수 있습니다. 하지만 데이터의 개수가 해시테이블 크기의 두 세배쯤($α$가 2~3)만 되어도 탐색, 삭제는 $O(1)$이 됩니다.    ## open addressing open addressing은 chaining과 달리 한 버킷당 들어갈 수 있는 엔트리가 하나뿐인 해시테이블입니다. 해시함수로 얻은 주소가 아닌, 다른 주소에 데이터를 저장할 수 있도록 허용한다는 취지에서 open addressing이라는 이름이 붙은 것 같습니다. 메모리 문제가 발생하지 않으나 해시충돌이 생길 수 있습니다.  예컨대 해시함수를 '키값을 7로 나눈 나머지'로 정의했다고 칩시다. 그리고 나서 키 50, 700, 76, 85, 92, 73, 101순으로 데이터를 저장한다고 가정해 봅시다. 다음 그림과 같습니다.  <a href="https://imgur.com/IM4FA2h"><img src="https://i.imgur.com/IM4FA2h.png" title="source: imgur.com" /></a>  위 예시에서 주목할 부분은 85부터입니다. 85를 7로 나눈 나머지는 1입니다. 그런데 해시값 1에 해당하는 버킷에 이미 50이 있으므로, 다음 버킷(2)에 저장해 둡니다. 92를 7로 나눈 나머지 역시 1입니다. 그런데 해시값 1에 해당하는 버킷에 이미 50이 있고, 그 다음 해시값 2 버킷에 85가 있으므로, 92를 3번 버킷에 저장합니다. 73, 101 역시 자신의 버킷에는 이미 주인이 있으므로 빈 버킷에 할당합니다.  ### 삭제, 삽입, 탐색 해시함수가 '키값을 8로 나눈 나머지'이고 10, 18, 26 순으로 해시테이블에 삽입한다고 가정해 보겠습니다. 세 숫자 가운데 첫번째 입력값 10을 제외한 18, 26은 원래 버킷(2) 말고 각각 다음(3), 다음다음(4) 버킷에 저장하는 것이 open addressing의 방식입니다. | 0  | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | |   |   | 10 | 18 | 26 |   |   |   |   | 위 표에서 18을 삭제해 보겠습니다. 18의 해시값은 2인데 여기엔 10이 저장돼 있으므로 스킵하고, 그 다음 버킷(3)을 탐색해 봅니다. 18이 여기에 있군요. 지웁니다. 다음과 같습니다. | 0  | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | |   |   | 10 |   | 26 |   |   |   |   | 위 표에서 26을 탐색해 보겠습니다. 26의 해시값은 2인데 여기엔 10이 저장돼 있으므로 스킵하고, 그 다음 버킷(3)을 탐색해 봅니다. 그런데 비어 있습니다. 별도로 조치하지 않으면 알고리즘은 '2번 해시값 1칸 옆인 3에 저장된 데이터가 없구나, 해시충돌이 발생한 적이 없다는 얘기네, 탐색을 끝내야 겠다'고 판단할 수 있습니다. 이를 해결하기 위해 삭제 연산 때 아래처럼 별도로 표시를 해둡니다.  | 0  | 1  | 2  |  3  | 4  | 5  | 6  | 7  | 8  | | :--: | :--: | :--: | :-----: | :--: | :--: | :--: | :--: | :--: | |   |   | 10 | **DEL** | 26 |   |   |   |   |  ### probing open addressing은 그 구조상 해시충돌 문제가 발생할 수 있습니다. 앞선 예시에서 살펴봤듯 특정 해시값에 키가 몰리게 되면 open addressing의 효율성이 크게 떨어집니다. 해시충돌은 탐사(probing) 방식으로 해결할 수 있습니다. 탐사란 삽입, 삭제, 탐색을 수행하기 위해 해시테이블 내 새로운 주소(해시값)를 찾는 과정입니다. **선형 탐사(Linear probing)**는 가장 간단한 방식입니다. 앞선 예시에 해당합니다. 최초 해시값에 해당하는 버킷에 다른 데이터가 저장돼 있으면 해당 해시값에서 고정 폭(예컨대 1칸)을 옮겨 다음 해시값에 해당하는 버킷에 액세스(삽입, 삭제, 탐색)합니다. 여기에 데이터가 있으면 고정폭으로 또 옮겨 액세스합니다.  그런데 탐사 이동폭이 고정돼 있는 선형탐사는 특정 해시값 주변 버킷이 모두 채워져 있는 primary clustring 문제에 취약하다고 합니다. 예컨대 아래 그림처럼 52~56까지 데이터가 저장돼 있고 임의의 키의 최초 해시값이 52라면 탐사를 네 번 수행하고 나서야 원하는 위치를 찾을 수 있습니다. 모두 빈 버킷이었다면 단 한 번의 해시만으로도 저장할 수 있었을 텐데 말이죠.  <a href="https://imgur.com/D1WrmZE"><img src="https://i.imgur.com/D1WrmZE.png" width="200px" title="source: imgur.com" /></a>  **제곱 탐사(Quadratic probing)**은 고정 폭으로 이동하는 선형 탐사와 달리 그 폭이 제곱수로 늘어난다는 특징이 있습니다. 예컨대 임의의 키값에 해당하는 데이터에 액세스할 때 충돌이 일어나면 $1^2$칸을 옮깁니다. 여기에서도 충돌이 일어나면 이번엔 $2^2$칸, 그 다음엔 $3^2$칸 옮기는 식입니다.  하지만 제곱탐사는 여러 개의 서로 다른 키들이 동일한 초기 해시값(아래에서 *initial probe*)을 갖는 secondary clustering에 취약하다고 합니다. 초기 해시값이 같으면 다음 탐사 위치 또한 동일하기 때문에 효율성이 떨어집니다. 예컨대 아래 그림에서 초기 해시값이 7인 데이터를 삽입해야 할 경우 선형 탐사 기법보다 성큼성큼 이동하더라도 탐사를 네 번 수행하고 나서야 비로소 데이터를 저장할 수 있습니다.  <a href="https://imgur.com/KqvA9b9"><img src="https://i.imgur.com/KqvA9b9.png" width="250px" title="source: imgur.com" /></a>  **이중해싱(double hashing)**은 탐사할 해시값의 규칙성을 없애버려서 clustering을 방지하는 기법입니다. 2개의 해시함수를 준비해서 하나는 최초의 해시값을 얻을 때, 또 다른 하나는 해시충돌이 일어났을 때 탐사 이동폭을 얻기 위해 사용합니다. 이렇게 되면 최초 해시값이 같더라도 탐사 이동폭이 달라지고, 탐사 이동폭이 같더라도 최초 해시값이 달라져 primary, secondary clustering을 모두 완화할 수 있습니다. - 해시값을 반환해주는 $h_1$을 '3으로 나눈 나머지', 탐사 이동폭을 결정해주는 $h_2$를 '5로 나눈 나머지'라고 둡시다. 예컨대 키가 3, 6인 데이터의 최초 해시값은 모두 0이 됩니다. 하지만 키가 3인 데이터의 탐사이동폭은 3, 6인 데이터의 이동폭은 1로 달라집니다. 반대로 키가 6, 11인 데이터의 탐사이동폭은 모두 1이 됩니다. 하지만 키가 6인 데이터의 최초 해시값은 0, 11은 2로 달라집니다. - 단 제수(위 예시에서 3, 5)는 서로소(relatively prime, 공약수가 1뿐)이어야 원하는 효과를 볼 수 있습니다.   ### 계산복잡성 open addressing은 chaining과 달리 해시테이블의 크기($m$)가 고정돼 있으므로 $n$개 데이터를 모두 저장하려는 경우 Load Factor $α=n/m$는 1과 같거나 작다고 가정합니다. 다시 말해 open addressing은 해시테이블에 데이터가 꽉 차지 않는다는 걸 전제로 한다는 이야기입니다. 아울러 open addressing에 적용된 해시함수는 키들을 모든 버킷에 균등하게 할당한다고 가정하고 계산복잡성을 분석합니다. open addressing 탐색의 계산복잡성은 탐사(probing) 횟수에 비례합니다. 따라서 탐색 계산복잡성을 따질 때 핵심은 '탐사 횟수의 기대값'입니다. successful search와 unsuccessful search의 탐사횟수 기대값은 각각 다음과 같다고 합니다.  $$ \begin{align*} successful\quad search\quad &:\quad \frac { 1 }{ \alpha } \ln { \frac { 1 }{ 1-\alpha } } \\ unsuccessful\quad search\quad &:\quad \frac { 1 }{ \alpha } \end{align*} $$  해시테이블에 데이터가 반만 차 있다($α=0.5$)고 가정하면 successful search와 unsuccessful search의 탐사횟수 기대값은 각각 1.387, 2가 됩니다. 다시 말해 최초로 해시값을 만드는 1회를 뺀 나머지, 즉 한번 정도만 추가 탐사하면 원하는 데이터를 대체로 찾을 수 있다는 얘기입니다. 반대로 $α=0.8$이라면 탐사횟수 기대값은 8.047과 5로 치솟게 됩니다. 요컨대 open addressing 탐색 연산의 계산복잡성은 $α$에 크게 영향을 받는 구조입니다. 따라서 해시테이블에 데이터가 어느 정도 차게 되면 해시테이블 크기 $m$을 적절하게 늘려주고 처음부터 다시 해싱을 하는 것이 좋다고 합니다. 삭제와 삽입 연산 역시 탐사 횟수가 중요하기 때문에 해시테이블 크기에 신경을 써주어야 합니다.   ## 해시함수 이번엔 해시함수로 해시충돌을 완화하는 방법을 살펴보겠습니다. 해시테이블의 크기가 $m$이라면, 좋은 해시함수는 임의의 키값을 임의의 해시값에 매핑할 확률이 $1/m$이 될 겁니다. 다시 말해 특정 값에 치우치지 않고 해시값을 고르게 만들어내는 해시함수가 좋은 해시함수라는 이야기입니다.  ### division method 나눗셈법은 간단하면서도 빠른 연산이 가능한 해시함수입니다. 숫자로 된 키를 해시테이블 크기 $m$으로 나눈 나머지를 해시값으로 반환합니다. $m$은, 대개 소수(prime number)를 쓰며 특히 2의 제곱수와 거리가 먼 소수를 사용하는 것이 좋다고 합니다. 다시 말해 해시함수 특성 때문에 해시테이블 크기가 정해진다는 단점이 있다는 이야기입니다.  ### multiplication method 숫자로 된 키가 $k$이고 $A$는 0과 1 사이의 실수일 때 곱셈법은 다음과 같이 정의됩니다. $m$이 얼마가 되든 크게 중요하지는 않으며 보통 2의 제곱수로 정한다고 합니다. 나눗셈법보다는 다소 느리다고 합니다. 2진수 연산에 최적화한 컴퓨터 구조를 고려한 해시함수라고 합니다.  $$ h\left( k \right) =\left( kA\quad mod\quad 1 \right) \times m $$  ### universal hasing 다수의 해시함수를 만들고, 이 해시함수의 집합 $H$에서 무작위로 해시함수를 선택해 해시값을 만드는 기법입니다. $H$에서 무작위로 뽑은 해시함수가 주어졌을 때 임의의 키값을 임의의 해시값에 매핑할 확률을 $1/m$로 만드려는 것이 목적입니다. 다음과 같은 특정 조건의 해시함수 집합 $H$는 $1/m$으로 만드는 게 가능하다고 수학적으로 증명됐습니다.  - 해시테이블의 크기 $m$를 소수로 정한다. - 키값을 다음과 같이 $r+1$개로 쪼갠다 : $k_0$, $k_1$,..., $k_r$ - 0부터 $m-1$ 사이의 정수 가운데 하나를 무작위로 뽑는다. 분리된 키값의 개수($r+1$)만큼 반복해서 뽑는다. 이를 $a=[a_0, a_1,...,a_r]$로 둔다. 따라서 $a$의 경우의 수는 모두 $m^{r+1}$가지이다. - 해시함수를 다음과 같이 정의한다 : $h_a(x)=Σ_{i=0}^r{(a_ik_i\mod\ m)}$ - $a$가 $m^{r+1}$가지이므로 해시함수의 집합 $H$의 요소 수 또한 $m^{r+1}$개이다. 위와 같은 조건에서는 키가 동일하더라도 $a$가 얼마든지 랜덤하게 달라질 수 있고, 이에 해당하는 해시함수 $h_a$ 또한 상이해지기 때문에 $H$는 유니버설 함수가 됩니다.
comsent␞ 이번 글에서는 한국어 **복문(複文)**에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 복문이란 **단문(單文)**이란 주술관계가 한 번 있는 문장을, 복문이란 주술 관계가 둘 이상 포함된 문장을 가리킵니다. 아래 예에서 (가)는 단문, (나)~(라)는 복문입니다. > (가) 우리 집 셋째가 집에서 숙제를 한다. > > (나) \[인생은 짧고\] \[예술은 길다\]. > > (다) \[진이가 와서\] \[우리는 모임을 시작했다\]. > > (라) \[나는 \[봄이 왔음]을 오늘에서야 깨달았다\].   ## 학교문법에서 보는 복문의 종류 학교문법에서는 복문을 다음과 같이 분류합니다.  **이어진문장** - 대등적으로 이어진 문장 : *\[먼동이 트고\] \[별들이 사라진다\]* - 종속적으로 이어진 문장 : *\[먼동이 트자\] \[별들이 사라진다\]*  **안은 문장** - 명사절을 안은 문장 : *\[그가 돈이 많음\]이 분명하다* - 관형사절을 안은 문장 : *\[그가 우리를 도와 준\] 일을 잊지 맙시다* - 부사절을 안은 문장 : *그 사람이 \[말도 없이\] 떠나 버렸구나* - 서술절을 안은 문장 : *철수가 \[키가 아주 크다]*  그러나 위와 같이 (1) '대등적으로 이어진 문장(대등절)'과 '종속적으로 이어진 문장(종속절)'을 구별하고 (2) '종속적으로 이어진 문장'과 '부사절을 안은 문장(부사절)'을 별개의 것으로 보는 견해는 국어학계에서 소수라고 합니다. 실제 사례들을 따져보면 예외가 상당히 많이 발생하기 때문입니다. 세 가지 기준으로 살펴보겠습니다.   ## 이동가능성 첫번째 기준은 절이 문장 내에서 이동가능한지 여부로 종속절, 부사절, 대등절을 나눠보는 것입니다. 예문을 살펴보겠습니다.  **종속절** : 이동가능 > [아버지가 돌아가시자] 진이는 고향을 떠났다. > > 진이는 [아버지가 돌아가시자] 고향을 떠났다.  **부사절** : 이동가능 > [구름에 달이 흘러가듯이] 나그네가 간다. > > 나그네가 [구름에 달이 흘러가듯이] 간다.  **대등절** : 이동불가능 > [인생은 짧고] 예술은 길다. > > \*예술은 [인생은 짧고] 길다.  학교문법에서는 종속절이 대등절과 비슷하다고 봅니다. 그러나 이동가능성 기준을 놓고 볼 때 종속절은 오히려 부사절과 유사합니다.   ## 주어의 '은/는' 결합 가능성 두번째 기준은 분석 대상 절의 주어에 조사 '-은/는'이 붙을 수 있는지 여부입니다. 예문을 보겠습니다.  **종속절** : 결합불가능 > [{사촌이, *사촌은} 땅을 사서] 배가 아프다.  **부사절** : 결합불가능 > [{엄마가, *엄마는} 지나가게] 아빠가 길을 비켜 주셨다.  **대등절** : 결합가능 > [{산이, 산은} 높고] 물은 깊다.  주어의 '은/는' 결합 가능성 기준을 놓고 봐도 종속절은 부사절과 유사합니다.   ## 재귀 대명사의 결속 가능성 세번째 기준은 분석 대상 절에 재귀 대명사가 쓰일 수 있는지 여부입니다. 예문을 보겠습니다.  **종속절** : 결속가능 > 온달은 [**자기** 아내가 공주이므로] 부마가 된다.  **부사절** : 결속가능 > 진이는 [**자기** 동생이 지나가게] 길을 비켜 주었다.  **대등절** : 결속불가능 > 진이는 키가 크고 *\[**자기** 동생은 키가 작다].  재귀대명사의 결속 가능성 기준을 놓고 봐도 종속절은 부사절과 유사합니다.   ## 다시 보는 복문의 종류 지금까지 논의한 내용을 바탕으로 복문의 종류를 다시 분류해보면 다음과 같습니다. '종속적으로 이어진 문장(종속절)' 모두를 '부사절을 안은 문장(부사절)'으로 보는 것입니다.  **이어진 문장** - 대등적으로 이어진 문장  **안은 문장** - 명사절을 안은 문장 - 관형사절을 안은 문장 - 부사절을 안은 문장 (종속적으로 이어진 문장 포함) - 서술절을 안은 문장    ## 어미의 종류 어미를 위치와 기능에 따라 대략적으로 분류한 표는 다음과 같습니다.  <a href="https://imgur.com/6M5xQHq"><img src="https://i.imgur.com/6M5xQHq.png" width="500px" title="source: imgur.com" /></a>  **어말어미**란 단어의 끝에서 쓰이는 어미입니다. **선어말어미**란 어말어미 앞자리에서 쓰이는 어미입니다. 어말어미엔 **종결어미(문말어미)**와 **비종결어미** 둘로 나뉩니다. 종결어미는 한 문장을 끝맺는 기능을 합니다. 비종결어미엔 **연결어미(접속어미)**와 **전성어미**가 있습니다. 연결어미는 한 문장을 다음 문장으로 이어주는 역할을 합니다. 전성어미는 한 문장을 명사나 관형사, 부사와 같은 단어의 자격으로 전성(change)시키는 기능을 합니다. 여기에서 연결어미는 '이어진 문장', 전성어미는 '안은 문장'과 더 깊은 관련을 맺고 있습니다. 
recursive␞ 이번 포스팅에선 **Recursive Neural Networks(RNN)**에 대해 다뤄보려고 합니다. RNN은 **Recurrent Neural Networks**와 더불어 최근 자연언어처리 분야에서 각광받고 있는 모델인데요. 두 모델 모두 음성, 문자 등 순차적 데이터 처리에 강점을 지니고 있고 이름마저 유사해서 헷갈릴 수 있겠습니다만, 조금 차이가 있는 모델입니다. Recurrent Neural Networks에 대한 자세한 내용은 [이곳](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)을 참고하시기 바랍니다. 이번 글은 미국 스탠포드대학의 [CS224d](http://cs224d.stanford.edu/) 강의를 참고로 하되 순전파와 역전파 계산그래프는 제가 작성했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## recurrent vs convolutional vs recursive <a href="http://imgur.com/MmQRH38"><img src="http://i.imgur.com/MmQRH38.png" width="500px" title="source: imgur.com" /></a> Recurrent Neural Networks는 입력값을 순서대로 받아 하나씩 순차적으로 처리하는 네트워크 구조입니다. 위 그림처럼 'the country of my birth'라는 입력이 있을 때 첫 입력값은 'the'에 대응하는 단어벡터, 그 다음은 'country', 이후엔 각각 'of', 'my', 'birth'가 됩니다. 그림을 보시면 아시겠지만 입력값 중간에 건너뛰거나 하는 부분이 없고 등장순서대로 그대로 처리하는 구조입니다. 그리고 위 예시에선 은닉층이 하나인 구조를 띄고 있는데요, 마지막 히든 노드인 (2.5, 3.8)은 이전까지의 모든 맥락(the, country, of, my)과 함께 현재 입력값(birth) 정보가 모두 반영된 것을 알 수 있습니다. <a href="http://imgur.com/lb6M5Ov"><img src="http://i.imgur.com/lb6M5Ov.png" width="500px" title="source: imgur.com" /></a> 이제 **Convolutional Neural Networks(CNN)**를 볼까요? 입력값을 생략없이 모두 반영한다는 점에서는 Recurrent Neural Networks와 큰 차이는 없습니다. 하지만 입력값을 하나씩(the, country...) 보는 Recurrent Neural Networks와 달리 CNN은 위 그림을 보면 2개 단어씩(the country, country of, of my...) 한번에 분석하고 있는 것을 알 수 있죠. 이건 **필터(filter)**라는 존재 때문입니다. 여기서는 필터의 크기가 단어 2개로 세팅되어 있는데, 이 필터가 한칸씩 슬라이딩하면서 문장을 단어 두개씩 읽어들여 분석하는 구조입니다. Recurrent Neural Networks는 입력값이 순차적으로 주어지는 데 반해 CNN은 입력값이 한번에 주어지고 필터가 슬라이딩하면서 문장의 지역적인 정보를 반영한다는 점도 조금 다른 점입니다. 위 그림에서 삼각형의 상단 꼭지점에 해당하는 (3,3.5)가 이 문장의 전체 정보가 모두 반영된 벡터입니다. <a href="http://imgur.com/bfVzTm5"><img src="http://i.imgur.com/bfVzTm5.png" width="500px" title="source: imgur.com" /></a> Recursive Neural Networks(RNN)은 입력값으로 주어지는 몇 개 단어를 묶어서 분석한다는 점에 있어서는 CNN과 유사합니다. 하지만 CNN이 모든 지역정보를 생략없이 반영하는 데 비해 RNN은 일부 정보는 스킵한다는 점에 큰 차이를 보입니다. 예컨대 위 예시에서 'the country'는 'of my birth'의 수식을 받는 구조입니다. 또 'the country', 'my birth'는 'country of'나 'of my'보다는 응집성이 높은 표현입니다. CNN의 방식처럼 'the country', 'country of', 'of my'... 이렇게 모두 분석할 필요가 없다는 것이지요. RNN은 이러한 언어의 **hiarchy**한 성질을 네트워크 구조에 적극 차용한 모델이라고 볼 수 있습니다.  실제로 언어학에서는 문장을 아래와 같이 계층적으로 나누어 분석하고 있습니다. 한국어 파싱과 관련해서는 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/04/29/parsing/)을 참고하면 좋을 것 같습니다. <a href="http://imgur.com/Himmgu4"><img src="http://i.imgur.com/Himmgu4.png" width="500px" title="source: imgur.com" /></a> 다만 RNN은 Recurrent Neural Networks나 CNN과 달리 트리 구조의 입력값을 반드시 필요로 합니다. 예컨대 아래와 같은데요. 이런 구조의 데이터를 생성하려면 대단히 많은 시간과 비용을 들여야 하는데다 계산도 복잡하기 때문에 RNN이 CNN이나 Recurrent Neural Networks에 비해 주목을 덜 받는 경향이 있는 것 같습니다. > ( ( ( The ) ( actors ) ) ( ( ( are ) ( fantastic ) ) ( . ) ) ) 마지막으로 Recurrent Neural Networks는 Recursive Neural Networks의 특수 케이스라는 점을 짚어보겠습니다. 만약 Recursive Neural Networks가 모든 지역정보를 순서대로 빠짐없이 반영한다고 하면 아래와 같이 구조를 그릴 수 있는데요, 이를 각도 회전해놓고 보면 본질적으로 Recurrent Neural Networks와 같습니다. <a href="http://imgur.com/AwJAPQ0"><img src="http://i.imgur.com/AwJAPQ0.png" width="500px" title="source: imgur.com" /></a>  ## Simple RNN의 구조 RNN은 다음과 같이 여러 단어의 결합으로 이뤄진 표현을 벡터공간에 임베딩해 **파싱(parsing)**, **감성분석(sentiment analysis)** 등 특정과업을 수행하는 걸 목표로 합니다. <a href="http://imgur.com/2Vz4mg0"><img src="http://i.imgur.com/2Vz4mg0.png" width="500px" title="source: imgur.com" /></a> 가장 간단한 형태의 Simple RNN 구조는 아래 그림처럼 나타낼 수 있습니다. <a href="http://imgur.com/2InLlzA"><img src="http://i.imgur.com/2InLlzA.png" width="600px" title="source: imgur.com" /></a> 위 그림을 천천히 살펴보면 **자식노드(child node)**에 해당하는 단어벡터 $c_1$과 $c_2$가 1차적으로 **부모노드(parent node)** $p_1$으로 합쳐지고, $c_3$는 $p_1$과 함께 $p_2$를 만들고 있음 확인할 수 있습니다. RNN은 부모노드를 만들 때마다 점수(score)도 함께 생성합니다. 만약 파싱을 위한 RNN이라면 이 스코어는 합쳐진 단어들이 얼마나 말이 되는지를 나타내는 점수가 될 것이고, 감성분석을 위한 RNN이라면 해당 점수는 긍/부정 극성을 나타내는 지표가 됩니다. 한편 $p_2$는 또 다른 부모노드와 합쳐지기 위해 또 다시 분석대상이 됩니다. 이를 도식화한 것이 우측 상단의 그림인데요, 실선 방향은 계산그래프의 **forward pass**, 점선 방향은 그래디언트가 전파되는 **backward pass**로 이해하시면 좋을 것 같습니다.  $i$번째 부모노드인 $p_i$의 값은 아래처럼 정의됩니다. 각 파라메터의 차원수 또한 아래처럼 정의됩니다. 아래 식에서 pleft와 pright는 각각 $i$번째 부모노드의 좌측, 우측 자식노드입니다. 위 그림 기준으로 하면 $p_2$의 pleft는 $c_3$, pright는 $p_1$이 되는 셈이죠. $d$는 은닉층의 차원수로서 사용자가 지정해주는 하이퍼파라메터입니다.  $${ p }_{ i }=\tanh { (W\cdot \begin{bmatrix} { p }_{ left } \\ { p }_{ right } \end{bmatrix}+b) } \\ { p }_{ i }\in { R }^{ d },\quad b\in { R }^{ d },\quad W\in { R }^{ d\times 2d }\quad $$ 위 식에서 $W$와 pleft, pright의 결합은 아래와 같습니다. $$W\cdot \begin{bmatrix} { p }_{ left } \\ { p }_{ right } \end{bmatrix}=\begin{bmatrix} { w }_{ 1 } & { w }_{ 2 } \end{bmatrix}\cdot \begin{bmatrix} { p }_{ left } \\ { p }_{ right } \end{bmatrix}={ w }_{ 1 }{ \times p }_{ left }+{ w }_{ 2 }{ \times p }_{ right }$$ $i$번째 부모노드의 스코어, $s_i$를 구하는 식은 다음과 같습니다. $${ s }_{ i }={ W }_{ s }{ p }_{ i }+{ b }_{ s }$$ RNN은 이렇게 부모노드로부터 계산된 스코어와 해당 부분에 해당하는 정답 레이블과 비교한 후 오차를 최소화하는 방향으로 **역전파(backpropagation)**를 수행해 파라메터($W$, $b$, $W_s$, $b_s$)를 업데이트하는 방식으로 학습을 합니다. 이와 더불어 말단노드의 입력값들에도 그래디언트를 역전파해 학습시킨다면 벡터공간에 임베딩된 단어벡터를 얻어낼 수 있을 겁니다. 다만 여기서 주의할 것은 forward pass 수행 과정에서 경우의 수를 모두 고려해 스코어가 높은 선택지만을 뽑아 트리 구조를 만든다는 사실입니다. 아래 예시를 보면 처음 부모노드를 만들 때 그럭저럭 말이 되는 'The cat', 'the mat'만 결합시킵니다. 이후엔 'on the mat'을 만듭니다. 이런 식으로 반복 수행해서 전체 문장 'The cat sat on the mat'의 트리 구조를 구축하는데요. 학습 초기엔 이런 결합이 중구난방 이루어지다가 어느 정도 학습이 진행되면 정답과 유사하게 트리 구조가 만들어지게 됩니다. <a href="http://imgur.com/6C4vXGq"><img src="http://i.imgur.com/6C4vXGq.png" width="800px" title="source: imgur.com" /></a> 그런데 학습 과정에서의 트리 탐색은 **탐욕적(greedy)**인 방식입니다. CS224d 강의에 따르면 트리 구조 탐색시 [Beam Search Algorithm](https://en.wikipedia.org/wiki/Beam_search) 등을 이용한다고 합니다. Beam Search 알고리즘은 **최고우선탐색(Best-First Search)** 기법을 기본으로 하되 기억해야 하는 노드 수를 제한해 효율성을 높인 방식입니다. Beam Search 알고리즘에 대해 좀 더 자세히 살펴보시려면 [이곳](https://ratsgo.github.io/deep%20learning/2017/06/26/beamsearch/)을 참고하시면 좋을 것 같습니다.  ## Simple RNN의 forward pass 지금까지 이야기한 simple RNN 구조를 다시 그림으로 그리면 아래와 같습니다. 방향이 바뀌어서 헷갈리실 수도 있는데요, 계산그래프를 좀 더 예쁘게 그리려고 회전한 것이지 본질적으론 같은 그림이니 너무 놀라지 마셔요. 어쨌든 부모노드마다 스코어값이 모두 나온다는 점에 유의해서 보시면 좋을 것 같은데요. $p_1$에서 나오는 스코어는 $s_1$이고요, 마찬가지로 $p_2$에선 $s_2$가 나옵니다. <a href="http://imgur.com/Dh2lAP4"><img src="http://i.imgur.com/Dh2lAP4.png" width="600px" title="source: imgur.com" /></a> 위 그림을 토대로 forward compute pass를 그리면 아래 그림과 같습니다. 우선 첫번째 부모노드 $p_1$이 만들어지는 과정을 보시죠. 이전 챕터에서 소개드린 수식을 계산그래프로 바꿔놓은 것일 뿐입니다. <a href="http://imgur.com/dBgYVFI"><img src="http://i.imgur.com/dBgYVFI.png" width="600px" title="source: imgur.com" /></a> 이어서 $p_2$를 만드는 과정을 소개해드립니다. $p_2$는 $c_3$에 위 그림에서 만들어진 $p_1$을 결합해 만듭니다. <a href="http://imgur.com/Ja8GcTb"><img src="http://i.imgur.com/Ja8GcTb.png" width="600px" title="source: imgur.com" /></a>  ## Simple RNN의 backward pass 역전파 관련 내용이 생소하시거나 헷갈리시는 분은 미국 스탠포드대학의 [CS231n](http://cs231n.github.io/optimization-2/) 강의를 참고하시면 좋을 것 같습니다. 아시다시피 역전파는 계산과정의 맨 마지막 부분에서 시작되어야 합니다. <a href="http://imgur.com/RYmfwBJ"><img src="http://i.imgur.com/RYmfwBJ.png" width="600px" title="source: imgur.com" /></a> 우선 forward pass 과정에서 산출된 $s_2$와 정답을 비교해서 계산된 손실(Loss)값은 이미 구해졌다고 칩시다. 그렇다면 $s_2$의 그래디언트, 즉 $dL/ds_2$가 최초로 전파된 그래디언트값이 될 겁니다. 이를 편의상 $ds_2$라고 적었습니다. 계산그래프에서 덧셈연산은 흘러들어온 그래디언트가 그대로 전파되므로 $dL/db_s$는 흘러들어온 그대로 $ds_2$가 될 겁니다.  곱셈 연산은 [흘러들어온 그래디언트 * 로컬 그래디언트(상대방의 변화량)]이므로 $dW_s$는 $p_2 * ds_2$가 됩니다. 마찬가지로 $dp_2$는 $W_s * ds_2$가 됩니다. **하이퍼볼릭탄젠트** $tanh(x)$의 로컬 그래디언트는 $1-tanh^2(x)$이므로 $dp2raw$는 여기에 흘러들어온 그래디언트 $dp_2$를 곱해준 값이 됩니다.  $dp2raw$는 덧셈 그래프를 타고 그대로 분배가 되기 때문에 $db$는 그대로 $dp2raw$가 됩니다. $dW$와 $dp2concat$의 로컬 그래디언트는 각각 $p2concat$, $W$이므로 여기에 흘러들어온 그래디언트 $dp2raw$를 곱해주면 $dW$와 $dp2concat$을 구할 수 있습니다.  마지막 $dc_3$와 $dp_1$에 주의할 필요가 있는데요. $c_3$($d$차원 벡터)과 $p_1$($d$차원 벡터)은 사실 별도의 연산을 하지 않고 그냥 합치기만 한 후 ($2d$차원 x $d$차원) 크기의 가중치 행렬 $W$을 곱해 $p_2$를 만들어 나가게 되는데요. 역전파를 할 때는 이 가중치 행렬의 절반이 $c_3$의 그래디언트에, 나머지 절반이 $p_1$의 그래디언트에 영향을 미치게 됩니다.  따라서 $c_3$의 그래디언트는 $dp2concat$의 첫번째 절반, $p_1$의 그래디언트는 $dp2concat$의 나머지 절반이 됩니다. 혹시 헷갈리신다면 RNN의 기본구조 챕터에서 $W$와 pleft, pright의 결합 부분을 별도로 설명한 식을 보시면 좋을 것 같습니다. 한편 $p_1$의 그래디언트, 즉 $dp_1$은 별도로 **별표** 표시를 해두었는데요. Recursive Neural Networks는 이름 그대로 부모노드의 값을 재귀적으로 구해 나가는 구조이기 때문에 역전파 과정에서 그래디언트도 재귀적으로 반영되게 됩니다. 다음 그림에서 $dp_1$이 어떻게 반영되는지를 살펴볼까요? <a href="http://imgur.com/TswcLDq"><img src="http://i.imgur.com/TswcLDq.png" width="600px" title="source: imgur.com" /></a> 자, 이제 첫번째 부모노드 $p_1$을 구하는 그래프로 왔습니다. 우선 $p_1$을 통해서도 스코어 $s_1$이 계산되기 때문에 여기에서 전파되어 들어오는 그래디언트가 있습니다. 이를 ■로 표시했습니다. 그리고 앞선 그림에서 설명드렸듯이 ★ 또한 역전파 과정에서 흘러들어오게 됩니다. 따라서 위 그림에서 $dp_1$은 ■와 ★를 더해 만들어지게 되는 것이죠.  이후 역전파 과정은 이전에 설명했던 과정과 동일합니다. 지금은 이해를 돕기 위해 가장 단순한 구조의 RNN을 예로 들어서 설명을 드렸지만 이 구조가 깊어지면 각 층위마다 그래디언트가 재귀적으로 더해지면서 복잡한 양상을 띄게 됩니다.  ## Syntatically-Untied RNN **Syntatically-Unitied RNN(SU-RNN)**은 동사구, 명사구 등 기능이 다른 표현에 각기 다른 가중치를 적용하는 RNN 구조입니다. 반면 Simple RNN은 품사 정보에 상관없이 모든 구(phrase)에 같은 가중치를 씁니다. 둘의 비교는 아래 그림과 같습니다. <a href="http://imgur.com/3fZ2vDx"><img src="http://i.imgur.com/3fZ2vDx.png" width="500px" title="source: imgur.com" /></a> 아래는 학습이 잘 된 SU-RNN의 가중치를 시각화한 그림입니다. 붉은색일수록 그 가중치가 높은데요. DT(관사)-NP(명사구)를 맡은 가중치 $W$를 보시면 DT를 커버하는 $w_1$의 대각성분보다 NP를 담당하는 $w_2$의 대각성분의 값이 큰 걸 확인할 수 있습니다. 이는 SU-RNN이 과업을 수행할 때 관사보다는 명사구를 중요하게 취급했다는 반증인데요. 실제로 'a cat', 'the cat' 같은 표현에서 a, the보다는 cat이라는 명사가 중요한 의미를 가지니 직관적으로 납득할 만한 결과인 것 같습니다. 반면 VP(동사구)-NP(명사구)의 경우 둘 모두 중요하게 취급하고 있는 점을 볼 수 있습니다. <a href="http://imgur.com/QFG8Piw"><img src="http://i.imgur.com/QFG8Piw.png" width="400px" title="source: imgur.com" /></a> ## 마치며 이상으로 RNN과 Recurrent/Convolutional Neural Networks를 비교하고 Simple RNN의 구조와 foward/backward compute pass에 대해 살펴보았습니다. RNN 역시 다른 구조의 딥러닝 아키텍처와 마찬가지로 자연언어처리에 강점을 가진 구조로 널리 알려져 있는데요. 발전된 RNN 모델에 대해 살펴보시려면 [이곳](https://ratsgo.github.io/deep%20learning/2017/06/24/RNTN/)을 참고하시면 좋을 것 같습니다. 여기까지 읽어주셔서 진심으로 감사드립니다.
lexicon␞ 이번 포스팅에서는 자연언어처리의 기본 절차와 몇 가지 용어에 대해 살펴보도록 하겠습니다. 이번 포스팅은 기본적으로 [고려대 강필성 교수님](https://github.com/pilsung-kang/text-mining)과 역시 같은 대학의 정순영 교수님 강의를 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  # 자연언어처리의 기본 절차 <a href="http://imgur.com/1bhgstG"><img src="http://i.imgur.com/1bhgstG.png" width="500px" title="source: imgur.com" /></a> 자연언어처리의 전반적인 절차를 간략하게 시각화한 것은 위 그림과 같습니다. 자연언어처리는 우선 언어학을 근간으로 하고 있습니다. 주지하다시피 언어학은 말소리를 연구하는 **음운론(Phonology)**, [단어](https://ratsgo.github.io/korean%20linguistics/2017/04/10/word/)와 [형태소](https://ratsgo.github.io/korean%20linguistics/2017/03/20/morpheme/)를 연구하는 **형태론(Morphology)**, 문법과 맥락/담화를 각각 논의하는 **통사론(syntax)**, **의미론(Senmantics)** 등 세부 분야가 있는데요. 자연언어처리 절차와 단계도 이런 구분과 궤를 같이 합니다. 다시 말해 음성 인식, 형태소 분석, 파싱(문장의 문법적 구조 분석) 등이 각각 언어학의 음운/형태/통사론 등에 대응된다는 얘기입니다. 구체적인 분석 과정을 도표로 정리한 그림은 다음과 같습니다. <a href="https://imgur.com/KgyPoG1"><img src="https://i.imgur.com/KgyPoG1.png" width="500px" title="source: imgur.com" /></a> 과정별로 나타낸 그림은 다음과 같습니다. <a href="https://imgur.com/jxZnuyN"><img src="https://i.imgur.com/jxZnuyN.png" width="500px" title="source: imgur.com" /></a> 이번 글에서는 **어휘분석(Morphological and lexcical analysis)** 중심으로 이야기를 해보겠습니다.   # 어휘분석(Lexical Analysis) 어휘 분석을 한눈에 조망할 수 있는 그림이 바로 아래 예시입니다.  <a href="http://imgur.com/lpuN4IT"><img src="http://i.imgur.com/lpuN4IT.png" width="600px" title="source: imgur.com" /></a> **포스태깅(Part of speech)**는 단어의 품사 정보를 결정하는 절차이며 **개체명 인식(Named entity recognition)**은 인명, 지명 등 고유명사를 분류하는 방법론입니다. **상호참조(co-reference)**는 선행 단어/구를 현재 단어/구와 비교해 같은 개체인지를 결정하는 문제입니다. **의존관계 분석(basic dependencies)**은 성분에 따라 문장구조를 정의하는 구구조문법(생성문법 기반)과 달리 단어와 다른 단어가 가지는 의존관계를 중시해 문장 구조를 분석하는 방법입니다. 이들 넷은 모두 어휘분석의 하위 범주로 언어학, 통계학, 수학, 컴퓨터사이언스 등 다양한 분야의 학자들이 꽤 많은 성과를 낸 영역입니다. 사실 자연언어처리는 이들 영역이 모두 겹쳐있는 융합학문입니다. <a href="http://imgur.com/5eyQgSs"><img src="http://i.imgur.com/5eyQgSs.png" width="400px" title="source: imgur.com" /></a>   # 어휘분석 절차 이번 챕터에서는 어휘분석 절차에 대해 이야기해보겠습니다. 크게 **문장분리(sentence splitting)**, **토크나이즈(tokenize), Morphological analysis**, **포스태깅** 네 단계로 나뉩니다.  ## Sentence splitting 컴퓨터 입장에서 **말뭉치(corpus)**는 의미없는 글자들의 나열일 겁니다. 우선 이를 문장 단위로 끊어서 입력해야 합니다. 일반적으로는 마침표(.)나 느낌표(!), 물음표(?) 등 기준으로도 충분히 문장분리를 잘 수행할 수 있습니다. 하지만 토픽모델링 같은 특정 알고리즘이나 방법론의 경우 문장분리를 반드시 수행하지 않아도 됩니다.  ## Tokenize **토큰(token)**이란 의미를 가지는 문자열을 뜻합니다. 토큰은 형태소(뜻을 가진 최소 단위)나 그보다 상위 개념인 **단어**(자립하여 쓸 수 있는 최소 단위)까지 포함합니다. **토크나이징(tokenizing)**이란 문서나 문장을 분석하기 좋도록 토큰으로 나누는 작업입니다. 영어의 경우 공백만으로도 충분히 토큰을 나눌 수 있다고 합니다. 물론 '-'(state-of-the-art vs state of the art)이나 합성어(Barack Obama) 등 처리를 세밀히 해줘야 하는 문제가 남아있긴 하지만요. 띄어쓰기를 거의 하지 않는 중국어의 경우 토큰 분석 작업이 난제로 꼽힙니다.  ## Morphological analysis **Text Normaization**이라고 불리기도 합니다. 토큰들을 좀 더 일반적인 형태로 분석해 단어수를 줄여 분석의 효율성을 높이는 작업입니다. 예컨대 'cars'와 'car', 'stopped'와 'stop'을 하나의 단어로 본다던지 하는 식입니다. 영어에선 대문자를 소문자로 바꿔주는 **folding**도 이와 관련된 중요한 작업이라고 하네요. **stemming**과 **lemmatization**이라는 작업도 있습니다. stemming이란 단어를 축약형으로 바꿔주는 걸 뜻하고, lemmatization은 품사 정보가 보존된 형태의 기본형으로 변환하는 걸 말합니다. 아래 표가 두 기법 차이를 잘 드러내고 있습니다. |  Word   | stemming | lemmatization | | :---------: | :------: | :-----------: | |  Love   |  Lov  |   Love   | |  Loves  |  Lov  |   Love   | |  Loved  |  Lov  |   Love   | |  Loving  |  Lov  |   Love   | | Innovation | Innovat | Innovation  | | Innovations | Innovat | Innovation  | | Innovate  | Innovat |  Innovate  | | Innovates | Innovat |  Innovate  | | Innovative | Innovat | Innovative  |  ## Part-Of-Speech Tagging 포스태깅이란 토큰의 품사정보를 할당하는 작업입니다. 지금까지 많은 방법론들이 개발되었는데요. 의사결정나무(Decision Trees), 은닉 마코프 모델(Hidden Markov Models), 서포트벡터머신(Support Vector Machines) 등이 여기에 해당합니다. [KoNLPy](http://konlpy.org) 같은 한국어 기반의 포스태거들은 문장분리, 토크나이즈, lemmatization, 포스태깅에 이르기까지 전 과정을 한꺼번에 수행해 줍니다. 하지만 조사, 어미가 발달한 한국어의 경우 정확한 분석이 정말 어렵습니다. 한국어는 **교착어** 성질을 지니는 언어이기 때문입니다. 즉 **어근**에 파생접사나 어미가 붙어서 단어를 이룹니다. 바꿔 말하면 한국어를 분석할 때 어근과 접사, 어미를 적절하게 나누어야 하는데, 이게 쉽지 않다는 얘기입니다. 예를 들면 이렇습니다. > 깨뜨리시었겠더군요. 여기에서 '깨-'는 어근이며, '-뜨리-'는 접사로서 '힘줌'의 뜻을 나타냅니다. '-시-'는 높임, '-었-', '-겠-', '-더-'는 모두 시간을 보이는 어미들이며, '-군-'은 감탄의 뜻을 나타내는 어미, '-요'는 문장을 끝맺는 어미입니다. 위 문장을 제대로 분석하려면 8개 형태소로 쪼개야 합니다. 매우 고된 작업이지요.  ## 마치며 이상으로 자연언어처리의 기본 절차를 어휘분석 중심으로 살펴보았습니다. 정리하면서 느낀 건데 단어와 형태소 분석이 자연언어처리의 기본 중 기본 아닐까 하는 생각이 듭니다. 이 작업이 신통치 않다면 이를 기반으로 하는 파싱(문장 구조 분석) 등 이후 과정의 신뢰도가 무너지게 될 겁니다. 더 나은 방법이 없을까 늘 고민해보겠습니다. 여기까지 읽어주셔서 감사합니다. 
RLR␞ 이번 글에서는 회귀계수들에 제약을 가해 **일반화(generalization)** 성능을 높이는 기법인 **Regularized Linear Regression**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 김성범 교수님, 같은 대학의 강필성 교수님 강의, 미국 스탠포드 대학의 CS231n 강의 노트 일부를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 정규화의 목적 **정규화(regularization)**란 회귀계수가 가질 수 있는 값에 제약조건을 부여하는 방법입니다. 미래데이터에 대한 오차의 기대값은 모델의 **Bias**와 **variance**로 분해할 수 있는데요. 정규화는 variance를 감소시켜 일반화 성능을 높이는 기법입니다. 물론 이 과정에서 bias가 증가할 수 있기는 하지만요. 정규화의 이론적 배경인 Bias-Variance Decomposition에 대해 살펴보시려면 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/19/biasvar/)을 참고하시기 바랍니다. 정규화의 결과를 직관적으로 나타낸 그림은 아래와 같습니다. 하단좌측 그림은 학습데이터를 정말 잘 맞추고 있지만, 미래 데이터가 조금만 바뀌어도 예측값이 들쭉날쭉할 수 있습니다. 반면 우측 그림은 가장 강한 수준의 정규화를 수행한 결과인데요. 학습데이터에 대한 설명력을 다소 포기하는 대신 미래 데이터 변화에 상대적으로 안정적인 결과를 냅니다.  <a href="http://imgur.com/edAE2WU"><img src="http://i.imgur.com/edAE2WU.png" width="400px" title="source: imgur.com" /></a>  ## 일반 선형회귀 모델 정규화는 **일반 선형회귀 모델(Ordinary Linear Regression Model)**에서 도출된 회귀계수들에 제약을 가하는 방법론입니다. 일반 선형회귀 모델은 종속변수($y$)의 실제값과 모델의 예측값 사이의 **평균제곱오차(Mean Square Error)**를 최소화하는 회귀계수들의 집합을 가리킵니다. 이러한 회귀계수를 뽑는 데 쓰는 기법을 **최소자승법(Least Squares Method)**라고 합니다. 우리가 가진 학습데이터의 독립변수가 $k$개, 관측치가 $n$개라고 칩시다. 그러면 이로부터 도출할 수 있는 일반 선형회귀 모델을 행렬 형태로 나타내면 다음과 같습니다. 아래 행렬에서 1은 회귀모델의 상수항에 대응하는 값입니다.  $$ \begin{bmatrix} \hat{ y }_{ 1 } \\ \hat{ y }_{ 2 } \\ ... \\\hat { y }_{ n } \end{bmatrix}=\begin{bmatrix} 1 & { x }_{ 11 } & ... & { x }_{ 1k } \\ 1 & { x }_{ 21 } & ... & { x }_{ 2k } \\ ... & ... & ... & ... \\ 1 & { x }_{ n1 } & ... & { x }_{ nk } \end{bmatrix}\begin{bmatrix} { \beta }_{ 0 } \\ { \beta }_{ 1 } \\ ... \\ { \beta }_{ k } \end{bmatrix} $$  이를 행렬식으로 간단히 나타내면 다음과 같습니다. 독립변수로 구성된 행렬 $X$, 종속변수로 구성된 벡터 $y$는 우리가 이미 가지고 있는 학습데이터이고 벡터 y-hat은 모델이 예측한 값입니다. 회귀계수 벡터 $β$가 모델 구축 결과물입니다.  $$ \hat { y } =X \beta  $$  최소자승법은 실제값과 예측값의 MSE를 최소화하도록 합니다. 아래와 같이 쓸 수 있습니다.  $$ \begin{align*} { \hat { \beta }^{ LS } } &=\min _{ \beta }{ { (y-\hat { y } ) }^{ T }(y-\hat { y } ) } \\ &=\min _{ \beta }{ { (y-X\beta ) }^{ T }(y-X\beta ) } \end{align*} $$  최소자승법의 해인 회귀계수 벡터 $β$는 위 식을 $β$로 미분한 식을 0으로 놓고 풀면 다음과 같이 명시적으로 구할 수 있습니다.  $$ { \hat { \beta }^{ LS } }  ={ ({ X }^{ T }X) }^{ -1 }{ X }^{ T }y $$  이렇게 구한 $β$는 bias가 없는 추정량 가운데 variance가 가장 작다고 합니다. 이름하여 **Best Linear Unbiased Estimator(BLUE)**입니다. 앞으로 설명해드릴 정규화 기법들은 bias를 소폭 허용(희생)하면서 variance를 줄이는 방법론이라고 할 수 있겠습니다.   ## 릿지회귀 **릿지 회귀(Ridge Regression)**란 평균제곱오차를 최소화하면서 회귀계수 벡터 $β$의 $L_2$ norm을 제한하는 기법입니다. 선형회귀 모델의 목적식(MSE 최소화)과 회귀계수들에 대한 제약식을 함께 쓰면 아래와 같습니다. 여기에서 $λ$는 제약을 얼마나 강하게 걸지 결정해주는 값으로 사용자가 지정하는 하이퍼파라메터입니다.  $$ { { \hat{ \beta }^{ Ridge } } } =\arg\min _{ \beta }{ \left\{ { (y-X\beta ) }^{ T }(y-X\beta )+\lambda { \beta }^{ T }\beta \right\} } $$  릿지회귀의 해인 회귀계수 벡터 $β$는 위 식을 $β$로 미분한 식을 0으로 놓고 풀면 다음과 같이 명시적으로 구할 수 있습니다.  $$ { { \hat{ \beta }^{ Ridge } } } ={ ({ X }^{ T }X+\lambda I) }^{ -1 }{ X }^{ T }y $$  평균제곱오차뿐 아니라 $β$의 $L_2$ norm 또한 최소화하는 것이 릿지 회귀의 목적입니다. 우선 아래 예시 표를 볼까요? <a href="http://imgur.com/8qnLAnf"><img src="http://i.imgur.com/8qnLAnf.png" width="400px" title="source: imgur.com" /></a> MSE 기준으로는 벡터 $β$의 첫번째 요소 $β_1$과 두번째 요소 $β_2$가 각각 4, 5여야 최소입니다. 일반 선형회귀 모델이었다면 (4,5)가 회귀계수로 결정됐을 겁니다.  하지만 여기에 $β_1^2+β_2^2$이 30 이하여야 한다는 제약을 가해 봅시다. 그러면 표 상단 세 가지 경우의 수는 고려에서 제외됩니다. 제약을 만족하는 나머지 세 개 가운데 MSE가 최소인 (2,4)를 회귀계수로 결정하는 것이 릿지 회귀의 방식입니다.  ## 릿지회귀의 기하학적 이해 우리가 찾아야 하는 최적 회귀계수 벡터 $β$를 [$β_1, β_2$]라고 두겠습니다. 평균제곱오차를 식으로 쓰면 다음과 같습니다. (아래 식의 모든 요소는 스칼라값입니다)  $$ \begin{align*} MSE({ \beta }_{ 1 },{ \beta }_{ 2 })=&\sum _{ i=1 }^{ n }{ { ({ y }_{ i }-{ \beta }_{ 1 }{ x }_{ i1 }-{ \beta }_{ 2 }{ x }_{ i2 }) }^{ 2 } } \\ =&\left( \sum _{ i=1 }^{ n }{ { x }_{ i1 }^{ 2 } } \right) { \beta }_{ 1 }^{ 2 }+\left( \sum _{ i=1 }^{ n }{ { x }_{ i2 }^{ 2 } } \right) { \beta }_{ 2 }^{ 2 }+2\left( \sum _{ i=1 }^{ n }{ { x }_{ i1 }{ x }_{ i2 } } \right) { \beta }_{ 1 }{ \beta }_{ 2 }\\&-2\left( \sum _{ i=1 }^{ n }{ { y }_{ i }{ x }_{ i1 } } \right) { \beta }_{ 1 }-2\left( \sum _{ i=1 }^{ n }{ { y }_{ i }{ x }_{ i2 } } \right) { \beta }_{ 2 }+\sum _{ i=1 }^{ n }{ { y }_{ i }^{ 2 } } \end{align*} $$  위 식을 자세히 보시면 MSE는 $Aβ_1^2+Bβ_1β_2+Cβ_2^2+Dβ_1+Eβ_2+F$ 형태의 **원추곡선(conic equation)**이 됩니다. 타원, 쌍곡선, 원, 포물선은 원추곡선의 특수한 경우에 해당하는데요. 판별식 $B^2-4AC$이 0보다 작으면 타원 형태가 된다고 합니다. 위 식에서 판별식을 계산해 보면 **코시-슈바르츠 부등식** 조건에 의해 0 이하가 됩니다.  따라서 MSE가 같은 [$β_1, β_2$]의 자취를 그려보면 **타원** 모양이 된다는 겁니다. 바로 아래 그림처럼요. <a href="http://imgur.com/RBxwo0D"><img src="http://i.imgur.com/RBxwo0D.png" width="700px" title="source: imgur.com" /></a> 좌측상단 그림에서 타원 모양의 녹색 실선은 MSE가 동일한 [$β_1, β_2$]의 자취입니다. $β^{LS}$라고 표시된 검정색 점은 일반 선형회귀 모델의 결과로, MSE가 최소가 되는 지점입니다. 여기에서 멀리 떨어져 있는 타원일 수록 MSE가 점점 커진다고 이해하면 좋을 것 같습니다. 좌측상단 그림에서 파란색 원은 $β$의 $L_2$ norm이 동일한 [$β_1, β_2$]의 자취입니다. 원의 반지름이 작아질 수록 $L_2$ norm이 감소하고, 그만큼 제약이 커진다고 이해하면 좋을 것 같습니다. 다시 말해 하이퍼파라메터 $λ$가 클수록 $β$의 $L_2$ norm이 줄어듭니다.  우리가 특정 $λ$을 지정해 $β_1^2+β_2^2$이 $t_3$ 이하가 되도록 제약을 가했다고 가정해 봅시다. 그러면 릿지 회귀 기법은 이러한 제약을 만족하면서도 MSE가 최소인 지점에 해당하는 [$β_1, β_2$]를 찾게 됩니다. 위 예시 기준으로는 $β^{LS}$라고 표시된 검정색 점과 가장 가까운 점이 릿지 회귀의 결과가 될 겁니다. 하이퍼파라메터 $λ$를 0으로 두면 릿지 회귀의 제약식($λβ^Tβ$)이 사라지기 때문에 일반 선형회귀 모델의 결과와 동일한 회귀계수들을 얻을 수 있습니다. 하지만 $λ$가 커질수록(=$t$가 작아질수록) 회귀계수들에 가해지는 제약이 커져서 계수들의 값이 점점 줄어드는 모습을 우측상단 그래프에서 확인할 수 있습니다. 마지막으로 릿지회귀에서의 ridge는 산등성이라는 뜻을 가졌는데요. 위 그림에서처럼 MSE와 제약식이 가지는 자취가 산등성이 모양을 지녀서 이런 이름이 붙은 것 아닌가 생각합니다.  ## 라쏘회귀 **라쏘회귀(Least Absolute Shrinkage and Selection Operator)**의 목적식과 제약식을 한번에 쓰면 다음과 같습니다. 릿지회귀와 동일하지만 $L_1$ norm을 제약한다는 점이 다릅니다.  $$ { { \hat { \beta } ^{ Lasso } } }=\min _{ \beta }{ \left\{ { (y-X\beta ) }^{ T }(y-X\beta )+\lambda { \left\| \beta \right\| }_{ 1 } \right\} } $$  요소 개수가 $p$개인 회귀계수 벡터 $β$의 $L_1$ norm은 각 요소에 절대값을 취한 뒤 모두 더해 구합니다. 아래와 같습니다.  $$ { \left\| \beta \right\| }_{ 1 }=\sum _{ i=1 }^{ p }{ \left| { \beta }_{ i } \right| } $$  $L_1$ norm은 미분이 불가능하기 때문에 라쏘회귀의 경우 해를 단박에 구할 수 없습니다. 이 때문에 numerial 기법들이 다양하게 제시됐습니다.  ## 라쏘회귀의 기하학적 이해 우리가 찾아야 하는 최적 회귀계수 벡터 $β$를 [$β_1, β_2$]라고 두고, 이를 그림으로 나타내면 다음과 같습니다.  <a href="http://imgur.com/xsa2fNQ"><img src="http://i.imgur.com/xsa2fNQ.png" width="600px" title="source: imgur.com" /></a>  MSE가 동일한 [$β_1, β_2$]의 자취는 릿지회귀 때와 마찬가지로 타원입니다. 제약식은 $L_1$ norm(절대값)을 썼기 때문에 $L_2$ norm이 동일한 [$β_1, β_2$]의 자취는 마름모 꼴이 됩니다.  파란색 마름모 꼴의 제약 범위 내에서 MSE가 최소인 점은 $β_2$축 위의 검정색 점입니다. 이 점은 바로 $β_1=0$인 지점인데요. $β_1$이 0이라는 이야기는 그에 대응하는 독립변수 $x_1$이 예측에 중요하지 않다는 말과 같습니다.  이처럼 라쏘회귀는 예측에 중요하지 않은 변수의 회귀계수를 감소시킴으로써 **변수선택(Feature Selection)**하는 효과를 낸다고 합니다.  ## 엘라스틱넷 **엘라스틱넷(Elastic Net)**은 제약식에 $L_1, L_2$ norm 모두 쓰는 기법입니다. 목적식과 제약식을 한번에 쓰면 다음과 같습니다.  $$ { { \hat { \beta } ^{ enet } } }=\min _{ \beta }{ \left\{ { (y-X\beta ) }^{ T }(y-X\beta )+{ \lambda }_{ 1 }{ { \left\| \beta \right\| }_{ 1 }+\lambda }_{ 2 }{ \beta }^{ T }\beta \right\} } $$   ## 릿지회귀 vs 라쏘회귀 vs 엘라스틱넷 세 가지 방법을 비교한 표는 다음과 같습니다. |  구분  |    릿지회귀     |    라쏘회귀    |     엘라스틱넷     | | :------: | :-----------------: | :---------------: | :-------------------: | |  제약식  |   $L_2$ norm   |  $L_1$ norm   |  $L_1$+$L_2$ norm  | |  변수선택  |     불가능     |    가능     |     가능      | | solution |   closed form   |   명시해 없음    |    명시해 없음     | |  장점  | 변수간 상관관계가 높아도 좋은 성능 | 변수간 상관관계가 높으면 성능↓ |  변수간 상관관계를 반영한 정규화  | |  특징  | 크기가 큰 변수를 우선적으로 줄임 | 비중요 변수를 우선적으로 줄임 | 상관관계가 큰 변수를 동시에 선택/배제 | 세 기법의 제약식의 자취를 그림으로 나타내면 아래와 같습니다. (녹색 점선=릿지회귀, 검정색 점선=라쏘회귀, 파란색 도형=엘라스틱넷) <a href="http://imgur.com/7rPnTjz"><img src="http://i.imgur.com/7rPnTjz.png" width="400px" title="source: imgur.com" /></a>  ## 기타 정규화 기법들 인접한 변수들을 동시에 선택하는 **Fused Lasso**, 사용자가 정의한 그룹 단위로 변수를 선택하는 **Group Lasso**, 사용자가 정의한 그래프의 연결 관계에 따라 변수를 선택하는 **Graph-Constrained Regularization** 등이 있습니다.   ## 딥러닝과의 연계 이미지가 주어졌을 때 해당 이미지가 고양이인지 개인지 배인지를 맞추는 문제를 푼다고 칩시다. 다음과 같이 다범주 선형회귀 모델을 만들 수 있습니다.  <a href="https://imgur.com/Lm6DF5y"><img src="https://i.imgur.com/Lm6DF5y.png" title="source: imgur.com" /></a>  여기서 하나 상상해 봅시다. 만약 입력데이터 $x$가 [1, 1, 1, 1]이고 cat score를 만드는 데 쓰이는 가중치 벡터($W$의 첫 행벡터) $w_1$이 [1, 0, 0, 0]이라 칩시다. dog score를 만드는 가중치 벡터 $w_2$는 [0.25, 0.25, 0.25, 0.25]라 칩시다. 이렇게 되면 $w_1x=w_2x=1$이 되어 같은 결과를 냅니다. 다만 차이가 있습니다. $w_1$은 데이터의 특정 영역만 보고 dog인지 판단한다면, $w_2$는 데이터를 전체적으로 보고 판단한다는 겁니다. 이번엔 ship score를 내는 $w_3$가 [2, 2, 2, 2]라고 칩시다. $w_3x=8$이 되어 최종적으로 이 그림이 ship으로 분류되게 됩니다. 그런데 이렇게 되면 ship이라는 클래스가 cat이나 dog보다 더 큰 영향력을 발휘하게 되어 결과적으로 미지의 데이터에 대한 일반화 성능이 떨어지게 됩니다(어떤 그림이 들어와도 ship이라고 분류). 손실 최소화와 동시에 정규화(regularization)를 하는 이유입니다. 위 예시에서 $w_1$의 L2 norm은 1, $w_2$는 0.25, $w_3$은 16입니다. 
generate2␞ 이번 글에서는 **유한문법(finite grammar)**을 바탕으로 문장을 생성하는 모델에 대해 살펴보도록 하겠습니다. 이 글은 '밑바닥부터 시작하는 데이터 과학(조엘 그루스 지음, 인사이트 펴냄)'을 정리하였음을 먼저 밝힙니다. 지금은 저 스스로 정리할 목적으로 올리는 포스트인데요, 한국어를 기반으로 한 실험 결과를 조만간 업데이트하겠습니다.  ## 아이디어 문법에 기반해 말이 되는 문장을 생성해보자는 게 핵심 아이디어입니다.  예컨대 영어에서 문장(S)은 명사구(NP)와 동사구(VP)로 분석할 수 있습니다. 동사구(VP)에는 동사 하나(V)로만 구성될 수 있지만 동사(V)와 명사구(NP)가 결합해 있는 구로도 구성될 수 있습니다. 그런데 이 명사구(NP)에는 다시 명사(N) 하나로만 구성될 수도 있고, 형용사(A)+명사구(NP)+전치사(P)+형용사(A)+명사(N)로 이뤄진 구일 수도 있습니다. 다시 말해 유한한 수의 문법규칙만으로도 무한한 개수의 문장을 만들어낼 수 있다는 이야기입니다. ```python grammar = {   "_S" : ["_NP _VP"],   "_NP" : ["_N",       "_A _NP _P _A _N"],   "_VP" : ["_V",       "_V _NP"],   "_N" : ["data science", "Python", "regression"],   "_A" : ["big", "linear", "logistic"],   "_P" : ["about", "near"],   "_V" : ["learns", "trains", "tests", "is"] } ```   ## 코드 그렇다면 유한문법 규칙을 활용해 어떻게 문장을 생성할 수 있을까요? 문장(S)로 시작한다고 했을 때 모든 항목이 종결어(teminal)가 될 때까지 유한문법규칙에 맞는 구나 단어를 재귀적으로 선택함으로써 만들어낼 수 있습니다. 그 코드는 다음과 같습니다. ```python import random def is_terminal(token):   return token[0] != "_" def expand(grammar, tokens):   for i, token in enumerate(tokens):     # ignore terminals     if is_terminal(token): continue     # choose a replacement at random     replacement = random.choice(grammar[token])     if is_terminal(replacement):       tokens[i] = replacement     else:       tokens = tokens[:i] + replacement.split() + tokens[(i+1):]     return expand(grammar, tokens)   # if we get here we had all terminals and are done   return tokens def generate_sentence(grammar):   return expand(grammar, ["_S"]) ``` 
genmodels␞ 이번 글에서는 *Generative model*, 특히 Generative Adversarial Network(GAN)의 다양한 응용 연구들에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. PyTorch 코드는 [이곳](https://github.com/InsuJeon/Hello-Generative-Model)을 참고하였습니다. GAN과 관련해서는 [이곳](https://ratsgo.github.io/generative%20model/2017/12/20/gan/)을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.   ## EnhanceNet EnhanceNet은 GAN의 손실함수를 적용해 *Super Resolution* 기법의 성능을 높였습니다. *Super Resolution*(SR)이란 아래 그림처럼 저해상도의 이미지/영상을 고해상도로 변환하는 작업을 가리킵니다.  <a href="https://imgur.com/VxuNxlQ"><img src="https://i.imgur.com/VxuNxlQ.png" width="400px" title="source: imgur.com" /></a>  EnhanceNet이 SR 문제에 GAN 구조를 적용한 아이디어는 이렇습니다. 생성자 $G$의 인풋으로 노이즈 대신 저해상도의 이미지를 입력합니다. 판별자 $D$는 $G$가 생성한 가짜 고해상도 이미지와 실제 고해상도 이미지를 구분하는 역할을 합니다. $G$는 $D$를 속이도록 고해상도 이미지를 생성하도록 학습됩니다. 이처럼 EnhanceNet은 어떤 task이든 GAN 손실함수를 사용하여 원하는 결과를 얻어낼 수 있다는 점에서 눈길을 끕니다. GAN 손실함수의 효과를 직관적으로 나타낸 그림은 아래와 같습니다. 원본 고해상도 이미지 $I_{HR}$에서 인위적으로 해상도를 낮춘 이미지 $I_{LR}$이 있다고 칩시다. $I_{LR}$을 인풋, $I_{HR}$을 정답으로 놓고 학습시킬 때 평균제곱오차(Mean Squared Error)를 손실함수로 많이들 씁니다. MSE는 아래 그림처럼 입력값과 정답을 평균(average)하려는 성향이 강하다(MSE와 관련해서는 [이곳](https://ratsgo.github.io/linear%20algebra/2017/10/20/projection/) 참고)는 점이 단점입니다. 그런데 GAN 손실함수(adversarial loss)를 썼더니 $I_{HR}$을 제법 잘 근사하는 걸 확인했다고 합니다.  <a href="https://imgur.com/95muNZL"><img src="https://i.imgur.com/95muNZL.png" width="300px" title="source: imgur.com" /></a>   ## SimGAN SimGAN의 목적은 현실감 있는 인공데이터를 만들어내는 데 있습니다. 이 때 GAN을 씁니다. 아이디어는 이렇습니다. 기존 GAN의 생성자 역할을 하는 Refiner $R$은 인공데이터를 받아서 실제 데이터로 변환하는 역할을 합니다. 판별자 $D$는 $R$이 생성한 가짜(refined) 데이터와 실제(real) 데이터를 구분하는 역할을 합니다. $R$이 $D$를 속이려고 하는 과정에서 $R$이 학습됩니다. 이 과정을 도식적으로 나타내면 다음 그림과 같습니다.  <a href="https://imgur.com/1EiwI8F"><img src="https://i.imgur.com/1EiwI8F.png" width="500px" title="source: imgur.com" /></a>  SimGAN에서는 다른 연구에 참고가 될 만한 몇 가지 기술들이 포함돼 있습니다. 우선 Self-Regularization입니다. $R$을 학습시킬 때 기존 GAN 손실함수만 사용할 경우, $R$이 그저 $D$를 속이는 데만 집중하게 되면서 $R$이 생성한 데이터가 실제 데이터와 완전히 동떨어지게 될 염려가 크기 때문입니다. $R$의 입력값인 인공데이터도 조악하나마 실제 데이터의 특징을 담고 있으므로 $R$의 손실함수에 다음과 같은 regularization 항을 추가했습니다.  $$ { L }_{ reg }={ \left\| \psi \left( R\left( x \right) \right) -\psi \left( x \right) \right\| }_{ 1 } $$  위와 같은 항을 손실함수에 추가하게 되면 $R$에 입력되는 인공데이터 $x$와 $R$이 산출한 데이터 $R(x)$ 사이의 오차가 줄어들게 됩니다. 결과적으로 $R$이 생성하는 데이터가 입력데이터에서 너무 벗어나지 않게 되는 셈이죠. 단 여기에서 $ψ$는 입력값의 *feature*를 뽑는 함수인데요. 논문에서는 *identity mapping*을 사용했다고 합니다. 또 한가지 기법은 Local patch-Discriminator입니다. 기존 GAN에서 $D$는 입력데이터 전체를 보고 real/fake 여부를 판별합니다. 이 때문에 $G$는 대개 $D$를 속이기 위해 데이터의 일부 특징을 과장하려는 경향이 있습니다. 이 문제를 완화하기 위해 다음 그림과 같이 $D$가 데이터의 일부 영역만 보도록 하고, 전체적인 판단은 이들 패치의 평균이라든지 가중합이라든지 하는 방식으로 취하도록 했습니다. 그 결과 $D$의 능력을 어느 정도 제한하면서 $R$의 성능을 높일 수 있었다고 합니다.    <a href="https://imgur.com/s7LygPQ"><img src="https://i.imgur.com/s7LygPQ.png" width="400px" title="source: imgur.com" /></a>  마지막으로 언급할 부분은 History Buffer입니다. 기존 GAN에선 $D$를 학습시키는 과정에서 최근 학습샘플에만 적합하는 문제가 있었습니다. 이를 *continual learning issue* 내지 *catastrophic forgetting problem*이라고도 합니다. 이 문제를 해결하기 위해 도입된 것이 바로 History Buffer입니다. buffer에 예전 학습 데이터를 모아뒀다가 최신 데이터와 함께 학습시키자는 아이디어입니다. 결과적으로 $D$로 하여금 $R$이 예전에 생성한 데이터를 지속적으로 기억할 수 있게 도와줍니다. SimGAN에서는 아래와 같이 적용됐습니다.   <a href="https://imgur.com/uTXIhEh"><img src="https://i.imgur.com/uTXIhEh.png" width="400px" title="source: imgur.com" /></a> - 학습 도중 $R$이 생성한 데이터가 가운데 랜덤하게 반을 선택하여 buffer에 넣는다. - 각 step에서 buffer에서 랜덤하게 선택한 반과 $R$이 현재 생성한 데이터 반을 $D$에 전달한다.   ## Pix2Pix Pix2Pix는 다음과 같이 *image to image translation*을 하는 데 GAN을 접목한 연구입니다.  <a href="https://imgur.com/iH3KG4T"><img src="https://i.imgur.com/iH3KG4T.png" width="600px" title="source: imgur.com" /></a>  아키텍처는 다음과 같습니다. 우선 $G$는 소스 도메인의 데이터를 입력 받아 타겟 도메인의 데이터를 생성합니다. $G$는 소스 도메인의 데이터와 생성된 타겟 도메인의 데이터를 쌍으로 묶어 $D$에 전달합니다. $D$는 $G$가 생성한 가짜 데이터 pair와 실제 데이터 pair를 구분합니다. $G$는 $D$를 속이도록 하는 과정에서 데이터를 더 잘 생성하게 됩니다.  <a href="https://imgur.com/jigPX5b"><img src="https://i.imgur.com/jigPX5b.png" width="450px" title="source: imgur.com" /></a>  $G$는 다음과 같이 오토인코더(autoencoder)에 *Unet*을 결합한 아키텍처를 썼다고 합니다. *encoder*, *decoder* 사이에 발생할 수 있는 정보손실을 *skip-connection*을 이용해 완화한 겁니다. Pix2Pix 역시 SimGAN의 Local Patch Disciriminator를 사용했다고 합니다.  <a href="https://imgur.com/FSGh3or"><img src="https://i.imgur.com/FSGh3or.png" width="300px" title="source: imgur.com" /></a>   ## CycleGAN Pix2Pix의 단점은 학습데이터가 항상 pair로 존재해야 한다는 겁니다. CycleGAN은 이러한 문제를 해결하기 위해 제안됐습니다. 이를 도식적으로 나타낸 그림은 다음과 같습니다. <a href="https://imgur.com/cgynmJJ"><img src="https://i.imgur.com/cgynmJJ.png" width="400px" title="source: imgur.com" /></a>  CycleGAN의 기본 프레임워크는 다음과 같습니다. 두 개의 생성자 $G$, $F$와 두 개의 판별자 $D_X$, $D_Y$를 씁니다. $G$는 $X$ 도메인의 데이터를 $Y$ 도메인으로 변환하는 역할을 합니다. $F$는 $Y$ 도메인의 데이터를 $X$ 도메인으로 변환합니다. $D_X$는 $F$가 생성한 가짜 데이터와 $X$ 도메인의 실제 데이터를 구분합니다. $D_Y$는 $G$가 생성한 가짜 데이터와 $Y$ 도메인의 실제 데이터를 구분합니다. $G$와 $F$는 반대 도메인의 구분자를 속이도록 적대적으로 학습됩니다. 이렇게 학습이 진행되면서 굳이 데이터가 pair 형태로 존재하지 않아도 됩니다.  <a href="https://imgur.com/ZWjYGVU"><img src="https://i.imgur.com/ZWjYGVU.png" width="200px" title="source: imgur.com" /></a>  CycleGAN에는 기존 GAN loss 이외에 *cycle-consitency loss*라는 것이 추가됐습니다. 아래 그림처럼 도메인을 변경했다가 다시 돌아왔을 때 모습이 원래 입력값과 비슷한 형태가 되도록 regularization을 걸어주는 것입니다. 이렇게 되면 도메인을 넘나들 때 더욱 현실감 있는 데이터가 생성될 것입니다.   <a href="https://imgur.com/ZhUHD2i"><img src="https://i.imgur.com/ZhUHD2i.png" width="500px" title="source: imgur.com" /></a>  CycleGAN을 PyTorch로 구현한 코드를 살펴보겠습니다. 우선 두 개의 $G$와 두 개의 $D$를 정의합니다. (일반적인 *generator*, *discriminator* 사용) ```python # Generator arguments : input_dim, num_filter, output_dim, num_resnet G_A = Generator(3, params.ngf, 3, params.num_resnet) G_B = Generator(3, params.ngf, 3, params.num_resnet) # Discriminator arguments : input_dim, num_filter, output_dim D_A = Discriminator(3, params.ndf, 1) D_B = Discriminator(3, params.ndf, 1) ``` $G$의 loss를 구하는 코드는 다음과 같습니다. ```python # A -> B fake_B = G_A(real_A) D_B_fake_decision = D_B(fake_B) G_A_loss = MSE_loss(D_B_fake_decision, Variable(torch.ones(D_B_fake_decision.size()))) # forward cycle loss recon_A = G_B(fake_B) cycle_A_loss = L1_loss(recon_A, real_A) * params.lambdaA # B -> A fake_A = G_B(real_B) D_A_fake_decision = D_A(fake_A) G_B_loss = MSE_loss(D_A_fake_decision, Variable(torch.ones(D_A_fake_decision.size()))) # backward cycle loss recon_B = G_A(fake_A) cycle_B_loss = L1_loss(recon_B, real_B) * params.lambdaB # Back propagation G_loss = G_A_loss + G_B_loss + cycle_A_loss + cycle_B_loss ``` $D$의 loss를 구하는 코드는 다음과 같습니다. ```python # Train discriminator D_A D_A_real_decision = D_A(real_A) D_A_real_loss = MSE_loss(D_A_real_decision, Variable(torch.ones(D_A_real_decision.size()))) fake_A = fake_A_pool.query(fake_A) D_A_fake_decision = D_A(fake_A) D_A_fake_loss = MSE_loss(D_A_fake_decision, Variable(torch.zeros(D_A_fake_decision.size()))) D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5 # Train discriminator D_B D_B_real_decision = D_B(real_B) D_B_real_loss = MSE_loss(D_B_real_decision, Variable(torch.ones(D_B_real_decision.size()))) fake_B = fake_B_pool.query(fake_B) D_B_fake_decision = D_B(fake_B) D_B_fake_loss = MSE_loss(D_B_fake_decision, Variable(torch.zeros(D_B_fake_decision.size()))) D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5 ```   ## StarGAN StarGAN은 CycleGAN의 단점을 보완한 연구입니다. CycleGAN은 도메인 수가 늘어나게 되면 필요한 $G$의 수가 기하급수적으로 증가하고, $D$는 선형적으로 증가합니다. 아래 그림의 (a)의 경우 도메인 수가 4개가 되자, $G$는 12개, $D$는 4개가 필요한 것을 확인할 수 있습니다. 반면 StarGAN은 (b)와 같이 생겼습니다. $D$와 $G$는 각각 하나만 있으면 됩니다.  <a href="https://imgur.com/vuvKH72"><img src="https://i.imgur.com/vuvKH72.png" width="400px" title="source: imgur.com" /></a>  StarGAN의 학습 방식을 저자가 든 예시 기준으로 설명해 보겠습니다. *CelebA* 데이터셋과 *RaFD* 데이터 셋이 있고 각각의 레이블은 아래 그림과 같이 주황색, 녹색 박스라고 칩시다. *Mask Vector*는 모델이 현재 다루는 데이터가 *CelebA*에 속하는지, *RaFD*에 속하는지 나타내는 one-hot-vector입니다.  우선 (b)의 $G$에 입력되는 데이터를 보겠습니다. 이 데이터는 검은색 머리의 젊은 여성인데요, 타겟 도메인을 검은색 머리의 젊은 남자로 설정하였습니다. $G$의 입력데이터는 소스 도메인의 원래 이미지, 레이블 벡터, *Mask Vector* 셋을 합친 형태입니다. 어쨌든 $G$는 이 데이터를 검은색 머리의 젊은 남자로 변환해야 합니다. 이 데이터를 (d)의 $D$에 보내서 $D$가 실제 데이터로 구분하도록, 그리고 검은색 머리의 젊은 남자($[1,0,0,1,1]$)로 분류하도록 속여야 하니까요. $G$는 $D$를 잘 속일 수 있도록 학습됩니다.  <a href="https://imgur.com/O1VrGT1"><img src="https://i.imgur.com/O1VrGT1.png" width="600px" title="source: imgur.com" /></a>  (b)의 $G$가 생성한 데이터는 다시 $G$에 보내집니다. 이번에 $G$에 입력되는 데이터는 방금 전 $G$가 생성한 타겟 도메인의 이미지, 원 데이터의 레이블 벡터(검은색 머리의 젊은 여성, $[0,0,1,0,1]$), *Mask Vector* 셋을 합친 형태입니다. $G$는 이렇게 만든 데이터가 원래 이미지와 유사하도록 학습됩니다. 이는 CycleGAN의 *cycle-consitency loss*를 그대로 차용했습니다. 결과적으로 $G$는 하나의 이미지 데이터로 $D$를 속이는 과정에서, *cycle-consitency loss*를 줄이는 과정에서 두 번 학습되는 셈이죠. StarGAN의 목적함수는 다음과 같습니다. <a href="https://imgur.com/EwPxI06"><img src="https://i.imgur.com/EwPxI06.png" width="600px" title="source: imgur.com" /></a>  ## Anormaly detection with GAN GAN을 이상치 탐지, 즉 *Novelty Detection*에 활용한 연구도 있습니다. GAN은 $G$가 노이즈 $z$를 받아 현실감 있는 데이터를 생성하도록 학습되는데요. $G$가 생성한 데이터를 역추적해 latent space를 분석하면 이 latent space 내에서 특정 영역이 이상치에 해당할 것이라는 전제가 깔려 있습니다. 이를 도식적으로 나타낸 그림은 다음과 같습니다.  <a href="https://imgur.com/zl0xWyh"><img src="https://i.imgur.com/zl0xWyh.png" width="250px" title="source: imgur.com" /></a>   ## TripleGAN TripleGAN은 GAN으로 새롭게 생성한 데이터를 활용해 성능이 좋은 분류기(classifier)를 만들어내는 게 목표입니다. 아키텍처와 목적함수를 도식화한 그림은 다음과 같습니다. <a href="https://imgur.com/D7lm8MW"><img src="https://i.imgur.com/D7lm8MW.png" title="source: imgur.com" /></a> 차근차근 살펴보겠습니다. 우선 생성자 $G$는 노이즈 $z$를 받아서 인공데이터 $x$를 산출하고 $y$는 실제 데이터로부터 샘플링합니다. $G$가 만든 데이터는 판별자 $D$와 분류기 $C$로 보내집니다. $D$는 이 데이터가 진짜인지 가짜인지 구분하며, $C$는 $G$가 만든 $x$를 입력으로 하고 역시 $G$가 만든 $y$를 출력으로 하는 classification task를 수행합니다. 레이블이 있는 실제 데이터($x_l, y_l$)는 분류기 $C$를 학습하는 데 사용됩니다(supervised learning). 이 데이터는 $D$에도 들어가 $D$가 진짜인지 가짜인지 구분하도록 학습됩니다. 마지막으로 레이블이 없는 실제 데이터($x_c$)가 분류기 $C$에 입력되면 $C$는 이 데이터의 레이블을 예측합니다. $C$가 잘 학습되어 있다면 $x_c$ 역시 레이블이 있는 데이터처럼 역할을 하게 되겠지요. 어쨌든 이렇게 레이블이 추가된 $x_c$ 역시 $D$에 입력돼 진짜/가짜 여부를 판별합니다. TripleGAN에서는 $G$가 $D$를 속이는 과정에서 생성한 데이터가 $C$ 학습에 활용돼 $C$의 성능을 높일 수 있습니다. 뿐만 아니라 $C$는 레이블이 없는 데이터 $x_c$의 레이블을 예측할 때 $D$가 가짜라고 구분하지 않도록 그럴듯한 레이블을 달도록 학습이 진행됩니다. 결과적으로 TripleGAN의 학습이 잘 되면 기존 데이터만 가지고 학습한 것보다 성능이 좋은 분류기 $C$가 도출되리라고 기대할 수 있습니다.
funcall␞ 이번 글에서는 **함수호출(function call)**과 이와 관련된 여러 개념에 대해 살펴보도록 하겠습니다. 이 글은 C언어를 바탕으로 설명해주신 고려대 김황남 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 점프와 프로그램 카운터 **폰 노이만 아키텍처(Von-Neumann Architecture)**는 헝가리 출신 미국인 수학자 존 폰 노이만(1903-1957)이 제안한 컴퓨터 구조입니다. 그는 **저장된 프로그램(stored-program)**이라는 개념으로 아키텍처를 설계했는데요. 데이터와 명령어를 따로 구분하지 않고 같은 공간에 저장한다는 것이 핵심입니다. 이 구조의 장점은 컴퓨터에 다른 작업을 시키려고 할 때 굳이 하드웨어를 재배치할 필요 없이 소프트웨어만 바꾸면 되기 때문에 범용성이 크게 향상된다는 것입니다. 이 때문에 현재 거의 모든 컴퓨터 중앙처리장치(CPU)는 이 구조를 따르고 있다고 합니다. 그 개념도는 다음과 같습니다.  <a href="https://imgur.com/7SOoxhV"><img src="https://i.imgur.com/7SOoxhV.png" width="400px" title="source: imgur.com" /></a>  **레지스터(register)**란 CPU에서 데이터와 명령어를 저장해두는 아주 빠른 기억 장소(위 그림에서 memory unit)입니다. 대부분의 CPU는 보조 메모리에서 레지스터로 데이터든 명령어든 옮겨와 이를 처리한 후 필요시 그 내용을 다시 보조 메모리로 저장하는 **로드-스토어(Load-Store) 설계**를 사용하고 있다고 합니다. 레지스터는 다양한 종류가 있는데, 이 중 함수호출과 직접 관련된 것은 **프로그램 카운터(program counter)**입니다. 프로그램 카운터란 다음에 실행될 기계어로 된 명령어의 메모리 주소를 저장해두는 레지스터의 일종으로 '명령어 포인터'라고도 불립니다. 한편 **기계어(machine language)**란 CPU가 직접 실행하는 명령어의 집합입니다. 기계어에는 로드, 스토어 같은 데이터 이동(data transfer) 명령, AND/OR 등 산술/로직(Arithmetic/Logic) 명령, 그리고 콘트롤(control) 명령 등이 있습니다. 콘트롤 명령은 프로그램 실행과 관련이 있는데요, 콘트롤 명령 가운데 함수호출과 직접 관련된 것은 **점프(jump)**라고 합니다. 보통 CPU는 프로그램을 순차적으로 처리합니다. 그런데 특정 조건이 만족돼 점프가 수행되면 프로그램 카운터에 저장돼 있는 주소값이 바뀌게 됩니다. 함수호출과 관련해 이를 다시 살펴보겠습니다.  <a href="https://imgur.com/R6iBX1Y"><img src="https://i.imgur.com/R6iBX1Y.png" width="550px" title="source: imgur.com" /></a>  예컨대 함수 A를 실행하다가 B를 호출하고, B를 실행하다가 C, C 이후 D를 차례로 호출하는 프로그램을 작성했다고 칩시다. 또 C는 함수 D의 실행 결과를 반환받아 나머지 코드를 실행한 뒤 그 결과를 B에, B는 다시 A에, 이로써 A는 최종 아웃풋을 산출하는 구조라고 가정해보겠습니다. 이 경우 CPU는 함수 A를 실행하다가 중간쯤에서 점프를 합니다. 프로그램 카운터가 함수 B가 저장된 주소값으로 바뀌게 됩니다. 아울러 B가 실행되는 중간쯤 다시 점프, 프로그램 카운터의 주소값이 함수 C의 시작 위치로 바뀝니다. 이러한 방식으로 함수호출이 점프, 프로그램 카운터와 긴밀한 관련을 맺게 되는 것입니다.  ## 매개변수와 전달인자 그러면 함수 간 소통은 어떠한 방식으로 이뤄지는 걸까요? 다시 말해 위 그림에서 함수 D의 실행결과는 C, C가 리턴한 값은 B, B의 결과는 A의 연산에 영향을 미치는 갈색 화살표 방향이 우리의 주된 관심입니다. 이 때 중요한 개념이 바로 **매개변수(parameters)**와 **전달인자(arguments)**입니다. 매개변수란 서브함수에 입력값으로 전달되는 데이터를 가리키기 위한 변수(variable)이며, 전달인자는 서브함수를 호출할 때 전달되는 실제 값(value)을 뜻합니다. 보통 매개변수는 함수를 정의할 때 선언합니다. 예를 들어보겠습니다. ```c int incr( int i ) {  int j;  j = i + 1;  return j; } int main( void ) {  int k, m = 4;  k = incr(m);  printf( "k = %d, m = %d\n", k, m);  return 0; } ``` *incr* 함수는 어떤 값을 넣으면 여기에 1을 더한 값을 반환하는 함수입니다. 위 코드에서 매개변수는 $i$, 전달인자는 4가 됩니다. *main* 함수는 *incr*을 호출할 때 4를 전달하며, *incr* 함수는 4를 $i$에 대입시켜 연산을 수행합니다. *incr* 함수의 최종 출력은 $j$인데, 여기엔 실제로 5라는 값이 들어 있게 되겠죠. 이 값이 다시 $main$ 함수의 $k$라는 변수에 저장되는 형식입니다. C언어의 **인자 전달(argument passing)**에는 크게 **값에 의한 호출(call-by-value)**과 **포인터에 의한 호출(call-by-pointer)** 등이 있습니다. 위 예시는 바로 값에 의한 호출 방식으로 인자를 전달한 것인데요. 서브함수를 호출할 때 전달인자의 복사본을 전달하며, 함수의 전달인자는 별도의 변수로 관리됩니다. 인자의 복사본이 서브함수에 전달되기 때문에 인자가 서브함수 내에서 바뀌어도, 원래 함수의 변수는 변하지 않습니다. 위 예시를 기준으로 말씀드리면 $m$이 가리키는 값(4)의 복사본이 *incr* 함수에 전달되기 때문에 *main* 함수의 $m$의 값은 *main* 함수가 종료되더라도 4로 남아있게 됩니다.  ## 포인터 **포인터(pointer)**란 변수의 메모리 주소 정보를 가리킵니다. 예를 볼까요? > int v = 1; 위 코드는 $v$에 해당하는 포인터에 1이라는 값을 할당(assign)하라는 뜻입니다. 그러면 포인터에 의한 호출과 관련해 아래 예시를 보겠습니다. ```c void incr( int* i ) {  *i = *i + 1; } int main( void ) {  int m = 4;  incr(&m);  printf( "m = %d\n", m);  return 0; } ``` *main* 함수에서 'incr(&m)'이란 변수 $m$의 포인터를 *incr* 함수에 인자로 전달한다는 뜻입니다. *incr* 함수에서 'int* i'란 매개변수 $i$의 포인터가 가리키는 값을 불러온다는 뜻입니다. 따라서 *incr* 함수는 $m$의 포인터에 저장돼 있는 4라는 값을 불러와 여기에 1을 더한 뒤 다시 $m$에 저장합니다. 결과적으로 *main* 함수에서 출력되는 $m$의 값은 5가 되는 것입니다.  ## 재귀함수 **재귀함수(recursion)**란 자기 자신을 반복적으로 호출하는 함수입니다. 다음 세 가지 조건을 만족해야 합니다. > (1) 종료조건(base case)이 존재한다 (=안 그러면 무한 루프) > > (2) 반복문이 정의되어 있다 > > (3) 서브루틴을 수행할 수록 base case에 가까워진다 (=안 그러면 무한 루프) 이를 만족하는 대표적인 사례가 **factorial**(1부터 지정한 수까지의 모든 자연수의 곱)입니다. 코드는 다음과 같습니다. ```c int factorial(int n) {  if (n < 2) {   return 1;  } else {   return factorial(n-1) * n;  } } ``` 물론 위 함수를 반복문으로 작성할 수도 있습니다. 다음과 같습니다. ```c int factorial_iter(int n) {  int result = 1;  int i;  for (i = 1; i <= n; ++i) {   result *= i;  }  return result; } ``` 위 둘 가운데 재귀함수 방식의 계산복잡성이 아주 약간 높다고 합니다. 왜냐하면 실행 과정에서 인자를 전달해야하고, 수행 중에 점프를 해야 하는 등 함수호출 관련 추가적인 연산이 필요하기 때문입니다. 하지만 재귀함수로 코드를 작성하면 디버깅이 수월해지는 등의 장점이 있어서 선호되는 방식이라고 합니다. 그런데 재귀함수를 쓰면 되레 안 좋은 경우가 있습니다. **피보나치 수열**(다음 피보나치 수는 바로 앞의 두 피보나치 수의 합이 되는 수열)이 바로 그 예입니다([그림 출처](https://berkeley-cs61as.github.io/textbook/dictionaries-and-memoization.html)). 딱 봐도 계산 중복이 많은데요(fib(3)는 세 번이나 계산해야 하네요). 이 경우에는 재귀함수보다는 저장해 두었다가 풀기(다이나믹 프로그래밍)를 쓰면 효율적이라고 합니다.  <a href="https://imgur.com/mMjKqxr"><img src="https://i.imgur.com/mMjKqxr.png" width="500px" title="source: imgur.com" /></a>
ida␞ 이번 글에서는 '이다'라는 형태소에 대해 살펴보겠습니다. 이번 글은 경희대 이선웅 교수님 강의와 '왜 다시 품사론인가(남기심 외, 커뮤니케이션북스)'에 실린 남길임(2006)을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## '이다' : 조사? 형용사? 접사? '이다'는 한국어에서 명사(구)와 함께 쓰여 서술어로 기능하는 형태소의 일종입니다. 형태적으로는 자립성이 없어 앞말에 의존하여 나타나며, 앞말과의 사이에 다른 요소들의 개입을 허용하지 않습니다. 예컨대 다음과 같습니다. > 나는 김철수**다**, 나는 네 의견에는 반대**다**, 불**이야** 학교문법에서는 '이다'를 **서술격조사**로 분류하고 있습니다. 조사는 주로 명사구 뒤에 나타나서 선행하는 명사구가 다른 말과 맺는 관계를 나타내거나 선행하는 명사구에 일정한 의미를 더하는 문법부류입니다. 형태적으로 변화하지 않는다는 특성을 가집니다. '이다'의 경우 위 예문과 같이 명사구에 결합하여 쓰이고 선행하는 말에 의존적이라는 점에서는 조사의 특성을 일부 갖고 있습니다.  하지만 '이다'는 아래처럼 활용한다는 특징을 가지며 그 양상은 대체로 형용사와 유사해 학교문법처럼 딱 잘라 조사라고 말하기 어렵습니다. '이다'의 범주를 굳이 따지자면 형용사로 분류해야 하는 것 아니냐는 이야기죠. 형용사는 형용사이되 앞말에 의존하여 나타나며 앞말과의 사이에 다른 요소들의 개입을 허용하지 않는다는 점에서 특수한 형용사(**의존형용사**)로 보는 견해입니다. > 이다 : 학생**이다**, 학생**이구나** > > 형용사 : 예쁘**다**, 예쁘**구나** > > 동사 : 먹**는다**, 먹**는구나** 하지만 형용사(어휘형태소)로 분류해야 한다는 견해에 문제가 전혀 없는 것은 아닙니다. 한국어에서 구개음화는 형태소 경계에서 /ㄷ, ㅌ/가 /$i,j$/로 시작하는 문법형태소와 연쇄하는 경우에 일어납니다. (예: 같-이 > [가치]) 다시 말해 어떤 말이 구개음화의 환경이 되는 경우, 그 말은 문법형태소일 가능성이 크다는 말입니다. '이다' 앞에서도 구개음화가 일어난다는 점(예 : 밭-이다 > [바치다])을 고려할 때 '이다'를 문법형태소로 분류해야 한다는 견해가 설득력이 있습니다. 이와 별개로 '이다'의 주된 역할이 문법적 기능이라는 사실도 '이다'를 어휘형태소의 일종인 형용사로 분류하는 데 주저하게 만듭니다. 심지어 모음 뒤의 '이다'는 생략할 수 있는 경우가 많아서 분석이 매우 까다롭습니다. 없어도 되는 거라면 대체 '이다'는 정체가 뭐냐는 것이죠. 다음 예문을 보겠습니다. > 그 문제를 푼 분은 뛰어난 {수학자이다, 수학자다}. > > 그 분은 뛰어난 {수학자이지만, 수학자지만} 천재는 아니다. 이 때문에 '이다'를 접사로 보아야 한다는 견해도 제기됩니다. 생략되거나 구개음화의 적용을 받는다는 점에서 '이다'가 문법형태소의 일종(**통사적 접사**)이 아니냐는 문제제기인 것이죠. 하지만 '이다'는 단어를 만드는 기능을 하는게 아니라 문장(서술어)를 만드는 기능을 한다는 점에서 이 견해도 완벽하지 않습니다. 지금까지의 논의가 '이다'의 성격을 완전히 설명하는 것은 아니고 각자 일부의 진실을 드러내고 있으며 그 영역이 중첩돼 있습니다. 다시 말해 '이다'는 학교문법의 기존 9품사 체계에서 어느 한 쪽에 분류하기 쉽지 않다는 이야기입니다. 이 글에서는 '이다'를 특정 문법 범주로 분류하기보다 '이다'에 나타나는 다양한 문법적 성격을 제가 이해하는 한도 내에서 설명해볼까 합니다.   ## 대상의 정체 밝힘 '이다'는 어휘적으로 명시적인 의미가 드러나지 않아 '이다'가 어휘 의미를 가지느냐에 대해서는 국어학계 논쟁의 대상이었습니다. 이와 관련해 외솔 최현배 선생(1894-1970)은 '이다'의 의미를 문장의 서술을 완전히 하는 지정의 의미를 가진다고 설명하면서 '잡음씨'로 규정한 바 있습니다. 이때 지정이란 대상의 정체를 밝히는 확인(identification)을 가리킵니다.  실제로 '이다'가 가장 많이 쓰이는 부류가 바로 지정입니다. 예문을 보겠습니다. > **속성 지정** : 너는 바보**다** > > **동일대상 지정** : 영희가 그녀**이다**   ## 앞말과 뒷말 연결 계사(繫辭, copula)란 문장의 주어와 보어, 주어와 서술어를 연결시키는 단어를 가리킵니다. 계사의 기능 중 대표적인 것이 지정이며 영어 be동사가 대표적인 계사로 분류됩니다. 국어의 '이다' 역시 몇 가지 쓰임에 있어서는 be동사와 유사한 특성을 가집니다. 아래 예문과 같습니다. > **동일대상** : 나는 김철수**다**, The Morning Star **is** the Evening Star > > **일원** : 나는 학생**이다**, The Moscow **is** a large city > > **속성** : 그는 12살**이고** 사춘기**다**, The hen **is** next to the cockerel   ## 앞말을 서술어로 만들어주기 한국어에서 명사는 의미상으로 서술어적 성격을 가지고 있다고 하더라도 어미가 결합할 수 없어서 문법적으로는 서술어로 기능할 수 없습니다. 예컨대 다음 문장과 같습니다. > 체육은 진이가 최고 위 문장에서 '최고'는 서술어적 성격을 지니지만 문법적으로는 명사이기 때문에 완전한 문장이라고 할 수 없습니다. 이때 해당 명사가 서술어로 기능할 수 있도록 받쳐주는 버팀목 같은 역할을 하는 요소가 필요합니다. 이런 역할을 하는 요소를 기능동사라고 합니다. 다음과 같습니다. > 체육은 진이가 최고**다**. '이다'는 기능동사로 쓰이는 경우가 많습니다. 이때 '이다'는 정말 별뜻없이 서술이라는 용언 기능만을 담당할 뿐입니다. 예문을 보겠습니다. > (1) 나는 그 의견에 반대**다** > > (2) 내 연구실이 엉망**이다** > > (3) 우리는 친구**다** 위 예문의 (1)에서 '나'라는 행위주역(Agent)과 '그 의견'이라는 대상역(Theme)이 실현된 데에는 '반대'라는 서술성명사가 있었기 때문입니다. 다시 말해 '반대'가 '나'와 '그 의견'을 논항으로 요구했기 때문이지 '이다'에 특별한 의미가 있는 것이 아니라는 이야기입니다. 마찬가지로 (2)의 '엉망'은 '내 연구실'을, (3)의 '친구'는 '우리'를 논항으로 요구해 실현된 것을 확인할 수 있습니다. (1)~(3)처럼 서술성명사에 후행하는 '이다'는 별뜻없이 서술이라는 용언 기능만 하고 있습니다. 한편 한국어 기능동사에는 '이다' 외에 '하다'(공부하다, 건강하다 등)도 있습니다. 이제부터는 '이다'를 용례별로 정리해 보겠습니다.   ## 감탄, 놀라움, 사실의 전달 '이다'의 다음과 같이 **도입문(presentation sentence)** 형식으로도 나타납니다. 주로 발화 현장에 있는 대상을 지시하는 체언 뒤에 쓰여서 현장에 있는 사실에 대한 감탄, 놀라움 등을 나타내거나 어떤 사실을 알릴 때 씁니다. > 와, 눈**이다** > > 경찰**이다**! > > 손님, 주문하신 카페라떼**입니다**   ## 구어에서의 다양한 쓰임 구어에서 '이다'는 상황, 맥락에 따라 결합제약 없이 자유롭게 쓰입니다. 예컨대 '나는 커피다'라는 표현은 평소엔 비문입니다. 하지만 음료를 정해야 하는 상황에서 '난 커피다'라고 말하는 것은 자연스럽습니다. 이때 '이다'의 의미는 통사론의 분석 범주를 넘어서 의미론, 화용론적 인 것이 됩니다. 그 예는 다음과 같습니다. > 커피는 셀프**입니다** > > 다음 주는 한강**이지**? > > 침대는 과학**입니다**   ## 관용표현 명사류와 '이다'가 함께 쓰여 본래 명사나 '이다'에서 전혀 발견할 수 없는 새로운 의미를 가지는 경우도 있습니다. 이럴 때는 구 전체를 한 단위로 보는 게 적절할 수 있습니다. > 김치 냄새는 **양반이지** > > 아유, 쟤는 참 **밥맛이야** > > 돈 십만 원이 **어디야**? > > 북한은 협상에 **도사다** > > 이제부터 거짓말하지 **않기다**   ## -ㄴ/ㄹ 명사+이다 '이다'는 다음과 같이 '-ㄴ/ㄹ 명사+이다' 구성으로도 자주 쓰입니다. 이들은 주로 선행하는 절에 대한 화자에 태도, 즉 **양태(modality)**를 나타냅니다. > 나는 다음 주 일본에 **갈 것이다** > > 내일부터 일기를 **쓸 예정이야** > > 이젠 어떻게 **할 생각이니**? > > 왠지 무슨 일이라도 일어날 것 같**은 느낌이다** > > 날 속이겠다**는 작정이었군** 위 용례 가운데 말뭉치에 가장 많이 나타나는 표현은 바로 '-ㄴ/ㄹ 것이다'입니다. 남길임(2006)에 따르면 21세기 세종계획 1000만 어절 균형말뭉치에는 '것이다'가 주로 아래와 같이 축약, 활용한 형태로 실현됩니다. > 거야, 거거든요, 거고, 거구, 거군요, 거네, 거니, 거니까, 거다, 거라구, 거라면, 거면, 거야, 거예요, 거잖아, 거요, 거지, 건가요, 건데, 걸까, 겁니까... '-ㄴ/ㄹ 명사+이다' 구성에서 명사 위치에 실현되는 어휘의 목록은 다음과 같습니다. > 각오, 경향, 계획, 기분, 기색, 눈빛, 눈치, 느낌, 마음, 방침, 상황, 처지, 생각, 설명, 속셈, 시늉, 실정, 심사, 심산, 심정, 안색, 예정, 입장, 의견, 작정, 태세, 표정, 형국, 형편...   ## 부사+이다 '이다'는 다음과 같이 몇몇 부사와 결합하여 그 부사의 뜻을 강조할 때도 쓰입니다. 소수의 부사와만 결합하고 결합에 있어서 특별한 규칙을 찾을 수 없다는 점에서 관용적인 용법의 일종으로 볼 수 있습니다. > 여름엔 이 노래가 **딱이다** > > 내일 참석해 주세요. **꼭이요!** > > **정말이지** 시댁에 너무 가기 싫습니다 '부사+이다' 구성에서 부사 위치에 실현되는 어휘의 목록은 다음과 같습니다 > 아직, 벌써, 오래, 금방, 금세, 보통, 별로, 제발, 따로, 계속, 먼저, 바로, 또, 캡, 짱, 왕, 딱, 꼭, 일쑤, 십상, 그만, 고작, 제법, 물론... 
graph␞ 이번 글에서는 **그래프(Graph)**라는 자료구조의 정의와 관련 용어들에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님과 역시 같은 대학의 김선욱 교수님 강의와 위키피디아를 먼저 밝힙니다. 그럼 시작하겠습니다.   ## graph 그래프란 일련의 `노드(node, vertex, 정점, 꼭지점)` 집합 $V$와 `엣지(edge, 간선, 변)` 집합 $E$로 구성된 자료구조의 일종입니다. 일반적으로 노드엔 데이터, 엣지엔 노드와 노드 사이의 관계 정보가 포함되어 있습니다. 이를 그림으로 나타내면 다음과 같습니다.  <a href="https://imgur.com/SYsNnEB"><img src="https://i.imgur.com/SYsNnEB.png" width="400px" title="source: imgur.com" /></a>    ## sparse/dense graph *sparse graph*란 하단 좌측 그림처럼 노드의 수보다 엣지 수가 적은 그래프를 가리킵니다. 반대로 *dense graph*란 하단 우측 그림처럼 노드 수보다 엣지 수가 큰 그래프입니다.  <a href="https://imgur.com/Hke3iQl"><img src="https://i.imgur.com/Hke3iQl.png" width="400px" title="source: imgur.com" /></a>   ## incident/adjacent 임의의 두 노드가 하나의 엣지로 연결돼 있을 경우, 이 노드들은 서로 `인접(adjacent)`해 있다고 합니다. 같은 경우에 이 엣지는 두 노드에 `부속(incident)`한다고 합니다.   ## degree 한 노드의 `차수(degree)`란 해당 노드에 연결된 엣지의 수(혹은 엣지 가중치의 합)를 가리킵니다.   ## loop/isolated 다음 그림과 같이 한 엣지가 같은 노드에 부속해 있을 때 *loop*이라고 합니다.  <a href="https://imgur.com/g4gms4o"><img src="https://i.imgur.com/g4gms4o.png" width="50px" title="source: imgur.com" /></a>  이와 반대로 임의의 한 노드에 부속해 있는 엣지가 전혀 없을 때 해당 노드를 *isolated vertex*라고 합니다.   ## isomorphic 한 그래프의 두 노드를 연결하는 엣지가 하나이고, 다른 그래프에서 그에 대응하는 노드를 연결하는 엣지가 하나뿐일 때 두 그래프는 `동형(同型, isomorphic)`이라고 합니다. 쉽게 말해 두 그래프는 생김새만 다르게 생길 뿐 본질적으로는 구조가 같다는 이야기입니다. 다음 그림과 같습니다.  <a href="https://imgur.com/ttTiz7J"><img src="https://i.imgur.com/ttTiz7J.png" width="400px" title="source: imgur.com" /></a>   ## subgraph 임의의 그래프 $G=(V,E)$가 주어졌을 때 다음을 만족하는 $G'=(V',E')$는 $G$의 `부분그래프(subgraph)`라고 합니다. - $E'$는 $V'$에만 부속(=$V'$에 속한 모든 엣지가 $G'$에 있어야 함)되어 있으며 $E$의 부분집합이다. - $V'$는 $V$의 부분집합이다. 이 가운데 $V=V'$를 만족하는 부분그래프를 *spanning subgraph*라고 합니다. 쉽게 말해 원 그래프와 노드는 같고 일부 엣지만 포함된 부분그래프를 가리킵니다. 이 부분그래프가 [트리](https://ratsgo.github.io/data%20structure&algorithm/2017/10/21/tree/)을 만족할 경우 *spanning tree*라고 합니다. 하단 좌측과 우측의 그림이 원 그래프와 *spanning subgraph*를 예로 든 것입니다.  <a href="https://imgur.com/ItSKR4t"><img src="https://i.imgur.com/ItSKR4t.png" width="400px" title="source: imgur.com" /></a>  원 그래프를 *spanning subgraph*로 표현하면 노드 간 불필요한 관계 정보 처리를 생략할 수 있게 돼 효율성을 도모할 수 있다고 합니다.   ## complete graph/multigraph 모든 노드들이 엣지로 연결돼 있어, 엣지의 수가 최대인 그래프(하단 좌측)를 `완전그래프(complete graph)`라고 합니다. 노드 수가 4개라면 기호로 $K_4$라고 표시합니다. 반면 노드 사이를 잇는 엣지가 하나 이상일 경우 해당 엣지를 *transitive*하다고 하며, 이 그래프를 *multigraph*라고 합니다(하단 우측).   <a href="https://imgur.com/4Wrz9qX"><img src="https://i.imgur.com/4Wrz9qX.png" width="350px" title="source: imgur.com" /></a> 모든 노드들이 엣지로 연결된 부분그래프를 `클리크(clique)`라고 합니다. 아래 예시의 경우 클리크는 다음 여섯가지입니다.  <a href="https://imgur.com/3mN61lf"><img src="https://i.imgur.com/3mN61lf.png" width="250px" title="source: imgur.com" /></a>  - $a,b$ - $a,c,d$ - $b,g$ - $c,d,e,f$ - $c,f,h$ - $f,g$ 이 가운데 노드의 수가 가장 많은 클리크($c,d,e,f$)를 *maximum clique*라고 합니다.   ## directed graph `방향그래프(directed graph, digraph)`란 엣지가 순서가 있는 쌍으로 표현된 그래프의 일종입니다. 다시 말해 엣지가 방향성을 가집니다. 아래 그림처럼 $V_2$에서 $V_1$으로 향하는 엣지 $e_1$가 있다면, $V_2$를 `predecessor/source`, $V_1$을 `successor/sink`라고 부릅니다. 이 때 $e_1$을 $V_2$의 *outgoing edge*, $V_1$의 *incoming edge*라고 합니다. 방향그래프에서 한 노드의 `차수(degree)`는 *incoming degree*와 *outgoing degree*로 나뉩니다. 다시 말해 어떤 한 노드를 기준으로 들어오는 엣지 수(혹은 가중치의 합), 나가는 엣지 수(혹은 가중치의 합)이 바로 그것입니다. 아래 방향그래프에서 $V_1$의 *incoming degree*는 $e_1$, *outgoing degree*는 $e_2$, $e_3$가 됩니다.  <a href="https://imgur.com/9uLuafn"><img src="https://i.imgur.com/9uLuafn.png" width="200px" title="source: imgur.com" /></a>  $V_1$에서 $V_2$, $V_2$에서 $V_3$으로 각각 *outgoing edge*가 존재한다면, $V_1,V_2,V_3$를 `체인(chain)`이라고 합니다.   ## weighted graph `가중치그래프(weighted graph)`란 엣지에 가중치 내지 우선순위 정보가 추가된 형태의 그래프입니다. 이 때 함수 $g$는 엣지를 가중치로 매핑하는 역할을 합니다.   <a href="https://imgur.com/ZCBypaD"><img src="https://i.imgur.com/ZCBypaD.png" width="500px" title="source: imgur.com" /></a>  물론 방향그래프 또한 가중치를 가질 수 있습니다. 이글 `방향가중치그래프(directed weighted graph)`라고 합니다.   ## path 그래프에서 `경로(path)`란 인접한 노드들로 구성된 시퀀스(1개 이상)를 가리킵니다. 엣지가 겹치지 않는 경로를 *simple*하다고 하고, 노드가 겹치지 않는 경로를 *elementary*하다고 합니다. 경로의 `길이(length)`는 경로 내 존재하는 엣지의 수를 나타냅니다. 다음과 같은 그래프의 노드 시퀀스가 있다고 칩시다.  <a href="https://imgur.com/DdTKBkL"><img src="https://i.imgur.com/DdTKBkL.png" width="500px" title="source: imgur.com" /></a> - $[v_1, v_2, v_3, v_4, v_5, v_3, v_4, v_5]$ - $[v_1, v_2, v_3, v_4, v_5, v_8, v_6, v_4, v_7]$ 위 예시에서 첫번째 노드 시퀀스는 인접한 노드들로 구성돼 있기 때문에 경로라고 할 수 있습니다. 그러나 엣지도, 노드도 겹치기 때문에 *simple*하지도, *elementary*하지도 않습니다. 두번째 노드 시퀀스는 인접한 노드들로 구성돼 있기 때문에 경로라고 할 수 있습니다. 엣지가 겹치지 않기 때문에 *simple*하다고 말할 수 있습니다. 하지만 노드가 겹치기 때문에 *elementary*하지는 않습니다.   ## cycle `사이클(cycle)`이란 한 노드에서 시작해 해당 노드에서 끝나는 경로를 가리킵니다. `사이클(cycle)` 또한 엣지가 겹치지 않는 경우 *simple*하다고 하고, 노드가 겹치지 않을 경우 *elementary*하다고 합니다. 위 그래프를 기준으로 아래의 두 개 노드 시퀀스를 보겠습니다. - $[v_1, v_2, v_3, v_4, v_5, v_8, v_6, v_5, v_9, v_1]$ - $[v_1, v_2, v_3, v_4, v_5, v_9, v_1]$ 첫번째 노드 시퀀스는 인접한 노드들로 구성돼 있고 $v_1$으로 시작해 $v_1$으로 끝났으므로 사이클입니다. 엣지가 겹치지 않기 때문에 *simple*하다고 말할 수 있습니다. 하지만 노드가 겹치기 때문에 *elementary*하지는 않습니다. 두번째 노드 시퀀스는 인접한 노드들로 구성돼 있고 $v_1$으로 시작해 $v_1$으로 끝났으므로 사이클입니다. 엣지도, 노드도 겹치지 않기 때문에 각각 *simple*하고, *elementary*하다고 말할 수 있습니다. 만약 $n$개의 노드가 사이클을 이루고 있을 경우 이를 기호로 $C_n$이라고 표시합니다. 다음 그림과 같이 사이클이 없는 그래프를 *acyclic*하다고 합니다.  <a href="https://imgur.com/3a30Hqo"><img src="https://i.imgur.com/3a30Hqo.png" width="150px" title="source: imgur.com" /></a>   ## connected 임의의 두 노드가 연결되었다(connected)는 것은 두 노드 사이에 경로가 존재한다는 이야기입니다. 이와 관련해 다음과 같이 정의됩니다. - 모든 노드쌍 사이에 경로가 존재하는 무방향그래프는 연결되었다고 말한다. - 임의의 방향그래프에서 방향을 무시하고 보면 연결되어 있을 경우, 해당 방향 그래프는 연결되었다고 말한다. - 방향그래프의 임의의 노드쌍 $a$, $b$에 대해 $a$에서 $b$로 가는 경로, $b$에서 $a$로 가는 경로가 존재한다면, 해당 방향그래프는 `강연결(strongly connected)`되었다고 말한다. 아래 방향그래프에서 방향을 무시하고 보면 이 그래프 내 임의의 노드쌍 사이에 모두 경로가 존재함을 알 수 있습니다. 따라서 아래 방향그래프는 *connected graph*입니다. 하지만 $v_1$에서 $v_3$로 가는 경로는 존재($v_1, v_2, v_3, v_9, v_3$)하나, 반대로 $v_3$에서 $v_1$으로 가는 경로는 존재하지 않는다는 점에서 *strongly conntected graph*는 아닙니다.  <a href="https://imgur.com/12rONen"><img src="https://i.imgur.com/12rONen.png" width="350px" title="source: imgur.com" /></a>   ## connected component 원 그래프 $G$에서 노드와 엣지가 서로 겹치지 않는(*independent*) 부그래프를 $G$의 `요소(component)`라고 합니다. 이들 요소 가운데 요소 내 모든 노드쌍에 대해 경로가 존재하는 부그래프 $S$를 $G$의 `연결요소(connected component)`라고 합니다. 그 정의상 `연결그래프(connected graph)`는 하나의 연결요소만을 가집니다.  원 그래프의 부분그래프들 사이에 겹치는 요소가 없고, 부분그래프의 합집합이 원 그래프를 이룰 때 이들 부분그래프를 `파티션(partition)`이라고 합니다. 아래 그림에서 15개 노드와 모든 엣지를 $G$로 본다면 $G$의 연결요소는 두 개이며, 이 연결요소는 $G$의 파티션입니다.  <a href="https://imgur.com/6uXA9de"><img src="https://i.imgur.com/6uXA9de.png" width="400px" title="source: imgur.com" /></a>  연결요소 가운데 노드 수가 가장 많은 연결요소를 `최대연결요소(maximal connected component)`라고 합니다.   ## Vertex/edge-cut 원그래프에서 어떤 노드를 제거해 부분그래프로 나누는 것을 `vertex-cut`이라고 합니다. 엣지를 제거해 부분그래프로 나누는 과정을 `edge-cut`이라고 합니다. 아래 예시에서 노드 $e$를 제거하면 vetex-cut, 노드 $e$와 노드 $x$를 잇는 엣지를 제거하면 원그래프가 두 개 부분그래프로 분리되면서 각각 vetex-cut, edge-cut이 됩니다.  <a href="https://imgur.com/VlH2Y8V"><img src="https://i.imgur.com/VlH2Y8V.png" width="350px" title="source: imgur.com" /></a>  가중치무방향그래프에서 제거 대상 엣지의 가중치가 최대가 되도록 하는 edge-cut 기법을 `MaxCut`, 최소로 하는 기법을 `MinCut`이라고 합니다.   ## Join 새로운 노드 $X$가 추가돼 기존 그래프 $V$의 모든 노드와 연결될 경우 `조인(Join)`이라고 합니다. 이때 기호로는 $V+X$라고 표기합니다.  <a href="https://imgur.com/HiGDdmo"><img src="https://i.imgur.com/HiGDdmo.png" width="250px" title="source: imgur.com" /></a>   ## edge complement 다음과 같은 관계를 지니는 두 그래프를 `edge complement`라고 합니다. 노드는 서로 같고 엣지 존재 양상이 정반대인 경우에 해당합니다.  <a href="https://imgur.com/0Dl03ux"><img src="https://i.imgur.com/0Dl03ux.png" width="350px" title="source: imgur.com" /></a>   ## releative complement 아래 그림과 같이 $H$는 $G$의 부그래프이고, $H$에 속한 모든 엣지를 제거한 그래프를 `relative complement`라고 합니다. 기호로는 $G-H$라고 씁니다.  <a href="https://imgur.com/0mkyi2a"><img src="https://i.imgur.com/0mkyi2a.png" width="400px" title="source: imgur.com" /></a>   ## graph representation 그래프를 컴퓨터가 처리하게 만드려면, 그래프를 적절한 자료구조로 변환해 주어야 합니다. 크게 두 가지 방식이 있는데요. `인접행렬(adjacency matrix)`과 `인접리스트(adjacency list)`입니다. 각각 행렬과 연결리스트(linked list)로 구현합니다. 가중치가 없는 방향그래프를 인접행렬로 표현하는 방식을 도식화한 그림은 다음과 같습니다.   <a href="https://imgur.com/A1qMCWH"><img src="https://i.imgur.com/A1qMCWH.png" width="550px" title="source: imgur.com" /></a>  가중치가 없는 방향그래프를 인접리스트로 표현하는 방식을 도식화한 그림은 다음과 같습니다.  <a href="https://imgur.com/VRoE2Rv"><img src="https://i.imgur.com/VRoE2Rv.png" width="500px" title="source: imgur.com" /></a>  가중치가 있는 무방향그래프를 인접행렬로 표현하는 방식을 도식화한 그림은 다음과 같습니다. $∞$는 두 노드 사이에 엣지가 있고 가중치가 0인 경우와 대비하기 위해 만든 표지입니다.  <a href="https://imgur.com/7wUpNT6"><img src="https://i.imgur.com/7wUpNT6.png" width="480px" title="source: imgur.com" /></a>  가중치가 있는 무방향그래프를 인접리스트로 표현하는 방식을 도식화한 그림은 다음과 같습니다.  <a href="https://imgur.com/TyIs2Av"><img src="https://i.imgur.com/TyIs2Av.png" width="500px" title="source: imgur.com" /></a>  ### 시간복잡성 우선 전체 노드 수가 $V$개, 엣지 수가 $E$개일 때 시간복잡성을 따져보겠습니다. 분석 대상 연산은 (1) 임의의 두 노드($i, j$)가 주어졌을 때 인접해 있는지 여부(*operation 1*) (2) 임의의 한 노드($i$)가 주어졌을 때 인접해 있는 모든 노드를 찾기(*operation 2*) 등 두 가지입니다. 먼저 인접행렬의 경우입니다. - *operation 1* : 인접행렬에서 $i$행, $i$열을 참조하면 됩니다. 행렬의 한 원소를 액세스하는 데엔 $O(1)$의 시간복잡성이 듭니다. - *operation 2* : 인접행렬에서 $i$행 전체에 대해 조사하면 됩니다. 노드 전체를 따져봐야 하므로 $O($\|$V$\|$)$만큼의 시간복잡성이 듭니다. 인접리스트의 경우입니다. - *operation 1* : 인접리스트(연결리스트)에서 $i$번째 버킷에 속한 요소 가운데 $j$가 있는지 탐색(search)하려면 우선 전체 버킷 가운데 $i$번째 버킷을 찾은 뒤 이 버켓 내에 $j$가 있는지 따져야 합니다. $i$번째 노드의 차수를 $d$라고 할 때 $O(d)$의 시간복잡성이 듭니다. 참고로 전체 노드의 평균 차수는 \|$E$\|/\|$V$\|입니다. - *operation 2* : 인접리스트에서 $i$번째 버킷에 속한 모든 요소를 순회(traverse)하면서 출력합니다. 따라서 *operation 1*과 본질적으로 다르지 않습니다. $O(d)$만큼의 시간복잡성이 듭니다.   ### 공간복잡성 이번엔 두 연산의 공간복잡성을 따져보겠습니다. 먼저 인접행렬의 경우입니다. - *operation 1* : 노드 수 × 노드 수만큼의 행렬이 필요합니다. 따라서 $O($\|$V$\|$^2)$만큼의 공간복잡성이 듭니다. - *operation 2* : 버킷은 전체 노드 수만큼 필요합니다. 각 노드를 잇는 포인터는 전체 엣지의 수만큼(무방향그래프의 경우 전체 엣지의 두 배) 필요합니다. 따라서 $O($\|$V$\|$+$\|$E$\|$)$만큼의 공간복잡성이 듭니다.   ### 자료구조의 선택 '노드와 엣지가 어떻게 구성되어 있는가'가 인접행렬 혹은 인접리스트를 택하는 데 중요한 요인이 됩니다. 예컨대 노드 수보다 엣지 수가 많은 *dense graph*의 경우 인접행렬을 쓰는 것이 좋습니다. 반대로 노드 수보다 엣지 수가 적은 *sparse graph*의 경우 인접리스트를 쓰는 것이 좋습니다. 
svgen␞ 이번 글에서는 지도학습(supervised learning) 기반의 **generative model**을 [나이브 베이즈 모델](https://ratsgo.github.io/machine%20learning/2017/05/18/naive/), [선형판별분석 모델](https://ratsgo.github.io/machine%20learning/2017/03/21/LDA/) 중심으로 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## generative model *generative model*은 데이터 $x$가 생성되는 과정을 두 개의 확률모형, 즉 $p(y)$와 $p(x$\|$y)$로 정의합니다. 지도학습 기반의 *generative model*은 레이블 $y$가 명시적으로 주어진 경우를 가리킵니다. 대표적으로 나이브 베이즈 모델(naive bayes models)과 선형판별분석(linear discriminant analysis)이 있습니다.   ## 나이브 베이즈 모델 나이브 베이즈 모델을 *generative modeling* 관점에서 분석하면 다음과 같습니다.  $$ p\left( y \right) \sim { \phi }_{ y }\\ p\left( { x }_{ j }|y=0 \right) \sim { \phi }_{ j|y=0 }\\ p\left( { x }_{ j }|y=1 \right) \sim { \phi }_{ j|y=0 } $$  여기에서 $x$는 데이터, $y$는 범주를 나타냅니다. 영화리뷰를 대상으로 나이브 베이즈 모델을 구축한다면 $x$는 리뷰, $y$는 긍정(1), 부정(0) 극성이 될 겁니다. $y$는 파라메터 $Φ_y$를 가지는 [베르누이분포](https://ratsgo.github.io/statistics/2017/09/21/prob/)(성공 또는 실패 두 가지 가능한 결과에 대한 확률분포)를 따른다고 가정합니다. $x_j$는 영화 리뷰에서 $j$번째 단어를 가리킵니다. 영화 리뷰가 부정($y=0$)일 때 $j$번째 단어가 등장할 확률 $p(x_j$\|$y=0)$은 파라메터 $Φ_{j,y=0}$을 가지는 베이누이분포를 따른다고 가정합니다. 다시 말해 이 확률은 $j$번째 단어가 한번 이상 나타날 가능성을 가리킵니다.  나이브베이즈 모델의 우도 함수는 다음과 같습니다. $x$와 $y$의 결합확률(joint probability)을 베이즈룰(bayes rule)에 따라 다시 적은 겁니다.  $$ \begin{align*} L({ \phi }_{ y },{ \phi }_{ k|y=0 },{ \phi }_{ k|y=1 })=&\prod _{ i=1 }^{ m }{ p\left( { x }^{ (i) },{ y }^{ (i) } \right) } \\ =&\prod _{ i=1 }^{ m }{ \left( \prod _{ j=1 }^{ { n }_{ i } }{ p\left( { x }_{ j }^{ (i) }|y;{ \phi }_{ k|y=0 },{ \phi }_{ k|y=1 } \right) } \right) p\left( { y }^{ (i) };{ \phi }_{ y } \right) } \end{align*} $$  위 식에 로그를 취하고 각각의 파라메터에 대해 미분을 하여 0이 되는 지점을 찾는 방식으로 계산하면 각각의 파라메터는 다음과 같이 분석적으로 도출할 수 있습니다. 전체 데이터(말뭉치)를 대상으로 아래처럼 각 단어별로 빈도를 세면 파라메터 추정이 종료된 겁니다.  $$ { \phi }_{ y }=\frac { \sum _{ i }^{ }{ I\left\{ { y }^{ (i) }=1 \right\} } }{ m } \\ { \phi }_{ k|y=0 }=\frac { \sum _{ i }^{ }{ I\left\{ { y }^{ (i) }=0,{ x }_{ j }^{ (i) }=1 \right\} } }{ \sum _{ i }^{ }{ I\left\{ { y }^{ (i) }=0 \right\} } } \\ { \phi }_{ k|y=1 }=\frac { \sum _{ i }^{ }{ I\left\{ { y }^{ (i) }=1,{ x }_{ j }^{ (i) }=1 \right\} } }{ \sum _{ i }^{ }{ I\left\{ { y }^{ (i) }=1 \right\} } } $$  이렇게 추정된 파라메터를 가지고 새로운 데이터 $x$에 대한 레이블 추정은 다음과 같이 베이즈룰을 이용합니다. 쉽게 말해 우도 $p(x$\|$y)$와 사전확률 $p(y)$ 곱이 큰 쪽으로 $y$를 추정하는 겁니다.  $$ \begin{align*} arg\max _{ y }{ p(y|x) } =&arg\max _{ y }{ \frac { p(x|y)p\left( y \right) }{ p\left( x \right) } } \\ =&arg\max _{ y }{ p(x|y)p\left( y \right) } \end{align*} $$   ## 선형판별분석 선형판별분석을 *generative modeling* 관점에서 분석하면 다음과 같습니다. 다시 말해 $p(x$\|$y)$가 정규분포를 따르고, 각각의 분포는 분산이 $Σ$로 같다고 가정합니다. 아울러 $y$는 파라메터가 $Φ$인 베르누이분포를 따른다고 가정합니다.  $$ p\left( y \right) \sim { \phi }_{ y }\\ p\left( x|y=0 \right) \sim N\left( { \mu }_{ 0 },\Sigma \right) \\ p\left( x|y=1 \right) \sim N\left( { \mu }_{ 1 },\Sigma \right) $$ 각각의 확률함수는 다음과 같습니다.  $$ p\left( y \right) ={ { \phi } }^{ y }{ { \left( 1-\phi \right) } }^{ y }\\ p\left( x|y=0 \right) =\frac { 1 }{ { \left( 2\pi \right) }^{ n/2 }{ \left| \Sigma \right| }^{ 1/2 } } exp\left( -\frac { 1 }{ 2 } { \left( x-{ \mu }_{ 0 } \right) }^{ T }{ \Sigma }^{ -1 }{ \left( x-{ \mu }_{ 0 } \right) } \right) \\ p\left( x|y=1 \right) =\frac { 1 }{ { \left( 2\pi \right) }^{ n/2 }{ \left| \Sigma \right| }^{ 1/2 } } exp\left( -\frac { 1 }{ 2 } { \left( x-{ \mu }_{ 1 } \right) }^{ T }{ \Sigma }^{ -1 }{ \left( x-{ \mu }_{ 1 } \right) } \right) $$ 선형판별분석 모델의 로그우도 함수는 다음과 같습니다. $x$와 $y$의 결합확률(joint probability)을 베이즈룰(bayes rule)에 따라 다시 적은 겁니다.  $$ \begin{align*} l(\phi ,{ \mu }_{ 0 },{ \mu }_{ 1 },\Sigma )=&\log { \prod _{ i=1 }^{ m }{ p\left( { x }^{ (i) },{ y }^{ (i) };\phi ,{ \mu }_{ 0 },{ \mu }_{ 1 },\Sigma \right) } } \\ =&\log { \prod _{ i=1 }^{ m }{ p\left( { x }^{ (i) }|{ y }^{ (i) };\phi ,{ \mu }_{ 0 },{ \mu }_{ 1 },\Sigma \right) \cdot p\left( { y }^{ (i) };{ \phi } \right) } } \end{align*} $$  선형판별분석 모델의 파라메터는 위 로그 우도함수를 각각의 파라메터에 대해 미분해서 0이 되는 지점을 찾는 방식으로 분석적으로 도출할 수 있습니다. 자세한 도출 과정은 [이곳](https://towardsdatascience.com/gaussian-discriminant-analysis-an-example-of-generative-learning-algorithms-2e336ba7aa5c)을 참고하시면 좋을 것 같습니다.  어쨌든 이렇게 추정된 파라메터를 가지고 새로운 데이터 $x$에 대한 레이블 추정은 다음과 같이 베이즈룰을 이용합니다. 쉽게 말해 우도 $p(x$\|$y)$와 사전확률 $p(y)$ 곱이 큰 쪽으로 $y$를 추정하는 겁니다.  $$ \begin{align*} arg\max _{ y }{ p(y|x) } =&arg\max _{ y }{ \frac { p(x|y)p\left( y \right) }{ p\left( x \right) } } \\ =&arg\max _{ y }{ p(x|y)p\left( y \right) } \end{align*} $$  
detertime␞ 이번 글에서는 한국어 관형사절의 시간 표현에 대해 살펴보도록 하겠습니다. 이 글은 고려대 정연주 선생님 강의를 정리하였음을 먼저 밝힙니다. 참고로 말씀드리면 한국어 관형사절의 시간 표현을 이해하려면 [시제](https://ratsgo.github.io/korean%20linguistics/2017/11/03/tense/)와 [상](https://ratsgo.github.io/korean%20linguistics/2017/07/10/aspect/) 개념을 모두 알고 있어야 한다고 합니다(링크 참고). 그럼 시작하겠습니다.   ## 관형사절? [관형사](https://ratsgo.github.io/korean%20linguistics/2017/06/28/nounad/)란 명사류(체언) 앞에서 그 명사류의 뜻을 분명하게 제한하는 품사입니다. 주어와 서술어가 함께 나타난 구성을 [절](https://ratsgo.github.io/korean%20linguistics/2017/07/13/syntax/)이라고 합니다. [관형사절](https://ratsgo.github.io/korean%20linguistics/2017/09/05/NP/)이란 관형사가 들어갈 자리에서 관형사 역할을 하는 절을 가리킵니다. 다음 예문과 같습니다. - **관형사** : **새** 책 - **관형사절** : **철수가 본** 책 관형사절을 만드는 어미를 `관형사형 전성어미`라고 합니다. 대표적으로 `-ㄴ`과 `-ㄹ`이 있습니다. `-ㄴ`은 현실화된 일을 나타내는 절에 결합하고, `-ㄹ`은 현실화되지 않고 아직 사고의 영역에 있는 일을 나타내는 절에 결합하는 경향이 있습니다. 예문을 보겠습니다. 1. [쥐를 잡**은**] 고양이가 낮잠을 잔다. 2. [쥐를 잡**을**] 고양이가 낮잠을 잔다. (1)의 고양이는 이미 쥐를 잡았고, (2)의 고양이는 아직 잡지 않았다는 점에서 의미상 차이가 있습니다.   ## 한국어 관형사절의 시간 표현 [한국어 주절(모절)의 시제 체계](https://ratsgo.github.io/korean%20linguistics/2017/11/03/tense/)는 다음과 같이 정리할 수 있습니다. 요컨대 한국어 주절의 시제는 `-었-(과거)`, `-는-(현재)`, `-겠-(미래)`의 3분 체계입니다.  <a href="https://imgur.com/1QiZ2cH"><img src="https://i.imgur.com/1QiZ2cH.png" width="500px" title="source: imgur.com" /></a>  한국어 관형사절의 시간 표현은 다음과 같습니다.   <a href="https://imgur.com/fSnvxAW"><img src="https://i.imgur.com/fSnvxAW.png" width="510px" title="source: imgur.com" /></a>  첫번째 표와 두번째 표를 비교해서 보면 주절의 시간 표현과 관형사절의 시간 표현이 이루는 체계가 사뭇 다른 점을 확인할 수 있습니다. 관형사형 전성어미 `-ㄴ`과 `-ㄹ`를 제거하면, 관형사형 시간 표현은 `-더-(과거)`, `-느-(현재)`, `-∅-(미래)`의 3분 체계인데요. 각각이 어떤 문법적 의미를 지니는지 확실하지 않습니다. 동사와 형용사의 아주 다른 체계를 이루고 있는 점도 주목할 점입니다. 이러한 세 가지 의문점을 중심으로 설명해 보겠습니다.   ## 중세 한국어의 시간 표현 국어학자들의 연구에 따르면 중세 한국어의 시간 표현 체계는 주절이든 관형사절이든 상관없이 다음과 같았다고 합니다. 완망, 비완망 개념과 관련해서는 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/07/10/aspect/)을 참고하시면 좋을 것 같습니다.  <a href="https://imgur.com/uStlnCo"><img src="https://i.imgur.com/uStlnCo.png" width="250px" title="source: imgur.com" /></a>  그런데 17세기쯤 과거 표시 형태소 `-었-(='-어 있-')`이 등장하면서 기존의 `-∅-`와 `-더-`와 경쟁 구도를 이루다가, 현대에 와서는 `-었-`이 완승에 가깝게 널리 쓰이고 있습니다. `-∅-`는 이 경쟁에 져서 사라지고, `-더-`는 새로운 의미를 가지게 되면서 겨우 살아남았습니다.  그런데 신기한 것은 `-었-`은 유독 관형사절에 침투하지 못했다는 점입니다. 그래서 현대 한국어의 관형사절에서만큼은 중세 한국어의 시간 표현 체계가 화석처럼 남았습니다. 다음 예문을 보겠습니다. > 내가 먹**던** 밥 위 관형사절을 일반적인 문장으로 바꾸면 아래와 같이 비문이 됩니다. `-더-`라는 형태소가 과거 표시 기능을 하는 게 아니라 다른 새로운 의미를 가지게 됐다는 것이죠. > *내가 밥을 먹**더**라. 관형사절은 한국어 시간 표현 체계 전체의 변화에서 제외된 원인과 관련해 다양한 의견이 제시되고 있지만 다음과 같은 설명도 가능할 것 같습니다. - 새로운 문법소(예컨대 `-었-`)는 주로 정보 전달의 [초점](https://ratsgo.github.io/korean%20linguistics/2017/07/11/senttopic/)에서 발달한다. - 관형사절은 정보 전달의 초점이 아니라 이미 전제된 내용이 언급되는 부분이다. - 따라서 관형사절에서는 기존의 오래된 문법소가 계속해서 쓰이는 경향이 있다.    ## 동사 관형사절의 시간표현 `-더-, -느-, -∅-`와 `-ㄴ, -ㄹ`의 조합으로 관형사절 시간표현 관련 어미들의 의미를 곱씹어볼 수 있습니다. 우선 현재에 대응하는 `-는-`부터 살펴보겠습니다.  <a href="https://imgur.com/dtO9Y8M"><img src="https://i.imgur.com/dtO9Y8M.png" width="500px" title="source: imgur.com" /></a>  `-는`은 '현재'와 '현실'의 조합으로 생각해볼 수 있겠습니다. 즉 현재 일어나고 있는 일을 나타냅니다. 다음 예문과 같습니다. > 내가 먹**는** 밥 이번엔 과거에 대응하는 `-은, -던, -었던`을 살펴보겠습니다.  <a href="https://imgur.com/JxE5RPe"><img src="https://i.imgur.com/JxE5RPe.png" width="500px" title="source: imgur.com" /></a>  `-은`은 '과거 완망'과 '현실'의 조합으로 생각해볼 수 있습니다. 과거의 일인데 사태의 시작과 끝이 시야에 들어와 있음을 나타냅니다. 쉽게 말해 '끝난 과거'를 가리킵니다. 다음 예문과 같습니다. > 내가 먹**은** 밥 (밥을 다 먹었음) > > 꽃이 **핀** 들판 (꽃이 핀 상태가 지속됨) `-던`은 '과거 비완망'과 '현실'의 조합으로 생각해볼 수 있습니다. 과거의 일인데 화자가 사태의 내부를 들여다 보고 있음을 나타냅니다. 쉽게 말해 '끝나지 않은(혹은 끝났는지 모르는) 과거의 일'을 가리킵니다. 다음 예문과 같습니다. > 내가 먹**던** 밥 (밥을 먹었긴 했으나 다 먹었는지는 나타나지 않음) `-었던`은 과거의 일이지만 현재와의 접점이 없는 걸 나타냅니다. 쉽게 말해 '단절된 과거'를 가리킵니다. 이는 주절의 시제 표현에서 `-었었-`과 비슷합니다. > 꽃이 피**었던** 들판 (과거에 꽃이 피었으나 지금은 꽃이 피지 않음) 마지막으로 미래에 대응하는 `-을`을 살펴보겠습니다.  <a href="https://imgur.com/DtRtsDj"><img src="https://i.imgur.com/DtRtsDj.png" width="500px" title="source: imgur.com" /></a>  `-을`은 아직 현실화되지 않은 일을 나타냅니다. 다음 예문과 같습니다. > 내가 먹**을** 밥 (아직 밥을 먹지 않았으나 앞으로 먹을 예정)   ## 형용사 관형사절의 시간 표현 형용사 관형사절은 중세 국어의 시간 표현 체계를 그대로 따르고 있습니다. 차례대로 살펴보겠습니다. 우선 `-은`은 형용사 관형사절에서 현재 성립하는 상태를 표현할 때 씁니다. 다음 표, 예문과 같습니다.  <a href="https://imgur.com/lf8Q7JL"><img src="https://i.imgur.com/lf8Q7JL.png" width="500px" title="source: imgur.com" /></a>  > 지지율이 높**은** 정치인 `-은`은 과거 완망의 `-∅-`과 현실의 `-ㄴ`의 조합으로도 생각해 볼 수 있습니다. 그런데 '과거 완망'과 '현실'이 합쳐진 `-은`이 **현재**를 나타낸다는 게, 지금까지의 설명에 비추어봤을 때 다소 생소하긴 합니다. 이와 관련해서는 이런 견해가 있습니다. > 형용사에는 시간과 끝이라는 개념이 없고 시간을 초월해서 펼쳐진 개념이다. 따라서 사태의 시작과 끝을 전제로 한 완망/비완망 개념과 애초에 양립이 불가능하다. 형용사의 과거를 나타낼 때 `-더-`를 늘 쓰다보니, `-더-`를 안쓰면 현재로 해석되게 되었다. 그래서 `-∅-`의 의미가 동사에서는 과거 완망, 형용사에서는 현재로 그 의미가 달라지게 된 것이다.  혛용사 관형사절에서 과거의 상태를 표현할 때는 `-던` 또는 `-었던`을 씁니다. 둘 모두 과거 비완망의 `-더-`와 현실의 `-ㄴ`의 조합입니다.   <a href="https://imgur.com/kGOM9cZ"><img src="https://i.imgur.com/kGOM9cZ.png" width="500px" title="source: imgur.com" /></a>  다만 형용사 관형사절의 과거를 나타내는 `-더-`는 완망, 비완망 개념은 없고 순전히 과거의 의미만 나타냅니다. 아울러 형용사 관형사절의 `-었던`은 `-던`과 큰 의미 차이가 없습니다. 다음 예문과 같습니다. > 지지율이 높**던** 정치인 > > 지지율이 높**았던** 정치인 마지막으로 형용사 관형사절의 미래의 상태, 즉 현실화되지 않은 상태를 나타낼 때는 `-을`을 씁니다. 다음 표, 예문과 같습니다.  <a href="https://imgur.com/FSC5Lrq"><img src="https://i.imgur.com/FSC5Lrq.png" width="500px" title="source: imgur.com" /></a>  > 지지율이 높**을** 정치인      
aspect␞ 이번 글에서는 한국어 주절의 [문법상(grammatical aspect)](https://ratsgo.github.io/korean%20linguistics/2017/07/10/aspect/)을 가장 잘 드러내면서 널리 쓰이고 있는 보조용언 구성인 `-어 있-`과 `-고 있-`에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## -어 있- `-어 있-`은 크게 `결과상(resultative)`과 `정태상(stative)`을 나타냅니다. 차례대로 살펴 보겠습니다.  ### 결과상 결과상이란 과거 사태의 결과가 지속되는 걸 가리킵니다. 동사가 나타내는 사태가 종결된 뒤 그 결과 상태가 주어에게 성립됨을 나타냅니다. 예문을 보겠습니다. > 꽃이 피**어 있**다. 위 예문의 동사 `피다`가 나타내는 사태(開花)가 끝난 뒤, 그 결과 상태가 주어 `꽃`에게 성립되고 있음을 알 수 있습니다. 다시 말해 꽃이 과거 어느 시점에 피었는데, 핀 상태가 현재도 계속되고 있다는 의미로 `-어 있-`이 쓰였다는 얘기입니다. 하지만 `-어 있-`이 아무 동사에나 결합하는 것은 아니고 결합 제약이 있습니다. `-어 있-`은 '놓이다', '깔리다', '숨다', '앉다', '눕다'와 같이 **시간적 끝점을 갖는 [자동사]((https://ratsgo.github.io/korean%20linguistics/2017/05/09/verb/))**(목적어를 취하지 않는 동사)와 결합합니다. 예문을 보겠습니다. > (1) 진이가 *뛰**어 있**다. > > (2) 진이가 예쁜 옷을 *입**어 있**다. (1)의 `뛰다`는 에너지만 공급되면 계속 뛸 수 있다는 점에서 끝점이 없는 동사입니다. (2)의 `입다`는 끝이 있는 동사이지만 목적어를 갖는 타동사입니다. (1), (2) 모두 비문입니다. 다시 말해 서술어가 끝점이 없거나, 타동사라면 `-어 있-`이 결합할 수 없습니다. 물론 `-어 있-`과 결합할 수 있는 타동사가 일부 있기는 합니다. 이를 이해하기 위해선 우선 자동사와 타동사 개념을 살짝 살펴봐야 할 것 같습니다. 예문을 보겠습니다. > 아이가 잔다. 자동사 `자다`가 가리키는 행위로 영향을 받는 대상은 주어 `아이`입니다. (1)과 (2) 예문에서도 서술어 동사가 가리키는 행위로 영향을 받는 대상은 주어 `진이`입니다.  반면 타동사는 해당 동사가 가리키는 행위로 영향을 받는 대상이 목적어입니다. 다음 예문과 같습니다. > 철수가 친구를 때렸다. 자, 이제 원래 목적으로 돌아와서 `-어 있-`과 결합할 수 있는 타동사를 살펴보겠습니다. 다음 예문과 같습니다. > 진이가 등대를 향**해 있**다. 위 예문의 타동사 `향하다`가 가리키는 행위로 영향을 받는 대상은 무엇일까요? 대충 봐서는 목적어인 `등대`일 것 같지만 사실 주어인 `진이`가 영향을 받는 의미로 전달됩니다.  요컨대 `-어 있-`과 결합할 수 있는 타동사는 타동사이면서도 목적어가 변화를 겪는 것이 아니라 주어가 변화를 겪는 의미로 사용되는 단어들입니다. 이러한 예로는 '향하다', '떠나다', '넘어서다', '건너오다', '초과하다' 등이 있습니다.  ### 정태상 과거 사건의 발생 여부에 대해서는 아무런 함축도 갖지 않고 단지 현재 `상태`만 나타내는 상 범주를 정태상이라고 합니다. 다음 예문과 같습니다. > 우리 마을은 산으로 둘러싸**여 있**다. > > 이 길은 바닷가까지 뻗**어 있**다. 정태상은 의미적으로 결과상에서 파생된 용법이라고 합니다.  ## -고 있- `-고 있-`은 크게 `결과상(resultative)`, `정태상(stative)`, `연속상(continuous)`, `반복상(iterative)`을 나타냅니다. 차례대로 살펴 보겠습니다.  ### 결과상 `-고 있-`이 결과상의 의미로 쓰인 예문은 다음과 같습니다. > 철수는 흰 셔츠를 입**고 있**다. 위 예문의 `-고 있-`은 철수가 흰 셔츠를 착용하는 동작을 완결한 뒤 그 결과 상태(옷을 입은 상태)가 지속되고 있음을 나타내고 있습니다. 결과 상태가 타동사의 주어에게 성립되고 있습니다. 다시 말해 `입다`라는 행위로 당장 영향을 받는 대상은 `흰 셔츠`이지만, 결과적으로 옷을 입은 행위(服着)의 결과로 주어인 `철수`가 옷을 입은 상태로 변화했다는 이야기입니다. 이처럼 타동사가 가리키는 행위로 영향을 받는 대상이 1차적으로는 목적어이지만, 결과적으로 주어에 영향을 미친다는 의미를 갖는 타동사를 **재귀성 타동사**라고 합니다. `-어 있-`은 재귀성 타동사와 결합할 때 결과상(결과 상태의 지속)의 의미를 갖습니다. 이러한 동사의 예로는 '(신발을)신다', '(명찰을)달다', '(이불을)덮다', '(고개를)숙이다' 등이 있습니다.  그러나 다음과 같은 경우도 있어 분석에 주의를 기울여야 합니다. > (가) 철수가 이불을 덮**고 있**다. > > (나) 철수가 지붕에 짚을 덮**고 있**다. (가)의 `덮다`는 결과적으로 주어인 `철수`를 변화시키기 때문에 재귀성을 가졌지만, (나)는 그렇지 않습니다. 재귀성 타동사가 쓰인 (가)의 `-고 있-`은 결과상, 그렇지 않은 (나)의 `-고 있-`은 연속상(진행상)의 의미로 쓰인 것을 확인할 수 있습니다. 이번엔 다른 사례를 보겠습니다.  > 관중들이 경기장을 가득 메우**고 있**다. 위 예문의 결과 상태가 타동사의 목적어에 성립된 경우여서 재귀성이 없습니다. 다만 경기장을 가득 `메우는 데` 주어 `관중들`의 적극적인 개입이 있어서 ` -어 있-`이 결과상의 의미를 갖습니다.   ### 정태상 `-고 있-`의 정태상 관련 예문은 다음과 같습니다. > 이 도시를 여러 산들이 병풍처럼 둘러싸**고 있**다.   ### 연속상(진행상) 연속상이란 사태가 지속되고 있는 걸 가리킵니다. 예문을 보겠습니다. > 철수는 흰 셔츠를 입**고 있**다. 위 예문은 결과상으로도, 연속상으로도 해석할 수 있는 중의적인 구문입니다. 연속상으로 해석할 경우 철수가 현재 흰 셔츠를 착용하는 동작을 수행하고 있음을 나타냅니다. 한국어의 연속상은 영어의 `be+현재분사`와 유사하지만 다른 점도 있습니다. 가장 다른 점은 `-고 있-`이 정적인 사태를 나타내는 동사와도 매우 자유롭게 결합할 수 있다는 점입니다. 다음 예문과 같습니다. - 알고 있다, 모르고 있다, 믿고 있다, 생각하고 있다, 사랑하고 있다... 이와 별개로 `-ㄴ 중-`은 정적인 사태를 나타내는 동사와 잘 결합하지 않습니다. - *아는 중이다, *모르는 중이다, *믿는 중이다, *생각 중이다, *사랑 중이다... 하지만 다음과 같은 예문이 자주 쓰이는데, 아래의 `생각하다`는 동적 사태(적극적으로 고민하고 있음)에 가까운 사태를 동사이기 때문인 것 같습니다. > 나는 생각하는 중이야.  ### 반복상 반복상이란 그 사태가 반복해서 발생함을 나타내는 상 범주입니다. 다음 예문과 같습니다. > 최근 이와 비슷한 사건이 자주 발생하**고 있**다.   ## -어 있-, -고 있- 모두 결합할 수 있는 동사 `-어 있-`과 `-고 있-`은 각각 특정 종류의 동사와만 결합하는 제약이 있으나 둘 모두 쓰이는 동사도 있습니다. `성장하다`가 대표적인 사례입니다.  - **성장해 있다**(결과상) : 성장이라는 상태 변화가 어떤 완결점에 이미 도달해서 그 결과 상태가 지속됨을 나타냅니다. - **성장하고 있다**(연속상) : 성장이라는 상태 변화가 아직 완결되지 않고 진행 중임을 나타냅니다. 동사가 다의어여서 둘 모두 결합하는 경우도 있습니다. `살다`가 대표적인 사례입니다. - **살아 있다**(결과상) : `살다`가 *alive* 정도의 의미를 가질 때에는 시작점(태어난 순간), 끝점(죽는 순간)을 가지는 유계동사(telic verb)로서 생명력이 있는 상태가 지속됨을 나타냅니다. - **살고 있다**(연속상) : `살다`가 거주하다의 의미일 때는 무계동사(atelic verb)로서 해당 지역에 거주하는 중이다 정도의 의미를 나타냅니다.
augmentedDS␞ 이번 글에서는 **Augmented Data Structure**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아를 참고해 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept *Augmented Data Stucture*란 기존 자료구조에 추가적인 정보를 저장해, 이를 바탕으로 계산효율성을 높이려는 자료구조의 일종입니다. [이진탐색트리(binary search tree)](https://ratsgo.github.io/data%20structure&algorithm/2017/10/22/bst/), [RB 트리](https://ratsgo.github.io/data%20structure&algorithm/2017/10/28/rbtree/) 등 노드에 서브트리 노드의 개수 정보를 추가해 중위탐색(inorder traverse) 성능을 높이는 사례가 바로 여기에 해당합니다. 이진탐색트리, RB 트리에서 중위탐색에 소요되는 계산복잡성은 $O(n)$인데, *Augmented Data Structure*를 써서 $O(\log{n})$의 계산복잡성을 달성할 수 있습니다.   ## OS-Select *OS-Select*는 주어진 이진탐색트리에서 $i$번째 작은 값을 찾는 문제입니다(1번째 작은 값=최소값). 아래 그림과 같이 기존 이진탐색트리 노드에 자기 자신을 포함한 자식노드의 개수를 별도로 저장해 둡니다. 예컨대 아래 이진탐색트리에서 잎새노드는 자식노드가 없으므로 그 값이 1이 됩니다. $F$에 해당하는 노드는 자식노드 2개에 자기 자신까지 해서 그 값이 3이 됩니다. 마찬가지로 $C$ 노드는 왼쪽 서브트리의 노드 1개, 오른쪽 서브트리의 노드 3개, 자기 자신, 이렇게 총 5가 됩니다.  <a href="https://imgur.com/HMoRAtM"><img src="https://i.imgur.com/HMoRAtM.png" width="500px" title="source: imgur.com" /></a>  예컨대 위 트리에서 6번째 작은 값을 찾는다고 칩시다. 이진탐색트리는 각 노드에 해당하는 값이 왼쪽 자식노드보다는 크고 오른쪽 자식노드보다는 작다는 성질을 가지고 있습니다. 주어진 이진탐색트리 루트노드의 왼쪽 서브트리 노드 수가 5개이므로, 위 트리에서 6번째 작은 값은 루트노드 $M$이 됩니다(`case 1`). 이번엔 4번째 작은 값을 찾아 봅시다. 루트노드의 왼쪽 서브트리 노드 수가 5개이므로, 우리가 찾고자 하는 값은 루트노드의 왼쪽 서브트리에 속해 있다는 걸 알 수 있습니다. 다시 말해 루트노드의 왼쪽 자식노드를 루트로 하는 새로운 서브트리 가운데 4번째 작은 값이 우리가 찾는 값이 됩니다(`case 2`이고 *OS-Select($C$, 4)* 재귀 호출).  이번엔 8번째 작은 값을 찾아 봅시다. 루트노드의 왼쪽 서브트리와 루트노드를 포함한 노드 수가 6개이므로, 우리가 찾고자 하는 값은 루트노드의 오른쪽 자식노드를 루트로 하는 새로운 서브트리 가운데 2번째(8-6=2) 작은 값이 됩니다(`case 3`이고 *OS-Select($P$, 8-6)* 재귀 호출). 이를 의사코드로 표현하면 다음과 같습니다. ```python # x: 주어진 이진탐색트리의 루트노드 # i: i번째 작은값의 i OS-Select(x, i): 	r = x.left.size + 1 	# case 1   if i == r: 		return x   # case 2 	elif i < r: 		return OS-Select(x.left, i) 	# case 3   else: 		return OS-Select(x.right, i-r) # 최초 시작은 루트노드에서 # 이후 재귀적으로 함수 호출 OS-Select(T.root, i) ``` *OS-Select*는 최악의 경우에도 루트노드에서 잎새노드까지의 경로만을 탐색하게 됩니다. *OS-Select*의 계산복잡성은 트리 노드수가 전체 $n$개일 때 트리의 높이($\log{n}$)에 비례한다는 얘기입니다. 따라서 전체적으로 계산복잡성은 $O(\log{n})$이 됩니다.   ## OS-Rank *OS-Rank*는 주어진 이진탐색트리에서 $x$가 몇 번째로 큰 값인지 알아내는 문제입니다. *OS-Select*와 마찬가지로 기존 이진탐색트리에 자기 자신을 포함한 자식노드의 개수를 별도로 저장해 둡니다. 아래 그림은 *OS-Select* 때 예시로 든 것과 동일합니다.  <a href="https://imgur.com/HMoRAtM"><img src="https://i.imgur.com/HMoRAtM.png" width="500px" title="source: imgur.com" /></a>  이진탐색트리에서 각 노드의 rank는 왼쪽 서브트리의 노드 수가 중요합니다. 예컨대 몇 번째 큰 값인지 알고자 하는 노드가 $F$라고 칩시다. $F$의 rank는 다음과 같이 분리해서 생각해볼 수 있습니다. - F와 F의 왼쪽 서브트리 : 1+D의 값(1) - C와 C의 왼쪽 서브트리 : 1+A의 값(1) - F의 rank = 2+2 = 4 이를 의사코드로 표현하면 다음과 같습니다. 아래 코드에서 *y.p.left.size*는 *y* 노드 부모의 왼쪽 서브트리 노드의 수를 가리킵니다. ```python # T : 이진탐색트리 # x : 몇 번째 큰 값인지 알고자 하는 노드 OS-Rank(T, x): 	r = x.left.size + 1 	y = x 	while y != T.root:    	# 위 그림 기준으로 C, F가     # 각각 부모노드, 오른쪽 자식노드인지 확인 		if y == y.p.right:      	 # 기존 rank에 더해       # 왼쪽 서브트리 + 자기 자신 반영 			r = r + y.p.left.size + 1 		y = y.p 	return r ``` *OS-Rank*는 최악의 경우 잎새노드에서 시작해 루트노드까지 올라가며 랭크를 계산합니다. *OS-Rank* 역시 계산복잡성은 $O(\log{n})$이 됩니다.   ## subtree 크기 업데이트 지금까지 설명해드린 *OS-Select*, *OS-Rank*를 무리없이 구현하려면 각 노드별로 서브트리 노드 수를 반영해 주어야 합니다. 트리를 *build*할 때는 물론 새 노드를 *insert*, 기존 노드를 *delete*할 때마다 서브트리의 노드 수가 바뀌게 됩니다.  우선 *insert*를 기준으로 생각해보면 이진탐색트리의 노드 삽입은 잎새에서 이루어지고, 이 잎새에서 루트에 이르는 경로에만 subtree 숫자들이 바뀌기 때문에 최대 트리의 높이에 해당하는 노드들에 대해서만 노드 수 업데이트를 해주면 됩니다($O(\log{n})$). 물론 RB 트리와 같이 삽입 과정에서 *rotation*이 이뤄지는 경우도 상정해볼 수는 있겠지만 아래처럼 상수시간 내 연산이 가능하기 때문에 전체적인 계산복잡성을 지배하지 않습니다.   <a href="https://imgur.com/TI2X87q"><img src="https://i.imgur.com/TI2X87q.png" width="600px" title="source: imgur.com" /></a>  한편 *delete*로 인한 subtree 크기 업데이트에 대한 계산복잡성도 $O(\log{n})$이라고 합니다.   ## interval tree *interval tree*란 각 노드의 값이 구간(interval)인 이진탐색트리인 자료구조를 가리킵니다. 여기에 (1) 해당 노드 구간의 상한 (2) 해당 노드 왼쪽 서브트리의 값 가운데 최대값 (3) 해당 노드 오른쪽 서브트리의 값 가운데 최대값 등 세 가지 가운데 최대값을 각 노드에 구간 정보와 별도로 저장해 놓습니다. 예컨대 다음 그림과 같습니다.  <a href="https://imgur.com/yeZtSXM"><img src="https://i.imgur.com/yeZtSXM.png" width="450px" title="source: imgur.com" /></a>  우리가 알고 싶은 값은 특정 구간이 주어졌을 때 위 *interval tree*에서 겹치는 구간이 있는지, 있다면 어느 구간이 겹치는지 정보입니다. 예컨대 위와 같은 트리에서 [14, 16]이 겹치는지 알아보고 싶다고 칩시다. 그 과정은 다음과 같습니다. - 알고 싶은 구간의 하한 14와 루트노드의 왼쪽 자식노드(18)를 비교합니다. **작으므로** 루트노드의 **왼쪽 자식노드로** 갑니다. - 알고 싶은 구간의 하한 14와 루트노드의 왼쪽 자식노드의 왼쪽 자식노드(8)를 비교합니다. **크므로** 루트노드의 왼쪽 자식노드의 **오른쪽 자식노드로** 갑니다. - 알고 싶은 구간의 하한 14와 루트노드의 왼쪽 자식노드의 오른쪽 자식노드의 왼쪽 자식노드(10)를 비교합니다. **크므로** 루트노드의 왼쪽 자식노드의 오른쪽 자식노드의 **오른쪽 자식노드로** 가야 합니다. 그런데 [15, 18] 이 노드는 자식노드를 가지지 않고, [14, 16]과 그 구간이 겹치므로 [15, 18]을 결과값으로 반환합니다. *interval-search*의 의사코드는 다음과 같습니다. ```python Interval-Search(T, i): 	x = T.root 	while x != T.nil and i does not overlap x.int: 		if x.left != T.nil and x.left.max >= i.low: 			x = x.left 		else: 			x = x.right 	return x ``` 원하는 결과를 찾기 위해 최악의 경우 루트노드에서 잎새노드에 이르기까지 탐색하게 됩니다. *interval-search*의 계산복잡성 또한 $O(\log{n})$이 됩니다.
Ldependence␞ 이번 포스팅에서는 **선형독립(linear independence)**과 **선형변환(linear transformation)**에 대해 살펴보도록 하겠습니다. 이번 글 역시 [고려대 박성빈 교수님](http://info.korea.ac.kr/page_professor.php) 강의를 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 선형독립과 선형종속 아래 조건을 만족하는 유한한 $n$개의 벡터는 **선형종속**(線型從屬, linear dependence)이라고 정의됩니다. $$S=\left\{ { v }_{ 1 },{ v }_{ 2 },...,{ v }_{ n } \right\} 에\quad 대해\\{ c }_{ 1 }{ v }_{ 1 }+{ c }_{ 2 }{ v }_{ 2 }+...+{ c }_{ n }=0을\quad만족하는\\0이\quad 아닌\quad { c }_{ 1 },{ c }_{ 2 },...,{ c }_{ n }이\quad존재한다$$ 반대로 c가 모두 0일 때만 위 조건을 만족하는 경우에는 **선형독립**(線型獨立, linear independence)이라고 합니다. 그 정의에 의해 **동차선형방정식(homogeneous linear equation)** $Ax=0$가 자명해($x=0$)를 유일한 해로 가질 때 **계수행렬(coefficient matrix)** $A$의 **열벡터(column vector)**들은 서로 선형독립입니다.  무슨 말인지 알쏭달쏭하시죠? 예를 들어보겠습니다. 다음과 같은 두 개의 1차 연립방정식이 있습니다. $$3{ x }_{ 1 }+6{ x }_{ 2 }=0\\ 2{ x }_{ 1 }+2{ x }_{ 2 }=0$$ 위 연립방정식의 계수행렬 $A$는 아래와 같습니다. $A$의 열벡터와 $x$의 선형결합으로 위 연립방정식을 다시 표현한 것 또한 아래와 같습니다. $$A=\begin{bmatrix} 3 & 6 \\ 2 & 2 \end{bmatrix},\quad x=\begin{bmatrix} { x }_{ 1 } \\ { x }_{ 2 } \end{bmatrix}\\ { x }_{ 1 }\begin{bmatrix} 3 \\ 2 \end{bmatrix}+{ x }_{ 2 }\begin{bmatrix} 6 \\ 2 \end{bmatrix}=\begin{bmatrix} 0 \\ 0 \end{bmatrix}$$ 위 식을 살펴보면 $A$의 열벡터들을 선형결합해 영벡터를 만들기 위해선 $x_1$과 $x_2$가 동시에 0인 경우 말고는 해가 존재하지 않습니다. 이 경우 벡터 (3,2)와 (6,2)는 선형독립이라고 말할 수 있습니다. 그럼 아래의 경우는 어떨까요? $${ x }_{ 1 }\begin{bmatrix} 3 \\ 1 \end{bmatrix}+{ x }_{ 2 }\begin{bmatrix} 6 \\ 2 \end{bmatrix}=\begin{bmatrix} 0 \\ 0 \end{bmatrix}$$ 위와 같은 경우엔 식을 만족하는 $x$가 무수히 많습니다. (3,1)과 (6,2)는 동일한 직선 위에 있기 때문입니다. 이를 그림으로 보면 아래와 같습니다.  <a href="http://imgur.com/hVmV0na"><img src="http://i.imgur.com/hVmV0na.png" width="350px" title="source: imgur.com" /></a> 그럼 3차원에선 어떨까요? 아래와 같이 벡터 $u$, $v$가 주어졌을 때 $u$, $v$가 만드는 공간과 $w$가 선형독립일 필요충분조건은 무엇일까요? 답은 이렇습니다. $x_1$과 $x_2$가 어떤 값을 가지든 상관없지만 $x_3$는 반드시 0이어야 합니다. 이해를 돕기 위해 그림으로도 표현해보겠습니다. $$u=\begin{bmatrix} 3 \\ 1 \\ 0 \end{bmatrix},\quad v=\begin{bmatrix} 1 \\ 6 \\ 0 \end{bmatrix},\quad w=\begin{bmatrix} { x }_{ 1 } \\ { x }_{ 2 } \\ { x }_{ 3 } \end{bmatrix}$$ ![linear dependence](http://i.imgur.com/Ss2LDRI.png) 벡터 $u$와 $v$는 평면을 **생성(span)**합니다. 하지만 $u$와 $v$의 어떤 조합으로도 $x_3$이 0이 아닌 벡터(상단 좌측 그림의 파란색 벡터)를 만들어 낼 수는 없습니다. $x_3$에 대응하는 세번째 요소가 $u$, $v$ 모두 0이기 때문입니다.  $x_3$이 0이 아니라면 $w$는 $u$, $v$가 만들어내는 평면에 속하지 않게 됩니다. 다시 말해 $w$와 Span{$u$, $v$}가 선형독립이라는 얘기입니다.  반대로 $x_3$가 0이면 $w$는 $u$, $v$가 만드는 평면에 속하게 됩니다. 바꿔 말하면 $w$가 $u$, $v$의 선형결합으로 표시할 수 있다는 얘기입니다. 벡터 요소의 수/벡터 개수와 선형독립과의 관계를 살펴보겠습니다. 벡터가 다음과 같이 주어졌다고 칩시다. $$a=\begin{bmatrix} 2 \\ 1 \end{bmatrix},\quad b=\begin{bmatrix} 4 \\ -1 \end{bmatrix},\quad c=\begin{bmatrix} -2 \\ 2 \end{bmatrix}$$ 벡터 $b$와 $c$를 더하면 $a$와 같습니다. 즉 $a$, $b$, $c$는 서로 선형종속입니다.  한편 벡터의 요소 수(위의 경우 2)보다 벡터 숫자(위 예시에서 3)가 많으면 해당 벡터들은 선형종속 관계를 갖습니다. 이는 **차원(dimension)**과 **기저(basis)**와 연관되는 개념인데요, 이번 포스팅 주제를 넘어서므로 추후에 논의하도록 하겠습니다. 마지막으로 영벡터를 포함한 벡터 집합은 서로 선형종속 관계입니다. $v_1$을 0으로 놓으면(사실 $v_2$, $v_3$… 아무렇게나 지정해도 관계 없습니다) 아래와 같은 식이 성립하기 때문입니다. $$1{ v }_{ 1 }+0{ v }_{ 2 }+...+0{ v }_{ n }=0$$  ## 선형변환의 정의 아래 조건을 만족하는 매핑 함수 $T$를 Linear하다고 정의합니다. 즉 $T$는 **선형변환**(線型變換, linear transformation)입니다. > 임의의 두 벡터 $v$, $w$에 대해 $T(v+w)=T(v)+T(w)$ > > 임의의 스칼라 $a$와 벡터 $v$에 대해 $T(av)=aT(v)$ > > 임의의 스칼라 $c, d$와 벡터 $u,v$에 대해 $T(cu+dv)=cT(u)+dT(v)$ 지금까지 논의한 선형시스템(1차 연립방정식) $Ax=b$을 선형변환으로 이해할 수도 있습니다. 행렬 $A$가 m x n 크기이고, $x$가 $n$차원, $b$가 $m$차원 벡터라고 할 때 행렬 $A$는 $n$차원 벡터 $x$를 $m$차원 벡터 $b$로 변환하는 선형변환 함수라는 것이지요. 이를 그림으로 도시하면 아래와 같습니다. <a href="http://imgur.com/Eq53kxG"><img src="http://i.imgur.com/Eq53kxG.png" width="400px" title="source: imgur.com" /></a> 선형변환 함수 $T$를 아래와 같이 정의했다고 합시다. 그러면 아래 그림과 수식처럼 2차원 벡터 (2, -1)은 3차원 벡터 (5, 1, -9)로 변환됩니다. $$T(x)=\begin{bmatrix} 1 & -3 \\ 3 & 5 \\ -1 & 7 \end{bmatrix}\begin{bmatrix} { x }_{ 1 } \\ { x }_{ 2 } \end{bmatrix}$$ <a href="http://imgur.com/ynM9tFL"><img src="http://i.imgur.com/ynM9tFL.png" width="250px" title="source: imgur.com" /></a>  ## 선형변환 예시 그럼 이제부터 몇 가지 전형적인 선형변환과 그 행렬 형태를 살펴보도록 하겠습니다. 직관적으로 이해가능한데다 저도 보관 용도로 정리해두었으니 참고하시기 바랍니다.  ### reflections <a href="http://imgur.com/uPnbpUw"><img src="http://i.imgur.com/uPnbpUw.png" width="400px" title="source: imgur.com" /></a> <a href="http://imgur.com/RoDXSuM"><img src="http://i.imgur.com/RoDXSuM.png" width="400px" title="source: imgur.com" /></a> <a href="http://imgur.com/ospTeBE"><img src="http://i.imgur.com/ospTeBE.png" width="400px" title="source: imgur.com" /></a> <a href="http://imgur.com/QC495wq"><img src="http://i.imgur.com/QC495wq.png" width="400px" title="source: imgur.com" /></a> <a href="http://imgur.com/bnlpdpx"><img src="http://i.imgur.com/bnlpdpx.png" width="400px" title="source: imgur.com" /></a>  ### contractions and expansions <a href="http://imgur.com/Jwihag1"><img src="http://i.imgur.com/Jwihag1.png" width="450px" title="source: imgur.com" /></a> <a href="http://imgur.com/cQP4sU8"><img src="http://i.imgur.com/cQP4sU8.png" width="450px" title="source: imgur.com" /></a>  ### shears <a href="http://imgur.com/VVAf9kP"><img src="http://i.imgur.com/VVAf9kP.png" width="450px" title="source: imgur.com" /></a> <a href="http://imgur.com/dP2dXad"><img src="http://i.imgur.com/dP2dXad.png" width="450px" title="source: imgur.com" /></a>  ### projections <a href="http://imgur.com/u4ZTNdX"><img src="http://i.imgur.com/u4ZTNdX.png" width="400px" title="source: imgur.com" /></a> <a href="http://imgur.com/vy3DFXB"><img src="http://i.imgur.com/vy3DFXB.png" width="400px" title="source: imgur.com" /></a> 
recurrence␞ 이번 글에서는 알고리즘의 계산복잡도 함수가 **재귀식(Recurrence relation)** 내지 **점화식** 형태로 표현되는 경우를 살펴보도록 하겠습니다. 재귀식 또는 점화식이란 피보나치 수열(다음 피보나치 수는 바로 앞의 두 피보나치 수의 합이 되는 수열)처럼 수열의 항 사이에서 성립하는 관계식을 말합니다. 이로부터 데이터 수 $n$에 대해 **닫힌 형태(closed-form expression)**의 정확한 계산복잡도 함수를 찾는 것이 이 글의 목표입니다. (복잡도의 기준은 알고리즘이 필요로 하는 시간과 메모리 등 자원인데 전자를 '시간복잡도', 후자를 '공간복잡도'라 합니다) 이번 글 역시 고려대 김선욱 교수님 강의를 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 재귀식 형태로 표현된 시간복잡성 알고리즘의 계산복잡도 함수가 재귀식으로 표현되는 대표적인 사례 가운데 하나가 **분할-정복(divide-and-conquer) 문제**입니다. 다음과 같이 풉니다. 우선 원래 문제를 부분문제로 쪼갭니다(divide). 부분 문제를 풉니다(conquer). 이를 합칩니다(merge). 원래 문제에 $n$개의 데이터가 있고, 이를 푸는 데 드는 시간복잡도를 $T(n)$이라고 할 때 $T(n)$은 다음과 같이 분해할 수 있습니다.  $$ T\left (n\right)=T\left (divide\right)+T\left (conquer\right)+T\left (merge\right) $$  이를 **합병정렬(merge sort)**을 예시로 설명하겠습니다. 합병정렬 관련 자세한 내용은 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/09/06/insmersort/)을 참고하시면 좋을 것 같습니다.  $T(divide)$는 문제를 분할하는 데 걸리는 시간을 가리킵니다. 합병정렬을 예로 들면 원래 문제를 두 개로 나누기 위해 데이터를 반으로 자를 위치(인덱스) 하나만 고르면 되므로 $T(divide)=Θ(1)$입니다. (Big $Θ$ notation 관련해서는 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/09/13/asymptotic/)을 참고하시면 좋을 것 같습니다) $T(conquer)$는 (분할한 문제의 수 * 하위문제를 푸는 데 걸리는 시간)을 의미합니다. 원래 문제를 절반씩 두 개로 나누었고, 각 하위문제는 $n/2$개의 데이터가 있으므로 $T(conquer)=2*T(n/2)$가 될 것입니다. $T(merge)$는 하위문제를 합치는 데 걸리는 시간입니다. 합병정렬에서는 하위문제를 합치면서 정렬을 수행합니다. $n=8$일 때 다음 그림과 같습니다.  <a href="https://imgur.com/mx0Hyvk"><img src="https://i.imgur.com/mx0Hyvk.png" width="300px" title="source: imgur.com" /></a>  위 그림을 자세히 보면 하위 첫번째 array의 첫번째 요소(2)와 두번째 array의 첫번째 요소(1)을 비교해 sorted array의 첫번째 요소를 결정(1)합니다. 그 다음으로 첫번째 array의 첫번째 요소(2)와 두번째 array의 두번째 요소(2)를 비교해 sorted array의 두번째 요소를 결정(2)합니다. 이런 방식으로 merge를 모두 수행하는 데 총 $n=8$회의 연산을 수행하게 됩니다. 따라서 데이터 수가 $n$일 때 $T(merge)=Θ(n)$이 됩니다. 이를 바탕으로 합병정렬의 시간복잡도를 다시 쓰면 다음과 같습니다.   $$ T(n)=\Theta \left( 1 \right) +2\cdot T\left( \frac { n }{ 2 } \right) +\Theta \left( n \right) $$  하지만 위와 같은 재귀식 형태로는 해당 알고리즘의 시간복잡도를 정확히 알기가 어렵습니다. $T(n)$을 어렵게 구했지만 내부에 $T(n/2)$가 또 있어서 꼬리에 꼬리를 물고 $n$이 1이 될 때까지 식을 길게 늘여뜨려 써야하기 때문입니다. 이를 닫힌 형태로 구해보기 위해 다음 세 가지 방법을 씁니다.   ## Substitution method 이 방법은 (1) 해당 알고리즘의 시간복잡도를 $n$에 대한 함수로 가정한 뒤 (2) 이를 귀납(induction)에 의해 증명하는 방식입니다. 합병정렬을 예로 들면, 시간복잡도 함수 $T(n)=2T(n/2)+Θ(n)$의 $T(n)$이 $n\log_{2}{n}+n$일 거라 우선 가정해보는 것입니다. (알고리즘 계산복잡도를 따질 때 상수항은 무시하므로 $Θ(1)$은 없는 것으로 취급) 이를 바탕으로 (2) 귀납에 의한 증명을 해보면 다음과 같습니다. (2-1) $n=1$일 때 성립함을 보임   $$ 1\log _{ 2 }{ 1 } +1=0+1=T(1) $$  (2-2) $n$보다 작은 임의의 $k$에 대해 성립한다고 가정   $$ k\log _{ 2 }{ k } +k=T(k) $$  (2-3) $k/2$일 때도 성립함을 보임  $$ \begin{align*} T\left( \frac { k }{ 2 } \right) &=2T\left( \frac { k }{ 4 } \right) +\frac { k }{ 2 } \\ &=2\left( \frac { k }{ 4 } \log _{ 2 }{ \frac { k }{ 4 } } +\frac { k }{ 4 } \right) +\frac { k }{ 2 } \\ &=\frac { k }{ 2 } \log _{ 2 }{ \frac { k }{ 4 } } +\frac { k }{ 2 } +\frac { k }{ 2 } \\ &=\frac { k }{ 2 } \left( \log _{ 2 }{ \frac { k }{ 2 } } -\log _{ 2 }{ 2 } \right) +\frac { k }{ 2 } +\frac { k }{ 2 } \\ &=\frac { k }{ 2 } \log _{ 2 }{ \frac { k }{ 2 } } -\frac { k }{ 2 } +\frac { k }{ 2 } +\frac { k }{ 2 } \\ &=\frac { k }{ 2 } \log _{ 2 }{ \frac { k }{ 2 } } +\frac { k }{ 2 } \end{align*} $$  따라서 $T(n)=n\log_{2}{n}+n=Θ(n\log{n})$입니다. 하지만 Substitution method의 첫 단추인 가정 부분을 제대로 설계하지 않으면 증명이 불가능하다는 단점이 있습니다.   ## Iteration method 이 방법은 점화식을 무한히 풀어 헤쳐 모두 더하는 방식으로 구합니다. $T(n)=n+4T(n/2)$을 구해보겠습니다.  $$ \begin{align*} T\left( n \right) &=n+4T\left( \frac { n }{ 2 } \right) \\ &=n+4\left( \frac { n }{ 2 } +4T\left( \frac { n }{ 4 } \right) \right) =n+4\frac { n }{ 2 } +4T\left( \frac { n }{ 4 } \right) \\ &=n+4\left( \frac { n }{ 2 } +4\left( \frac { n }{ 4 } +4T\left( \frac { n }{ 8 } \right) \right) \right) =n+4\frac { n }{ 2 } +{ 4 }^{ 2 }\frac { n }{ 4 } +{ 4 }^{ 3 }T\left( \frac { n }{ 8 } \right) \\ &=...\\ &=n+4\frac { n }{ 2 } +{ 4 }^{ 2 }\frac { n }{ 4 } +{ 4 }^{ 3 }\frac { n }{ 8 } +...+{ 4 }^{ k }T\left( \frac { n }{ { 2 }^{ k } } \right) \end{align*} $$  위 식에서 $n/2^k$가 1이 될 때까지 끝까지 반복해서 더합니다. 이 때 $k$는 $\log_{2}{n}$입니다. ($2^k=n$) 그런데 여기에서 로그의 성질에 의해 $4^{\log_{2}{n}}=2^{2\log_{2}{n}}=n^{2\log_{2}{2}}=n^2$이 되므로 다음이 성립합니다.  $$ \begin{align*} T\left( n \right) &=n+4\frac { n }{ 2 } +{ 4 }^{ 2 }\frac { n }{ 4 } +{ 4 }^{ 3 }\frac { n }{ 8 } +...+{ 4 }^{ \log _{ 2 }{ n } }T\left( 1 \right) \\ &=\sum _{ i=0 }^{ \log _{ 2 }{ n } -1 }{ \left( 4^{ i }\frac { n }{ { 2 }^{ i } } \right) } +{ n }^{ 2 }T\left( 1 \right) \\ &=n\sum _{ i=0 }^{ \log _{ 2 }{ n } -1 }{ { 2 }^{ i } } +{ n }^{ 2 }T\left( 1 \right) \\ &=n(\frac { { 2 }^{ \log _{ 2 }{ n } }-1 }{ 2-1 } )+{ n }^{ 2 }T\left( 1 \right) \\ &=n(n-1)+{ n }^{ 2 }T\left( 1 \right) \\ &=\Theta \left( { n }^{ 2 } \right) +\Theta \left( { n }^{ 2 } \right) \\ &=\Theta \left( { n }^{ 2 } \right) \end{align*} $$  수식 말고도 트리 구조를 활용해 직관적으로 구하는 방법도 있습니다. $T(n)=T(n/3)+T(2n/3)$을 구해보겠습니다. 다음 그림과 같습니다.   <a href="https://imgur.com/K9WrTvy"><img src="https://i.imgur.com/K9WrTvy.png" width="400px" title="source: imgur.com" /></a>  우선 알고리즘이 한 개의 데이터를 처리하는 데 필요한 시간을 $c$라고 두면, $n$개 데이터를 처리하는 데 드는 시간복잡도는 $cn$입니다. 위 점화식은 한번 분기할 때마다 데이터를 각각 1/3, 2/3씩 나누게 됩니다.  따라서 위 그림 트리를 $i$번 분기했을 때 말단 좌측 끝 노드의 처리 대상 데이터 수는 $n/3^i$가 됩니다. 이 말단 노드의 데이터 수가 1이 될 때까지 분기를 했을 경우 그 분기 횟수 $i$는 $\log_{3}{n}$이 됩니다. ($3^i=n$)  마찬가지로 트리를 $j$번 분기했을 때 말단 우측 끝 노드의 데이터 수는 $n*{(2/3)}^j$가 됩니다. 이 말단 노드의 데이터 수가 1이 될 때까지 분기를 했을 경우 그 분기 횟수 $j$는 $\log_{3/2}{n}$이 됩니다. (${(3/2)}^j=n$) 점근 표기법(자세한 내용은 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/09/13/asymptotic/) 참고)은 데이터 수 $n$에 대해 최고차항의 차수만 따집니다. 그런데 위 트리에서 각 층을 연산하는 데 $cn$, 분기 횟수는 최대 $\log_{3/2}{n}$이 되므로 이 알고리즘의 계산복잡도는 $Θ(n\log{n})$가 됩니다. 이렇게 놓고 보면 재귀적으로 분기하는 함수에서 분기 횟수는 분기 비율의 역수를 밑으로 하고 데이터 수를 진수로 하는 로그값임을 알 수 있습니다. 하지만 Iteration method은 점화식이 수렴하지 않고 발산하는 형태일 경우 적용할 수 없습니다.   ## Master method 이 기법은 알고리즘의 계산복잡도 함수가 $T(n)=aT(n/b)+f(n)$ 형태일 경우 단번에 닫힌 형태를 구할 수 있는 마법과 같은 방법입니다. (단 $a≥1, b>1, f(n)>0$) 여기에서 $n^{\log_{b}{a}}$와 $f(n)$의 크기를 비교해 다음과 같이 한번에 닫힌 형태를 도출합니다. 그러나 아래 세 가지 경우를 제외한 함수에 대해서는 Master method를 적용할 수 없습니다.  `case 1` $n^{\log_{b}{a}}>f(n)$ → $T(n)=Θ(n^{\log_{b}{a}})$ `case 2` $n^{\log_{b}{a}}×\log{k}≓f(n)$ → $T(n)=Θ(n^{\log_{b}{a}}×\log{(k+1)}×n)$ - 단 로그를 제외한 최고차항의 차수가 같고 $k≥0$이어야 함 `case 3` $n^{\log_{b}{a}}<f(n)$ → $T(n)=f(n)$ - 단 충분히 큰 $n$과 1보다 작은 $c$에 대해 $af(n/b)≤cf(n)$을 만족해야 함  예를 들어보겠습니다.  - $T(n)=9T(n/3)+n$  - $n^{\log_{3}{9}}=n^2$이고 $f(n)=n$이므로 `case 1`에 해당  - 따라서 $T(n)=Θ(n^2)$ - $T(n)=27T(n/3)+Θ(n^3\log{n})$  - $n^{\log_{3}{27}}=n^3$이고 $f(n)=Θ(n^3\log{n})$이므로 `case 2`에 해당하는지 체크 : $n^3$, $n^3\log{n}$ 비교  - 로그를 제외한 최고차항의 차수가 3으로 같고 $k=1$일 때 `case 2`가 성립  - 따라서 $T(n)=Θ(n^3×\log2×n)$ - $T(n)=5T(n/2)+Θ(n^3)$  - $n^{\log_{2}{5}}<n^3$이므로 `case 3 `에 해당  - $af(n/b)=5{(n/2)}^2=5n^3/8≤cn^3$를 만족하는 1보다 작은 $c$가 존재  - 따라서 $T(n)=Θ(n^3)$    ## Recursive Matrix Multiplication에 적용 지금까지 말씀드린 기법을 **Recursive Matrix Multiplication**에 적용해보겠습니다. 이 기법은 $n×n$ 정방행렬을 $n/2×n/2$ 행렬 4개로 나눈 뒤 내적(inner product)해 공간복잡도를 줄이는 방법입니다. 이같은 방식을 **타일링(tiling)**이라고 합니다. $A$와 $B$를 내적해 $C$를 얻는 연산($C=AB$)의 경우 다음과 같이 분할-정복 방식으로 나눠풀 수 있습니다.  $$ \begin{align*} \begin{pmatrix} { C }_{ 11 } & { C }_{ 12 } \\ { C }_{ 21 } & { C }_{ 22 } \end{pmatrix}&=\begin{pmatrix} { A }_{ 11 } & A_{ 12 } \\ { A }_{ 21 } & A_{ 22 } \end{pmatrix}\cdot \begin{pmatrix} { B }_{ 11 } & B_{ 12 } \\ B_{ 21 } & { B }_{ 22 } \end{pmatrix}\\ \\ { C }_{ 11 }&={ A }_{ 11 }\cdot { B }_{ 11 }+{ A }_{ 12 }\cdot { B }_{ 21 }\\ { C }_{ 12 }&={ A }_{ 11 }\cdot { B }_{ 12 }+{ A }_{ 12 }\cdot { B }_{ 22 }\\ { C }_{ 21 }&={ A }_{ 21 }\cdot { B }_{ 11 }+{ A }_{ 22 }\cdot { B }_{ 21 }\\ { C }_{ 22 }&={ A }_{ 21 }\cdot { B }_{ 12 }+{ A }_{ 22 }\cdot { B }_{ 22 } \end{align*} $$  $n×n$ 정방행렬을 내적하는 데 필요한 계산복잡도를 $T(n)$이라 할 때 이를 다음과 같이 분해할 수 있습니다.  $$ T\left (n\right)=T\left (divide\right)+T\left (conquer\right)+T\left (merge\right) $$  $T(divide)=Θ(1)$입니다. 1부터 $n$의 범위에서 행렬을 어디서 나눌지 한번만 결정하면 되기 때문입니다. $T(conquer)=8T(n/2)$입니다. 위의 수식처럼 $n/2×n/2$ 행렬 내적을 8번 수행해야 합니다. $T(merge)=Θ(n^2)$입니다. 예컨대 $A_{11}B_{11}$과 $A_{12}B_{21}$을 더해 $C_{11}$을 만든다고 할 때 $n×n$ 정방행렬의 전체 요소 $n^2$개의 1/4만큼 덧셈 연산을 수행해야할 것입니다. 이를 4회 반복해야 하므로 이같은 결과가 나옵니다. 이를 바탕으로 $T(n)$을 다시 쓰면 다음과 같습니다.  $$ T(n)=8\cdot T\left( \frac { n }{ 2 } \right) +\Theta \left( {n}^{2} \right) $$  위 점화식 형태의 함수를 Master method를 이용해 닫힌 형태로 나타내면 다음과 같습니다.  - $n^{\log_{2}{8}}=n^3>n^2$이므로 `case 1 `에 해당 - 따라서 $T(n)=Θ(n^{\log_{2}{8}})=Θ(n^3)$     
viterbi␞ 이번 글에서는 **비터비 알고리즘(Viterbi Algorithm)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아를 참고해 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept 비터비 알고리즘이란 `히든 스테이트의 최적 시퀀스`(the most likely sequence of hidden states)를 찾기 위한 다이내믹 프로그래밍(dynamic programming) 기법의 일종입니다. 여기서 히든 스테이트란 [은닉마코프모델](https://ratsgo.github.io/machine%20learning/2017/03/18/HMMs/) 등의 추정 대상인 품사, 개체명 등을 가리킵니다. 은닉마코프모델에 적용된 비터비 알고리즘을 파이썬 코드로 구현한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/10/14/computeHMMs/)을 참고하시면 좋을 것 같습니다. 어쨌든 비터비 알고리즘을 이해하기 위해서는 은닉마코프모델 등의 아키텍처뿐 아니라 다이내믹 프로그래밍 개념(반복되는 계산 결과를 저장해 두었다가 풀기)을 익히고 있어야 하는데요. 이 글에서는 [다이내믹 프로그래밍]()의 대표적 예시 가운데 하나이자 비터비 알고리즘과 유사한 기법인 *Assembly-Line Scheduling*을 중심으로 살펴 보겠습니다.   ## Assembly-Line Scheduling *Assembly-Line Scheduling* 문제는 2개(혹은 그 이상)의 조립라인 사이에서 생산비용을 최소화하는 최적 경로(path)를 찾는 문제입니다. 다음 그림과 같습니다.  <a href="https://imgur.com/WzPD3id"><img src="https://i.imgur.com/WzPD3id.png" title="source: imgur.com" /></a>  위 그림에서 동그라미는 비용(cost)을 나타냅니다. 제품은 1번 내지 2번 라인을 자유롭게 오갈 수 있습니다. 제품이 첫번째 공정에서 1번 라인에 보내진다면 그 비용은 2+7, 즉 9가 됩니다. 제품이 첫번째 공정에서 2번 라인에 보내진다면 비용은 4+8, 즉 12가 됩니다. 이를 식으로 쓰면 다음과 같습니다. - $f_1[1]=2+7=9$ - $f_1[2]=4+8=12$ 그러면 두번째 공정에서 제품이 1번 라인에 있다면 그 최소 비용(=$f_2[1]$)은 얼마일까요? 두 가지 경우의 수를 생각해 볼 수 있습니다. 첫번째 공정에서 1번 라인, 두번째 공정도 1번 라인인 *case*입니다. 또 첫번째 공정에서 2번 라인, 두번째 공정은 1번 라인인 *case*입니다. 두 경우 중 작은 값을 취해 구합니다.  $$ \begin{align*} { f }_{ 2 }\left[ 1 \right] &=\min { \left( 2+7+9,4+8+2+9 \right) } \\ &=\min { \left( { f }_{ 1 }\left[ 1 \right] +9,{ f }_{ 1 }\left[ 2 \right] +2+9 \right) } \\ &=\min { \left( 18,23 \right) } =18 \end{align*} $$  그렇다면 두번째 공정의 1번 라인을 기준으로 보면, 1번 라인을 유지하는게 나을까요, 아니면 1번에서 2번으로 라인을 바꾸는 것이 좋을까요? 각각의 비용은 18, 23이므로 유지하는 것이 좋습니다. 제품이 두번째 공정에서 1번 라인에 있다면 생산비용을 줄이기 위한 제품의 최적 경로는 **1번 라인**(직전 공정) → 1번 라인(현재 공정)입니다.  이를 식으로 나타내면 다음과 같습니다.  - $l_2[1]=1$ 같은 방식으로 $f_2[2]$와 $l_2[2]$를 구하면 각각 다음과 같습니다. 다시 말해 제품이 두번째 공정에서 2번 라인에 있다면 제품의 최적 경로는 **1번 라인** → 2번 라인입니다. - $f_2[2]=min(4+8+5,2+7+2+5)\\=min(f_1[2]+5,f_1[1]+2+5)=min(17,16)=16$ - $l_2[2]=1$ 그런데 구하는 과정을 자세히 보면 처음에 구한 $f_1[1]$과 $f_1[2]$을 다음 공정에 소요되는 최소 비용을 구할 때 재활용한다는 사실을 알 수 있습니다. 이처럼 계산과정이 반복될 때 중간 계산과정을 저장해 두었다가 해당 계산결과가 필요할 때 다시 써먹는 기법을 `다이내믹 프로그래밍`이라고 합니다. 위와 같은 과정을 반복해 각 단계별 최소 생산비용을 구한 표는 다음과 같습니다.  |  $j$  | 1  | 2  | 3  | 4  | 5  | 6  | | :------: | :--: | :--: | :--: | :--: | :--: | :--: | | $f_j[1]$ | 9  | 18 | 20 | 24 | 32 | 35 | | $f_j[2]$ | 12 | 16 | 22 | 25 | 30 | 37 | 각 단계별 최적 경로는 다음과 같습니다. |  $j$  | 2  | 3  | 4  | 5  | 6  | | :------: | :--: | :--: | :--: | :--: | :--: | | $l_j[1]$ | 1  | 2  | 1  | 1  | 2  | | $l_j[2]$ | 1  | 2  | 1  | 2  | 2  | 자, 이제는 제품이 라인을 빠져나가는 경우를 생각해 봅시다. 제품이 여섯번째 공정까지 왔고 1번 라인에 있는 경우의 최소 소요비용($f_6[1]$)은 35입니다. 1번 라인에서 출하하는 데 드는 비용은 위의 그림을 보니 3입니다. 둘을 더한 38이 총 생산비용이 됩니다. 마찬가지로 2번 라인에 대해 총 생산비용을 구하면 37+2로 39가 됩니다. 따라서 총 생산비용을 최소화하는 제품 생산 경로는 마지막 여섯번째 공정 때 1번 라인에 있어야 합니다.  각 단계별로 *backtrace*를 한 결과는 다음과 같습니다. - 총 생산비용을 최소화하려면, 제품은 다섯번째 공정에서 2번 라인에 있어야 한다. (∵ $l_6[1]=2$) - 제품은 네번째 공정에서 2번 라인에 있어야 한다. (∵ $l_5[2]=2$) - 제품은 세번째 공정에서 1번 라인에 있어야 한다. (∵ $l_4[2]=1$) - 제품은 두번째 공정에서 2번 라인에 있어야 한다. (∵ $l_3[1]=2$) - 제품은 첫번째 공정에서 1번 라인에 있어야 한다. (∵ $l_2[2]=1$) 이를 그림으로 나타내면 다음과 같습니다. 처음에 소개한 그림과 동일합니다.  <a href="https://imgur.com/WzPD3id"><img src="https://i.imgur.com/WzPD3id.png" title="source: imgur.com" /></a>    ## Viterbi Algorithm 비터비 알고리즘을 애니메이션으로 만든 그림은 다음과 같습니다([출처](https://www.researchgate.net/publication/273123953_Animation_of_the_Viterbi_algorithm_on_a_trellis_illustrating_the_data_association_process)). 현재 스테이트로 전이할 확률이 가장 큰 직전 스테이트를 모든 시점, 모든 스테이트에 대해 구합니다.   <a href="https://imgur.com/bHji1M9"><img src="https://i.imgur.com/bHji1M9.gif" width="500px" title="source: imgur.com" /></a>  모든 시점, 모든 스테이트에 대해 구한 결과는 다음과 같습니다. (원래는 그물망처럼 촘촘하게 되어 있으나 경로가 끊어지지 않고 처음부터 끝까지 연결되어 있는 경로가 유효할 것이므로 그래프를 그린 사람이 이해를 돕기 위해 이들만 남겨 놓은 것 같습니다)  <a href="https://imgur.com/PXxizNe"><img src="https://i.imgur.com/PXxizNe.png" width="500px" title="source: imgur.com" /></a>  위 패스에서 만약 최대 확률을 내는 $k+2$번째 시점의 상태가 $θ_0$라면 *backtrace* 방식으로 구한 최적 상태열은 다음과 같습니다. - $[θ_0, θ_2, θ_2, θ_1, θ_0, θ_1]$
NNtricks␞ 이번 글은 딥러닝 관련 다양한 학습기술들을 살펴보고자 합니다. 이번 글은 미국 스탠포드 대학의 [CS231n](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&sqi=2&ved=0ahUKEwjRkaLSyLzTAhVFnZQKHVIlCKEQFgghMAA&url=http%3A%2F%2Fcs231n.stanford.edu%2F&usg=AFQjCNHK3W1B3pbCvVlwKseIa18p7vPsAA&sig2=Lez1Eruk0Q60GK-il-qjtA)과 역시 같은 대학의 [CS224d](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiTztbayLzTAhUFl5QKHf8MBjsQFgghMAA&url=http%3A%2F%2Fcs224d.stanford.edu%2F&usg=AFQjCNG1D6WOf9hSDyugLLEk8TxsdTjt2w&sig2=jXE0EVMekjNGesD0DvmrQw) 강좌를 정리했음을 먼저 밝힙니다. 따로 정리할 예정인 **배치정규화(batch-regularization)**를 제외하고 전반적인 내용을 요약하였습니다. 그럼 시작하겠습니다.  ## 딥러닝 학습의 일반적 절차 딥러닝의 일반적 절차는 다음과 같습니다. 1. **적절한 네트워크 선택**   1) **구조(structure)** : Single words vs Bag of Words, etc.   2) **비선형성(nonlinearity) 획득 방법** : ReLu vs tanh, etc. 2. **그래디언트 체크** : 네트워크를 구축했는데 그래디언트 계산이 혹시 잘못될 염려가 있으므로 잘됐는지 체크해봅니다 3. **학습 파라메터 초기화** : 초기화 방법에도 여러가지가 있으므로 적절히 선택합니다 4. **학습 파라메터 최적화** : Stochastic Gradient vs Adam, etc. 5. **과적합 방지** : dropout vs regularize, etc.   ## 비선형성 획득 : 활성함수 뉴럴네트워크의 개별 뉴런에 들어오는 입력신호의 총합을 출력신호로 변환하는 함수를 **활성화함수(activation function)**라고 합니다. 활성화함수 유무는 초창기 모델인 **퍼셉트론(perceptron)**과 뉴럴네트워크의 유일한 차이점이기도 하죠. 활성화함수는 대개 **비선형함수(non-linear function)**를 씁니다. 활성화함수로 왜 선형함수를 쓰면 안되는 걸까요? '밑바닥부터 시작하는 딥러닝'의 한 글귀를 인용해보겠습니다. > 선형함수인 $h(x)=cx$를 활성화함수로 사용한 3층 네트워크를 떠올려 보세요. 이를 식으로 나타내면 $y(x)=h(h(h(x)))$가 됩니다. 이는 실은 $y(x)=ax$와 똑같은 식입니다. $a=c^3$이라고만 하면 끝이죠. 즉, 은닉층이 없는 네트워크로 표현할 수 있습니다. 뉴럴네트워크에서 층을 쌓는 혜택을 얻고 싶다면 활성화함수로는 반드시 비선형 함수를 사용해야 합니다. 그러면 뉴럴네트워크 활성화함수 몇 가지 살펴보겠습니다.  ### 시그모이드 로지스틱 함수로도 불립니다. 원래 수식 및 미분식은 아래와 같습니다. $$\sigma (x)=\frac { 1 }{ 1+{ e }^{ -x } } \\ \sigma '\left( x \right) =\sigma (x)(1-\sigma (x))$$ 시그모이드 함수의 범위는 $[0,1]$이고요, 그래프의 모양은 아래와 같습니다. <a href="http://imgur.com/HpSpWal"><img src="http://i.imgur.com/HpSpWal.png" width="500px" title="source: imgur.com" /></a> 시그모이드 함수를 1차 미분한 그래프는 아래와 같습니다. <a href="http://imgur.com/WpKD6kW"><img src="http://i.imgur.com/WpKD6kW.png" width="500px" title="source: imgur.com" /></a> 시그모이드 함수는 개별 뉴런이 내뱉어 주는 값을 S자 커브 형태로 자연스럽게 활성화를 해주기 때문에 예전부터 인기가 좀 있었습니다. 다만 입력값이 -5보다 작거나 5보다 클 경우에는 그래디언트 값이 지나치게 작아지고(=이렇게 되면 학습이 잘 안되죠), exp 연산이 다소 무겁다(=학습이 느려지죠)는 단점이 있습니다.  아울러 $σ(x)$의 범위는 $[0,1]$로서 모두 0 이상의 값을 지닌다는 문제가 있습니다. 이게 단점이 되는 이유는 바로 학습 속도와 관련이 있는데요. 예컨대 아래와 같은 뉴런이 있고 활성화함수 $f$가 시그모이드라고 가정해봅시다.  <a href="http://imgur.com/euw7qQu"><img src="http://i.imgur.com/euw7qQu.png" width="400px" title="source: imgur.com" /></a> $x_0$, $x_1$, $x_2$는 모두 0 이상의 값을 갖습니다. 이들은 직전 층에서 시그모이드 함수에 의해 그 값이 양수로 활성화됐기 때문입니다. 여기에서 역전파시 최종 Loss에서 출발해 시그모이드 적용 직전의 $w_ix_i+b$ 각각에 들어오는 그래디언트를 $δ$라고 두겠습니다. 그렇다면 $w_i$의 그래디언트는 아래와 같습니다. $$\frac { \partial L }{ \partial { w }_{ i } } ={ x }_{ i }\times \delta $$ 앞서 말씀드렸듯 $x_0​$, $x_1​$, $x_2​$는 모두 0 이상이기 때문에 $δ​$가 양수라면 Loss에 대한 $w_0, w_1, w_2​$ 각각의 그래디언트가 모두 양수, 반대라면 모두 음수 값이 될 것입니다. 따라서 데이터 $x​$와 파라메터 $w​$를 2차원 벡터로 가정해 본다면 $w​$의 그래디언트는 2사분면과 4사분면 쪽 방향이 될 수는 없습니다. 결과적으로 $w$ 학습시 아래 그림처럼 허용되는 방향에 제약이 가해져(요소값이 모두 양수인' 1사분면과' 모두 음수인 '3사분면' 쪽 방향만 선택 가능) 학습속도가 늦거나 수렴이 어렵게 됩니다. 이 문제는 함수값이 0에 대해 대칭(zero-centered)인 하이퍼볼릭탄젠트 같은 함수를 쓰면 극복할 수 있다고 합니다.  <a href="http://imgur.com/bvyJYfy"><img src="http://i.imgur.com/bvyJYfy.png" width="300px" title="source: imgur.com" /></a>  ### 하이퍼볼릭탄젠트 하이퍼볼릭탄젠트는 시그모이드 함수의 **크기와 위치를 조절(rescale and shift)**한 함수입니다. 시그모이드 함수와의 관계식과 미분식은 각각 아래와 같습니다. $$ \begin{align*} tanh(x)&=2\sigma (2x)-1\\ &=\frac { { e }^{ x }-{ e }^{ -x } }{ { e }^{ x }+{ e }^{ -x } } \\tanh'\left( x \right) &=1-tanh^{ 2 }\left( x \right) \end{align*} $$ 하이퍼볼릭탄젠트의 범위는 $[-1,1]$입니다. 그래프의 모양은 시그모이드 함수와는 달리 0을 기준으로 대칭인 점을 확인할 수 있습니다. 이 때문에 하이퍼볼릭탄젠트는 시그모이드를 활성화함수로 썼을 때보다 학습 수렴 속도가 빠르다고 합니다. <a href="http://imgur.com/xaQpDt4"><img src="http://i.imgur.com/xaQpDt4.png" width="500px" title="source: imgur.com" /></a> 하이퍼볼릭탄젠트를 1차 미분한 그래프는 아래와 같습니다. 시그모이드함수와 마찬가지로 $x$가 -5보다 작거나 5보다 크면 그래디언트가 0으로 작아지는 점을 볼 수 있습니다. 이것이 하이퍼볼릭탄젠트의 단점입니다. <a href="http://imgur.com/0mVuW9h"><img src="http://i.imgur.com/0mVuW9h.png" width="500px" title="source: imgur.com" /></a>  ### Rectified Linear Unit (ReLU) ReLU는 아래와 같이 정의됩니다. $$f(x)=max(0,x)$$ 그래프의 모양은 아래와 같습니다. $x$가 양수이기만 하면 그래디언트가 1로 일정하므로 그래디언트가 죽는 현상을 피할 수 있고, 미분하기도 편리해 계산복잡성이 낮습니다. 실제로 시그모이드나 하이퍼볼릭탄젠트 함수 대비 학습수렴 속도가 6배나 빠르다고 합니다. <a href="http://imgur.com/SAxRPcy"><img src="http://i.imgur.com/SAxRPcy.png" width="500px" title="source: imgur.com" /></a> 다만 위 그림에서 확인할 수 있듯 0을 기준으로 대칭인 모양은 아닙니다. 아울러 $x$가 음수이면 그래디언트가 무조건 0이 된다는 단점이 있습니다. 이를 극복하기 위해 **Leaky ReLU**가 고안되었습니다.   ### Leaky ReLU Leaky ReLU의 식은 아래와 같습니다. $$f(x)=max(0.01x,x)$$ 그래프의 모양은 다음과 같습니다. $x$가 음수일 때 그래디언트가 0.01이라는 점을 제외하고는 ReLU와 같은 특성을 지닙니다. <a href="http://imgur.com/SXq4jmJ"><img src="http://i.imgur.com/SXq4jmJ.png" width="500px" title="source: imgur.com" /></a>  ### Exponential Linear Units (ELU) ELU는 ReLU의 특성을 공유하고요, 그래디언트가 죽지 않는다는 장점이 있다고 합니다. 다음 수식과 같습니다. $$f(x)=x\quad if\quad x>0\\ f(x)=\alpha ({ e }^{ x }-1)\quad if\quad x\le 0$$  ### Maxout Neurons MN은 다음과 같습니다. 연결된 두 개의 뉴런 값 중 큰 값을 취해 비선형성을 확보합니다. 다만 활성화함수를 적용하기 위해 필요한 연산량이 많다는 단점이 있습니다. $$f(x)=max({ w }_{ 1 }^{ T }x+{ b }_{ 1 },{ w }_{ 2 }^{ T }x+{ b }_{ 2 })$$    ## 학습 파라메터 초기화 각 층의 가중치(weights)와 편향(bias) 등 학습 파라메터는 초기값 설정이 매우 중요하다고 합니다. 뉴럴네트워크가 풀려는 문제 자체가 non-convex optimization이기 때문에 시작점에 따라 최적지점을 찾지 못하게 될 수도 있습니다. 또한 학습 파라메터의 초기값을 적절하게 설정할 경우 그래디언트 조절에도 유의미한 효과를 낸다고 합니다. 이와 관련해 시그모이드 함수의 1차 미분 그래프를 다시 보도록 하겠습니다. <a href="http://imgur.com/WpKD6kW"><img src="http://i.imgur.com/WpKD6kW.png" width="500px" title="source: imgur.com" /></a> 입력값 $x$에 가중치 $w$를 곱하고 편향 $b$를 더한 식을 $t$라고 둡시다. 여기에서 $w$가 100, $b$가 50이라면 $x$가 0.01로 매우 작더라도 $t$는 51이 됩니다. 역전파시 시그모이드 함수를 통과시키면 $σ'(51)$가 반환이 될텐데요, 위 그래프를 보시다시피 $t$가 5만 넘어도 $σ'(t)$는 0에 수렴하기 때문에 그래디언트가 죽어버리는 결과를 초래하게 됩니다. 그래디언트가 지나치게 작아지기 때문에 이후 학습이 사실상 불가능해지는 것이지요.  이와 별개로 뉴럴네트워크 입력층의 가중치 $W$를 모두 0으로 초기화한다면 어떻게 될까요? 순전파 때는 $W$가 0이기 때문에 두번째 층의 뉴런에 모두 같은 값이 전달됩니다. **미분의 연쇄법칙(chain-rule)**을 떠올려보면 두번째 층의 모든 뉴런에 같은 값이 입력된다는 것은 역전파 때 두번째 층의 가중치가 모두 똑같이 갱신된다는 말이 됩니다. 다시 말해 뉴런이 100개가 됐든 1000개가 됐든 거의 같은 값을 출력하게 돼 네트워크의 표현력을 제한하게 된다는 얘기입니다. 따라서 학습파라메터의 초기값을 잘 설정해주어야 합니다. 이와 관련해 다양한 파라메터 초기화 방법론이 제시되었습니다. 일부를 소개하면 다음과 같습니다. 여기에서 $n_{in}$은 직전 레이어의 차원수, $n_{out}$은 다음 레이어의 차원수입니다. 아래 초기화식은 각 층의 가중치 $W$에 관한 식이고요, 은닉층과 출력층의 편향 $b$는 대개 0으로 설정한다고 합니다.  ### LeCun Initialization (Xavier Initialization) $$W\sim Uniform({ n }_{ in },{ n }_{ out })\\ Var(W)=\frac { 1}{ { n }_{ in } } $$  ### Glorot Initialization $$W\sim Uniform({ n }_{ in },{ n }_{ out })\\ Var(W)=\frac { 2 }{ { n }_{ in }+{ n }_{ out } }$$  ### He Initialization $$W\sim Uniform({ n }_{ in },{ n }_{ out })\\ Var(W)=\frac { 2 }{ { n }_{ in } }$$  ## 학습 파라메터 최적화 (1) 학습 파라메터 최적화 기법으로 널리 쓰이는 **그래디언트 디센트(Gradient Descent)**는 기본적으로 아래와 같은 구조를 지닙니다. 여기에서 $θ$는 갱신 대상 학습 파라메터, $dL/dθ$는 Loss에 대한 $θ$의 그래디언트, $η$는 **학습률(leaning rate)**을 의미합니다. 즉 아래 식은 Loss에 대한 $θ$의 그래디언트 반대 방향으로 $η$만큼 조금씩 $θ$를 업데이트하라는 뜻입니다. $$\theta \leftarrow \theta -\eta \frac { \partial L }{ \partial \theta } $$ 그래디언트 디센트 방법론에도 여러 변형이 존재합니다. 세 가지 살펴보겠습니다. 아래 제시된 코드는 파이썬 기준입니다.  ### Batch Gradient Descent 이 방법은 전체 학습데이터 Loss에 대한 각 파라메터의 그래디언트를 한꺼번에 구한 뒤 1 epoch동안 모든 파라메터 업데이트를 단 한번 수행하는 방식입니다. 매우 느리고 메모리 요구량이 많다는 단점이 있지만 최적해를 찾을 수 있다는 장점이 있다고 합니다. (It's guaranteed to converge to the global minimum for convex error surfaces and to a local minimum for non-convex surfaces) ```python for i in range(nb_epochs):   params_grad = evaluate_gradient(loss_function, data, params)   params = params - learning_rate * params_grad ```  ### Stochastic Gradient Descent 학습데이터의 순서를 랜덤으로 섞은 뒤 개별 레코드(위 코드에서 example) 단위로 Loss와 그래디언트를 구한 뒤 학습 파라메터를 조금씩 업데이트하는 방식입니다. 1 epoch동안 학습데이터 개수만큼의 업데이트가 수행됩니다. BGD보다 훨씬 빠르면서도 수렴 결과가 BGD와 일치(학습률을 줄였을 때)한다고 합니다.  ```Python for i in range(nb_epochs):   np.random.shuffle(data)   for example in data:   	params_grad = evaluate_gradient(loss_function, example, params)   	params = params - learning_rate * params_grad ```  ### Mini-batch Gradient Descent 이 방식은 개별 레코드가 아니라 batch_size(아래 코드에서 50) 단위로 학습한다는 점을 제외하고는 SGD와 같습니다. SGD에 비해 안정적으로 학습하는 경향이 있다고 합니다. 게다가 데이터가 배치 단위로 들어가게 되면 사실상 행렬 연산이 되기 때문에 시중에 공개돼 있는 강력한 라이브러리를 사용할 수 있다는 장점 또한 있습니다. ```python for i in range(nb_epochs):   np.random.shuffle(data)   for batch in get_batches(data, batch_size=50):   	params_grad = evaluate_gradient(loss_function, batch, params)   	params = params - learning_rate * params_grad ```   ## 학습 파라메터 최적화 (2) 그래디언트 디센트 계열 외에 다양한 최적화 기법을 소개합니다. 최근 각광받고 있는 기법들입니다.  ### Momentum 모멘텀은 운동량을 뜻하는 단어로 물리 현상과 관계가 있습니다. 예컨대 아래 그림처럼 공이 한번 움직이기 시작하면 기울기 방향으로 힘을 받아 가속하게 되죠. 모멘텀 기법은 바로 이 점에 착안했습니다. <a href="http://imgur.com/SQAkzU2"><img src="http://i.imgur.com/SQAkzU2.png" width="200px" title="source: imgur.com" /></a> 모멘텀 기법은 수식으로는 다음과 같이 쓸 수 있습니다. 여기에서 $μv$는 물체가 아무런 힘을 받지 않을 때 서서히 하강시키는 역할을 합니다($μ$는 0.9 등의 값으로 설정합니다). 물리에서는 지면 마찰이나 공기 저항에 해당합니다. 나머지는 그래디언트 디센트 기법과 동일합니다. $$v\leftarrow \mu v-\eta \frac { \partial L }{ \partial \theta } \\ \theta \leftarrow \theta +v$$ 모멘텀 기법의 최적화 효과를 직관적으로 나타낸 그림은 아래와 같습니다. 하단 좌측 그림을 보시면 현재의 그래디언트가 모멘텀과 같은 방향이라면 업데이트가 더 크게 이뤄지게 됩니다. 하단 우측 그림에서 최적화 지점이 원 내부 중앙이라고 했을 때 모멘텀 기법이 조금 더 효율적인 업데이트 경로를 거치고 있는 점을 확인할 수 있습니다. <a href="http://imgur.com/6nnAWF8"><img src="http://i.imgur.com/6nnAWF8.png" width="400px" title="source: imgur.com" /></a> 코드로는 아래와 같습니다. 여기에서 $μ$는 사용자가 지정하는 하이퍼파라메터입니다. ```python param_grad = evaluate_gradient(loss_function, data, params) v = mu * v - learning_rate * param_grad param = v + param ```  ### Nesterov Accelerated Gradient 이 기법은 모멘텀 기법을 업그레이드한 버전입니다. 현재 학습 파라메터(붉은색 원 : 아래 코드에서 $params$)를 직전까지 축적된 그래디언트 방향(녹색선)으로 이동시킵니다. 이 벡터($params_{ahead}$)를 기준으로 그래디언트(붉은색 선 : $params\_grad_{ahead}$)를 계산합니다. 실제 업데이트는 둘을 모두 반영해 이뤄집니다.  > **모멘텀과의 차이** : 모멘텀은 현재 점(붉은색 원)에서 그래디언트를 구합니다. NAG는 녹색선과 빨간선이 이루는 꼭지점에서 그래디언트를 구합니다. <a href="http://imgur.com/xC1YRNZ"><img src="http://i.imgur.com/xC1YRNZ.png" width="300px" title="source: imgur.com" /></a> 이 기법을 코드로 나타내면 아래와 같습니다. 여기에서도 $μ$는 역시 사용자가 지정하는 하이퍼파라메터입니다. ```Python params_ahead = params + mu * v params_grad_ahead = evaluate_gradient(loss_function, data, params_ahead) v = mu * v - learning_rate * params_grad_ahead params = v + params ```  ### AdaGrad **학습률 감소**와 연관된 기법입니다. AdaGrad는 각각의 학습 파라메터에 맞춤형으로 학습률을 조정하면서 학습을 진행합니다. 수식은 아래와 같습니다. 여기에서 $⊙$는 행렬의 원소별 곱셈을 의미합니다. 식을 보시면 학습 파라메터의 원소 가운데 많이 움직인(크게 갱신된) 원소는 학습률이 낮아지게 돼 있습니다. 다시 말해 학습률이 학습 파라메터의 원소마다 다르게 적용된다는 뜻입니다. $$h\leftarrow h+\frac { \partial L }{ \partial \theta } \odot \frac { \partial L }{ \partial \theta } \\ \theta \leftarrow \theta -\frac { \eta }{ \sqrt { h } } \frac { \partial L }{ \partial \theta } $$ 이를 코드로 나타면 아래와 같습니다. 아래 코드에서 eps는 분모가 너무 0에 가깝지 않도록 안정화하는 역할을 합니다. 보통 $10^{-4}$에서 $10^{-8}$의 값을 쓴다고 합니다. ```Python params_grad = evaluate_gradient(loss_function, data, params) h = h + params_grad**2 params = params - learning_rate / (np.sqrt(h) + eps) * params_grad ```  ### RMSProp AdaGrad는 학습률 $η$를, 과거의 기울기를 제곱한 값을 계속 더해나간 $h$로 나눠줍니다. 학습을 진행할 수록 $η$가 지속적으로 작아진다는 뜻입니다. 계속 학습하면 $η$가 0이 돼서 학습이 불가능해지는 시점이 옵니다. RMSProp은 이를 개선하기 위한 기법입니다. 즉 과거의 모든 기울기를 다 더해 균일하게 반영하는 것이 아니라, 먼 과거의 기울기는 서서히 잊고 새로운 기울기 정보를 크게 반영하기 위해 $h$를 계산할 때 **지수이동평균(Exponential Moving Average)**을 적용합니다.  코드는 아래와 같습니다. 여기에서 decay_rate는 사용자 지정 하이퍼파라메터이고 보통 $[0.9, 0.99, 0.999]$ 가운데 하나를 쓴다고 합니다. ```python params_grad = evaluate_gradient(loss_function, data, params) h = decay_rate * h + (1 - decay_rate) * params_grad**2 params = params - learning_rate / (np.sqrt(h) + eps) * params_grad ```  ### Adam 모멘텀은 공이 구르듯 하는 물리 법칙에 착안해 만들어진 기법입니다. AdaGrad과 RMSProp은 학습 파라메터의 개별 원소마다 학습률을 달리 적용합니다. 두 기법을 합친 것이 바로 Adam입니다. 퍼포먼스가 좋아서 최근 많은 관심을 받고 있는 기법인데요. 코드는 다음과 같습니다. ```python params_grad = evaluate_gradient(loss_function, data, params) m = beta1 * m + (1 - beta1) * params_grad v = beta2 * v + (1 - beta2) * params_grad**2 params = params - learining_rate * m / (np.sqrt(v) + eps) ``` 여기에서 $beta_1$, $beta_2$, $eps$는 사용자가 지정하는 하이퍼파라메터입니다. 논문에 따르면 각각 0.9, 0.999, $10^{-8}$이 좋다고 합니다.  ### 각 기법 비교 너무나도 유명한 그림이라 설명은 생략하겠습니다. 저 역시 정리 용도로 올려 둡니다. <a href="http://imgur.com/U34fEr3"><img src="http://i.imgur.com/U34fEr3.gif" width="400px" title="source: imgur.com" /></a> <a href="http://imgur.com/i98ywya"><img src="http://i.imgur.com/i98ywya.gif" width="350px" title="source: imgur.com" /></a>   ## 과적합 방지 **과적합(overfitting)**이란 모델이 학습데이터에만 지나치게 적응해서 일반화 성능이 떨어지는 경우를 말합니다. 기계학습은 범용 성능을 지향하기 때문에 학습데이터 외에 처음 보는 데이터가 주어지더라도 올바르게 판단할 수 있는 능력을 가져야 합니다. 뉴럴네트워크 학습시 과적합을 방지하는 몇 가지 기법에 대해 살펴보도록 하겠습니다.  ### 모델 크기 줄이기 가장 간단한 방법입니다. 레이어나 뉴런 등 학습해야할 파라메터의 개수를 줄여서 과적합을 방지합니다.  ### early stopping 학습을 일찍 중단하는 방식으로 과적합을 방지합니다.  ### 가중치 감소 과적합은 학습 파라메터의 값이 커서 발생하는 경우가 많다고 합니다. **가중치 감소(weight decay)**는 이를 방지하기 위해 학습 파라메터의 값이 크면 그에 상응하는 큰 패널티를 부여하는 기법입니다.  **1) L2 Regularization** : 가장 일반적인 regulization 기법입니다. 기존 손실함수($L_{old}$)에 모든 학습파라메터의 제곱을 더한 식을 새로운 손실함수로 씁니다. 아래 식과 같습니다. 여기에서 $1/2$이 붙은 것은 미분 편의성을 고려한 것이고, $λ$는 패널티의 세기를 결정하는 사용자 지정 하이퍼파라메터입니다. 이 기법은 큰 값이 많이 존재하는 가중치에 제약을 주고, 가중치 값을 가능한 널리 퍼지도록 하는 효과를 냅니다. $$W=\begin{bmatrix} { w }_{ 1 } & { w }_{ 2 } & ... & { w }_{ n } \end{bmatrix}\\ { L }_{ new }={ L }_{ old }+\frac { \lambda }{ 2 } { (w }_{ 1 }^{ 2 }+{ w }_{ 2 }^{ 2 }+...+{ w }_{ n }^{ 2 })$$ **2) L1 Regulazation** : 기존 손실함수에 학습파라메터의 절대값을 더해 적용합니다. 이 기법은 학습파라메터를 **sparse**하게(거의 0에 가깝게) 만드는 특성이 있습니다.  $${ L }_{ new }={ L }_{ old }+\lambda (\left| { w }_{ 1 } \right| +\left| { w }_{ 2 } \right| +...+\left| { w }_{ n } \right| )$$ **3) L1 + L2 **: 물론 두 기법을 동시에 사용할 수도 있습니다.  $${ L }_{ new }={ L }_{ old }+\frac { { \lambda }_{ 1 } }{ 2 } { W }^{ T }W+{ \lambda }_{ 2 }(\left| { w }_{ 1 } \right| +\left| { w }_{ 2 } \right| +...+\left| { w }_{ n } \right| )$$  ### Dropout **드롭아웃**은 일부 뉴런을 꺼서 학습하는 방법입니다. 일종의 **앙상블(ensemble)** 효과를 낸다고 합니다. 학습시에는 삭제할 뉴런을 무작위로 끄고, 테스트할 때 모든 뉴런을 씁니다.  ## 기타 학습 기법들 기타 기법들을 소개합니다.  ### 학습률 감소 학습률(learining rate)은 아래 그림처럼 학습 과정에 중요한 역할을 차지합니다. 지나치게 크면 발산하여 올바른 학습을 할 수 없고, 작으면 학습시간이 너무 길어집니다. <a href="http://imgur.com/qJ5sm14"><img src="http://i.imgur.com/qJ5sm14.jpg" width="300px" title="source: imgur.com" /></a> 학습 시작부터 종료시까지 학습률을 고정한 채로 학습을 시킬 수도 있지만 학습이 거듭될 수록 해당 모델이 최적 지점에 수렴하게 될 것이므로 막바지에는 학습률을 작게 해 파라메터를 미세 조정하는 것이 좋을 것입니다. 학습률 감소 기법은 이 때문에 제안됐는데요, 각각 아래와 같습니다. 여기에서 $η$는 학습률, $t$는 스텝 수이며 $k$는 사용자가 지정하는 하이퍼파라메터입니다. **step decay** : 스텝마다 일정한 양만큼 학습률을 줄이는 기법입니다. 5epoch마다 반으로 줄이거나 20epoch마다 1/10씩 줄이는 방법이 많이 쓰이지만, 데이터나 네트워크 구조에 따라 일률적으로 적용하기는 어렵습니다. **exponential decay** : $η=η_0e^{-kt}$ **$1/t$ decay** : $η=η_0/(1+kt)$   ### 하이퍼파라메터 최적화 하이퍼파라메터는 사용자가 지정해줘야 하는 값으로 어떤 값이 최적인지는 미리 알기 어렵습니다. 데이터나 모델 구조마다 달라지기도 하고요. 최적의 하이퍼파라메터를 찾기 위한 일반적인 절차는 아래와 같습니다. - 1단계 : 하이퍼파라메터 값의 범위를 설정한다 - 2단계 : 설정된 범위에서 하이퍼파라메터의 값을 무작위로 추출한다 - 3단계 : 샘플링한 하이퍼파라메터 값을 사용해 학습하고, 검증 데이터로 정확도를 평가한다 (단, 에폭은 작게 설정) - 2단계와 3단계를 반복하고, 그 결과를 보고 하이퍼파라메터 탐색 범위를 좁힌다    ### Multi-Task Learning **Multi-Task Learing**이란 여러 학습 과제를 동시에 해결하는 기계학습의 한 종류입니다. 예컨대 같은 학습말뭉치로 **개체명인식(Named Entity Recognition)**과 **품사분류(Part-Of-Speech Tagging)**를 동시에 수행하는 뉴럴네트워크를 만들 수 있습니다. 아래 그림을 먼저 볼까요? <a href="http://imgur.com/bvAKXL6"><img src="http://i.imgur.com/bvAKXL6.png" width="500px" title="source: imgur.com" /></a> 위 그림의 두 네트워크는 마지막에 붙어있는 **소프트맥스 계층(Softmax layer)**만 제외하면 완전히 동일합니다. 다만 $S_1$의 소프트맥스 확률값은 NER, $S_2$는 포스태깅 과제를 수행하면서 나오는 스코어라는 점에 유의할 필요가 있습니다. 위와 같은 Multi-Task Learining 네트워크에서는 아래 수식처럼 역전파시 $S_1$의 그래디언트와 $S_2$의 그래디언트가 동일한 네트워크에 함께 전달되면서 학습이 이뤄지게 됩니다.  $${ \delta }^{ total }={ \delta }^{ NER }+{ \delta }^{ POS }$$
nounontology␞ 이번 글에서는 국립국어원에서 만든 표준국어대사전의 명사 분류 체계에 대해 살펴보도록 하겠습니다. 자료는 [국립국어원 언어정보나눔터](https://ithub.korean.go.kr/)에서 내려받아 제 나름대로 정리한 것임을 밝힙니다. 그럼 시작하겠습니다.  ## 개요 및 대분류 표준국어대사전 명사 분류 체계는 0~7단계로 나뉩니다. 대분류에 해당하는 0~1단계는 다음과 같습니다. **온** (0단계) : 전부, 모두 - 구체물 (1단계) - 집단 (1단계) - 장소 (1단계) - 추상적 대상 (1단계) - 사태 (1단계)  이번 글에서는 구체물, 집단, 장소를 포괄합니다. 목차는 다음과 같습니다.  * 목차 {:toc}  ## 구체물 **구체물**이란 시공간적 延長(extension)을 가지며 감각기관을 통해 지각될 수 있는 대상을 가리킵니다. 하위 범주(2단계)로는 구체자연물, 구체인공물, 속성구체물, 관계구체물 네 가지가 있습니다. 구체물로 분류된 명사는 다음과 같습니다. <p class="message"> 가닥, 가루, 기름띠, 꽃다발, 내용물(內容物), 대통(_桶), 도관(導管), 만물(萬物), 먹이, 무생물체(無生物體), 물자(物資), 물질(物質), 물체(物體), 복합체(複合體), 여의주(如意珠) </p> ### 구체자연물 **구체자연물**이란 자연상태에서 존재하는 구체물을 가리킵니다. <p class="message"> 거미줄, 디엔에이(DNA), 목석(木石), 삼라만상(森羅萬象), 알, 암석(巖石), 암초(暗礁), 앙금, 약물(藥_), 영양(營養), 인슐린(insulin), 작대기, 천연생산물(天然生産物), 풍월(風月), 황금물결(黃金__) </p> #### 무생물 무생물로 분류된 명사는 다음과 같습니다. <p class="message"> 갯바위, 검댕, 검불, 고드름, 고리화합물(__化合物), 고치, 과당(果糖), 광명단(光明丹), 광자(光子), 굴개(窟_), 규산(硅酸), 규소(硅素), 그을음, 글리코겐(glycogen), 기름기(__氣), 기암절벽(奇巖絶壁), 기포(氣泡), 나트륨(Natrium), 낙엽(落葉), 녹, 누에고치, 니코틴(nicotine), 단구퇴적물(段丘堆積物), 단백질(蛋白質), 더께, 독소(毒素), 마그마(magma), 매흙모래, 맹독(猛毒), 먼지, 모래, 모래알, 모래진흙, 무기물(無機物), 무수규산(無水珪酸), 바위, 방사능(放射能), 방사선(放射線), 배양토(培養土), 벌집, 병풍바위(屛風__), 복화합물(複化合物), 부엽토(腐葉土), 분자(分子), 분토(墳土), 불포화지방산(不飽和脂肪酸), 붕산(硼酸), 붕소(硼素), 비타민(vitamin), 빙산(氷山), 빙설(氷雪), 뻘, 사마귀알집, 사물(事物), 삼단, 석주(石柱), 섬유질(纖維質), 수산화나트륨(水酸化___), 수소수용체(水素受容體), 스테로이드(steroid), 실리콘(silicon), 쑥돌찰흙, 아데노신(adenosine), 아드레날린(adrenaline), 알루미늄(aluminum), 알칼리(alkali), 암반(巖盤), 앙금흙, 양간수(洋_水), 얼음, 얼음덩이, 얼음판, 에스트로겐(estrogen), 열원자핵(熱原子核), 염류(鹽類), 염분(鹽分), 영양분(營養分), 우두(牛痘), 우라늄(uranium), 우지(牛脂), 원목(原木), 원소(元素), 원자(原子), 위산(胃酸), 이온(ion), 인산(燐酸), 재, 점토(粘土), 정살여, 중성자(中性子), 지각(地殼), 지푸라기, 진토(塵土), 진흙, 차돌모래, 천연자원(天然資源), 치석(齒石), 카로틴(carotin), 카페인(caffeine), 칼륨(kalium), 칼슘(calcium), 콜레스테롤(cholesterol), 탄소(炭素), 토사(土砂), 토석(土石), 토양(土壤), 티, 티끌, 페놀(phenol), 펩톤(peptone), 포말(泡沫), 플루토늄(plutonium), 할로겐(halogen), 핵산(核酸), 햇볕, 햇빛, 햇살, 헤모글로빈(hemoglobin), 혈구(血球), 혈당(血糖), 홍두깨흙, 환경호르몬(環境___), 황사(黃砂|黃沙), 황산구리(黃酸__), 황토(黃土), 흑토(黑土), 흙, 흙더미, 흙덩이 </p> 천체 : 우주에 존재하는 별 <p class="message"> 거문고자리유성군(_____流星群), 거성(巨星), 금성(金星), 남녀궁(男女宮), 남쪽물고기자리(南______), 늑대별, 달, 만월(滿月), 망원경자리(望遠鏡__), 명왕성, 목성(木星), 바깥떠돌이별, 별, 별자리, 보병궁(寶甁宮), 북두칠성(北斗七星), 사냥개자리, 사냥개좌(___座), 사자자리유성군(獅子__流星群), 상하현(上下弦), 새벽달, 샛별, 성운(星雲), 성좌(星座), 소사자좌(小獅子座), 수성(水星), 유성(流星), 은하(銀河), 은하계별구름(銀河系___), 은하수(銀河水), 일월광(日月光), 일월성수(日月星宿), 일월성신(日月星辰), 재백궁(財帛宮), 지구(地球), 천왕성(天王星), 천체(天體), 초승달(初生_), 초신성(超新星), 초저녁달(初___), 칠성(七星), 큰곰별, 태양(太陽), 태음(太陰), 토성(土星), 한울, 항성(恒星), 해, 해왕성(海王星), 햇덩이, 행성(行星), 혜성(彗星), 혹성(惑星), 화가자리(畵架__), 화성(火星), 흑점(黑點) </p> 광물 : 땅속에서 캐내는 물질 <p class="message"> 게르마늄, 고대현무암(高臺玄武岩), 고령토(高嶺土), 곱돌, 광물(鑛物), 광석(鑛石), 광석광물(鑛石鑛物), 괴석(怪石), 구리, 규석(硅石), 금(金), 금광석(金鑛石), 금빛돌비늘(金____), 금은(金銀), 기암(奇巖), 기암괴석(奇巖怪石), 납, 납덩이, 노다지, 놋, 니켈(nickel), 다이아(diamond), 다이아몬드(diamond), 단사(丹沙), 대리석(大理石), 돌, 돌멩이, 돌비늘편마암(___片麻巖), 라듐(radium), 루비(ruby), 마그네슘(magnesium), 마노(瑪瑙), 망간(Mangan), 몰리브덴(Molybd_n), 무쇠, 미네랄(mineral), 바다모래, 바닥자갈돌, 반석(盤石), 백금(白金), 변쑥돌(變__), 보석(寶石), 비취(翡翠), 사금(沙金), 사암(沙巖), 사파이어(sapphire), 산호석회암(珊瑚石灰巖), 석고(石膏), 석면(石綿), 석순(石筍), 석영(石英), 석탄(石炭), 석회암(石灰巖), 쇠, 쇳덩이, 수정(水晶), 순금(純金), 슬레이트(slate), 아연(亞鉛), 안문탄(眼紋炭), 에머럴드(emerald), 에메랄드(emerald), 연강철(軟鋼鐵), 염소산가리(鹽素酸加里), 염소산나트륨(鹽素酸___), 염소산소다(鹽素酸__), 염소산칼륨(鹽素酸__), 옥(玉), 옥석(玉石), 운석(隕石), 원생광물(原生鑛物), 원석(原石), 유황(硫黃), 은(銀), 이산화망간(二酸化__), 자갈, 자석(磁石), 잡석(雜石), 장석(長石), 조각돌, 주철(鑄鐵), 중금속(重金屬), 중석(重石), 지하자원(地下資源), 진주(眞珠), 철광(鐵鑛), 철광석(鐵鑛石), 코발트(cobalt), 탄(炭), 텅스텐(tungsten), 편마암(片麻巖), 홈통바위(_桶__), 화강석(花剛石), 화강암(花崗岩), 화석(化石), 화성광물(火成鑛物), 활석(滑石), 황금(黃金), 황동, 흑연(黑鉛) </p> 기상관련물 : 기상현상이 발생할 때 대기 중에 존재하는 물질 <p class="message"> 꽃비, 눈송이, 달먼지, 백설(白雪), 번갯불, 비구름, 빗물, 빗방울, 서리, 서릿발, 성에, 악수, 이슬, 해빙(海氷) </p> 기체 : 상온에서 기체 상태로 존재하는 물질 <p class="message"> 가스(gas), 공기(空氣), 기체(氣體), 네온(neon), 매연(煤煙), 메탄(methane), 목가스(木__), 배출가스(排出__), 부탄(butane), 불소(弗素), 비화수소(砒化水素), 산소(酸素), 수소(水素), 수소가스(水素__), 수증기(水蒸氣), 아산화질소(亞酸化窒素), 아황산가스(亞黃酸__), 암모니아(ammonia), 압축공기(壓縮空氣), 에틸렌(ethylene), 연탄가스(煉炭__), 오존(ozone), 온실가스(溫室__), 유독가스(有毒__), 이산화탄소(二酸化炭素), 입김, 증기(蒸氣), 질소(窒素), 질소산화물(窒素酸化物), 탄산가스(炭酸__), 탄산수소(炭酸水素), 프레온(freon), 헬륨(helium), 활성수소(活性水素) </p> 액체 : 상온에서 액체 상태로 존재하는 물질 <p class="message"> 강물(江_), 개수, 격류(激流), 경수(輕水), 곱, 글리세린(glycerin), 낙수(落水), 냉각수(冷却水), 냉수(冷水), 눈물, 눈물방울, 담수(淡水), 동물성유(動物性油), 동물유지(動物油脂), 동백기름(冬栢__), 땔감기름, 뜨물, 림프(lymph), 링거(Ringer), 링거액(Ringer_), 망간산(Mangan_), 맹물, 메탄올(methanol), 물, 물기(_氣), 물방울, 민물, 바닷물, 벤젠(benzene), 빙수(氷水), 샘물, 생수(生水), 석유(石油), 성수(聖水), 성유(聖油), 소발기름, 쇠뼈기름, 수분(水分), 수은(水銀), 시약(試藥), 식은땀, 아세톤(acetone), 알코올(alcohol), 액체(液體), 양수(羊水), 양잿물(洋__), 에탄올(ether), 염산(鹽酸), 오수(汚水), 오일(oil), 온수(溫水), 온천(溫泉), 용매(溶媒), 용수(用水), 용암(鎔巖), 용액(溶液), 원유(原油), 위액(胃液), 유분(油分), 유체(流體), 유혈(流血), 이슬방울, 일시센물(一時__), 잿물, 저장액(低張液), 점액(粘液), 정수(淨水), 정유(精油), 젖, 중류(中流), 중질원유(重質原油), 즙(汁), 지하수(地下水), 진(津), 진물(津_), 질산(窒酸), 짠물, 찬물, 체액(體液), 초성포도산(焦性葡萄酸), 타르(tar), 탁류(濁流), 탄산(炭酸), 포르말린(Formalin), 피, 한류(寒流), 해수(海水), 허드렛물, 혈청(血淸), 황산(黃酸), 휘발유(揮發油), 흙탕물(_湯_) </p> 배설물 : 생물체가 배설하는 물질 <p class="message"> 가래, 대변(大便), 대소변(大小便), 똥, 변(便), 분뇨(糞尿), 소변(小便), 소피(小避), 쇠똥, 오줌, 오줌똥, 인분(人糞), 진땀, 태변(胎便), 피똥, 혈뇨(血尿) </p> 분비물 <p class="message"> 객혈(喀血), 게거품, 군침, 담즙(膽汁), 당밀(糖蜜), 땀, 멜라닌(melanin), 모유(母乳), 밥통호르몬(_桶___), 분비물(分泌物), 성호르몬(性___), 소화효소(消化酵素), 송진(松津), 신물, 쌍코피(雙__), 쓸개즙(__汁), 에피네프린(epinephrine), 엔도르핀(endorphine), 침, 코피, 콧물, 타액(唾液), 페로몬(pheromone), 피고름, 피지(皮脂), 혈담(血痰), 호르몬(hormone) </p>  #### 생물 생물로 분류된 명사는 다음과 같습니다. <p class="message"> 고생물(古生物), 동식물(動植物), 배아(胚芽), 생명체(生命體), 생물(生物), 유기물(有機物), 유기체(有機體), 유독생물(有毒生物), 토템(totem), 화조(花鳥) </p> 식물 식물로 분류된 명사는 다음과 같습니다. <p class="message"> 가시덤불, 겨자, 구름골풀, 굴참나무, 나뭇잎, 녹두(綠豆), 농작물(農作物), 느타리버섯, 다시마, 덤불, 도토리, 메밀, 면화(綿花), 모종, 밀, 바닷가식물(___植物), 박하(薄荷), 밤송이, 버들까치수염(____鬚髥), 별꽃풀, 볏가리, 보리농구, 분재(盆栽), 분홍바늘꽃(粉紅___), 삼수개미자리(三水____), 삿갓버섯, 상추, 새싹, 석이(石耳), 선녀고사리(仙女___), 선바위고사리, 선인장(仙人掌), 솔이끼식물(___植物), 수세기오이, 시금치, 식물(植物), 신선손바닥(神仙___), 싸리, 야생식물(野生植物), 야채, 약초(藥草), 양란(洋蘭), 옥수수, 은빛담쟁이덩굴(銀______), 이끼, 인동덩굴(忍冬__), 잎줄기채소(___菜蔬), 작물(作物), 장고새, 정물(靜物), 줄기식물(__植物), 줄기채소(__菜蔬), 지부배추(芝?__), 참외, 채소(菜蔬), 춘란(春蘭), 코스모스(cosmos), 콩나물, 탄수화물(炭水化物), 파래, 팥, 포도덩굴(葡萄__), 표고, 표고버섯, 해초(海草), 해태(海苔), 화초(花草), 화훼(花卉) </p> (1) 나무 <p class="message"> 가나무(　__), 가로수(街路樹), 가문비나무, 감나무, 개머루덩굴, 고목(古木), 고송(古松), 과수(果樹), 관목(灌木), 길가나무, 까마귀머루, 꼬리겨우살이, 나무, 낙엽송(落葉松), 남해배나무(南海___), 노송(老松), 느티나무, 능수버들, 단풍나무(丹楓__), 담쟁이, 담쟁이덩굴, 당단풍나무(唐丹楓__), 대, 대나무, 덤불오리나무, 돌감람나무(_橄欖__), 동백(冬柏), 동백나무겨우살이(冬栢______), 들배나무, 떡갈나무, 떡느릅나무, 라일락(lilac), 매화(梅花), 머루, 먹감나무, 모란(牧丹), 목면(木綿), 묘목(苗木), 무궁화(無窮花), 미루나무, 미역줄나무, 밤나무, 배나무, 백동백나무(白冬柏__), 버드나무, 버들, 보리수(菩提樹), 복사앵두나무(__櫻桃__), 뽕나무겨우살이, 뽕잎피나무, 서낭, 설탕단풍(雪糖丹風), 섬나무딸기, 소나무, 솔, 송백(松柏), 수목(樹木), 신도복숭아, 야자(椰子), 여름귤(__橘), 여름귤나무(__橘__), 연꽃진달래(蓮____), 오동(梧桐), 오동나무(梧桐__), 오리나무, 올리브(olive), 유실수(有實樹), 은행나무(銀杏__), 인가목(__木), 인도고무나무(印度____), 자연림(自然林), 자작나무, 잡목(雜木), 장구밤나무, 장미(薔薇), 재목(材木), 진달래, 찔레, 참나무, 철쭉, 초목(草木), 카카오, 통나무, 포플러(poplar), 플라타너스(platanus), 혹느릅나무 </p> (2) 풀 <p class="message"> 갈대, 강낭콩, 강모(강모), 강재(江材), 개고사리, 개구리때, 개연(_蓮), 검바늘골, 고들빼기, 고비나물, 고사리, 골개고사리, 곰비늘고사리, 구리때뿌리, 귀리, 그늘개고사리, 금강아지풀(金____), 까치수영, 꽈리, 난(蘭), 난초(蘭草), 날개골, 날개골풀, 노랑개자리, 논냉이, 눈빛승마(__升麻), 단풍잎돼지풀(丹楓____), 담배, 담장넝쿨(_墻__), 당개나리(唐___), 대구돌나물(大邱___), 대국밀, 대마(大麻), 댕댕이덩굴, 덩굴며느리주머니, 도깨비바늘, 두메기름나물, 들개미자리, 등골나물, 땅딸기, 땅콩, 만병초(萬病草), 맨드라미, 메기장, 며느리밥풀, 며느리배꼽, 명아주, 모, 모기쑥, 목건초(牧乾草), 목초(牧草), 물감풀, 물개구리밥, 물까치수염(___鬚髥), 미나리냉이, 민들레, 바닐라(vanilla), 바위돌꽃, 박, 백일홍(百日紅), 백합(百合), 벼, 보리, 봉선화(鳳仙花), 부추, 비녀골풀, 사탕수수(砂糖__), 산갈퀴(山__), 삼, 삿갓들이, 선괭이눈, 섬광대수염(_鬚髥__), 섬꿩고사리, 소경불알, 손바닥난초(___蘭草), 솔체꽃, 솜바늘꽃, 쇠돌피, 수레국화(__菊花), 수수, 수정란풀(水晶蘭_), 수초(水草), 시계꽃(時計_), 쑥, 쑥갓, 씨눈난초(__蘭草), 아마(亞麻), 아주까리, 애기고추나물, 애기괭이눈, 애기괭이밥, 억새, 엉겅퀴, 여우꼬리, 열무, 완두(豌豆), 왜젓가락풀(倭___), 우단꼬리풀(羽緞___), 육지괭이눈(陸地___), 율무, 익모초(益母草), 자주개자리(紫朱___), 자주만년초(紫朱萬年草), 작약(芍藥), 잔디, 잡초(雜草), 제주괭이눈(濟洲___), 좀개구리밥, 좀미역고사리, 좁쌀냉이, 진주고추나물(晉注____), 질경이, 참깨, 창포(菖蒲), 천궁(川芎), 청초(靑草), 클로버(clover), 토란(土卵), 톳, 튤립(tulip), 파, 파초(芭蕉), 파피루스(papyrus), 팬지(pansy), 풀, 풀잎, 향초(香草), 홀아비꽃대, 황기(黃蓍) </p> (3) 곰팡이 <p class="message"> 곰팡이, 국곰팡이(麴___), 자루곰팡이 </p> (4) 꽃 <p class="message"> 갈꽃, 개나리, 고깔제비꽃, 과꽃, 국화(國花), 금강제비꽃(金剛___), 꽃, 꽃송이, 낙화(落花), 노랑매미꽃, 들국화(_菊花), 만주바람꽃(滿洲___), 메밀꽃, 목련(木蓮), 뫼제비꽃, 버들강아지, 벚꽃, 베고니아(begonia), 봉숭아, 부용(芙蓉), 붓꽃, 산화(山花), 살구꽃, 생화(生花), 석죽(石竹), 수국(水菊), 아네모네(anemone), 아욱제비꽃, 아카시아(acacia), 에델바이스(edelweiss), 연꽃(蓮_), 외대바람꽃, 장미꽃(薔薇_), 장미화(薔薇花), 제라늄(geranium), 조화(弔花), 진달래꽃, 채송화(菜松花), 철쭉꽃, 춘화(春花), 카네이션(carnation), 칸나, 타래붓꽃, 패랭이, 해바라기, 해안메꽃(海岸__), 화단나팔꽃(花壇喇叭_) </p> (5) 열매 <p class="message"> 감귤(柑橘), 개암, 견과(堅果), 결명자(決明子), 고구마, 고추, 골감, 깍정이, 깨알, 능금, 다래, 담해열매, 대추, 매실(梅實), 모과, 목화(木花), 무수감자, 무화과(無花果), 밀감(蜜柑), 버찌, 복숭아, 사과(沙果), 상수리, 석류(石榴), 앵두, 오디, 오이, 유자(柚子), 차나락, 체리(cherry), 치자(梔子), 코코넛(coconut), 콩, 탱자, 토마토(tomato), 풋고추, 피망(piment), 호박, 홍시(紅枾) </p> (6) 뿌리 <p class="message"> 마, 무우, 산삼(山蔘), 연근(蓮根), 인삼(人蔘), 장뇌(長腦), 탈바꿈뿌리, 편(片), 풀뿌리, 홍당무(紅唐_), 홍삼(紅蔘) </p> 동물 동물로 분류된 명사는 다음과 같습니다. <p class="message"> 가재, 가축(家畜), 개구리, 거미, 거북, 거북이, 게, 고래, 공룡(恐龍), 구관조(九官鳥), 굿닭, 귀가오리, 금개구리(金___), 금수(禽獸), 기관동물(氣管動物), 낙지, 달팽이, 동물(動物), 등뼈동물(__動物), 말미잘, 멍게, 물개, 미물(微物), 바다꽃봉오리, 바다나리, 박쥐, 불가사리, 산호(珊瑚), 새앙쥐, 수놈, 수달(水獺), 수컷, 씨수컷, 악어(鰐魚), 안경뱀(眼鏡_), 암놈, 암수, 암컷, 애완동물(愛玩動物), 야생동물(野生動物), 어룡(漁龍), 어조(漁鳥), 연체동물(軟體動物), 오징어, 올챙이, 왕새우(王__), 자웅(雌雄), 전복(全鰒), 집게게, 청개구리(靑___), 카멜레온(chameleon), 파충류(爬蟲類), 편충(鞭蟲), 플라나리아(planaria), 해룡(海龍), 해백합(海百合), 해파리, 히드라(hydra) </p> (1) 짐승 : 육지에서 사는 날지 못하는 동물 <p class="message"> 강아지, 개, 개발사슴, 고라니, 고려뒤쥐(高麗__), 고리눈말, 고릴라(gorilla), 고슴도치, 고양이, 곰, 구렁이, 군견(軍犬), 군마(軍馬), 기린(麒麟), 나귀, 낙타(駱駝), 날다람쥐, 너구리, 노루, 노새, 누렁이, 늑대, 다람쥐, 담비, 당나귀, 대륙멧돼지(大陸___), 도둑고양이, 도롱뇽, 도마뱀, 독사(毒蛇), 돔뱀, 돼지, 두꺼비, 두더지, 둘암말, 둘암소, 들소, 마소, 망아지, 맹견(猛犬), 맹수(猛獸), 맹호(猛虎), 머루다람쥐, 멧돼지, 명견(名犬), 명마(名馬), 무소, 물소, 밍크(mink), 바둑이, 발바리, 발톱도롱뇽, 백마(白馬), 백호(白虎), 뱀, 범, 불도그(bulldog), 불독(bulldog), 사슴, 사자(獅子), 사향뒤쥐(麝香__), 산양(山羊), 산토끼(山__), 삽사리, 생쥐, 송아지, 스컹크(skunk), 승냥이, 씨수말, 씨암양(__羊), 안경원숭이(眼鏡___), 암구렁이, 암노루, 암소, 애견(愛犬), 야생마(野生馬), 야수(野獸), 양(羊), 얼룩송아지, 여우, 염소, 오리주둥이, 우마(牛馬), 원숭이, 인도들소(印度__), 자라, 잔나비, 재규어(jaguar), 적토마(赤兎馬), 젖소, 족제비, 종마(種馬), 준마(駿馬), 준족(駿足), 쥐, 짐승, 초식동물(草食動物), 충견(忠犬), 침팬지(chimpanzee), 캥거루(kangaroo), 코끼리, 코브라(cobra), 큰곰, 토끼, 튀기, 트기, 팬더(panda), 표범(豹_), 퓨마(puma), 하룻강아지, 하마(河馬), 하이에나(hyena), 한우(韓牛), 호랑이(虎狼_), 화사(花蛇), 황소(黃_) </p> (2) 물고기 : 물(시내, 강, 바다)에서 사는 동물 <p class="message"> 가리, 가물치, 가오리, 가자미, 갈치, 강고기(江__), 강담돔, 고등어, 광어(廣魚), 금붕어(金__), 금줄촉수(金_觸鬚), 꼴뚜기, 꽁치, 날가지숭어(___秀魚), 넙치, 농어, 다랑어(__魚), 대구(大口), 대어(大魚), 도루묵, 도미, 돌고래, 돔, 돛물뱀, 등줄숭어(__秀魚), 망둥이, 메기, 멸치, 명태(明太), 모래주사, 문광어(紋廣魚), 물고기, 물꽃치, 미꾸라지, 민어(民漁), 밴댕이, 뱀장어(_長魚), 뱅어, 별넙치, 병어, 복어(_漁), 부세(富世), 붕어, 빙어, 산갈치(山__), 삼치, 상어, 새물청어(__靑魚), 새우, 송사리, 송어(松魚), 수염대구(鬚髥大口), 숭어, 쏘가리, 연어(_魚), 월척(越尺), 은구어(銀口魚), 인도멸치(印度__), 잉어, 자갈치, 장어(長魚), 전어(錢魚), 젓뱅어, 정어리, 조기, 쭈꾸미, 참치, 청어(靑魚), 치어(稚魚), 칼치, 팔목장어(八目長魚), 피라미, 피래미, 해마(海馬), 해삼(海蔘), 향어(香魚), 호박씨붕어 </p> (3) 새 : 날개 있는 척추 동물 <p class="message"> 가금(家禽), 가마우지, 갈매기, 거위, 고니, 곽새, 곽쥐, 괭이갈매기, 기러기, 까마귀, 까치, 까투리, 꾀꼬리, 꿩, 노고지리, 닭, 닭구리, 독수리, 되때까치, 두견(杜鵑), 두견이(杜鵑_), 두루미, 따오기, 딱따구리, 때까치, 뜸부기, 매, 맹금(猛禽), 메추라기, 메추리, 물새, 백로(白鷺), 백조(白鳥), 백학(白鶴), 병아리, 보라매, 부엉이, 비둘기, 뻐꾸기, 산갈가마귀(山____), 새, 소쩍새, 솔개, 송골매(松<U+9DBB>_), 수리, 수탉, 쑥국새, 암탉, 앵무새(鸚鵡_), 약병아리(藥___), 오골계(烏骨鷄), 오리, 올빼미, 왜가리, 원앙(鴛鴦), 잉꼬(inko), 장끼, 장닭, 재갈매기, 제비, 제비갈매기, 제주굴뚝새(濟洲___), 조류(鳥類), 종다리, 종달새, 찌르레기, 참새, 철새, 청둥오리, 촌닭(村_), 칠면조(七面鳥), 카나리아, 크낙새, 타조(駝鳥), 텃새, 펭귄(penguin), 학(鶴), 해오라기, 해조(海鳥), 혹부리오리, 홍학(紅鶴), 황새, 황제펭귄(黃帝__) </p> (4) 패류 <p class="message"> 개시맛, 골방조개(_房__), 꼬막, 다슬기, 닭게, 대합(大蛤), 바지락, 성게, 소라, 우렁이, 조가비, 조개, 조개류(__類), 패류(貝類), 홍합(紅蛤) </p> (5) 벌레 <p class="message"> 강변메뚜기(江邊___), 개미, 개밥도둑, 거머리, 고치물자리, 곤봉딱정벌레(棍棒____), 곤충(昆蟲), 광대불나방, 굼벵이, 귀뚜라미, 까마귀밤나방, 꼬마불나방, 꿀벌, 나무굼벵이, 나방, 나방파리, 나부, 나비, 노랑나비, 노래기, 노랭이, 노린재, 뇌염모기(腦炎__), 누에, 누에나비, 담배밤나방, 도둑벌레, 독개미(毒__), 독나비(毒__), 독충(毒蟲), 등불베짱이(燈____), 등불여치(燈___), 등에, 등에잎벌, 등줄모기, 딱정벌레, 띠호박벌, 말똥구리, 매미, 메뚜기, 멧돼지거미, 멸구, 모기, 모래무지거저리, 무늬말벌, 물결나비, 물고기진드기, 바퀴, 바퀴벌레, 반디, 반딧불이, 밤나무벌레, 밤색하루살이(_色____), 방아깨비, 배추흰나비, 백랍벌레(白蠟__), 백랍충(白蠟蟲), 버러지, 버마재비, 번개매미, 번데기, 벌, 벌레, 벙어리매미, 베짱이, 벼룩, 불개미거미, 빈대, 살빛고치, 서캐, 성충(成蟲), 소금당세, 소금쟁이, 소나무자치, 송충이(松蟲_), 쇠똥구리, 수염송곳벌(鬚髥___), 신부나비(新婦__), 쓰르라미, 애벌레, 여왕개미(女王__), 여치, 오리나무바구미, 왕귀뚜라미, 왕땅개, 왕물매미, 왕사마귀(王___), 유지매미(油脂__), 유충(幼蟲), 은줄표범나비(銀_豹___), 일꾼개미, 전갈(全蝎), 전나무창벌(___槍_), 점불나방(點___), 정도충(釘倒蟲), 조롱박벌, 줄무늬물방개, 지네, 지렁이, 진드기, 진디, 처녀왕(處女王), 파리, 포플러잎벌(poplar__), 표범나비(豹___), 풍뎅이, 하늘밥도둑, 해충(害蟲), 호랑나비, 회색밤나방(灰色___), 회충(蛔蟲) </p> (6) 관계동물 <p class="message"> 천적(天敵) </p> (7) 상상적동물 : 실제로는 존재하지 않는 동물 <p class="message"> 괴물(怪物), 괴수(怪獸), 구미여우(九尾__), 구미호(九尾狐), 봉황(鳳凰), 불사조(不死鳥), 용(龍), 청룡(靑龍), 황룡(黃龍) </p> 미생물 <p class="message"> 균(菌), 나균(癩菌), 독균(毒菌), 디스토마(distoma), 면역체(免疫體), 미생물(微生物), 바이러스(virus), 박테리아(bacteria), 병균(病菌), 병원균(病原菌), 분해자(分解者), 세균(細菌), 수소세균(水素細菌), 식초산균(食醋酸菌), 아메바(amoeba), 이스트(yeast), 잡균(雜菌), 조직기생충(組織寄生蟲), 좀, 촌충(寸蟲), 큰창자균(___菌), 플랑크톤(plankton), 항원(抗原), 화농균(化膿菌), 효모(酵母), 효소(酵素) </p> 관계생물 <p class="message"> 수성배우자(_性配偶子), 수정란(受精卵) </p> 인간 <p class="message"> 개개인(個個人), 개인(個人), 고객(顧客), 남녀노소(男女老少), 단골, 동일인물(同一人物), 등장인물(登場人物), 만민(萬民), 멤버(member), 사람, 여러분, 인(人), 인간(人間), 인류(人類), 인물(人物), 인체(人體), 향락업주(享樂業主), 헤르츠(hertz), 현세대(現世代) </p> (1) 관계인간 : 특정 인간과의 관계에 의해서 정해지는 인간 <p class="message"> 가부장(家父長), 각시, 강적(强敵), 고용자(雇傭者), 구성원(構成員), 군식구(_食口), 남매(男妹), 노동조합원(勞動組合員), 반려(伴侶), 본인(本人), 부모님(父母_), 분신(分身), 빽(back), 삼족(三族), 아류(亞流), 양자(兩者), 유가족(遺家族), 이종(姨從), 이해관계자(利害關係者), 이해당사자(利害當事者), 인척(姻戚), 일반인(一般人), 일행(一行), 장본인(張本人), 적(敵), 적대세력(敵對勢力), 적수(敵手), 적장(敵將), 전관(前官), 전실(前室), 종씨(宗氏), 종친(宗親), 주체(主體), 척(戚), 친권자(親權者), 피붙이, 피해자(被害者), 학부형(學父兄), 혈연(血緣), 호주(戶主), 후원자(後援者), 후인(後人) </p> 가. 대칭적 관계인간 <p class="message"> 겹사돈(_査頓), 고우(故友), 글벗, 급우(級友), 난적(難敵), 노사(勞使), 동갑내기(同甲__), 동년배(同年輩), 동료(同僚), 동료교수(同僚敎授), 동무, 동민(洞民), 동지(同志), 동창(同窓), 동행중(同行衆), 라이벌(rival), 배우자(配偶者), 벗, 붕우(朋友), 살친구(_親舊), 소꿉동무, 소꿉친구(__親舊), 앙숙(怏宿), 애인(愛人), 연인(戀人), 우인(友人), 의자매(義姉妹), 이웃사람, 입사동기(入社同期), 전우(戰友), 주말부부(週末夫婦), 죽마고우(竹馬故友), 직장동료(職場同僚), 짝, 짝꿍, 친구(親舊), 친우(親友), 친지(親知), 커플(couple), 콤비(combination), 파트너(partner), 피차(彼此), 학우(學友), 학형(學兄), 할멈, 향우(鄕友) </p> - 대칭적 친족 <p class="message"> 고부(姑婦), 근친(近親), 동서(同壻), 맏동서(_同壻), 맏매부(_妹夫), 배필(配匹), 본남편(本男便), 부부(夫婦), 부자(父子), 붙이, 사촌(四寸), 안팎식구(__食口), 오누이, 외사촌(外四寸), 이모형제(異母兄弟), 이복형제(異腹兄弟), 이종사촌(姨從四寸), 자매(姉妹), 친족(親族), 친척(親戚), 형제(兄弟), 형제자매(兄弟姉妹) </p> 나. 비대칭적 관계인간 <p class="message"> 나으리, 남자친구(男子親舊), 님, 대모(代母), 대부(代父), 대선배(大先輩), 도련님(道令_), 도제(徒弟), 마님, 문민(文民), 미망인(未亡人), 밭단골, 부하(部下), 북녘동포(北_同胞 ), 비부(婢夫), 상대방(相對方), 상대자(相對者), 상대편(相對便), 상전(上典), 색시, 선배(先輩), 선조(先祖), 선학(先學), 선후배(先後輩), 수제자(首弟子), 숙적(宿敵), 스승, 신랑(新郞), 심복(心腹), 아랫것, 아랫사람, 애첩(愛妾), 여자친구(女子親舊), 와이프(wife), 원수(怨讐), 원조(元祖), 윗사람, 은사(恩師), 은인(恩人), 임, 적군(敵軍), 전임(前任), 전처(前妻), 정실(正室), 제자(弟子), 조상(祖上), 주변인물(周邊人物), 지원자(支援者), 직장상사(職場上司), 첩(妾), 타자(他者), 후계자(後繼者), 후배(後輩), 후임(後任), 후진(後進), 후학(後學), 휘하(麾下) </p> - 비대칭적 친족 <p class="message"> 가운데어머니, 가친(家親), 계모(繼母), 계부(繼父), 계수(季嫂), 고명딸, 고모(姑母), 고모부(姑母夫), 고조할아버지(高祖____), 고종사촌(姑從四寸), 남동생(男__), 남편(男便), 노모(老母), 노부모(老父母), 누나, 누님, 누이, 누이동생, 당고모(堂姑母), 당숙(堂叔), 당질(堂姪), 독녀(獨女), 동생(同生), 따님, 딸, 딸년, 딸아이, 딸애, 딸자식, 마누라, 막내, 막내딸, 막내며느리, 막내아들, 막둥이, 맏손녀(_孫女), 맏손자(_孫子), 맏이, 매부(妹夫), 매형(妹兄), 며느리, 모녀(母女), 모친(母親), 민며느리, 백모(伯母), 백부(伯父), 부(父), 부군(夫君), 부녀(父女), 부모(父母), 부인(夫人), 부질(婦姪), 부친(父親), 부형(父兄), 사위, 사촌매부(四寸妹夫), 삼남(三男), 삼촌(三寸), 새사람, 새엄마, 생모(生母), 생부(生父), 서모(庶母), 서방(書房), 서자(庶子), 서출(庶出), 선고(先考), 선친(先親), 소생(所生), 손녀(孫女), 손녀딸(孫女_), 손부(孫婦), 손자(孫子), 손자며느리(孫子___), 손주, 수양딸(收養_), 수양아들(收養__), 수양어머니(收養___), 숙모(叔母), 숙부(叔父), 시고모(媤姑母), 시누이(媤__), 시부모(媤父母), 시숙(媤叔), 시아버지(媤___), 시어머니(媤___), 시어머님, 십대손(十代孫), 아내, 아들, 아바마마, 아버님, 아버지, 아범, 아비, 아빠, 아우, 아저씨, 아주머니, 아주머님, 아주버니, 아주버님, 안부인(_婦人), 애비, 양녀(養女), 양모(洋母), 양친(兩親), 어르신, 어머니, 어머님, 어멈, 어미, 어버이, 언니, 엄마, 에미, 여동생(女同生), 여식(女息), 영감(令監), 영애(令愛), 오라버니, 오라버님, 오라비, 오빠, 올케, 외동딸, 외딸, 외삼촌(外三寸), 외삼촌댁(外三寸宅), 외손녀(外孫女), 외숙모(外叔母), 외숙부(外叔父), 외아들, 외조모(外祖母), 외조부(外祖父), 외할머니(外___), 외할아버지(外____), 유족(遺族), 의부(義父), 의붓딸, 의붓아비, 의붓어미, 의붓자식(__子息), 이남(二男), 이모(姨母), 일녀(一女), 자녀(子女), 자당(慈堂), 자모(慈母), 자부(子婦), 자손(子孫), 자식(子息), 자제(子第), 자친(慈親), 자형(姉兄), 작은누이, 작은마누라, 작은아버지, 작은어머니, 작은형(__兄), 장남(長男), 장녀(長女), 장모(丈母), 장손(長孫), 장인(丈人), 장자(長子), 제부(弟夫), 조모(祖母), 조부(祖父), 조카, 종손(宗孫), 증손(曾孫), 증조(曾祖), 증조부(曾祖父), 지아비, 질녀(姪女), 질부(姪婦), 집사람, 차남(次男), 차녀(次女), 차손(次孫), 처(妻), 처남(妻男), 처외삼촌(妻外三寸), 처자(妻子), 처자식(妻子息), 처제(妻弟), 처첩(妻妾), 처형(妻兄), 첩실(妾室), 친남매(親男妹), 친모(親母), 친부(親父), 친손(親孫), 친자(親子), 친자식(親子息), 친정붙이(親庭__), 친형(親兄), 큰동서(_同壻), 큰딸, 큰사위, 큰삼촌(_三寸), 큰아들, 큰아버지, 큰어머니, 큰형(_兄), 학부모(學父母), 할머니, 할머님, 할미, 할아버님, 할아버지, 혈육(血肉), 형(兄), 형부(兄夫), 형수(兄嫂), 홀시아버지, 홀시어머니, 홀시할머니, 홀어머니, 후손(後孫), 후실(後室), 후예(後裔), 후처(後妻) </p> - 소속인간 <p class="message"> 단원(團員), 당원(黨員), 분교생(分校生), 생도(生徒), 성원(成員), 여학생(女學生), 일인(一人), 준회원(準會員), 철도회원(鐵道會員), 회원(會員) </p> (2) 화시적인간 : 화시적 관계에 의해 지시 대상이 정해지는 인간 <p class="message"> 각개(各個), 각기(各其), 각인(各人), 각자(各自), 남, 내국인(內國人), 내부자(內部者), 모모(某某), 민간인(民間人), 삼자(三者), 서로, 스스로, 얘, 외인(外人), 외지인(外地人), 이방인(異邦人), 일동(一同), 자가(自家), 자기(自己), 자기편(自己便), 자네, 자신(自身), 자타(自他), 제삼자(第三者), 타(他), 타인(他人), 혹자(或者) </p> (3) 호칭 : 사람을 부르는 데 사용되는 말 <p class="message"> 나리, 낭군(郎君), 노형(老兄), 닥터(doctor), 미스터(mister), 아씨, 여사(女史), 전하(殿下), 제군(諸君), 진사(進士), 첨지(僉知), 춘당(春堂), 춘장(椿丈), 폐하(陛下) </p> (4) 속성인간 : 특정 속성을 지닌 인간 <p class="message"> 강골한(强骨漢), 거물(巨物), 거한(巨漢), 계집, 고아(孤兒), 고인(古人), 골초(_草), 공민(公民), 공배수배자(公開手配者), 공비(共匪), 공신(功臣), 과부(寡婦), 과원(課員), 관료(官僚), 괴한(怪漢), 궤변론자(詭辯論者), 극성팬(極盛_), 금욕주의자(禁慾主義者), 기인(奇人), 깜둥이, 꺽다리, 꼬맹이, 녀석, 노소(老少), 노약자(老弱者), 노인자제(老人子弟), 노조원(勞組員), 놈, 늦깍이, 대처승(帶妻僧), 독생자(獨生子), 독신녀(獨身女), 동성연애자(同性戀愛者), 동포(同胞), 동호인(同好人), 딸부자, 뜨내기, 마나님, 말고기자반(___佐飯), 말괄량이, 문사(文士), 문학소녀(文學少女), 물주(物主), 반골(反骨), 반면교사(反面敎師), 방관자(傍觀者), 백계노인(白系露人), 백발노인(白髮老人), 베테랑(veteran), 변사자(變死者), 보통사람, 사내, 사생아(私生兒), 사회인(社會人), 서얼(庶孼), 서울깍쟁이, 선비, 성인남자(成人男子), 소녀가장(少女家長), 소유자(所有者), 소유주(所有主), 소지인(所持人), 속인(俗人), 숫처녀(_處女), 식인종(食人種), 신여성(新女性), 실권자(實權者), 쌍둥이(雙__), 악동(惡童), 악바리, 애호가(愛好家), 얌전단지, 어리광쟁이, 억만장자(億萬長者), 억척꾸러기, 여고생(女高生), 여성상(女性像), 요원(要員), 월급쟁이(月給__), 유한마담(有閑__), 응석꾸러기, 의심꾸러기(疑心___), 익살꾸러기, 익살쟁이, 일반시민(一般市民), 잠보, 재담가(才談家), 재야인사(在野人士), 전쟁고아(戰爭孤兒), 정상인(正狀人), 제보자(提報者), 조합원(組合員), 종교인(宗敎人), 주검, 주당(酒黨), 중진(重鎭), 지상태아(紙狀胎兒), 차주(車主), 촌색시(村__), 축구광(蹴球狂), 측근자(側近者), 토박이(土__), 특정인(特定人), 팔삭둥이(八朔__), 풍류객(風流客), 한량(閑良), 햇병아리, 현대인(現代人), 호모(homo), 호사가(好事家), 호색가(好色家), 화신(化身), 회복기보균자(回復期保菌者), 후궁(後宮), 히피(hippie) </p> 가. 부정적 속성인간 <p class="message"> 가난뱅이, 개구장이, 개구쟁이, 개다리출신(___出身), 개새끼, 건달(乾達), 걸신(乞神), 겁꾸러기(怯___), 겁보(怯_), 겁쟁이(怯__), 게이(gay), 경박소년(輕薄少年), 공처가(恐妻家), 괴짜(怪_), 구리귀신(__鬼神), 글방도련님(_房___), 글방퇴물(_房退物), 기형아(畸形兒), 까마귀사촌(___四寸), 꼴지, 꼴찌, 난민(難民), 낭인(浪人), 놈팡이, 눈엣가시, 늦잠꾸러기, 도끼목수(__木手), 독불장군(獨不將軍), 돌팔이, 떠버리, 뚱뚱보, 먹보, 못난이, 무뢰한(無賴漢), 무성격자(無性格者), 문외한(門外漢), 반역자(反逆者), 밤손님아버지, 변덕쟁이, 별인물(別人物), 불우이웃(不遇__), 빈농(貧農), 빈민(貧民), 사고덩어리(事故___), 색광(色狂), 수전노(守錢奴), 술고래, 술꾼, 술망나니, 술주정꾼(_酒酊_), 술주정뱅이(_酒酊__), 시골뜨기, 식객(食客), 식충(食蟲), 아낙군수(__郡守), 악질분자(惡質分子), 약자(弱者), 약졸, 어중이, 왈가닥, 왈패(_牌), 왜장녀(__女), 요강도둑, 욕심꾸러기(慾心___), 울보, 원흉(元兇), 음치(音癡), 인간쓰레기(人間___), 잔풀내기, 잠꾸러기, 잡것(雜_), 장기수(長期囚), 장난꾸러기, 정치모리배(政治謀利輩), 졸부(猝富), 좀생원(_生員), 좀팽이, 좁쌀영감(__令監), 종이호랑이(__虎狼_), 죄인(罪人), 주구(走狗), 주전자운전수(酒煎子運轉手), 주정뱅이(酒酊__), 주착바가지, 진범(眞犯), 천덕꾸러기(賤____), 철부지(_不知), 치인(癡人), 칠삭둥이(七朔__), 코맹맹이, 패자(敗者), 폐인(廢人), 허풍쟁이(虛風__), 현행범(現行犯), 화냥년, 흉물(凶物) </p> 나. 긍정적 속성인간 <p class="message"> 갑부(甲富), 강자(强者), 개혁자(改革者), 거두(巨頭), 거부(巨富), 거장(巨匠), 건국유공자(建國有功者), 걸물(傑物), 검객(劍客), 고승(高僧), 공로자(功勞者), 국부(國父), 군웅(群雄), 귀공자(貴公子), 귀염둥이, 귀인(貴人), 금지옥엽(金枝玉葉), 기대주(期待株), 달인(達人), 대중스타(大衆__), 명관(名官), 명군(明君), 명사(名士), 명수(名手), 명인(名人), 명장(名將), 명창(名唱), 무등호인(無等好人), 문호(文豪), 문화인(文化人), 발명왕(發明王), 백의천사(白衣天使), 본보기(本__), 부농(富農), 상수(上手), 수혜자(受惠者), 숙련노동자(熟鍊勞動者), 신랑감(新郞_), 신예(新銳), 실력자(實力者), 실력파(實力派), 실속파(實_派), 실천자(實踐者), 실행가(實行家), 씨름꾼, 애국지사(愛國志士), 애어른, 애처가(愛妻家), 양민(良民), 양인(良人), 여걸(女傑), 여장부(女丈夫), 열사(烈士), 영웅(英雄), 영웅호걸(英雄豪傑), 우등생(優等生), 운동가(運動家), 웃음제조기(__製造機), 원로(元老), 유망주(有望株), 유명역술인(有名曆術人), 유명연예인(有名演藝人), 유명인사(有名人士), 유명정치인(有名政治人), 의인(義人), 이론가(理論家), 인걸(人傑), 인권변호사(人權辯護士), 인기가수(人氣歌手), 재간둥이(才幹), 재롱둥이, 재원(才媛), 저명인사(著名人士), 지성인(知性人), 지식인(知識人), 지역유지(地域有志), 지역인사(地域人士), 지인(至人), 총아(寵兒), 태두(泰斗), 태산북두(泰山北斗), 팔방미인(八方美人), 프로(pro), 현인(賢人), 현자(賢者), 협객(俠客), 호걸(豪傑), 호인(好人), 호한(好漢), 환경운동가(環境運動家), 휴머니스트(humanist) </p> 다. 신체 속성인간 <p class="message"> 거인(巨人), 뚱뚱이, 성전환자(性轉換者), 안경잡이(眼鏡__), 앞뒤짱구, 양복쟁이(洋服__), 오른손잡이, 왕눈이, 왼발잡이, 왼손잡이 </p> - 긍정적신체속성인간 <p class="message"> 가인(佳人), 강골(强骨), 건각(健脚), 건아(健兒), 글래머(glamor), 묘소년(妙少年), 미남(美男), 미녀(美女), 미인(美人), 장골(壯骨), 절세미인(絶世美人) </p> - 부정적신체속성인간 <p class="message"> 고자(鼓子), 곰뱅이, 꼽추, 난장이, 난쟁이, 넓죽이, 농아(聾啞), 눈뜬장님, 늙다리, 다리병신(__病身), 더듬이, 딱부리, 뚱보, 말라깽이, 맹인(盲人), 문둥이, 벙어리, 병신(病身), 병인(病人), 병자(病者), 봉사, 색맹(色盲), 석녀(石女), 소경, 시각장애인(視覺障碍人), 신체장애자(身體障?者), 앉은뱅이, 애꾸눈, 애꾸눈이, 약골(弱骨), 약시(弱視), 약체(弱體), 언청이, 외눈박이, 외팔이, 육손이(六__), 자폐아(自閉兒), 잔병꾸러기(_病___), 잠복기보균자(潛伏期保菌者), 장님, 장애아동(障碍兒童), 장애인(障碍人), 장애자(障碍者), 절름발이, 점박이(點__), 정신지체자(精神肢體者), 중독자(中毒者), 중증장애인(重症障碍人), 지체장애인(肢體障<U+7919>人), 지체장애자(肢體障?者), 쩔름발이, 추남(醜男), 털보, 폐결핵환자(肺結核患者) </p> 라. 정도속성인간 <p class="message"> 범부(凡夫), 야구광(野球狂), 학사(學士) </p> - 능력속성인간 <p class="message"> 강병(强兵), 변사(辯士), 숙련공(熟鍊工), 아마추어(amateur), 인기연예인(人氣演藝人), 적임자(適任者), 전공자(專攻者), 전문가(專門家), 초보자(初步者) </p> 마. 시간속성인간 <p class="message"> 고대인(古代人), 고참(古參), 구세대(舊世代), 노장(老將), 늦둥이, 새댁(_宅), 새색시, 새아기씨, 수습사원(修習社員), 신인(新人), 신입(新入), 신입사원(新入社員), 신입생(新入生), 신진(新進), 신진작가(新進作家), 신참(新參), 신혼부부(新婚夫婦), 원로교수(元老敎授), 원시인(原始人), 초선의원(議員初選), 최고참(最古參) </p> - 연령인간 <p class="message"> 갓난아기, 갓난아이, 갓난이, 고등학생(高等學生), 고령자(高齡者), 고조(高祖), 공자(公子), 기성세대(旣成世代), 꼬마, 남아(男兒), 노부부(老夫婦), 노스님(老__), 노옹(老翁), 노인(老人), 노처녀(老處女), 노총각(老總角), 노파(老婆), 늙은이, 대인(大人), 도령, 독거노인(獨居老人), 동자(童子), 또래, 미성년자(未成年者), 성인(成人), 세쌍둥이(_雙__), 소녀(少女), 소년(少年), 시험관아기(試驗管__), 신생아(新生兒), 십대(十代), 아가, 아가씨, 아기, 아기씨, 아낙, 아동(兒童), 아이, 아이들, 아줌마, 애기, 애송이, 애숭이, 어른, 어린것, 어린아이, 어린애, 어린이, 여아(女兒), 영감님, 영감태기(令監__), 영감탱이(令監__), 영아(U+5B30;兒), 원아(園兒), 유아(乳兒), 장부(丈夫), 장정(壯丁), 젊은이, 젖먹이, 조무래기, 좌상(座上), 처녀(處女), 청년(靑年), 청소년(靑少年), 청장년(靑壯年), 초립동(草笠童), 촌로(村老), 태아(胎兒), 하이틴(high teen), 환갑노인(還甲老人) </p> 바. 지역인간 <p class="message"> 교민(僑民), 교포(僑胞), 국민(國民), 도시인(都市人), 동네주민(洞_住民), 동양인(東洋人), 마을주민(__住民), 미국인(美國人), 서양인(西洋人), 서울뜨기, 서인(西人), 야인(野人), 양코배기(洋___), 양키(Yankee), 왜놈(倭_), 왜인(倭人), 외국인(外國人), 원주민(原住民), 일본인(日本人), 재미교포(在美僑胞), 재미동포(在美同胞), 재외국민(在外國民), 재일동포(在日同胞), 중국인(中國人), 지방출신(地方出身), 지역주민(地域住民), 촌놈(村_), 촌뜨기(村__), 촌민(村民), 촌부(村夫), 토인(土人), 프랑스인(France_), 한국인(韓國人), 한인(韓人) </p> 사. 성별인간 <p class="message"> 남녀(男女) </p> - 여성인간 <p class="message"> 계집아이, 규수(閨秀), 낭자(娘子), 미스(Miss), 미시(missy), 미혼여성(未婚女性), 본실(本室), 본처(本妻), 부녀자(婦女子), 아낙네, 아녀자(兒女子), 안방마님(_房__), 여(女), 여류(女流), 여성(女性), 여인(女人), 여자(女子), 여자아이(女子__), 여편네(女便_), 이혼녀(離婚女), 직장여성(職場女性) </p> - 남성인간 <p class="message"> 남성(男性), 남자(男子), 남자아이(男子_), 사나이, 사내대장부(__大丈夫), 총각(總角), 홀아비 </p> 아. 인종 <p class="message"> 검둥이, 백인(白人), 백인종(白人種), 유대인(__人), 흑인(黑人) </p> 자. 추종자 <p class="message"> 민족주의자(民族主義者), 사상가(思想家), 운명론자(運命論者), 원칙주의자(原則主義者), 인도주의자, 자유주의자(自由主義者), 채식주의자(菜食主義者), 페미니스트(feminist), 평화주의자(平和主義者), 현실주의자(現實主義者), 후보지지자(候補支持者) </p> - 종교적추종자 <p class="message"> 기독교인(基督敎人), 불교도(佛敎徒), 불교신자(佛敎信者), 불도(佛徒), 불자(佛子), 예수쟁이(Jesus__), 유대인기독교도(Judea_____), 이교도(異敎徒), 파계승(破戒僧), 회교도(回敎徒) </p> - 정치적추종자 <p class="message"> 극우인사(極右人士), 나치(Nazi), 냉전주의자(冷戰主義者), 반공주의자(反共主義者), 반미주의자(反美主義者), 반전주의자(反戰主義者), 보수주의(保守主義者), 빨갱이, 사회주의자(社會主義者), 아나키스트(anarchist), 운동권학생(運動圈學生), 좌익사범(左翼事犯), 파시스트(fascist) </p> - 학문적추종자 <p class="message"> 실학자(實學者), 염세주의자(厭世主義者), 유림(儒林), 유생(儒生) </p> - 예술적추종자 <p class="message"> 낭만주의자(浪漫主義者) </p> 차. 사회계급인간 : 생산수단의 소유여부 <p class="message"> 권력자(權力者), 귀족(貴族), 금융자본가(金融資本家), 노동자(勞動者), 노비(奴婢), 노예(奴隸), 민초(民草), 반상(班常), 봉건영주(封建領主), 부르조아(bourgeois), 부르주아(bourgeois), 사대부(士大夫), 사부(士夫), 상민(常民), 서민(庶民), 소년근로자(少年勤勞者), 소시민(小市民), 소외계층(疎外階層), 소작농(小作農), 소지주(小地主), 양반(兩班), 엘리트, 영세민(零細民), 영세사업자(零細事業者), 이주노동자(移駐勞動者), 인텔리(인텔리겐치아), 일용근로자(日傭勤勞者), 일용노동자(日傭勞動者), 일용잡급직(日傭雜給職), 자본가(資本家), 재벌총수(財閥總帥), 조직근로자(組織勤勞者), 중인(中人), 진골(眞骨), 창가비(唱歌婢), 천민(賤民), 큰부자(_富者), 평민(平民), 프롤레타리아(proletariat), 필부(匹夫) </p> (5) 상태인간 <p class="message"> 간염보균자(肝炎保菌者), 결식어린이(缺食_), 결핵환자(結核患者), 국가유공자(國家有功者), 남학생(男學生), 마주(馬主), 만성질환자(慢性疾患者), 말기암환자(末期癌患者), 망자(亡者), 부상자(負傷者), 부재자(不在者), 비거주자(非居住者), 빈털터리, 사망자(死亡者), 사상자(死傷者), 선박소유자(船舶所有者), 선주(船主), 세입자(貰入者), 수인(囚人), 수형자(受刑者), 실수요자(實需要者), 실업자(失業者), 억류자(抑留者), 여대생(女大生), 예금주(預金主), 원생(院生), 월급생활자(月給生活者), 유부남(有婦男), 유부녀(有夫女), 응급환자(應急患者), 임산부(姙産婦), 임신부(姙娠婦), 임자, 입원환자(入院患者), 재소자(在所者), 죄수(罪囚), 주택소유자(住宅所有者), 중증환자(重症患者), 중환자(重患者), 청상과부(靑孀寡婦), 취객(醉客), 해고노동자(解雇勞動者), 행려사망자(行旅死亡者), 혐의자(嫌疑者), 환자(患者), 휴가병(休暇兵), 희망자(希望者) </p> (6) 역할인간 : 특정 역할에 의해 규정되는 인간 <p class="message"> 가장(家長), 간판스타(看板__), 간호장교(看護將校), 고정게스트(固定_), 공직자(公職者), 과학자(科學者), 관계관(關係官), 관계자(關係者), 관련자(關聯者), 관리인(管理人), 관리자(管理者), 광고주(廣告主), 군신(君臣), 굿감독(_監督), 궁인(宮人), 담당교수(擔當敎授), 담당기자(擔當記者), 담당자(擔當者), 담당직원(擔當職員), 담당형사(擔當刑事), 담임교사(擔任敎師), 담임선생(擔任先生), 당국자(當局者), 당사자(當事者), 대리모(代理母), 대변자(代辯者), 대상자(對象者), 대의원(代議員), 대표자(代表者), 동반자(同伴者), 막료(幕僚), 목동(牧童), 발행인(發行人), 보병(步兵), 보조교사(補助敎師), 보초(步哨), 부양의무자(扶養義務者), 사업자(事業+者), 선박관리인(船舶管理人), 세납자(稅納者), 세대주(世帶主), 송신인(送信人), 수사관(搜査官), 수취인(受取人), 수탁자(受託者), 수행인(隨行人), 스포츠맨(sportsman), 신하(臣下), 실무자(實務者), 심사원(審査員), 심판관(審判官), 업자(業者), 역군(役軍), 왜군(倭軍), 왜병(倭兵), 외국투자가(外國投資家), 운영위원(委員運營), 유모(乳母), 음유시인(吟遊詩人), 인도자(引導者), 인민군(人民軍), 인턴(intern), 작중인물(作中人物), 잡부(雜夫), 장병(將兵), 적병(敵兵), 정병(精兵), 조교(助敎), 졸개(卒_), 종군위안부(從軍慰安婦), 종복(從僕), 종사자(從事者), 주군(主君), 주동자(主動者), 주민대표(住民代表), 주범(主犯), 주부(主婦), 주주(株主), 중견(中堅), 지주(地主), 직원(職員), 참모(參謀), 취재원(取材源), 타이머(timer), 타이피스트(typist), 통치자(統治者), 투자가(投資家), 투자자(投資者), 편자(編者), 평신도(平信徒), 필자(筆者), 하수인(下手人), 학도(學徒), 학동(學童), 학생(學生), 할아범, 해금수(奚琴手), 헌병(憲兵), 활동가(活動家), 후견인(後見人) </p> 가. 위계인간 <p class="message"> 고관대작(高官大爵), 고위관료(高位官僚), 고위인사(高位人事), 상것(常_), 선달(先達), 영부인(令夫人), 황국신민(皇國臣民) </p> - 직위인간 : 인간 조직 내의 역할에 의해 규정되는 인간 <p class="message"> 각료(閣僚), 간부(幹部), 간사(幹事), 객사정(客舍正), 검사장(檢事長), 검찰총수(檢察總帥), 검찰총장(檢察總長), 경영주(經營主), 경제수석(經濟首席), 경제장관(經濟長官), 계원(係員), 계장(係長), 고관(高官), 고급공무원(高級公務員), 고위공직자(高位公職者), 고위관계자(高位關係者), 공동대표(共同代表), 공동의장(共同議長), 공보수석(公報首席), 과장(課長), 관원(官員), 관장(館長), 교감(校監), 교감선생(校監先生), 교관(敎官), 교육감(敎育監), 교육장(敎育長), 교장(校長), 교장선생(校長先生), 교황관리인(敎皇管理人), 구단주(球團主), 국가원수(國家元首), 국무위원(國務委員), 국무장관(國務長官), 국무총리(國務總理), 국방장관(國防長官), 국방차관(國防次官), 국원(局員), 국장(局長), 국정원장(國情院長), 국회의장(國會議長), 군졸(軍卒), 궁녀(宮女), 궁도련님(宮___), 급사중(給事中), 급장(級長), 기관장(機關長), 기사(技士), 기장(機長), 기획위원(企劃委員), 나인, 낭도(郎徒), 내각총리대신(內閣總理大臣), 내무부장관(內務部長官), 노신(老臣), 노조위원장(勞組委員長), 단체장(團體長), 당수(黨首), 대검차장(大檢次長), 대관(大官), 대령목수(待令木手), 대법관(大法官), 대법원장(大法院長), 대법원판사(大法院判事), 대변인(代辯人), 대사(大使), 대신(大臣), 대왕(大王), 대통령(大統領), 대표이사(代表理事), 대학생(大學生), 대학총장(大學總長), 동장(洞長), 리더(leader), 마스터(master), 말단공무원(末端公務員), 맹주(盟主), 면장(面長), 명예교수(名譽敎授), 명예총재(名譽總裁), 명예회장(名譽會長), 문관(文官), 문교부장관(文敎部長官), 박사(博士), 반장(班長), 법무장관(法務長官), 법무차관(法務次官), 법사위원(法司委員), 벼슬아치, 별감(別監), 보좌관(補佐官), 본부장(本部張), 부관(副官), 부대장(部隊長), 부사장(副社長), 부위원장(副委員長), 부의장(副議長), 부장(副長), 부총리(副總理), 부총장(副總長), 부통령(副統領), 부회장(副會長), 비례대표(比例代表), 비서관([U7955]書+官), 비서실장([U7955]書室長), 사또, 사령관(司令官), 사무국장(事務局長), 사무총장(事務總長), 사서서기(司書書記), 사신(使臣), 사외이사(社外理事), 사장(社長), 삼급공무원(三級公務員), 상공부장관(商工部長官), 상궁(尙宮), 상무(常務), 상원의원(上院議員), 상임고문(常任顧問), 상임이사(常任理事), 생원(生員), 서장(署長), 선량(選良), 선임(先任), 선장(船長), 성주(城主), 소장(所長), 수령(首領), 수상(首相), 수위사자(收位使者), 시녀상궁(侍女尙宮), 시장(市長), 신민(臣民), 실장(室長), 심사위원장(審査委員長), 십장(什長), 아전(衙前), 어사(御史), 업주(業主), 여성총리(女性總理), 역장(驛長), 연구생(硏究生), 영도자(領導者), 영수(領袖), 영업주(營業主), 영의정(領議政), 영주(領主), 외무장관(外務長官), 운영위원장(運營委員長), 원장(院長), 위원(委員), 위원장(委員長), 유도대신(留都大臣), 은행장(銀行長), 읍장(邑長), 의원(議員), 의장(議長), 이사(理事), 이사장(理事長), 이장(里長), 일대교주(一代敎主), 임원(任員), 장관(長官), 장수(將帥), 재상(宰相), 재선의원(再選議員), 재판장(裁判長), 전무(專務), 전문경영인(專門經營人), 전문경영자(專門經營者), 전문위원(專門委員), 전임강사(專任講師), 전임교수(專任敎授), 절대권력자(絶對權力者), 절도사(節度使), 정부관료(政府官僚), 정부관리(政府官吏), 정부통령(正副統領), 제관(祭官), 제독(提督), 제후(諸侯), 조교수(助敎授), 조수(助手), 조장(組長), 조합장(組合長), 족장(族長), 좌의정(左議政), 주교(主敎), 주사(主事), 주석(主席), 주임(主任), 주지(住持), 주필(主筆), 줄반장(班長), 중대장(中隊長), 지도자(指導者), 지배인(支配人), 지부장(支部長), 지사(知事), 지역대표(地域代表), 지점장(支店長), 지휘관(指揮官), 지휘자(指揮者), 차관(次官), 차관보(次官補), 차장(次長), 참모총장(參謀總長), 청장(廳長), 촌장(村長), 총감(總監), 총감독(總監督), 총대(總代), 총독(總督), 총리(總理), 총리서리(總理署理), 총무(總務), 총수(總帥), 총장(總長), 총재(總裁), 총책(總責), 총통(總統), 최고경영자(最高經營者), 최고의원(最高議員), 추기경(樞機卿), 추장(酋長), 칼리프, 코치(coach), 태수(太守), 통감(統監), 통장(統長), 팀장(team_), 판서(判書), 편집위원장(編輯委員長), 평교사(平敎師), 평의원(評議員), 포졸(捕卒), 하급공무원(下級公務員), 학교장(學校長), 학장(學長), 함장(艦長), 해병대사령관(海兵隊司令官), 회장(會長), 훈련대장(訓練大將) </p> - 계급인간 : 인간 조직 내의 계급에 의해 규정되는 인간 <p class="message"> 경장(警長), 공군참모총장(空軍參謀總長), 군관(軍官), 군수장교(軍需將校), 나졸(邏卒), 대감(大監), 대령(大領), 대위(大尉), 대장(大將), 동지절제사(同知節制事), 배기수(陪旗手), 병장(兵長), 병졸(兵卒), 브라만(Brahman), 사관(士官), 사무관(事務官), 사병(士兵), 상병(上兵), 상사(上士), 샌님, 서기(書記), 소대원(小隊員), 소령(少領), 소위(少尉), 우포도대장(右捕盜大將), 이병(二等兵), 일년생(一年生), 일병(一兵), 장군(將軍), 장졸(將卒), 졸병(卒兵), 준위(准尉), 준장(准將), 중령(中領), 중사(中士), 중위(中尉), 중장(中將), 총경(總警), 하사(下士), 하사관(下士官) </p> - 서열인간 : 인간 조직 내의 서열에 의해 규정되는 인간 <p class="message"> 골목대장(__大將), 두령(頭領), 두목(頭目), 보스(boss), 부원(部員), 상급생(上級生), 수괴(首魁), 수뇌(首腦), 수반(首班), 왕초(王_), 좌장(座長), 지배자(支配者) </p> 나. 작위 : 왕이 신하에게 내리는 지위 <p class="message"> 남작(男爵), 백작(伯爵), 정승(政丞), 후작(侯爵) </p> 다. 왕족 : 왕족에게 세습되는 신분 <p class="message"> 가내(家內), 가문(家門), 가정(家庭), 가족(家族), 가족공동체(家族共同體), 가족관계(家族關係), 대가족(大家族), 명가(名家), 모자가정(母子家庭), 무장대가(武將大家), 문중(門中), 부잣집(富者_), 성가정(聖家庭), 소가족(小家族), 숙질(叔姪), 시가족(_家族), 식구(食口), 식솔(食率), 신가정(新家庭), 씨족(氏族), 양가(良家), 양갓집(良家_), 왕가(王家), 왕실(王室), 왕족(王族), 외가(外家), 외가댁(外家宅), 이산가족(離散家族), 일가(一家), 일가족(一家族), 일족(一族), 족속(族屬), 종가(宗家), 집안, 친가(親家), 친인척(親姻戚), 친정(親庭), 콩가루집안, 큰댁(_宅), 큰집, 한가(寒家), 핵가족(核家族), 혈족(血族), 혼처(婚處), 황실(皇室) </p> 라. 직업인간 : 생활을 위해 특징적으로 하는 일에 의해 규정되는 인간 <p class="message"> 가수(歌手), 가신(家臣), 가이드(guide), 가정부(家政婦), 각설이, 간병인(看病人), 간수(看守), 간호사(看護師), 간호원(看護員), 간호조무사(看護助務士), 갈보, 감독(監督), 감독원(監督員), 감사원(鑑査員), 강사(講師), 개사(介士), 객원가수(客員歌手), 객원교수(客員敎授), 객원기자(客員記者), 갱부(坑夫), 거상(巨商), 건축가(建築家), 건축사(建築士), 겸임교수(兼任敎授), 경비교도관(警備矯導官), 경비아저씨(警備___), 경영인(經營人), 경제인(經濟人), 경제학자(經濟學者), 경찰관(警察官), 경호원(警護員), 곁꾼, 계집애종, 고교생(高校生), 고문변호사(顧問辯護士), 고철장수(古鐵__), 공공근로자(公共勤勞者), 공공노동자(公共勞動者), 공무원(公務員), 공익요원(公益要員), 공인(工人), 공인중개사(公認仲介士), 공인회계사(公認會計士), 관기(官妓), 관노(官奴), 광고모델(廣告__), 광부(鑛夫), 광주리장수, 교도관(矯導官), 교사(敎師), 교수(敎授), 교원(敎員), 교육자(敎育者), 구두닦이, 국가공무원(國家公務員), 국어교사(國語敎師), 국어학자(國語學者), 군경(軍警), 군병(軍兵), 군속(軍屬), 군의관(軍醫官), 군인(軍人), 궁사(弓師), 궁수(弓手), 극작가(劇作家), 근로자(勤勞者), 근무자(勤務者), 금융인(金融人), 기관원(機關員), 기녀(妓女), 기술자(技術者), 기업가(企業家), 기업인(企業人), 기업주(企業主), 기자(記者), 까까중, 남파공작원(南派工作員), 내관(內官), 노가다, 노승(老僧), 농군(農軍), 농민(農民), 농부(農夫), 농어민(農漁民), 단골레, 대농(大農), 대장장이, 대학강사(大學講師), 댄서(dancer), 도공(陶工), 도매상(都賣商), 도사공(都__), 둥우리장수, 디자이너(designer), 딜러(dealer), 때밀이, 레지(레지), 레지던트(resident), 마담(madame), 마름, 마부(馬夫), 만화가(漫_家), 매니저(manager), 매장직원(賣場職員), 매춘부(賣春婦), 매춘여성(賣春女性), 머슴, 목사(牧師), 목수(木手), 목자(牧者), 무관(武官), 무녀(巫女), 무당(巫堂), 무사(武士), 무신(武臣), 무용가(舞踊家), 무희(舞姬), 문무(文武), 문신(文臣), 문인(文人), 문지기(門__), 문화예술인(文化藝術人), 물리치료사(物理治療師), 미술교사(美術敎師), 미장이, 바이어(buyer), 바이얼리니스트(violinist), 바이올리니스트(violinist), 발레리나(ballerina), 방송인(放送人), 방송작가(放送作家), 방송진행자(放送進行), 배관공(配管工), 배우(俳優), 백정(白丁), 뱃놈, 뱃사람, 버스기사(bus__), 버스운전사(bus___), 법관(法官), 법조인(法曹人), 벤처경영인(venture___), 벤처기업가(venture___), 벤처기업인(venture___), 벤처사업가(venture___), 변호사(辯護士), 변호인(辯護人), 보건교사(保健敎師), 보디가드(bodyguard), 보따리장수(褓----), 보모(保姆), 보이(boy), 보조간호사(補助看護師), 보험설계사(保險設計士), 보험외판원(保險外販員), 복서(boxer), 브로커(broker), 비바리, 비서(秘書), 비즈니스맨(businessman), 비평가(批評家), 비행사(飛行士), 사건기자(事件記者), 사공(沙工), 사범(師範), 사서(司書), 사업가(事業家), 사진기자(寫眞記者), 사창(私娼), 사채업자(社債業者), 사환(使喚), 사회학자(司會學者), 삯벼슬아치, 산림간수(山林看守), 산파(産婆), 상고배(商賈輩), 상사중개인(商事中介人), 상인(商人), 샐러리맨(salaryman), 생명공학자(生命工學者), 서양화가(西洋畵家), 석공(石工), 석수(石手), 석장(石匠), 선생(先生), 선생님(先生_), 선원(船員), 설계가(說計家), 성우(聲優), 세관공무원(稅關公務員), 세리(稅吏), 세무공무원(稅務公務員), 세일즈맨(salesman), 소금장수, 소농(小農), 소리광대, 소매업자(小賣業者), 소몰이꾼, 소방공무원(消防公務員), 소방대원(消防隊員), 소사(小使), 소설가(小說家), 소프라노(soprano), 속기사(速記士), 수간호사(首看護師), 수간호원(首看護員), 수도승(修道僧), 수련의(修鍊醫), 수리공(修理工), 수산업자(水産業者), 수습기자(修習記者), 수위(守衛), 수위아저씨(守衛___), 수입업자(輸入業者), 수출상(輸出商), 수출업자(輸出業者), 수학자(數學者), 수화통역사(手話通譯士), 순경(巡警), 순사(巡査), 스턴트맨(stuntman), 스턴트우먼(stuntwoman), 스튜어디스(stewardess), 스파이(spy), 승무원(乘務員), 시간강사(時間講師), 시녀(侍女), 시다(시다), 시동(侍童), 시민운동가(市民運動家), 시사평론가(時事評論家), 시인(詩人), 시장대리인(市場代理人), 시장상인(市場商人), 식모(食母), 신문기자(新聞記者), 신문배달원(新聞配達員), 신문팔이(新聞__), 신부(神父), 심마니, 싸전쟁이(_廛__), 아나운서(announcer), 악사(樂士), 안과의(眼科醫), 안무가(按舞家), 앵커(anchor), 약사(藥師), 약제사(藥劑師), 양의(洋醫), 양치기(羊__), 어릿광대, 어민(漁民), 어부(漁夫), 언론인(言論人), 엑스트라(extra), 엔지니어(engineer), 여공(女工), 여교사(女敎師), 여군(女軍), 여배우(女俳優), 여비서(女秘書), 여선생(女先生), 여의(女醫), 여자경찰관(女子警察官), 여직원(女職員), 여행가(旅行家), 역무원(驛務員), 역사가(歷史家), 역사학자(歷史學者), 역술가(曆術家), 역졸(驛卒), 연구원(硏究員), 연구위원(硏究委員), 연극인(演劇人), 연금사(鍊金師), 연기자(演技者), 연예인(演藝人), 연출가(演出家), 연출자(演出者), 연탄장수(煉炭__), 영감무(靈感巫), 영사(領事), 영세노점상(零細露店商), 영세업자(零細業者), 영업사원(營業社員), 영업인(營業人), 영업자(營業者), 영화감독(映畵監督), 영화배우(映畵俳優), 영화업자(映畵業者), 영화인(映_人), 예능인(藝能人), 예술가(藝術家), 예술인(藝術人), 옹기장수(甕器__), 외교관(外交官), 외교원(外交員), 요리사(料理師), 요식업자(料食業者), 용병(傭兵), 우주비행사(宇宙飛行士), 우주인(宇宙人), 우편배달부(郵便配達夫), 운동선수(運動選手), 운전기사(運轉技士), 운전사(運轉士), 운전수(運轉手), 원예가(園藝家), 웨이터(waiter), 은행원(銀行員), 음악가(音樂家), 음악인(音樂人), 음악치료사(音樂治療師), 의경(義警), 의료인(醫療人), 의무경찰(義務警察), 의사(醫師), 이발사(理髮師), 인부(人夫), 일꾼, 일수쟁이(日收__), 자영업자(自營業者), 자유노동자(自由勞動者), 작가(作家), 작곡가(作曲家), 작부(酌婦), 작인(作人), 잠수부(潛水夫), 장꾼(場_), 장발시인(長髮詩人), 장의사(葬儀社), 재단사(裁斷師), 재야법조인(在野法曹人), 재판관(裁判官), 저널리스트(journalist), 전기기술자(電氣技術者), 전문의(專門醫), 전업주부(專業主婦), 전임교원(專任敎員), 전투경찰(戰鬪警察), 점원(店員), 정교원(正敎員), 정보요원(精報要員), 정비사(整備士), 정신과전문의(精神科專門醫), 정원사(庭園師), 정치가(政治家), 정치인(政治人), 정치학자(政治學者), 제조업자(製造業者), 조각가(彫刻家), 조립공(組立工), 조종사(操縱士), 조판공(組版工), 종군기자(從軍記者), 종업원(從業員), 주모(酒母), 주방장(廚房長), 주차단속원(駐車團束員), 주차도우미(駐車___), 주차요원(駐車要員), 중간도매상(中間都賣商), 중간상인(中間商人), 중개상인(仲介商人), 중견작가(中堅作家), 중농(中農), 중등교사(中等敎師), 중등교원(中等敎員), 중매쟁이(仲媒__), 중학생(中學生), 지방의원(地方議員), 직공(職工), 직업인(職業人), 직장인(職場人), 집사(執事), 창녀(娼女), 창부(娼婦), 채석업자(採石業者), 책략가(策略家), 철학자(哲學者), 첨병(尖兵), 첩보요원(諜報要員), 청소부(淸掃夫), 청지기(廳__), 첼리스트(cellist), 초등교사(初等敎師), 초등교원(初等敎員), 초등학생(初等學生), 총잡이(銃__), 출납공무원(出納公務員), 출입기자(出入記者), 춤꾼, 충복(忠僕), 취재기자(取材記者), 치과의사(齒科醫師), 카드사업자(card___), 카우보이(cowboy), 카운슬러(counselor), 칼럼리스트, 코미디언(comedian), 탐정(探偵), 택시운전사(taxi___), 탤런트(talent), 퇴기(退妓), 특파원(特派員), 파발(擺撥), 파일럿(pilot), 파출부(派出婦), 판관(判官), 판매원(販賣員), 판사(判事), 펀드매니저(fund manager), 편집자(編輯者), 평론가(評論家), 포병(砲兵), 프로게이머(progamer), 프로그래머(programmer), 프로듀서(producer), 프리랜서(freelancer), 피아니스트(pianist), 하녀(下女), 하역부(荷役夫), 하인(下人), 학자(學者), 한의(韓醫), 한의사(韓醫師), 항해사(航海士), 해녀(海女), 해병(海兵), 행원(行員), 현역군인(現役軍人), 형리(刑吏), 홍보담당자(弘報擔當者), 화가(畵家), 화류(花柳), 화백(畵伯), 화학자(化學者), 환경미화원(環境美化員), 환관(宦官), 회사원(會社員), 훈장(訓長) </p> 마. 종교역할인간 <p class="message"> 교구신부(敎區神父), 교주(敎主), 교황(敎皇), 권사(勸士), 담임목사(擔任牧師), 랍비(랍비), 명승(名僧), 법사(法師), 비구(比丘), 비구니(比丘尼), 사제(司祭), 샤먼(shaman), 석가(釋家), 선교사(宣敎師), 선승(禪僧), 성직자(聖職者), 수녀(修女), 수련수녀(修鍊修女), 스님, 승(僧), 승려(僧侶), 승정(僧正), 여승(女僧), 장로(長老), 전도사(傳道師), 종교지도자(宗敎指導者), 중, 혜심(慧心) </p> 바. 반사회적직업인간 : 법률적으로 제재를 받게 되는 일을 직업적으로 하는 인간 <p class="message"> 간첩(間諜) </p> 사. 일시적 역할인간 : 일시적으로 어떤 역할을 하는 인간 <p class="message"> 객(客), 객식구(客食口), 객원(客員), 견습공(見習工), 경쟁자(競爭者), 공범(共犯), 과객(過客), 관광객(觀光客), 관람객(觀覽客), 교육위원(敎育委員), 구경꾼, 국비장학생(國費奬學生), 국빈(國賓), 귀빈(貴賓), 귀성객(歸省客), 글쓴이, 급식당번(給食當番), 기갑병(機甲兵), 기수(旗手), 내빈(來賓), 달머슴, 담임(擔任), 당자(當者), 당직자(堂直者), 대리인(代理人), 대선후보(大選候補), 대원(隊員), 동지상사(同知上使), 들러리, 마수손님, 목격자(目擊者), 문객(門客), 민병(民兵), 밀사(密使), 방문객(訪問客), 방청객(傍聽客), 백년손(百年_), 보증인(保證人), 보호자(保護者), 사절(使節), 사회자(司會者), 산업연수생(産業硏修生), 상두꾼(喪__), 상주(喪主), 선봉장(先鋒將), 소매각시(小梅__), 소식통(消息通), 소주주(小株主), 손님, 수상자(受賞者), 수습생(修習生), 수험자(受驗者), 술래, 승병(僧兵), 시험관(試驗官), 실습생(實習生), 심판자(審判者), 앞잡이, 여주인공(女主人公), 연사(演士), 예비신랑(豫備新郞), 예비역(豫備役), 오너(honor), 운동원(運動員), 원고(原告), 원저자(原著者), 위안부(慰安婦), 유권자(有權者), 응시자(應試者), 의뢰인(依賴人), 의료소비자(醫療消費者), 의병(義兵), 이중간첩(二重間諜), 이해관계인(利害關係人), 인솔자(引率者), 인질(人質), 일일교사(一日敎師), 임부(姙婦), 입장객(入場客), 입후보자(立候補者), 장기기증인(臟器寄贈人), 정기구독자(定期購讀者), 정보증인(正保證人), 제주(祭主), 조문객(弔問客), 주객(主客), 주례(主禮), 주빈(主賓), 주연(主演), 주인(主人), 주인공(主人公), 중재인(仲裁人), 증인(證人), 지도교사(指導敎師), 지도교수(指導敎授), 지역위원(地域委員), 지지자(支持者), 지킴이, 책임자(責任者), 챔피언(champion), 첩자(諜者), 청취자(聽取者), 총받이(銃__), 추천인(推薦人), 출연자(出演者), 칙사(勅使), 탑승객(搭乘客), 토론자(討論者), 투고자(投稿者), 특사(特使), 포로(捕虜), 피에로(피에로), 하객(賀客), 행인(行人), 회의참가자(會議參加者), 회중(會衆), 후보(候補), 후보자(候補者) </p> 아. 운동경기역할인간 : 운동 경기 내의 특정 역할에 의해 규정되는 인간 <p class="message"> 가드(guard), 골키퍼(goal keeper), 골퍼(golfer), 대타(代打), 대표선수(代表選手), 부심(副審), 선수(選手), 센터(center), 주심(主審), 주자(走者), 주전(主戰), 축구선수(蹴球選手), 캐디(caddie), 캐처(catcher), 타선(打線), 투수(投手), 포수(捕手) </p> 자. 권리인간 : 특정 권리를 지닌 인간 <p class="message"> 소액주주(少額株主), 입주자(入住者), 출전권(出戰權), 취급자(取扱者) </p> (7) 행위인간 : 특정 행위에 의해 규정되는 인간 <p class="message"> 가해자(加害者), 가해학생(加害學生), 개척자(開拓者), 경비원(警備員), 경영자(經營者), 관찰자(觀察者), 광대(廣大), 구매자(購買者), 권력행사자(權力行使者), 기타리스트(guitarist), 길잡이, 나그네, 나무꾼(__軍), 남창(男娼), 납세자(納稅者), 노동운동가(勞動運動家), 논객(論客), 논자(論者), 단골손님, 독립운동가(獨立運動家), 독자(讀者), 독재자(獨裁者), 동물애호가(動物愛好家), 등산객(登山客), 떠돌이, 뜨내기손님, 메시아(Messiah), 문학가(文學家), 문학인(文學人), 미아(迷兒), 발기인(發起人), 배낭여행객(背囊旅行客), 범인(犯人), 병정(兵丁), 복병(伏兵), 불청객(不請客), 빨치산(partizan), 사수(射手), 사업주(事業主), 사용자(使用者), 생산자(生産者), 생활인(生活人), 서생(書生), 소비자(消費者), 소액투자자(少額投資者), 수험생(受驗生), 승객(乘客), 시국사범(時局事犯), 시청자(視聽者), 식도락가(食道樂家), 심부름꾼, 씨받이, 아베크족(avec_), 암살자(暗殺者), 애국자(愛國者), 애독자(愛讀者), 야영객(野營客), 억압자(抑壓者), 여객(旅客), 여행객(旅行客), 여행자(旅行者), 역자(譯者), 연구자(硏究者), 연주자(演奏者), 예언가(豫言家), 예언자(預言者), 외교분석가(外交分析家), 외교소식통(外交消息通), 외국투자자(外國投資者), 요양객(療養客), 운전자(運轉者), 웅변가(雄辯家), 원인제공자(原因提供者), 위반자(違反者), 위정자(爲政者), 유료이용자(有料利用者), 유학생(留學生), 유혹자(誘惑者), 은자(隱者), 음주운전자(飮酒運轉者), 응답자(應答者), 이용자(利用者), 자살자(自殺者), 자원봉사자(自願奉仕者), 자원자(自願者), 작성자(作成者), 작자(作者), 저자(著者), 저작자(著作者), 전과자(前科者), 전사(戰士), 정보원(情報員), 제작자(製作者), 제조자(製造者), 주문자(注文者), 주민(住民), 지망생(志望生), 지원병(志願兵), 진행자(進行者), 참가자(參加者), 참고인(參考人), 참석자(參席者), 창안자(創案者), 창조자(創造者), 초보운전자(初步運轉者), 침모(針母), 카드사용자(card___), 카드이용자(card___), 피난민(避難民), 해설자(解說者), 해외이주자(海外移住者), 해외투자가(海外投資家), 해외투자자(海外投資者), 화자(話者), 훼방꾼(毁謗_), 흉내쟁이, 흡연자(吸煙者) </p> 가. 수동적행위인간 <p class="message"> 병역특례자(兵役特例者), 볼모, 수배자(受配者), 수재민(水災民), 양심수(良心囚), 업둥이, 연루자(連累者), 영수인(領收人), 용의자(容疑者), 유산상속자(遺産相續者), 중상자(重傷者), 피고(被告), 피고인(被告人), 피보험자(被保險者), 피의자(被疑者), 흡연피해자(吸煙避害者), 희생자(犧牲者) </p> 나. 결과행위인간 : 특정 행위의 결과에 의해 규정되는 인간 <p class="message"> 가입자(加入者), 개선장군(凱旋將軍), 다수확왕(多收穫王), 당선자(當選者), 메달리스트(medalist), 범죄자(犯罪者), 불합격자(不合格者), 산모(産母), 산부(産婦), 살인범(殺人犯), 살인자(殺人者), 생존자(生存者), 선동정치가(煽動政治家), 선두주자(先頭走者), 수료자(修了者), 수사자(水死者), 수석(首席), 수익자(受益者), 순교자(殉敎者), 스타(star), 승자(勝者), 신용불량자(信用不良者), 실패자(失敗者), 애국선열(愛國先烈), 위장전입자(僞裝轉入者), 일등공신(一等功臣), 전화가입자(電話加入者), 조난자(遭難者), 졸업생(卒業生), 지은이, 참전군인(參戰軍人), 참전용사(參戰勇士), 창시자(創始者), 철거민(撤去民), 최종합격자(最終合格者), 탈퇴자(脫退者), 합격자(合格者), 해직언론인(解職言論人), 혁명가(革命家) </p> (8) 상상적인간 : 실제로 존재하지 않지만 인간의 상상에 의해 인간과 비슷한 속성을 지닌 것으로 상정되는 존재 <p class="message"> 객귀(客鬼), 관세음보살(觀世音菩薩), 구세주(救世主), 귀신(鬼神), 꽃귀신(_鬼神), 낮도깨비, 도깨비, 동생신(同生神), 마귀(魔鬼), 마녀(魔女), 마왕(魔王), 망령(亡靈), 물귀신(_鬼神), 복제인간(複製人間), 사탄(Satan), 산신(山神), 산타(Santa), 산타클로스(Santa Clause), 상제(上帝), 선녀(仙女), 선인(仙人), 성부(聖父), 성신(聖神), 수호신(守護神), 수호천사(守護天使), 신령(神靈), 신선(神仙), 심령(心靈), 악귀(惡鬼), 악령(惡靈), 악마(惡魔), 야광귀(夜光鬼), 여래(如來), 여신(女神), 염라대왕(閻羅大王), 옥황상제(玉皇上帝), 요술쟁이(妖術__), 요정(妖精), 용왕(龍王), 원혼(寃魂), 유령(幽靈), 인어(人魚), 일각수(一角獸), 잡귀(雜鬼), 잡신(雜神), 적그리스도(敵____), 정령(精靈), 조물주(造物主), 주신(主神), 지기(地祈), 지령(地靈), 지신(地神), 천사(天使), 천신(天神), 천제(天帝), 천주(天主), 초인(超人), 충혼(忠魂), 팔선녀(八仙女), 하나님, 하느님, 허깨비, 혼령(魂靈), 화덕성군(火德星君), 화덕진군(火德眞君), 화성인(火星人) </p>  #### 자연음식물 <p class="message"> 감자, 강굴, 강직(江直), 건어물(乾魚物), 계란(鷄卵), 계피(桂皮), 곱창, 굵은소금, 꿀, 녹용(鹿茸), 농산물(農産物), 농수산물(農水産物), 당귀(當歸), 동삼(童蔘), 등질우유(等質牛乳), 멱, 모이, 미역, 벌꿀, 생식품(生食品), 선지, 소금물, 수산(水産), 시래기, 싸라기, 어육(漁肉), 원두(原豆), 조갯살 </p> ### 구체인공물 **구체인공물**이란 인간이 만들어낸 구체물을 뜻합니다. 그 예는 다음과 같습니다. <p class="message"> 가등(街燈), 가솔린(gasoline), 가족사진(家族寫眞), 각목(角木), 간판(看板), 강관(鋼管), 강괴(鋼塊), 강단(講壇), 갱목(坑木), 거울, 거적, 거즈(gauze), 건초(乾草), 걸레, 검인(檢印), 경량벽돌(輕量__), 계면활성제(界面活性劑), 고삐, 공물(貢物), 공산품(工産品), 공중볼(空中_), 공책(空冊), 과녁, 과염소산(過鹽素酸), 관(管), 관물(官物), 관소금(官__), 관인(官印), 구슬, 군수물자(軍需物資), 그물망(__網), 근영(近影), 금괴(金塊), 금박(金箔), 금속활자(金屬活字), 금품(金品), 기계강(機械鋼), 기물(器物), 기성품(旣成品), 기와, 기치군물(旗幟軍物), 깔개, 꼭두각시, 나프탈렌(naphthalene), 낙서(落書), 낙인(烙印), 낚싯밥, 냅킨(napkin), 널빤지, 네모고리, 놀이기구(__器具), 농약(農藥), 누비이불, 눈사람, 단주(短珠), 담배불씨, 담요(<U+6BEF>_), 당좌(當座), 덩이거름, 덮개, 도미노(domino), 동판(銅板), 두엄, 뒷거름, 드라이아이스(dry ice), 등피(燈皮), 디스크(disk), 라벨(label), 랩(wrap), 레이스(lace), 레코드(record), 렌즈(lens), 립스틱(lipstick), 링(ring), 마네킹(mannequin), 마대(麻袋), 막대, 망사(網紗), 매장사료(埋藏飼料), 매트(mat), 먹, 멍석, 메밀가루, 면사(綿絲), 명주(明紬), 명패(名牌), 명함(名銜), 모르타르(mortar), 모포(毛布), 모피(毛皮), 목곽(木槨), 목마(木馬), 목발(木_), 목침(木枕), 무가산(無價散), 문패(門牌), 물건(物件), 물기먹이, 물물(物物), 물품(物品), 밀가루, 밑거름, 반도체(半導體), 반죽, 반창고(絆瘡膏), 방사선사진(放射線寫眞), 방송매체(放送媒體), 방탄벽(防彈壁), 백(白), 범종(梵鍾), 베개, 베이스(base), 병풍(屛風), 보료, 본설계도(本設計圖), 불씨, 비닐(vinyl), 비단(緋緞), 비료(肥料), 비품(備品), 빨래, 사진(寫眞), 사향(麝香), 산욕(産褥), 상(床), 생산물(生産物), 생필품(生必品), 샴푸(shampoo), 석제(石製), 석판(石板), 선향(線香), 세공품(細工品), 세트(set), 셀로판(cellophane), 셀룰로이드(celluloid), 소다(soda), 소방대상물(消防對象物), 솜, 솜이불, 수납인(收納印), 수돗물(水道_), 수라상(水剌床), 스티커(sticker), 스프링(spring), 슬라이드(slide), 시렁, 식용유(食用油), 신보(新譜), 신주(神主), 실낱, 실몽당이, 실체(實體), 실크(silk), 실타래, 싸개, 아교(阿膠), 아크릴라이트(acrylite), 아크릴레이트(acrylite), 안장(鞍裝), 안테나(antenna), 알콜(alcohol), 약(藥), 양달력(洋_曆), 양이온계면활성제(陽__界面活性劑), 양탄자(洋__), 연(鳶), 영정(影幀), 예술품(藝術品), 왁스(wax), 왕골방석(__方席), 왕골베개, 외양간두엄(__間__), 요, 요지경(瑤池鏡), 용품(用品), 우단(羽緞), 우표(郵票), 원반(圓盤), 원통(圓筒), 위패(位牌), 유리(琉璃), 유약(釉藥), 육성테이프(肉聲___), 육아용품(育兒用品), 융단(絨緞), 은막(銀幕), 은박(銀箔), 음반(音盤), 응원용품(應援用品), 의수(義手), 의식(衣食), 의식주(衣食住), 이부자리, 이불, 인감(印鑑), 인공신장(人工腎臟), 인공지능(人工知能), 인공지하수(人工地下水), 인장(印章), 인주(印朱), 인테리어(interior), 인형(人形), 자개, 잡화(雜貨), 장대(長_), 장막(帳幕), 장판(壯版), 전신사진(全身寫眞), 전지(電池), 제기, 제품(製品), 조립장난감(組立___), 졸(卒), 종(鐘), 종이비행기(__飛行機), 좌판(座板), 주물(鑄物), 중후(中候), 직물(織物), 짚동, 차일(遮日), 차표(車票), 총알구멍(銃___), 카펫(carpet), 캘린더(calendar), 커튼(curtain), 탈색제(脫色劑), 테두리, 트럼프(trump), 트로피(trophy), 판넬(panel), 판자(板子), 패널, 페인트칠(paint_), 포장(包裝), 포켓(pocket), 폭죽(爆竹), 표백제(漂白劑), 풀솜, 품목(品目), 풍선(風船), 프레파라트(praparat), 필름(film), 필지(筆紙), 함석, 합금(合金), 행주, 향(香), 향수(香水), 향촉(香燭), 현물(現物), 현판(懸板), 화환(花環), 회초리, 휘장(揮帳) </p>  #### 신체착용물 <p class="message"> 가면(假面), 가발(假髮), 가스마스크(gas mask), 각반(脚絆), 갑옷(甲_), 갑주(甲胄), 갓, 골무, 군장(軍裝), 굴레, 귀걸이, 글러브(glove), 기저귀, 꼬까, 대님, 도롱이, 돋보기안경(___眼鏡), 띠, 마스크(mask), 마패(馬牌), 망건(網巾), 머플러(muffler), 베일(veil), 사자가면(獅子假面), 삿갓, 샅바, 선글라스(sunglass), 손가락장갑(___掌匣), 숄(shawl), 수경(水鏡), 숙녀복(淑女服), 스카프(scarf), 신사복(紳士服), 쓰개치마, 안경(眼鏡), 안대(眼帶), 어깨걸이, 의관(衣冠), 의대(衣帶), 의상(依裳), 장갑(掌匣), 정조대(貞操帶), 종이광대, 지가면(紙假面), 철갑(鐵甲), 콘돔(condom), 콘택트렌즈(contact lens), 탈, 탈바가지, 토시, 패드(pad), 팬티스타킹(panty stocking), 포대기 </p> 옷 <p class="message"> 가래단속곳(__單__), 가운(gown), 갖저고리, 개구멍바지, 개금셔츠(開襟__), 개량복(改良服), 거들치마, 검도복(劍道腹), 곁마기, 고어스커트(gore skirt), 고쟁이, 관복(官服), 교복(校服), 군복(軍服), 금갑(金甲), 깃고대, 까치설빔, 꼴담장, 남루(襤褸), 내복(內服), 내의(內衣), 넝마, 노랑회장저고리(__回裝___), 노타이(no tie), 누더기, 니트(knit), 다홍치마(_紅__), 단복(團服), 단체복(團體服), 대례복(大禮服), 도량창옷(道場__), 도복(道服), 도포(道袍), 동복(冬服), 두루마기, 드레스(dress), 란제리(란제리), 러닝셔츠(running shirt), 마고자, 망토(manteau), 메리야스, 모피코트(毛皮__), 미니(mini), 미니스커트(miniskirt), 바바리(Burberry), 바바리코트(burberry coat), 바지, 바지저고리, 반회장저고리(半回裝___), 배내옷, 백의(白衣), 법의(法衣), 베적삼, 브래지어(brassiere), 블라우스(blouse), 비늘갑옷(__甲_), 비키니(bikini), 빔, 사복(私服), 삼베옷, 삼회장저고리(三回裝_), 상복(喪服), 상의(上衣), 설빔, 설빔옷, 성의(聖衣), 셔츠(shirt), 소복(素服), 속곳, 속옷, 수의(壽衣), 스웨터(sweater), 스커트(skirt), 슬립(slip), 아랫도리, 아랫도리옷, 양복(洋服), 여름옷, 여벌(餘_), 여성복(女性服), 예복(禮服), 오버(overcoat), 옷, 옷가지, 와이셔츠(white shirt), 외출복(外出服), 외투(外套), 우비(雨備), 웃옷, 원피스(one piece), 위생복(衛生服), 유니폼(uniform), 유아동복(乳兒童服), 의류(衣類), 의복(衣服), 일벌일습(一_一襲), 자켓(jacket), 작업복(作業服), 잠바(jumper), 잠방이, 잠수복(潛水服), 잠옷, 장미색제의(薔薇色祭衣), 장삼(長衫), 장옷, 재킷(jacket), 저고리, 적삼, 점퍼(jumper), 정복(正服), 정장(正裝), 제복(制服), 조끼, 조끼허리, 조끼허리통치마, 조복(朝服), 주름치마, 중의(中衣), 청바지(靑__), 추석빔(秋夕_), 치마, 치마저고리, 코트(coat), 쾌자(快子), 트레이닝팬츠(training pants), 티셔츠(T-shirts), 파자마(pajamas), 판타롱(판타롱), 팬츠(pants), 팬티(panties), 페티코트(petticoat), 평복(平服), 피복(被服), 하복(夏服), 하의(下衣), 한복(韓服), 홈패션(home fashion) </p> 모자 <p class="message"> 건(巾), 고깔, 금관(金冠), 남바위, 너울, 두건(頭巾), 말총갓, 머리쓰개, 머릿수건(__手巾), 모자(帽子), 밀짚모자(__帽子), 바가지모자(___帽子), 방한모(防寒帽), 배감투, 벙거지, 보닛(bonnet), 상모(象毛), 쓰개, 왕관(王冠), 운동모자(運動帽子), 전립(戰笠), 족두리, 중절모(中折帽), 중절모자(中折帽子), 철모(鐵帽), 탕건(宕巾), 투구, 헬멧(helmet), 화관(花冠) </p> 패용물 <p class="message"> 가락지, 건국훈장(建國勳章), 견장(肩章), 고무벨트(__belt), 금배지(金__), 넥타이(necktie), 노리개, 댕기, 도투락, 말머리꾸미개, 메달(medal), 멜빵, 명찰(名札), 목가면(木假面), 목걸이, 바늘집노리개, 반지(斑指), 방울, 배지(badge), 벨트(belt), 복대(腹帶), 브로치(brooch), 비녀, 수나비노리개(繡_____), 앞줄댕기, 액세서리(accessory), 약혼반지(約婚斑指), 양말대님(洋襪__), 염주(念珠), 완장(腕章), 장신구(裝身具), 전대(纏帶), 족두리잠(___簪), 타대(拖帶), 패물(佩物), 핀(pin), 허리끈, 허리띠, 혁대(革帶) </p> 신 <p class="message"> 가죽신, 검정가죽신, 고무신, 고무신짝(gomme__), 구두, 군화(軍靴), 길목버선, 꽃대신, 나막신, 농구화(籠球靴), 단화(短靴), 덧신, 미투리, 부츠(boots), 샌들(sandal), 스케이트(skate), 스키(ski), 스타킹(stockings), 슬리퍼(slippers), 신, 신발, 운동화(運動靴), 워커(walker), 장화(長靴), 짚신, 코고무신(_gomme_), 평나막신(平___), 헌신짝 </p> 양말 <p class="message"> 버선, 양말(洋襪), 오목다리, 타이츠(tights) </p> #### 교통기관 <p class="message"> 가마, 대중교통(大衆交通), 상행(上行), 세발자전거(__自轉車), 수상항공기(水上航空機), 승강기(昇降機), 썰매, 자동차(自動車), 해운(海運) </p> 육상교통기관 <p class="message"> 견인기관차(牽引機關車), 경운기(耕耘機), 경차(輕車), 관광버스(觀光__), 광차(鑛車), 구조불차(救助_車), 궤도차량(軌道車輛), 꽃가마, 냉방차(冷房車), 달구지, 덤프트럭(dump truck), 리무진(limousine), 리어카(rear car), 마차(馬車), 봉고(bongo), 불도저(bulldozer), 뺑소니차(___車), 사이클(cycle), 소달구지, 소방자동차(消防自動車), 소방차(消防車), 손수레, 수레, 스쿠터(scooter), 스쿨버스(school bus), 승용차(乘用車), 승합자동차(乘合自動車), 앰뷸런스(ambulance), 어가(御駕), 역마(驛馬), 오토바이(auto+bicycle), 옴니버스(omnibus), 위반차량(違反車輛), 이륜차(二輪車), 인력거(人力車), 일반차량(一般車輛), 자가용(自家用), 자전거(自轉車), 장갑자동차(裝甲自動車), 장갑차(裝甲車), 장의차(葬儀車), 전기자동차(電氣自動車), 중고자동차(中古自動車), 지게차(__車), 지프(jeep), 차(車), 차량(車輛), 철갑차(鐵甲車), 트랙터(tractor), 트럭(truck), 트레일러(trailer), 트로이카(troika), 포장마차(布帳馬車), 화학소방차(化學消防車) </p> (1) 대중교통기관 <p class="message"> 개인택시(個人__), 고속버스(高速__), 노선버스(路線__), 모범택시(模範__), 버스(bus), 셔틀버스(shuttle bus), 시내버스(市內__), 시외버스(市外__), 우등고속(優等高速), 일반버스(一般__), 총알택시(銃___), 택시(taxi), 트레일러버스(trailerbus) </p> 가. 철도교통기관 <p class="message"> 국철(國鐵), 급행(急行), 급행열차(急行列車), 기차(汽車), 내연기관차(內燃機關車), 시가전차(市街電車), 야간열차(夜間列車), 여객차(旅客車), 열차(列車), 완행(緩行), 완행열차(緩行列車), 전동차(電動車), 전차(電車), 전철(電鐵), 증기기관차(蒸氣機關車), 지하철(地下鐵), 직통열차(直通列車), 철마(鐵馬), 화차(火車) </p> 수상교통기관 <p class="message"> 객선(客船), 경비정(警備艇), 곤돌라, 군함(軍艦), 기선(汽船), 나룻배, 뗏목(_木), 모선(母船), 목선(木船), 무장상선(武裝商船), 방주(方舟), 범선(帆船), 병선(兵船), 보트(boat), 본선(本船), 선박(船舶), 선편(船便), 수송선(輸送船), 어선(漁船), 여객선(旅客船), 연락선(連絡船), 외국배(外國_), 요트(yacht), 원양어선(遠洋漁船), 원자력잠수함(原子力潛水艦), 유람선(遊覽船), 유조선(油槽船), 이보트(E-boat), 잠수함(潛水艦), 전함(戰艦), 중선(重船), 철갑선(鐵甲船), 카누(canoe), 카약(kayak), 쾌속정(快速艇), 폐선(廢船), 함상(艦上), 해적선(海賊船), 호수기선(湖水汽船), 화물선(貨物船) </p> 공중교통기관 <p class="message"> 군용비행기(軍用飛行機), 글라이더(glider), 민간여객기(民間旅客機), 민간항공기(民間航空機), 비행기(飛行機), 소리개차(___車), 수송기(輸送機), 여객기(旅客機), 우주선(宇宙船), 인공위성(人工衛星), 인력비행기(人力飛行機), 전투기(戰鬪機), 제트기(jet_), 폭격기(爆擊機), 항공(航空), 항공기(航空機), 행글라이더(hang-glider), 헬기(hel_), 헬리콥터(helicopter) </p> #### 용기 <p class="message"> 가마니, 가방, 갑(匣), 고배(苦杯), 곽, 구유, 굽다리바리, 궤짝(櫃_), 그릇, 그릇그릇, 글라스(glass), 김장독, 꾸러미, 꿀단지, 놋그릇, 놋대야, 눈깔바구니, 다기(茶器), 단지, 담뱃갑(__匣), 대야, 대접, 도가니, 도기(陶器), 도반(桃盤), 도시락, 도자(陶瓷), 도자기(陶瓷器), 독, 독배(毒杯), 동이, 되, 둥우리, 뒤주, 드럼통(drum_), 망, 망태기, 목기(木器), 물통(_桶), 박스(box), 발노구, 밥공기(_空器), 밥그릇, 백자(白磁), 보시기, 보자기, 비커(beaker), 살통주머니(_筒___), 삼태기, 상자(箱子), 성냥갑(__匣), 세숫대야(洗手__), 소금가마, 소두(小斗), 소주병(燒酒甁), 소쿠리, 수조(水槽), 수통(水筒), 술병(_甁), 술잔(_盞), 시루, 신선로(神仙爐), 쌈지, 쓰레기봉투(___封套), 쓰레받기, 액자(額子), 약병(藥甁), 약봉지(藥封紙), 양푼, 연적(硯滴), 영구(靈柩), 옹기(甕器), 요강, 욕조(浴槽), 원자로(原子爐), 유기(鍮器), 유발(乳鉢), 은주전자(銀酒煎子), 음성사서함(音聲私書函), 자루, 자루바가지, 잔(盞), 장독(醬_), 재떨이, 쟁반(錚盤), 제구(祭具), 종지, 주머니, 주발(周鉢), 주전자(酒煎子), 주형(鑄型), 죽기(竹器), 쪽박, 차합(茶盒), 찬합(饌盒), 찻잔(茶盞), 책보(冊褓), 철기(鐵器), 철통(鐵桶), 청자(靑瓷|靑磁), 초롱, 칠기(漆器), 침통(鍼筒), 칫솔갑(齒_匣), 캔(can), 캡슐(capsule), 컨테이너(container), 컵(cup), 타구(唾具), 탕기(湯器), 탱크(tank), 터주항아리(_主缸__), 토기(土器), 틀, 팩(pack), 포대(布袋), 포트(port), 프라이팬(frypan), 함(函), 함지박, 항아리(缸__), 핸드백(handbag), 향로(香爐), 화분(花盆), 화수분 </p> 그릇 <p class="message"> 가마솥, 계량컵(計量_), 광구발(廣口鉢), 광주리, 군불솥, 굽잔(_盞), 기명(器皿), 냄비, 묵사발(_沙鉢), 물감그릇, 바구니, 바리, 반합(飯盒), 밥솥, 사발(沙鉢), 성배(聖杯), 성합(聖盒), 세발솥, 소반(小盤), 솥, 식기(食器), 옥쟁반(玉錚盤), 옹기그릇(甕器__), 유리컵(琉璃_), 저자망태(__網_), 접시, 종이컵(--cup), 찬그릇(饌), 청동기(靑銅器), 코펠(kocher), 홉되, 화덕(火-), 화로(火爐) </p> 통 <p class="message"> 깔때기홈통(____桶), 깡통(_筒), 돼지저금통(__貯金筒), 물동이, 밥통(_桶), 분필통(粉筆桶), 쓰레기통(___桶), 저금통(貯金筒), 통(桶), 필통(筆筒), 휴지통(休紙桶) </p> 병 <p class="message"> 호롱 </p> 항아리 <p class="message"> 술독 </p> 주머니 <p class="message"> 바랑, 봉지(封紙), 봉투(封套), 부대(負袋), 신발주머니, 염낭(_囊), 옆착, 지갑(紙匣) </p> 가방 <p class="message"> 걸망(_網), 괴나리봇짐, 배낭(背囊), 새들백(saddlebag), 손가방, 쇼핑백(shopping bag), 책가방(冊__), 트렁크(trunk) </p> #### 상자 <p class="message"> 궤(櫃), 금고(金庫), 금궤(金櫃), 사서함(私書函), 석곽(石槨), 석관(石棺), 순찰함(巡察函), 우편사서함(郵便私書函), 적재함(積載函) </p> #### 동물집 <p class="message"> 봄고치, 새둥주리, 어항(魚缸) </p> #### 소지품 <p class="message"> 봉(棒), 부케(bouquet), 손거울, 손수건(_手巾), 장죽(長竹) </p> #### 가구 <p class="message"> 가구(家具), 강대(講臺), 개다리소반(___小盤), 개수대(__臺), 걸상(_床), 경대(鏡臺), 더블베드(double bed), 등가구(藤家具), 등교의(藤交椅), 문갑(文匣), 밥상(_床), 벤치(bench), 새살림, 서가(書架), 선반, 세간, 세간살이, 소파(sofa), 술상(_床), 식상(食床), 식탁(食卓), 안락의자(安樂椅子), 앉은뱅이책상(____冊床), 옷장(_欌), 원탁(圓卓), 의자(椅子), 장롱(欌籠), 저녁상(__床), 진열장(陳列欌), 집기(什器), 찬장(饌欌), 책상(冊床), 침대(寢臺), 침상(寢牀), 칸막이(間__), 캐비넷(cabinet), 탁자(卓子), 테이블(table), 평상(平牀), 행거(hanger), 회전의자(回轉椅子), 흔들의자(__椅子) </p> #### 기기 <p class="message"> 광섬유(光纖維), 교육자재(敎育資材), 교육장비(敎育裝備), 기기(器機), 기재(器材), 뇌관(雷管), 등불(燈_), 디스켓(diskette), 땡땡이, 벨(bell), 보안장치(保安裝置), 시설(施設), 실린더(cylinder), 안전면도기(安全面刀器), 의료기기(醫療器機), 이기(利器), 자동번역기(自動飜譯機), 자동지급기(自動支給期), 장비(裝備), 장애용품(障碍用品), 장치(裝置), 지퍼(zipper), 진자(振子), 트랜지스터(transistor), 풍로(風爐), 풍차(風車), 헤드폰(headphone), 화투짝(花鬪_) </p> 도구 <p class="message"> 가루뿌리개, 가마니바늘, 가스라이터(gaslighter), 가위, 가전제품(家電製品), 가지가위, 갈고리, 갈퀴, 강판(薑板), 개머리쇠, 개상반(_床盤), 거북이자물쇠, 건전지(乾電池), 걸이, 계단격자(階段格子), 곡괭이, 곤봉(棍棒), 곤장(棍杖), 골남비, 골패(骨牌), 공구(工具), 공이, 괭이, 구둣주걱, 구멍돌도끼, 국자, 귀거울, 귀마개옥(___玉), 그물, 극망원경(極望遠鏡), 긁개, 금수안장(錦繡鞍裝), 기구(器具), 길마, 깔때기, 꼬챙이, 꽃가위, 꽃상여(_喪輿), 꾐등불(_燈_), 끈고리, 끈끈이, 끌, 끌쟁기, 나무가위, 나사(螺絲), 낙하산(落下傘), 낚시, 낚시바늘, 낚시받침대, 낚싯대, 낚싯바늘, 남날개, 낫, 너트(nut), 네트(net), 노(櫓), 녹음테이프(錄音___), 놋수저, 놋젓가락, 농기구(農器具), 눈가리개, 눈썰매, 닻, 대걸레(大__), 대궐반(大闕盤), 대나무못, 대롱, 대패, 덫, 도구(道具), 도끼, 도르래, 도리깨, 도마, 돋보기, 돼지목매, 두레박, 드라이버(driver), 드릴(drill), 따옴표(__表), 때수건(_手巾), 라이터(lighter), 롤러(roller), 리모콘(리모콘), 릴(reel), 마른걸레, 마치, 만년필(萬年筆), 말머리가리개, 망원경(望遠鏡), 망치, 매직(magic), 면도기(面刀器), 면회흙손(面灰__), 모루, 모필(毛筆), 목탁(木鐸), 못, 몽둥이, 무논써레, 묵주(默珠), 문진(文鎭), 물감판(__板), 물걸레, 물때표(__表), 물뿌리개, 밀대, 바늘, 바람막이, 바리캉(bariquant), 바위긁개, 바인더(binder), 반달돌칼(半___), 반사경(反射鏡), 받침대(__臺), 받침목(__木), 발돌줄, 밤송이솔, 밥숟가락, 밥숟갈, 방망이, 방아, 방안칠판(方眼漆板), 방추(方錐), 배터리(battery), 백묵(白墨), 벼루, 벼훑이, 보습, 본드(bond), 볼트(bolt), 볼펜(ball pen), 봉인(封印), 부메랑(boomerang), 부목(副木), 부지깽이, 부채, 북채, 분무기(噴霧器), 분첩(粉貼), 분필(粉筆), 불갈고리, 붓, 붕대(繃帶), 붕어자물쇠, 비누, 비행기대패(飛行機__), 빗, 빗자루, 빗장, 빛느낌재개, 사다리, 사슬문고리(__門__), 사슴뿔장식(___粧飾), 사인펜(signpen), 사포(沙布), 살문향(殺蚊香), 삿대, 상보(床褓), 상여(喪輿), 새끼발, 샤워기(shower_), 샤프(sharp), 샤프펜슬(sharp pencil), 서진(書鎭), 석기(石器), 석쇠(炙_), 석연(石硯), 석필(石筆), 성냥, 성냥개비, 세면도구(洗面道具), 세숫비누(洗手__), 세정제(洗淨劑), 세제(洗劑), 세척제(洗滌劑), 세필(細筆), 소꿉, 소도구(小道具), 소독저(消毒_), 소등나팔(消燈喇叭), 속돌매, 송곳, 송곳망치, 쇠고리, 쇠구슬, 쇠끌개, 쇠사슬, 수갑(手匣), 수건(手巾), 수도꼭지(水道__), 수력방적기(水力紡績機), 수세미, 수신안테나(受信___), 수저, 수판(數板), 순간접착제(瞬間接着劑), 숟가락, 숟갈, 숫돌, 스펀지(sponge), 스푼(spoon), 스프레이(spray), 슬리핑백(sleeping bag), 시추기(試錐機), 시험대(試驗臺), 신골방망이, 신문철(新聞綴), 신석기(新石器), 실, 실감개, 실패, 써레, 쏘시개, 쐐기, 쑤시개, 아교풀(阿膠_), 안전벨트(安全__), 암나사(_螺絲), 압정(狎釘), 압지(狎紙), 양끝못(兩__), 양날망치(兩___), 어구(漁具), 어망(漁網), 얼레, 여과기(濾過器), 연결고리(連結__), 연꽃끌(蓮__), 연장, 연필(鉛筆), 연필깎이(鉛筆__), 열쇠, 열쇠고리, 오른나사(__螺絲), 올가미, 올무, 옷걸이, 용구(用具), 용수철(__鐵), 우산(雨傘), 움직도르래, 위상차현미경(位相差顯微鏡), 윷놀이채찍, 이쑤시개, 이젤(easel), 인두, 자갈돌석기(___石器), 자료화면(資料畵面), 자물쇠, 작살, 장도리, 장어통발(長魚__), 재갈, 쟁기, 쟁기지게, 저(箸), 절구, 절구통(__桶), 접착제(接着劑), 접착테이프(接着___), 정파리경(淨頗梨鏡), 조리, 족쇄(足鎖), 족집게, 주걱, 주사위, 주판(籌板), 줄, 줄눈흙손, 줄풀부채, 지게, 지목(支木), 지우개, 지팡이, 직인(職印), 집게, 집속자석(集束磁石), 집속코일(集束__), 찌, 채찍, 천체망원경(天體望遠鏡), 청진기(聽診器), 체, 초크(chalk), 촉매(觸媒), 촛대(_臺), 축구공(蹴球_), 취사도구(炊事道具), 침구(寢具), 침낭(寢囊), 칫솔(齒_), 컴퍼스(compass), 콤파스(compass), 클립(clip), 탄산가스소화기(炭酸__消火器), 테이프(tape), 톱, 톱날나사(__螺絲), 톱날낫, 톱니가위, 튜브(tube), 파레트(파레트), 파이프(pipe), 팔레트(팔레트), 펜(pen), 펜촉(pen_), 펜치(pincers), 포크(fork), 풀무, 퓨즈(fuse), 프리즘(prism), 플라스크(flask), 피스톤(piston), 핀셋(pincette), 필(筆), 필기도구(筆記道具), 필라멘트(filament), 해달벼루, 현미경(顯微鏡), 형광표백제(螢光漂白劑), 호루라기, 호미, 호스(hose), 호치키스(Hotchkiss), 홍단(紅短), 홍두깨, 화가투(花歌鬪), 화투(花鬪), 화판(畵板), 화폭(畵幅), 활자(活字), 후궁목소(_宮木_), 휘슬(whistle) </p> (1) 측정도구 <p class="message"> 가스계량기(gas___), 관되(官_), 광물현미경(鑛物顯微鏡), 눈금대롱, 눈금자, 눈압력재개(_壓力__), 목판되(木版_), 수은기압계(水銀氣壓計), 안개상자(__箱子), 압력저울(壓力__), 액체온도계(液體溫度計), 용수철저울(__鐵__), 자, 자리상재개(__相__), 저울, 전기계량기(電氣計量器), 전기저항온도계(電氣抵抗溫度計), 천칭(天秤), 체적계(體積計), 측량기계(測量器械) </p> (2) 칼 <p class="message"> 과도(果刀), 나이프(knife), 대도(大刀), 돌날몸돌, 돌날핵(__核), 메스(mes), 바이트(bite), 배코칼, 비수(匕首), 식칼(食_), 작두(斫刀), 장도(粧刀), 죽도(竹刀), 칼 </p> (3) 줄 <p class="message"> 고무줄, 금줄(金_), 끄나풀, 끈, 동아줄, 로프(rope), 리본(ribbon), 무명실, 밧줄, 빨랫줄, 사슬, 새끼, 새끼줄, 색노끈(色__), 색실(色_), 연결선(連結線), 연줄(鳶_), 오라, 자일(자일), 전선(電線), 지게꼬리, 철사(鐵絲), 철조(鐵條), 체인(chain), 코드(cord), 코일(coil), 털실, 포승(捕繩) </p> (4) 칠감 <p class="message"> 그리스(grease), 금물(金_), 누렁, 니스(nisu), 도료(塗料), 먹물, 물감, 법랑(琺瑯), 색소(色素), 색연필(色鉛筆), 수묵(水墨), 수성페인트(水性paint), 안료(顔料), 야광물감(夜光__), 에나멜(enamel), 염료(染料), 옻, 잉크(ink), 크레용(crayon), 크레파스, 튜브물감(tube__), 파스텔(pastel), 페인트(paint), 합성물감(合成__), 화감청(花紺靑) </p> (5) 푸는도구 <p class="message"> 모종삽, 바가지, 삽, 삽가래, 젓가락, 티스푼(tea spoon) </p> 기구 <p class="message"> 가스레인지(gas range), 경적(警笛), 경종(警鐘), 경첩, 고가사다리(高架___), 곤로, 공, 괘종(掛鐘), 괘종시계(掛鐘時計), 굴렁쇠, 그네, 난로(暖爐), 당구대(撞球臺), 딱총, 라켓(racket), 마구(馬具), 마우스(mouse), 맷돌, 멍에, 메가폰(megaphone), 물레방아, 미끄럼틀, 바람개비, 바벨(barbell), 바통(bU+00E2;ton), 배트(bat), 백구(白球), 보일러(boiler), 블라인드(blind), 뺑뺑이, 셔틀콕(shuttlecock), 소독기(消毒器), 소변기(小便器), 소켓(socket), 소화기(消火器), 속구(速球), 쇠고랑, 순간온수기(瞬間溫水器), 스틱(stick), 아령(啞鈴), 야구공(野球_), 야구방망이(野球___), 양궁(洋弓), 양산(陽傘), 역기(力器), 역도(力道), 연감개(鳶__), 오뚜기, 왜건(wagon), 윷, 의료기(醫療器), 장난감, 전기담요(電氣담_), 죽부인(竹夫人), 채, 쳇바퀴, 콘센트, 탁구공(卓球_), 투전(鬪錢), 팽이, 평균대(平均臺), 폴(pole), 해머(hammer), 홍보매체(弘報媒體) </p> (1) 전기전자기구 <p class="message"> 가전(家電), 공중전화기(公衆電話機), 김치냉장고(__冷藏庫), 난방기구(煖房器具), 냉방기(冷房機), 냉장고(冷藏庫), 녹음기(錄音器), 녹즙기(綠汁機), 다리미, 두꺼비집, 드라이어(dryer), 라디오(radio), 레이저(laser), 레인지(range), 멀티비전(multivision), 벽전화기(壁電話器), 브라운관(Braun_), 사진복사기(寫眞複寫器), 선풍기(扇風機), 세탁기(洗濯機), 수압기(水壓機), 스테레오라디오(stereo radio), 스토브(stove), 스피커(speaker), 아이시라디오(IC radio), 앰프(amplifier), 에어컨(air conditioner), 오븐(oven), 유성기(留聲機), 인터폰(interphone), 저음확성기(低音擴聲器), 전자제품(電子製品), 전축(電蓄), 진공관(眞空管), 충전기(充電器), 카세트(cassette), 텔레비전(television), 텔레비전수상기(television___), 토스터(toaster), 팬(fan) </p> (2) 조명기구 <p class="message"> 가로등(街路燈), 꼬마전구, 등잔(燈盞), 등잔불(燈盞_), 라이트(light), 랜턴(lantern), 램프(lamp), 방향지시등(方向指示燈), 백랍초(白蠟_), 샹들리에(chandelier), 석등(石燈), 손전등(_電燈), 스탠드(stand), 알코올램프(alcohol lamp), 양각등(羊角燈), 양초(洋_), 연등(燃燈), 육각등(六角燈), 잔등(殘燈), 재개등(__燈), 전구(電球), 전등(電燈), 집중조명(集中照明), 플래시(flash), 형광등(螢光燈), 환등(幻燈) </p> 기계 <p class="message"> 가스스토브(gas stove), 가습기(加濕器), 감시카메라(監視___), 검색엔진(檢索__), 계량기(計量器), 계산기(計算器), 공기청정기(空氣淸淨器), 공작기계(工作機械), 공중전화(公衆電話), 관측기(觀測器), 광석라디오(鑛石___), 광석확성기(鑛石擴聲器), 교류라디오수신기(交流___受信機), 교류수신기(交流受信機), 교환기(交換機), 금속탐지기(金屬探知機), 기계(機械), 기관(機關), 난방(暖房), 농기계(農機械), 누전차단기(漏電遮斷器), 단말기(端末機), 단파수신기(短波受信機), 닻감개, 도청기(盜聽機), 땜질발전기(__發電機), 레이더(radar), 로봇(robot), 로켓(rocket), 마이크(mike), 모니터(monitor), 모터(motor), 무자위, 무전기(無電機), 물레, 믹서(mixer), 바이킹(Viking), 반도체집적회로(半導體集積回路), 발신기(發信機), 발전기(發電機), 방적기(紡績機), 버너(burner), 보안시스템(保安___), 삐삐, 사진기(寫眞機), 손목시계(__時計), 수상기(受像機), 수신기(受信機), 슈퍼컴퓨터(supercomputer), 스캐너(scanner), 스테레오(stereo), 시계(時計), 시내전화(市內電話), 에스컬레이터(escalator), 엔진(engine), 엘리베이터(elevator), 연탄보일러(煉炭___), 열교환기(熱交換器), 열기구(熱氣球), 용광로(鎔鑛爐), 워드프로세서(word processor), 워키토키(walkie-talkie), 원자력엔진(原子力__), 위성계산기(衛星計算機), 위성컴퓨터(衛星___), 유도발전기(誘導發電機), 유선전화(有線電話), 음성송신기(音聲送信機), 음성타자기(音聲打字機), 이동전화(移動電話), 인공호흡기(人工呼吸器), 일반전화(一般電話), 자격루(自擊漏), 자동판매기(自動販賣機), 자명종(自鳴鐘), 자판(字板), 자판기(自販機), 재봉틀(裁縫_), 전기계산기(電氣計算器), 전력계량기(電力計量器), 전신기(電信機), 전자계산기(電子計算器), 전화(電話), 전화기(電話機), 전화통(電話筒), 정밀기기(精密器機), 제초기(除草器), 주변계산기(周邊計算機), 중장비(重裝備), 첩보위성(諜報衛星), 초음파풍속계(超音波風速計), 촬영기(撮影機), 침공사진기(針孔寫眞機), 카드판독기(card___), 카메라(camera), 캐터펄트(catapult), 컴퓨터(computer), 콤바인(combine), 크랭크(crank), 크레인(crane), 타이프(type), 타자기(打字機), 탁상시계(卓上時計), 탈곡기(脫穀器), 터빈(turbine), 트랜스(transformer), 팩시밀리(facsimile), 펌프(pump), 폴라로이드(polaroid), 프레스(press), 프린터(printer), 하드웨어(hardware), 핸드폰(handphone), 현금인출기(現金引出機), 현금지급기(現金支給機), 회계기(會計機), 히터(heater) </p> #### 무기 <p class="message"> 대인지뢰(對人地雷), 둔기(鈍器), 명궁(名弓), 무기(武器), 방패(防牌), 병기(兵器), 사냥활, 생물학무기(生物學武器), 소이무기(燒夷武器), 유탄(流彈), 전략핵무기(戰略核武器), 전술핵무기(戰術核武器), 전역핵무기(戰域核武器), 전쟁가스(戰爭__), 중폭격기(重爆擊機), 지뢰(地雷), 철퇴(鐵槌), 첨단무기(尖端武器), 총검(銃劍), 탄도(彈道), 탄약(彈藥), 탄창(彈倉), 탄피(彈皮), 포탄(砲彈), 폭약(爆藥), 폭탄(爆彈), 핵무기(核武器), 화살, 화약(火藥), 화염병(火焰甁), 활, 흉기(凶器) </p> 총포 <p class="message"> 경기관총(輕機關銃), 고사포(高射砲), 권총(拳銃), 기관총(機關銃), 남포, 대포(大砲), 미사일(missile), 선회기관총(旋回機關銃), 소이산탄(燒夷散彈), 소총(小銃), 쌍권총(雙拳銃), 야포(野砲), 어뢰(漁雷), 엽총(獵銃), 장님총(__銃), 장총(長銃), 조총(鳥銃), 총(銃), 총기(銃器), 총포(銃砲), 탄알(彈_), 탄환(彈丸), 포(砲), 함포(艦砲), 화포(火砲) </p> 칼창 <p class="message"> 검(劍), 단검(短劍), 단도(短刀), 대검(大劍), 도검(刀劍), 보검(寶劍), 소도(小刀), 쌍칼(雙_), 죽창(竹槍), 창검(槍劍), 총칼(銃_) </p> 탄환 <p class="message"> 사냥화살, 산탄(霰彈), 수류탄(手榴彈), 시한폭탄(時限爆彈), 실탄(實彈), 에이치봄(H-bomb), 원자탄(原子彈), 원자폭탄(原子爆彈), 원폭(原爆), 유도탄(誘導彈), 직격탄(直擊彈), 총알, 총탄(銃彈), 최루탄(催淚彈), 축포(祝砲), 탄도미사일(彈道___) </p> #### 약 <p class="message"> 고약(膏藥), 구감초(灸甘草), 구급약(救急藥), 내용가루약(內用__藥), 단방약(單方藥), 모르핀(morphine), 묘약(妙藥), 민간약(民間藥), 방울눈약(___藥), 백신(vaccine), 보약(補藥), 부스럼떡, 사후피임약(事後避妊藥), 살충제(殺蟲劑), 생약(生藥), 선약(仙藥), 소독약(消毒藥), 소삐고약, 수면제(睡眠劑), 승마갈근탕(升麻葛根湯), 신약(新藥), 아스피린(aspirin), 안정제(安靜劑), 약제(藥劑), 약품(藥品), 연고(軟膏), 우황청심환(牛黃淸心丸), 의약(醫藥), 의약물(醫藥物), 의약품(醫藥品), 이담약(利膽藥), 좌약(坐藥), 진정제(鎭靜劑), 청량제(淸凉劑), 최면제(催眠劑), 치약(齒藥), 탈모제(脫毛劑), 탕약(湯藥), 파상풍혈청(破傷風血淸), 파스(파스), 페니실린(penicillin), 페니실린우유(penicillin__), 한방약(韓方藥), 한약(韓藥), 항균물질(抗菌物質), 항생제(抗生劑), 해열제(解熱劑), 헤로인(heroin), 환(丸), 환약(丸藥) </p> #### 독약 <p class="message"> 극약(劇藥), 독약(毒藥), 사약(賜藥) </p> #### 마약 <p class="message"> 마약(麻藥), 아편(阿片), 코카인(cocaine) </p> #### 악기 <p class="message"> 사죽(絲竹), 손건반(_鍵盤), 악기(樂器), 오르골(orgel), 풀잎피리, 호드기 </p> 현악기 <p class="message"> 가야금(伽倻琴), 가얏고(伽倻__), 거문고, 기타(guitar), 바이올린(violin), 비올라(viola), 비파(琵琶), 아쟁(牙箏), 쟁(箏), 첼로(cello), 하프(harp), 해금(奚琴) </p> 관악기 <p class="message"> 고음나팔(高音喇叭), 금관악기(金管樂器), 나발, 나팔(喇叭), 날라리, 단소(短簫), 대금(大芩　), 목관(木管), 색소폰(saxophone), 클라리넷(clarinet), 퉁소(洞簫), 트럼펫(trumpet), 트롬본, 플루트(flute), 플룻, 피리, 피리젓대, 하모니카(harmonica), 행군나팔(行軍喇叭), 호른(horn) </p> 타악기/건반악기 <p class="message"> 꽹과리, 드럼(drum), 만종(晩鐘), 북, 실로폰(xylophone), 심벌즈(cymbals), 장고(杖鼓), 장구, 징, 탬버린(tambourine) </p> (1) 건반악기 <p class="message"> 건반악기(鍵盤樂器), 오르간(organ), 키보드(keyboard), 풍금(風琴), 피아노(piano) </p> #### 미술작품 <p class="message"> 명필(名筆), 모빌(mobile), 모자이크(mosaic), 미술공예품(美術工藝品), 미술도안(美術圖案), 미술품(美術品), 벽화(壁畵), 소품(小品), 수예품(手藝品), 족자(簇子) </p> 회화 <p class="message"> 고화(古畵), 그림, 녹화머리초(綠花__草), 도안(圖案), 드로잉(drawing), 명화(名畵), 목각화(木刻畵), 바위벽그림(__壁__), 사냥그림, 삽화(揷畵), 서화(書畵), 소묘(素描), 수묵화(水墨畵), 수채화(水彩畵), 스케치(sketch), 양화(洋畵), 유화(油畵), 정면도(正面圖), 채화(彩畵), 청사진(靑寫眞), 초상화(肖像畵), 크로키(크로키), 탱화(幀畵), 판화(版畵), 풍경화(風景畵) </p> 조소 <p class="message"> 목각(木刻), 목상(木像), 석고상(石膏像), 조각상(彫刻像) </p> #### 설치물 <p class="message"> 경수로(輕水爐), 관광시설(觀光施設), 농구대(籠球臺), 높이뛰기기둥, 말뚝, 묘석(墓石), 바리케이드(barricade), 발판(_板), 방장(房帳), 변기(便器), 보루(堡壘), 봉토(封土), 사형대(死刑臺), 수족관(水族館), 스크린(screen), 시상대(施賞臺), 시설물(施設物), 시소(seesaw), 신호등(信號燈), 실험대(實驗臺), 싱크대(sink_), 연단(演壇), 이동통신(移動通信), 인터넷(internet), 입원시설(入院施設), 칠판(漆板), 텐트(tent), 파라솔(parasol), 해먹(hammock), 후경(後景) </p> 조형물 <p class="message"> 구조물(構造物), 금부처(金__), 기념비(紀念碑), 남대문(南大門), 다보탑(多寶塔), 담장(_墻), 돌각담, 돌사람돌말, 묘(墓), 묘비(墓碑), 묘소(墓所), 묘지(墓地), 벽돌아치(U+7513;___), 변두리기둥, 불상(佛像), 비석(碑石), 석불(石佛), 석비(石碑), 석상(石像), 석탑(石塔), 열녀문(烈女門), 옹관묘(甕棺墓), 우상(偶像), 입석(立石), 장승, 제단(祭壇), 종각(鐘閣), 종루(鐘樓), 철탑(鐵塔), 첨탑(尖塔), 추모비(追慕碑), 추모탑(追慕塔), 타워(tower), 탑(搭), 토우(土偶), 퉁부처, 피라미드(pyramid), 허수아비 </p> 시설물 <p class="message"> 게시판(揭示板), 공공시설물(公共施設物), 구들, 난간(欄干), 내선(內線), 놀이시설(__施設), 다다미, 대롱물길, 덕가리, 목책(木柵), 물꼬, 발전소(發電所), 배관(配管), 벽난로(壁煖爐), 상수도(上水道), 상하수도(上下水道), 생산라인(生産__), 설비(設備), 소화전(消火栓), 송전탑(送電塔), 수도(水道), 수채, 숙박시설(宿泊施設), 시궁창, 안전시설(安全施設), 온돌(溫突), 우물, 유선(有線), 유선케이블(有線___), 유아시설(乳兒施設), 의료시설(醫療施設), 인터체인지(interchange), 자동계단(自動階段), 전봇대(電報_), 전화박스(電話__), 접속선(接續線), 주거시설(住居施設), 철책(鐵柵), 초고속인터넷(超高速___), 케이블(cable), 탁구대(卓球臺), 텔레비전네트워크(television network), 토관(土管), 통신망(通信網), 통신케이블(通信___), 페치카(pechka), 플라이(fly), 홰, 회로(回路), 회선(回線) </p> 시설망 <p class="message"> 감시시스템(監視___), 네트워크(net work), 시외전화(市外電話), 안전망(安全網), 온라인(online), 전산망(電算網), 포위망(包圍網) </p> 표지판 <p class="message"> 도로이정표(道路里程標), 도로표지판(道路標識板), 도표(道標), 벽보판(壁報板), 안내전광판(案內電光板), 안내판(案內板), 안내표지판(案內標識板), 야광표지판(夜光標識板), 전면간판(全面看板), 토론게시판(討論揭示板), 푯대(標_), 플래카드(placard), 현수막(懸垂幕) </p> 저장시설 <p class="message"> 제방(堤防) </p> #### 소프트웨어 <p class="message"> 검색시스템(檢索___), 데이터베이스(database), 메일서버(mail server), 소프트웨어(software), 홈페이지(home page) </p> #### 돈 <p class="message"> 가계비(家計費), 개평, 거금(巨金), 거스름돈, 거액(巨額), 결산잔금(決算殘金), 곗돈, 고금리(高金利), 공금(公金), 공수표(空手票), 공채(公債), 국고(國庫), 금화(金貨), 급전(急錢), 기금(基金), 단일통화(單一通貨), 달러(dollar), 대가(代價), 매각대금(賣却代金), 목돈, 미군불(美軍弗), 밑천, 박봉(薄俸), 법정통화(法定通貨), 선일자수표(先日字手票), 수출선수금(輸出先受金), 쌈짓돈, 억만금(億萬金), 엔화(엔_), 외화(外貨), 외환(外換), 용돈(用_), 원금(元金), 원화(_貨), 은화(銀貨), 인지(印紙), 자금(資金), 자본(資本), 자산(資産), 잔고(殘高), 잔금(殘金), 잔돈푼, 잔액(殘額), 적금(積金), 적립금(積立金), 전액(全額), 절값, 정액(定額), 주머니밑천, 지원보초(至元寶?), 지참금(持參金), 차익(差益), 천금(千金), 축의금(祝儀金), 출자액(出資額), 토큰(token), 통화(通貨), 통화요금(通話料金), 프랑(프랑), 피물돈(皮物_), 현금(現金), 현금통화(現金通貨), 현찰(現札), 화폐(貨幣), 환어음(換__) </p> 주화 <p class="message"> 동전(銅錢), 열쇠돈, 엽전(葉錢), 주화(鑄貨) </p> 지폐 <p class="message"> 위조지폐(僞造紙幣), 지폐(紙幣) </p> 유가증권 <p class="message"> 도서상품권(圖書商品券), 마권(馬券), 수표(手票), 어음, 여행자수표(旅行者手票), 왕복권(往復券), 왕복항공권(往復航空券), 유가증권(有價證券), 자유이용권(自由利用權), 장외주식(場外株式), 전쟁공채(戰爭公債), 주식(株式), 즉석복권(卽席福券), 증권(證券), 채권(債券), 쿠폰(coupon), 통행권(通行券), 티켓(ticket), 할인쿠폰(割引_), 횡선수표(橫線手票) </p> 카드 <p class="message"> 교통카드(交通__), 신용카드(信用__), 전화카드(電話__), 제휴카드(提携__) </p> #### 담배 <p class="message"> 궐련(卷煙), 담배꽁초, 양담배(洋__), 잎담배 </p> #### 음식 <p class="message"> 가당연유(加糖煉乳), 가락국수, 가루우유(__牛乳), 간식(間食), 강정, 개고기, 갱엿, 건강말(乾薑末), 고명, 고지, 곤쟁이젓, 곰탕(_湯), 공깃밥, 과자(菓子), 관식(官食), 국, 국국물, 국물, 국물김치, 국수, 군량(軍糧), 굴비, 굴비찌개, 굴튀김, 김치, 깡보리밥, 깨강정, 깻묵, 껌(gum), 꽁보리밥, 끼니, 낙산물(酪産物), 날것, 냉동육(冷凍肉), 냉장육(冷藏肉), 녹말(綠末), 누가(누가), 누룽지, 눈깔사탕, 다시, 다시맛국, 다식(茶食), 다이어트식(diet_), 달걀, 당면(唐麵), 대용식(代用食), 더운밥, 도넛(doughnut), 도래목정, 두부(豆腐), 디저트(dessert), 떡가래, 떡고추장(___醬), 라면(ramen), 마가린(margarine), 마른안주(__按酒), 마카로니(마카로니), 만두(饅頭), 먹거리, 먹을거리, 면류(麵類), 명란(明卵), 무침, 묵, 묵장물(_醬_), 미숫가루, 밀기울, 박하사탕(薄荷砂糖), 반기, 반찬, 밥, 밥알, 밥풀강정, 밥풀과자(__菓子), 백반(白飯), 범벅, 별미(別味), 별식(別食), 보리밥, 북어포(北魚脯), 분식(粉食), 뷔페(buffet), 비스킷(biscuit), 비오리사탕(___砂糖), 비지, 비짓국, 사리, 사식(私食), 사탕, 새알사탕(__沙糖), 새우젓찌개, 생사탕(生蛇湯), 생선묵튀김(生鮮___), 설렁탕(__湯), 성찬(盛饌), 세찬(歲饌), 소, 소박이, 소시지(sausage), 소찬(素饌), 수라(水刺), 수수개떡, 수수밥, 수수풀떡, 순대, 순대찜, 순두부(_豆腐), 순두부찌개(_豆腐__), 순쌀밥(純__), 술국밥, 술안주(_按酒), 식량(食糧), 식품(食品), 식품첨가물(食品添加物), 쌀밥, 쌈, 쑥갓나물, 쑥갓쌈, 아이스크림(ice cream), 아침밥, 안줏거리(按酒__), 약과(藥果), 약대구(藥大口), 양갱(羊羹), 여물, 연약밥(軟藥__), 엿, 엿가락, 영계백숙, 오곡밥(五穀_), 오뎅(오뎅), 완자, 우무, 유제품(乳製品), 육수(肉水), 음식(飮食), 음식물(飮食物), 이유식(離乳食), 일식(日食), 자반, 잡곡밥(雜穀_), 장국냉면(醬_冷麵), 장국죽(醬_粥), 잼(jam), 저녁밥, 전병(煎餠), 점심(點心), 정식(定食), 제수(祭需), 젤리(jelly), 조반(朝飯), 조석(朝夕), 조식(朝食), 조청(造淸), 족발(足_), 죽(粥), 중식(中食), 중화(中火), 진미(珍味), 진수성찬(珍羞盛饌), 진지, 짠지, 찌게, 찬(饌), 찬밥, 청포(淸泡), 초코렛, 초콜렛, 초콜릿(chocolate), 치킨(chicken), 칠첩반상(七), 캔디(candy), 커피(coffee), 크래커(cracker), 특식(特食), 팝콘(popcorn), 팥가루, 팥고물, 팥밥, 팥죽(_粥), 편의식품(便宜食品), 폐백(弊帛), 푸딩(pudding), 피클(pickle), 한식(韓食), 햄(ham), 햄버거(hamburger), 호박잎쌈, 호식(好食), 회(膾), 후식(後食), 흑설탕(黑雪糖) </p> 음료 <p class="message"> 감주(甘酒), 과일즙(__汁), 과즙(果汁), 냉차(冷茶), 녹차(綠茶), 드링크(drink), 무수다(無水茶), 밀크(milk), 분유(粉乳), 블랙커피(black coffee), 사이다(cider), 생강즙(生薑汁), 생즙(生汁), 수정과(水正果), 숭늉, 시럽(syrup), 식수(食水), 식혜(食醯), 아이스커피(ice coffee), 엽차(葉茶), 우유(牛乳), 원두커피(原豆__), 음료(飮料), 음료수(飮料水), 인삼차(人蔘茶), 주스(juice), 청량음료(淸凉飮料), 코코아(cocoa), 콜라(cola), 포도즙(葡萄汁), 호모우유(homo__), 홍차(紅茶) </p> (1) 알콜음료 <p class="message"> 고량주(高粱酒), 곡주(穀酒), 공술(空_), 과실주(果實酒), 독주(毒酒), 동동주(__酒), 럼(rum), 막걸리, 맥주(麥酒), 밀주(密酒), 배갈(白干;0-513F;), 배꽃술, 보드카(vodka), 보리막걸리, 브랜디(brandy), 생맥주(生麥酒), 샴페인(champagne), 선술, 세주(歲酒), 소주(燒酒), 송별주(送別酒), 술, 스카치위스키(Scotch whisky), 약주(藥酒), 양조주(釀造酒), 양주(洋酒), 와인(wine), 위스키(whiskey), 이강주(梨薑酒), 적포도주(赤葡萄酒), 정종(正宗), 청주(淸酒), 축배(祝杯), 칵테일(cocktail), 코냑(cognac), 탁주(濁酒), 포도주(葡萄酒), 폭탄주(爆彈酒), 해장술(解), 화주(火酒) </p> 떡 <p class="message"> 감자떡, 경단(瓊團), 고려밤떡(高麗__), 떡, 메시루떡, 메찰떡, 모태, 밀개떡, 백설기, 송편(松_), 시루떡, 쑥개피떡, 쑥인절미, 오방떡(大判_), 인절미, 절편, 증편(蒸_), 칡뿌리떡 </p> 빵 <p class="message"> 꽈배기, 빵(빵), 식빵(食_), 카스테라, 카스텔라, 케이크(cake), 토스트(toast), 파이(pie) </p> 발효식품 <p class="message"> 김칫국, 깍두기, 담해저(淡 菹), 된장(_醬), 메주, 멸치젓, 명란젓(明卵_), 미역귀김치, 밀기울된장(____醬), 새우젓, 소금깍두기, 열무김치, 장(醬), 젓, 젓갈, 조개젓, 집메주, 치즈(cheese) </p> 양념 <p class="message"> 가는소금, 간, 간장(-醬), 건장(乾醬), 고추양념, 고추장(_醬), 고춧가루, 기름, 기름소금, 깨, 누룩, 단간장(__醬), 드레싱(dressing), 마요네즈(마요네즈), 면실유(棉實油), 버터(butter), 별간장(別_醬), 볕소금, 사카린(saccharin), 설탕(屑糖), 소금, 소스(sauce), 식물성유(植物性油), 식초(食醋), 아미노산간장(amino___), 양념, 조미료(調味料), 참기름, 찹쌀고추장(____醬), 초(醋), 카레(curry), 케첩(ketchup), 통후추, 향료(香料), 화학조미료(化學調味料), 후추, 후춧가루(胡椒__) </p> 요리 <p class="message"> 갈비탕(__湯), 개떡수제비, 게감정, 게구이, 고기구이, 고추장볶이(__醬__), 곰국, 광어무침(廣魚__), 구이, 국밥, 기스면(鷄絲麵), 김밥, 깨죽, 꼬치구이, 냉면(冷麵), 냉채(冷菜), 녹두부침개(綠豆___), 녹두전(綠豆煎), 다시마튀각, 닭고기무침, 닭곰탕(__湯), 닭죽(_粥), 대구구이(大口__), 대구찌개(大口__), 덮밥, 동치미, 된장찌개, 두부껍질비빔(豆腐____), 두부장국(豆腐醬_), 등골백숙(__白熟), 등꽃나물(藤___), 따로국밥, 떡갈비, 떡볶이, 로스구이(roast__), 마늘잎조림, 만두소찌개(饅頭___), 맛살백숙(__白熟), 매운탕(__湯), 맹물탕(__湯), 무리떡국, 밀국수, 바베큐(barbecue), 바비큐(barbecue), 백숙(白熟), 부침, 부침개, 불고기, 비둘기구이, 샌드위치(sandwitch), 샐러드(salad), 생채(生菜), 서양요리(西洋料理), 소갈비구이(素____), 소머리편육(__片肉), 수란(水卵), 수육(_肉), 수제비, 수프(soup), 숯불갈비, 스테이크(steak), 스파게티(spaghetti), 쌈밥, 야채샐러드(野菜___), 양고기죽(羊__粥), 연어두부(<U+9C31>魚豆腐), 오이지무침, 육개장(肉_醬), 자장면(炸醬麵), 잡채(雜菜), 잡탕(雜湯), 장떡(醬_), 장아찌, 전(煎), 전골, 전복죽(全鰒粥), 전채(前菜), 제육볶음(_肉__), 조림, 족편(足_), 지단(鷄蛋), 짜장면, 짬뽕(짬뽕), 찌개, 찜, 첫국밥, 청포묵(淸泡_), 초밥(醋_), 콩국, 콩밥, 쿠키(cookie), 탕(湯), 탕국(湯_), 탕수육(糖水肉), 통닭, 튀김, 틀국수, 파전(_煎), 피자(pizza), 함흥냉면(咸興冷麵), 핫도그(hot dog), 화채(花菜) </p> #### 텍스트담지물 텍스트담지물이란 텍스트를 담지할 목적으로 만든 구체인공물입니다. <p class="message"> 가이드북(guidebook), 간접광고(間接廣告), 간행물(刊行物), 게시물(揭示物), 견출지(見出紙), 결석계(缺席屆), 계획서(計劃書), 공개장(公開狀), 광고전단지(廣告傳單紙), 괘도(掛圖), 괘지(罫紙), 교과서(敎科書), 교지(校誌), 국방백서(國防白書), 국서(國書), 국어사전(國語辭典), 그림일기(__日記), 그림책(__冊), 그림파일(_file), 기관지(機關紙), 기네스북(the Ginness Book), 꼬리표(__票), 노비문서(奴婢文書), 노트(note), 논고장(論告狀), 단어장(單語帳), 단자(單子), 달력(_曆), 답변서(答辯書), 답안지(答案紙), 답지(答紙), 당적(黨籍), 대자보, 대차대조표(貸借對照表), 도감(圖鑑), 도록(圖錄), 도면(圖面), 도서(圖書), 동화책(童話冊), 등본(謄本), 만장(輓章), 만화(漫畵), 매뉴얼(manual), 목판(木版), 문건(文件), 문서(文書), 문집(文集), 물금체(勿禁帖), 밀서(密書), 백과사전(百科辭典), 백서(白書), 법전(法典), 벽보(壁報), 병적기록부(兵籍記錄簿), 보고문(報告文), 본보(本報), 봉서(封書), 부적(符籍), 비자(visa), 삐라(삐라), 사보(社報), 사증(査證), 사진첩(寫眞帖), 사표(辭表), 산질본(散秩本), 상품매매장(商品賣買帳), 서류철(書類綴), 서책(書冊), 석간(夕刊), 석간신문(夕刊新聞), 선집(選集), 설화집(說話集), 성가집(聖歌集), 소논문(小論文), 소설책(小說冊), 소송기록(訴訟記錄), 소환장(召喚狀), 송년호(送年號), 수배전단(手配傳單), 수첩(手帖), 수험표(受驗票), 스냅(snap), 스케치북(sketchbook), 스크랩북(scrapbook), 시사월간지(時事月刊誌), 시사주간지(時事週刊誌), 시험지(試驗紙), 신간(新刊), 신간서적(新刊書籍), 악보(樂譜), 안내서(案內書), 암표(暗票), 앨범(album), 여성지(女性紙), 연습장(練習帳), 연재만화(連載漫畵), 연하장(年賀狀), 엽서(葉書), 영어사전(英語辭典), 영한사전(英韓辭典), 예금통장(預金通帳), 예산서(豫算書), 옥편(玉篇), 외출증(外出證), 요청서(要請書), 우대권(優待券), 월급명세서(月給明細書), 위임장(委任狀), 위촉장(委囑狀), 유인물(油印物), 응시원서(應試願書), 이정표(里程表), 익명게시판(匿名揭示板), 인명사전(人名事典), 인쇄매체(印刷媒體), 인쇄물(印刷物), 일간신문(日刊新聞), 일기장(日記帳), 일반우편(一般郵便), 일일식단(一日食單), 임명장(任命狀), 자기소개서(自己紹介書), 자녀안(恣女案), 자료집(資料集), 자습서(自習書), 장문전보(長文電報), 장서(藏書), 전개도(展開圖), 전단(傳單), 전표(傳票), 전화번호부(電話番號簿), 접수증(接受證), 정기간행물(定期刊行物), 정본(正本), 조간신문(朝刊新聞), 조커(joker), 족보(族譜), 종이신문(__新聞), 종합일간지(綜合日刊紙), 주민등록등본(住民登錄謄本), 주민등록초본(住民登錄抄本), 주민등록카드(住民登錄__), 주보(週報), 지석(誌石), 지진기상(地震記象), 지침서(指針書), 지형도(地形圖), 차림표(__表), 참고서(參考書), 창간호(創刊號), 책력(冊曆), 책자(冊子), 천연색사진(天然色寫眞), 첨부양식(添附樣式), 첨부파일(添附__), 청원서(請願書), 청첩장(請牒狀), 초대권(招待券), 초청장(招請狀), 총계정원장(總計定元帳), 총서(叢書), 출금전표(出金傳票), 출납증(出納證), 출입증(出入證), 치부책(置簿冊), 카탈로그, 칼라필름(color film), 투표용지(投票用紙), 파일(file), 판결문(判決文), 판본(板本), 팜플렛, 패스(pass), 팸플릿(pamphlet), 편람(便覽), 편지틀(便紙_), 포스터(poster), 표찰(標札), 학보(學報), 학습장(學習帳), 학적(學籍), 허위자료(虛僞資料), 현금출납장(現金出納帳), 호외(號外), 홍보비디오(弘報___), 화집(畵集), 화첩(畵帖), 활자본(活字本), 회지(會誌), 흑판(黑板) </p> #### 자재 <p class="message"> 벽돌(?_), 수자원(水資源), 알매흙, 원자재(原資材) </p> 목재 <p class="message"> 널, 목재(木材), 생소나무(生___), 송판(松板), 판목(版木) </p> 금속재 <p class="message"> 강철(强鐵), 금속(金屬), 레일(rail), 쇠붙이, 양은(洋銀), 양철(洋鐵), 연강(鍊鋼), 철강(鐵鋼), 철근(鐵筋), 철망(鐵網), 철물(鐵物), 철봉(鐵棒), 철판(鐵板), 청동(靑銅) </p> 석재 <p class="message"> 규산벽돌(硅酸?_), 방석(方石), 보도블록(步道__), 색대리석(色大理石), 석재(石材), 석조(石造), 석회(石灰), 세라믹(ceramics), 시멘트(cement), 용마루장식(___裝飾), 타일(tile) </p> 화학자재 <p class="message"> 백랍(白;U+0-945E랍), 아스팔트(asphalt), 아크릴(acrylic), 젤라틴(gelatin), 폴리에틸렌(polyethylene), 플라스틱(plastic), 피로인산(pyro__), 화합물(化合物) </p> #### 연료 <p class="message"> 공기건전지(空氣乾電池), 대체에너지(代替___), 대체휘발유(代替揮發油), 목탄(木炭), 액체연료(液體燃料), 연료(燃料), 장작(長斫) </p> 석유 <p class="message"> 나프타(naphta), 등유(燈油), 유류(油類) </p> 가스 <p class="message"> 고체탄산가스(固體炭酸__) </p> 고체연료 <p class="message"> 숯, 연탄(煉炭), 장작개비, 장작더미(長斫__), 조개탄, 화촉(華燭) </p> #### 천 <p class="message"> 강보(襁褓), 견사(絹紗), 광목(廣木), 구가목(驅價木), 깁, 나일론(nylon), 마포(麻布), 모시, 모직(毛織), 무명, 베, 보(褓), 삼베, 색동(色_), 섬유(纖維), 순면(純綿), 순모(純毛), 안동포(安東布), 앙고라(Angora), 오팔(opal), 옥양목(玉洋木), 옷감, 옷감가지, 천, 침대보(寢臺褓), 캔버스(canvas), 펠트(felt), 포목(布木), 플란넬(flannel), 피륙 </p> #### 종이 <p class="message"> 갱지(更紙), 골판지(_板紙), 닥종이, 먹지(_紙), 모눈종이, 모조지(模造紙), 백지(白紙), 색종이(色__), 습자지(習字紙), 신문지(新聞紙), 양지(洋紙), 원고지(原稿紙), 인쇄용지(印刷用紙), 장판지(壯版紙), 종이, 쪽지, 창호지(窓戶紙), 파지(破紙), 판지(板紙), 한지(韓紙), 화장지(化粧紙), 휴지(休紙) </p> #### 화장품 <p class="message"> 곤지, 로션(lotion), 매니큐어(manicure), 무스(mousse), 선크림(suncream), 스킨(skin), 썬크림(suncream), 파우더(powder), 파운데이션(foundation), 포마드(pomade), 햇볕차단제(_遮斷製), 화장품(化粧品) </p> #### 기 <p class="message"> 고기비늘연(____鳶), 교기(校旗), 국기(國旗), 기치(旗幟), 깃발, 백기(白旗), 태극기(太極旗) </p> ### 속성구체물 **속성구체물**이란 특정한 속성을 비교적 지속적으로 가지는 구체물을 가리킵니다. <p class="message"> 가리개, 가표(可票), 견본(見本), 결혼예물(結婚禮物), 경품(景品), 곤마(困馬), 과립(顆粒), 관광자원(觀光資源), 광원(光源), 군더더기, 군용품(軍用品), 균열(龜裂), 금테(金_), 기차표(汽車票), 끝물, 뇌물(賂物), 눈요깃감(_僚飢_), 다듬이, 단골메뉴(__menu), 덤, 도체(導體), 두루마리, 떨기, 막대기, 매물(賣物), 매체(媒體), 멍울, 메이커(maker), 모델(model), 물증(物證), 물컹이, 뭉텅이, 미끼, 민속자료(民俗資料), 방부제(防腐劑), 변종(變種), 별것(別_), 별종(別種), 보푸라기, 부동산(不動産), 부스러기, 부의(賻儀), 부조(扶助), 분말(粉末), 분진(粉塵), 붕괴감마선(崩壞__線), 붙박이목표(___目標), 사체(死體), 상품(商品), 생활필수품(生活必需品), 소비재(消費材), 소지품(所持品), 소집영장(召集令狀), 수공품(手工品), 수산물(水産物), 수입농산물(輸入農産物), 수제(手製), 수집물(蒐集物), 수확물(收穫物), 습득물(拾得物), 시료(試料), 시제품(試製品), 신상품(新商品), 실경(實景), 실용품(實用品), 심해퇴적물(深海堆積物), 십자가(十字架), 십장생(十長生), 애물(愛物), 에이스(ace), 오브제(오브제), 옵션(option), 완구(緩球), 외상술, 요깃거리(療飢__), 원시안(遠視眼), 유산(遺産), 유아동용품(乳兒童用品), 유아용품(乳兒用品), 유품(遺品), 은메달(銀__), 일엽편주(一葉片舟), 입선작(入選作), 잉여생산물(剩餘生産物), 자국, 자선냄비(慈善__), 자양(滋養), 자양분(滋養分), 자연산(自然産), 재물(財物), 재생품(再生品), 재활용품(再活用品), 저당물(抵當物), 전시물(展示物), 전유물(專有物), 전형(典型), 정기물(定期物), 정표(情表), 제물(祭物), 졸고(拙稿), 졸저(拙著), 준비물(準備物), 증거방법(證據方法), 지경돌(地境_), 집게고리, 철권(鐵拳), 체질안료(體質顔料), 초구(初球), 최종생산물(最終生産物), 출토품(出土品), 출판물(出版物), 측면도(側面圖), 퇴비(堆肥), 표식(標識), 필수품(必需品), 혈흔(血痕), 혼수(婚需), 혼수품(婚需品), 홍보물(弘報物), 홑겹, 휴대품(携帶品), 희귀본(稀貴本) </p> #### 시간속성구체물 시간에 의해 그 속성이 규정되는 구체물입니다. <p class="message"> 고물(古物), 고전주의건축(古典主義建築), 고철(古鐵), 골동품(骨董品), 구석기(舊石器), 노구(老軀), 막차(_車), 새것, 신작(新作), 신판(新版), 신품(新品), 옛것, 유물(遺物), 유적(遺跡), 재고(在庫), 재고품(在庫品), 중고(中古), 처녀작(處女作), 첨가물(添加物), 첫술, 폐건전지(廢乾電池) </p> #### 지역속성구체물 지역에 의해 그 속성이 규정되는 구체물입니다. <p class="message"> 국산(國産), 국산품(國産品), 산물(産物), 수입품(輸入品), 외제(外製), 일본제(日本製), 토산(土産), 토산품(土産品), 특산(特産), 특산물(特産物) </p> #### 크기속성구체물 크기에 의해 그 속성이 규정되는 구체물입니다. <p class="message"> 거구(巨軀), 거목(巨木), 거봉(巨峯), 거포(巨砲), 국판(菊版), 몽당연필(__鉛筆), 뭉치, 박편(薄片), 쇼트커트(short cut), 어이, 어처구니, 억장(億丈), 장발(長髮), 통째 </p> #### 수량속성구체물 수량에 의해 그 속성이 규정되는 구체물입니다. <p class="message"> 곱빼기, 대설(大雪), 쌍발(雙發), 일루(一縷), 일말(一抹), 잉여(剩餘) </p> #### 긍정적속성구체물 긍정적 속성을 지니고 있는 구체물입니다. <p class="message"> 가보(家寶), 가치상품(價値商品), 걸작(傑作), 결혼선물(結婚膳物), 고가제품(高價製品), 고가품(高價品), 고급품(高級品), 국보(國寶), 군계일학(群鷄一鶴), 귀금속(貴金屬), 금메달(金__), 노작(勞作), 달필(達筆), 마스코트(mascot), 명기(名器), 명물(名物), 명약(名藥), 명저(名著), 명품(名品), 문화재(文化財), 미식(美食), 보물(寶物), 보배, 보화(寶貨), 서운(瑞雲), 선물(膳物), 신출귀물(新出貴物), 아미(蛾眉), 알짜, 애용품(愛用品), 영물(靈物), 영양물(營養物), 예물(禮物), 유기농산물(有機農産物), 유형문화재(有形文化財), 인격체(人格體), 장식품(裝飾品), 전곡(錢穀), 주옥(珠玉), 진귀품(珍貴品), 진본(眞本), 진솔, 진품(眞品), 천군만마(千軍萬馬), 천연기념물(天然記念物), 칠보(七寶), 특제(特製) </p> #### 부정적속성구체물 부정적 속성을 지니고 있는 구체물입니다. <p class="message"> 걸림돌, 구닥다리(舊___), 노폐물(老廢物), 담보(擔保), 독물(毒物), 맹탕(_湯), 사치품(奢侈品), 싸구려, 오발탄(誤發彈), 오염원(汚染源), 위폐(僞幣), 유독물질(有毒物質), 유해물(有害物), 음란물(淫亂物), 음란폭력물(淫亂暴力物), 음화(淫畵), 잡동사니(雜___), 장물(臟物), 장애물(障碍物), 졸작(拙作), 증거물(證據物), 촌지(寸志), 추물(醜物), 퇴물(退物), 폐물(廢物), 폐품(廢品) </p> #### 화물 인간이나 동물, 기타 운반 수단에 의해 운반되는 속성을 가진 구체물입니다. <p class="message"> 개별화물(個別貨物), 보따리(褓__), 보통우편물(普通郵便物), 보퉁이(褓__), 선물꾸러미(膳物___), 소포(小包), 수하물(手荷物), 우편물(郵便物), 이삿짐(移徙_), 짐, 짐짝, 행장(行裝), 화물(貨物) </p> #### 폐기물 <p class="message"> 생활쓰레기(生活___), 쓰레기, 오물(汚物), 오염물질(汚染物質), 유해폐기물(有害廢棄物), 음식쓰레기(飮食___), 음식찌꺼기(飮食___), 찌끼, 폐기물(廢棄物), 폐기용품(廢棄用品), 폐수(廢水), 폐유(廢油), 하수(下水) </p> #### 부산물 <p class="message"> 부산물(副産物), 잿더미, 쭉정이, 찌꺼기, 톱밥 </p> ### 관계구체물 **관계구체물**이란 다른 구체물에 대하여 일정한 관계에 놓여있는 구체물을 말합니다. <p class="message"> 개개(箇箇), 개체(個體), 건더기, 관물때(罐__), 광맥(鑛脈), 구둣발, 구판(舊版), 나머지, 내용(內容), 능, 들깻묵, 모체(母體), 모형(模型), 받침, 본(本), 부장품(副葬品), 사금파리, 사본(寫本), 사유재산(私有財産), 상위폴더(上位__), 상징물(象徵物), 상편(上篇), 상흔(傷痕), 샘플(sample), 셋째, 스페어(spare), 실물(實物), 알몸뚱이, 여체(女體), 예속물(隸屬物), 오리지널(original), 온몸, 완성품(完成品), 원작(原作), 원저(原著), 원전(原典), 위성(衛星), 육(肉), 육신(肉身), 음영(陰影), 이것저것, 일신(一身), 잔해(殘骸), 전매품(專賣品), 전자(前者), 전집(全集), 중간생산물(中間生産物), 증빙자료(證憑資料), 증표(證票), 징검돌, 촛농(_膿), 표적(表迹), 하권(下卷), 하편(下篇), 항체(抗體), 환원불꽃(還元__), 흔적(痕迹) </p> #### 부분 전체에 대한 부분의 관계로 파악될 수 있는 구체물입니다. <p class="message"> 가지, 겉, 결, 계좌(計座), 공기가슴(空氣__), 구성요소(構成要素), 굽다리, 귤껍질(橘__), 그루터기, 단면(斷面), 덩어리, 반반(半半), 반절(半折), 분절(分節), 빈칸, 상부(上部), 솥뚜껑, 수정체포(水晶體胞), 술구더기, 여분(餘分), 우익(右翼), 유전자(遺傳子), 이랑, 일각(一角), 일면(一面), 일부(一部), 일편(一片), 자투리, 절반(折半), 지류(支流), 철면(凸面), 초기화면(初期畵面), 측면(側面), 태초(太初), 토막, 파편(破片), 허리춤, 후부(後部) </p> 구체물의 부분 <p class="message"> 가게문(__門), 가장자리, 가죽, 갑문(閘門), 갑판(甲板), 거죽, 건반(鍵盤), 겉감, 계기판(計器板), 고동, 고리, 고의춤, 곡면(曲面), 골조(骨組), 교각(橋脚), 교문(校門), 구두끈, 구두창, 구멍, 구슬감기, 굴뚝, 귀걸이수화기(___受話器), 귀퉁이, 기단(基壇), 기둥, 기저(基底), 기축(機軸), 껍데기, 껍질, 꼬리손잡이, 꼭지, 꽁초, 끄트머리, 날, 날개바퀴, 날줄, 낫감기, 내벽(內壁), 내부장식(內部裝飾), 내화구조(耐火構造), 냄비뚜껑, 냉동실(冷凍室), 노즐(nozzle), 농구자루(農具__), 다락문, 다이얼(dial), 단, 단추, 단춧구멍, 대들보(大__), 대문(大門), 덧문(_門), 덮개돌, 도막, 도선(導線), 도어(door), 동강, 두레박줄, 두리기둥, 두부껍질(豆腐__), 뒷면(_面), 뒷문(_門), 들보, 등받이, 뚜껑, 띠살문(__門), 마개, 만전창살(卍田窓_), 말굽도리, 말굽서까래, 말기허리, 매듭, 매트리스(mattress), 머리끝금(___錦), 메모리(memory), 멜빵허리, 면(面), 모서리, 문(門), 문고리(門__), 문지방(門地枋), 문짝(門_), 문턱(門_), 물받이, 미늘, 미닫이, 미등(尾燈), 밑바닥, 바깥귀, 바대, 바람꼭지, 박차(拍車), 밥뚜껑, 방아쇠, 방아쇠울, 밭두둑, 배면(背面), 밸브(valve), 뱃집지붕, 버클(buckle), 버튼(button), 베갯모, 베어링(bearing), 벼리, 벽(壁), 벽면(壁面), 변죽(邊_), 병목(甁_), 본체(本體), 부분(部分), 부위(部位), 부품(部品), 붙박이날개, 비표(碑表), 사륜(四輪), 사립, 사립문(_門), 사면(四面), 상면(上面), 상부구조(上部構造), 새발심지, 서까래, 서랍, 서슬, 설주(_柱), 성문(城門), 세로줄눈, 세부(細部), 셔터(shutter), 소맷부리, 소자(素子), 속껍질, 손잡이, 손잡이문골(___門_), 솔가지, 송곳날, 솥이마, 쇠문짝(_門_), 수납공간(受納空間), 수문(水門), 수챗구멍, 수화기(受話器), 숟갈총, 스위치(switch), 스테인드글라스(stained glass), 시계바늘(時計__), 시곗바늘(時計__), 실밥, 심(心), 심지(心_), 쌍심지(雙心_), 아가리, 아치(arch), 안감, 안경다리(眼鏡__), 안경알(眼鏡_), 알갱이, 알맹이, 앞가리개, 양면(兩面), 얼룩, 여백(餘白), 연통(煙筒), 예봉(銳鋒), 오른쪽닻, 오지랖, 옥문(獄門), 올, 와이퍼(wiper), 외면(外面), 외벽(外壁), 우두머리, 우산대(雨傘_), 우산살(雨傘_), 원두은장(圓頭隱_), 원시땅껍질(原始___), 유리돌비늘(琉璃___), 유리창(琉璃窓), 은못촉(隱_鏃), 은장홈(隱__), 음극(陰極), 응어리, 이면(裏面), 이불속, 이슬마루, 이차감줄(二次__), 일단(一段), 일차감줄(一次__), 입자(粒子), 자동문(自動門), 자락, 자보(jabot), 자위, 잡티(雜_), 장구머리초(____草), 장지두꺼비집(障____), 정곡(正鵠), 조각, 조개껍질, 조리개눈금, 종단면(縱斷面), 좌익(左翼), 주발뚜껑(周鉢__), 주변기기(周邊機器), 주변장치(周邊裝置), 주추(柱礎), 지구기억장치(持久記憶裝置), 지붕, 지붕골판(___板), 지붕돌받침, 지축(支軸), 지침(指針), 진동, 진열창(陳列窓), 집적회로(集積回路), 쪼가리, 찌몸통, 차양(遮陽), 차축(車軸), 창, 창구(窓口), 창문(窓門), 창문턱(窓門_), 창문틀(窓門_), 창틀(窓_), 책갈피(冊__), 책장(冊張), 챙, 처마, 천장(天障), 천정(天井), 철골(鐵骨), 철문(鐵門), 철벽(鐵壁), 철창(鐵窓), 초석(礎石), 초침(秒針), 촉(鏃), 총개머리(銃___), 총구(銃口), 총신(銃身), 추(錘), 추녀, 축(軸), 출구(出口), 치맛자락, 칩(chip), 칸, 칸막이벽(間__壁), 칼날, 칼라(collar), 칼집붙이, 칼집아가리, 커버(cover), 쿠션(cushion), 클랙슨(klaxon), 클러치(clutch), 탁상(卓上), 탄두(彈頭), 탑신(塔身), 태엽(胎葉), 테, 토대(土臺), 토벽(土壁), 톱니, 톱니바퀴, 튜너(tuner), 페달(pedal), 페이지(page), 포문(砲門), 포신(砲身), 포판(砲板), 표면(表面), 표피(表皮), 프로세서(processor), 프로펠러(propeller), 플러그(plug), 핀트, 필터(filter), 하단(下段), 핸들(handle), 헤드(head), 현(弦), 현관문(玄關門), 호주머니(胡___), 홈, 화면(畵面), 환기통(換氣筒), 회벽(灰壁), 흠(欠) </p> (1) 의복의 부분 <p class="message"> 끝단, 끝동, 목가리개, 선단, 섶, 소매, 솔기, 시접, 옷고름, 옷깃, 옷자락, 창구멍, 치마폭(__幅), 후드(hood) </p> 신체부위 : 인간이나 동물의 신체의 부분입니다. <p class="message"> 가랑이, 가랭이, 가슴, 가슴근육(__筋肉), 가슴팍, 가슴패기, 각막(角膜), 각질(角質), 간뇌(肝腦), 간담(肝膽), 갈비, 감관(感官), 거스러미, 거웃, 검지(_指), 겨드랑, 겨드랑이, 견갑골(肩胛骨), 결막(結膜), 경혈(經穴), 곁아래, 고개, 고막(鼓膜), 고혈(膏血), 고환(睾丸), 골, 골격(骨格), 골격근(骨格筋), 골기질(骨基質), 골반(骨盤), 골수(骨髓), 골육(骨肉), 골치, 골통, 곰보, 관절(關節), 광대뼈, 광등뼈, 교감신경(交感神經), 국소(局所), 굳은살, 궁둥이, 귀, 귀싸대기, 귀청, 귓가, 귓구멍, 귓등, 근섬유초(筋纖維?), 근시안(近視眼), 근육(筋肉), 금발(金髮), 급소(急所), 기골(氣骨), 기관폐(氣管肺), 기본골격(基本骨格), 까까머리, 꺼풀, 끄덩이, 나룻, 나신(裸身), 나체(裸體), 남경(男莖), 남근(男根), 낯, 낯짝, 내이(內耳), 냉점(冷點), 넓적코, 뇌(腦), 뇌리(腦裏), 눈, 눈가, 눈깔, 눈꺼풀, 눈동자(_瞳子), 눈망울, 눈살, 눈시울, 눈썹, 눈알, 눈자위, 눈초리, 늑골(肋骨), 늑막(肋膜), 다리, 단순(丹脣), 단전(丹田), 당나귀뼈, 대가리, 대갈통, 대뇌(大腦), 대립유전자(對立遺傳子), 덜미, 동공(瞳孔), 동맥(動脈), 동체(胴體), 두(頭), 두개골(頭蓋骨), 두뇌(頭腦), 두발(頭髮), 두상(頭上), 두피(頭皮), 둔부(臀部), 뒤꿈치, 뒤통수, 뒷다리, 뒷머리, 등, 등골, 등골신경계(__神經系), 등뼈, 등줄기, 등짝, 등판, 디옥시리보핵산(deoxyribo__), 따귀, 땀구멍, 만면(滿面), 말초신경(末梢神經), 맛감각기관(_感覺器官), 망막(網膜), 맨발, 맨발바닥, 맨상투, 맨손, 맨손바닥, 맨주먹, 머리, 머리등골, 머리채, 머리카락, 머리칼, 머리털, 며느리발톱, 멱살, 면상(面上), 명치, 모가지, 모공(毛孔), 모발(毛髮), 모세혈관(毛細血管), 목, 목구멍, 목덜미, 목젖, 목줄띠, 목청, 몸, 몸뚱아리, 몸뚱이, 몸체(_體), 몸통, 무릎, 물개수염(__鬚髥), 미간(眉間), 미목(眉目), 밖넓적다리, 반신(半身), 발, 발가락, 발가락뼈, 발길, 발꿈치힘줄, 발끝, 발뒤꿈치, 발뒤꿈치힘줄, 발등, 발목, 발바닥, 발바닥뼈, 발톱, 밥줄샘, 배꼽, 배알, 배질세포(胚質細胞), 백골(白骨), 백발(白髮), 백혈구(白血球), 뱃속, 변경유전자(變更遺傳子), 보조개, 보지, 복근(腹筋), 복부(腹部), 볼, 볼기, 볼깃살, 부비강(副鼻腔), 부신피질(副腎皮質), 분문(糞門), 불알, 비강(鼻腔), 비듬, 뺨, 뼈, 뼈다귀, 뼈대, 뼉다귀, 사족(四足), 사지(四肢), 사타구니, 삭신, 살, 살갗, 살점(_點), 상반신(上半身), 상체(上體), 상투, 상판(相_), 샅, 새끼손가락, 새끼손톱, 새치, 생식기관(生殖器官), 생식세포(生殖細胞), 생체(生體), 선혈(鮮血), 설근(舌根), 섬모(纖毛), 성기(性器), 성대(聲帶), 성체(聖體), 세포(細胞), 속살, 손, 손가락, 손금, 손길, 손끝, 손등, 손목, 손바닥, 손발, 손발톱, 손뼉, 손아귀, 손톱, 솜털, 송장, 쇄골(鎖骨), 수염, 수족(手足), 수중(手中), 숨골, 숨길, 숨통(_筒), 시상하부(視床下部), 시신(屍身), 시신경(視神經), 시체(屍體), 식도(食道), 식지(食指), 신경(神經), 신경계(神經系), 신경중추(神經中樞), 신병(身柄), 신체(身體), 심근(心筋), 심신(心身), 쌍수(雙手), 씹, 아랫니, 아랫배, 아랫입술, 안구(眼球), 안귀신경(__神經), 안면(顔面), 알몸, 앞가슴, 앞니, 약지, 양각(兩脚), 양손(兩_), 어금니, 어깨, 어깻죽지, 어안, 억압유전자(抑壓遺傳子), 얼굴짝, 엄지, 엄지손가락, 엉덩이, 연골(軟骨), 영구치(永久齒), 옆갈비, 옆구리, 옆장칼(_掌_), 오금, 오른발, 오른손, 오른팔, 왼발, 왼손, 용안(龍顔), 우황(牛黃), 운동뉴론(運動__), 운동신경(運動神經), 웃통, 원순(圓脣), 위팔동맥(__動脈), 윗몸, 유골(遺骨), 유골조직(類骨組織), 유두(乳頭), 유미(柳眉), 유방(乳房), 유해(遺骸), 육안(肉眼), 육체(肉體), 음경(陰莖), 음낭(陰囊), 음모(陰毛), 음부(陰部), 음핵(陰核), 이, 이마, 이마빡, 이목구비(耳目口鼻), 이뿌리막(___膜), 이소골(耳小骨), 인대(靭帶), 인생계급장(人生階級章), 인중(人中), 일손, 입, 입가, 입술, 입천장, 잇몸, 자지, 장딴지, 장지(長指), 전병코(煎餠_), 전신(全身), 전안방(前眼房), 점막(粘膜), 정강이, 정강이뼈, 정맥(靜脈), 정맥혈(靜脈血), 정수리(頂__), 정충(精蟲), 젖가슴, 젖꼭지, 종아리, 좆, 주둥이, 주름, 주먹, 주먹코, 죽지, 줄기세포(__細胞), 줌, 중이(中耳), 진피(眞皮), 쪽, 척수(脊髓), 척추(脊椎), 청, 청각기관(聽覺器官), 체내(體內), 체모(體毛), 치골(恥骨), 치모(恥毛), 치아(齒牙), 치열(齒列), 치조(齒槽), 코, 코빼기, 콧구멍, 콧대, 콧등, 콧수염, 태(胎), 태내(胎內), 터럭, 턱, 턱밑, 턱살밑, 턱활뼈, 털, 판막(瓣膜), 팔, 팔꿈치, 팔다리, 팔뚝, 팔목, 편도선(扁桃腺), 포경(包莖), 품속, 품안, 피골(皮骨), 피부(皮膚), 피질(皮質), 피하(皮下), 핏줄, 하반신(下半身), 하복부(下腹部), 하지(下肢), 하체(下體), 항문(肛門), 해골(骸骨), 허리, 허물, 허벅지, 혀, 혈관(血管), 혈분(血分), 혈소판(血小板), 혈액(血液), 혈장(血漿), 혓바닥, 호흡기(呼吸器), 혼신(渾身), 홍채(虹彩), 환부(患部), 활개, 활등코, 횡격막(橫膈膜), 후두(喉頭), 후두부(後頭部), 후설(喉舌), 흉, 흉강(胸腔), 흉골(胸骨), 흉곽(胸廓), 흉부(胸部), 흉선(胸腺), 힘줄 </p> (1) 내장 <p class="message"> 가운데창자, 꼴(盲腸), 난관(卵管), 난소(卵巢), 내장(內臟), 뇌하수체(腦下垂體), 담낭(膽囊), 대뇌피질(大腦皮質), 대동맥궁(大動脈弓), 맹장(盲腸), 미각기관(味覺器官), 방광(膀胱), 복막(腹膜), 부신(副腎), 소화관(消化管), 심낭(心囊), 심방(心房), 심실(心室), 심장(心臟), 심폐(心肺), 십이지장(十二指腸), 쓸개, 아래대동맥(__大動脈), 염통, 오장(五臟), 요도(尿道), 웅담(熊膽), 위(胃), 자궁(子宮), 정낭(精囊), 정소(精巢), 지라, 창자, 체강(體腔), 충수(蟲垂), 췌장(膵臟), 콩팥, 큰창자, 폐(肺), 폐경(肺經), 폐부(肺腑), 폐포(肺胞), 허파 </p> (2) 동물신체부위 <p class="message"> 갈기, 거대세포(巨大細胞), 게딱지, 고기비늘, 굽, 깃, 깃털, 꼬리, 꽁무니, 꽁지, 나래, 난자(卵子), 날개, 녹각(鹿角), 닭똥집, 독침(毒針), 돌기(突起), 뒷발, 뒷발굽, 말굽, 머리가슴, 먹물주머니, 물개쓸개, 물소뿔, 발목마디, 밭깃털, 볏, 복염색체(複染色體), 부레, 부리, 비계덩어리, 비늘, 뿔, 사골(四骨), 상아(象牙), 송곳니, 쇠뿔, 수달피(水獺皮), 아가미, 아양피(兒羊皮), 앞발굽, 원장강(原腸腔), 유창, 이리, 이빨, 족(足), 쥐뿔, 지느러미, 집게발톱, 처녑, 촉수(觸手), 촉수용기(觸受容器), 피혁(皮革), 호피(虎皮), 화대모(華玳瑁) </p> (3) 상처 <p class="message"> 생채기, 창상(創傷), 칼자국, 화상(火傷) </p> (4) 이상신체부위 <p class="message"> 결절(結節), 기미, 담석(膽石), 딱지, 반점(斑點), 버짐, 뾰루지, 여드름, 종기(腫氣), 종양(腫瘍), 주근깨, 주름살, 충치(蟲齒), 혹, 흉터 </p> (5) 속성신체부위 <p class="message"> 쌍꺼풀(雙__), 쑥대머리, 안짱다리, 애교머리(愛嬌__) </p> 식물의 부분 <p class="message"> 가랑잎, 가시, 가장이, 감초(甘草), 겉겨, 겉껍질, 겨, 고갱이, 관솔, 꼬투리, 꽃가루, 꽃씨, 꽃잎, 꽃턱잎, 나무거죽, 나무겉, 나뭇가지, 나비꽃잎, 넝쿨, 단풍잎(丹楓_), 덩굴, 덩쿨, 두꽃밥, 둥치, 등걸, 등겨, 땅위뿌리, 떡잎칼집, 마디, 말초(末梢), 맹아(萌芽), 무순(_筍), 볍씨, 볏짚, 봉오리, 뽕, 뿌리, 삼대, 새삼씨, 세포판(細胞板), 소엽(小葉), 소태, 속대, 솔잎, 송이, 송화(松花), 수관(樹冠), 수수깡, 수술, 수피(樹皮), 순(筍), 싹, 쌀알, 씨, 씨껍질열매, 씨앗, 앞씨눈, 열매, 엽록체(葉綠體), 옹이, 왕골껍질, 움, 유관속(維管束), 이삭, 이파리, 잎, 잎겨드랑이, 잎맥(_脈), 잎사귀, 잎새, 잔뿌리, 정자꽃밥(丁字__), 제때꽃받침, 종자(種子), 죽순(竹筍), 줄기, 짚, 콩깍지, 파밑동, 포낭(包囊), 포자(胞子) </p> 교통기관의 부분 <p class="message"> 기어(gear), 돛, 돛대, 백미러(back mirror), 뱃머리, 브레이크(brake), 선체(船體), 수직꼬리날개(垂直____), 에어백(air bag), 왼쪽깜박이, 왼쪽깜빡이, 타이어(tire), 허리돛대 </p> #### 재료/성분 어떤 구체물의 재료나 성분인 구체물입니다. <p class="message"> 갑사(甲紗), 건설자재(建設資材), 골재(骨材), 구성체(構成體), 기자재(器資材), 단속곳감(單___), 당분(糖分), 밀랍(蜜蠟), 발암물질(發癌物質), 붙박이자본재(___資本財), 성분(成分), 소재(素材), 솜털실, 쇠가죽, 쇠붙이진공관(___眞空管), 식료(食料), 신소재(新素材), 약재(藥材), 염색체(染色體), 와이어(wire), 요소(要素), 용재(用材), 원단(原緞), 원료(原料), 원재료(原材料), 이엉, 인조견(人造絹), 자재(資材), 재료(材料), 잿물벽돌(__?_), 전분(澱粉), 점심거리(點心__), 주성분(主成分), 주원료(主原料), 철분(鐵分), 철제(鐵製), 첨단소재(尖端素材), 초전도물질(超傳導物質), 코르크(cork), 코튼(cotton), 콘크리트(concrete), 콩고물, 크림(cream), 탄성매질(彈性媒質), 펄프(pulp), 포화지방(飽和脂肪), 포화지방산(飽和脂肪酸), 합판(合板), 허가연(虛家椽), 헝겊, 황(黃), 휴즈(fuse), 흑백필름(黑白__) </p>  ## 집단 **집단**이란 복수의 구성원(인간 및 비인간)으로 이루어진 집합을 말합니다. 하위 범주(2단계)로는 인간집단, 비인간집단 두 종류가 있습니다. 그 예는 다음과 같습니다. <p class="message"> 결사조직(結社組織), 떼, 종개체군(種個體群), 집단(集團), 학군(學群), 항간(巷間) </p> ### 인간집단 **인간집단**이란 인간을 구성원으로 하는 집단입니다. <p class="message"> 각계(各界), 강팀(强_), 강호(强豪), 개미군단(__軍團), 경쟁사회(競爭社會), 경제주체(經濟主體), 계급사회(階級社會), 공동운명체(共同運命體), 공동체(共同體), 공직사회(公職社會), 관민(官民), 국제사회(國際社會), 군민(軍民), 군벌(軍閥), 군부(軍部), 군상(群像), 권력집단(勸力集團), 그룹(group), 근대사회(近代社會), 기술진(技術陳), 농가(農家), 다세대(多世帶), 다중(多衆), 단일민족(單一民族), 당(黨), 도당(徒黨), 동인(同人), 두뇌집단(頭腦集團), 리그(league), 만인(萬人), 말공동체(_共同體), 망국배(亡國輩), 무자리, 미개사회(未開社會), 민간(民間), 민주사회(民主社會), 민주세력(民主勢力), 민중(民衆), 반군(叛軍), 배후세력(背後勢力), 백성(百姓), 복지사회(福祉社會), 봉건사회(封建社會), 부국강병(富國强兵), 불가(佛家), 블록(bloc), 사회공동체(社會共同體), 사회구성체(社會構成體), 상하노소(上下老少), 생활공동체(生活共同體), 서구(西歐), 선대(先代), 선민(選民), 성인남녀(成人男女), 세인(世人), 속류(俗流), 수구언론(守舊言論), 시민(市民), 시민사회(市民社會), 신세대(新世代), 쌍방(雙方), 쌍벽(雙璧), 양방(兩方), 운명공동체(運命共同體), 유목민(遊牧民), 유민(流民), 이세(二世), 이익사회(利益社會), 인력(人力), 인민(人民), 일당(一黨), 임직원(任職員), 잔당(殘黨), 재계(財界), 제가(諸家), 조선왕조(朝鮮王朝), 족벌(族閥), 종족(種族), 종파(宗派), 주축(主軸), 중생(衆生), 취재진(取材陣), 친일세력(親日勢力), 코러스(chorus), 파벌(派閥), 패(牌), 후세(後世) </p> #### 국가 일정한 지역에서 하나의 政體(권력 기구)에 소속되어 그 통제를 받는 사람들의 집합(또는 그 권력기구)입니다. <p class="message"> 각국(各國), 강국(强國), 강대국(强大國), 공산국가(共産國家), 공업국(工業國), 공화국(共和國), 근대국가(近代國家), 깡패국가(__國家), 나라, 남한(南韓), 당사국(當事國), 대영제국(大英帝國), 도이칠란드, 독립국가(獨立國家), 독재국가(獨裁國家), 동맹국(同盟國), 만국(萬國), 만방(萬邦), 망국(亡國), 문화선진국(文化先進國), 벗나라, 복지국가(福祉國家), 부국(富國), 북한(北韓), 불량국가, 불완전독립국(不完全獨立國), 사직(社稷), 삼국(三國), 삼한(三韓), 상임이사국(常任理事國), 서방국가(西方國家), 선진국(先進國), 소국(小國), 속국(屬國), 수입국(輸入國), 승전국(勝戰國), 식민지(植民地), 약소국가(弱小國家), 양국(兩國), 연방(聯邦), 연방국가(聯邦國家), 연합국(聯合國), 연합국가(聯合國家), 열강(列强), 영미(英美), 왕국(王國), 왕조(王朝), 우방(友邦), 우호국(友好國), 이웃나라, 인공(人共), 일국(一國), 자본주의국가(資本主義國家), 적국(敵國), 정보기관(精報機關), 제국(帝國), 조선(朝鮮), 종주국(宗主國), 주권국가(主權國家), 중개국(仲介國), 중립국(中立國), 중진국(中進國), 지도자국가(指導者國家), 참가국(參加國), 최혜국(最惠國), 패권국가(覇權國家), 피보호국(被保護國), 한일(韓日), 회원국(會員國), 후삼국(後三國), 후진국(後進國), 후한(後漢) </p> #### 종족 공통의 유전적, 신체적 특성에 의해 묶여지는 인간 집단입니다. <p class="message"> 남만북적(南蠻北狄), 동족(同族), 몽고족(蒙古族), 민족(民族), 북적(北狄), 소수민족(少數民族), 약소민족(弱小民族), 여진족(女眞族), 오랑캐, 유색인종(有色人種), 이민족(異民族), 인디언(indian), 인종(人種), 집시(gipsy), 훈족(Hun_) </p> #### 계층/계급 사회적 계층이나 계급을 형성하고 있는 인간 집단입니다. <p class="message"> 노동계급(勞動階級), 독자층(讀者層), 사회(社會), 수척(水尺), 자본가계급(資本家階級), 저소득층(低所得層), 절대빈곤층(絶對貧困層), 중류층(中流層), 지도급(指導級), 지배계급(支配階級), 특권계급(特權階級), 파워엘리트(power elite), 호족(豪族) </p> #### 혈연집단 혈연 관계에 의해 맺어진 인간 집단입니다. <p class="message"> 가내(家內), 가문(家門), 가정(家庭), 가족(家族), 가족공동체(家族共同體), 가족관계(家族關係), 대가족(大家族), 명가(名家), 모자가정(母子家庭), 무장대가(武將大家), 문중(門中), 부잣집(富者_), 성가정(聖家庭), 소가족(小家族), 숙질(叔姪), 시가족(_家族), 식구(食口), 식솔(食率), 신가정(新家庭), 씨족(氏族), 양가(良家), 양갓집(良家_), 왕가(王家), 왕실(王室), 왕족(王族), 외가(外家), 외가댁(外家宅), 이산가족(離散家族), 일가(一家), 일가족(一家族), 일족(一族), 족속(族屬), 종가(宗家), 집안, 친가(親家), 친인척(親姻戚), 친정(親庭), 콩가루집안, 큰댁(_宅), 큰집, 한가(寒家), 핵가족(核家族), 혈족(血族), 혼처(婚處), 황실(皇室) </p> #### 지역집단 일정한 지역을 중심으로 형성된 인간 집단입니다. <p class="message"> 군락(群落), 도민(道民), 동네(洞_), 보통지방자치단체(普通地方自治團體), 빈촌(貧村), 서양(西洋), 영어마을(英語__), 윗마을, 지구촌(地球村), 지역사회(地域社會), 판자촌(板子村) </p> #### 단체 같은 목적을 달성하기 위해 모인 인간의 조직체입니다. <p class="message"> 거대조직(巨大組織), 경제공동체(經濟共同體), 경제단체(經濟團體), 계(契), 곡마단(曲馬團), 공식파트너(公式___), 과(科), 관련단체(關聯團體), 관변(官邊), 광복군사령부(光復軍司令部), 교섭단체(交涉團體), 교수진(敎授陣), 교원단체(敎員團體), 교향악단(交響樂團), 구단(球團), 국가연합(國家聯合), 국제법단체(國際法團體), 기능사회집단(機能社會集團), 기자단(記者團), 기자협회(記者協會), 길드(guild), 날탕패(__牌), 노동단체(勞動團體), 노동조합(勞動組合), 노조(勞組), 농협(農協), 단체(團體), 대표단(代表團), 독립협회(獨立協會), 동창회(同窓會), 두레패, 모임, 무용단(舞踊團), 무장단체(武裝團體), 무장집단(武裝集團), 민간단체(民間團體), 민간연구소(民間硏究所), 반상회(班常會), 밴드(band), 법인(法人), 보건연구소(保健硏究所), 부녀회(婦女會), 사단법인(社團法人), 사조직(私組織), 사회단체(社會團體), 사회세력(司會勢力), 사회집단(司會集團), 선수단체(選手團體), 시민연대(市民連帶), 시향(市響), 신문협회(新聞協會), 신사유람단(紳士遊覽團), 악단(樂團), 압력단체(壓力團體), 업계(業界), 연대회의(連帶會議), 연맹(聯盟), 연합회(聯合會), 오케스트라(orchestra), 우익단체(右翼團體), 우익세력(右翼勢力), 운동단체(運動團體), 음반협회(音盤協會), 의료진(醫療陣), 의사협회(醫師協倉), 이익단체(利益團體), 이익집단(利益集團), 이적단체(利敵團體), 이해집단(利害集團), 인권단체(人權團體), 일진(一陣), 임의단체(任意團體), 재단(財團), 재즈밴드(jazz band), 전열(戰列), 제약협회(製藥 協會), 조사기관(調査器官), 조직(組織), 조합(組合), 중소기업협동조합(中小企業協同組合), 지배주주(支配株主), 지회(支會), 참여연대(參與連帶), 총선연대(總選連帶), 총학생회(總學生會), 축구협회(蹴球協會), 축산업협동조합(畜産業協同組合), 탐험대(探險隊), 팀(team), 평단(評壇), 필진(筆陣), 학생회(學生會), 향우회(鄕友會), 협의체(協議體), 협회(協會), 회장단(會長團), 후원회(後援會) </p> 기관 : 일정한 사회적 역할과 목적을 위해 제도적으로 설치된 인적 기구나 조직 <p class="message"> 감독관청(監督官廳), 감독기관(監督機關), 거래소(去來所), 경제특구(經濟特區), 공공기관(公共機關), 공안기관(公安機關), 공영방송(公營放送), 관서(官署), 교육센터(敎育__), 국가기구(國家機構), 극우언론(極右言論), 내외통신(內外通信), 노인교실(老人敎室), 당정(黨政), 대사관(大使館), 대표부(代表部), 대한자강회(大韓自强會), 매스컴(mass communication), 무역기구(貿易機構), 민간기관(民間機關), 방송국(放送社), 보육시설(保育施設), 복지시설(福祉施設), 분원(分院), 사학재단(私學財團), 상공회의소(商工會議所), 상담센터(相談__), 상담소(相談所), 소속기관(所屬機關), 수사기관(搜査機關), 수사당국(搜査當局), 순회도서관(巡廻圖書館), 신문사(新聞社), 신용기관(信用機關), 안구은행(眼球銀行), 양로원(養老院), 양육원(養育院), 언론(言論), 위원회(委員會), 윤리위원회(倫理委員會), 일간지(日刊紙), 임의기구(任意機構), 자문기구(諮問機構), 저널(journal), 전문기관(專門機關), 전신전화국(電信電話局), 전자국회(電子國會), 전자도서관(電子圖書館), 총무처(總務處), 편집국(編輯局), 협동조합(協同組合) </p> (1) 국가기관 : 국가를 운영하기 위해 설치한 제도적 조직 <p class="message"> 검찰(檢察), 검찰조직(檢察組織), 경제기획원(經濟企劃院), 경찰(警察), 고검(高檢), 고등법원(高等法院), 공보처(公報處), 공안당국(公安當局), 관가(官家), 관계당국(關係當局), 관계부처(關係部處), 관광공사(觀光公社), 관청(官廳), 교육부(敎育部), 교육청(敎育廳), 국가기관(國家機關), 국무회의(國務會議), 국방부(國防部), 국세청(國稅廳), 국회(國會), 군청(郡廳), 내각(內閣), 내무부(內務部), 노동부(勞動部), 대법원(大法院), 도량형사무국(度量衡事務局), 면사무소(面事務所), 문교부(文敎部), 문화재청(文化財廳), 방송공사(放送公社), 법무부(法務部), 법원(法院), 보험공단(保險公團), 사간원(司諫院), 사법기관(司法機關), 사법부(司法府), 상공부(商工部), 상원(上院), 세관(稅關), 세무서(稅務署), 소년감전(少年監典), 시경(市警), 시의회(市議會), 시청(市廳), 양원(兩院), 연방정부(聯邦政府), 외교기관(外交機關), 외무부(外務部), 우체국(郵遞局), 우파정권(右派政權), 육군본부(陸軍本部), 은행감독원(銀行監督院), 읍(邑), 의회(議會), 임시국회(臨時國會), 임시정부(臨時政府), 임정(臨政), 입법부(立法府), 장금사(掌禁司), 재판소(裁判所), 정부(政府), 중앙정부(中央政府), 지방의회(地方議會), 지방정부(地方政府), 지청(支廳), 철도청(鐵道廳), 체신부(遞信部), 총독부(總督府), 총회(總會), 통감부(統監府), 통계청(統計廳), 하원(下院), 행정부(行政部), 호방(戶房), 환경처(環境處) </p> (2) 교육기관 : 교육에 관련된 활동을 위하여 만들어진 기관 <p class="message"> 강습소(講習所), 고교(高校), 고등보통학교(高等普通學校), 고등소학교(高等小學敎), 고보(高普), 공고(工高), 공과(工科), 공과대학(工科大學), 공업고등학교(工業高等學校), 교육기관(敎育機關), 교육대학(敎育大學), 국문과(國文科), 국민학교(國民學校), 귀농학교(歸農學校), 남녀공학(男女共學), 농아학교(聾啞學校), 단대(單大), 대안학교(代案學校), 대학(大學), 대학교(大學校), 대학원(大學院), 명문대학(名門大學), 물리학과(物理學科), 미술학원(美術學院), 박사과정(博士課程), 법과(法科), 법대(法大), 본과(本科), 부속중학교(附屬中學校), 사립대(私立大), 사립대학(私立大學), 사립유치원(私立幼稚園), 사립학교(私立學校), 사설유치원(私設幼稚園), 사설학원(私設學院), 서당(書堂), 서원(書院), 소학교(小學校), 시골학교(__學校), 실업학교(實業學校), 아카데미(academy), 약대(藥大), 어린이집, 여고(女高), 여대(女大), 여상(女商), 여자의과대학(女子醫科大學), 여자전문학교(女子專門學校), 여전(女專), 여중(女中), 영문과(英文科), 외국어학교(外國語學校), 육군보병학교(陸軍步兵學校), 육사(陸士), 음대(音大), 의과대학(醫科大學), 입시학원(立試學園), 전문대(專門大), 전문대학(專門大學), 중등학교(中等學校), 중학(中學), 중학교(中學校), 지방대학(地方大學), 체대(體大), 체육대학(體育大學), 초등학교(初等學校), 타교(他校), 학당(學堂), 학부(學府), 학원(學院), 향교(鄕校) </p> (3) 의료기관 : 질병의 진료를 위해 설립된 기관 <p class="message"> 결핵요양소(結核療養所), 보건소(保健所), 순회병원(巡廻病院), 의료기관(醫療機關), 정신병동(精神病棟), 종합병원(綜合病院), 지정병원(指定病院) </p> (4) 금융기관 : 예금 및 자금의 대부, 투자와 관련된 활동을 하는 기관 <p class="message"> 금융기관(金融機關), 마을금고(__金庫), 민간은행(民間銀行), 벤처캐피탈(venture capital), 사금융(私金融), 상호신용금고(相互信用金庫), 상호저축은행(相互貯蓄銀行), 준비은행(準備銀行), 중앙은행(中央銀行), 증권회사(證券會社), 채권은행(債券銀行) </p> (5) 국제기구 : 국제적인 목적이나 활동을 위하여 두 나라 이상으로 구성된 조직체 <p class="message"> 국제기구(國際機構), 유엔(U.N.) </p> 정당 : 특정 정치적 신념, 성향을 지닌 사람들이 결성한 제도적 단체 <p class="message"> 거대야당(巨大野黨), 공당(公黨), 공동여당(共同與黨), 공산당(共産黨), 민주정당(民主政黨), 보수정당(保守政黨), 야권(野圈), 야당(野黨), 양당(兩黨), 여당(與黨), 여야(與野), 우파정당(右派政黨), 정당(政黨), 좌파정당(左派政黨), 지구당(地區黨), 집권당(執權黨), 집권여당(執權與黨), 타당(他黨) </p> 기업 : 영리 추구를 목적으로 재화나 용역을 생산, 판매하는 조직체 <p class="message"> 거대기업(巨大企業), 건설업체(建設業體), 경쟁사(競爭社), 계열사(系列社), 공공기업(公共企業), 공공기업체(公共企業體), 공기업(公企業), 공기업체(公企業體), 급식업체(給食業體), 기업(企業), 기업체(企業體), 당사(當社), 대행사(代行社), 민간기업(民間企業), 민간언론사(民間言論社), 민간항공사(民間航空社), 발전회사(發電會社), 방송사(放送社), 방위산업체(防衛産業體), 버스회사(bus__), 벤처업체(venture__), 보험회사(保險會社), 본지(本紙), 부실기업(不實企業), 사기업(私企業), 사설기업체(私設企業體), 사업체(事業體), 산업체(産業體), 상회(商會), 소개소(紹介所), 스폰서(sponsor), 심부름센터(___center), 언론사(言論社), 업체(業體), 여행사(旅行社), 영리법인(營利法人), 영세사업장(零細事業場), 영자신문사(英字新聞社), 영화사(映畵社), 용역업체(用役業體), 용역회사(用役會社), 위탁업체(委託業體), 유통업체(流通業體), 음반제작사(音盤製作社), 이삿짐센터(移徙___), 자사(自社), 잡지사(雜誌社), 재벌(財閥), 재벌기업(財閥企業), 제약회사(製藥會社), 제조업체(製造業體), 제조원(製造元), 제조회사(製造會社), 제휴업체(提携業體), 족벌신문(族閥新聞), 족벌언론(族閥言論), 주식회사(株式會社), 중소기업(中小企業), 중소업체(中小業體), 증권사(證券社), 출판사(出版社), 타사(他社), 통신사(通信社), 판매업체(販賣業體), 프로덕션(production), 항공사(航空社), 향락산업(享樂産業), 홍보업체(弘報業體), 회사(會社), 회사기업(會社企業) </p> 군대 : 전쟁, 전투, 방위 등의 목적을 위해 설립된 조직체 <p class="message"> 게릴라, 공군(空軍), 공병(工兵), 관군(官軍), 국군(國軍), 군(軍), 군단(軍團), 군대, 군문(軍門), 대대(大隊), 막막강병(莫莫强兵), 미군(美軍), 미군부대(美軍部隊), 백위군(白衛軍), 병력(兵力), 삼군(三軍), 선진(先陣), 수군(水軍), 수비대(守備隊), 수사대(搜査隊), 십자군(十字軍), 여단(旅團), 연합군(聯合軍), 예비군(豫備軍), 우림위(羽林衛), 원군(援軍), 원대(原隊), 유격대(遊擊隊), 유엔군(UN_), 육군(陸軍), 자위대(自衛隊), 장갑부대(裝甲部隊), 저격대(狙擊隊), 저항세력(抵抗勢力), 전군(全軍), 정부군(政府軍), 주력(主力), 중공군(中共軍), 중대(中隊), 지대(支隊), 침략군(侵略軍), 패군(敗軍), 평화유지군(平和維持軍), 함대(艦隊), 해군(海軍), 향군(鄕軍), 헌병대(憲兵隊) </p> 학술단체 : 학문적 목적을 위해 결성된 단체 <p class="message"> 국문연구소(國文硏究所), 연구기관(硏究機關), 연구회(硏究會), 조선어연구회(朝鮮語硏究會), 학회(學會), 헌정연구회(憲政硏究會) </p> 종교단체 : 특정 종교를 믿는 사람들의 단체 <p class="message"> 그리스정교회(Greece___), 기독교계(基督敎界), 사유교회(私有敎會), 수도원(修道院), 조계종(曹溪宗), 종단(宗團), 카톨릭(catholic), 타종(他宗), 화교(華僑) </p> 취미단체 : 공통의 취미 활동을 위해 결성된 단체 <p class="message"> 그룹사운드(group sound), 극예술연구회(劇藝術硏究會), 동아리, 보이스카우트(Boy Scouts), 서클(circle), 야구단(野球團), 야구팀(野球_), 오빠부대(__部隊), 중창단(重唱團), 청소년적십자(靑少年赤十字), 체육회(體育會), 친목계(親睦契), 친목회(親睦會), 클럽(club), 합창단(合唱團) </p> 단체의 부서 : 인간 집단 내에서 일정한 역할을 담당하기 위해 나뉘어진 부분 <p class="message"> 각부(各部), 경영진(經營陣), 고객센터(顧客__), 농과(農科), 대학원위원회(大學院委員會), 대화창구(對話窓口), 문화부(文化部), 민원실(民願室), 반(班), 본대(本隊), 본부(本部), 본청(本廳), 부서(部署), 부처(部處), 분대(分隊), 사령부(司令部), 사무국(事務局), 사무소(事務所), 사무처(事務處), 소대(小隊), 수납계(收納系), 수뇌부(首腦部), 신경과(神經科), 인기학과(人氣學科), 재판부(裁判部), 정보부(情報部), 지도부(指導部), 지역본부(地域本部), 집행부(執行部), 철학과(哲學科), 출장소(出張所), 파트(part), 편집부(編輯部), 편집실(編輯室), 편집위원회(編輯委員會), 학급(學級) </p> 반사회적 단체 <p class="message"> 매춘조직(賣春組織), 왜구(倭寇), 왜적(倭賊), 집단강도(集團强盜), 폭력단(暴力團) </p> #### 유파 공통의 신념, 성향에 따라 묶이는 인간 집단입니다. <p class="message"> 건달패(乾達牌), 계파(系派), 구파(舊派), 노장파(老壯派), 분파(分派), 사림(士林), 순정파(純情派), 신파(新派), 유파(流派), 일파(一派), 학생운동권(學生運動圈) </p> 예술유파 : 공통의 예술적 신념이나 성향에 따라 묶이는 유파 <p class="message"> 전위(前衛), 후기인상파(後期印象派) </p> 정치유파 : 공통의 정치적 신념이나 성향에 따라 묶이는 인간 집단 <p class="message"> 강경파(强硬派), 개혁파(改革派), 극우세력(極右勢力), 극우집단(極右集團), 급진좌파(急進左派), 당파(黨派), 보수강경파(保守强硬派), 보수세력(保守勢力), 보수우익(保守右翼), 보수우파(保守右派), 보수파(保守派), 볼셰비키(Bol'sheviki), 붕당(朋黨), 수구보수(守舊保守), 수구집단(守舊集團), 온건파(穩健派), 우파(右派), 정파(政派), 좌익세력(左翼勢力), 좌파(左派), 중도우파(中道右派), 중도좌파(中道左派), 중도파(中道派), 지지세력(支持勢力), 진보세력(進步勢力), 집권세력(執權勢力) </p> 학파 : 특정 학문적 신념, 성향에 따라 묶이는 인간 집단 <p class="message"> 고전경제학파(古典經濟學派), 수리경제학파(數理經濟學派), 신고전학파(新古典學派), 유가(儒家), 정통경제학파(正統經濟學派), 정통학파(正統學派), 제자백가(諸子百家), 학파(學派) </p> #### 일시적집단 일시적으로 형성되었다가 해체되는 인간 집단입니다. <p class="message"> 거리응원단(__應援團), 경비대(警備隊), 관객(觀客), 관중(觀衆), 군중(群衆), 대열(隊列), 대오(隊伍), 돌격대(突擊隊), 두레, 민(民), 박수부대(拍手部隊), 반란군(反亂軍), 백군(白軍), 보도진(報道陣), 비토세력(veto__), 비판세력(批判勢力), 선발대(先發隊), 선수단(選手團), 스태프(staff), 습격대(襲擊隊), 시위대(示威隊), 심사위원단(審査委員團), 아군(我軍), 외교사절단(外交使節團), 위문단(慰問團), 유람단(遊覽團), 의료지원단(醫療支援團), 의용군(義勇軍), 이야기모임, 인파(人波), 일군(一群), 정신대(挺身隊), 제작진(製作陣), 조문사절단(弔問使節團), 조사단(調査團), 조사위원회(調査委員會), 좌중(座中), 집회(集會), 채권자집회(債權者集會), 청군(靑軍), 청중(聽衆), 촛불시위대(__示威隊), 패거리(牌__), 폭도(暴徒), 한편짝, 합동수사반(合同搜査班), 합동조사단(合同調査團), 호화군단(豪華軍團), 후보지지층(候補支持層) </p> #### 범위인간집단 <p class="message"> 노동계(勞動界), 반공세대(反共世代), 연기파(演技派), 열성파(熱誠派), 오전반(午前班), 원시공동체(原始共同體), 전교(全校), 전교생(全校生) </p> ### 비인간집단 **비인간집단**이란 인간 외의 구성원으로 이뤄진 집단입니다. <p class="message"> 다발, 단청, 더미, 무더기, 무리, 물고기무리, 바위옷무리, 빙설식물상(氷雪植物相), 수풀, 식생(植生), 양떼(羊_), 토양생물상(土壤生物相) </p> ## 장소 **장소**란 이동의 대상이 될 수 없고 이동의 기준이 되며, 인간이 활동하는 공간을 뜻합니다. 하위 범주(2단계)로는 지상장소, 물장소, 공중장소, 상징적 장소, 건물, 길, 다리, 굴, 부분장소, 관계장소, 자리/좌석, 경계, 지역, 속성/기능 장소 등이 있습니다. <p class="message"> 가설극장(假設劇場), 가운데뜰, 강바닥(江__), 개울가, 개인공간(個人空間), 거처(居處), 경지(耕地), 경향(京鄕), 고을, 공간(空間), 공단(工團), 근원(根源), 금수강산(錦繡江山), 금지구역(禁止區域), 날씨단구(__段丘), 누리, 다방(茶房), 대처(大處), 도처(到處), 맨홀(manhole), 문틈(門_), 방방곡곡(坊坊曲曲), 방파제(防波堤), 본거지(本據地), 산천(山川), 산하(山河), 서경(西經), 세상(世上), 속계(俗界), 속세(俗世), 수륙(水陸), 스키장(ski_), 시삼촌댁(媤三寸宅), 위치(位置), 이승, 이역(異域), 일리(一里), 자리, 장소(場所), 정처(定處), 지점(地點), 지층(地層), 지하(地下), 진원(震源), 차안(此岸), 천지(天地), 천하(天下), 한대(寒帶) </p> ### 지상장소 **지상장소**란 인간이 활동하는 땅 위의 장소입니다. <p class="message"> 간척지(干拓地), 강가(江_), 강기슭(江__), 강변(江邊), 개척지(開拓地), 갯가, 갯마을, 갯벌, 고랑, 고산꽃밭(高山__), 고수부지(高水敷地), 골땅, 골짜기, 곶(串), 광산(鑛山), 광야(廣野), 구덩이, 군도(群島), 극지(極地), 기슭, 꽃밭, 나루, 나루터, 낙도(落島), 난달, 남극(南極), 내륙(內陸), 내리막, 노천(露天), 대륙(大陸), 대지(大地), 대학가(大學街), 동토(凍土), 두덩, 두둑, 두메산골(__山_), 들, 들판, 땅, 모래밭, 무인도(無人島), 뭍, 바닷가, 반도(半島), 백사장(白沙場), 벌판, 분지(盆地), 빙상(氷上), 빙판(氷板), 빙하(氷河), 사막(砂漠), 산간(山間), 산야(山野), 산지(産地), 삼천리(三千里), 삼천리강산(三千里江山), 설원(雪原), 섬, 수구장문(水口藏門), 습지(濕地), 시냇가, 신대륙(新大陸), 실외(室外), 심심산골(深深山_), 심심산천(深深山川), 야외(野外), 연안(沿岸), 열도(列島), 오아시스(oasis), 옥토(沃土), 올림꽃밭, 육지(陸地), 임야(林野), 임해(臨海), 자갈바닥, 자갈밭, 자투리땅, 잔디밭, 잔디코트(__court), 장벽습지(障壁濕地), 전원(田園), 절터, 중동(中東), 지괴(地塊), 지면(地面), 지반(地盤), 지상(地上), 지평(地平), 지표(地表), 지표면(地表面), 지협(地峽), 지형(地形), 진창, 첩첩산중(疊疊山中), 초원(草原), 캄캄절벽(__絶壁), 탄전(炭田), 택지(宅地), 터, 터전, 토지(土地), 툰드라(tundra), 펄, 평야(平野), 평원(平原), 평지(平地), 폐허(廢墟), 포도밭(葡萄_), 풀밭, 하계(下界), 항구도시(港口都市), 해도(海島), 해변(海邊), 해안(海岸), 해안교두보(海岸橋頭堡), 해안선(海岸線), 허방, 협곡(峽谷), 호반(湖畔), 화원(花園), 환경(環境), 황야(荒野) </p> #### 고지대 수직적으로 높은 지상장소 <p class="message"> 경사면(傾斜面), 고갯길, 고갯마루, 고봉(高峯), 고원(高原), 골짝, 날가지, 낭떠러지, 능선(稜線), 둔덕, 뒷산(_山), 등성이, 벼랑, 봉우리, 봉정(峯頂), 비탈, 빙벽(氷壁), 산골(山_), 산골짜기(山___), 산골짝(山__), 산기슭(山__), 산꼭대기(山___), 산등성이(山___), 산록(山麓), 산봉우리(山___), 산비탈(山__), 산악지형(山岳地形), 산자락, 산정(山頂), 산줄기(山__), 산중(山中), 산허리(山__), 상봉(上峯), 암벽(巖壁), 언덕, 오르막, 우백호(右白虎), 절벽(絶壁), 주름산달(__山_), 최고봉(最高峰) </p> 산/산맥 <p class="message"> 고산(高山), 난산(亂山), 동산, 명산(名山), 백두대간(白頭大幹), 산(山), 산맥(山脈), 산악(山嶽), 서산(西山), 선산(先山), 야산(野山), 지맥(地脈), 청산(靑山), 험산(險山), 화산(火山) </p> #### 숲 수풀이 덮여있는 지상장소 <p class="message"> 국유림(國有林), 녹림(綠林), 녹음(綠陰), 녹지(綠地), 목초지(牧草地), 밀림(密林), 산림(山林), 삼림(森林), 소림(疏林), 솔밭, 송림(松林), 수림(樹林), 숲, 열대림(熱帶林), 임산(林産), 정글(jungle), 풍림(風林) </p> #### 농경지 농관련 장소 <p class="message"> 건못자리(乾___), 고랑못자리, 과수밭(果樹_), 과수원(果樹園), 논, 논밭, 농경지(農耕地), 농원(農園), 농장(農場), 농지(農地), 농토(農土), 대밭, 모판(_板), 밭, 보온못자리(保溫___), 수전(水田), 자갈논, 잔돌밭, 전답(田畓), 주지논, 집단농장(集團農場), 평전(平田), 화전(火田) </p> #### 휴양지/공원 인간이 휴식을 취하고 놀기 위해 만들어진 개방된 지상장소 <p class="message"> 공원(公園), 광장(廣場), 놀이공원(__公園), 놀이동산, 놀이터, 대공원(大公園), 동물원(動物園), 바위정원(__庭園), 시민공원(市民公園), 약수터(藥水_), 유원지(遊園地), 휴양지(休養地) </p> #### 묘지 인간이 인공적으로 조성하여 죽은 사람들의 시신을 묻는 지상장소 <p class="message"> 공동묘지(共同墓地), 국립묘지(國立墓地), 돌무지무덤, 돌방무덤, 목곽분(木槨墳), 뫼, 묘원(墓園), 무덤, 봉분(封墳), 분묘(墳墓), 석실분(石室墳), 선영(先塋), 왕릉(王陵), 적석총(赤石塚), 지석묘(支石墓), 호화묘지(豪華墓地) </p> #### 담 인간이 외부와 구분을 짓기 위해 만든 지상장소 <p class="message"> 담, 담벼락, 돌담, 석벽(石壁), 성곽(城郭), 성벽(城壁), 옹벽(擁壁), 울, 울타리, 철조망(鐵條網), 축대(築臺) </p> #### 제방 인간이 물의 범람을 막기 위해 만든 지상 장소 <p class="message"> 개자리두둑, 논둑, 댐(dam), 둑, 방죽 </p> ### 물장소 **물장소**란 인간이 활동하는 물 장소입니다. <p class="message"> 강해(江海), 개울, 개펄, 계곡(溪谷), 광천(鑛泉), 군항(軍港), 냇가, 늪, 대륙붕(大陸棚), 만(灣), 물밑, 물줄기, 본류(本流), 분수(噴水), 산골샘(山__), 상수원(上水源), 샘, 서안(西岸), 수계(水系), 수렁, 수맥(水脈), 수면(水面), 수역(水域), 수영장(水泳場), 수원(水源), 어장(漁場), 여울, 옹달샘, 웅덩이, 잔고기못, 주류(主流), 파면(波面), 폭포(瀑布), 하구(河口), 하류(下流), 해수욕장(海水浴場), 해협(海峽) </p> #### 하천 일정한 방향으로 흐르는 물장소 <p class="message"> 강(江), 개천(開川), 내, 냇물, 대하(大河), 도랑, 사천(沙川), 시냇물, 실개천(__川), 쌍둥이강(雙__江), 원류(源流), 하천(河川) </p> #### 바다 지상장소로 둘러 쌓이지 않은 물장소 <p class="message"> 근해(近海), 남해(南海), 대서양(大西洋), 대양(大洋), 대해(大海), 동해(東海), 동해안(東海岸), 바다, 북양(北洋), 북해(北海), 사해(四海), 서해(西海), 심해(深海), 앞바다, 영해(領海), 원양(遠洋), 창해(滄海), 해면(海面), 해상(海上), 해양(海洋), 해역(海域), 해연(海淵), 해저(海底), 황해(黃海) </p> #### 호수 지상장소로 둘러싸여 흐름이 없는 물장소 <p class="message"> 연못(蓮_), 연지(蓮池), 저수지(貯水池), 지당(池塘), 호수(湖水) </p> ### 공중장소 **공중장소**란 인간이 활동하는 지상장소 위의 장소입니다. <p class="message"> 고공(高空), 공중(空中), 반공중(半空中), 밤하늘, 상공(上空), 서천(西天), 수련천(水連天), 영공(領空), 외계(外界), 우주(宇宙), 우주공간(宇宙空間), 저공(低空), 전리층(電離層), 조각하늘, 중천(中天), 창공(蒼空), 천공(天空), 청천(靑天), 하늘, 한천(寒天), 허공(虛空) </p> ### 상상적장소 **상상적 장소**란 신이나 죽은 인간이 산다는 상상 속의 장소입니다. <p class="message"> 극락세계(極樂世界), 극락정토(極樂淨土), 나락(奈落), 낙원(樂園), 낙토(樂土), 내세(來世), 별천지(別天地), 선경(仙境), 용궁(龍宮), 유토피아(Utopia), 이상향(理想鄕), 저승, 정토(淨土), 지옥(地獄), 천계(天界), 천국(天國), 천근(天根), 천당(天堂), 천상(天上), 타계(他界), 피안(彼岸), 하늘나라, 함지(咸池), 혈(穴), 황천(黃泉) </p> ### 건물 **건물**이란 인간이 안에서 활동할 수 있도록 지어놓은 장소입니다. <p class="message"> 가옥(家屋), 가택(家宅), 개집, 건물(建物), 건축구조물(建築構造物), 건축물(建築物), 고궁(古宮), 공공시설(公共施設), 공중변소(公衆便所), 관아(官衙), 구관(舊館), 궁전(宮殿), 궁정(宮廷), 내전(內殿), 누각(樓閣), 대장간(__間), 대학병원(大學病院), 대형건물(大形建物), 등대(燈臺), 마천루(摩天樓), 막(幕), 망대(望臺), 망루(望樓), 문화시설(文化施設), 본관(本館), 부군당(府君堂), 비각(碑閣), 비닐하우스(vinyl house), 빌딩(building), 서고(書庫), 수력발전소(水力發電所), 수용소(收容所), 스튜디오(studio), 스포츠센터(sports center), 신관(新館), 안내소(案內所), 연구소(硏究所), 영화관(映畵館), 왕궁(王宮), 우사(牛舍), 원두막(園頭幕), 정자(亭子), 지국(支局), 지부(支部), 지소(支所), 차고(車庫), 창고(倉庫), 처갓집(妻家), 캠프(camp), 화력발전소(火力發電所), 화방(畵房), 화실(畵室) </p> #### 주택 인간이 거주하는 건물 <p class="message"> 고옥(古屋), 고층아파트(高層___), 고택(古宅), 공가(空家), 공공주택(公共住宅), 공관(公館), 공동주택(共同住宅), 관사(官舍), 관저(官邸), 궁(宮), 궁궐(宮闕), 궁내(宮內), 궁성(宮城), 궁중(宮中), 궐(闕), 기숙사(寄宿舍), 누옥(陋屋), 단독주택(單獨住宅), 단칸(單_), 대궐(大闕), 독채(獨_), 막사(幕舍), 맨션(mansion), 민가(民家), 방갈로(bungalow), 별궁(別宮), 별장(別莊), 별채(別_), 본채(本_), 빈집, 빌라(villa), 사가(私家), 사랑채(舍廊_), 사옥(社屋), 사원아파트(社員___), 사저(私邸), 사택(舍宅), 생가(生家), 소형아파트(小型___), 시댁(媤宅), 아파트(appartment), 양옥(洋屋), 오두막(__幕), 오막(_幕), 오막살이(_幕__), 오피스텔(office+hotel), 움막(_幕), 이글루(igloo), 임대아파트(賃貸___), 임대주택(賃貸住宅), 자택(自宅), 저택(邸宅), 전각(殿閣), 전셋집(傳貰_), 주인댁(主人宅), 주택(住宅), 집, 집단주택(集團住宅), 집집, 천막(天幕), 초가(草家), 초가삼간(草家三間), 초가집(草家_), 초당(草堂), 초막(草幕), 폐가(廢家), 하숙집(下宿_), 한옥(韓屋), 합숙소(合宿所), 호화주택(豪華住宅), 황궁(皇宮), 흉가(凶家) </p> #### 종교건물 종교적인 의식이 행해지는 건물 <p class="message"> 거찰(巨刹), 교회(敎會), 대웅전(大雄殿), 법당(法堂), 본당(本堂), 본산(本山), 불당(佛堂), 사당(祠堂), 사원(寺院), 사찰(寺刹), 산사(山寺), 산신각(山神閣), 서낭당(__堂), 성당(聖堂), 성전(聖殿), 승방(僧房), 신궁(神宮), 신당(神堂), 신전(神殿), 암자(庵子), 예배당(禮拜堂), 절, 절간(_間), 폐사(廢寺), 회당(會堂) </p> #### 교통기관관련건물 교통기관이 서거나 머무르는 장소 <p class="message"> 고속터미널(高速___), 공항(空港), 버스정류소(bus___), 버스정류장(bus___), 버스터미널(bus terminal), 부두(埠頭), 불개항(不開港), 비행장(飛行場), 선착장(船着場), 세관비행장(稅關飛行場), 승강장(乘降場), 승차장(乘車場), 역(驛), 정거장(停車場), 정류장(停留場), 종착역(終着驛), 주차장(駐車場), 지하철역(地下鐵驛), 철도역(鐵道驛), 택시승강장(taxi___), 터미널(terminal), 포구(浦口), 프랫폼(platform), 플랫폼(platform), 항구(港口), 항만(港灣), 활주로(滑走路) </p> #### 상업건물 인간의 상업활동이 이루어지는 건물 장소 <p class="message"> 가게, 가구점(家具店), 간이식당(簡易食堂), 간이음식점(簡易飮食店), 객주(客主), 결혼상담소(結婚相談所), 경마장(競馬場), 고서점(古書店), 골동품상(骨董品商), 골프연습장(golf___), 골프장(golf_), 공동목욕탕(共同沐浴湯), 공장(工場), 공중목욕탕(公衆沐浴湯), 공창(工廠), 구멍가게, 극장(劇場), 금은방(金銀房), 기계간(機械間), 기계공장(機械工場), 기생집(妓生_), 꽃가게, 나이트(night), 난가게, 남탕(男湯), 노래방(__房), 다실(茶室), 당구장(撞球場), 대리점(代理店), 대여점(貸與店), 대중목욕탕(大衆沐浴湯), 대중식당(大衆食堂), 도장(道場), 디스코테크(디스코테크), 떡집, 러브호텔(love hotel), 레스토랑(레스토랑), 룸살롱(room__), 매점(賣店), 매춘업소(賣春業所), 모텔(motel), 목욕탕(沐浴湯), 문방구(文房具), 문방구점(文房具店), 미장원(美粧院), 바(bar), 백화점(百貨店), 복권판매소(福券販賣所), 복덕방(福德房), 분점(分店), 사설주차장(私設駐車場), 사업장(事業場), 사진관(寫眞館), 산장(山莊), 상점(商店), 서관(書館), 서림(書林), 서점(書店), 선술집, 세차장(洗車場), 숙박업소(宿泊業所), 술집, 슈퍼(super), 슈퍼마켓(supemarket), 시계포(時計鋪), 식당(食堂), 안방술집(_房__), 약국(藥局), 약방(藥房), 양복감가게(洋服___), 양조장(釀造場), 어전(漁廛), 여관(旅館), 여인숙(旅人宿), 영업소(營業所), 영업장(營業場), 예식장(禮式場), 요릿집(料理_), 욕탕(浴湯), 위성백화점(衛星百貨店), 유명백화점(有名百貨店), 유흥업소(遊興業所), 유흥음식점(遊興飮食店), 윤락업소(淪落業所), 음식점(飮食店), 음악다방(音樂茶房), 이발소(理髮所), 잡화상(雜貨商), 전당포(典當鋪), 전문점(專門店), 전자오락실(電子娛樂室), 점포(店鋪), 정비소(整備所), 제과점(製菓店), 제재소(製材所), 주막(酒幕), 주막집(酒幕_), 주유소(注油所), 주점(酒店), 지물포(紙物鋪), 찻집(茶_), 책방(冊房), 체인점(chain_), 총대리점(總代理店), 치과(齒科), 카바레, 카지노, 카페, 콘도(condominium), 콘도미니엄(condominium), 타점(他店), 피시방(PC_), 향락업소(享樂業所), 헌책방, 호텔(hotel), 호프(hof), 휴게소(休憩所) </p> #### 기관건물 인간집단이 공적인 업무를 수행하는 건물 장소 <p class="message"> 감영(監營), 검찰청사(檢察廳舍), 경찰서(警察署), 고아원(孤兒院), 공공도서관(公共圖書館), 공립학교(公立學校), 공영방송사(公營放送社), 관공서(官公署), 구청(區廳), 국회도서관(國會圖書館), 국회의사당(國會議事堂), 기상관측소(氣象觀測所), 기선우체국(汽船郵遞局), 노인복지관(老人福祉館), 대학본부(大學本部), 도서관(圖書館), 동사무소(洞事務所), 동헌(東軒), 동회(洞會), 등기소(登記所), 미대(美大), 법정(法庭), 병동(病棟), 병원(病院), 분교(分校), 사립대학교(私立大學校), 산부인과(産婦人科), 송신소(送信所), 수산시험장(水産試驗場), 심상소학교(尋常小學校), 안과(眼科), 어머니교실(___敎室), 여름경찰서(__警察署), 여학교(女學校), 연수원(硏修院), 우정국(郵政局), 유치원(幼稚園), 은행(銀行), 정신병원(精神病原), 정형외과(整形外科), 주재소(駐在所), 중앙청(中央廳), 지검(地檢), 지법(地法), 지서(支署), 참고열람실(參考閱覽室), 청사(廳舍), 파출소(派出所), 학교(學校), 학교도서관(學校圖書館), 햇빛요양소(__療養所) </p> 교도소 <p class="message"> 감옥(監獄), 개방교도소(開放矯導所), 교도소(矯導所), 구치소(拘置所), 민간교도소(民間矯導所), 영창(營倉), 유치장(留置場), 육군교도소(陸軍矯導所), 형무소(刑務所) </p> #### 문화행사건물 인간 또는 인간집단이 전시, 공연, 운동 등의 문화 관련 행사를 갖는 건물 장소 <p class="message"> 강당(講堂), 갤러리(gallery), 경기장(競技場), 공공미술관(公共美術館), 공연장(公演場), 구장(球場), 국립박물관(國立博物館), 기념관(記念館), 노래극장(__劇場), 노천강당(露天講堂), 노천극장(露天劇場), 대회장(大會場), 미술관(美術館), 박물관(博物館), 빙상경기장(氷上競技場), 성인전용관(成人專用館), 소극장(小劇場), 스타디움(stadium), 식장(式場), 실내체육관(室內體育館), 유물전시관(遺物展示館), 자연사박물관(自然史博物館), 전시관(展示館), 전시장(展示場), 정구장(庭球場), 종합경기장(綜合競技場), 체육관(體育館), 투우장(鬪牛場), 학교박물관(學校博物館), 화랑(畵廊), 회관(會館) </p> #### 방어건물 인간 사이의 물리적인 충돌을 위해 만들어진 건물장소 <p class="message"> 미군기지(美軍基地), 산성(山城), 성(城), 성보(城堡), 성채(城砦), 요새(要塞), 장벽(障壁), 철옹성(鐵甕城), 초소(哨所), 평성(平城) </p> ### 길 **길**이란 인간이 이동할 때 거치는 장소입니다. <p class="message"> 가도(街道), 가두(街頭), 가로(街路), 갱도(坑道), 거리, 건널목, 골목, 골목골목, 골목길, 교차로(交叉路), 극장가(劇場街), 길, 길거리, 길나들이, 길바닥, 네거리, 노상(路上), 노선(路線), 농로(農路), 도중(途中), 목잔(木棧), 미로(迷路), 뱃길, 번화가(繁華街), 보급로(補給路), 비탈길, 산골길(山___), 산길(山_), 산천만리(山川萬里), 삼거리(三__), 상가(商街), 생눈길(生__), 소로(小路), 시가(市街), 시장골목(市場__), 신작로(新作路), 앞길, 애로(隘路), 오솔길, 외딴길, 육로(陸路), 인도(人道), 자갈길, 전용차로(專用車路), 전용차선(專用車線), 지름길, 출퇴근길(出退勤_), 큰길, 통로(通路), 퇴로(退路), 한길, 항공로(航空路), 행로(行路), 험로(險路), 협로(夾路), 횡단보도(橫斷步道) </p> #### 도로 차가 다니는 길 <p class="message"> 고가도로(高架道路), 고속도로(高速道路), 교통로(交通路), 국도(國道), 대로(大路), 도로(道路), 등산로(登山路), 로터리(rotary), 우회로(迂廻路), 진입로(進入路), 차도(車道), 차로(車路), 차선(車線) </p> #### 철로 철도교통기관이 다니는 길 <p class="message"> 고속철도(高速鐵道), 궤도(軌道), 기차선로(汽車線路), 선로(線路), 안전옆줄(安全__), 철길(鐵_), 철도(鐵道), 철로(鐵路) </p> #### 수로 수상교통기관이 다니는 길 <p class="message"> 물길, 수로(水路), 운하(運河), 항로(航路), 해로(海路) </p> ### 다리 **다리**란 떨어진 두 지점을 연결하기 위해 지상보다 높게 만들어진 길입니다. <p class="message"> 교량(橋梁), 대교(大橋), 부교(浮橋), 석교(石橋), 외나무다리, 육교(陸橋), 징검다리 </p> #### 고가도로 육상교통기관이 다니는 다리 #### 철교 철도교통기관이 다니는 다리 <p class="message"> 구름다리철길(____鐵_), 철교(鐵橋) </p> ### 굴 **굴**이란 인간이 활동하고, 지상으로 완전하게 드러나지 않은 장소입니다. <p class="message"> 개구멍, 개미굴(__窟), 갱내(坑內), 굴(窟), 금광(金鑛), 동굴, 석굴(石窟), 수평갱(水平坑), 은광(銀鑛), 탄광(炭鑛), 토굴(土窟), 폐광(廢鑛) </p> #### 터널 떨어진 두 장소를 연결하기 위해 땅속으로 만들어진 길 <p class="message"> 터널(tunnel) </p> ### 부분장소 **부분장소**란 기능 또는 속성에 따라 분할되어 있는 장소의 하위 공간입니다. <p class="message"> 감방(監房), 구석구석, 굽이, 길가, 남부(南部), 내부(內部), 내야(內野), 논두렁, 담고리, 동구(洞口), 동부(東部), 뒤꼍, 땅바닥, 말단(末端), 모롱이, 모퉁이, 묘실(墓室), 물목, 밭고랑, 변두리(邊__), 변방(邊方), 복판, 북단(北端), 북부(北部), 북서부(北西部), 산모퉁이(山___), 산문(山門), 상단(上段), 서부(西部), 성안(城_), 성중(城中), 속, 시가지(市街地), 시장바닥(市場__), 아귀, 어귀, 언덕바지, 옥중(獄中), 입구(入口), 장내(場內), 정중(正中), 중간(中間), 중심가(中心街), 중심부(中心部), 중심지(中心地), 중앙(中央), 쥐구멍, 초입(初入), 촌구석(村__), 측방(側方), 커브(curve), 코로나(corona), 타석(打席), 트랙(track), 페어웨이(fairway), 필드(field), 하부(下部), 한구석, 한데, 한마을, 현관(玄關) </p> #### 건물부분장소 **건물부분장소**란 건물을 구성하는 하위 장소입니다. <p class="message"> 가겟방(__房), 가묘(家廟), 각방(各房), 각층(各層), 감시대(監視臺), 강의실(講義室), 개찰구(改札口), 객실(客室), 객장(客場), 거실(居室), 건넌방(__房), 건넛방(__房), 경내(境內), 경호실(警護室), 계단(階段), 곡창(穀倉), 골방(_房), 곳간(庫間), 공방(工房), 공중화장실(公衆化粧室), 광, 교단(敎壇), 교무실(敎務室), 교실(敎室), 교장실(校長室), 군불아궁이, 굴뚝개자리, 규방(閨房), 꽃무늬담, 내실(內室), 다락, 대청(大廳), 대청마루(大廳__), 대합실(待合室), 도서실(圖書室), 독방(獨房), 독실(獨室), 라운지(lounge), 로비(lobby), 마루, 마룻바닥, 목욕실(沐浴室), 문간(門間), 문간방(門間房), 문간채(門間_), 문전(門前), 바닥, 발코니(balcony), 방(房), 베란다(veranda), 변소(便所), 별당(別堂), 병실(病室), 봉당(封堂), 부뚜막, 부속실(附屬室), 부엌, 분실(分室), 세면장(洗面場), 솟을대문(__大門), 쇼윈도(show window), 수위실(守衛室), 숙직실(宿直室), 스카이라운지(sky lounge), 승강구(昇降口), 시청각교실(視聽覺敎室), 시체실(屍體室), 아궁이, 안방(_房), 암실(暗室), 여관방(旅館房), 연구실(硏究室), 연회실(宴會室), 영안실(靈安室), 옥상(屋上), 온돌방(溫_房), 욕실(浴室), 원내(院內), 윗목(윗목), 응접실(應接室), 이층(二層), 일층(一層), 자료실(資料室), 작업실(作業室), 저장실(貯藏室), 전세방(傳貰方), 접견실(接見室), 정문(正門), 조리실(調理室), 조제실(調劑室), 주방(廚房), 지하실(地下室), 집무실(執務室), 쪽문(_門), 출입구(出入口), 출입문(出入門), 치료실(治療室), 침실(寢室), 콩나물교실(___敎室), 탈의실(脫衣室), 테라스(terrace), 툇마루, 특실(特室), 하층(下層), 학내(學內), 한방(_房), 행랑(行廊), 헛간(_間), 홀(hall), 화계(花階), 화단(花壇), 화장실(化粧室), 환자실(患者室), 회랑(回廊), 회의실(會議室), 휴게실(休憩室) </p> 통로 <p class="message"> 나선계단(螺旋階段), 바깥문간(__門間), 복도(複道), 아케이드(arcade), 출로(出路), 층계(層階) </p> 건물주변장소 <p class="message"> 교정(校庭), 다원(茶園), 담벽, 뜰, 마당, 안뒤꼍, 옥외(屋外), 장독대(醬_臺), 정원(庭園), 캠퍼스(campus), 후문(後門) </p> 방 <p class="message"> 구석건넌방(____房), 별실(別室), 비서실([U7955]書室), 사랑방(舍廊房), 사무실(事務室), 산실(産室), 상담실(相談室), 서재(書齋), 석실(石室), 셋방(貰房), 실습실(實習實), 실험실(實驗室), 안방구석(_房__), 호실(號室) </p> #### 교통기관부분장소 교통기관을 구성하는 하위장소 <p class="message"> 객차(客車), 기내(機內), 뱃전(_), 삼등칸(三等_), 선내(船內), 선미(船尾), 선상(船上), 선실(船室), 역구내(驛區內) </p> ### 관계장소 **관계장소**란 다른 대상을 기준으로 규정되지만 부분을 구성하지 않는 장소입니다. <p class="message"> 가, 가까이, 가운데, 갈피, 강남(江南), 강북(江北), 거래처(去來處), 건너, 건너편(__便), 격지(隔地), 곁, 골문(goal_), 관내(管內), 관문(關門), 교내(校內), 교외(郊外), 구석, 구역(區域), 국내(國內), 국외(國外), 국토(國土), 권역(圈域), 궐내(闕內), 근교(近郊), 근동(近洞), 근린(近隣), 근방(近方), 근처(近處), 길목, 꼭대기, 끝, 남국(南國), 남단(南端), 남문(南門), 남측(南側), 내곽(內廓), 내국(內國), 내면(內面), 내외(內外), 내지(內地), 너머, 노변(路邊), 눈앞, 대외(對外), 대체공항(代替空港), 도상(途上), 도읍(都邑), 동렬(同列), 동서양(東西洋), 둘레, 둘레도시(__都市), 뒤, 뒷골목, 뒷동산, 뒷전, 마상(馬上), 머리맡, 면전(面前), 모래강변(__江邊), 목전(目前), 밑, 밖, 반대편(反對便), 발치, 방바닥(房__), 방안(房_), 배후(背後), 벽지(僻地), 별관(別館), 보금자리, 본고장(本__), 본교(本校), 본사(本社), 본서(本署), 본점(本店), 본진(本陣), 본토(本土), 부근(附近), 북안(北岸), 빈틈, 사각지대(死角地帶), 사외(社外), 사이, 삼면(三面), 상류(上流), 상층(上層), 성터(城_), 소재지(所在地), 시외(市外), 실내(室內), 심층(深層), 아래, 아래뜸, 아랫목, 안, 안중(眼中), 안쪽, 안채, 안팎, 앞, 앞뒤, 양쪽(兩_), 양측(兩側), 양편(兩便), 어깨너머, 어름, 언저리, 역내(域內), 연변(沿邊), 열외(列外), 영전(靈前), 영토(領土), 옆, 옆방(_房), 옆집, 오른편, 옥내(屋內), 외곽(外郭), 외부(外部), 외지(外地), 외항(外港), 왼쪽, 왼편(_便), 우변(右邊), 우편(右便), 원산(原産), 원산지(原産地), 원외(院外), 위쪽, 위층(_層), 유역(流域), 이국(異國), 이북(以北), 이웃, 이웃집, 이하(以下), 인근(隣近), 인근마을(隣近__), 인근지역(隣近地域), 일대(一帶), 일원(一圓), 장외(場外), 장중(場中), 전역(全域), 전후(前後), 절정(絶頂), 정면(正面), 정점(頂點), 제자리, 종점(終點), 좌청룡(左靑龍), 좌측(左側), 좌편(左便), 주변(周邊), 중부(中部), 중심(中心), 중층(中層), 중턱(中_), 체외(體外), 측근(側近), 코너(corner), 틈, 한가운데, 한군데, 해외(海外), 행방(行方), 후편(後便) </p> #### 화시적 장소 **화시적 장소**란 화시적 중심(deictic centre)을 기준으로 정해지는 장소입니다. <p class="message"> 각처(各處), 맞은편(__便), 모처(某處), 바깥, 여기저기, 원근(遠近), 주위(周圍), 즉석(卽席), 타관(他關) </p> #### 인간관계 장소 **인간관계 장소**란 인간과 밀접하게 관련되어, 그를 확인해주는 장소입니다. <p class="message"> 거주지(居住地), 고국(故國), 고장, 고향(故鄕), 댁(宅), 동향(同鄕), 모교(母校), 모국(母國), 본가(本家), 본국(本國), 본향(本鄕), 소굴(巢窟), 소유지(所有地), 시골집, 시집(媤_), 연고지(緣故地), 외갓집(外家_), 유명(幽明), 조국(祖國), 직장(職場), 처가(妻家), 출신학교(出身學校), 타동(他洞), 타지(他地), 타처(他處), 타향(他鄕), 향리(鄕里) </p> ### 자리/좌석 **자리/좌석**이란 인간이 앉도록 만들어진 자리입니다. <p class="message"> 객석(客席), 경로석(敬老席), 귀빈석(貴賓席), 노약자석(老弱者席), 뒷자리, 방청석(傍聽席), 상석(上席), 상좌(上座), 시트(seat), 심판석(審判席), 운전석(運轉席), 웃자리, 응원석(應援席), 의석(議席), 일반석(一般席), 잠자리, 좌석(坐席), 증인석(證人席), 특석(特席), 한자리 </p> ### 경계 **경계**란 어떤 대상과 대상을 구분할 수 있게 해 주는 것입니다. <p class="message"> 갈림길, 강계(疆界), 경계(境界), 경계선(境界線), 경선(經線), 국경(國境), 국경선(國境線), 남방한계선(南方限界線), 북방한계선(北方限界線), 사선(死線), 수평선(水平線), 시계지평선(視界地平線), 적도(赤道), 접경지대(接境地帶), 지경(地境), 지평선(地平線), 휴전선(休戰線) </p> ### 지역 **지역**이란 사회, 문화, 역사적인 동질성으로 구분이 되는 인간의 활동 장소입니다. <p class="message"> 각지(各地), 강촌(江村), 강토(疆土), 거대도시(巨大都市), 건넛마을, 계획도시(計劃都市), 광산촌(鑛山村), 교구(敎區), 국제도시(國際都市), 남도(南道), 남부지방(南部地方), 농어촌(農漁村), 농촌(農村), 도시(都市), 도회, 도회지(都會地), 동네방네, 동리(洞里), 동양(東洋), 마을, 만주(滿洲), 민촌(民村), 벽촌(僻村), 부락(部落), 부촌(富村), 북구(北歐), 북극(北極), 북반구(北半球), 북촌(北村), 빈민가(貧民街), 사창가(私娼街), 사회주의경제권(社會主義經濟圈), 산골마을(山___), 산촌(山村), 서역(西域), 세계(世界), 세계만방(世界萬邦), 속령(屬領), 슬럼가(slum_), 시골, 시내(市內), 시중(市中), 어촌(漁村), 위험반원(危險半圓), 전국(全國), 전원도시(田園都市), 주요지역(主要地域), 지방(地方), 지역(地域), 촌(村), 촌락(村落), 취락(聚落), 판도(版圖), 팔도(八道) </p> #### 대륙 **대륙**이란 인간이 활동하는 다소간의 광범위한, 예를 들어 국가보다 큰 지역 장소입니다. <p class="message"> 구대륙(舊大陸), 미주(美洲), 북미(北美), 서유럽(西__) </p> #### 국가 장소 주권을 갖고 자치적인 통치력을 행사하고 법적으로 경계가 정해진 지역장소 <p class="message"> 국가(國家), 남조선(南朝鮮), 독일(獨逸), 동독(東獨), 러시아(Russia), 몽골(蒙古), 북쪽나라(北___), 외국(外國), 위협국가(威脅國家), 타국(他國) </p> #### 행정구역 국가의 행정으로 분할된 장소 <p class="message"> 구(區), 군현(郡顯), 도내(道內), 도성(都城), 모스크바(Moskva), 북도(北道), 서울, 선거구(選擧區), 성읍(城邑), 소읍(小邑), 수도권(首都圈), 신도시(新都市), 영내(領內), 영지(領地), 왕도(王都), 왕성(王城), 읍내(邑內), 장안(長安), 직할시(直轄市), 타도(他道), 호남(湖南) </p> ### 속성/기능 장소 **속성/기능장소**란 특정 속성이나 기능을 갖는 장소입니다. <p class="message"> 강나루, 강제수용소(强制收容所), 객지(客地), 거점(據點), 거주지역(居住地域), 검문소(檢問所), 경품사이트(景品___), 고분(古墳), 고적(古蹟), 고해(苦海), 곳곳, 공란(空欄), 공사장(工事場), 공석(公席), 공영주차장(公營駐車場), 공터(空_), 과학단지(科學團地), 관광지(觀光地), 관광특구(觀光特區), 광구(鑛區), 군밤구덩이, 군영(軍營), 권좌(權座), 그린(green), 근거(根據), 근거지(根據地), 금산(金山), 급식사업소(給食事業所), 기관실(汽罐室), 길지(吉地), 난대(暖帶), 남쪽나라(南___), 냉장실(冷藏室), 냉탕(冷湯), 노동시장(勞動市場), 노동현장(勞動現場), 뉴스룸(news room), 달동네(_洞_), 당산(堂山), 대내(對內), 대피소(待避所), 도매시장(都賣市場), 도박판(賭博_), 도심(都心), 도지(賭地), 돌팔이글방(____房), 두렁, 두메, 둥지, 뒷간(_間), 땔감숲, 리본꽃밭(ribbon__), 마구간(馬廐間), 마운드(mound), 막후(幕後), 매표소(賣票所), 메카(Mecca), 면허시험장(免許試驗), 명당(明堂), 명소(名所), 명승지(名勝地), 목공소(木工所), 목물전(木物廛), 못자리, 묘역(墓域), 무대(舞臺), 무법지대(無法地帶), 문고(文庫), 문화식민지(文化植民地), 문화유적지(文化遺跡地), 미궁(迷宮), 밀실(密室), 바다기상대(__氣象臺), 바람막이숲, 박토(薄土), 배구장(排球場), 배수진(背水陣), 번식지(繁殖地), 벙커(bunker), 벽장(壁欌), 병영(兵營), 보물섬(寶物_), 보세건설장(保稅建設場), 보호구역(保護區域), 불단(佛壇), 비경(秘境), 빨래터, 사석(私席), 사적(史蹟), 성소(聖所), 성역(聖域), 성지(聖地), 소금밭, 소독실(消毒室), 숯가마, 스케이트장(skate_), 스테이지(stage), 시골구석, 신방(新房), 신역(神域), 신위(神位), 신천지(新天地), 아열대(亞熱帶), 안벽뜰(岸壁_), 안전지대(安全地帶), 암흑가(暗黑街), 양달유적(陽_遺蹟), 업소(業所), 여지(餘地), 연락처(連絡處), 연병장(練兵場), 연회석(宴會席), 연회장(宴會場), 열대(熱帶), 염전(鹽田), 옛터, 오지(奧地), 온대(溫帶), 온천장(溫泉場), 온탕(溫湯), 완충지대(緩衝地帶), 외딴곳, 요새지(要塞地), 요양지(療養地), 요지(要地), 요충(要衝), 요충지(要衝地), 용지(用地), 우주정류장(宇宙停留場), 운동경기장(運動競技場), 운동본부(運動本部), 운동장(運動場), 위험지구(危險地區), 위험지역(危險地域), 유령도시(幽靈都市), 유명사이트(有名___), 유적지(遺跡地), 유전(油田), 유통단지(流通團地), 유통시장(流通市場), 유흥가(遊興街), 은닉처(隱匿處), 은신처(隱身處), 음지(陰地), 응급실(應急室), 응달, 일터, 임업시험장(林業試驗場), 임지(任地), 입지(立地), 자취방(自炊房), 자치지역(自治地域), 작업장(作業場), 장벽막장(長壁__), 재래시장(在來市場), 재판정(裁判廷), 전당(殿堂), 전시실(展示室), 조련장(操鍊場), 종합쇼핑몰(綜合___), 주거공간(住居空間), 주거단지(住居團地), 주거지역(住居地域), 주식시장(株式市場), 주차공간(駐車空間), 주택가(住宅街), 중계국(中繼局), 중탕(重湯), 증권시장(證券市場), 지역구(地域區), 직영지(直營地), 참여광장(參與廣場), 채석장(採石場), 처녀지(處女地), 처리장(處理場), 처소(處所), 초토(焦土), 최적지(最適地), 추진본부(推進本部), 춤판, 취사장(炊事場), 취직자리(就職__), 카운터(counter), 탁아소(託兒所), 탈출구(脫出口), 특정사이트(特定_), 피난처(避難處), 하우스(house), 학창(學窓), 한증막(汗蒸幕), 함정(陷穽), 항도(港都), 해방구(解放區), 해병훈련소(海兵訓練所), 행선지(行先地), 향락시설(享樂施設), 향락지구(享樂地區), 향촌(鄕村), 향토(鄕土), 현장(現場), 현지(現地), 화상경마장(畵像競馬場), 황도(皇都), 황무지(荒蕪地), 회복실(回復室), 회의장(會議場), 휴식처(休息處) </p> #### 일시적기능장소 일시적으로 특정 기능을 하는 장소 <p class="message"> 건설현장(建設現場), 공격목적(攻擊目的), 교두보(橋頭堡), 교통지옥(交通地獄), 굿판, 그라운드(ground), 그린벨트(green belt), 난전(亂廛), 노점(露店), 노점상(露店商), 놀이마당, 단식농성장(斷食籠城場), 병상(病床), 병석(病席), 본보기시장(本__市場), 비트, 빈소(殯所), 선물시장(先物市場), 수산시장(水産市場), 숙소(宿所), 시험장소(試驗場所), 싸움터, 싸움판, 아지트(아지트), 야외무대(野外舞臺), 야전병원(野戰病院), 어시장(魚市場), 유세장(遊說場), 일선(一線), 자유금시장(自由金市場), 장터(場_), 적지(敵地), 적진(敵陳), 전장(戰場), 전쟁구역(戰爭區域), 점령지(占領地), 주둔지(駐屯地), 중간기착지(中間寄着地), 중앙도매시장(中央都賣市場), 진영(陣營), 진중(陣中), 집결지(集結地), 참호(塹壕), 촬영장(撮影場), 투표소(投票所), 파시(波市), 할인시장(割引市場), 합동분향소(合同焚香所), 형장(刑場), 회의소(會議所) </p> #### 기준점 인간의 특정 행위와 관련하여 시작, 종결 등의 기준이 되는 점적인 장소 <p class="message"> 기점(起點), 목적지(目的地), 시발점(始發點), 출발점(出發點), 톨게이트(tollgate) </p> #### 사육장소 <p class="message"> 계사(鷄舍), 닭장(_欌), 돈사(豚舍), 목장(牧場), 사육장(飼育場), 양계장(養鷄場), 양식장(養殖場), 온상(溫床), 온실(溫室), 외양간(_間), 우리, 축사(畜舍) </p> #### 감옥 
tense␞ 이번 글에서는 한국어의 시제에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 시제 시제(tense)란 절이나 문장이 나타내는 사태가 발생한 시간적 위치를 문법적 수단을 통해 나타난 것을 가리킵니다. 사태의 발생 시점을 나타내는 언어적 수단 가운데는 어휘적 수단도 있고 문법적 수단도 있을 수 있는데, 이 가운데 문법적 수단에 의한 것만을 시제라고 합니다. 시제 언어란 과거 사태와 비(非) 과거 사태가 필수적으로 구분되어 쓰이고, 이 역할을 담당하는 시제 형태소가 있는 언어를 뜻합니다. 시제 언어는 다음과 같이 두 개 유형이 있습니다. - **2분법** : 과거/비과거 또는 비미래/미래 - **3분법** : 과거/현재/미래 2분법의 대표적인 사례는 과거 대 비과거 체계를 가지고 있는 일본어입니다. 영어는 논란의 여지가 있으나 과거-현재-미래의 3분적 시제 체계를 갖는 언어라고 할 수 있다고 합니다.  한편 세계 언어들은 미래보다는 과거의 의미 영역을 세분하는 경향이 있다고 합니다. 예컨대 '먼 과거', '가까운 과거' 등으로 나누는 것입니다.   ## 한국어의 시제 체계 현대 한국어는 시제 언어입니다. 과거와 비과거의 구별이 다음과 같이 거의 필수적으로 표시되기 때문입니다.  | 과거 | 비과거 | | :--: | :--: | | -었- | -는- | | -었- | -Ø- | 논란이 있기는 하지만 한국어는 과거-현재-미래의 3분 체계로 볼 수 있다고 합니다. 다음 표와 같습니다.  <a href="https://imgur.com/1QiZ2cH"><img src="https://i.imgur.com/1QiZ2cH.png" width="500px" title="source: imgur.com" /></a>  한국어의 과거, 현재, 미래시제 등을 차례대로 살펴 보겠습니다.   ## 과거 시제 한국어 과거 시제는 '-었-'과 '-었었-'으로 실현됩니다.  ### -었- '-었-'는 한국어에서 대표적인 **과거** 표시 형태소입니다. 다음 예문과 같습니다. > 나는 어제 밥을 먹**었**다. '-었-'결과 상태 지속을 나타내던 '-어 잇-'이 문법화한 형태소입니다. 이 때문에 일부 동사와 '-었-'이 결합하면 과거가 아니라 **결과 상태 지속**의 의미를 나타냅니다. 다음 예문을 보겠습니다. > 꽃이 피**었**다. 위 예문에서 '피다'는 끝(end)이 있는 행위를 가리키는 동사입니다. 개화(開花)는 특정 시점에만 이뤄지는 사건으로 끝이 존재합니다. 이러한 부류의 동사를 유계(telic) 동사라고 합니다. 한국어 유계동사의 예에는 웃다, 싸우다, (바람이)불다, 걷다, 뛰다 등이 있습니다. '-었-'은 유계동사와 결합하면 결과나 상태가 지속되고 있다는 의미를 가집니다. 위 예문의 경우 꽃이 핀 상태가 지속되고 있다는 의미로 '-었-'이 쓰였다고 말할 수 있습니다. 물론 '-었-'과 유계동사가 결합한다고 무조건 결과 상태 지속의 의미를 나타내는 것은 아닙니다. 다음 예문을 보겠습니다. > (1) 진이는 결혼했으니까 잊어버려. (결과 상태 지속) > > (2) 진이는 올림픽공원에서 결혼했다. (과거) (1)의 경우 유부녀인 상태가 지속되고 있다는 의미로, (2)의 경우 결혼식이라는 사건이 과거에 일어났다는 취지로 쓰였음을 확인할 수 있습니다. '-었-'은 특이하게 미래의 일에 쓰이기도 합니다. **아직 시작도 하지 않은 일을 이미 끝난 일처럼 말하는 용법**으로 사용됩니다. 예문과 같습니다. > 너 이제 장가는 다 갔다. > > 너 내일 죽었다.   ### -었었- '-었었-' 또한 과거 표시 형태소입니다. 하지만 '-었-'과는 달리 말하는 시점(발화시)에는 성립하지 않는 사건, 즉 **단절된 과거**를 나타냅니다. 예문과 같습니다. > 그 시, 고등학교 때는 외웠었다. (이제는 다 잊어버렸다) > > 진이는 어렸을 때 예뻤었다. (지금은 별로 안 예쁘다) '-었었-'은 과거 기준점보다 앞선 시점에 일어난 사태, 즉 **과거에서의 과거(대과거)**를 나타내는 데에도 쓰입니다. 다음 예문을 보겠습니다. > 진이는 9시에야 학교에 도착했다. 집에서 7시에 떠났었다. 최근에는 '-었었-'이 자주 쓰이면서 '-었-'과 비교해 '-었었-'이 가지는 특별한 의미 기능이 잘 드러나지 않는 경우가 많아졌습니다. 일종의 의미의 인플레이션 현상이 나타난 것이지요. 자동차 비상깜빡이가 일상적으로 사용되면서 비상깜빡이를 켰다고 emergency라고 인지하는 운전자들이 적어진 것과 비슷한 이치입니다.   ## 현재 시제 한국어의 현재 시제는 환경에 따라 그 형태가 다양합니다. 다음 예문과 같습니다. - **-는다** : 서술어 동사, 종결어미 '-다', 자음 뒤 (예) 먹는다 - **-ㄴ다** : 서술어 동사, 종결어미 '-다', 모음 뒤 (예) 간다 - **Ø** : 종결어미가 '-거든', '-어' 등일 때 (예) 먹어, 먹거든 - **-는구나** : 서술어 동사, 종결어미 '-구나' (예) 먹는구나, 가는구나 예정된 미래나 확실한 미래는 현재가 아니지만 현재 시제를 씁니다. 다음 예문과 같습니다. > 나는 내일 떠난다. 시간의 제한에 제약을 받지 않는 보편적 사실을 진술할 때에도 현재 시제가 사용됩니다. > 지구는 태양을 돈다. > > 진이는 커피 전문점을 운영한다. 과거에 일어난 일이지만 현장감을 강조할 때 쓰이기도 합니다. > 케네디는 중대 발표를 결심한다.   ## 미래 시제 논란의 여지가 있지만 한국어의 미래 시제는 '-을 것이-'와 '-겠-'으로 실현된다고 볼 수 있다고 합니다. 이들은 모두 추측과 떼려야 뗄 수 없는 관계를 가지고 있습니다. '-겠-'은 화자가 내면화하지 않은 정보에 기반을 둔 추측, 혹은 현장 지각에 따른 화자의 추측, 화자 자신의 지각력을 바탕으로 한 추측을 나타냅니다. 다음 예문은 기상 캐스터가 구름 사진 등을 판독하면서 하는 말입니다. > 내일은 남부 지방에 걸쳐 있는 기압골의 영향으로 남부 지방에 많은 비가 내리겠습니다. '-을 것이-'는 내면화된 정보를 바탕으로 한 추측, 화자 또는 타인의 지식이나 믿음에 바탕을 둔 화자의 추측을 나타냅니다. 다음 예문은 일기예보에 관한 보도를 듣고 내일 날씨에 관한 지식을 획득한 뒤 이를 바탕으로 추측을 한 일반인의 말입니다. > 내일은 비가 올 거야. 다음 상황에서는 각각 '-겠-', '-을 것이-'을 쓰는 것이 더 자연스럽습니다. > (테이블 끝에서 떨어질락 말락 하고 있는 공을 보고) {떨어지겠다/??떨어질 것이다}. > > (긴 테이블 한 가운데에서 천천히 굴러가고 있는 공의 속도 등을 바탕으로 추측건대) 공은 테이블에서 {?떨어지겠다/떨어질 것이다}.    ## 상대시제 시제는 일정한 시점을 기준으로 하여 어떤 사건의 시간적 전후 관계를 표시하는 문법범주입니다. 지금까지 설명해드린 시제 개념에서 기준이 되는 '일정한 시점'은 말하는 시점(발화시)이었습니다. 다음 예문을 보겠습니다. > 동생이 배가 아프다고 투덜거렸어요. > > 냇물에서 수영하는 아이들을 보았어요. 위 예문에서 아픈 시점, 수영을 한 시점은 발화시를 기준으로 과거에 해당합니다. 하지만 그 형태를 보면 현재 시제로 쓰였습니다. 정동사절(종결어미가 붙은 서술어)의 시제가 기준이 되었기 때문입니다. 다시 말해 위 예문 모두 해당 사건이 일어난 시점은 '과거 기준으로 현재', 즉 과거라는 이야기입니다.  이처럼 발화시가 아닌 다른 시점을 기준으로 결정되는 시제를 상대시제라고 합니다. 상대시제는 복문을 분석할 때 유용합니다. 아래 예문에서 '노래하고'와 '노는'의 발화시 기준 절대시제는 다음과 같습니다. > 다 같이 노래하고 춤춘다 : 현재의 현재=현재 > > 다 같이 노래하고 춤추었다 : 과거의 현재=과거 > > 공원에서 노는 아이들을 본다 : 현재의 현재=현재 > > 공원에서 노는 아이들을 보았다 : 과거의 현재=과거 하지만 복문에서 상대시제가 일률적으로 적용되지는 않습니다. 다음 예문을 보겠습니다. > (가) 내가 지금 **읽는** 책을 아빠가 좋아했다. > > (나) 진이는 책을 **읽었고** 민이는 음악을 들었다. 기존 상대시제에 기반해 (가)를 분석하면 '읽은'의 발화시 기준 절대시제는 '과거의 현재', 즉 과거가 됩니다. 하지만 문장을 자세히 보면 내가 책을 읽는 사건은 현재에 일어난 것입니다. (나)의 경우 기존 상대시제에 기반해 '읽은'의 발화시 기준 절대시제를 따져보면 '과거의 과거', 즉 대과거가 됩니다. 하지만 진이가 책을 읽는 사건은 그저 과거에 일어났다고 보는 것이 자연스럽습니다. 어미의 종류에 따라 '-었-'이 반드시 실현되어야 하거나 실현되지 않아야 하는 경우가 있습니다. 다음 예문과 같습니다. > (다) 진이는 집에 {가자마자/*갔자마자} 숙제부터 했다. > > (라) 진이는 춤을 {*추나/추었으나} 민이는 노래를 불렀다. (다)의 경우 '가다'라는 사건은 상대시제로 해석해야 합니다(과거의 현재=과거). (라)의 경우 '추다'라는 사건은 발화시 기준 절대시제로 해석해야 합니다(과거). 
CNN␞ 이번 포스팅에서는 **Convolutional Neural Networks(CNN)**로 문장을 분류하는 방법에 대해 살펴보겠습니다. 이번 포스팅의 아키텍처와 코드는 각각 [Yoon Kim(2014)](http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf)과 [이곳](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)을 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 자연어 처리에 특화된 네트워크 구조? 자연언어는 단어나 표현의 등장 순서가 중요한 **sequential data**입니다. 아래 예문을 볼까요? > {무거운 / \*가벼운 / \*큰} 침묵 > > 침묵이 {\*무겁다}. > **Only** I hit him in the eye yesterday. (No one else did) > > I **only** hit him in the eye yesterday. (did not slap him) '무거운 침묵'은 고정된 형식으로 '정적이 흐르는 상태가 매우 심하다'는 뜻의 **연어(collocation)**으로 쓰입니다. 하지만 순서를 바꿔서 '침묵이 무겁다'는 표현은 문장 자체가 성립되지 않는 비문이라고 할 수 있죠. 영어의 경우 위 예시처럼 단어 등장 순서가 의미 차이를 만드는 경우가 많습니다. 이렇듯 단어나 표현의 순서는 그 의미 차이를 드러내거나 문장 성립 여부를 결정하는 등 중요한 정보를 함축하고 있습니다. **Recurrent Neural Networks(RNN)**이나 이번 포스팅의 주제인 CNN은 등장 순서가 중요한 sequential data를 처리하는 데 강점을 지닌 아키텍처입니다. RNN의 경우 아래와 같이 입력값을 순차적으로 처리합니다. 입력값을 '단어'로 바꿔놓고 생각해보면 단어의 등장 순서를 보존하는 형태로 학습이 이뤄지게 됨을 알 수 있습니다. <a href="http://imgur.com/MIlIxoJ"><img src="http://i.imgur.com/MIlIxoJ.png" width="600px" title="source: imgur.com" /></a>  그렇다면 CNN은 어떨까요? 본래 CNN은 이미지 처리를 하기 위해 만들어진 아키텍처입니다. 아래 움짤([출처](http://cs231n.github.io/convolutional-networks/))처럼 **필터(filter)**가 움직이면서 이미지의 지역적인 정보를 추출, 보존하는 형태로 학습이 이뤄지게 됩니다. ![cnn](http://i.imgur.com/OXwLhaf.gif) CNN을 텍스트 처리에 응용한 연구가 바로 [Yoon Kim(2014)](http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf)입니다. 이미지 처리를 위한 CNN의 필터(9칸짜리 노란색 박스)가 이미지의 지역적인 정보를 추출하는 역할을 한다면, 텍스트 CNN의 필터는 텍스트의 지역적인 정보, 즉 단어 등장순서/문맥 정보를 보존한다는 것이죠. 이를 도식화하면 제가 만든 아래 움짤과 같습니다. <a href="http://imgur.com/1Flo6TK"><img src="http://i.imgur.com/1Flo6TK.gif" width="500px" title="source: imgur.com" /></a> 위 움짤을 자세히 보시면 한 문장당 단어 수는 총 n개**(아래 설명해 드릴 코드에서 변수명 : sequence_length)**입니다. 이 단어들 각각은 p차원**(변수명 : embedding_size)**의 벡터이구요, 붉은색 박스는 필터를 의미합니다. 위 움짤의 경우 필터의 크기는 2로써 한번에 단어 2개씩을 보게 됩니다. 이 필터는 문장에 등장한 단어 순서대로 슬라이딩해가면서 문장의 지역적인 정보를 보존하게 됩니다. 필터의 크기가 1이라면 Unigram, 2라면 Bigram, 3이면 Trigram.. 이런 식으로 필터의 크기를 조절함으로써 다양한 **[N-gram](https://en.wikipedia.org/wiki/N-gram)** 모델을 만들어낼 수 있습니다.  **요컨대 RNN은 단어 입력값을 순서대로 처리함으로써, CNN은 문장의 지역 정보를 보존함으로써 단어/표현의 등장순서를 학습에 반영하는 아키텍처라 할 수 있겠습니다.** RNN과 CNN이 자연언어처리 분야에서도 각광받고 있는 이유이기도 합니다. 이 글에서 설명하지 않았지만 **Recursive Neural Networks**도 단어/표현의 등장순서를 학습에 반영하는 구조인데요, Recursive Neural Networks의 자세한 내용을 보시려면 [이곳](https://ratsgo.github.io/deep%20learning/2017/04/03/recursive/)을 참고하시면 좋을 것 같습니다. 아울러 CNN의 **역전파(backpropagation)** 등 학습방식에 관심이 있으시면 [이곳](https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/)을, RNN의 어플리케이션 사례를 보시려면 [이곳](https://ratsgo.github.io/natural%20language%20processing/2017/03/12/s2s/)을 방문하시길 권해드립니다.  ## CNN을 활용한 문장 분류 아키텍처 [Yoon Kim(2014)](http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf)의 아키텍처는 아래와 같습니다. <a href="http://imgur.com/JN72JHW"><img src="http://i.imgur.com/JN72JHW.png" width="600px" title="source: imgur.com" /></a> 이 논문은 영화 리뷰 사이트에 게시된 댓글과 평점 정보를 이용해 각 리뷰가 긍정인지 부정인지 분류하는 모델을 만들고자 했습니다. n개의 단어로 이뤄진 리뷰 문장을 각 단어별로 k차원의 행벡터로 임베딩합니다. 단어를 벡터로 임베딩하기 위해서는 [Word2Vec](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/)이나 [GloVe](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/09/glove/)처럼 [distributed representation](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/29/NNLM/)을 쓸 수도 있고요, 단어벡터의 초기값을 랜덤으로 준 뒤 이를 다른 파라메터들처럼 학습 과정에서 조금씩 업데이트해서 사용하는 방법도 있습니다. 한편 위 그림을 보면 CNN 필터의 크기는 2와 3인데요, 각각 Bigram, Trigram 모델을 뜻한다고 볼 수 있겠습니다. 이후 필터 개수만큼의 **feature map**을 만들고, **Max-pooling** 과정을 거쳐 클래스 개수(긍정 혹은 부정 : 2개)만큼의 스코어를 출력하는 네트워크 구조입니다.  ## 영화리뷰를 숫자로 바꾸기 텐서플로우 코드로 구현된 이 아키텍처를 한국어 영화 리뷰에 적용해 보기로 했습니다. 우선 영화 리뷰 품질이 국내에서 가장 좋은 것으로 평가받는 [왓챠](https://watcha.net/)에서 댓글과 평점 데이터 657만2288건을 모았습니다. 스크래핑한 데이터는 아래와 같습니다. ``` 알프레도는 필름을 통해 인생과 사랑에 대해서 얘기하고자 했던것같다. 그 무수한 날들을 거치면서 항상 전진해야했던 토토에 비해 영화는 항상 향수를 자극시키며 그 자리에 계속 있었다. 많은 오고가는 흐릿한 생각들 끝에 내가 생각하는 영화는 정말 사랑과도 같다. 이해할수도 설명할수도 없는 그 느낌. 이 영화를 통해 영화를 더욱 사랑하게되었다, 5.0 고마워요 알프레도, 4.0 나머지 별 반개는 감독판을 보는 날에, 4.5 영화가 주는 감동이란..., 4.5 뭘 얘기하고 싶은건데?, 2.0 ``` 우선 CNN 문장분류 아키텍처의 입력값과 출력값을 만들어야 합니다. 우선 입력 데이터를 만들어 볼까요? 이 글에서는 Word2Vec 같은 distributed representation을 쓰지 않고, 단어벡터를 랜덤하게 초기화한 뒤 이를 학습과정에서 업데이트하면서 쓰는 방법을 채택했습니다. 이런 방식을 사용하기 위해서는 위 텍스트 문장을 숫자들(단어의 ID)의 나열로 변환해야 합니다.  그런데 단어들이 너무 많으면 메모리 문제로 학습 자체가 불가능해지므로 전체 단어 숫자를 좀 줄일 필요가 있습니다. 이 때문에 문장을 띄어쓰기 기준으로 어절로 나누고 어절 처음 두 글자만 잘랐습니다. 바꿔 말하면 아래 단어들을 모두 한 단어로 보는 방식입니다. 이 방식을 적용하면 말뭉치에 등장하는 전체 단어수**(변수명 : vocab_size)**를 아무런 처리를 하지 않았던 기존 대비 4분의 1로 줄일 수 있습니다.  > **잘어**울리는 > **잘어**울렸다 > **잘어**울리네요 > **잘어**울리는데 > **잘어**울림 > **잘어**울려요 > **잘어**울리고 > **잘어**울렸는데 > **잘어**울렸음 > **잘어**울린다 이후 단어별로 ID를 부여해 사전을 만들었습니다. 이 사전을 가지고 각 리뷰를 ID(숫자)들의 나열로 바꾸는 것입니다. > {‘가’: 0, ‘가가’: 1, ‘가감’: 2, (중략) '잘어': 10004, (하략) } 이제 출력(정답) 데이터를 살펴볼까요? 왓챠 평점은 5점 만점인데 2.5점보다 높으면 긍정([1,0])을, 2.5점보다 낮으면 부정([0,1]) 범주를 부여했습니다. 지금까지 설명한 방식을 적용해 입력값과 출력값을 만든 결과의 예시는 아래와 같습니다.  ``` 고마워요 알프레도 (하략), 4.0         [[502, 3101, ......], [1,0]] 영화가 주는 감동이란 (하략), 4.5      [[2022, 3043, 301, ...], [1,0]] 뭘 얘기하고 싶은건데? (하략), 2.0       [[1005, 2206, 1707, ...], [0,1]] ```  ## Lookup 테이블 구축 지금까지 우리가 만든 입력값은 아래 그림에서 빨간색 박스에 대응됩니다. 다시 말해 문장 길이**(변수명 : sequence_length)**에 해당하는 개수만큼의 단어 ID들의 나열이죠. 이미 설명드렸다시피 이번 글에서는 Word2Vec을 쓰지 않고 단어벡터를 만들기로 했었습니다. 대신 커다란 Lookup 테이블(아래 그림에서 파란색 박스)을 만들겁니다. 이 테이블의 크기는 전체 단어수**(변수명 : vocab_size) ** * 사용자가 지정한 단어벡터 차원수**(변수명 : embedding_size)**입니다. 파란색 박스의 행벡터들은 개별 단어 ID에 대응하는 벡터입니다. 초기값은 랜덤하게 설정하고요, 이후 학습 과정에서 문장 분류를 가장 잘하는 방식으로 조금씩 업데이트됩니다.  지금까지 리뷰를 단어 ID들의 나열로 바꿨고, ID에 해당하는 단어벡터도 만들었으니 이제 단어 ID들 각각을 벡터로 바꿔주기만 하면 되겠네요. 방법은 쉽습니다. 파란색 Lookup 테이블에서 단어 ID에 해당하는 행벡터를 참조해서 가져오기만 하면 됩니다. 그 결과는 바로 아래 그림의 보라색 박스입니다. 이 박스의 크기는 (문장길이 * 사용자가 지정한 단어벡터 차원수)가 됩니다. ![cnn input](http://i.imgur.com/EXiUlme.png) 이상 논의한 내용을 텐서플로우 코드로 표현하면 다음과 같습니다. 최종 결과물인 보라색 박스에 대응하는 변수명은 **embedded_chars**인데요, 여기에 conv2d 함수가 요구하는 차원수로 만들어주기 위해 차원을 하나 추가해 줍니다.  ```python W = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name="W") embedded_chars = tf.nn.embedding_lookup(W, input_x) # 차원수: [sequence length, embedding size] embedded_chars_expanded = tf.expand_dims(embedded_chars, -1) # 차원수 : [sequence length * embedding size * 1] ```   ## Conv Layer 만들기 **embedded_chars_expanded**는 **배치(batch)** 단위로 CNN에 들어가게 됩니다. 배치를 반영한 입력값의 차원수는 [batch_size, sequence_length, embedding_size, channel_size]가 됩니다. 그런데 제가 실험한 CNN 구조에선 채널수를 1로 설정하여서 결과적으로 [batch_size, sequence_length, embedding_size, 1]이 됩니다. 자, 그러면 필터의 차원수를 살펴보겠습니다. 아래 그림을 보면 아시겠지만 필터의 너비는 **embedding_size**입니다. 높이는 **filter_size**인데요, 만약 2라면 Bigram, 3이라면 Trigram 모델이 될 겁니다. 채널수는 1로 고정했습니다.  ![filter](http://i.imgur.com/WlGbDJfm.png) 이를 종합해 텐서플로우가 요구하는 문법으로 필터 차원수를 정의하면 이렇습니다. > filter_shape = [filter_size, embedding_size, 1, num_filters] 자, 그러면 텐서플로우 구현의 핵심인 conv layer를 만드는 부분을 볼까요? 여기서 입력값과 필터의 가중치는 각각 embedded_chars_expanded와 W입니다. 필터가 입력값을 볼 때 그 보폭(strides)은 [1, 1, 1, 1]로 하고 엣지 패딩없이 문장을 슬라이딩하라는 뜻입니다.  ```python conv = tf.nn.conv2d(self.embedded_chars_expanded,           W,           strides=[1, 1, 1, 1],           padding="VALID",           name="conv") h = tf.nn.relu(tf.nn.bias_add(conv, b), name="relu") ``` 그럼 [1, 1, 1, 1]의 의미는 무엇일까요? 텐서플로우 문서를 보면 strides값은 [batch_size, input_height, input_width, input_channels] 순서로 지정하라고 정의돼 있습니다. 보폭이 [1, 1, 1, 1]이라는 건 배치데이터 하나씩, 단어 하나씩 슬라이딩하면서 보라는 의미입니다. 그런데 여기서 input_width와 input_channels는 큰 의미가 없습니다. 왜냐하면 우리는 입력값의 너비와 필터의 너비를 embedding_size로 같게 설정했고, 채널수는 1로 모두 고정했기 때문입니다. 바꿔 말하면 보폭 [1, 1, 1, 1] 중 뒤의 두 개는 입력데이터와 필터가 같은 값을 지니기 때문에 슬라이딩할 수 있는 여유 공간이 없어 무의미하다는 뜻입니다.  이렇게 conv를 적용한 뒤의 텐서 차원수는 [batch_size, sequence_length - filter_size + 1, 1, num_filters]가 됩니다. 첫번째 요소 batch_size가 나오는 건 직관적으로 이해 가능하실 것 같고요, 나머지 차원수에 대해서는 텐서플로우 공식문서를 확인하시면 빠르게 이해하실 수 있으실 겁니다. 이후 ReLU를 써서 비선형성(non-linearity)을 확보합니다. 이제 Max-pooling하는 부분을 보겠습니다. 여기서 핵심은 **ksize**인데요, Max-pooling하는 영역의 크기가 되겠습니다. 예컨대 ksize가 [1, 2, 2, 1]이라면 배치데이터/채널별로 가로, 세로 두 칸씩 움직이면서 Max-pooling하라는 지시입니다. Max-pooling이 적용된 후의 텐서 차원수는 [batch_size, 1, 1, num_filters]가 됩니다.  ```python pooled = tf.nn.max_pool(h,           ksize=[1, sequence_length - filter_size + 1, 1, 1],           strides=[1, 1, 1, 1],           padding='VALID',           name="pool") ``` 이후엔 Max-pooling한 결과물을 합치고 Full-connected layer를 통과시켜 각 클래스에 해당하는 스코어를 낸 뒤 **크로스엔트로피오차**를 구하고 **역전파(Backpropagation)**를 수행해 필터의 가중치 등 파라메터들을 업데이트하는 일반적인 과정을 거칩니다. 여기서 특이한 점은 단어벡터의 모음인 Lookup 테이블도 학습과정에서 같이 업데이트한다는 사실입니다.  ## 코드 공유 지금까지 이야기한 내용을 바탕으로 [이곳](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)을 참고해 커스터마이징한 코드는 아래와 같습니다. <script src="https://gist.github.com/ratsgo/7ff405f582437dbf96216dd940917427.js"></script> 위 코드에 쓰인 입력데이터 전처리용 코드는 다음과 같습니다. <script src="https://gist.github.com/ratsgo/d5c43d40be348987c69466c81edb3904.js"></script> 제가 실험한 결과도 간략히 소개합니다. 제가 선택한 하이퍼파라메터 조합은 아래와 같습니다. ``` embedding_size = 128 filter_sizes = 3,4,5 num_filters = 128 dropout_keep_prob = 0.5 batch_size = 64 max_document_length = 100 ``` 우선 [왓챠](https://watcha.net/)에서 모은 댓글과 평점 데이터 657만2288건 가운데 80%를 학습데이터, 20%를 검증데이터로 분리했습니다. 학습에 쓰지 않은 검증데이터에 대한 예측 결과(단순정확도)는 step수가 3만회를 넘어가면서 85% 내외로 수렴하는 모습을 보였습니다. 그 결과는 다음과 같습니다. ``` step 37600, loss 0.401777, acc 0.87 step 41500, loss 0.347608, acc 0.85 step 47000, loss 0.384077, acc 0.84 step 51000, loss 0.30739, acc 0.86 step 53800, loss 0.328676, acc 0.82 ```  ## 마치며 이상으로 CNN을 활용한 문장 분류 모델을 살펴보았습니다. CNN은 지역 정보를 보존한다는 점에서 순차적인 데이터 처리에 강점을 지닌 RNN과 더불어 자연언어처리 분야에서 주목을 받고 있습니다. 평점이라는 정답 데이터가 존재한다면 CNN을 가지고도 훌륭한 문장 분류기를 만들어낼 수 있다는 사실을 실험적으로 확인할 수 있었습니다. 제언이나 질문하실 것 있으시면 언제든지 댓글이나 이메일로 연락주시기 바랍니다. 여기까지 읽어주셔서 감사합니다.
gradient␞ 이번 글에서는 그래디언트 디센트(Gradient Descent)에 대해 살펴보도록 하겠습니다. 이 글은 고려대 강필성 교수님 강의와 하용호 님의 [자료](https://www.slideshare.net/yongho/ss-79607172)를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 산등성이 내려가기 우리는 오차가 적은 모델을 만들고 싶습니다. 이 오차는 미리 구해졌다고 칩시다. 딥러닝 모델의 오차가 무엇인지에 관련해서는 [이곳](https://ratsgo.github.io/deep%20learning/2017/09/24/loss/)을 참고하시기 바랍니다. 어쨌든 오차를 줄이는 과정, 즉 학습과정은 높은 산등성이에서 산 아래로 이동할 때 두 눈을 가리고 한발한발 내딛어 더 낮은 쪽으로 한걸음씩 내려가는 것에 비유할 수 있을 것입니다.   <a href="https://imgur.com/1ZtqOba"><img src="https://i.imgur.com/1ZtqOba.jpg" width="400px" title="source: imgur.com" /></a>  이 때 중요한 것은 현재 위치 $x_{old}$에서 내려가야 할 방향과 보폭입니다. 우리가 만들고 있는 모델을 $f$, 방향을 그래디언트(gradient) $f'$, 보폭을 학습률(learning rate) $α$(0<$α$<1)라고 두면, 그래디언트 디센트에 의해 정해진 다음 위치 $x_{new}$는 다음과 같이 정의됩니다.  $$ { x }_{ new }={ x }_{ old }-\alpha f^{ \prime }\left( {x}_{old} \right) $$  $f(x_{new})$는 $f(x_{old})$보다 항상 작습니다. 테일러 급수 전개(Taylor Series Expansion)를 활용해 유도해보겠습니다. $f(x+Δx)$는 테일러 급수 전개에 의해 다음과 같이 무한합으로 나타낼 수 있습니다.  $$ f\left( x+\Delta x \right) =f\left( x \right) +\frac { f^{ ' }\left( x \right) }{ 1! } \Delta x+\frac { f^{ '' }\left( x \right) }{ 2! } { \Delta x }^{ 2 }+... $$  $x_{new}=x_{old}-αf'(x_{old})$이므로 양변에 $f$를 적용하면 $f(x_{new})=f(x_{old}-αf'(x_{old}))$이 성립합니다. 여기에서 $x_{old}-αf'(x_{old})$를 위 테일러 급수 전개식의 $x+Δx$라고 보면 다음 또한 성립합니다.  $$ \begin{align*} f\left( { x }_{ new } \right) &=f\left[ { x }_{ old }-\alpha f^{ ' }\left( x \right) \right] \\&=f\left( { x }_{ old } \right) +\frac { f^{ ' }\left( { x }_{ old } \right) }{ 1! } \left[ -\alpha f^{ ' }\left( { x }_{ old } \right) \right] +\frac { f^{ '' }\left( { x }_{ old } \right) }{ 2! } { \left[ -\alpha f^{ ' }\left( { x }_{ old } \right) \right] }^{ 2 }+...\\ &\cong f\left( { x }_{ old } \right) -\alpha { \left[ f^{ ' }\left( { x }_{ old } \right) \right] }^{ 2 }<f\left( { x }_{ old } \right) \end{align*} $$ 위 식의 마지막 줄은 [테일러 급수 전개식을 2차항까지만 써서 근사](https://ratsgo.github.io/linear%20algebra/2017/10/20/projection/)한 결과입니다. 그런데 $f'(x_{old})^2$의 값은 항상 양수이므로 결론적으로 $f(x_{new})<f(x_{old})$가 성립합니다. 요컨대 그래디언트 디센트 기법을 취해 오차를 줄여나갈 수 있다는 이야기입니다.   ## 오차를 역전파하기 딥러닝 학습 과정에서는 모델이 틀린 정도(오차)를 모델 전체의 파라메터에 역전파(backpropagation)하게 됩니다. 미분하고 곱하고 더하고를 역방향으로 반복하며 파라메터를 업데이트하는 구조입니다. 오차를 역전파하는 과정에 대해서는 [이곳](https://ratsgo.github.io/deep%20learning/2017/05/14/backprop/)을 참고하시면 좋을 것 같습니다. 딥러닝 모델 파라메터 업데이트는 체인룰(chain rule)에 의해 그래디언트를 계속 **곱하는** 과정에서 이뤄집니다. 그런데 중간에 있는 계층의 그래디언트가 0이거나 작은 값이면 곱셈이 누적되는 과정에서 파라메터 업데이트가 잘 안되는 경우가 발생할 수 있습니다. 이를 **Vanishing Gradient** 문제라고 합니다.  Vanishing Gradient 문제는 맨 뒤에 있는 학생까지 줄을 세우려는 교장 선생님에 비유할 수 있습니다. (정말 명쾌한 비유라고 생각됩니다, 하용호님 감사합니다)  <a href="https://imgur.com/jw1mdkJ"><img src="https://i.imgur.com/jw1mdkJ.png" width="500px" title="source: imgur.com" /></a>  Vanishing Gradient 문제를 해결하기 위해 활성함수(activation function)를 바꾸는 방안이 제시됐습니다. 매우 큰 양수이거나 작은 음수일 때 그래디언트가 사그라드는 시그모이드 대신 ReLU 등을 사용하는 것입니다. 활성함수와 관련해서는 [이곳](https://ratsgo.github.io/deep%20learning/2017/04/22/NNtricks/)을 참고하시면 좋을 것 같습니다.   ## 파라메터 최적 업데이트 그래디언트 디센트 방법은 현재 위치 $x_{old}$에서 학습데이터 전체를 넣어 전체 오차를 계산한 뒤 나온 그래디언트를 구해 이 그래디언트의 역방향으로 $x_{old}$를 업데이트하는 방식입니다. 하지만 학습데이터의 양이 기본적으로 많은 만큼 계산량이 커질 수밖에 없습니다. 이 때문에 학습데이터의 일부만 활용해 그래디언트를 구하는 Stochastic Gradient Descent(SGD) 같은 다양한 업데이트 기법들이 제안되었습니다. 하용호 님 표현에 따르면 '느린 완벽보다는 불완전하나마 빠른 방식'을 택한 것이라 볼 수 있겠습니다. 그 개념을 도식화하면 다음과 같습니다. <a href="https://imgur.com/Oos1AjX"><img src="https://i.imgur.com/Oos1AjX.png" width="500px" title="source: imgur.com" /></a>  파라메터 업데이트 기법으로는 SGD를 비롯해 Momentum, RMSProp, Adam 등 다양한 방식이 제안되었습니다. 이 가운데 Adam의 성능이 좋은 것으로 알려져 있다고 합니다. 파라메터 업데이트 기법 간 관계도(하용호님 자료)는 다음과 같습니다. 파라메터 업데이트 기법과 관련 자세한 내용은 [이곳](https://ratsgo.github.io/deep%20learning/2017/04/22/NNtricks/)을 참고하시기 바랍니다.  <a href="https://imgur.com/8RbqC0z"><img src="https://i.imgur.com/8RbqC0z.png" title="source: imgur.com" /></a>
heapsort␞ 이번 글에서는 **힙(heap)**이라는 자료구조와 **힙 정렬(Heap Sort)** 알고리즘에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님과 역시 같은 대학의 김선욱 교수님 강의와 위키피디아를 정리하였음을 먼저 밝힙니다. 파이썬 코드 구현은 [이곳](https://github.com/TheAlgorithms/Python/blob/master/sorts/heap_sort.py)을 참고하였습니다. 그럼 시작하겠습니다.   ## Heap 힙은 큰 키(우선 순위)에 자주 액세스하거나 키(우선 순위) 중심으로 정렬된 시퀀스를 활용해야 할 때 유용한 자료구조입니다. 힙은 한 노드(node)가 최대 두 개의 자식노드(child node)를 가지면서, 마지막 레벨을 제외한 모든 레벨에서 노드들이 꽉 채워진 **완전이진트리(complete binary tree)**를 기본으로 합니다.  힙 속성(heap property)은 다음 두 가지입니다. - **heap order property** : 각 노드의 값은 자신의 자식노드가 가진 값보다 크거나 같다(최대 힙, Max heap). 각 노드의 값은 자신의 자식노드가 가진 값보다 작거나 같다(최소 힙, Min heap). - **heap shape property** : 모양은 완전이진트리이다. 즉 마지막 레벨의 모든 노드는 왼쪽에 쏠려 있다. (이진트리에 대해서 자세한 내용은 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/10/21/tree/)을 참고하시면 좋을 것 같습니다) 다음 그림이 바로 최대 힙 속성을 만족하는 자료구조입니다.   <a href="https://imgur.com/HBPzkwJ"><img src="https://i.imgur.com/HBPzkwJ.png" width="300px" title="source: imgur.com" /></a>      ## Heap vs Binary Search Tree 아래 그림은 이진탐색트리(Binary Search Tree)를 나타내고 있습니다. 힙과 이진탐색트리 모두 이진트리라는 점에서 공통점을 가지만 노드값이 다소 다르게 구성돼 있는 점을 확인할 수 있습니다. 힙은 각 노드의 값이 자식노드보다 큰 반면, 이진탐색트리는 왼쪽 자식노드가 제일 작고 부모노드가 그 다음 크며 오른쪽 자식노드가 가장 큰 값을 가집니다. 힙은 우선순위(키) 정렬에, 이진탐색트리는 탐색에 강점을 지닌 자료구조라고 합니다.  <a href="https://imgur.com/YmnDkvE"><img src="https://i.imgur.com/YmnDkvE.png" width="250px" title="source: imgur.com" /></a>  이진탐색트리와 관련해 자세한 내용은 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/10/22/bst/)을 참고하시면 좋을 것 같습니다.    ## Heap을 Array로 표현 힙은 완전이진트리(complete binary tree) 성질을 만족하기 때문에 다음처럼 1차원 배열(array)로도 표현이 가능합니다. <a href="https://imgur.com/3sUWVY2"><img src="https://i.imgur.com/3sUWVY2.png" width="500px" title="source: imgur.com" /></a>  이를 파이썬 코드로 구현하면 다음과 같습니다. 파이썬은 데이터의 인덱스가 0부터 시작합니다. 예컨대 인덱스가 2인 노드(10)의 왼쪽 자식노드(9)의 인덱스는 5, 오른쪽 자식노드(3)의 인덱스는 6이 됩니다. 어떤 노드의 인덱스를 *index*, 왼쪽 자식노드의 인덱스를 *left_index*, 오른쪽 자식노드의 인덱스를 *right_index*로 선언하면 다음과 같은 관계를 지닙니다. ```python left_index = 2 * index + 1 right_index = 2 * index + 2 ``` 하지만 글에서의 설명은 그림처럼 구성된 인덱스 기준으로 하겠습니다.   ## heapify 주어진 자료구조에서 힙 성질을 만족하도록 하는 연산을 *heapify*라고 합니다. 다음 예시와 같습니다.   <a href="https://imgur.com/5tVTziM"><img src="https://i.imgur.com/5tVTziM.png" width="500px" title="source: imgur.com" /></a>  먼저 4를 보겠습니다. 4는 왼쪽 자식노드 14보다 작으므로 힙 성질을 만족하지 않습니다(4는 오른쪽 자식노드 7보다도 작지만 알고리즘 구현상 왼쪽 자식노드 우선 적용). 4와 14 위치를 바꿉니다. 위치 변경 이후에도 힙 성질이 유지되는지 살펴야 합니다. 4는 새로운 왼쪽 자식노드 2보다는 크지만 오른쪽 자식노드 8보다는 작습니다. 힙 성질을 만족하지 않습니다. 4와 8 위치를 바꿉니다. 위치 변경 이후에도 힙 성질이 유지되는지 살펴야 하지만 더 이상 살필 자식노드가 없으므로 연산 수행을 종료합니다. *heapify*를 파이썬으로 구현한 코드는 다음과 같습니다. ```python def heapify(unsorted, index, heap_size):   largest = index   left_index = 2 * index + 1   right_index = 2 * index + 2   if left_index < heap_size and unsorted[left_index] > unsorted[largest]:     largest = left_index   if right_index < heap_size and unsorted[right_index] > unsorted[largest]:     largest = right_index   if largest != index:     unsorted[largest], unsorted[index] = unsorted[index], unsorted[largest]     heapify(unsorted, largest, heap_size) ``` *heapify*의 계산복잡성은 최악의 경우 루트노드에서 잎새노드까지 값을 비교해야 하므로 트리의 높이($h=\log_2{n}$)에 의존적입니다. 값을 비교하거나 바꾸는 연산은 $O(1)$이므로 결과적으로 *heapify*의 계산복잡성은 $O(\log{n})$이 됩니다.   ## insert 힙은 자료구조의 일종이므로 삽입 연산이 가능해야 합니다. 힙 속성 가운데 *shape* 속성을 만족하려면 새로운 노드는 아래 그림과 같이 마지막 레벨의 비어있는 공간 가운데 가장 왼쪽에 들어가야 할 겁니다.  <a href="https://imgur.com/oOEG3p7"><img src="https://i.imgur.com/oOEG3p7.png" width="300px" title="source: imgur.com" /></a>  예를 들어보겠습니다. 아래와 같은 힙 구조에서 18을 삽입한다고 가정해 보겠습니다. 그러면 마지막 레벨의 비어있는 공간 가운데 가장 왼쪽, 즉 5의 오른쪽 자식노드 위치에 처음 들어가게 됩니다.  <a href="https://imgur.com/PjGdges"><img src="https://i.imgur.com/PjGdges.png" width="500px" title="source: imgur.com" /></a>  하지만 18이 새로 삽입되면서 힙 속성이 깨졌습니다. *heapify*를 통해 맞춰 주어야 합니다. 우선 18을 부모노드인 5와 비교합니다. 위치를 바꿔 줍니다. 이번엔 16과 비교해 위치를 바꿔 줍니다. 이같이 삽입 연산을 할 때 *heapify*는 **아래에서 위로** *heapify*를 해줍니다. 삽입 연산의 *heapify* 과정에서는 형제 노드에 대해선 값을 비교할 필요가 없습니다. 예컨대 상단 중앙그림의 마지막 레벨인 3, 18을 봅시다. 이미 힙 속성을 유지하고 있는 완전이진트리이기 때문에 기존 노드 3은 자신의 부모노드 5보다는 작거나 같다는 게 보장되어 있습니다. 따라서 18을 *hepify*할 때 부모노드인 5와만 비교해도 원하는 결과를 낼 수 있습니다. 그러면 삽입 연산의 계산복잡성은 얼마일까요? 삽입하는 데 드는 연산 $O(1)$, 해당 노드를 *heapfy*하는 데 $O(\log{n})$이 드므로, 전체적으로는 $O(\log{n})$가 됩니다.   ## delete 이번엔 삭제 연산을 살펴보겠습니다. 다음과 같습니다.  <a href="https://imgur.com/fPS4LPp"><img src="https://i.imgur.com/fPS4LPp.png" width="500px" title="source: imgur.com" /></a>  우리가 지우고 싶은 값이 위 힙 구조에서 18이라고 가정해 봅시다. 그러면 마지막 레벨의 마지막 값, 즉 힙을 배열로 표현했을 때 가장 마지막 값인 5를 삭제된 요소의 위치에 옮깁니다. 이후 이 5가 잎새노드에 다다르기까지 **위에서 아래로** *heapify*를 수행합니다. 5는 왼쪽 자식노드인 16보다 큽니다. 힙 성질을 만족하지 않습니다. 둘의 위치를 바꿔줍니다. 새로운 위치의 5는 왼쪽 자식노드인 3보다 크고, 오른쪽 자식노드는 없습니다. 힙 성질을 만족합니다. 둘의 위치를 바꾸지 않고, *heapify*를 종료합니다. 그러면 삭제 연산의 계산복잡성은 얼마일까요? 삭제하는 데 드는 연산 $O(1)$, 배열의 마지막 노드를 삭제 위치로 옮기는 연산 $O(1)$, 해당 노드를 *heapfy*하는 데 드는 연산 $O(\log{n})$, 이렇게 해서 전체적으로 $O(\log{n})$가 됩니다.   ## build heap 이번에는 임의의 숫자들을 최대 힙으로 구성해 보도록 하겠습니다. 이러한 일련의 연산 과정을 *build heap*이라고 합니다. 예를 들어 다음과 같은 리스트가 주어졌다고 칩시다. > 12, 30, 6, 7, 4, 13, 8, 11, 50, 24, 2, 5, 10 위 숫자들을 가지고 *bulid heap*을 하는 가장 단순한 방법은 비어있는 힙에 위 요소들을 차례로 *insert* 연산을 수행해 힙을 만들어가는 과정이 될 겁니다. 새로 삽입해야 할 노드 수가 $n$개라면 노드 하나의 *insert* 연산을 $n$번 반복 수행해야 합니다. 그런데 마지막 요소를 삽입할 때 힙을 이미 구성하고 있는 노드의 수는 $n-1$개일 것이므로 *insert* 연산의 계산복잡성은 $O(\log{n})$입니다. 따라서 이 방식의 계산복잡성은 결과적으로 $O(n\log{n})$이 됩니다. 이보다 더 줄일 수는 없을까요? 방법이 하나 있습니다. 다음 그림을 보겠습니다. 위 리스트를 가지고 완전이진트리 형태로 쭉 나열하면 하단 좌측그림과 같습니다. 여기에서 잎새노드를 가지지 않는 노드(=배열의 개수를 2로 나눈 몫을 인덱스로 하는 노드)부터 차례대로 *heapify*를 수행해주는 것입니다. 하단 좌측그림에서 보는 것처럼 8, 13, 4, 7 순서대로 **위에서 아래로** *heapify*를 수행합니다.  <a href="https://imgur.com/BxjApth"><img src="https://i.imgur.com/BxjApth.png" width="600px" title="source: imgur.com" /></a>  우선 8부터 보겠습니다. 자식노드가 없으므로 *heapify*를 수행할 대상이 없습니다. 8에 대한 *heapify*를 종료합니다. 이번엔 13입니다. 13은 자식노드인 5, 10보다 크므로 힙 성질을 이미 만족하고 있습니다. 13에 대한 *heapify*를 종료합니다. 다음은 4입니다. 4는 왼쪽 자식노드인 24보다 작으므로 힙 성질을 만족하지 않습니다. 4와 24 위치를 바꿔 줍니다. 새로운 위치의 4는 자식노드가 없으므로 *heapify*를 수행할 대상이 없습니다. 4에 대한 *heapify*를 종료합니다. 다음은 7입니다. 7은 왼쪽 자식노드인 11보다 크고, 오른쪽 자식노드인 50보다 크므로 힙 성질을 만족하지 않습니다. 7과 50 위치를 바꿔 줍니다. 새로운 위치의 7은 자식노드가 없으므로 *heapify*를 수행할 대상이 없습니다. 7에 대한 *heapify*를 종료합니다. 이를 수행한 결과가 상단 우측 그림과 같습니다. 이번엔 6과 30을 차례대로 *heapify*를 수행합니다. 이를 수행한 결과는 하단 우측 그림과 같습니다.  <a href="https://imgur.com/C4fKSXE"><img src="https://i.imgur.com/C4fKSXE.png" width="600px" title="source: imgur.com" /></a>  마지막으로 루트노드를 대상으로 *heapify*를 수행합니다. 이를 수행한 결과는 하단 우측 그림과 같습니다.  <a href="https://imgur.com/VSAz5w1"><img src="https://i.imgur.com/VSAz5w1.png" width="600px" title="source: imgur.com" /></a>  이같은 방식의 계산복잡성을 따져 보겠습니다. 1개 노드를 *heapify*하는 데 필요한 계산량은 $O(\log{n})$이고, $n/2$개 노드에 대해 *heapify*를 수행해야 하므로 전체적으로는 $O(n\log{n})$입니다. 하지만 조금 더 생각해 볼 필요가 있습니다. 아래 그림을 보겠습니다. 모든 레벨의 모든 노드가 꽉 차 있는 정이진트리(full binary tree)에서 오른쪽 맽 끝에 해당합니다.  <a href="https://imgur.com/wPvJ4IU"><img src="https://i.imgur.com/wPvJ4IU.png" width="300px" title="source: imgur.com" /></a>  노드 안의 숫자들은 노드 수가 $n$개인 이진트리를 배열로 표현했을 때 인덱스를 가리킵니다. 인덱스가 $n$인 데이터는 정이진트리의 오른쪽 끝 잎새노드가 되는 셈이지요. 잎새노드에 해당하는 레벨을 $d$라고 했을 때 레벨이 $d$인 노드 수는 $n/2$개입니다. 왜냐하면 레벨 $d-1$의 오른쪽 끝 노드의 인덱스가 $n/2$이기 때문입니다. 레벨이 $d-1$인 노드의 수는 전체 노드($n$)에서 레벨 $d$에 해당하는 노드 수($n/2$)와 레벨 $d-2$에 해당하는 노드 수($n/4$)를 뺀 $n/4$개가 됩니다. *build heap*의 계산복잡성은 수행 대상의 노드가 전체 트리에서 차지하는 높이, 그리고 수행 대상 노드 수에 비례합니다. 레벨 $d-1$에 해당하는 노드는 그 높이가 1(=잎새노드까지의 엣지 수)입니다. 마찬가지로 레벨 $d-2$는 2, $d-3$은 3이 되겠지요. 지금까지 말씀드린 내용을 종합해 *build heap*의 계산복잡성을 대략적으로 나타내면 다음과 같습니다.  $$ \begin{align*} 0\cdot \frac { n }{ { 2 }^{ 1 } } &+1\cdot \frac { n }{ { 2 }^{ 2 } } +2\cdot \frac { n }{ { 2 }^{ 3 } } +3\cdot \frac { n }{ { 2 }^{ 4 } } +...\\ &=\frac { n }{ 4 } \cdot \left( 1+2\cdot \frac { 1 }{ 2 } +3\cdot \frac { 1 }{ 4 } +... \right) \\ &=\frac { n }{ 4 } \cdot c=O\left( n \right) \end{align*} $$  지금 설명드린 방식이 비어있는 힙에 차례로 *insert* 연산을 수행해 힙을 만들어가는 방식보다 더 효율적임을 알 수 있습니다.   ## Heap sort 자, 드디어 이제 힙 정렬에 대해 살펴볼 시간입니다. 힙 정렬을 수행하기 위해서는 주어진 데이터를 가지고 우선 최대 힙을 구성해야 합니다. 우리에게 주어진 데이터가 다음과 같다고 칩시다. ```python unsorted = [16, 4, 10, 14, 7, 9, 3, 2, 8, 1] ```  <a href="https://imgur.com/1yzgwET"><img src="https://i.imgur.com/1yzgwET.png" width="300px" title="source: imgur.com" /></a> Heapify의 시작점은 데이터 개수(10)의 절반에 해당하는 **다섯번째 노드**입니다. "각 노드의 값은 자식노드보다 크거나 같다"를 만족해야 힙 성질을 가진다고 할 수 있습니다. 다섯번째 노드(7)는 자식노드의 값(1)보다 크므로 힙 성질을 만족합니다. 따라서 더 이상의 연산이 필요 없습니다. 다음은 **네번째 노드**를 볼 차례입니다. 네번째 노드(14)는 왼쪽 자식노드(2), 오른쪽 자식노드(8)보다 크므로 힙 성질을 만족합니다. 따라서 더 이상의 연산이 필요 없습니다. **세번째 노드** 차례입니다. 세번째 노드(10)은 왼쪽 자식노드(9), 오른쪽 자식노드(3)보다 크므로 힙 성질을 만족합니다. 따라서 더 이상의 연산이 필요 없습니다. **두번째 노드** 차례입니다. 두번째 노드(4)는 왼쪽 자식노드(14)보다 작습니다. 힙 성질을 만족하지 않으므로 다음처럼 4와 14의 위치를 바꿔 줍니다. ```python unsorted = [16, 14, 10, 4, 7, 9, 3, 2, 8, 1] ``` <a href="https://imgur.com/qilyQfo"><img src="https://i.imgur.com/qilyQfo.png" width="300px" title="source: imgur.com" /></a> 4의 위치가 위의 그림처럼 바뀌었으니 4의 자식노드들을 좀 더 살펴보아야 합니다. 4는 오른쪽 자식노드(8)보다 작습니다. 힙 성질을 만족하지 않으므로 다음처럼 4와 8의 위치를 바꿔 줍니다. ```python unsorted = [16, 14, 10, 8, 7, 9, 3, 2, 4, 1] ``` <a href="https://imgur.com/ttFJIPp"><img src="https://i.imgur.com/ttFJIPp.png" width="300px" title="source: imgur.com" /></a> 4의 위치가 위의 그림처럼 바뀌었으니 4의 자식노드들을 좀 더 살펴보아야 합니다. 그런데 4의 자식노드는 존재하지 않습니다. 이로써 **두번째 노드**에 대한 연산을 종료합니다. 마지막으로 **첫번째 노드** 차례입니다. 첫번째 노드(16)는 왼쪽 자식노드(14), 오른쪽 자식노드(10)보다 크므로 힙 성질을 만족합니다. 따라서 더 이상의 연산이 필요 없습니다. 이로써 최대 힙을 구성하는 데 성공했습니다. 최대 힙을 구성하게 되면 unsorted의 첫번째 요소(16)가 전체 요소 가운데 최댓값이 됩니다.   ## Heap Sort 파이썬 구현 힙 정렬의 수행 방법은 다음과 같습니다. 1. 주어진 원소들로 최대 힙을 구성합니다. 2. 최대 힙의 루트노드(=현재 배열의 첫번째 요소=최댓값)와 말단노드(=현재 배열의 마지막 요소)를 교환해 줍니다. 3. 새 루트노드에 대해 최대 힙을 구성합니다. 4. 원소의 개수만큼 2와 3을 반복 수행합니다. 이를 파이썬 코드로 구현하면 다음과 같습니다. ```python def heap_sort(unsorted):   n = len(unsorted)   # BUILD-MAX-HEAP (A) : 위의 1단계   # 인덱스 : (n을 2로 나눈 몫-1)~0   # 최초 힙 구성시 배열의 중간부터 시작하면   # 이진트리 성질에 의해 모든 요소값을   # 서로 한번씩 비교할 수 있게 됨 : O(n)   for i in range(n // 2 - 1, -1, -1):     heapify(unsorted, i, n)   # Recurrent (B) : 2~4단계   # 한번 힙이 구성되면 개별 노드는   # 최악의 경우에도 트리의 높이(logn)   # 만큼의 자리 이동을 하게 됨   # 이런 노드들이 n개 있으므로 : O(nlogn)   for i in range(n - 1, 0, -1):     unsorted[0], unsorted[i] = unsorted[i], unsorted[0]     heapify(unsorted, 0, i)   return unsorted ``` A. BUILD-MAX-HEAP의 인덱스($i$)에 따른 정렬 과정은 다음과 같습니다. (단 여기에서 $i$는 파이썬 인덱스 기준) | $i$ |        data        | | :--: | :-------------------------------: | | 초기값 | [16, 4, 10, 14, 7, 9, 3, 2, 8, 1] | | 4  | [16, 4, 10, 14, 7, 9, 3, 2, 8, 1] | | 3  | [16, 4, 10, 14, 7, 9, 3, 2, 8, 1] | | 2  | [16, 4, 10, 14, 7, 9, 3, 2, 8, 1] | | 1  | [16, 14, 10, 8, 7, 9, 3, 2, 4, 1] | | 0  | [16, 14, 10, 8, 7, 9, 3, 2, 4, 1] | B. Recurrent 부분의 인덱스에 따른 정렬 과정은 다음과 같습니다. | $i$ |        data        | | :--: | :-------------------------------: | | 9  | [1, 14, 10, 8, 7, 9, 3, 2, 4, 16] | | 8  | [1, 8, 10, 4, 7, 9, 3, 2, 14, 16] | | 7  | [2, 8, 9, 4, 7, 1, 3, 10, 14, 16] | | 6  | [2, 8, 3, 4, 7, 1, 9, 10, 14, 16] | | 5  | [1, 7, 3, 4, 2, 8, 9, 10, 14, 16] | | 4  | [2, 4, 3, 1, 7, 8, 9, 10, 14, 16] | | 3  | [1, 2, 3, 4, 7, 8, 9, 10, 14, 16] | | 2  | [1, 2, 3, 4, 7, 8, 9, 10, 14, 16] | | 1  | [1, 2, 3, 4, 7, 8, 9, 10, 14, 16] |   ## Heap sort의 계산복잡성 그러면 힙 정렬의 계산복잡성을 따져보도록 하겠습니다. 우선 최초로 최대 힙을 만드는 A의 계산복잡성은 이미 살펴보았듯 $O(n)$입니다. 이번엔 힙이 구성된 상태에서 각 노드에 대해 *heapify*를 수행하는 B를 살펴보겠습니다. 말단 노드(최댓값)가 루트 노드에 올라오기까지 트리의 높이(데이터 수가 $n$개일 때 $h=\log_2n$)만큼 자리 이동을 해야 합니다. 이렇게 heapify를 해야 하는 노드들이 $n$개가 있으므로 B의 계산복잡성은 $O(n\log{n})$이 됩니다. 따라서 힙 정렬의 계산복잡성은 A와 B를 합친 $O(n)+O(n\log{n})$이며 결과적으로 $O(n\log{n})$이 됩니다. 
asymptotic␞ 이번 글에서는 내가 만든 알고리즘이 얼마나 효율적인지를 따져보기 위한 도구인 **점근 표기법(asymptotic notation)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님과 역시 같은 대학의 김선욱 교수님 강의를 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 개요 내가 만든 알고리즘을 수퍼컴퓨터에서 돌릴 때와 노트북에서 수행할 때는 분명 속도 면에서 차이가 날 겁니다. 수행환경을 통제하지 않고서는 공정한 비교라고 할 수 없겠지요. 이 때문에 알고리즘의 계산복잡성은 컴퓨터 성능에 관계없이 machine independent한 방식으로 따져보게 됩니다. 알고리즘 자체의 효율성은 데이터 개수($n$)가 주어졌을 때 덧셈, 뺄셈, 곱셈 등 해당 알고리즘 수행시 필요한 '기본 연산(basic operation)의 횟수'로 표현하는 것이 일반적입니다. 이렇게 따져본 내 알고리즘의 계산복잡성이 $20/πn^2+n+100$이라고 칩시다. $n$이 증가함에 따라 이 알고리즘의 계산복잡성이 대략 어떻게 늘어나는지, 머릿 속에서 그 모양과 방향을 예측하기가 그렇게 쉽지만은 않습니다. 여기에 어떤 개발자가 내놓은 알고리즘은 $100000n+100000$이라고 가정해봅시다. 그러면 내가 만든 알고리즘과 비교해 어떤 것이 더 나은 알고리즘일까요? 이 문제도 역시 단박에 알아내기가 어렵습니다. 이럴 때는 가늠해보려는 알고리즘의 계산복잡성 증가 양상을 단순화시켜 우리가 익히 알고 있는 로그, 지수, 다항함수 등과의 비교로 표현하는 점근 표기법이 유용하게 쓰일 수 있습니다.   <a href="https://imgur.com/EoUstgL"><img src="https://i.imgur.com/EoUstgL.png" width="300px" title="source: imgur.com" /></a>  점근 표기법에서는 원 함수를 단순화하여 최고차항의 차수만을 고려합니다. 최고차항을 제외한 모든 항과 최고차항의 계수는 무시합니다. 이 표기법을 따르면 내 알고리즘의 계산복잡도는 $n^2$, 다른 개발자의 알고리즘은 $n$이 됩니다. 따라서 데이터 수가 증가함에 따라 내 알고리즘의 계산복잡도는 지수적으로, 상대방의 알고리즘은 선형적으로 증가하며, 상대방의 알고리즘이 제 것보다 더 나은 알고리즘이라고 비교할 수 있게 됩니다. 만약 위 그림처럼 점근 표기법으로 표현된 계산복잡성이 $\log{n}$인 알고리즘이 등장한다면 state-of-the-art의 기법이 되겠지요. 점근 표기법에는 대표적으로 대문자 O 표기법, 대문자 오메가(Ω) 표기법, 대문자 세타(Θ) 표기법, 소문자 o 표기법, 소문자 오메가(ω) 표기법 다섯 종류가 있습니다. 다섯 표기법 모두 내가 만든 알고리즘 $f(n)$를 지수, 다항함수 등 우리가 익히 알고 있는 함수 $g(n)$와 어떤 관계가 있는지 표현해 줍니다. 차례로 살펴보겠습니다.  ## Big-O notation 대문자 O 표기법에서는 아래 그림을 만족하는 $f(n)$를 $O(g(n))$이라고 표시합니다. 이 때 $g(n)$를 $f(n)$의 **점근 상한(an asymptotic upper bound)**이라고 합니다. 러프하게 보면, 내가 만든 알고리즘 $f(n)$이 $O(g(n))$에 속한다면, $f(n)$의 계산복잡도는 최악의 경우라도 $g(n)$과 같거나 혹은 작다는 뜻입니다.   <a href="https://imgur.com/QmfDswm"><img src="https://i.imgur.com/QmfDswm.png" width="300px" title="source: imgur.com" /></a>  이를 수식으로 나타내면 다음과 같습니다.  $$ O\left( g\left( n \right) \right) =\left\{ f\left( n \right) |0\le f\left( n \right) \le c\cdot g\left( n \right) \quad for\quad all\quad n\ge { n }_{ 0 }>0 \right\} \quad for\quad ∃c>0 $$  예를 들어보겠습니다. $2n^2=O(n^3)$입니다. 2($n_0$) 이상의 모든 $n$에 대해 $0≤2n^2≤cn^3$을 만족하는 $c$가 존재하기 때문입니다($c=1$).  이를 그림으로 나타내면 다음과 같습니다. (빨간색 선=점근 상한=$n^3$) **이 알고리즘의 계산복잡도는 최악의 경우에도 빨간색 선보다는 작거나 같습니다.**  <a href="https://imgur.com/0xHjrdE"><img src="https://i.imgur.com/0xHjrdE.png" width="200px" title="source: imgur.com" /></a>  다음은 $O(n^2)$에 속한 함수 $f(n)$입니다. 최고차항의 차수가 2보다 작거나 같은 함수들입니다. > $n^2$ > > $n^2+n$ > > $n^2+1000n$ > > $1000n^2+1000n$ > > $n$ > > $n/1000$ > > $n^{1.99999}$ > > $n^2/\log\log\log{n}$   ## Big-Ω notation 대문자 Ω 표기법에서는 아래 그림을 만족하는 $f(n)$를 $Ω(g(n))$이라고 표시합니다. 이 때 $g(n)$는 $f(n)$의 **점근 하한(an asymptotic lower bound)**이라고 합니다. 러프하게 보면, 내가 만든 알고리즘 $f(n)$의 계산복잡도가 $Ω(g(n))$에 속한다면, $f(n)$의 계산복잡도는 최선의 경우를 상정하더라도 $g(n)$과 같거나 혹은 크다는 뜻입니다.  <a href="https://imgur.com/1Hnuy1s"><img src="https://i.imgur.com/1Hnuy1s.png" width="300px" title="source: imgur.com" /></a>  이를 수식으로 나타내면 다음과 같습니다.  $$ \Omega\left( g\left( n \right) \right) =\left\{ f\left( n \right) |0\le c\cdot g\left( n \right) \le f\left( n \right) \quad for\quad all\quad n\ge { n }_{ 0 }>0 \right\} \quad for\quad ∃c>0 $$  예를 들어보겠습니다. $\sqrt{n}=Ω(\ln{n})$입니다. 2($n_0$) 이상의 모든 $n$에 대해 $0≤\ln{n}≤c\sqrt{n}$인 $c$가 존재하기 때문입니다($c=1$).  이를 그림으로 나타내면 다음과 같습니다. (녹색 선=점근 하한=$\ln{n}$) 다시 말해 **이 알고리즘의 계산복잡도는 최선의 경우에도 녹색 선보다는 크거나 같습니다.**  <a href="https://imgur.com/27uFjy5"><img src="https://i.imgur.com/27uFjy5.png" width="400px" title="source: imgur.com" /></a>  다음은 $Ω(n^2)$에 속하는 함수 $f(n)$입니다. 최고차항의 차수가 2보다 크거나 같은 함수들입니다. > $n^2$ > > $n^2+n$ > > $n^2-n$ > > $1000n^2+1000n$ > > $1000n^2-1000n$ > > $n^3$ > > $n^{2.00001}$ > > $n^2\log\log\log{n}$ > > $2^{2^n}$   ## Big Θ-notation 대문자 Θ 표기법에서는 아래 그림을 만족하는 $f(n)$를 $Θ(g(n))$이라고 표시합니다. 이 때 $g(n)$은 $f(n)$의 **점근적 상한과 하한의 교집합(an asymptotic tight bound)**이라고 합니다. 러프하게 보면, 내가 만든 알고리즘 $f(n)$이 아무리 나쁘거나 좋더라도 그 계산복잡도는 $g(n)$의 범위 내에 있다는 뜻입니다. 다음과 같습니다.  <a href="https://imgur.com/Bx7ykk3"><img src="https://i.imgur.com/Bx7ykk3.png" width="300px" title="source: imgur.com" /></a>  이를 수식으로 나타내면 다음과 같습니다.  $$ \Theta \left( g\left( n \right) \right) =\left\{ f\left( n \right) |0\le {c}_{1}\cdot g\left( n \right) \le f\left( n \right) \le {c}_{2}\cdot g\left( n \right) \quad for\quad all\quad n\ge { n }_{ 0 }>0 \right\} \quad for\quad ∃{c}_{1},{c}_{2}>0 $$  예를 들어보겠습니다. $n^2/2-2n=Θ(n^2)$입니다. 8($n_0$) 이상인 모든 $n$에 대하여 $0≤c_1n^2≤n^2/2-2n≤c_2n^2$을 만족하는 $c_1, c_2$가 존재하기 때문입니다($c_1=1/4, c_2=1/2$).  이를 그림으로 나타내면 다음과 같습니다. (노란색 선=점근 하한=$1/4n^2$, 검정색 선=점근 상한=$1/2n^2$) 다시 말해 **이 알고리즘의 계산복잡도는 최선의 경우에도 보라색 선보다는 크거나 같고, 최악의 경우에도 검정색 선보다는 작거나 같습니다.**  <a href="https://imgur.com/9pPcm8o"><img src="https://i.imgur.com/9pPcm8o.png" width="400px" title="source: imgur.com" /></a>    ## o-notation, ω-notation 소문자 o 표기법, 소문자 오메가(ω) 표기법은 각각 대문자 O 표기법, 대문자 오메가(Ω) 표기법과 비교해 등호가 빠지는 등 조건이 약간 더 엄격합니다. $o(g(n))$의 정의는 다음과 같습니다.  $$ O\left( g\left( n \right) \right) =\left\{ f\left( n \right) |0\le f\left( n \right) < c\cdot g\left( n \right) \quad for\quad all\quad n\ge { n }_{ 0 }>0 \right\} \quad for\quad ∀c>0 \\another \quad view:\quad\lim _{ n\rightarrow \infty }{ \frac { f\left( x \right) }{ g\left( x \right) } } =0 $$  그 예시는 다음과 같습니다. 최고차항의 차수가 2보다 작은 함수(정확히 2인 것은 제외)입니다. > $n^{1.99999}=o(n^2)$ > > $n^2/\log{n}=o(n^2)$ > > $n^2≠o(n^2)$ (마치 $2 ≮ 2$ 인 것과 같음) > > $n^2≠o(n^2)$  $ω(g(n))$의 정의는 다음과 같습니다.  $$ \Omega\left( g\left( n \right) \right) =\left\{ f\left( n \right) |0< c\cdot g\left( n \right) \le f\left( n \right) \quad for\quad all\quad n\ge { n }_{ 0 }>0 \right\} \quad for\quad ∀c>0 \\another \quad view:\quad\lim _{ n\rightarrow \infty }{ \frac { f\left( x \right) }{ g\left( x \right) } } =\infty $$  그 예시는 다음과 같습니다. 최고차항의 차수가 2보다 큰 함수(정확히 2인 것은 제외)입니다. > $n^{2.00001}=ω(n^2)$ > > $n^2\log{n}=ω(n^2)$ > > $n^2≠ω(n^2)$   ## 표기법 간의 관계 다섯가지 점근 표기법을 한눈에 정리하면 다음 표와 같습니다. |  표기법  |     대략적 의미     | | :------: | :----------------------: | | $f=ω(g)$ |  $f$는 $g$보다 크다, $f>g$  | | $f=Ω(g)$ | $f$는 $g$보다 크거나 같다, $f≥g$ | | $f=Θ(g)$ | $f$는 $g$와 대략 같다, $f=g$ | | $f=O(g)$ | $f$는 $g$보다 작거나 같다, $f≤g$ | | $f=o(g)$ |  $f$는 $g$보다 작다, $f<g$  | 엄밀히 말해 $ω(g), Ω(g), Θ(g), O(g), o(g)$는 각각 함수의 **집합**을 의미합니다. 각 집합의 요소 수는 무한히 많을 것입니다. 다섯 집합 사이의 관계를 따져보면 다음과 같습니다.  <a href="https://imgur.com/tMfg0j8"><img src="https://i.imgur.com/tMfg0j8.png" width="400px" title="source: imgur.com" /></a>  알고리즘 계산복잡도를 따질 때 보통 가장 많이 쓰이는 것은 대문자 O 표기법이라고 합니다. 최악의 경우에도 해당 알고리즘이 어떤 성능을 낼지 가늠해볼 수 있기 때문입니다.   ## 점근 표기법의 속성 점근 표기법은 다음과 같은 속성을 지닌다고 합니다. 저 또한 정리 용도로 올려둡니다.  <a href="https://imgur.com/x171NET"><img src="https://i.imgur.com/x171NET.png" width="500px" title="source: imgur.com" /></a>   
DFS␞ 이번 글에서는 [그래프(Graph)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/)라는 자료구조를 순회하는 알고리즘 가운데 **깊이우선탐색(Breath First Search)** 기법을 살펴보도록 하겠습니다. 파이썬 코드는 [이곳](http://interactivepython.org/runestone/static/pythonds/Graphs/GeneralDepthFirstSearch.html)을 참고하였습니다. 이 글은 고려대 김황남 교수님과 역시 같은 대학의 김선욱 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept 깊이우선탐색이란 더 이상 나아갈 엣지가 없을 때까지 깊이 탐색하는 그래프 순회(traverse) 기법입니다. 깊이우선탐색을 도식화한 그림은 다음과 같습니다.  <a href="https://imgur.com/YjfpWci"><img src="https://i.imgur.com/YjfpWci.png" width="250px" title="source: imgur.com" /></a>   ## 파이썬 구현 깊이우선탐색을 파이썬으로 구현한 코드는 다음과 같습니다. 알고리즘에서 쓰이는 변수는 다음과 같습니다. - 그래프 : *Graph* (각 노드에는 값과 엣지뿐 아니라 방문시간 *time*, 색상 *Color* 정보도 들어 있음) - 시작노드 : *startVertex* - 시작노드와 이웃한 노드 : *nextVertex* - 색상 : 아직 방문하지 않았다면 *white(defalut)*, 이미 방문했다면 *black*, 방문 여부를 검토(processing)하고 있다면 *gray* - 방문시간 : 최초 방문(*discovery*)한 시간, 방문을 마친(*finish*) 시간 두 가지로 나뉨 ```python from pythonds.graphs import Graph class DFSGraph(Graph):   def __init__(self):     super().__init__()     self.time = 0 	   def dfs(self):     # 모든 노드의 색상을 white,     # 부모노드 정보를 -1로 초기화     for aVertex in self:       aVertex.setColor('white')       aVertex.setPred(-1)     for aVertex in self:      	# 임의의 노드가 아직 방문하지 않은(white)       # 노드라면 해당 노드에 대해 dfsvisit 호출       # dfsvisit은 더 이상 나아갈 엣지가 없을 때까지       # 재귀적으로 수행, 수행 후에도 white인 노드가 있으면       # 해당 노드를 시작노드로 해서 dfsvisit 반복 수행       if aVertex.getColor() == 'white':         self.dfsvisit(aVertex)   def dfsvisit(self,startVertex):    	# processing이라는 의미로     # 시작노드의 색상을 gray로 변경     startVertex.setColor('gray')     # 방문시간에 1을 더함     self.time += 1     # 시작노드를 발견한 시점을 기록     startVertex.setDiscovery(self.time)     # 시작노드에 인접한 모든 이웃노드들에 대해     for nextVertex in startVertex.getConnections():       # 해당 노드가 아직 방문하지 않은(white) 노드라면       if nextVertex.getColor() == 'white':        	# 해당 노드의 부모를 시작노드라고 기록         nextVertex.setPred(startVertex)         # 해당 노드를 시작노드로 해서 dfsvisit 호출         self.dfsvisit(nextVertex)     # 이렇게 모든 이웃노드들에 대해 탐색이 끝나면     # 시작노드 방문을 마쳤다는 의미로 black으로 변경     startVertex.setColor('black')     # 방문시간에 1을 더함     self.time += 1     # 시작노드 processing을 끝낸 시점을 기록     startVertex.setFinish(self.time) ```   ## 순회 예시 (a)와 같은 그래프를 깊이우선탐색 방식으로 순회해보겠습니다. 시작노드 *startVertex*를 $u$로 두겠습니다. 그러면 우선 시작노드 발견시점을 1로 적어두고, *processing*하고 있다는 의미로 색상을 *gray*로 바꿉니다. 이후 *dfsvisit* 함수가 재귀적으로 세 번 호출되면서 $v$, $y$, $x$ 노드에 대해 같은 작업이 진행돼 전체적으로는 (b), (c), (d) 같은 모습을 띄게 됩니다.  <a href="https://imgur.com/c1rJ8Hs"><img src="https://i.imgur.com/c1rJ8Hs.png" title="source: imgur.com" /></a>  이번엔 (f)를 봅시다. (f)에서는 $x$를 시작노드로 하는 재귀함수 *dfsvisit*이 수행되고 있습니다. $x$의 이웃노드 가운데 *white*인 노드가 없어서 더 이상 깊이우선탐색이 불가능합니다. $x$의 *processing*이 완료되었다는 의미로 색상을 *black*으로 바꾸고 종료시점(5)을 기록하고 재귀함수 호출을 종료합니다. (g)를 봅시다. (g)에서는 $y$를 시작노드로 하는 재귀함수 *dfsvisit*이 수행되고 있습니다. $y$의 이웃노드 가운데 *white*인 노드가 없어서 더 이상 깊이 우선 탐색이 불가능합니다. $y$의 *processing*이 완료되었다는 의미로 색상을 *black*으로 바꾸고 종료시점(6)을 기록하고 재귀함수 호출을 종료합니다. (h)를 봅시다. (h)에서는 $v$를 시작노드로 하는 재귀함수 *dfsvisit*이 수행되고 있습니다. $v$의 이웃노드 가운데 *white*인 노드가 없어서 더 이상 깊이 우선 탐색이 불가능합니다. $v$의 *processing*이 완료되었다는 의미로 색상을 *black*으로 바꾸고 종료시점(7)을 기록하고 재귀함수 호출을 종료합니다.  <a href="https://imgur.com/F6MtJzY"><img src="https://i.imgur.com/F6MtJzY.png" title="source: imgur.com" /></a>  (m)을 봅시다. (m)에서는 $u$를 시작노드로 하는 재귀함수 *dfsvisit*이 수행되고 있습니다. $u$의 이웃노드 가운데 *white*인 노드가 없어서 더 이상 깊이 우선 탐색이 불가능합니다. $u$의 *processing*이 완료되었다는 의미로 색상을 *black*으로 바꾸고 종료시점(8)을 기록하고 재귀함수 호출을 종료합니다.  이로써 *dfs*에서의 *dfsvisit* 재귀함수 호출이 종료됐습니다. 그런데 아직 아래의 반복문은 계속 돌고 있으므로, 나머지 노드 가운데 아직 방문하지 않은(*white*) 노드가 있다면 해당 노드들에 대해서도 *dfsvistit*을 수행해 줍니다. ```python   for aVertex in self:     if aVertex.getColor() == 'white':       self.dfsvisit(aVertex) ``` (m)을 다시 봅시다. $w$를 시작노드로 *dfvisit*을 수행합니다. $w$ 발견시점을 9로 하고 *processing*하고 있다는 의미로 색상을 *gray*로 바꿉니다. 이후 $w$의 이웃노드인 $z$를 시작노드로 *dfvisit*을 재귀적으로 수행합니다. $z$ 발견시점을 10으로 하고 *processing*하고 있다는 의미로 색상을 *gray*로 바꿉니다. (o)를 봅시다. (o)에서는 $z$를 시작노드로 하는 재귀함수 *dfvisit*이 수행되고 있습니다. $z$의 이웃노드 가운데 *white*인 노드가 없어서 더 이상 깊이 우선 탐색이 불가능합니다. $z$의 *processing*이 완료되었다는 의미로 색상을 *black*으로 바꾸고 종료시점(11)을 기록하고 재귀함수 호출을 종료합니다.  (p)를 봅시다. (p)에서는 $w$를 시작노드로 하는 재귀함수 *dfvisit*이 수행되고 있습니다. $w$의 이웃노드 가운데 *white*인 노드가 없어서 더 이상 깊이 우선 탐색이 불가능합니다. $w$의 *processing*이 완료되었다는 의미로 색상을 *black*으로 바꾸고 종료시점(12)을 기록하고 재귀함수 호출을 종료합니다.  (p)까지 수행이 끝나면 그래프 전체에서 *white*인 노드가 없게 됩니다. 이로써 *dfs*의 반복문도 종료됩니다.  <a href="https://imgur.com/Foq0m9r"><img src="https://i.imgur.com/Foq0m9r.png" title="source: imgur.com" /></a>   ## 깊이우선탐색 그래프의 특성 위 예시에서 깊이우선탐색이 종료된 그래프의 모습은 다음과 같습니다.  <a href="https://imgur.com/CdjPenA"><img src="https://i.imgur.com/CdjPenA.png" width="300px" title="source: imgur.com" /></a>  깊이우선탐색으로 그래프를 순회한 결과로 부모-자식노드가 도출됩니다. 예컨대 위 그림에서는 $u$와 $v$, $w$와 $b$가 그러한 관계를 갖습니다. 부모에서 자식노드로 향하는 엣지를 `Tree edge/Discover edge`라고 합니다. 반대로 자식에서 부모노드로 향하는 엣지를 `Back edge`라고 합니다. 위 그림 기준으로는 음영표시된 엣지가 tree edge, **B**라고 표시된 엣지가 back edge입니다. [무방향그래프(undirected graph)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/)에서는 Tree edge와 Back edge만 존재합니다. Tree edge가 아닌 엣지 가운데 자손노드로 향하는 노드를 `Forward edge`라고 합니다. `Cross edge`는 이 세 가지 경우를 제외한 모든 종류의 엣지를 나타냅니다. 위 그림 기준으로는 **F**가 forward edge, **B**가 back edge입니다. back edge가 존재한다는 말은 [사이클(cycle)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/)이 존재한다는 말과 같습니다. 위 여섯개 노드를 발견시점과 탐색종료시점 순으로 나열하면 다음과 같습니다. 자식노드의 발견시점과 탐색종료시점은 부모노드의 부분집합이 됩니다. 이같은 구조를 *parenthesis structure*라고 합니다.  <a href="https://imgur.com/8DqJqgR"><img src="https://i.imgur.com/8DqJqgR.png" width="500px" title="source: imgur.com" /></a>  뿐만 아니라 어떤 임의의 노드가 있고, 이 경로상에 존재하는 *white* 노드들은 깊이우선탐색 기준 해당 노드의 자식노드가 됩니다. 이를 *white path theorem*이라고 합니다.   ## 깊이우선탐색의 계산복잡성 깊이우선탐색은 모든 노드와 엣지에 대해 한번씩은 탐색하게 되므로 전체적인 계산복잡성은 $O($\|$V$\|$+$\|$E$\|$)$가 됩니다.
representationlearning␞ 이번 글에서는 **representation learning** 개념에 대해 살펴보도록 하겠습니다. 딥뉴럴네트워크가 높은 성능을 내는 배경에는 복잡한 데이터 공간을 선형 분류가 가능할 정도로 단순화해 표현하기 때문이라는 이론인데요. 저도 공부하는 입장이니 많은 의견 부탁드립니다.  이번 글은 김현중, 고태훈 서울대 박사과정이 진행한 2017년 패스트캠퍼스 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 선형 모델의 한계 **다중선형회귀(Multiple Linear Regression)**는 설명변수(X)와 종속변수(Y) 사이의 관계를 선형으로 가정하고, 데이터와의 오차가 가장 작은 **직선**을 찾는 것을 목표로 합니다. 분류 문제도 마찬가지인데요. [선형판별분석(Linear Discriminant Analysis)](https://ratsgo.github.io/machine%20learning/2017/03/21/LDA/)이나 [로지스틱 회귀분석(Logistic Regression)](https://ratsgo.github.io/machine%20learning/2017/04/02/logistic/)도 항상 선형 분류 경계면을 만들어 냅니다.  이를 시각적으로 이해해 보면, 아래 그림의 경우 모델의 학습 결과로 하나의 직선(hyperplane), 즉 $[-1,1,1]^T$가 도출된 것을 확인할 수 있습니다. 선형 모델은 바로 이런 직선을 찾는 것이 학습의 목표가 됩니다. <a href="http://imgur.com/nnfHiIx"><img src="http://i.imgur.com/nnfHiIx.png" width="500px" title="source: imgur.com" /></a> 하지만 XOR 문제와 같이 데이터가 선형 관계가 아닐 경우 이들 모델은 높은 성능을 낼 수 없습니다. 아래 그림처럼 어떤 직선을 그어도 두 범주를 분류할 수가 없게 되거든요. 뉴럴네트워크의 할아버지격인 **퍼셉트론(Perceptron)**이 제시된 배경이기도 합니다. <a href="http://imgur.com/hEJRUQT"><img src="http://i.imgur.com/hEJRUQT.png" width="250px" title="source: imgur.com" /></a>  ## 뉴럴네트워크의 기본 구조 뉴럴네트워크를 이해해 보겠다면서 선형모델의 한계를 먼저 언급하고 있는 이유는 뉴럴네트워크의 본질이 사실상 **선형 모델**이기 때문입니다. 아래 그림은 뉴럴네트워크를 구성하고 있는 하나의 **뉴런(neuron)**을 나타낸 것입니다. 보시다시피 **활성함수(activation function)** 적용 직전의 값들은 가중치($w_i$)와 입력값($x_i$) 사이의 **선형결합(linear combination)**임을 확인할 수 있습니다. (아래 그림은 미국 스탠포드대학의 CS231n 강좌에서 퍼왔습니다) <a href="http://imgur.com/euw7qQu"><img src="http://i.imgur.com/euw7qQu.png" width="500px" title="source: imgur.com" /></a> 다만 여기에서 활성함수에 주목해야 합니다. 퍼셉트론과 뉴럴네트워크의 큰 차이점 가운데 하나는 바로 활성함수 여부에 있거든요. 활성함수는 보통 시그모이드, 하이퍼볼릭탄젠트, ReLU 등과 같이 비선형 함수를 씁니다. 이를 통해 선형모델의 한계를 극복하고자 한 것이죠. 활성함수에 대한 자세한 내용은 [이곳](https://ratsgo.github.io/deep%20learning/2017/04/22/NNtricks/)을 참고하시기 바랍니다.  ## XOR문제를 풀기 위한 단순 뉴럴네트워크 그럼 XOR 예시를 통해 뉴럴네트워크가 Representation Learining와 어떤 관련을 맺고 있는지 살펴보겠습니다. 아래 중앙 그림과 같은 XOR 문제를 풀기 위해 층이 두 개인 단순 뉴럴네트워크를 구축해 보겠습니다.  학습 결과 1층 첫번째 뉴런의 $h_1$이 아래 식처럼 도출될 경우 분류경계면은 하단 중앙의 연두색 선이 되고, 네트워크 전체 구조는 하단 좌측의 그림이 될 겁니다.  $$ { h }_{ 1 }={ x }_{ 1 }+{ x }_{ 2 }-\frac { 3 }{ 2 } $$ <a href="http://imgur.com/bHebe4m"><img src="http://i.imgur.com/bHebe4m.png" width="700px" title="source: imgur.com" /></a> 1층 첫번째 뉴런의 출력값인 $z_1$은 입력값과 가중치들의 선형결합으로 이뤄진 $h_1$이 활성함수($g$)에 의해 활성화된 것입니다. 뉴럴네트워크는 퍼셉트론과 흡사하나 활성함수가 추가됐다는 점이 다르다고 합니다. $g$는 아래와 같이 단순한 비선형 함수입니다. $${ z }_{ 1 }=g({ h }_{ 1 })=\begin{Bmatrix} 1\quad if\quad { h }_{ 1 }\ge 0 \\ 0\quad if\quad { h }_{ 1 }<0 \end{Bmatrix}$$ 이번엔 1층 두번째 뉴런의 출력값 $z_2$를 만들어 보겠습니다. $h_2$는 아래와 같고요, 활성함수는 $g$ 그대로 입니다.  $$ { h }_{ 2 }={ x }_{ 1 }+{ x }_{ 2 }-\frac { 5 }{ 2 },\quad { z }_{ 2 }=g({ h }_{ 2 }) $$ <a href="http://imgur.com/oOHrFYK"><img src="http://i.imgur.com/oOHrFYK.png" width="700px" title="source: imgur.com" /></a> 자, 이제 거의 다 왔습니다. 이번엔 전체 네트워크의 출력값 $z$를 만들어 보겠습니다. 학습 결과물은 다음과 같다고 칩시다.  $$ { o }_{ 1 }={ z }_{ 1 }-{ z }_{ 2 }-1,\quad z=g({ o }_{ 1 }) $$ <a href="http://imgur.com/qTgnxBd"><img src="http://i.imgur.com/qTgnxBd.png" width="600px" title="source: imgur.com" /></a> 최종 결과물 $z$를 보시면 동그라미와 네모 두 범주를 잘 분리하고 있는 점을 확인할 수 있습니다.  ## 뉴럴네트워크와 Represention Learning 위에서 예시로 든 단순 뉴럴네트워크의 학습과정을 좌표 축 위에 그리면 아래 그림과 같습니다. 이 모델의 첫번째 층은 입력값 $(x_1, x_2)$를 받아서 $(z_1, z_2)$를 출력합니다. 이 덕분에 모델의 두번째 층은 **직선** 하나만으로도 데이터의 범주를 분리해낼 수 있게 됐습니다. 기존대로라면 선형으로 분리할 수 없는 데이터가 선형 분리가 가능하게끔 데이터가 변형됐다는 얘기입니다. 다시 말해 뉴럴네트워크의 학습 과정에서 데이터의 **representaion**이 $(x_1, x_2)$에서 $(z_1, z_2)$로 바뀐 겁니다. <a href="http://imgur.com/udEynOf"><img src="http://i.imgur.com/udEynOf.png" width="300px" title="source: imgur.com" /></a> 이 글에서는 설명의 편의를 위해 단순 뉴럴네트워크를 예로 들었으나, 깊고 방대한 뉴럴네트워크는 학습데이터가 꽤 복잡한 represention이어도 이를 선형 분리가 가능할 정도로 단순화하는 데 좋은 성능을 낸다고 합니다. 이 때문에 뉴럴네트워크를 **representation learner**라고 부르는 사람들도 있습니다.   
honorification␞ 이번 글에서는 한국어의 객체경어법에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 객체경어법 객체경어법이란 문장 내의 목적어나 부사어를 높여서 존대를 실현하는 경어법의 한 종류입니다. 다음과 같이 주로 동사 서술어로 실현됩니다. - 묻다, 말하다 - 여쭙다 - 보다, 만나다 - 뵙다 - 주다 - 드리다 - 데리고 - 모시고 객체경어법은 여격조사 '께'로 실현되기도 합니다.   ## 언제 쓰이나 객체경어법은 다음과 같이 '화자보다 높은 객체'를 높이고자 할 때 쓰입니다. > (1) 언니가 아버지**께** 선물을 **드렸다**. 그러나 다음 예문은 비문입니다. > (2) (화자가 손자인 경우) *할아버지께서 아버지**께** 선물을 **드렸다**. 아버지는 화자보다 높은 객체라는 점에 주목한다면 (2) 또한 (1)처럼 객체경어법을 쓰지 않을 이유가 없습니다. 하지만 (1)은 아버지(객체)가 언니(주체)보다 높은 사람이지만, (2)는 아버지(객체)가 할아버지(주체)보다 낮은 사람이라는 점이 다릅니다. 객체높임은 '주체보다 높은 객체'를 높일 때 쓰인다는 것입니다. 다른 예문을 보겠습니다. > (3) (화자가 할아버지인 경우) ?철수야, 그거 어머니**께** 갖다 **드려라**. (3)에서는 어머니(객체)가 철수(주체)보다 높기 때문에, 객체가 주체의 존대 대상이 됩니다. 하지만 객체높임의 동사인 '드리다'를 쓰면 어색합니다. 어머니(객체)는 할아버지(화자)의 손아랫사람이기 때문입니다. 즉 객체높임은 화자와 객체와의 관계도 고려된다는 이야기입니다. 요컨대 객체높임은 객체가 화자보다 높고, 객체가 주체보다 높은 (1)과 같은 상황에서 실현될 수 있습니다.   ## 객체높임에서의 압존법 높여야 할 대상이지만 듣는 이가 더 높을 때 화자가 청자를 고려하여 주체의 공대를 줄이는 어법을 압존법(壓尊法)이라고 합니다. 객체높임에서도 압존법이 실현되는 경우가 있습니다. 객체높임이 실현된 예문을 먼저 보겠습니다. > 나는 신문을 아버지**께** 갖다 **드렸다**. 위 예문에 해당하는 내용을 할아버지께 말씀드린다고 가정해 봅시다. 이 경우 아래처럼 이야기해야 자연스럽습니다. 아버지(객체)가 할아버지(청자)보다 아랫사람이기 때문에 청자를 고려해 공대를 줄인 것입니다. > 할아버지, 신문을 아버지에게 갖다 주었습니다.    ## 객체경어법의 특징 객체경어법은 현대국어에서 그 쓰임이 아주 한정되어 있습니다. 주체높임의 선어말어미 '-시-'처럼 널리 쓰이는 형태소가 따로 없고 객체높임의 동사 몇 가지가 따로 있을 뿐입니다. 바꿔 말해 특수한 객체 존대형이 없는 용언에 대해서는 객체가 아무리 존귀한 인물이더라도 그에 대한 존대를 서술어 쪽에서는 표현할 방도가 없습니다. 예컨대 다음 예문의 할머니나 교장 선생님을 존대할 방법을 찾기가 마땅치 않습니다. > 창호는 할머니를 몹시 따른다. > > 영희야, 교장 선생님께 빨리 가거라.  
clustering␞ 이번 글에서는 **클러스터링(Clustering;군집화)**의 전반적 내용에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 강필성 교수님과 역시 같은 대학의 김성범 교수님 강의를 정리했음을 먼저 밝힙니다. 이 글은 클러스터링의 개괄적 내용을 설명하는 데 방점을 두었으니 [K-means 군집화](https://ratsgo.github.io/machine%20learning/2017/04/19/KC/), [계층적 군집화](https://ratsgo.github.io/machine%20learning/2017/04/18/HC/) 등 구체적 알고리즘을 살펴보시려면 링크를 클릭하시기 바랍니다. 그럼 시작하겠습니다.  ## 클러스터링의 목적 클러스터링의 목적은 간단합니다. 비슷한 개체끼리 한 그룹으로, 다른 개체는 다른 그룹으로 묶어보자는 겁니다. 이를 좀 있어보이게 표현하면 아래와 같습니다. <p class="message"> (1) 군집 간 분산(inter-cluster variance) 최대화<br> (2) 군집 내 분산(inner-cluster variance) 최소화 </p> 다만 여기서 주의해야 할 것은 클러스터링은 **분류(Classification)**와 구별해야 한다는 점입니다. 클러스터링은 정답이 없는 **비지도학습(unsupervised learning)**입니다. 다시 말해 각 개체의 그룹 정보 없이 비슷한 개체끼리 묶어보는 거죠. 반면 분류는 정답이 있는 **지도학습(supervised learining)**입니다. 분류 과제를 수행할 때는 데이터의 독립변수($X$)로 종속변수($Y$)를 예측하도록 학습을 진행하게 됩니다.  ## 군집 타당성 평가 클러스터링 과업은 정답이 없기 때문에 일반적인 머신러닝 알고리즘처럼 **단순정확도(Accuracy)** 등 지표로 평가할 수 없습니다. 아래 예에서 볼 수 있듯 최적의 군집 개수를 정답 없이 알아내기란 쉽지 않습니다. <a href="http://imgur.com/OhVcSqb"><img src="http://i.imgur.com/OhVcSqb.png" width="500px" title="source: imgur.com" /></a> 그렇다고 해서 군집이 제대로 만들어졌는지 평가할 수 있는 방법이 아주 없지는 않습니다. 군집을 만든 결과가 얼마나 유용한지 따지는 **군집타당성지표(Clustering Validity Index)**가 있기 때문입니다. 군집타당성지표는 아래 그림처럼 (1) 군집 간 거리 (2) 군집의 지름 (3) 군집의 분산 등을 고려합니다. 다시 말해 군집 간 분산과 군집 내 분산을 따진다는 겁니다. 이번 글에서는 **Dunn Index**와 **Silhouette** 두 가지 지표를 살펴보겠습니다. <a href="http://imgur.com/dFliYHp"><img src="http://i.imgur.com/dFliYHp.png" width="600px" title="source: imgur.com" /></a>  ### Dunn Index Dunn Index는 군집 간 거리의 최소값(하단 좌측)을 분자, 군집 내 요소 간 거리의 최대값(하단 우측)을 분모로 하는 지표입니다.  $$I(C)=\cfrac { \min _{ i\neq j }{ \{ { d }_{ c }({ C }_{ i },{ C }_{ j })\} } }{ \max _{ 1\le l\le k }{ \{ \triangle ({ C }_{ l })\} } } $$ 군집 간 거리는 멀수록, 군집 내 분산은 작을 수록 좋은 군집화 결과라 말할 수 있는데요. 이 경우에 Dunn Index는 커지게 됩니다. <a href="http://imgur.com/TClWvss"><img src="http://i.imgur.com/TClWvss.png" width="500px" title="source: imgur.com" /></a>  ### Silhouette 실루엣 지표를 계산하는 식은 아래와 같습니다. $$s(i)=\frac { b(i)-a(i) }{ \max { \{ a(i),b(i)\} } } $$ 여기에서 $a(i)$는 $i$번째 개체와 같은 군집에 속한 요소들 간 거리들의 평균입니다. $b(i)$는 $i$번째 개체와 다른 군집에 속한 요소들 간 거리들의 평균을 군집마다 각각 구한 뒤, 이 가운데 가장 작은 값을 취한 것입니다. 다시 말해 $b(i)$는 $i$번째 개체가 속한 군집과 가장 가까운 이웃군집을 택해서 계산한 값이라고 보시면 됩니다. 예컨대 아래처럼 파란색 군집 안에 있는 네모 박스에 해당하는 개체를 중심으로 실루엣 지표를 구할 수 있습니다. 이 경우 $a(i)$는 네모 개체와 파란색 군집 내 개체들 사이의 거리들의 평균이고요. $b(i)$는 네모 개체와 오렌지색 군집 내 개체들 사이의 거리들의 평균을 의미합니다. <a href="http://imgur.com/VfvGewn"><img src="http://i.imgur.com/VfvGewn.png" width="500px" title="source: imgur.com" /></a> 가장 이상적인 경우라면 $a(i)$가 0일 겁니다. 한 군집의 모든 개체가 한치도 떨어져 있지 않고 붙어있는 경우가 여기에 해당합니다. 그러면 실루엣 지표는 1이 됩니다. 최악의 경우에는 $b(i)$가 0입니다. 서로 다른 군집이 전혀 구분되지 않는 경우입니다. 이 때 실루엣 지표는 -1이 됩니다. 보통 실루엣 지표가 0.5보다 크면 군집 결과가 타당한 것으로 평가하게 된다고 합니다.  ## 클러스터링의 종류 클러스터링에는 몇 가지 종류가 있는데 다음과 같습니다. > **hard clustering** : 한 개체가 여러 군집에 속하는 경우를 허용하지 않는 군집화 방법입니다 > > **soft clustering** : 한 개체가 여러 군집에 속할 수 있습니다. > **pational clustering** : 전체 데이터의 영역을 특정 기준에 의해 동시에 구분하는 군집화 방법입니다. 각 개체들은 사전에 정의된 개수의 군집 가운데 하나에 속하게 됩니다. [K-mean 군집화](https://ratsgo.github.io/machine%20learning/2017/04/19/KC/)가 대표적입니다. > > [**hiarchical clustering**](https://ratsgo.github.io/machine%20learning/2017/04/18/HC/) : 개체들을 가까운 집단부터 차근차근 묶어나가는 방식입니다. 군집화 결과뿐 아니라 유사한 개체들이 결합되는 **덴드로그램(dendrogram)**을 생성합니다. > [**Self-Organizing Map**](https://ratsgo.github.io/machine%20learning/2017/05/01/SOM/) : 뉴럴넷 기반의 군집화 알고리즘입니다. > > [**Spectual clustering**](https://ratsgo.github.io/machine%20learning/2017/04/27/spectral/) : 그래프 기반의 군집화 방법론입니다 
shellsort␞ 이번 글에서는 **쉘정렬(selection sort)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의와 위키피디아를 정리하였음을 먼저 밝힙니다. 예시 그림과 파이썬 코드는 [이곳](http://interactivepython.org/runestone/static/pythonds/SortSearch/TheShellSort.html)을 참고하였습니다. 그럼 시작하겠습니다.   ## concepts 쉘정렬은 정렬되지 않은 배열을 정렬하는 데 많은 계산량이 드는 [삽입정렬](https://ratsgo.github.io/data%20structure&algorithm/2017/09/06/insmersort/)을 개선한 기법입니다. 다음과 같은 배열을 정렬한다고 칩시다. > 54, 26, 93, 17, 77, 31, 44, 55, 20 쉘정렬에서는 *gap*이라는 개념이 있습니다. 데이터를 띄엄띄엄 봐서 정렬한다는 개념인데요. 우선 위 숫자들을 아래와 같이 세 개 서브리스트로 나눕니다(*gap*=3).  <a href="https://imgur.com/9GmgdzX"><img src="https://i.imgur.com/9GmgdzX.png" width="350px" title="source: imgur.com" /></a>  이번엔 서브리스트별로 삽입정렬을 적용해 정렬한 뒤 세 서브리스트를 합칩니다. 다음과 같습니다.  <a href="https://imgur.com/g53byCb"><img src="https://i.imgur.com/g53byCb.png" width="350px" title="source: imgur.com" /></a>  마지막으로 위 리스트(`17, 26, 20, 44, 55, 31, 54, 77, 93 `)에 삽입정렬을 수행하면 쉘 정렬이 끝납니다. 쉘 정렬에서 *gap*은 정렬 대상 리스트의 절반으로 시작해 *iteration*이 돌 때마다 반씩 줄여가게 됩니다.   ## 파이썬 코드 쉘정렬을 파이썬으로 구현한 코드는 다음과 같습니다. ```python def shellSort(alist):   sublistcount = len(alist)//2   while sublistcount > 0:    for startposition in range(sublistcount):     gapInsertionSort(alist,startposition,sublistcount)    print("After increments of size",sublistcount,                  "The list is",alist)    sublistcount = sublistcount // 2 def gapInsertionSort(alist,start,gap):   for i in range(start+gap,len(alist),gap):     currentvalue = alist[i]     position = i     while position>=gap and alist[position-gap]>currentvalue:       alist[position]=alist[position-gap]       position = position-gap     alist[position]=currentvalue ``` 
BFS␞ 이번 글에서는 [그래프(Graph)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/)라는 자료구조를 순회하는 알고리즘 가운데 **너비우선탐색(Breath First Search)** 기법을 살펴보도록 하겠습니다. 파이썬 코드는 [이곳](http://interactivepython.org/runestone/static/pythonds/Graphs/ImplementingBreadthFirstSearch.html)을 참고하였습니다. 이 글은 고려대 김황남 교수님과 역시 같은 대학의 김선욱 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concepts 그래프 순회(traverse)란 그래프 내 모든 노드를 한번씩 모두 방문하는 걸 말합니다. 너비우선탐색이란 시작 노드를 방문한 후 시작 노드에 인접한 모든 노드를 우선 방문하는 그래프 순회 기법입니다. 더 이상 방문할 인접 노드가 없을 경우 그 다음 가까운 인접노드를 우선 방문합니다. 이 때 쓰는 자료구조가 바로 [큐(queue)](https://ratsgo.github.io/data%20structure&algorithm/2017/10/15/queue/)입니다. 너비우선탐색을 도식화한 그림은 다음과 같습니다.  <a href="https://imgur.com/SL1WRI6"><img src="https://i.imgur.com/SL1WRI6.png" width="250px" title="source: imgur.com" /></a>   ## 파이썬 코드 너비우선탐색을 파이썬으로 구현한 코드는 다음과 같습니다. 알고리즘에서 쓰이는 변수는 다음과 같습니다. - 그래프 : *g* (각 노드에는 값과 엣지뿐 아니라 거리 *Distance*, 색상 *Color* 정보도 들어 있음) - 시작노드 : *start* - 현재 분석 대상 노드 : *currentVert* - *currentVert*와 이웃한 노드 : *nbr* - 너비우선탐색을 위한 큐 자료구조 : *vertQueue* - 색상 : 아직 방문하지 않았다면 *white(defalut)*, 이미 방문했다면 *black*, 방문 여부를 검토하고 있다면 *gray* 알고리즘은 다음과 같이 동작합니다. ```python from pythonds.graphs import Graph, Vertex from pythonds.basic import Queue # g와 s를 입력으로 받습니다 def bfs(g,start):  # 시작노드의 거리를 0으로 초기화  start.setDistance(0)  # 시작노드의 부모는 None으로 초기화  start.setPred(None)  # vertQueue 선언  vertQueue = Queue()  # 시작노드 enqueue  vertQueue.enqueue(start)  # vertQueue 원소가 하나도 없을 때까지 반복  while (vertQueue.size() > 0):   # 큐에서 원소를 꺼내 currentVert에 저장   # 처음 시작할 경우 시작노드가 이것이 됨   currentVert = vertQueue.dequeue()   # currentVert에 인접한 노드(nbr)들을 하나씩 분석   for nbr in currentVert.getConnections():    # nbr이 아직 방문 안한 노드라면    if (nbr.getColor() == 'white'):     # 일단 분석 중이라는 의미로 gray로 색칠     nbr.setColor('gray')     # nbr의 거리, 부모 정보 업데이트     nbr.setDistance(currentVert.getDistance() + 1)     nbr.setPred(currentVert)     # nbr를 enqueue     vertQueue.enqueue(nbr)   # currentVert의 모든 이웃 분석이 끝나면   # currentVert를 이미 방문했다는 의미로 black으로 색칠   currentVert.setColor('black') ```   ## 순회 예시1 하단 좌측 그림과 같은 그래프 *g*를 너비우선탐색 방식으로 순회해보겠습니다. 시작노드 *start*는 1이라고 두겠습니다. 우선 시작노드의 거리를 0으로 초기화한 뒤 시작노드를 큐에 집어 넣습니다. 하단 우측그림과 같습니다.  <a href="https://imgur.com/XIZ75HD"><img src="https://i.imgur.com/XIZ75HD.png" width="500px" title="source: imgur.com" /></a>  *dequque*를 합니다. 1이 나옵니다. 1(*currentVert*)의 이웃노드들(3, 6)을 차례대로 돌면서 그 색상을 *gray*로 색칠해 두고, 거리와 부모 정보를 업데이트 한 뒤 큐에 집어 넣습니다. 이렇게 이웃노드들을 모두 돌면 1의 색상을 *black*으로 색칠해 둡니다. 이렇게 한 결과가 하단 좌측 그림입니다. *dequque*를 합니다. 이번엔 3이 나옵니다. 3의 이웃노드들(1, 2, 4, 5)을 차례로 돌면서 그 색상을 *gray*로 색칠해 두고, 거리와 부모 정보를 업데이트 한 뒤 큐에 집어 넣습니다. 그런데 1은 *white*가 아니므로 이러한 처리에서 제외합니다. 어쨌든 이렇게 이웃노드들을 모두 돌면 3의 색상을 *black*으로 색칠해 둡니다. 이렇게 한 결과가 하단 우측 그림입니다. 한편 아래 그림에서 $d=1,2,2,2$라는 얘기는 시작노드와 노드6 사이의 거리가 1, 노드2, 노드4, 노드5와는 각각 2라는 뜻입니다.  <a href="https://imgur.com/WJtlr3U"><img src="https://i.imgur.com/WJtlr3U.png" width="500px" title="source: imgur.com" /></a>  *dequeue*를 합니다. 이번엔 6이 나옵니다. 6의 이웃노드들(1, 5)을 차례로 돌면서 같은 방식으로 처리하려고 했더니 1, 5 모두 *white*가 아닌 것을 알 수 있습니다. 처리할 것이 없으므로 6의 색상을 *black*으로 칠해둡니다. 이렇게 한 결과가 하단 우측 그림입니다. 그런데 여기에서 6과 5 사이의 엣지가 사라진 것이 의아할 수 있습니다. 조금 이따가 **너비우선트리(Breadth-first-tree)**를 설명하려고 이렇게 그림을 그린 것입니다. 그래프 구조가 바뀐 것은 아니니 신경 안쓰고 넘어가셔도 됩니다.  <a href="https://imgur.com/JTdnggk"><img src="https://i.imgur.com/JTdnggk.png" width="500px" title="source: imgur.com" /></a>  *dequeue*를 합니다. 이번엔 2가 나옵니다. 2의 이웃노드들(3)을 차례로 돌면서 같은 방식으로 처리하려고 했더니 3이 *white*가 아닌 것을 알 수 있습니다. 처리할 것이 없으므로 2의 색상을 *black*으로 칠해둡니다. 이렇게 한 결과가 하단 좌측 그림입니다. 마찬가지로 4와 5에 대해서도 수행하면 너비우선탐색이 종료됩니다.  <a href="https://imgur.com/2Qx40Ng"><img src="https://i.imgur.com/2Qx40Ng.png" width="500px" title="source: imgur.com" /></a>  시작노드 중심으로 너비우선탐색으로 부모-자식 관계를 만들어 나타낸 그래프를 `너비우선트리(Breath First Tree)`라고 합니다. 다음과 같습니다.  <a href="https://imgur.com/1XbiAsN"><img src="https://i.imgur.com/1XbiAsN.png" width="350px" title="source: imgur.com" /></a>   ## 순회예시2 또다른 예시입니다. 다음과 같습니다. <a href="https://imgur.com/F64H5hP"><img src="https://i.imgur.com/F64H5hP.png" title="source: imgur.com" /></a>   ## 계산복잡성 변수초기화 부분은 $O(1)$이므로 *whle* 반복문이 전체 계산량을 좌우합니다. 큐에 한번 넣었다가 큐에서 빼는 걸 모든 노드에 대해 수행하므로 $O($\|$V$\|$)$의 계산복잡성이 소요됩니다. 그런데 *currentVert*의 모든 인접노드에 대해 색상, 거리, 부모 정보를 업데이트하고, 이는 곧 그래프의 모든 엣지를 스캔한다는 의미이므로 *for* 반목문 안의 계산복잡성은 $O($\|$E$\|$)$가 됩니다. 따라서 전체적인 계산복잡성은 $O($\|$V$\|$+$\|$E$\|$)$가 됩니다.  
morpheme␞ 이번 포스팅에서는 언어학과 자연언어처리 분야 기본 중 하나인 **형태소(形態素morpheme)**에 대해 다뤄보려고 합니다. 형태소 정의와 분석방법 등에 대해 알아보겠습니다. 이번 글은 [이선웅 경희대 교수](http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&ejkGb=KOR&barcode=9788984775275&orderClick=JA2), [최형용 이화여대 교수](https://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&ejkGb=KOR&barcode=9788962924572&orderClick=JAj)께서 쓰신 글들을 참고해 작성했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 형태소의 정의 형태소란 **의미를 가지는 최소 단위**로 정의됩니다. 더 쪼개면 뜻을 잃어버리는 말의 단위라고 할 수 있죠. 이때의 '의미'는 어휘적인 것뿐 아니라 문법적인 것도 포함한다는 사실을 염두에 두고 아래 예문을 통해 개념을 살펴보기로 하죠. 예시에서 '철수'를 '철'과 '수'로 쪼개면 '철수'라는 사람을 지칭하는 의미가 없어집니다. 마찬가지로 '밥'을 'ㅂ'과 '압'으로 나누면 먹는 밥(rice)의 뜻이 사라지게 되죠. 이런 점에서 '철수'와 '밥'은 형태소 후보에 오를 수 있겠습니다. > 철수가 밥을 먹었다. 형태소를 분석하는 기준으로는 **계열관계(系列關係paradigmatic relation)**와 **통합관계(統合關係sytagmatic relatation)**이 있습니다. 계열관계는 종적인 것으로서 그 자리에 다른 형태소가 '대치'될 수 있는가를 따지는 것이고, 통합관계는 횡적인 것으로서 그 형태소가 다른 형태소와 '결합'할 수 있는가를 고려하는 것입니다. 이 가운데 형태소 분석에서 더 중요한 역할을 담당하는 것은 계열관계인데요, 계열관계만으로도 형태소 자격을 부여할 수 있습니다. 일단 먼저 계열관계를 살펴볼까요? '철수' 자리에 '영희'와 같은 말이 대치될 수 있습니다. '밥' 대신에 '빵'을 쓸 수 있죠. 따라서 '철수'와 '밥'은 형태소 자격을 갖습니다. 그럼 '가'는 어떨까요? '가'는 그 자체로 어휘적 의미를 가지지는 못하지만 그 말이 결합한 말을 **주어**가 되게 하므로 문법적 의미를 갖습니다. 또 '가'는 '는'이나 '도'와 계열관계를 이루므로 형태소로서의 자격을 갖습니다. 그런데 '가'는 조금 더 세밀히 살펴야 합니다. 그 말을 주어가 되게 하는 것이 '가'만 있는 것은 아니기 때문인데요. 선행하는 말이 '철수'가 아니라 '책'과 같이 받침이 있는 말이라면 '가' 대신 '이'가 선택됩니다. 이처럼 '이'가 되거나 '가'가 되는 것은 '이'나 '가'가 서로 다른 (문법적)의미를 가지기 때문이 아니라 단지 선행하는 말이 받침을 가지고 있느냐 여부에 있으므로 '이'나 '가'는 모양은 다르지만 서로 같은 형태소라고 할 수 있습니다. 바꿔 말하면 '이'와 '가'는 같은 형태소의 다른 형태라고 할 수 있는 셈이죠. 이처럼 같은 형태소의 다른 형태들을 **이형태(異形態allomorph)**라고 합니다. '밥'을 조금 더 살펴보겠습니다. 앞서 언급했듯 '밥'은 형태소이지만 '밥만'과 같은 예에서는 '밤'으로 실현됩니다. '밥'과 '밤'이 이형태라는 말이지요. 하지만 이것은 표기에서는 구분되지 않습니다. 이것은 한국어의 표기체계가 이형태 가운데 대표적인 **기본형(基本形basic form)**을 밝혀 적은 원칙을 따르고 있기 때문입니다. 한편 '을'은 '가'와 상황이 비슷합니다. 주로 선행하는 말과 결합하여 그 말을 **목적어**가 되게 해주고 '은'이나 '도'와 계열관계를 이루고 있으므로 하나의 형태소입니다. 그러나 선행어가 받침을 가지느냐 여부에 따라 '를'을 이형태로 갖습니다. 이제 '먹었다'를 분석해볼까요? 우선 '먹-'은 그 자체로 어휘적인 의미를 가지면서 그 자리에 '잡-'과 같은 말이 대치될 수 있으므로 하나의 형태소입니다. '-었-'은 '과거'를 나타내주는 문법적 의미를 가지고 있으면서 '-겠-'과 같은 말과 계열관계를 이루고 있으므로 역시 형태소입니다. 마지막으로 '-다'도 문법적인 의미를 가지면서 '-어'와 같은 다른 어미와 대치될 수 있으므로 형태소입니다. '먹-'은 '먹는[멍는]'과 같은 예에서도 알 수 있듯 이형태로 '멍'과 같은 걸 가지지만 표기로는 반영되지 않습니다. '-었-'은 선행모음이 음성모음이냐 양성모음이냐에 따라 '-았-'이라는 이형태를, 선행어가 '하-'일 경우에는 '-였-'이라는 이형태를 갖습니다. '-다'는 '-더-'와 결합할 때는 '-라'를 이형태로 가집니다.  ## 형태소 정의에 관한 다양한 이견들 형태소는 앞서 언급한 바와 같이 의미를 가지는 최소 단위입니다. 더 쪼갤 수는 있으나 그렇게 하면 스스로 의미를 가지지 못한다는 걸 뜻합니다. 이때 의미는 어휘적 의미는 물론 문법적 의미를 포함합니다.  그런데 여기서 문제가 되는 것은 한국어의 '오솔길', '아름답다', '착하다', 영어의 'cranberry' 등에서 보이는 '오솔-', '아름-', '착-', 'cran-'과 같은 이른바 **특이형태소(unique morpheme)**라 불리는 존재들입니다. 이들은 분포가 극도로 제약되어 있기 때문에 원래 쓰이던 단어에서 분리하면 그 의미를 제대로 알기 어려운 것들입니다.  그러나 이들도 형태소임은 분명합니다. '오솔길', '아름답다', '착하다', 'cranberry'의 의미는 '오솔-', '아름-', '착-', 'cran-'을 빼면 확 달라지기 때문입니다. 다시 말해 '오솔-', '아름-' 같은 어구의 의미를 제대로 알기 어렵다고 해서 의미가 없는 것은 아니라는 얘기입니다. 또한 '오솔-'을 '오'와 '솔'로 나누는 것처럼 이들을 더 쪼개면 분리하기 전 있었던 의미가 사라지기 때문에 이 자체로 '의미를 가지는 최소의 단위', 즉 형태소가 됩니다. 이 때문에 최근의 국어학자들은 형태소를 '최소의 의미 단위'라는 굴레에서 벗어나 일정한 음운론적 특징을 가진 단위(소리가 비슷한 말들)까지 확대해 분석하는 경향이 있습니다. 의미를 잘 모르겠다고 해서 형태소 분석 대상에서 빠지는 말들이 없도록 하자는 취지입니다. 이보다 더 골치 아픈 개념이 바로 **공형태(소)** 개념입니다. 말 그대로 '의미가 없는 형태소'라는 뜻이죠. 최소의 의미 단위라는 정의 자체에 반하는 것이어서, 국어학자들 사이에서도 꽤나 논란이 되고 있습니다. [장윤희(1999)](http://hosting03.snu.ac.kr/~komorph/new/en/qna/qna01.php?boardName=boardQna&mode=view&bNo=14&page=18&PHPSESSID=2e8848d9357db7e7cd23e4c52f3cec93d41a7752)에 따르면 중세 한국어에서 '거맃-[濟]'과 동일한 의미의 '거리치-'에서 나타나는 '-이-'가 공형태라 볼 수 있습니다. 즉 '-이-'가 없어도 뜻 변화에 영향이 없다면 그 의미가 없는(empty) 형태소라는 말이죠. 한국어에 공형태소가 있느냐, 있다면 그 개념을 채택할 수 있느냐에 이르기까지 수많은 논의가 이뤄지고 있습니다. **영형태(소)**는 공형태(소)와 반대 개념입니다. 의미는 있으나 형태는 없는 형태(소)를 가리키는 말이죠. 영접사 등 체계적인 문법 기술(desciption)을 위해 도입된 개념으로, 이 역시 인정하는 쪽과 그렇지 않은 쪽 사이에 논란이 있습니다.  ## 어기, 어근, 어간 컴퓨터에 한국어 단어를 가르쳐줄 때 어근이나 어간 위주로 알려주는 것이 여러모로 편리할 것입니다. 한국어는 조사나 어미 등이 붙어 수많은 의미 분화가 이뤄지는 **교착어(첨가어)**이기 때문입니다. 그럼 단어의 뿌리에 해당하는 **어기, 어근, 어간**에 대해 살펴보겠습니다. > **어기(語基)** : 어근과 어간을 아우르는 용어 > > **어근(語根)** : 복합어의 형성에 나타나는 실질형태소. 한편으로는 규칙어근과 불규칙어근으로, 다른 한편으로는 단순어근과 복합어근으로 나뉜다. > > **어간(語幹)** : 활용어미가 직접 붙을 수 있는 부분. 문장 형성의 요소로서 단어형성의 요소인 '어근'과 층위를 달리한다. **규칙어근**이란 어근의 품사가 분명하고 다른 말과 자유롭게 통합될 수 있는 말을 뜻합니다. '집', '신', '드높-'에서의 '높-' 등이 여기에 해당합니다. **불규칙어근**은 품사가 명백하지 않고 다른 말과의 통합에 제약이 있는 말입니다. '아름-'과 '따뜻-'은 단독형으로 말할 수 없고 조사와의 통합도 제약됩니다. (*아름, *아름이, *아름을;\*따뜻, *따뜻이, *따뜻을) **단순어근**과 **복합어근**은 어근의 종류가 단일한가 아닌가로 나뉘는 개념입니다. '신선(新鮮)하다'에서의 '신'과 '선'은 단순어근이며 '신선'은 복합어근입니다. 어간의 예를 들어보겠습니다. '높다, 높고, 높으니, 높습니다...'에서의 '높-'이 바로 어간입니다. 어미가 붙어 그 의미가 분화합니다.  ## 말뭉치 분석 결과 이상 논의한 내용을 실제 말뭉치를 가지고 이야기해 보겠습니다. [왓챠](https://watcha.net/)의 영화 리뷰 657만2288건을 대상으로 분석을 했는데요. 우선 서울대 김현중 박사과정이 개발한 [띄어쓰기 알고리즘](https://github.com/lovit/soy/tree/master/soy/nlp/space)로 띄어쓰기 교정한 뒤 띄어쓰기 기준으로 어절을 나누었습니다. 어절 첫 두 글자가 같으면 같은 단어군(群)으로 묶었는데요, 그 결과는 아래와 같습니다. > 잊었다고, 잊었던, 잊었어도, 잊었다, 잊었나, 잊었지만 > 원동력, 원동력이란, 원동력만으로만, 원동력으로, 원동력이, 원동력을, 원동력은 > 쓸쓸, 쓸쓸한, 쓸쓸했다, 쓸쓸해졌다, 쓸쓸함, 쓸쓸하다, 쓸쓸함도, 쓸쓸하지만은, 쓸쓸히, 쓸쓸해진다, 쓸쓸해져온다, 쓸쓸하지, 쓸쓸해보이는, 쓸쓸하게, 쓸쓸하여, 쓸쓸함을, 쓸쓸함이란, 쓸쓸해서, 쓸쓸하고도, 쓸쓸했고, 쓸쓸함이, 쓸쓸하며, 쓸쓸해도, 쓸쓸했지만, 쓸쓸하고 단순 띄어쓰기, 어절 첫 두 글자로 분석한 내용이기에 절대 엄밀한 결과가 될 수는 없지만 어절 첫 두 글자를 단어의 뿌리로 보고 이를 같은 집단으로 보는 방법론이 어느 정도 활용 가능성이 있을 것이라는 희망을 갖게 됐습니다.  다만 이렇게 단어를 합쳐서 보는 데도 단어 수가 6~7만개 안팎으로 많아서(현재 연구용 PC로는 5만개 이상 단어는 메모리 한계로 분석 어려움) 단어 수를 효과적으로 줄이는 방법을 좀 더 연구해보려고 합니다. 단어를 합쳐서 보는 데 따른 정보량 손실을 최소화하면서도 계산효율성을 최대한 유지하는 방안을 고민 중입니다.  ## 마치며 이상으로 형태소의 정의와 어기, 어근, 어간 등에 대해 살펴보았습니다. 형태소 분석은 자연언어처리 분야에서도 아주 중요하게 취급되는 분야인데요, 국어학에서 이룬 성취를 최대한 반영해 모델링을 하고 싶은 게 제 소망입니다. 현재는 어절 첫 두 글자만 잘라 보는 조악한 방법론을 쓰고 있는데요, 차차 개선해보려고 합니다. 질문이나 의견 있으시면 언제든 이메일이나 댓글로 알려주시기 바랍니다. 여기까지 읽어주셔서 진심으로 감사드립니다. 
valency␞ 이번 글에서는 한국어 서술어의 논항과 자릿수에 대해 살펴보도록 하겠습니다. 이 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 절에서 서술어의 중요성 주어+서술어 구조의 구성을 '절'이라고 합니다. 절에서 필수적으로 쓰여야 하는 문장성분의 개수와 종류는 서술어의 의미에 따라 정해집니다. 서술어는 자신의 의미에 따라 하나 혹은 여러개의 언어요소들을 요구하고, 그것들로 절의 기본적 뼈대가 결정된다는 이야기죠. 예문을 보겠습니다. > 꽃이 피었다. > > 진이가 책을 샀다. > > 김 박사는 영호를 사위로 삼았다. 위의 예시와 같이 '피다', '사다', '삼다'는 각각 서로 다른 수와 종류의 문장성분을 요구하고 있음을 볼 수 있습니다. 예컨대 '삼다'의 경우 '김 박사는', '영호를', '사위로'라는 요소 없이는 완전한 문장을 구성해낼 수가 없게 됩니다. 이는 나중에 설명할 서술어의 자릿수와 관계가 있습니다.   ## 사태와 참여자 사태(state-of-affairs, situation)란 세계에서 일어나거나 성립되는 일을 가리킵니다. 예컨대 다음 예문과 같습니다. > **행위(action)** : 나는 학교에 **간다**. > > **상태(state)** : 물이 **차다**. > > **상태변화(change of state)** : 얼음이 **녹는다**. 참여자(participant)란 사태에 참여하는 존재를 나타냅니다. 사태의 성격에 따라 필요한 참여자의 수와 역할이 정해집니다. 그런데 사태와 참여자는 비언어적 존재 혹은 개념이라는 사실에 유의해야 합니다.   ## 서술어와 논항 사태와 참여자에 각각 연관되는 의미론적 개념이 술어와 논항입니다. 서술어(predicate)란 사태의 종류를 나타내는 언어요소입니다. 자신이 나타내는 사태가 필요로 하는 참여자의 수만큼 자신의 의미표상 속에 빈자리(slot)가 있습니다. 논항(argument)이란 서술어가 나타내는 사태에 참여하는 참여자를 나타내는 언여요소입니다. 서술어의 의미표상 속 빈자리를 채워주는 역할을 합니다. 다시 말해 서술어가 그 의미를 온전히 드러내기 위해 반드시 필요한 요소가 논항이라고 말할 수 있습니다. 예문을 보겠습니다. > 톰이 제리를 좋아한다. 위 예문의 서술어 동사 '좋아하다'가 그 의미를 나타내기 위해서는 최소한 좋아하는 행위를 하는 주체, 좋아하는 행위의 대상이 갖추어져야 어떤 사건의 장면이 성립됩니다. 곧 행위의 주체와 대상은 '좋아하다'가 *의미적으로* 꼭 필요한 요소라고 할 수 있고 이를 논항이라고 부릅니다.    ## 서술어의 자릿수 서술어가 꼭 필요로 하는 문장 성분, 즉 논항의 개수를 서술어의 **자릿수(valency)**라고 합니다. 한국어 서술어의 자릿수는 대개 한 개에서 세 개 사이라고 합니다. 그 예는 다음과 같습니다. > 한 자리 술어 : (사람이) 죽다, (아기가) 울다, (물이) 끓다, (친구가) 예쁘다 > > 두 자리 술어 : (아기가 밥을) 먹다, (범인이 피해자를) 죽이다, (진이가 연극을) 보다, (물이 얼음이) 되다, (어른이 아이에게) 속다, (진이가 학교에) 다니다, (그림이 실물과) 같다 > > 세 자리 술어 : (진이가 동생에게 선물을) 주다, (진이가 동생에게 선물을) 받다, (아이가 우체통에 편지를) 넣다, (김 선생이 저 아이를 제자로) 삼다 그런데 같은 어휘항목이라도 여러 의미를 가지는 경우(다의어)에는 자릿수 또한 달라질 수 있습니다. 다음 예문과 같습니다. > 진이가 음식을 만들었다. > > 그들은 이웃 나라를 속국으로 만들었다.   ## 논항 판별 기준1 그렇다면 문장의 어떤 성분이 해당 서술어의 논항일까요? 문장 필수성분인 논항과 논항이 아닌 부가성분을 가려내는 건 생각보다 쉽지 않습니다. 다음 예문에서 강조표시된 서술어의 논항이 무엇인지 살펴보겠습니다. > (가) 나의 집은 무서울 만큼 **조용했다**. > > (나) 진리는 시대에 따라 변하는 것이 **아니다**.  첫번째 논항 판별 기준은 모국어 화자의 '직관'을 활용하는 것입니다. 특정 문장성분을 빼도 문장이 성립하는지 따져보는 것입니다. 우선 (가)의 '조용하다'는 한 자리 술어인 것 같습니다. '나의 집은 조용했다'도 말이 되기 때문입니다. 이런 면에서 '조용하다'의 논항은 '(나의)집은'이 됩니다. (나)의 '아니다'는 두 자리 술어인 것 같습니다. '진리는 아니다', '시대에 따라 변하는 것이 아니다'라는 표현에 뭔가 부족한게 느껴지기 때문입니다. 이런 면에서 '아니다'의 논항은 '진리는'과 '(시대에 따라)변하는 것이'가 됩니다. 하지만 직관에 의존한 논항 판별 기준은 판단하는 사람마다 달라질 수 있고, 모호하다는 단점이 있습니다.   ## 논항 판별 기준2 두번째 판별 기준은 다음 예문과 같이 '반문 테스트'를 해보는 것입니다. (이정민, 남승호, 강범모 1998) > A: 존이 떠났어. > > B : 아, 그랬어? ?{그런데 어디에서?} > > C : 아, 그랬어? 그런데 어디로? 위와 같은 발화상황에서 청자가 '아, 그랬어?'라는 반응을 보였다는 것은 화자 A의 단언에 대해 충분히 알아들었다는 걸 의미합니다. 그런데 청자가 논항에 대해 반문한다면 그 발화는 어색할 수밖에 없습니다. 다시 말해 화자 A의 단언을 수긍했다는 것은 이미 그 단언이 당연히 함의하고 있는 정보에 대해서는 충분히 전달받았음을 인정하고 있다는 이야기입니다. 예시 기준으로 설명하면 '존이 떠났다'는 걸 수긍한 B가 다시 '어디에서 떠났느냐?'고 묻는 것은 어색합니다. 다시 말해 B가 A의 단언을 인정했다는 것은, 구체적인 발화상황 속에서는 '어딘가에서'가 생략됐지만, '누군가가 어딘가에서 떠났다'는 전체 정보를 이미 수긍했다는 의미이기 때문에, B도 이미 알고 있다고 판단되는 정보인 '어딘가에서'를 다시 반문하는 것이 어색하다는 이야기입니다. 따라서 이 반문테스트에서는 '어딘가에서'가 '떠나다'의 논항이 됩니다.  C의 경우 발화가 자연스럽습니다. 한국어 화자라면 '존이 떠났다'는 걸 수긍하더라도 충분히 궁금해할 수 있겠다는 생각이 듭니다. 바꿔 말해 '누군가가 어딘가에서 떠났다'는 전체 정보를 이미 수긍했더라도, '어디로'는 다시 물어봄직한 추가적인 정보에 해당한다는 이야기입니다. 따라서 이 반문테스트에서는 '어디로'는 '떠나다'의 논항이 아닙니다.   ## 논항 판별 기준3 세번째 판별 기준은 논항인지, 아닌지 잘 구별되는 통사적 환경을 일부러 만들어서 해당 성분이 논항인지를 따져보는 것입니다. 예컨대 '아이가 젓가락으로 밥을 먹는다'에서 '먹다'의 논항이 무엇인지 살피기 위해 다음과 같은 문장을 억지로 만들어 봅니다. > (A) 아이가 젓가락으로 먹는 것은 {밥이다, *밥을이다}. > > (B) 아이가 밥을 먹는 것은 {*젓가락이다, 젓가락으로이다}. 논항은 서술어의 필수성분입니다. 서술어로부터 의미적인 자격이나 문법적인 자격이 예측될 수 있으므로 격조사 없이도 그 자격이 명확합니다. (A)에서 '밥을이다'가 비문이 되는 건 이 때문이라고 할 수 있는데요. 따라서 세번째 판별 기준에 의하면 '밥'은 '먹다'의 논항이 됩니다. 반면 논항이 아닌 경우에는 해당 성분이 서술어가 요구하는 필수 성분이 아니므로, 서술어로부터 해당 요소의 자격을 예측해낼 수 없습니다. (B)에서 '젓가락이다'가 비문이 되는 건 이 때문입니다. 따라서 이 기준에 의하면 '젓가락'은 '먹다'의 논항이 아닙니다.   ## 온논항과 반논항 논항은 용언의 의미를 성립시키기 위한 필수 요소입니다. 그러므로 상황 맥락이 주어지지 않을 경우에는 문장에서 통사적으로도 반드시 나타나야 합니다. 논항이 통사적으로 나타났을 경우 **보충어(complement)**라고 합니다. 한국어에서 보충어는 일반적으로 격조사와 결합되어 실현됩니다. 그러나 어떤 논항은 중요성이 낮아서 보충어로 나타나지 않는 경우도 있습니다. 이때 통사적으로 나타난 논항을 **온논항(온전히 나타난 논항)**이라 하고, 논항이기는 하지만 통사적으로 나타나지 않은 논항을 **반논항**이라고 합니다. 예문을 보겠습니다. > (가) 나는 (집에서) 학교로 갔다. > > (나) 그는 이 물건을 나에게 (3만 원에) 팔았다. (가)에서 '가다'라는 동사의 의미는 행위의 주체가 어떤 지점에서 어떤 지점까지 공간 이동을 하였을 때 성립합니다. 그러므로 떠나는 지점(집에서)도 논항에 해당하는 겁니다. (나)에서 '팔다'라는 행위에는 반드시 대가가 있어야 합니다. 그 개념이 없으면 '주다'의 의미와 같아지기 때문입니다.  그러나 (가)의 '집에서'와 (나)의 '3만 원에'는 통사적으로 실현되지 않는 경우가 많습니다. 이들 논항이 중요하게 부각되는 상황이 실제 세계에서 드물게 발생하기 때문입니다. 다시 말해 화자가 관심을 기울이지 않는 정보는 논항이라고 하더라도 반논항이라는 겁니다. 아래 예시의 강조 표시는 언제나 온논항에 해당하는 필수 부사어입니다. > (ㄱ) 민들레는 **씀바귀와** 비슷하다. > > (ㄴ) 아내가 **귀엽게** 군다. > > (ㄷ) 철수는 **밥을 먹어** 버렸다.   ## 논항, 핵어, 보충어 논항이 보충어로 나타나기는 하지만 모든 보충어의 개념이 논항과 연관되는 것은 아닙니다. 정의를 한번 보겠습니다. > (1) 논항은 핵어의 *의미적* 구현에 꼭 필요한 의미적 요소이다. > > (2) 보충어는 핵어의 *통사적* 구현에 꼭 필요한 통사적 요소이다. > > (3) **핵어(head)**란 어떤 구성의 핵심적 요소이다. 예컨대 명사구(NP)의 핵어는 명사(N)이고 동사구(VP)의 핵어는 동사(V)이다. 가령 조사는 그 앞에 반드시 명사구가 결합되기를 통사적으로 요구합니다. 이때 조사 앞의 명사구는 조사의 보충어라고 할 수 있습니다. 그러나 이때의 명사구가 조사의 논항은 아닙니다. 논항은 사태(사건+상태) 성립에 필요한 의미적 요소이기 때문입니다. 한편 의존 명사 앞의 관형어도 명사구의 핵어가 의존 명사일 경우 그것이 통사적으로 구현되는 데에 꼭 필요한 통사적 요소이므로 보충어라고 할 수 있습니다.
MSSP␞ 이번 글에서는 순서가 있는 숫자들의 최대 부분합을 구하는 문제인 **Maximum Subsequence Sum Problem** 알고리즘에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의를 정리하였음을 먼저 밝힙니다. 네 가지 접근을 소개할 예정인데요, 계산복잡성이 차례로 줄어듭니다. 그럼 시작하겠습니다.   ## 접근1 다음과 같은 리스트가 있다고 가정해 보겠습니다. > 4, -3, 5, -2, -1, 2, 6, -2 이 문제를 가장 단순하게 푸는 방법은 모든 경우의 수를 하나하나 모두 따져보는 것입니다. $i$는 고려 대상 부분 리스트의 왼쪽 끝 인덱스, $j$는 오른쪽 끝 인덱스, Thissum은 고려 대상 부분 리스트의 합, Maxsum은 이 문제의 최종 결론입니다. 다음과 같습니다. | $i$ | $j$ |      Thissum      | Maxsum | | :--: | :--: | :-------------------------: | :----: | | 0  | 0  |       4       |  4  | | 0  | 1  |      4+(-3)      |  4  | | 0  | ... |       ...       | ...  | | 0  | 7  | 4+(-3)+5+(-2)+(-1)+2+6+(-2) |  11  | | 1  | 1  |       -3       |  11  | | 1  | 2  |      (-3)+5      |  11  | | ... | ... |       ...       | ...  | | 7  | 7  |       -2       |  11  | 위 표를 말로 풀어 설명하면 우선 $i$, $j$, Thissum, Maxsum을 모두 0으로 초기화합니다. $i$는 고정시킨 채 $j$를 0부터 리스트 요소 전체 숫자($n$)만큼 훑어가면서 부분 리스트를 만들고 이 리스트의 합을 Thissum으로 정의합니다. 그리고 이를 Maxsum과 비교해 더 큰 값을 Maxsum에 저장합니다. 이를 $i$와 $j$가 모두 $n=7$이 될 때까지 반복합니다. 이 방식의 의사코드는 다음과 같습니다. ```c Maxsum = 0 for (i=0; i < n; i++)  {   for (j=i; j < n; j++)    {     Thissum = sum(A[i:j])    	Maxsum = max(Thissum, Maxsum)    }  } ``` 이 방식의 계산복잡성은 $O(n^3)$이 됩니다. $i$와 관련된 반복문은 $n$번, $j$와 관련된 반복문은 최대 $n$번, Thissum을 구할 때 최대 $n$개의 요소를 계산해야 하기 때문입니다.   ## 접근2 접근1보다 계산복잡성을 낮추는 방법은 Thissum을 구할 때 중복을 좀 피하는 것입니다. 예제 리스트와 그 방식을 나타낸 표는 다음과 같습니다. > 4, -3, 5, -2, -1, 2, 6, -2 | $i$ | $j$ | Thissum | Maxsum | | :--: | :--: | :-----: | :----: | | 0  | 0  |  4  |  4  | | 0  | 1  | 4+(-3) |  4  | | 0  | 2  |  1+5  |  6  | | 0  | 3  | 6+(-2) |  6  | | 0  | ... |  ...  | ...  | | 0  | 7  | 11+(-2) |  11  | | ... | ... |  ...  | ...  | 표에서 접근1과의 차이가 느껴지실 지 모르겠습니다. 접근1에서는 Thissum을 구할 때 **sum(A[i:j])**을 취하여 매번 새로 구하다시피했습니다. 하지만 접근2에서는 직전 계산 결과를 재활용합니다. 예컨대 $i$가 0, $j$가 3일 경우 접근1에서는 4-3+5-2를 계산했다면, 접근2에서는 직전 계산결과인 6에 $j$번째 요소인 -2를 더해 Thissum을 구합니다. 의사코드는 다음과 같습니다. ```c Maxsum = 0 for (i=0; i < n; i++)  {   for (j=i; j < n; j++)    {     Thissum = sum(A[i:j])    	Maxsum = max(Thissum, Maxsum)    }  } ``` 이 방식의 계산복잡성은 $O(n^2)$이 됩니다. $i$와 관련된 반복문은 $n$번, $j$와 관련된 반복문은 최대 $n$번, Thissum을 구할 때는 $O(1)$의 계산만 하면 되기 때문입니다.   ## 접근3 접근3은 **분할정복(divide-and-conquer)**을 활용한 방식입니다. 분할정복이란 원 문제를 작은 부분문제로 나눠 푼 뒤 그 결과를 합쳐서 문제를 해결하는 알고리즘의 한 종류입니다. 접근3은 분석 대상 리스트를 절반씩 두 부분으로 나눕니다. 다시 예제 리스트를 보겠습니다. > 4, -3, 5, -2, -1, 2, 6, -2 위 리스트를 두 부분으로 나누면 [4, -3, 5, -2], [-1, 2, 6, -2]가 됩니다. 왼쪽 리스트의 최대 부분합은 6(4-3+5), 오른쪽 리스트의 최대 부분합은 8(2+6)이 됩니다.  그런데 고려해야 하는 경우의 수가 이것만 있는 것은 아닙니다. 예컨대 [5, -2, -1]처럼 자른 곳(-2와 -1 사이)를 포함하는 부분 리스트도 얼마든지 존재할 수 있기 때문입니다. 중간에 존재하는 케이스의 경우 1)왼쪽 리스트의 마지막 요소(left ending)를 끝으로 하는 부분 리스트의 최대 부분합 2)오른쪽 리스트의 첫 요소(right starting)를 시작으로 하는 부분 리스트의 최대 부분합을 각각 구해 이를 더하면 구할 수 있을 것입니다. 1)에 해당하는 수는 4(-2+5-3+4), 2)는 7(-1+2+6)이므로 중간 케이스의 최대 부분합은 11이 됩니다. 결과적으로는 8, 6, 11 가운데 최대값을 취한 것이 접근3의 결과물이 되겠습니다. 접근3의 의사코드는 다음과 같습니다. left와 right는 각각 고려 대상 리스트의 왼쪽 끝, 오른쪽 끝의 인덱스입니다. ```c Maxsubsum(A[], left, right)  {  	// 종료 조건   if (left == right)    {     maxsum = max(A[left], A[right])     return maxsum    }  	// divide&conquer  	Center = ⌞(left+right)/2⌟   // [1] 왼쪽   maxleftsum = Maxsubsum(A[], left, center)   // [2] 오른쪽   maxrightsum = Maxsubsum(A[], center+1, right)   // [3] 중간   maxleftbordersum = 0   leftbordersum = 0   // 1) left ending을 끝으로 하는 부분 리스트의 최대 부분합   for (i=center; i>=left; i--)    {     leftbordersum += A[i]     maxleftbordersum = max(maxleftbordersum, leftbordersum)    }   // 2) right starting을 시작으로 하는 부분 리스트의 최대 부분합   for (i=center+1; i<=right; i++)    {     rightbordersum += A[i]     maxrightbordersum = max(maxrightbordersum, rightbordersum)    }  	// [1], [2], [3] 가운데 최댓값을 취함  	return (max(maxleftsum, maxrightsum, maxleftbordersum+maxrightbordersum))  } ``` 그럼 이 코드가 어떻게 작동하는지 예제 리스트를 기준으로 설명해보겠습니다. 다음 그림과 같습니다.  <a href="https://imgur.com/Ebfj3HR"><img src="https://i.imgur.com/Ebfj3HR.png" width="500px" title="source: imgur.com" /></a>  우선 예제 리스트를 $A$, left는 0, right는 7로 정의해 Maxsubsum 함수에 넣어 실행합니다. 종료조건(0≠7)을 만족시키지 못했으므로 $A$를 반으로 나눠 Maxsubsum 함수를 다시 호출합니다. 두 개 리스트 가운데 왼쪽 [4, -3, 5, -2] 또한 종료조건(0≠3)을 만족시키지 못했으므로 이를 다시 반으로 나눠 Maxsubsum 함수를 다시 호출합니다. 나눠진 왼쪽 리스트인 [4, -3] 또한 종료조건(0≠1)을 만족시키지 못했으므로 이를 다시 반으로 나눠 Maxsubsum 함수를 다시 호출합니다.  [4]가 되어서야 비로소 종료조건(0=0)을 만족하므로 4를 반환합니다. 마찬가지로 [-3]은 -3이 반환될 겁니다. 이번엔 [4, -3]을 볼 차례입니다. 왼쪽 [4]의 최대 부분합은 4, 오른쪽 [-3]은 -3, 중간 최대 부분합은 1입니다. 이 가운데 최댓값 4가 [4,-3]의 결과로 반환됩니다. 동일한 과정을 거쳐 [5, -2]는 5가 반환됩니다. 이번엔 [4, -3, 5, -2]를 볼 차례입니다. 왼쪽 [4, -3]의 최대 부분합은 4, 오른쪽 [5, -2]는 5, 중간 최대 부분합은 6입니다. 이 가운데 최댓값 6이 [4, -3, 5, -2]의 결과로 반환됩니다. 동일한 과정을 거쳐 [-1, 2, 6, -2]는 8이 반환됩니다. 마지막으로 전체 리스트를 고려할 차례입니다. 왼쪽 [4, -3, 5, -2]의 최댓값은 6, 오른쪽 [-1, 2, 6, 2]는 8이며 중간의 최댓값은 11이므로 전체 최댓값을 11이 됩니다. 접근3의 계산복잡성을 따져보겠습니다. 리스트의 요소 수가 $n$이라 할 때 이를 절반씩 나눠 재귀함수를 다시 호출하고, 중간 결과를 계산할 때 $n$개 요소 전체에 대해 따져보게 되므로 다음과 같은 식이 성립합니다. ($c$는 컴퓨터 파워 등에 영향을 받는 상수값)  $$ \begin{align*} T\left( n \right) &=2T\left( \frac { n }{ 2 } \right) +cn\\ &=2\times \left[ 2T\left( \frac { n }{ { 2 }^{ 2 } } \right) +c\frac { n }{ 2 } \right] +cn\\ &={ 2 }^{ 2 }T\left( \frac { n }{ { 2 }^{ 2 } } \right) +2cn\\ &={ 2 }^{ 3 }T\left( \frac { n }{ { 2 }^{ 3 } } \right) +3cn\\ &=...\\ &={ 2 }^{ i }T\left( \frac { n }{ { 2 }^{ i } } \right) +icn \end{align*} $$  여기에서 $n/2^i$가 1이 될 때까지 반복해야 하므로 로그의 정의에 따라 $i$는 $\log_2n$이 됩니다. 식은 다음과 같이 다시 쓸 수 있습니다.   $$ \begin{align*} T\left( n \right) &={ 2 }^{ \log _{ 2 }{ n } }T\left( 1 \right) +\log _{ 2 }{ n } \times cn\\ &=nT\left( 1 \right) +\log _{ 2 }{ n } \times cn\\ &=O(n)+O(n\log _{ 2 }{ n } )\\ &=O(n\log _{ 2 }{ n } ) \end{align*} $$   ## 접근4 접근4는 부분 합이 음수가 될 경우 그 값은 논리적으로 최대값이 될 수 없다는 점에 착안해 계산량을 확 줄인 방법입니다. 복잡하고 현란한 기법을 쓰는 것보다 문제를 잘 이해하고 정의하는 것이 해결의 첫걸음이라는 교훈을 줍니다. 의사코드는 다음과 같습니다. ```c summax = 0 sum = 0 for i from 0 to n-1 {  sum = sum + a[i]  if sum < 0 then sum = 0  if summax < sum then summax = sum } ``` 접근4의 계산복잡도는 $i$에 대해 반복 횟수가 $n$이고, 1회당 연산은 $O(1)$이므로 전체적으로는 $O(n)$이 됩니다. 
greedy␞ 이번 글에서는 **탐욕 알고리즘(Greedy Algorithm)**을 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept 탐욕 알고리즘이란 매순간 최적이라고 생각되는 것을 선택해 나가는 방식으로 진행하여 최종적인 최적해에 도달하는 기법을 가리킵니다. 탐욕 알고리즘이 잘 작동하는 문제는 *greedy choice property*와 *optimal substructure* 두 가지 속성을 만족합니다. 전자의 경우 앞의 선택이 이후 선택에 영향을 주지 않는다는 걸 의미하고, 후자는 문제 전체에 대한 최적해(*global optimum*)가 부분문제에 대해서도 역시 최적해가 된다는 걸 뜻합니다. 예컨대 `분할가능 배낭문제(Fractional knapsack problem)`가 대표적인 탐욕 알고리즘의 사례에 속합니다. 배낭문제는 한 여행가가 가지고 가는 배낭에 담을 수 있는 무게의 최댓값이 정해져 있고, 일정 가치와 무게가 있는 짐들을 배낭에 넣을 때 가치의 합이 최대가 되도록 짐을 고르는 방법을 찾는 문제인데요. 분할가능 배낭문제는 짐을 쪼갤 수 있는 경우에 해당합니다.  분할가능 배낭문제는 단위 무게당 값어치가 가장 큰 짐을 먼저 넣으면 되는데요. 순간순간의 선택이 이후 선택에 영향을 주지 않고, 순간순간의 최적 선택이 전체 문제 최적해와 일치합니다. 따라서 분할가능 배낭문제는 탐욕 알고리즘으로 풀 수가 있습니다. 반면 짐을 쪼갤 수 없는 배낭문제를 `0-1 배낭문제(0-1 Knapsack Problem)`라고 합니다. 짐을 쪼갤 수 없기 때문에 가능한 모든 조합에 대해 일일이 따져본 후에 가치의 합이 최대가 되도록 하는 조합을 찾는 문제가 되는데, 이 때는 [동적계획법(dynamic programming)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/15/dynamic/)으로 문제를 풀게 됩니다. 다시 말해 모든 경우의 수를 따져보되 중간계산 결과를 저장해 두었다가 이를 다시 써먹는 방식으로 계산량 감소를 유도하는 전략입니다. 이 글에서는 탐욕 알고리즘의 대표 예시인 **Activity-Selection Problem**과 **Huffman Coding**에 대해 살펴보도록 하겠습니다.   ## Activity-Selection Problem 교실할당(classroom assignment)로도 불립니다. 한정된 교실 공간 내에서 최대 수업을 배정하는 문제입니다. 예컨대 9개 수업이 있고, 시작시간 $s$와 종료시간 $f$가 다음과 같이 주어졌다고 칩시다(종료시간 기준으로 오름차순 정렬).  | $i$ | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | 9  | | :---: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | | $s_i$ | 1  | 2  | 4  | 1  | 5  | 8  | 9  | 11 | 13 | | $f_i$ | 3  | 5  | 7  | 8  | 9  | 10 | 11 | 14 | 16 |  종료시간이 가장 빠른 수업을 먼저 배치하게 되면 교실 가용시간은 항상 최대가 됩니다. 종료시간이 빠른 수업부터 차례로 배정하기 때문에 앞의 선택이 이후 선택에 변화를 주지 않고, 매순간 선택이 항상 최적이 됩니다. 이 문제는 탐욕 알고리즘 속성을 만족한다는 이야기이죠.  어쨌든 종료시간을 오름차순으로 정렬해 수업을 배정하면 다음과 같은 그림이 됩니다.   <a href="https://imgur.com/b1XQeRU"><img src="https://i.imgur.com/b1XQeRU.png" width="500px" title="source: imgur.com" /></a>  탐욕 알고리즘을 적용한 결과 한 교실에 배정할 수 있는 최대 수업의 조합은 $a_1, a_3, a_6, a_8$인 걸 확인할 수 있습니다. 물론 $a_2, a_5, a_7, a_8$ 또한 가능합니다만, $a_1$을 기본 결과값으로 포함시킨 앞의 결과보다 더 나은 해라고 할 수는 없습니다.. 이 문제의 계산복잡성은 $O(n)$입니다. 첫번째 수업을 기본 결과값으로 포함시키고, 첫 수업과 나머지 $n-1$개 수업이 겹치는지 여부만 확인하면 되기 때문입니다.   ## Huffman Coding 허프만 코딩이란 탐욕 알고리즘을 사용해서 데이터를 압축하는 기법입니다. 기본 컨셉은 다음과 같습니다. 예컨대 우리가 가진 데이터는 네 가지 문자(A, B, C, D)만 있다고 칩시다. 정석대로 문자 인코딩을 하는 상황이라면 다음과 같이 글자 하나당 2비트가 필요할 겁니다.  | Symbol | Code | | :----: | :--: | |  A  | 00 | |  B  | 01 | |  C  | 10 | |  D  | 11 | 그런데 데이터의 문자별 빈도는 각각 다음과 같다고 칩시다. | Symbol | Frequency | | :----: | :-------: | |  A  |   6   | |  B  |   2   | |  C  |   3   | |  D  |   1   | 위의 경우 전체 데이터를 저장하는 데 총 24비트($6×2+2×2+3×2+1×2$)가 필요합니다. 이제 허프만 코딩을 적용해 빈도가 높은 문자는 적은 비트를 할당한다고 치겠습니다. 다음과 같습니다. | Symbol | Code | | :----: | :--: | |  A  | 0  | |  B  | 110 | |  C  | 10 | |  D  | 111 | 허프만 코딩 적용 결과 전체 데이터를 저장하는 데 총 21비트($6×1+2×3+3×2+1×3$)가 필요합니다. 기존보다 3비트를 줄이는 데 성공했습니다. 압축률은 데이터가 클 수록 좋아질 것입니다. 허프만 코딩 수행 과정은 다음과 같습니다. 예컨대 데이터의 문자별 빈도가 다음과 같다고 치겠습니다. | Symbol | Frequency | | :----: | :-------: | |  A  |  15   | |  B  |   6   | |  C  |   7   | |  D  |  12   | |  E  |  25   | |  F  |   4   | |  G  |   6   | |  H  |   1   | |  I  |  15   | 허프만 코딩을 하려면 다음 그림과 같이 트리를 구축합니다. 우선 가장 빈도가 낮은 H를 말단 왼쪽 노드로 선택합니다. 말단 오른쪽 노드엔 그 다음 적은 F를 놓습니다. 이 둘의 부모노드는 둘의 빈도를 합친 5가 됩니다. 이번엔 이 부모노드(5)를 포함해 가장 작은 값(5)을 왼쪽 노드로 선택합니다. 오른쪽 노드엔 그 다음 적은 B를 놓습니다. 이 둘의 부모노드는 둘의 값을 합친 11이 됩니다. 이번엔 이 부모노드(11)를 포함해 가장 작은 값(G)을 왼쪽 노드로 선택합니다. 오른쪽 노드엔 그 다음 적은 C를 놓습니다. 이 둘의 부모노드는 둘의 값을 합친 13이 됩니다. 이번엔 이 부모노드(13)을 포함해 가장 작은 값(11)를 왼쪽 노드로 선택합니다. 오른쪽 노드엔 그 다음 적은 D를 놓습니다. 이 둘의 부모노드는 둘의 값을 합친 23이 됩니다. 이번엔 이 부모노드(23)을 포함해 가장 작은 값(I)를 왼쪽 노드로 선택합니다. 오른쪽 노드엔 그 다음 적은 23을 놓습니다. 이 둘의 부모노드는 둘의 값을 합친 38이 됩니다. 이번엔 이 부모노드(38)을 포함해 가장 작은 값(E)을 왼쪽 노드로 선택합니다. 오른쪽 노드엔 그 다음 적은 28을 놓습니다. 이 둘의 부모노드는 둘의 값을 합친 53이 됩니다. 이번엔 이 부모노드(53)을 포함해 가장 작은 값(38)을 왼쪽 노드로 선택합니다. 오른쪽 노드엔 그 다음 적은 53을 놓습니다. 이 둘의 부모노드는 둘의 값을 합친 91이 됩니다.  <a href="https://imgur.com/0OyrkkT"><img src="https://i.imgur.com/0OyrkkT.png" width="500px" title="source: imgur.com" /></a>  문자 각각의 코딩 결과는 예컨대 다음과 같습니다. 빈도가 클 수록 그 길이가 짧은 걸 확인할 수 있습니다. - H : 01000 - G : 1100 - E : 10 허프만 코딩의 계산복잡성은 $O(n\log{n})$입니다. 
regression␞ 이번 글에서는 선형회귀 모델의 계수를 추정하는 방법을 살펴보도록 하겠습니다. 이번 글은 고려대 김성범 교수님 강의와 '밑바닥부터 시작하는 데이터과학(조엘 그루스 지음, 인사이트 펴냄)'을 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 선형회귀 **선형회귀(Multiple Linear Regression)**는 수치형 설명변수 X와 연속형 숫자로 이뤄진 종속변수 Y간의 관계를 선형으로 가정하고 이를 가장 잘 표현할 수 있는 회귀계수를 데이터로부터 추정하는 모델입니다. 다음 그림처럼 집 크기와 가격의 관계를 나타내는 직선을 찾는 것이 선형회귀의 목표입니다. <a href="http://imgur.com/lCKBBDV"><img src="http://i.imgur.com/lCKBBDV.png" width="350px" title="source: imgur.com" /></a>  독립변수들로 이뤄진 행렬 $X$와 종속변수 벡터 $Y$가 주어졌을 때 다중선형회귀 모델은 다음과 같이 정의됩니다.  $$ \begin{bmatrix} { y }_{ 1 } \\ { y }_{ 2 } \\ ... \\ { y }_{ n } \end{bmatrix}=\begin{bmatrix} 1 & x_{ 11 } & ... & { x }_{ 1k } \\ 1 & { x }_{ 21 } & ... & { x }_{ 2k } \\ ... & ... & & ... \\ 1 & { x }_{ n1 } & ... & { x }_{ nk } \end{bmatrix}\begin{bmatrix} { \beta }_{ 0 } \\ { \beta }_{ 1 } \\ ... \\ { \beta }_{ k } \end{bmatrix}+\begin{bmatrix} { \varepsilon }_{ 1 } \\ { \varepsilon }_{ 2 } \\ ... \\ { \varepsilon }_{ n } \end{bmatrix}\\ \\ \overrightarrow { y } =X\overrightarrow { \beta } +\overrightarrow { \varepsilon } ,\quad \overrightarrow { \varepsilon } \sim N(E(\overrightarrow { \varepsilon } ),V(\overrightarrow { \varepsilon } ))\\ \\ E(\overrightarrow { \varepsilon } )=\begin{bmatrix} 0 \\ 0 \\ ... \\ 0 \end{bmatrix},\quad V(\overrightarrow { \varepsilon } )={ \sigma }^{ 2 }I $$  ## Direct Solution 선형회귀의 계수들은 실제값과 모델 예측값의 차이, 즉 **오차제곱합(error sum of squares)**을 최소로 하는 값들입니다. 이를 만족하는 최적의 계수들은 회귀계수에 대해 미분한 식을 0으로 놓고 풀면 아래와 같이 **명시적인 해**를 구할 수 있습니다. 다시 말해 우리에게 주어진 $X$, $Y$ 데이터만 가지고 계수를 단번에 추정할 수 있다는 이야기입니다.  $$ \overrightarrow { \beta } ={ \left( { X }^{ T }X \right) }^{ -1 }{ X }^{ T }\overrightarrow { y } $$   ## 분석 대상 데이터 분석 대상 데이터는 '밑바닥부터 시작하는 데이터 과학'에서 제시된 예시데이터입니다. $X$는 친구수, 근무시간, 박사학위 취득여부이고, $Y$는 사용자가 웹사이트에서 보내는 시간(분)에 해당합니다. $X$ 가운데 친구 수 변수 하나만 떼어 $Y$와의 관계를 2차원으로 도시하면 아래 그림과 같습니다.  <a href="http://imgur.com/ZhMINpC"><img src="http://i.imgur.com/ZhMINpC.png" width="400px" title="source: imgur.com" /></a> 다음은 데이터입니다. $X$는 네 개 요소로 구성돼 있는데 각각 상수항, 친구수, 근무시간, 박사학위 취득 여부에 해당합니다. ```python # [1(beta_0), 친구수, 근무시간, 박사학위 취득 여부] input = [[1,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]] # 사이트에서 보내는 시간(분) output = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84] ``` $i$번째 데이터 포인트에 대한 회귀식은 다음과 같습니다. 우리는 여기에서 회귀계수로 이뤄진 벡터 $β$를 추정해야 합니다.  $$ { y }_{ i }=\beta { x }_{ i } $$  $(X^TX)^{-1}X^Ty$를 계산해 데이터로부터 명시적인 해를 구한 결과 $β$는 [30.63, 0.97, -1.87, 0.91]로 추정되었습니다.   ## Numerical Search 경사하강법 같은 반복적인 방식으로 선형회귀 계수를 구할 수도 있습니다. 경사하강법이란 어떤 함수값을 최소화하기 위해 임의의 시작점을 잡은 후 해당 지점에서의 그래디언트(경사)를 구하고, 그래디언트의 반대 방향으로 조금씩 이동하는 과정을 여러번 반복하는 것입니다. 예컨대 아래 그림([출처](http://neuralnetworksanddeeplearning.com/chap1.html))과 같습니다. <a href="http://imgur.com/hs1AlFR"><img src="http://i.imgur.com/hs1AlFR.png" width="400px" title="source: imgur.com" /></a> 이 글에서는 경사하강법 가운데 **Stochastic Gradient Descent(SGD)** 기법을 쓰겠습니다. SGD는 반복문을 돌 때마다 **개별 데이터 포인트에 대한 그래디언트를 계산**하고 이 그래디언트의 반대 방향으로 파라메터를 업데이트해 함수의 최소값을 구하는 기법입니다. SGD 관련 메인 코드는 다음과 같습니다. 코드에서 'value'는 우리가 최소화하고 싶은 값으로 선형회귀 모델에서는 오차제곱합을 가리킵니다. 'target_fn'은 목적함수로 오차제곱합을 아웃풋으로 산출하는 함수를 의미합니다. 'theta'는 해당 목적함수의 파라메터인데요, 우리 문제에선 $α$와 $β$를 말합니다. 'gradient_fn'은 각 파라메터에 대한 목적함수의 그래디언트를 가리킵니다. ```python def minimize_stochastic(target_fn, gradient_fn, x, y, theta_0, alpha_0=0.01):   # SGD 방식으로 gradient descent   # minimize_batch보다 훨씬 빠르다   data = zip(x, y)   # theta_0를 초기 theta로   theta = theta_0   # alpha_0를 초기 이동거리(step_size)로   alpha = alpha_0   # 시작할 때의 최소값   min_theta, min_value = None, float("inf")   iterations_with_no_improvement = 0   # 만약 100번 넘게 반복하는 동안 value가 더 작아지지 않으면 멈춤   while iterations_with_no_improvement < 100:     value = sum( target_fn(x_i, y_i, theta) for x_i, y_i in data )     # 새로운 최솟값을 찾았다면     if value < min_value:       # 이 값을 저장       min_theta, min_value = theta, value       # 100번 카운트도 초기화       iterations_with_no_improvement = 0       # 기본 이동거리로 돌아감       alpha = alpha_0     # 만약 최솟값이 줄어들지 않는다면     else:       # 이동거리 축소       alpha *= 0.9       # 100번 카운트에 1을 더함       iterations_with_no_improvement += 1 		     # 반복문이 돌 때마다 in_random_order를 호출하기 때문에     # 매 iter마다 그래디언트를 계산하는 순서가 달라짐     for x_i, y_i in in_random_order(data):       # 각 데이터 포인트에 대해 그래디언트를 계산       gradient_i = gradient_fn(x_i, y_i, theta)       # 기존 theta에서, 학습률(alpha)과 그래디언트를 뺀 것을 업데이트       theta = vector_subtract(theta, scalar_multiply(alpha, gradient_i))   return min_theta ``` 그러면 이제는 value와 target_fn, gradient_fn, theta를 정의해야 합니다. 우선 우리가 구해야 하는 파라메터는 입력변수 개수($k$=3)+상수항(1) 길이를 가진 벡터 $β$이므로 beta는 4차원 벡터로 선언했습니다. ```python import random random.seed(10) # 추정 대상 beta (vector) # beta = [beta_0, beta_1, ..., beta_k] beta = [random.random() for x_i in input[0]] ``` 우리가 최소화하고자 하는 값(value)은 오차제곱합입니다. $i$번째 데이터 포인트에 대한 오차제곱(Squared Error)은 다음과 같은 식으로 나타낼 수 있습니다.  $$ {SE}_{i}={ \left\{ { y }_{ i }-\left( \beta { x }_{ i }\right) \right\} }^{ 2 } $$  이를 'squared_error' 함수로 표현할 수 있습니다. ```python def squared_error(x_i, y_i, beta):   return error(beta, x_i, y_i) ** 2 def error(beta, x_i, y_i):   # 실제값 y_i와 예측값 사이의 편차   return y_i - predict(beta, x_i) def dot(v, w):   """v_1 * w_1 + ... + v_n * w_n"""   return sum(v_i * w_i for v_i, w_i in zip(v, w)) def predict(beta, x_i):   # 현재 회귀계수들을 가지고 예측   # 예측값 = x_i와 beta의 선형결합   # x_i = [1(beta_0), x_i1, x_i2, ..., x_ik]   # beta = [beta_0, beta_1, ..., beta_k]   return dot(x_i, beta) ``` gradient_fn은 다음과 같습니다. 목적함수인 'squared_error'를 'theta'로 미분한 값입니다. 이를 식으로 정리하면 다음과 같습니다.  $$ \frac { \partial { SE }_{ i } }{ \partial \alpha } =-2\left\{ { y }_{ i }-\left( \beta { x }_{ i }+\alpha \right) \right\} \\ \frac { \partial { SE }_{ i } }{ \partial \beta } =-2\left\{ { y }_{ i }-\left( \beta { x }_{ i }+\alpha \right) \right\} { x }_{ i } $$  이를 코드로 나타내면 다음과 같습니다. ```python def squared_error_gradient(x_i, y_i, beta):   # i번째 오류제곱 값의 beta에 대한 편미분값   return [-2 * x_ij * error(beta, x_i, y_i) for x_ij in x_i] ``` 이밖에 'minimize_stochastic' 구동에 필요한 함수도 정의하겠습니다. ```python def in_random_order(data):   # Stochastic Gradient Descent 수행을 위한 함수로,   # 한번 반복문을 돌 때마다 임의의 순서로 데이터 포인트를 반환   # 데이터 포인트의 인덱스를 list로 생성   indexes = [i for i, _ in enumerate(data)]   # 이 인덱스를 랜덤하게 섞는다   random.shuffle(indexes)   # 이 순서대로 데이터를 반환한다   for i in indexes:     yield data[i] def vector_subtract(v, w):   """subtracts two vectors componentwise"""   return [v_i - w_i for v_i, w_i in zip(v,w)] def scalar_multiply(c, v):   return [c * v_i for v_i in v] ``` 마지막으로 코드 전체를 구동하는 명령문은 다음과 같습니다. ```python beta = minimize_stochastic(target_fn=squared_error,              gradient_fn=squared_error_gradient,              x=input,              y=output,              theta_0=beta,              alpha_0=0.0001) ``` SGD 기법으로 해를 구한 결과 $β$는 [30.55184071133236, 0.973395629801253, -1.8632386392995979, 0.9471533590851985]로 추정되었습니다. 이는 명시적 해와 유사합니다.  ## 회귀계수를 얼마나 신뢰할 수 있나 데이터로부터 추정한 회귀계수는 진짜 회귀계수라고 할 수는 없습니다. 어디까지나 일부 데이터를 가지고 도출된 계수일 뿐더러 데이터에 노이즈가 끼어있을 수도 있기 때문이죠. 선형회귀 모델의 $j$번째 독립변수에 대한 추정 회귀계수 $β_j$를 추정 회귀계수의 표준편차 $σ_j$로 나눈 값($t_j$)은 $n-k$의 자유도를 지닌 $t$분포를 따른다는 사실이 알려져 있습니다. 그렇다면 회귀계수의 표준편차는 어떻게 구할까요? 이 때 쓰는 것이 **bootstap**입니다. 기존 데이터에서 중복을 허용된 재추출을 통해 새로운 데이터를 만들어내는 방법입니다. 우리가 갖고 있는 학습데이터에 bootstrap을 적용하여 여러 새로운 데이터를 생성하고, 이들 각각으로부터 추정 회귀계수를 도출할 수 있습니다.  예를 들어 특정 독립변수에 해당하는 회귀계수가 부트스트랩 데이터마다 크게 달라지지 않는다면 해당 회귀계수는 상당히 신뢰할 수 있을 겁니다. 반대로 계수가 크게 변한다면 추정된 계수는 신뢰할 수 없을 겁니다.  부트스트랩 데이터 개수만큼 회귀계수 추정값을 구하여 회귀계수의 표준편차 $σ_j$를 구한 뒤 이를 원래 데이터에서 구한 추정회귀 계수 $β_j$에 나눠줘 $t_j$를 계산합니다. 이 $t_j$가 $t$분포 상에서 어느 위치에 해당하는지를 따져서 진짜 회귀계수가 속해 있을 수 있는 신뢰구간을 구할 수 있게 됩니다. 부트스트랩 데이터 각각에 대해 회귀계수를 먼저 구해보겠습니다. 우선 데이터로부터 회귀계수를 추정하는 함수를 만들었습니다. ```python def estimate_beta(x, y):   # 추정 대상 beta (vector)   beta = [random.random() for _ in x[0]]   return minimize_stochastic(target_fn=squared_error,              gradient_fn=squared_error_gradient,                x=x,                y=y,                theta_0=beta,                alpha_0=0.0001) ``` 이제는 부트스트랩 함수를 만들 차례입니다. ```python def bootstrap_sample(data):   # 데이터 개수만큼 data로부터 무작위 재추출 (중복 허용)   return [random.choice(data) for _ in data] def bootstrap_statistic(data, stats_fn, num_samples):   # num_sample개의 bootstrap 샘플에 대해 stats_fn을 적용   return [stats_fn(bootstrap_sample(data))       for _ in range(num_samples)] def estimate_sample_beta(sample):   # sample은 (x_i, y_i)로 구성된 리스트   x_sample, y_sample = zip(*sample)   return estimate_beta(x_sample, y_sample) ``` 이제 함수를 실행해 봅시다.  ```python bootstrap_betas = bootstrap_statistic(zip(input, output),                    estimate_sample_beta,                    100) ``` 함수를 실행하면 100개의 부트스트랩 데이터에 대해 추정된 회귀계수의 쌍이 100개가 도출됩니다. 다음과 같습니다. ``` [[30.343293717263954, 0.955828442766452, -1.8249710660990814, 0.19262090720112343], [31.653090581087664, 0.8930047770677926, -1.8274769383940832, 0.003915653745906352], [30.062130836429326, 0.9735595051657044, -1.7409587831575586, -0.00993645069080973], [30.459536927917853, 0.9275688208209533, -1.970156796143431, 1.4162870885210503], [29.965245738566743, 0.9987255912413002, -1.8469983707870146, 1.2570210865880311], [30.688436939427994, 0.949721374789511, -1.791565743167013, 0.8490708882537681], [27.389069317384713, 1.1899927371032066, -1.6395966566222984, 2.201209799844561], [31.578900415746247, 0.963470036264341, -2.061237515990318, 0.6044582651703277], [29.9969538479282, 1.0563305743635187, -2.0370138317358597, 1.395128459047288], [30.71129774327976, 0.9412707718288738, -1.9049341856989015, 0.9975476331019565], [28.95704337705777, 1.0372235777797778, -1.7374326711464978, 2.017330974451086], [29.347442580389554, 0.9691244573476897, -1.6980453130961777, 1.758299750670592], [30.89303821117151, 0.9643400467987878, -2.0014985101424188, 0.9437323561405635], [31.033963018013235, 0.944512876776604, -1.8339869584884239, 1.3762002169288328], [29.7724071122711, 0.9637788276539256, -1.8712203112136903, 2.31343127588546], [30.712161312804817, 0.9787589052763698, -1.9637325222425992, 1.1877691857117059], [28.882828505113785, 1.0615985715436485, -1.8322410460473135, 2.282737207651317], [31.164357855104715, 0.9313158660935656, -1.9362632274947122, 1.190519238545326], [31.02991081861022, 0.9646849000104669, -2.048540894739888, 1.4641504377576209], [31.270216131821417, 0.9412983344101367, -1.9754923012624737, 0.9244505522676154], [28.972811257580727, 1.0626659243331988, -1.8172782368438227, 1.9772010790265988], [32.47326463848947, 0.9446160353528085, -1.8827511459492636, -0.555442587406212], [31.92477575189198, 0.9076629023019004, -1.833715795651844, 0.2543582162753717], [30.73653173338487, 0.9798526580610298, -1.8368633847870894, 1.3991627628282644], [31.052387396870795, 0.9465884318410379, -1.937853405314178, 1.6167719138597119], [30.838191991050294, 0.9547770115578801, -1.9540199662139435, 1.1143266882659546], [30.989458366759308, 0.9112712446387848, -1.8275575068998577, 1.1518607341417386], [31.499881551689803, 0.984790498881108, -2.017772833184302, 0.6959781050813002], [30.6294509899701, 0.9532711074826222, -1.9002085912683446, 0.41904632258007973], [31.871492871773135, 0.9640564217099683, -2.0592781960142137, -0.1325017160959066], [30.979163018183787, 0.9442339015956216, -1.9852723070949032, 1.018733620546921], [30.94960897962424, 0.9917550347995638, -1.879826427606344, -0.9344395120511418], [29.974194993513784, 0.9372566526240828, -1.6983466191579584, 1.413895309854322], [30.48871554272555, 0.9274603561875837, -1.6730463683580687, 0.7292989104575046], [29.976667988625856, 0.9711827384011987, -1.839308476190981, 1.9172708899219006], [30.692522310161685, 0.951972668383523, -1.7681190534968108, 0.4691416207459495], [28.288129698240517, 1.0948205153184756, -1.8171117444664553, 3.3038823592912854], [29.822963056351064, 1.0327653743440959, -1.869836637120832, 1.5486447223042832], [30.386808122240165, 0.9779154202444837, -1.8976774910373846, 2.1086881935517914], [30.741619085348518, 0.9217376178433008, -1.7198893947497884, -0.34894837617535585], [29.12768874650376, 1.0267526931238684, -1.7647591340646893, 1.6875260877074156], [30.24960760356648, 1.0121231682791874, -1.7376567600056418, 0.296763706300862], [31.035301020344654, 0.9431366335375586, -1.953384748218975, 1.1579872338326034], [30.5768817821496, 0.947021358453022, -1.7205109807167238, 0.783267985369746], [29.374898109259238, 1.0939268639920088, -1.6424719680107713, 1.140410049137131], [29.40635067130438, 1.0637366346977501, -1.874508187809908, 2.4511133687480937], [30.95063057843148, 0.936325594647627, -1.7737167596585748, 1.0343706367628467], [31.678274244399336, 0.9227541184400466, -1.9918345207726629, 0.5086225151581116], [29.98166257475079, 0.9605170287193446, -1.7577319419624025, 0.5120422638922413], [31.323616890901306, 0.8176945107731992, -1.6500326316218685, -0.8683616760822116], [30.302149825423008, 0.9737686518258278, -1.8128215160225314, 0.7033976674704967], [31.386502073193892, 0.882658769388189, -1.6825286945756024, -0.44420246297894167], [30.323858845499185, 1.0757705725166067, -2.071948018422145, 2.2968801639230105], [30.494825872775092, 1.0108387224084352, -1.9188457540102233, 0.8717781457244161], [30.576615201544183, 0.9120017225776094, -1.7251677135358494, 1.7832767592542957], [28.492384747280074, 1.1059593661729585, -1.7735172156402836, 2.663999434050509], [30.104972970041402, 1.0840732600063667, -1.9613608117473043, 1.5315485478845854], [31.757239201637674, 0.9596734272864389, -2.051685205450117, -0.2098820060083817], [29.854863672046072, 1.0209262822106175, -1.9439212461621536, 1.5185447249181654], [29.41528261809298, 1.1023172226932805, -1.891600842305552, 2.2231352104855175], [29.11300285931626, 1.0343057536723956, -1.7718637081275448, 1.6750740838338922], [29.39039719035395, 0.9297526750567007, -1.7896140395445401, 1.940908892848941], [27.962469288747435, 1.1422689401264716, -1.8893543588108115, 3.388049453882638], [29.099157058356646, 1.1348583693290986, -1.8317976244428604, 1.663037801381304], [29.137612379810427, 1.1300566948876725, -1.7913898643267325, 1.6482641446500326], [31.130222918185655, 0.9030219758748801, -1.9131692904927817, 1.474759950650903], [30.58125248343542, 0.9223235418040419, -1.6101280249243748, 1.0127434495055474], [30.891973319804126, 0.9193557426060519, -1.8375241356871626, 0.08461128745246431], [31.14771990918551, 0.9553305770320748, -1.878558304343514, 0.9002047428943074], [31.27678282839363, 0.9335965433539816, -1.9467073427528274, 0.9226402524279342], [29.56185170659549, 1.077105492914354, -1.8241298785196545, 1.595589221533047], [28.076434296423237, 1.0481641153277417, -1.6920455897818678, 1.8737381674617253], [28.90380434686726, 1.0604153971116186, -1.7365915272861396, 2.026884447765734], [29.99741704319044, 1.0666687600651432, -1.9111028667834695, 1.2256669988576885], [29.43736242616701, 1.0472064322799974, -1.8063134614295004, 1.9580133762596552], [29.227650225513607, 1.0144255050958706, -1.8016989061013566, 1.7520195371651819], [29.243279432899033, 0.9968822418447205, -1.778030031899557, 0.5551593556261414], [31.46888932259628, 0.9105043256707787, -1.7449900371478968, -0.7085272038815223], [29.924868298448885, 1.0239101298478512, -1.8708758584829717, 0.959971954552992], [30.88467060799466, 0.9380489354101933, -1.8289315911516493, 0.36156696066090643], [31.757648253366902, 0.96456365074318, -2.12281082826505, 0.4933404740397043], [30.359636241287728, 0.9930935207021235, -1.91614726756068, 0.11981014378409671], [29.689503027235425, 1.0275941570260614, -1.8684278630889204, 1.695936319407561], [30.675188326985708, 1.045569865938166, -1.9146598992756043, 1.0011598992584545], [30.43186544380135, 1.0040689827077782, -2.0168868872700227, 1.3592129670325508], [31.56317410958609, 0.9256366346831482, -1.8198369687354612, 0.37814324357003987], [32.0724948565735, 0.9134883775996528, -1.9211327000011957, -1.1653914277078095], [29.24454398282765, 0.9972606107989663, -1.7192410689836413, 1.0773787739745337], [29.565133763140803, 0.969925575012797, -1.6784388902600302, 1.16934425282509], [30.521873388440795, 0.9659927881039246, -1.81299769918763, 0.9066914988998109], [31.304315710353873, 0.9388059361772737, -1.7375886505932063, 0.22777427755049626], [30.485899853898623, 0.9831955516685744, -1.8216915684007813, 1.4665292532815406], [30.586128743092342, 0.954830980894403, -1.9606989544282951, 2.7599642168405083], [30.331607238578425, 0.9800674077114176, -1.9621069206081838, 2.229119033504103], [31.372326222839966, 1.0047554827884049, -2.0193398364534048, 0.9477139083724562], [30.231048927885226, 1.0141246515657603, -1.8918513233859755, 0.1924866352716917], [30.263326574321635, 0.9311507918160458, -1.9097048979881397, 2.9233469946337465], [31.515503088339216, 0.9178784037775057, -1.998991069549314, 1.2935446029780655], [30.03038991481507, 1.035274803835536, -2.028483027984759, 2.544621079119659], [31.070081646523697, 0.927782273878715, -1.9091320174841293, 0.15186481410364247]] ``` 우리는 이로부터 회귀계수 각각의 표준편차를 구할 수 있습니다. SGD 기법으로 해를 구한 결과 $β$는 [30.55184071133236, 0.973395629801253, -1.8632386392995979, 0.9471533590851985]로 추정됐다는 사실로부터 $t_j$ 또한 구할 수 있습니다. 이로부터 SGD로 구한 $β$가 얼마나 믿을 만한지 추론해낼 수 있습니다.  ## 정규화 **Regulization**은 회귀계수에 제약을 가해 일반화 성능을 높이는 기법입니다. 정규화와 관련해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/22/RLR/)을 참고하시면 좋을 것 같습니다. 이 가운데 $β$의 L2 norm을 제한하는 릿지 회귀를 살펴보겠습니다. 파이썬 코드는 다음과 같습니다. ```python def ridge_penalty(beta, alpha):   # alpha는 페널티의 강도를 조절하는 하이퍼 파라메터   # ridge회귀는 상수에 대한 패널티는 주지 않는다   return alpha * dot(beta[1:], beta[1:]) def squared_error_ridge(x_i, y_i, beta, alpha):   # beta를 사용할 때 오류와 페널티의 합을 반환   return error(beta, x_i, y_i) ** 2 + 			ridge_penalty(beta, alpha) def ridge_penalty_gradient(beta, alpha):   # ridge회귀는 상수에 대한 패널티는 주지 않는다   return [0] + [2 * alpha * beta_j for beta_j in beta[1:]] def vector_add(v, w):   """adds two vectors componentwise"""   return [v_i + w_i for v_i, w_i in zip(v,w)] def squared_error_ridge_gradient(x_i, y_i, beta, alpha):   # i번째 오류 제곱값과 패널티 합의 기울기   return vector_add(squared_error_gradient(x_i, y_i, beta),            ridge_penalty_gradient(beta, alpha)) def estimate_beta_ridge(x, y, alpha):   # 페널티 파라메터가 alpha인 ridge 회귀를 SGD로 학습   from functools import partial   beta_initial = [random.random() for _ in x[0]]   return minimize_stochastic(partial(squared_error_ridge,                     alpha=alpha),                partial(squared_error_ridge_gradient,                     alpha=alpha),                x, y,                beta_initial,                0.001) ``` alpha=0으로 실행하면 기존 선형회귀와 동일한 결과가 나옵니다. alpha를 증가시킬 수록 $β$가 작아집니다.  ```python random.seed(0) beta_0 = estimate_beta_ridge(input, output, alpha=0.0) beta_10 = estimate_beta_ridge(input, output, alpha=10.0) ``` alpha=10으로 실행하면 $β$는 [28.30817306438882, 0.7309844552226781, -0.9146285684215772, -0.01693934899423252]으로 추정되는데요. 0에 가까운 네번째 회귀계수에 해당하는 변수는 '박사학위 취득 여부'입니다. 다시 말해 박사학위 취득 여부는 사이트 이용시간에 큰 영향을 주는 변수가 아니라는 걸 알 수 있습니다.
Topological␞ 이번 글에서는 [그래프(Graph)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/)라는 자료구조를 활용한 정렬 알고리즘 가운데 하나인 **Topological sort** 기법을 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님과 역시 같은 대학의 김선욱 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept `Topogical Sort`란 **Directed Acyclic Graph**(방향을 가지면서 [사이클](https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/)이 없는 그래프)를 활용해 노드들 사이에 선후관계를 중심으로 정렬하는 알고리즘입니다. 이때 사용되는 기법이 [깊이우선탐색(DFS)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/20/DFS/)입니다. 옷입기 예시를 보겠습니다. 우선 아래 그래프를 깊이우선탐색으로 모든 노드를 탐색하고, 노드들에 방문시점/방문종료시점을 기록해 둡니다.  <a href="https://imgur.com/WMmHq96"><img src="https://i.imgur.com/WMmHq96.png" width="500px" title="source: imgur.com" /></a>  이후 방문종료시점의 내림차순으로 정렬합니다.  <a href="https://imgur.com/21g4yY5"><img src="https://i.imgur.com/21g4yY5.png" title="source: imgur.com" /></a>  `Topological Sort`의 계산복잡성은 깊이우선탐색에 비례합니다. 따라서 $O($\|$V$\|$+$\|$E$\|$)$가 됩니다.   ## DAG 최단거리 `Topological Sort`와 *[edge relaxation](https://ratsgo.github.io/data%20structure&algorithm/2017/11/25/shortestpath/)* 기법을 활용해 **Directed Acyclic Graph(DAG)**의 최단거리를 구할 수 있습니다. 그 과정은 다음과 같습니다. - 주어진 DAG에 대해 `Topological Sort`를 수행한다. - 시작노드를 0, 나머지의 거리를 무한대로 초기화한다. - 각 노드별 모든 엣지에 대해 *edge relaxation*을 수행한다.  <a href="https://imgur.com/Vh4U9rD"><img src="https://i.imgur.com/Vh4U9rD.png" title="source: imgur.com" /></a> 
SVM2␞ 이번 글에서는 서포트 벡터 머신(SVM)의 변형인 **C-SVM**에 대해 살펴보도록 하겠습니다. 이 글 역시 고려대 강필성 교수님과 역시 같은 대학의 김성범 교수님 강의를 정리했음을 먼저 밝힙니다. SVM의 일반적인 내용에 대해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/)을 참고하시기 바랍니다. 그럼 시작하겠습니다.   ## C-SVM의 목적의식 SVM은 두 범주를 잘 분류하면서 **마진(margin)**이 최대화된 **초평면(hyperplane)**을 찾는 기법입니다. 기본적으로 선형분류를 한다는 것이죠. 하지만 아래 그림처럼 어떤 직선을 그어도 두 범주를 완벽하게 분류하기 어려운 경우도 많습니다. <a href="http://imgur.com/5OVa7IM"><img src="http://i.imgur.com/5OVa7IM.png" width="350px" title="source: imgur.com" /></a> 이 경우에는 두 가지 해결 방법이 있습니다. minus-plane과 plus-plane 사이(즉 마진) 안에 관측치가 존재할 수 있도록 제약을 완화하는 방안이 첫번째입니다. 두번째로는 분류 경계면을 아예 구불구불한 비선형 모양으로 만드는 겁니다. 전자가 C-SVM, 후자가 **Kernel-SVM** 기법의 핵심 아이디어입니다. Kernel-SVM 기법에 대해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/30/SVM3/)을 참고하시면 좋을 것 같습니다.   ## C-SVM 개요 기존 SVM은 마진 안에 관측치가 들어올 수 없습니다(hard-margin). 마진 폭이 줄어드는 걸 감수하고서라도 그런 관측치가 없도록 마진을 설정하기 때문이죠. 그런데 C-SVM은 마진 안에 관측치의 존재를 허용합니다. 이를 **Soft-margin**이라고 합니다. 아래 그림을 보겠습니다.  <a href="http://imgur.com/vlG124W"><img src="http://i.imgur.com/vlG124W.png" width="400px" title="source: imgur.com" /></a>  위 그림에서 minus-plane을 벗어난 빨간점과 plus-plane을 벗어난 파란점이 눈에 띕니다. 마진을 최대화하되 이런 관측치들을 허용하는 게 바로 C-SVM입니다. 다만 plus/minus-plane을 벗어난 $ξ$ 만큼 panelty를 부과합니다. 우리가 찾아야할 C-SVM의 초평면을 $w^Tx+b$라고 할 때 C-SVM의 목적식은 다음과 같습니다. ($n$=관측치 개수)   $$ \min { \frac { 1 }{ 2 } { \left\| w \right\| }_{ 2 }^{ 2 } } +C\sum _{ i=1 }^{ n }{ { \xi }_{ i } } $$  위 목적식에서 $C$는 사용자가 설정하는 **하이퍼파라메터(hyperparameter)**입니다. $C$가 커질수록 마진 폭이 줄어듭니다. 이 기법이 C-SVM으로 불리는 이유입니다. $C$의 크기에 따른 효과는 이후 자세히 살펴보겠습니다.  C-SVM의 제약식은 다음과 같습니다. ($i=1,2,...,n$)  $$ { y }_{ i }({ w }^{ T }{ x }_{ i }+b)\ge 1-{ \xi }_{ i },\quad { \xi }_{ i }\ge 0 $$  제약식의 의미는 이렇습니다. 원 SVM의 제약식은 $y_i(w^Tx_i+b)≥1$이었습니다. 마진 폭이 $ξ_i$만큼 줄어들 수 있기 때문에 이를 반영한 것입니다. $ξ_i$가 음수라면 plus/minus-plane을 벗어나지 않은 경우이므로 고려할 필요가 없습니다.  ## 해 구하기 제약식에 라그랑지안 승수를 곱해 목적식에 합쳐 라그랑지안 Primal 문제로 바꾸면 다음과 같습니다.  $$ { \min { L_{ p }(w,b,{ { \xi }_{ i },\alpha }_{ i },{ \mu }_{ i }) } }=\frac { 1 }{ 2 } { \left\| w \right\| }_{ 2 }^{ 2 }+C\sum _{ i=1 }^{ n }{ { \xi }_{ i } } -\sum _{ i=1 }^{ n }{ { \alpha }_{ i }({ y }_{ i }({ w }^{ T }{ x }_{ i }+b)-1) } -\sum _{ i=1 }^{ n }{ { { \mu }_{ i }\xi }_{ i } } $$  원 문제의 제약식의 범위가 0 이상이므로 $L_p$의 제약은 다음과 같습니다.  $$ { \alpha }_{ i }\ge 0,\quad{ \mu }_{ i }\ge 0,\quad i=1,...,n $$  KKT 조건에서는 $L_p$를 미지수로 각각 편미분한 식이 0이 되는 지점에서 $L_p$가 최소값을 갖습니다. 다음과 같습니다.  $$ \begin{align*} \frac { \partial L_{p} }{ \partial w } =0\quad &\rightarrow \quad w=\sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i }{ x }_{ i } } \\ \frac { \partial L_{p} }{ \partial b } =0\quad &\rightarrow \quad \sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i } } =0\\\frac { \partial L_{ p } }{ \partial { \xi }_{ i } } =0\quad &\rightarrow \quad C-{ \alpha }_{ i }-{ \mu }_{ i }=0 \end{align*} $$  위 식을 $L$에 넣어 정리하면 라그랑지안 Primal 문제가 Dual 문제로 바뀝니다. $a_i$에 관한 문제로 단순해졌고, 미지수 최고차항 계수가 음수여서 최대화 문제로 바뀌었습니다. 이는 기존 SVM의 Dual 식과도 일치합니다.  $$ \max { { L }_{ D }({ \alpha }_{ i }) } =\sum _{ i=1 }^{ n }{ { \alpha }_{ i } } -\frac { 1 }{ 2 } \sum _{ i=1 }^{ n }{ \sum _{ j=1 }^{ n }{ { \alpha }_{ i }{ { \alpha }_{ j }y }_{ i }{ y }_{ j }{ x }_{ i }^{ T }{ x }_{ j } } } $$  KKT 조건에 의해 $L_D$의 제약식은 다음과 같습니다.  $$ \sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i } } =0 \\0\le { \alpha }_{ i }\le C,\quad i=1,...,n $$  위 제약식에서 $0≤α_i≤C$가 도출된 배경은 이렇습니다. $L_p$ 제약에 의해 $α_i$, $μ_i$는 모두 0 이상의 값을 가져야 합니다. 여기에서 KKT 조건에 의해 $L_p$를 $ξ_i$로 미분한 식을 0으로 두고 풀어서 나온 $C-α_i-μ_i=0$을 생각해 봅시다. 그렇다면 $α_i$는 아무리 커도 $C$ 이상의 값을 가질 수 없습니다.   ## C-SVM의 서포트 벡터 우리가 찾고자 한 답은 마진이 최대화된 분류경계면 $w^Tx+b$입니다. $w$와 $b$를 찾으면 SVM의 해를 구할 수 있게 됩니다. KKT 조건을 탐색하는 과정에서 $w$는 다음과 같이 도출됐습니다.  $$ w=\sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i }{ x }_{ i } } $$ $x_i$와 $y_i$는 우리가 가지고 있는 학습데이터이므로 라그랑지안 승수인 $α_i$값들만 알면 $w$를 찾을 수 있습니다. 그런데 여기에서 $α_i$가 0인 관측치들은 분류경계면 형성에 아무런 영향을 끼치지 못하는 non-support vector들입니다. KKT 조건에 의해 $L_D$가 최대값을 갖는다면 아래 두 개 가운데 하나는 반드시 0입니다. > (1) $α_i$ > > (2) $y_i(w^Tx_i+b-1)$ 아울러 아래 두 개 가운데 하나도 반드시 0입니다. > (1) $μ_i$ > > (2) $ξ_i$ $α_i$는 다음의 범위를 갖습니다.  $$ 0\le { \alpha }_{ i }\le C $$  $α_i$가 0보다 크고 $C$보다 작다면 $y_i(w^Tx_i+b-1)$는 0입니다. 따라서 이 조건을 만족하는 관측치들은 마진 위에 있는 support vector들이 됩니다. $α_i$가 $C$라면 $μ_i$는 0입니다. $C-α_i-μ_i=0$가 성립해야 하기 때문입니다. 그러면 $ξ_i$는 0보다 큰 값을 갖습니다. 따라서 이 조건을 만족하는 관측치들은 plus-plane과 minus-plane 사이에 있는, 즉 마진 안에 있는 support vector들이 됩니다.   ## C의 효과 하이퍼파라메터 $C$는 마진 폭을 줄이거나 넓히는 역할을 합니다. $C$가 크면 라그랑지안 문제에서 $ξ_i$의 역할이 커지고, 그만큼 마진 폭이 줄어듭니다. 그 효과를 나타낸 그림은 아래와 같습니다. <a href="http://imgur.com/o8lVZS9"><img src="http://i.imgur.com/o8lVZS9.png" width="400px" title="source: imgur.com" /></a> 
normal␞ 이번 글에서는 **정규분포(Normal Distribution)**과 **중심극한정리(Central Limit Theorem)**을 간단한 파이썬 코드 중심으로 살펴보도록 하겠습니다. 이 글은 '밑바닥부터 시작하는 데이터과학(조엘 그루스, 인사이트 펴냄)'과 '일반통계학(김우철 외, 영지문화사)' 두 책과 고려대 한성원 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 정규분포 정규분포는 가우스(Gauss, 1777-1855)에 의해 제시된 분포로서 일명 가우스분포(Gauss Distribution)라고 불리며 물리학 실험 등에서 오차에 대한 확률분포를 연구하는 과정에서 발견되었다고 합니다. 가우스 이후 이 분포는 여러 학문 분야에서 이용되었으며, 초기의 통계학자들은 모든 자료의 히스토그램이 정규분포의 형태와 유사하지 않으면 비정상적인 자료라고까지 생각하였다고 합니다. 이러한 이유로 이 분포에 '정규(normal)'라는 이름이 붙게 된 것입니다. 정규분포는 특성값이 연속적인 무한모집단 분포의 일종으로서 평균이 $μ$이고 표준편차가 $σ$인 경우 정규분포의 **확률밀도함수(Probability Density Function)**는 다음과 같습니다.  $$ f(x|\mu ,\sigma )=\frac { 1 }{ \sqrt { 2\pi } \sigma } exp\left( -\frac { { (x-\mu ) }^{ 2 } }{ 2{ \sigma }^{ 2 } } \right) $$  ## 평균, 편차에 따른 분포의 변화 정규분포의 파라메터는 평균과 표준편차입니다. 파라메터가 변하면 분포 또한 바뀌게 되는데요. 아래 그림과 같습니다. <a href="http://imgur.com/pkku7Az"><img src="http://i.imgur.com/pkku7Az.png" width="400px" title="source: imgur.com" /></a> 위 그림을 생성하는 데 필요한 파이썬 코드는 다음과 같습니다. ```python import math from matplotlib import pyplot as plt def normal_pdf(x, mu=0, sigma=1):   sqrt_two_pi = math.sqrt(2 * math.pi)   return (math.exp(-(x-mu)**2 / 2 / sigma**2) / (sqrt_two_pi * sigma)) xs = [x / 10.0 for x in range(-50,50)] plt.plot(xs,[normal_pdf(x,sigma=1) for x in xs],'-',label='mu=0,sigma=1') plt.plot(xs,[normal_pdf(x,sigma=2) for x in xs],'--',label='mu=0,sigma=2') plt.plot(xs,[normal_pdf(x,sigma=0.5) for x in xs],':',label='mu=0,sigma=0.5') plt.plot(xs,[normal_pdf(x,mu=-1) for x in xs],'-.',label='mu=-1,sigma=1') plt.legend() plt.title('Various Normal pdfs') plt.show() ```   ## 정규분포의 누적분포함수 **누적분포함수(Cumulative Distribution Function, CDF)**는 어떤 확률분포에 대해 확률변수가 특정 값보다 작거나 같은 확률을 나타냅니다. 아래 표는 평균이 0이고 표준편차가 1인 표준정규분포의 누적분포함수를 표로 정리한 것인데요. 빨간색 영역에 해당하는 확률이 바로 CDF에 해당합니다.  <a href="http://imgur.com/NzMZfQR"><img src="http://i.imgur.com/NzMZfQR.png" width="400px" title="source: imgur.com" /></a>  표준정규분포의 확률변수를 $Z$라고 할 때 $Z$값(위 표에서 행과 열의 이름에 해당)의 변화에 따른 누적분포함수 값의 변화를 나타낸 그림은 다음과 같습니다. 정규분포의 누적분포함수 또한 평균, 분산이 달라지면 그 모양도 달라지는걸 확인할 수 있습니다.  <a href="http://imgur.com/lgexkIF"><img src="http://i.imgur.com/lgexkIF.png" width="400px" title="source: imgur.com" /></a>  위 그림을 만드는 데 사용한 파이썬 코드는 다음과 같습니다. ```python import math from matplotlib import pyplot as plt def normal_cdf(x, mu=0, sigma=1):   return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2 xs = [x / 10.0 for x in range(-50,50)] plt.plot(xs,[normal_cdf(x,sigma=1) for x in xs],'-',label='mu=0,sigma=1') plt.plot(xs,[normal_cdf(x,sigma=2) for x in xs],'--',label='mu=0,sigma=2') plt.plot(xs,[normal_cdf(x,sigma=0.5) for x in xs],':',label='mu=0,sigma=0.5') plt.plot(xs,[normal_cdf(x,mu=-1) for x in xs],'-.',label='mu=-1,sigma=1') plt.legend(loc=4) plt.title('Various Normal cdfs') plt.show() ```   ## 표준정규분포 누적분포함수의 역함수 여러 통계학 문제를 풀다보면 특정 확률에 해당하는 표준정규분포의 $Z$값을 알고 싶은 경우가 많습니다. 예컨대 앞선 예시의 표에서 누적확률이 0.9990에 해당하는 $Z$값 3.09를 찾아보자는 것이죠. 이를 **이진검색** 기법을 활용해 근사하는 파이썬 코드는 다음과 같습니다. ```python # 정규분포 누적분포함수의 역함수 def inverse_normal_cdf(p, mu=0, sigma=1, tolerance=0.00001):   '''이진검색을 사용해서 역함수 근사'''   # 표준정규분포가 아니라면 표준정규분포로 변환   if mu != 0 or sigma != 1:     return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)   low_z, low_p = -10.0, 0 # normal_cdf(-10)는 0에 근접   hi_z, hi_p = 10.0, 1 # normal_cdf(10)는 1에 근접   while hi_z - low_z > tolerance:     mid_z = (low_z + hi_z) / 2 # 중간 값     mid_p = normal_cdf(mid_z) # 중간 값의 누적분포 값을 계산     if mid_p < p:       # 중간 값이 너무 작다면 더 큰 값들을 검색       low_z, low_p = mid_z, mid_p     elif mid_p > p:       # 중간 값이 너무 크다면 더 작은 값들을 검색       hi_z, hi_p = mid_z, mid_p     else:       break   return mid_z ``` 'inverse_normal_cdf(p=0.9990)'을 실행하면 '3.090238571166992'라는 값이 반환됩니다.   ## 중심극한정리 모집단의 분포가 정규분포를 따를 경우에는 모집단에서 뽑은 표본 또한 정규분포를 따릅니다. 모집단 평균이 $μ$이고 표준편차가 $σ$, 표본의 크기가 $n$일 때 다음이 성립합니다.  $$ X\sim N(\mu ,{ \sigma }^{ 2 })\quad \rightarrow \quad \overline { X } \sim N(\mu ,\frac { { \sigma }^{ 2 } }{ n } ) $$  모집단의 분포가 정규분포가 아닌 경우에는 이 사실이 성립하지 않습니다. 그러나 표본의 크기 $n$이 충분히 클 때에는 정규분포를 따르지 않는 임의의 모집단으로부터의 표본이라 하더라도 그 분포가 정규분포에 가깝다는 사실이 알려져 있으며 이것을 중심극한정리라고 합니다. 다시 말해 모집단의 분포가 어떤 형태이든 간에 표본의 크기가 충분히 크기만 하면 해당 표본이 근사적으로 정규분포를 따른다는 것입니다.   ## 중심극한정리 예시 보다 쉽게 이해하기 위해 **이항분포(Binomial Distribution)**를 예시로 설명해보겠습니다.  입시에서 합격과 불합격, 스포츠 경기에서 승리와 패배 같이 어떤 실험이 두 가지 가능한 결과만을 가질 경우 이를 **베르누이시행(Bernoulli)**이라고 합니다. 예를 들어 동전을 던지는 실험은 그 결과가 앞면, 또는 뒷면인 베르누이시행이 됩니다.  성공확률이 $p$인 베르누이시행을 $n$번 반복시행할 때 성공횟수 $X$의 분포를 이항분포라고 합니다. 이때 이항분포의 평균과 분산은 각각 $np$, $np(1-p)$가 되는데요. 중심극한정리는 $n$이 적당히 크다면 $X$가 정규분포를 따르지 않지만 표본의 분포가 평균이 $np$이고 분산이 $np(1-p)$인 정규분포와 유사해진다는 점을 알려줍니다. 아래 그림은 성공확률이 0.5인 베르누이시행을 100번 반복시행했을 때 성공횟수의 분포를 히스토그램으로 그린 것입니다. 실선은 평균이 50, 분산이 25인 정규분포를 그 확률밀도함수로부터 도출한 것입니다. 두 모양이 비슷한 것을 알 수 있습니다.  <a href="http://imgur.com/kstUqBK"><img src="http://i.imgur.com/kstUqBK.png" width="400px" title="source: imgur.com" /></a>  위 그림을 만드는 데 쓴 파이썬 코드는 다음과 같습니다.  ```python import math import random from collections import Counter from matplotlib import pyplot as plt def bernoulli_trial(p):   return 1 if random.random() < p else 0 def binomial(n, p):   return sum(bernoulli_trial(p) for _ in range(n)) def make_hist(p, n, num_points):   data = [binomial(n,p) for _ in range(num_points)]   # 이항분포의 표본을 막대 그래프로 표현   histrogram = Counter(data)   plt.bar([x - 0.4 for x in histrogram.keys()],       [v / num_points for v in histrogram.values()],       0.8,       color='0.75')   mu = p * n   sigma = math.sqrt(n * p * (1 - p))   # 근사된 정규분포를 라인 차트로 표현   xs = range(min(data), max(data) + 1)   ys = [normal_cdf(i + 0.5, mu, sigma) - normal_cdf(i - 0.5, mu, sigma) for i in xs]   plt.plot(xs,ys)   plt.title("Binomial Distribution vs. Normal Approximation")   plt.show() ``` 
NP␞ 이번 글에서는 한국어의 명사절/관형사절 내포에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 내포 **내포**란 하나의 절이 다른 절의 한 성분으로 참여하는 방식을 가리킵니다. 이때 안고 있는 절을 **모절**, **주절**, **상위절**이라 하고, 안겨 있는 절을 **내포절**, **종속절**, **하위절**이라고 합니다. 안겨 있는 절이 명사 역할을 할 경우 **명사절**, 관형사 역할일 경우 **관형사절**이라고 합니다. 이 글에서는 명사절과 관형사절을 중심으로 살펴봅니다.   ## 명사절 내포 예시는 다음과 같습니다. | 명사        | 명사절             | | ---------------- | --------------------------- | | **진실**이 알려졌다.  | **[진이가 음악에 소질이 있음]**이 알려졌다. | | 우리는 **기적**을 바랐다. | 우리는 **[올해도 풍년이 들기]**를 바랐다. |   ## 명사형 전성어미 명사절을 만드는 어미를 **명사형 전성어미**라고 합니다. 대표적으로 '-음'과 '-기'가 있습니다.  '-음'은 이미 현실화된 사태를 표현하거나, 개별적이고 구체적으로 존재하는 사태를 요구하는 서술어와 잘 어울립니다. 예문을 보겠습니다. > 12월 8일 초등학교 동창 만남. > > 진이는 자신이 큰 잘못을 저질렀음을 {기억했다, 깨달았다, 떠올렸다, 몰랐다, 알았다, 잊었다, 한탄했다}. > > 작가는 주인공이 이미 마음이 돌아섰음을 {보이고, 알리고, 암시하고} 있다. > > 나는 진이가 내게 호의를 가지고 있음을 {느꼈다, 의식했다}. > > 진이가 잘못을 했음이 {드러났다, 분명하다, 밝혀졌다, 알려졌다, 탄로났다, 틀림없다, 확실하다}. > > 진이는 민이가 적임자임을 {고백했다, 발표했다, 밝혔다, 보고했다, 주장했다, 지적했다, 통지했다}.  '-기'는 개별적 사태가 아닌 일반적 사태를 요구하는 서술어, 아직 일어나지 않고 머릿속에 존재하는 사태를 요구하는 서술어와 잘 어울립니다. 예문을 보겠습니다. > 12월 8일 초등학교 동창 만나기. > > 진이는 아침에 조깅하기를 {꺼린다, 싫어한다, 좋아한다, 즐긴다}. > > 중국어는 우리가 배우기에 {가능한, 까다로운, 나쁜, 쉬운, 알맞은, 어려운, 적당한, 좋은, 힘든} 언어이다. > > 농부들이 비가 오기를 {갈망한다, 고대한다, 기다린다, 기대한다, 기원한다, 바란다, 빈다, 원한다, 희망한다}. > > 나는 1년 후 귀국하기로 {결심했다, 결정했다, 계획했다, 맹세했다, 약속했다, 정했다}.   ## 관용적인 명사절 내포 관용표현으로 굳어진 형태로 쓰이는 사례도 많습니다. 예를 들어보겠습니다. > 밖에 비가 {오기/*옴} 때문에 행사를 진행하지 않고 있습니다. '때문이다'는 그 의미와 상관없이 반드시 '-기'로 끝나는 선행어를 써야 합니다. 마찬가지로 '나름이다', '마련이다', '십상이다', '위해'도 '-기'하고만 어울립니다. 아울러 '제가 알기로는', '제가 생각하기에는', '선생님이 말씀하시기를', '나를 알기를 우습게 안다', '친구들이 그립기 이를 데 없다/그지없다' 등도 관습적으로 쓰입니다.   ## 관형사절 내포 예문은 다음과 같습니다. | 관형사   | 관형사절     | | ------- | ------------- | | **새** 책 | **[철수가 본]** 책 |   ## 관형사형 전성어미 관형사절을 만드는 어미를 **관형사형 전성어미**라고 합니다. 대표적으로 '-ㄴ'과 '-ㄹ'이 있습니다. '-ㄴ'은 현실화된 일을 나타내는 절에 결합하고, '-ㄹ'은 현실화되지 않고 아직 사고의 영역에 있는 일을 나타내는 절에 결합하는 경향이 있습니다. 예문을 보겠습니다. > (1) [쥐를 잡**은**] 고양이가 낮잠을 잔다. > > (2) [쥐를 잡**을**] 고양이가 낮잠을 잔다. (1)의 고양이는 이미 쥐를 잡았고, (2)의 고양이는 아직 잡지 않았다는 점에서 의미상 차이가 있습니다.   ## 관형사절의 유형 관형사절에는 크게 **관계절**, **동격절**, 기타 세 가지 종류가 있습니다.  ### 관계절 피수식어에 해당하는 성분이 관형사절 내부에서 생략되어 있는 형태입니다. 모절과 내포절의 공통 명사를 매개로 두 절이 관계돼 있다는 취지로 관계절이라 불립니다. 예를 보겠습니다. (**e**는 생략됐다는 뜻입니다) > [**e** 쥐를 잡은] 고양이가 낮잠을 잔다. 위 예시에서 원래 문장은 (1) 고양이가 쥐를 잡았다 (2) 고양이가 낮잠을 잔다일 것입니다. 그런데 '고양이가'가 겹치므로 이것이 생략된 채로 내포문을 구성합니다. 다른 예를 보겠습니다. > [**e** 넓은] 밭이 펼쳐져 있다. 위 문장은 (1) 밭이 넓다 (2) 밭이 펼쳐져 있다 두 절로 분석할 수 있습니다. 마찬가지로 '밭이'가 겹치므로 생략된 형태로 관계절을 이룹니다.  주어 말고도 다른 성분으로 관계절을 이루는 예시는 다음과 같습니다. > 그 고양이가 쥐를 잡았다 + 쥐가 많다 = [그 고양이가 **e** 잡은] 쥐가 많다. > > 내가 어제 서점에 갔다 + 서점은 이 지역의 명소이다 = [내가 어제 **e** 간] 서점은 이 지역의 명소이다.  ### 동격절 피수식어에 해당하는 성분이 관형사절 내부에서 생략되어 있지 않은 형태입니다. 피수식어의 구체적인 내용을 보충하여 설명한다는 취지로 동격절 또는 보문절이라 불립니다. 예를 보겠습니다. > (가) 나는 **진이가 애쓴** 사실을 알고 있다. > > (나) 진이는 **내일 강연할** 계획을 취소했다. (가)에서 언급된 '사실'은 '진이가 애썼다'는 내용입니다. 의미상 같은 자격을 가지고, '사실'을 구체적으로 풀어쓴 형태입니다. 마찬가지로 (나)의 '계획'은 '내일 강연한다'는 내용입니다. 동격절에는 **긴 동격절**과 **짧은 동격절**로 나뉩니다. 전자는 다음 예문과 같이 관형사형 어미 앞이 완전한 문장 형식인 경우를 가리킵니다. > **진이가 곧 결혼한다는** 소문이 돈다. 짧은 동격절은 관형사형 어미 앞이 완전한 문장 형식이 아닌 경우를 말합니다. 예문을 보겠습니다. > 저는 **선생님을 만난** 기억이 없습니다.  ### 기타 동격절과 관계절 어느 쪽으로도 분류하기 어려운 사례도 있습니다. 예문을 보겠습니다. > (A) 진이는 **내가 집에 간** 후에 떠났다. (A)의 피수식어 '후'가 관형사절 내부의 성분이 아니라는 점에서 관계절로 보기 어렵습니다. 그렇다고 관형사절이 피수식 명사의 내용을 언급한다고 보기도 어렵다('내가 집에 갔다'≠후)는 점에서 동격절로도 분류할 수 없습니다. 굳이 성질을 따져본다면 특수한 명사(후)와 어울려 앞선 절을 뒤의 절에 연결시켜 주는 역할을 합니다. 이 점에 착안해 일부 학자들은 (B)의 '내가 집에 간'을 '연계절'이라고 부르기도 합니다. 다른 예문을 보겠습니다. > (B) **밥이 타는** 냄새가 난다. (B)의 피수식어 '냄새'가 관형사절 내부의 성분이 아니라는 점에서 관계절로 보기 어렵습니다. 또한 밥이 타는 것 자체가 냄새는 아니므로 동격절이라고도 보기 어렵습니다. 하지만 (A)의 '후'보다는 (B)의 '냄새'가 관형사절과 의미적으로 더 긴밀한 관련을 맺고 있는 느낌이 들기는 합니다. 이런 점에서 일부 학자들은 (B)의 '밥이 타는'을 '유사 동격절'이라 부르기도 합니다. 
VAE␞ 이번 글에서는 **Variational AutoEncoder**(VAE)에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아, 그리고 [이곳](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/) 등을 정리했음을 먼저 밝힙니다. PyTorch 코드는 [이곳](https://github.com/GunhoChoi/PyTorch-FastCampus)을 참고하였습니다. 그럼 시작하겠습니다.   ## concept VAE는 데이터가 생성되는 과정, 즉 데이터의 확률분포를 학습하기 위한 두 개의 뉴럴네트워크로 구성되어 있습니다. VAE는 잠재변수(latent variable) $z$를 가정하고 있는데요. 우선 *encoder*라 불리는 뉴럴네트워크는 관측된 데이터 $x$를 받아서 잠재변수 $z$를 만들어 냅니다. *decoder*라 불리는 뉴럴네트워크는 *encoder*가 만든 $z$를 활용해 $x$를 복원해내는 역할을 합니다. VAE 아키텍처는 다음 그림과 같습니다.  <a href="https://imgur.com/PhHb2aF"><img src="https://i.imgur.com/PhHb2aF.jpg" width="500px" title="source: imgur.com" /></a>  그렇다면 여기에서 잠재변수 $z$는 어떤 의미인 걸까요? 고양이 그림 예시를 들어 생각해보겠습니다. 수많은 고양이 사진이 있다고 칩시다. 사람은 고양이 사진들이 저마다 다르게 생겼다 하더라도 이들 사진이 고양이임을 단박에 알아낼 수 있습니다. 사람들은 고양이 사진을 픽셀 단위로 자세하게 보고 고양이라고 판단하는게 아니라, 털 색깔, 눈 모양, 이빨 개수 등 추상화된 특징을 보고 고양이라는 결론을 냅니다.  이를 잠재변수 $z$와 VAE 아키텍처 관점에서 이해해 보자면, *encoder*는 입력 데이터를 추상화하여 잠재적인 특징을 추출하는 역할, *decoder*는 이러한 잠재적인 특징을 바탕으로 원 데이터로 복원하는 역할을 한다고 해석해볼 수 있겠습니다. 실제로 잘 학습된 VAE는 임의의 $z$값을 *decoder*에 넣으면 다양한 데이터를 생성할 수 있다고 합니다.    ## latent vector 만들기 VAE의 *decoder* 파트는 다음과 같이 정규분포를 전제로 하고 있습니다. 다시 말해 *encoder*가 만들어낸 $z$의 평균과 분산을 모수로 하는 정규분포입니다.  $$ p\left( { x }|{ z } \right) =N\left( { x }|{ { f }_{ \mu }\left( z \right) },{ { f }_{ \sigma }\left( z \right) }^{ 2 }\times I \right) $$  최대우도추정(MLE) 방식으로 VAE 모델의 파라메터를 추정하려면 다음과 같이 정의된 *marginal log-likelihood* $\log{p(x)}$를 최대화하면 됩니다. 아래 식을 최대화하면 모델이 데이터를 그럴싸하게 설명할 수 있게 됩니다.  $$ \log { p\left( x \right) } =\log { \sum _{ z }^{ }{ p\left( { x }|{ { { f }_{ \mu }\left( z \right) },{ { f }_{ \sigma }\left( z \right) }^{ 2 }\times I } \right) } p\left( z \right) } $$  위 식은 최적화하기 어렵습니다. $z$는 무수히 많은 경우가 존재할 수 있는데 가능한 모든 $z$에 대해서 고려해야 하기 때문입니다. 이럴 때 써먹는 것이 [변분추론(Variational Inference)](https://ratsgo.github.io/generative%20model/2017/12/19/vi/)입니다. 변분추론은 계산이 어려운 확률분포를, 다루기 쉬운 분포 $q(z)$로 근사하는 방법입니다. 한편 $p(x)$는 베이즈 정리에서 *evidence*라고 이름이 붙여진 항인데요. 몇 가지 수식 유도 과정을 거치면 *evidence*의 하한(ELBO)을 다음과 같이 구할 수 있습니다.  $$ \log { p\left( x \right) } \ge { E }_{ z\sim q\left( z \right) }\left[ \log { p(x|z) } \right] -{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right) \right) $$  계산이 쉬운 위 부등식 우변, 즉 ELBO를 최대화하면 $\log{p(x)}$를 최대화할 수 있을 것입니다. 일반적인 변분추론에서는 $q(z)$를 정규분포로 정합니다. 예컨대 다음과 같습니다.  $$ q\left( z \right) =N\left( { \mu }_{ q },{ \sigma }_{ q }^{2} \right) $$  그런데 데이터 $x$가 고차원일 때는 $q$를 위와 같이 정하게 되면 학습이 대단히 어렵다고 합니다. 그도 그럴 것이 모든 데이터에 대해 동일한 평균과 분산, 즉 단 하나의 정규분포를 가정하게 되는 셈이니, 데이터가 복잡한 데 비해 모델이 너무 단순하기 때문인 것 같습니다. VAE에서는 이 문제를 해결하기 위해 $q$의 파라메터를 $x$에 대한 함수로 둡니다. 다음과 같습니다.  $$ q\left( z|x \right) =N\left( { \mu }_{q}\left( x \right) ,\Sigma_{q} \left( x \right) \right) $$  $q$를 위와 같이 설정하고 ELBO를 최대화하는 방향으로 $q$를 잘 학습하면, $x$가 달라질 때마다 $q$의 분포도 계속 달라지게 됩니다. $x$에 따라 $q$의 모수(평균, 분산)가 바뀌게 되니까요. VAE의 *encoder*에는, $x$를 받아서 $z$의 평균과 분산을 만들어내는 뉴럴네트워크 두 개($f_μ$, $f_σ$)가 포함되어 있습니다. 이 덕분에 복잡한 데이터에 대해서도 모델이 적절하게 대응할 수 있게 됩니다.  어쨌든 노이즈를 *zero-mean Gaussian*에서 하나 뽑아 $f_μ$, $f_σ$가 산출한 평균과 분산을 더하고 곱해줘서 sampled latent vector $z$를 만듭니다. 수식은 다음과 같으며, 이같은 과정을 *reparameterization trick*이라고 부릅니다. 다시 말해 $z$를 직접 샘플링하는게 아니고 노이즈를 샘플링하는 방식입니다. 이렇게 되면 역전파를 통해 *encoder*가 산출하면 평균과 분산을 업데이트할 수 있게 됩니다.  $$ z={ \mu }{ (x) }+{ \sigma }{ (x) } \times\epsilon ,\quad \epsilon \sim N\left( 0,1 \right) $$  VAE는 코드로 보는 것이 훨씬 잘 이해가 되는데요. 지금까지 설명한 내용이 아래 코드에 함축돼 있습니다(pytorch). ```python def __init__(self):   self.fc1_1 = nn.Linear(784, hidden_size)   self.fc1_2 = nn.Linear(784, hidden_size)   self.relu = nn.ReLU()             def encode(self,x):   x = x.view(batch_size,-1)   mu = self.relu(self.fc1_1(x))   log_var = self.relu(self.fc1_2(x)) 	return mu,log_var   def reparametrize(self, mu, logvar):   std = logvar.mul(0.5).exp_() 	eps = torch.FloatTensor(std.size()).normal_() 	return eps.mul(std).add_(mu) ``` VAE는 latent vector $z$를 위와 같이 만들기 때문에 데이터 $x$가 동일하다 하더라도 $z$는 얼마든지 달라질 수 있고, *decoder*의 최종 결과물 역시 변종이 발생할 가능성이 있습니다. $z$ 생성 과정에 *zero-mean Gaussian*으로 뽑은 노이즈가 개입되기 때문입니다. 데이터 $x$를 넣어 다시 $x$가 출력되는 구조의 *autoencoder*이지만, 맨 앞에 *variational*이 붙은 이유가 바로 여기에 있는 것 같습니다.   ## VAE의 목적함수 VAE의 *decoder*는 데이터의 사후확률 $p(x$\|$z)$을 학습합니다. 하지만 사후확률은 계산이 어렵기 때문에 다루기 쉬운 분포 $q(z)$로 근사하는 [변분추론](https://ratsgo.github.io/generative%20model/2017/12/19/vi/) 기법을 적용하게 됩니다. 변분추론은 $p(x$\|$z)$와 $q(z)$ 사이의 KL Divergence를 계산하고, KLD가 줄어드는 쪽으로 $q(z)$를 조금씩 업데이트해서 $q(z)$를 얻어냅니다. KLD 식을 조금 변형하면 다음과 같은 식을 유도할 수 있습니다. (자세한 내용은 [이곳](https://ratsgo.github.io/generative%20model/2017/12/19/vi/)을 참고하시면 좋을 것 같습니다)  $$ { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right) \right) ={ D }_{ KL }\left( q\left( z \right) ||p\left( z \right) \right) +\log { p\left( x \right) } -{ E }_{ z\sim q\left( z \right) }\left[ \log { p(x|z) } \right] $$  그런데 우리는 전 챕터에서 $q$를 정규분포로 두고, $q$의 평균과 분산을 $x$에 대한 함수로 정의한 바 있습니다. 이를 반영하고, *evidence*인 $\log{p(x)}$ 중심으로 식을 다시 쓰면 아래와 같습니다. 이 식을 $A$라고 두겠습니다.  $$ \begin{align*} \log { p\left( x \right) } =&{ E }_{ z\sim q\left( z|x \right) }\left[ \log { p(x|z) } \right] -{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z \right) \right) +{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z|x \right) \right)\\=&ELBO+{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z|x \right) \right) \end{align*} $$  동일한 확률변수에 대한 KLD 값(위 식 우변 세번째 항)은 항상 양수이므로 아래와 같은 부등식이 항상 성립합니다. 아래 식을 $B$라고 두겠습니다.  $$ \log { p\left( x \right) } \ge { E }_{ z\sim q\left( z|x \right) }\left[ \log { p(x|z) } \right] -{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z \right) \right)=ELBO $$  따라서 위 부등식 우변, 즉 ELBO를 최대화하면 우리의 목적인 *marginal log-likelihood* $\log{p(x)}$를 최대화할 수 있게 됩니다. 아울러 $A$와 $B$를 비교하면서 보면 ELBO를 최대화한다는 것은 $q(z$\|$x)$와 $p(z$\|$x)$ 사이의 KLD를 최소화하는 의미가 됩니다.  딥러닝 모델은 보통 손실함수를 목적함수로 쓰는 경향이 있으므로 위 부등식의 우변에 음수를 곱한 식이 *loss function*이 되고, 이 함수를 최소화하는 게 학습 목표가 됩니다. 손실함수는 다음과 같습니다.  $$ L=-{ E }_{ z\sim q\left( z|x \right) }\left[ \log { p(x|z) } \right] +{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z \right) \right) $$  위 식 우변 첫번째 항은 *reconstruction loss*에 해당합니다. *encoder*가 데이터 $x$를 받아서 $q$로부터 $z$를 뽑습니다. *decoder*는 *encoder*가 만든 $z$를 받아서 원 데이터 $x$를 복원합니다. 위 식 우변 첫번째 항은 이 둘 사이의 크로스 엔트로피를 가리킵니다. 위 식 우변 두번째 항은 *KL Divergence Regularizer*에 해당합니다. VAE는 $z$가 *zero-mean Gaussian*이라고 가정합니다. 정규분포끼리의 KLD는 분석적인 방식으로 도출 가능합니다. 계산이 쉽다는 말이지요. 따라서 위 식 우변 두번째 항을 다음과 같이 다시 쓸 수 있습니다.   $$ \begin{align*} { D }_{ KL }\left( q\left( z|x \right) ||p\left( z \right) \right) =&{ D }_{ KL }\left[ N\left( { \mu }_{ q }\left( x \right) ,\Sigma _{ q }\left( x \right) \right) ||N\left( 0,1 \right) \right] \\ =&\frac { 1 }{ 2 } \sum _{ k }^{ }{ \left\{ exp\left( \Sigma _{ q }\left( x \right) \right) +{ { \mu }_{ q }\left( x \right) }^{ 2 }-1-\Sigma _{ q }\left( x \right) \right\} } \end{align*} $$  위 식 우변 두번째 항을 최소화한다는 말은 $q$를 *zero-mean Gaussian*에 가깝게 만든다는 의미입니다. 지금까지 말씀드린 내용을 종합해 VAE의 손실함수를 도식적으로 나타내면 다음과 같습니다.  <a href="https://imgur.com/JnoyZIN"><img src="https://i.imgur.com/JnoyZIN.png" width="600px" title="source: imgur.com" /></a>  KLD를 아래처럼 분해해서 다음과 같이 해석하는 것도 가능합니다.  <a href="https://imgur.com/HRtHPkp"><img src="https://i.imgur.com/HRtHPkp.png" width="600px" title="source: imgur.com" /></a>  VAE의 목적함수를 PyTorch 코드로 구현한 결과는 다음과 같습니다.  ```python # the Binary Cross Entropy between the target and the output reconstruction_function = nn.BCELoss(size_average=False) def loss_function(recon_x, x, mu, logvar):   BCE = reconstruction_function(recon_x, x)   KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)   KLD = torch.sum(KLD_element).mul_(-0.5)   return BCE + KLD ```    ## VAE의 장단점 VAE는 GAN에 비해 학습이 안정적인 편이라고 합니다. 손실함수에서 확인할 수 있듯 *reconstruction error*과 같이 평가 기준이 명확하기 때문입니다. 아울러 데이터뿐 아니라 데이터에 내재한 잠재변수 $z$도 함께 학습할 수 있다는 장점이 있습니다(*feature learning*). 하지만 출력이 선명하지 않고 평균값 형태로 표시되는 문제, *reparameterization trick*이 모든 경우에 적용되지 않는 문제 등이 단점으로 꼽힌다고 합니다.
NF␞ 이번 글에서는 **Normalizaing Flow**(NF) 개념에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다.   ## 목적 변분추론(Variational Inference)의 목적은 계산이 어려운 사후확률 분포 $p(z$\|$x)$를 계산이 쉬운 $q(z$\|$x)$로 근사하는 것입니다. 우리는 *evidence*인 $p(x)$를 최대화하는 모델, 즉 데이터 $x$의 분포를 잘 설명하는 확률모형을 학습시키고자 합니다. 몇 가지 수식 정리 과정을 거치면 **Evidence Lower Bound**(ELBO)를 다음과 같이 도출할 수 있습니다. (수식 유도 과정에 대해서는 [이곳](https://ratsgo.github.io/generative%20model/2017/12/19/vi/) 참고)  $$ ELBO={ E }_{ z\sim q\left( z |x\right) }\left[ \log { p(x|z) } \right] -{ D }_{ KL }\left( q\left( z |x\right) ||p\left( z|x\right) \right) $$  [Variational AutoEncoder(VAE)](https://ratsgo.github.io/generative%20model/2018/01/27/VAE/)에서는 근사 대상 확률함수 $q$를 다음과 같이 정의합니다.  $$ q\left( z|x \right) =N\left( { \mu }_{q}\left( x \right) ,\Sigma_{q} \left( x \right) \right) $$  VAE에서 사후확률분포 $q$를 위와 같이 정한 이유는 샘플링과 계산의 용이성 때문입니다. 그런데 이보다 더 복잡한 형태의 사후확률분포를 만들어낼 수는 없을까요? 예컨대 $q$에서 뽑은 잠재변수를 $z_0$라 둡시다. 그런데 VAE는 $q$를 단순한 가우시안 분포로 가정하기 하기 때문에 아래와 같이 $z_0$에 특정한 형태의 함수 $f_k$들을 반복 적용하여 모델이 더욱 복잡한 형태의 잠재변수를 표현하게끔 만들어주자는 것입니다.  $$ { z }_{ K }={ f }_{ K }\circ ...\circ { f }_{ 2 }\circ { f }_{ 1 }\left( { z }_{ 0 } \right) $$  이것이 바로 NF가 노리는 바입니다.   ## Change of Variables $z'=f(z)$일 때 역함수가 존재하는 $f$와 임의의 확률분포 $q(z)$에 대해 다음 공식이 성립한다고 합니다.  $$ q\left( z' \right) =q\left( z \right) \left| det\frac { \partial { f }^{ -1 } }{ \partial z' } \right| =q\left( z \right) { \left| det\frac { \partial f }{ \partial z } \right| }^{ -1 } $$  따라서 $f$를 $K$번 적용한 $z_K$의 로그확률 $q_K(z_K)$값을 다음과 같이 표현할 수 있다고 합니다.  $$ \log { { q }_{ K }\left( { z }_{ K } \right) } =\log { { q }_{ 0 }\left( { z }_{ 0 } \right) } -\sum _{ k=1 }^{ K }{ \log { det\left| \frac { \partial { f }_{ k } }{ \partial { z }_{ k } } \right| } } $$   ## Normalizing Flow 그런데 이때 특정 함수 $f$를 사용하면 위 식의 행렬식(determinant) 부분을 쉽게 계산할 수 있다고 합니다. 그 종류는 다음과 같습니다.  <a href="https://imgur.com/DtOLSdZ"><img src="https://i.imgur.com/DtOLSdZ.png" width="400px" title="source: imgur.com" /></a>  $f$를 *planar*로 정했다고 칩시다. 이 경우 행렬식 부분은 다음과 같습니다.  $$ det\left| \frac { \partial { f }_{ k } }{ \partial { z }_{ k } } \right| =\left| 1+{ u }^{ T }\psi \left( { z }_{ k } \right) \right|\\,where\quad \psi \left( { z }_{ k } \right) =h'\left( { w }^{ T }z+b \right) w $$  $K$를 키울 수록 잠재변수를 더 복잡하게 모델링할 수 있습니다. 예컨대 다음과 같습니다.  <a href="https://imgur.com/H6nvMHh"><img src="https://i.imgur.com/H6nvMHh.png" width="400px" title="source: imgur.com" /></a>    
GPU␞ 해야지 해야지 하면서도 잡일이 많아서 미루고 미뤘던 GTX 1080을 드디어 연구실 컴에 장착했다!! 포장부터 영롱한 자태.. ![1](http://i.imgur.com/Gbaz3BA.jpg) 포장 개봉을 하면 이렇듯 웅장한 자태를 내뿜는다, 하악 ![2](http://i.imgur.com/UYME9Py.jpg) 비닐을 살포시 뜯어주고.. ![3](http://i.imgur.com/4JIo0xA.jpg) 컴퓨터에 장착!! (사실 크기가 너무 커서 본체 케이스 전체를 공사하다시피했다..뒷부분은 다 뜯어냈다고 보면 됨..ㅠ) ![4](http://i.imgur.com/WyL0uXc.jpg) 텐서플로우에서도 잘 인식된다, 저 메모리 용량을 보라.. ~~그동안 메모리 땜에 고생한 것만 생각하면 ㅠㅠㅠ~~ ![5](http://i.imgur.com/2f0vi0C.jpg) 조명빨도 좀 있다ㅋㅋㅋㅋ  ![7](http://i.imgur.com/tAK6sB5.jpg) 앞으로 열공할 일만 남았다.  **GPU를 지원해주신 강필성 교수님, 사용을 배려해준 김해동, 조수현, GPU 설치에 많은 도움을 준 박재선 학우 모두들 감사합니다ㅠㅠ**  
bellmanford␞ 이번 글에서는 [최단 경로(Shortest Path)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/25/shortestpath/)를 찾는 대표적인 기법 가운데 하나인 **벨만-포드 알고리즘(Bellman-Ford's algorithm)**을 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님과 역시 같은 대학의 김황남 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept 최단경로 문제의 *[optimal substructure](https://ratsgo.github.io/data%20structure&algorithm/2017/11/25/shortestpath/)*를 확장하면 최단경로를 다음과 같이 분해(decompostion)할 수 있습니다. 시작노드 $s$에서 $v$에 이르는 최단경로는 $s$에서 $u$까지의 최단경로에 $u$에서 $v$ 사이의 가중치(거리)를 더한 값이라는 겁니다.  $$ D\left( s,v \right) =D\left( s,u \right) +w\left( u,v \right) $$  벨만-포드 알고리즘은 $s,u$ 사이의 최단경로를 구할 때 그래프 내 모든 엣지에 대해 *[edge relaxation](https://ratsgo.github.io/data%20structure&algorithm/2017/11/25/shortestpath/)*을 수행해 줍니다. 그러면 이를 몇 번 수행해야 할까요? 생각해 보면 $s,u$ 사이의 최단경로는 $s$와 $u$뿐일 수 있고, $u$를 제외한 그래프의 모든 노드(\|$V$\|$-1$개)가 $s,u$ 사이의 최단경로를 구성할 수도 있습니다. 따라서 벨만-포드 알고리즘은 모든 엣지에 대한 *edge-relaxation*을 \|$V$\|$-1$회 수행합니다.   ## 수행예시1 하단 좌측 그림과 같은 그래프에 벨만-포드 알고리즘을 적용해 보겠습니다. 우선 시작노드 $A$를 제외한 모든 노드의 거리를 무한대로 초기화합니다. *edge relaxation* 순서는 *order*와 같습니다(예시를 위해 정해놓은 것일 뿐입니다).  <a href="https://imgur.com/JGvQFVi"><img src="https://i.imgur.com/JGvQFVi.png" title="source: imgur.com" /></a>  우선 ($B,E$)를 보겠습니다. `무한대-2=무한대`이므로 업데이트할 필요가 없습니다. ($C,E$), ($F,C$), ($D,F$), ($C,B$) 또한 마찬가지입니다. ($A,B$)의 경우 시작노드 $A$에서 $B$에 이르는 거리가 8이고, 이는 기존 거리(무한대)보다 작으므로 8을 $B$에 기록해 둡니다. 마찬가지로 $C,D$도 각각 -2, 4로 기록해 둡니다. 이로써 그래프 모든 엣지에 대한 첫번째 *edge relaxation*이 끝났습니다.  <a href="https://imgur.com/01Be9h5"><img src="https://i.imgur.com/01Be9h5.png" title="source: imgur.com" /></a>  상단 좌측 그림 차례입니다. ($B,E$)의 경우 `8-2=6`이고 이는 기존 거리(무한대)보다 작으므로 6을 $E$에 기록해 둡니다. ($C,E$)의 경우 `-2+3=1`이고 이는 기존 거리(6)보다 작으므로 1을 $E$에 기록해 둡니다. ($F,C$)의 경우 `무한대+9=무한대`이므로 업데이트할 필요가 없습니다. ($D,F$)의 경우 `4+5=9`이고 이는 기존 거리(무한대)보다 작으므로 9를 $F$에 기록해 둡니다. ($C,B$)의 경우 `-2+7=5`이고 이는 기존 거리(8)보다 작으므로 5를 $B$에 기록해 둡니다. ($C,D$)의 경우 `-2+1=-1`이고 이는 기존 거리(4)보다 작으므로 -1을 $D$에 기록해 둡니다.  ($A,B$)의 경우 `0+8=8`이고 이는 기존 거리(5)보다 크므로 업데이트할 필요가 없습니다. ($A,C$)의 경우 `0-2=-2`이고 이는 기존 거리(-2)와 같으므로 업데이트할 필요가 없습니다. ($A,D$)의 경우 `0+4=4`이고 이는 기존 거리(-1)보다 크므로 업데이트할 필요가 없습니다. 이로써 그래프 모든 엣지에 대한 두번째 *edge relaxation*이 끝났습니다. 이번엔 상단 우측 그림 차례입니다. ($B,E$)의 경우 `5-2=3`이고 이는 기존 거리(1)보다 크므로 업데이트할 필요가 없습니다. 이는 ($C,E$), ($F,C$) 또한 마찬가지입니다. ($D,F$)의 경우 `-1+5=4`이고 이는 기존 거리(9)보다 작으므로 4를 $F$에 기록해 둡니다. ($C,B$), ($C,D$), ($A,B$), ($A,C$), ($A,D$)는 모두 기존 거리보다 크므로 업데이트할 필요가 없습니다. 이로써 그래프 모든 엣지에 대한 세번째 *edge relaxation*이 끝났습니다. 벨만-포드 알고리즘은 시작노드를 제외한 전체 노드수 만큼의 *edge relaxation*을 수행해야 합니다. 위 예시의 경우 총 5회 반복 수행해야 합니다. 그런데 네번째 *edge relaxation*부터는 거리 정보가 바뀌지 않으므로 생략했습니다.   ## 수행예시2 벨만-포드 알고리즘의 또다른 수행 예시입니다. 그래프 모든 엣지에 대한 *edge relaxation*을 1회 수행한 것입니다. *edge relaxtion*을 수행할 때 거리정보뿐 아니라 최단경로(음영 표시) 또한 업데이트한다는 걸 알 수 있습니다.  <a href="https://imgur.com/hcWT22F"><img src="https://i.imgur.com/hcWT22F.png" title="source: imgur.com" /></a>   ## negative cycle [다익스트라 알고리즘(Dijkstra's algorithm)]()과 달리 벨만-포드 알고리즘은 가중치가 음수인 경우에도 적용 가능합니다. 그러나 다음과 같이 음수 가중치가 사이클(cycle)을 이루고 있는 경우에는 작동하지 않습니다.  <a href="https://imgur.com/46tJqd7"><img src="https://i.imgur.com/46tJqd7.png" width="400px" title="source: imgur.com" /></a>  위 그림에서 $c,d$ 그리고 $e,f$가 사이클을 이루고 있는 걸 확인할 수 있습니다. $c,d$의 경우 사이클을 돌 수록 거리가 커져서 최단경로를 구할 때 문제가 되지 않습니다. 반면 $e,f$의 경우 사이클을 돌면 돌수록 그 거리가 작아져 벨만-포드 알고리즘으로 최단경로를 구하는 것 자체가 의미가 없어집니다. 따라서 그래프 모든 엣지에 대해 *edge relaxation*을 시작노드를 제외한 전체 노드수 만큼 반복 수행한 뒤, 마지막으로 그래프 모든 엣지에 대해 *edge relaxation*을 1번 수행해 줍니다. 이때 한번이라도 업데이트가 일어난다면 위와 같은 *negative cycle*이 존재한다는 뜻이 되어서 결과를 구할 수 없다는 의미의 *false*를 반환하고 함수를 종료하게 됩니다. 벨만-포드 알고리즘 전체의 의사코드는 다음과 같습니다.  <a href="https://imgur.com/Co6NVQ8"><img src="https://i.imgur.com/Co6NVQ8.png" width="300px" title="source: imgur.com" /></a>   ## 계산복잡성 벨만-포드 알고리즘은 그래프 모든 엣지에 대해 *edge relaxation*을 시작노드를 제외한 전체 노드수 만큼 반복 수행하고, 마지막으로 그래프 모든 엣지에 대해 *edge relaxation*을 1번 수행해 주므로, 그 계산복잡성은 $O($\|$V$\|\|$E$\|$)$이 됩니다. 그런데 *dense graph*는 엣지 수가 대개 노드 수의 제곱에 근사하므로 간단하게 표현하면 $O($\|$V$\|$^3)$이 됩니다. 이는 다익스트라 알고리즘($O($\|$V$\|$^2)$보다 더 큰데, 벨만-포드 알고리즘은 음수인 가중치까지 분석할 수 있기 때문에 일종의 *trade-off*라고 생각해도 될 것 같다는 생각이 듭니다.ㄴ
lexicalaspect␞ 이번 글에서는 한국어의 **상(aspect)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## '상'이란 상이란 어떤 사태의 내적 시간 구성을 가리키는 문법 범주입니다. 한국어의 상에는 문법형태소로 표현되는 [문법상(grammatical aspect)](https://ratsgo.github.io/korean%20linguistics/2017/07/10/aspect/), 동사 어휘로 나타나는 **어휘상(lexical aspect)**가 있습니다. 이 글에서는 어휘상을 중심으로 살펴보도록 하겠습니다. 이 글 역시 고려대 정연주 선생님 강의와 한국어문법총론(구본관 외 지음)을 정리하였음을 먼저 밝힙니다.   ## 어휘상 한국어의 어휘상은 어떤 어휘가 상적 특성을 구성하는 자질을 어떻게 가지고 있느냐에 따라 분류됩니다. 그 자질로는 상태성, 순간성, 완성성 등이 있습니다. > [+상태성] : 성질이나 상태를 나타내는 형용사 > > [-상태성] : 행위나 작용을 나타내는 동사 > > [+순간성] : 해당 어휘가 나타내는 행위나 작용이 순간적으로 이뤄질 때 > > [-순간성] : 행위나 작용이 천천히 이뤄질 수 있을 때 > > [+완성성] : 행위나 작용이 다 끝나야 해당 어휘의 의미가 성립할 때 > > [-완성성] : 행위나 작용이 끝나지 않아도 의미가 성립할 때 한국어 어휘상의 분류는 다음과 같습니다.  | 범주  |    사례    |     자질     | | :---: | :------------: | :----------------: | | 상태 동사 | 높다, 낮다, 작다... | [+상태성, -순간성, -완성성] | | 과정 동사 | 걷다, 읽다, 울다... | [-상태성, -순간성, -완성성] | | 완성 동사 | 닫다, 눕다, 먹다... | [-상태성, -순간성, +완성성] | | 순간 동사 | 죽다, 차다, 잡다... | [-상태성, +순간성, +완성성] | | 심리 동사 | 믿다, 느끼다, 알다... | [-상태성, -순간성, -완성성] | 과정 동사는 제한적 시간의 폭을 나타내는 '한 시간동안'과 같은 부사구와 아주 잘 어울리나 심리 동사는 그러한 말과 잘 어울리지 않습니다. 심리 동사는 형식적으로는 동사이지만 의미적으로는 상태의 지속성을 나타내는 형용사에 가까워 이러한 특성이 생긴 것입니다. 완성 동사와 순간 동사는 순간성 자질이 앞뒤 맥락에 따라 달리 해석될 수 있습니다. 예컨대 다음과 같습니다. > (1) 완성 동사이나 [+순간성] : 문을 쾅 닫았다 > > (2) 순간 동사이나 [-순간성] : 그 개는 서서히 죽어갔다 어휘상은 앞뒤 맥락에 따라 달리 해석될 여지가 있는 **유동성**이 존재합니다. 그래서 동사의 어휘상을 다룰 때는 목적어나 부사어와 함께 전체 동사구의 상을 고찰하는 것이 일반적입니다. 이렇게 고찰된 상적 의미를 **상황유형(situation type)**이라 합니다.   ## 문법상과 어휘상의 연관성 상(문법상)은 어휘상과 밀접한 연관이 있습니다. 어휘 자체의 상적 의미와 상의 문법적 표현이 잘 어울려야 통사적 구성을 이룰 수 있기 때문입니다. 다음 예문을 보겠습니다. > (A) 진행상 : 순희가 공원을 걷고 있다 > > (B) 완료상 : 명희가 볼펜을 쥐고 있다 (A)의 '걷다'는 과정 동사입니다. 따라서 '-고 있다'가 결합하면 진행상의 의미로 해석하는 것이 자연스러워집니다. 이에 반해 (B)의 '쥐다'는 순간 동사입니다. 따라서 '-고 있다'가 결합할 때 진행상의 의미로 해석하기 어렵게 됩니다. 순간적으로 일어나는 행위는 시간의 폭이 너무나 짧기 때문입니다. 그래서 (B)의 '-고 있다'는 완료상으로 해석하게 됩니다. 다른 예문을 보겠습니다. > (ㄱ) 철수가 눈을 깜빡이고 있다 > > (ㄴ) 아이들이 공을 차고 있다 '깜빡이다'와 '차다'는 모두 순간 동사입니다. 그리고 이들의 행위는 행위의 결과가 남지 않는 동사이기도 합니다. 그러므로 원칙적으로는 진행상의 '-고 있다'도 쓸 수 없고 완료상의 '-고 있다'도 쓸 수 없어야 합니다.  그러나 (ㄱ), (ㄴ) 모두 말이 됩니다. (ㄱ)은 반복적 행위를 뜻하고 있습니다. (ㄴ) 역시 어떤 아이가 딱 한 번 공을 찼을 때 '공을 차고 있다'라고 하지 않는다는 점에서 반복적 행위를 뜻함을 알 수 있습니다. 반복적 행위는 행위의 지속성과 의미가 상통하기 때문에 진행상의 '-고 있다'와 어울려 쓰일 수 있는 것입니다. 이처럼 문법상과 어휘상의 어울림은 상황 맥락에 따른 미세한 시간 해석에 의존하는 경우가 많습니다. 
postag␞ 이번 글에서는 시중에 공개된 형태소 분석기 성능을 비교해 보도록 하겠습니다. 이번 글에서는 꼬꼬마, 코모란, 트위터 세 가지 형태소 분석기 성능을 비교해볼 예정입니다. (제 컴퓨터가 윈도우 기반이어서 은전한닢은 작동이 불가하고, 어떤 이유에선지 한나눔은 라이브러리 로드시 오류가 나서 어쩔 수 없이 제외하였습니다, 향후 환경을 개선하는대로 나머지 두 개 분석기 성능도 비교해 보겠습니다) 그럼 시작하겠습니다.  ## 형태소 분석 개요 **형태소 분석(POS-tagging)**이란 원시말뭉치를 형태소 단위로 쪼개고 각 형태소에 품사 정보를 부착하는 작업을 가리킵니다. 많은 분들이 한국어 형태소 분석에 매진해 오셨고, 정말 감사하게도 오픈소스로 만들어주셔서 저 같은 사람이 편리하게 사용하고 있습니다. 특히 [KoNLPy](http://konlpy-ko.readthedocs.io/)는 시중에 공개된 꼬꼬마, 코모란, 트위터, 한나눔, 은전한닢 다섯개 형태소 분석기를 한꺼번에 묶어서 편리하게 사용할 수 있도록 한 패키지입니다. 다시 한번 제작자 분들께 깊은 감사를 드립니다. 어쨌든 이번 글의 분석 대상인 꼬꼬마, 코모란, 트위터 형태소 분석기의 품사 태그표는 아래와 같습니다. 보시다시피 꼬꼬마는 **세종품사태그**에 가장 가깝고 분석 범주 또한 가장 많습니다. 트위터는 꼬꼬마 대비 분석 범주가 다소 적은 편이지만 이모티콘이나 해쉬태그 같은 인터넷 텍스트에 특화된 범주가 추가된 점이 눈에 띕니다. 코모란은 분석 범주 개수로는 꼬꼬마와 트위터 중간에 위치하고, 개발자 분께서 지속적으로 업데이트를 해주시고 계신 점이 강점이라고 할 수 있겠습니다. <a href="http://imgur.com/RXBrbue"><img src="http://i.imgur.com/RXBrbue.png" width="700px" title="source: imgur.com" /></a>  ## 분석 방법 왓챠에서 수집한 영화 리뷰 1만건을 분석 대상으로 삼았습니다. 예컨대 아래와 같습니다. - 영화가 아니라 영상으로 예술을 만든 작품 이다지도 소박한 주제에 숨이 막힐 듯 한 우아함이라니  - 옛날 sf영화의 장점 이해하기 쉽고 단순하며 유쾌하다 - 내게 남는건 슈퍼맨 뿐이다 잘생긴 슈퍼맨 완벽한 로맨티스트 슈퍼맨 별에서 온 슈퍼맨 굳이 의미를 더하자면 좋은 사람이랑 처음으로 같이 본 영화라는거 그럼에도 도저히 쉴드를 칠 수 없을 정도로 노잼이었단게 아쉬울 따름이다 우선 꼬꼬마 태거의 분석 결과를 보겠습니다. 전반적으로 분석 품질이 좋습니다. 다만 부사 '이다지'와 조사 '-도'의 결합을 지정사 '이-', 연결어미 '-다', 명사 '지도'로 엉뚱하게 분석한 것이 걸리네요. 또한 명사 '로맨티스트'를 '로', '맨', '티', '스트'로 쪼개어 결과를 낸 점도 아쉽습니다. 마지막으로 '우아함'을 '우아', '하-', '-ㅁ'이 아니라 '우', '아함'으로 분석한 부분도 문제삼을 만한 점입니다. - 영화/NNG, 가/JKC, 아니/VCN, 라/ECD, 영상/NNG, 으로/JKM, 예술/NNG, 을/JKO, 만들/VV, ㄴ/ETD, 작품/NNG, 이/VCP, 다/ECS, 지도/NNG, 소박/NNG, 하/XSV, ㄴ/ETD, 주제/NNG, 에/JKM, 숨/NNG, 이/JKS, 막히/VV, ㄹ/ETD, 듯/NNB, 한/MDN, 우/NNG, 아함/NNP, 이/VCP, 라니/EFQ - 옛날/NNG, sf/OL, 영화/NNG, 의/JKG, 장점/NNG, 이해/NNG, 하/XSV, 기/ETN, 쉽/VA, 고/ECE, 단순/NNG, 하/XSV, 며/ECE, 유쾌/XR, 하/XSA, 다/EFN - 내/VV, 게/ECD, 남/VV, 는/ETD, 것/NNB, 은/JKS, 슈퍼맨/NNG, 뿐/NNB, 이/VCP, 다/EFN, 잘생기/VV, ㄴ/ETD, 슈퍼맨/NNG, 완벽/NNG, 하/XSV, ㄴ/ETD, 로/NNG, 맨/NNG, 티/NNG, 스트/UN, 슈퍼맨/NNG, 별/NNG, 에서/JKM, 오/VV, ㄴ/ETD, 슈퍼맨/NNG, 굳이/MAG, 의미/NNG, 를/JKO, 더하/VV, 자면/ECE, 좋/VA, 은/ETD, 사람/NNG, 이랑/JC, 처음/NNG, 으로/JKM, 같이/MAG, 보/VV, ㄴ/ETD, 영화/NNG, 이/VCP, 라는/ETD, 거/NNB, 그러/VV, ㅁ에도/ECD, 도저히/MAG, 쉴드/UN, 를/JKO, 치/VV, ㄹ/ETD, 수/NNB, 없/VA, 을/ETD, 정도/NNG, 로/JKM, 노/NNG, 잼/NNG, 이/VCP, 었/EPT, 단/ETD, 것/NNB, 이/JKS, 아쉽/VA, ㄹ/ETD, 따름/NNB, 이/VCP, 다/EFN 아래는 코모란 태거의 분석 결과입니다. '이다지도'와 '우아함'을 잘 분석해냈습니다. 다만 '로맨티스트' 분석은 정확하지 않습니다. 또한 '좋은 사람'을 한 단어로 분석한 점이 걸리네요. - 영화/NNG, 가/JKS, 아니/VCN, 라/EC, 영상/NNG, 으로/JKB, 예술/NNG, 을/JKO, 만들/VV, ㄴ/ETM, 작품/NNG, 이다지/MAG, 도/JX, 소박/XR, 하/XSA, ㄴ/ETM, 주제/NNG, 에/JKB, 숨/NNG, 이/JKS, 막히/VV, ㄹ/ETM, 듯/NNB, 한/MM, 우아/XR, 하/XSA, ㅁ/ETN, 이/VCP, 라니/EC - 옛날/NNG, sf/SL, 영화/NNG, 의/JKG, 장점/NNG, 이해/NNG, 하/XSV, 기/ETN, 쉽/VA, 고/EC, 단순/XR, 하/XSA, 며/EC, 유쾌/XR, 하/XSA, 다/EC - 내/VV, 게/EC, 남/VV, 는/ETM, 건/NNB, 슈퍼맨/NNP, 뿐/NNB, 이/VCP, 다/EC, 잘생기/VA, ㄴ/ETM, 슈퍼맨/NNP, 완벽/NNG, 하/XSV, ㄴ/ETM, 로/NNG, 맨/XPN, 티스/NNP, 트/VV, 슈퍼맨/NNP, 별/NNG, 에서/JKB, 오/VV, ㄴ/ETM, 슈퍼맨/NNP, 굳이/MAG, 의미/NNG, 를/JKO, 더하/VV, 자면/EC, 좋은 사람/NNP, 이랑/JC, 처음/NNG, 으로/JKB, 같이/MAG, 보/VV, ㄴ/ETM, 영화/NNG, 이/VCP, 라는/ETM, 거/NNB, 그렇/VA, ㅁ/ETN, 에/JKB, 도/JX, 도저히/MAG, 쉴드/NNP, 를/JKO, 치/VV, ㄹ/ETM, 수/NNB, 없/VA, 을/ETM, 정도/NNG, 로/JKB, 노/NNG, 재/VV, ㅁ/ETN, 이/VCP, 었/EP, 단/ETM, 게/EC, 아쉽/VA, ㄹ/ETM, 따름/NNB, 이/VCP, 다/EC 마지막으로 트위터 태거의 분석 결과입니다. 용언 분석에 일관성이 다소 부족한게 아쉽습니다. 예컨대 '아니-', '쉽-' '좋-'의 경우 어간과 어미를 잘 분석한 걸 확인할 수 있습니다. 그러나 '만든', '소박한', '막힐', '우아함' 등은 어간과 어미가 결합된 채로 태깅이 됐네요. 뿐만 아니라 형용사 '유쾌하-'의 경우 그 품사가 명사로 잘못 분석된 점 또한 볼 수 있습니다. - 영화/Noun, 가/Josa, 아니/Adjective, 라/Eomi, 영상/Noun, 으로/Josa, 예술/Noun, 을/Josa, 만든/Verb, 작품/Noun, 이다지/Noun, 도/Josa, 소박한/Adjective, 주제/Noun, 에/Josa, 숨/Noun, 이/Josa, 막힐/Verb, 듯/Noun, 한/Verb, 우아함/Adjective, 이라니/Eomi - 옛날/Noun, sf/Alpha, 영화/Noun, 의/Josa, 장점/Noun, 이해하기/Verb, 쉽/Verb, 고/Eomi, 단순하며/Adjective, 유쾌하/Noun, 다/Josa - 내게/Verb, 남는/Verb, 건/Eomi, 슈퍼맨/Noun, 뿐/Noun, 이다/Josa, 잘생긴/Adjective, 슈퍼맨/Noun, 완벽한/Adjective, 로맨/Noun, 티스/Noun, 트/Noun, 슈퍼맨/Noun, 별/Noun, 에서/Josa, 온/Noun, 슈퍼맨/Noun, 굳이/Noun, 의미/Noun, 를/Josa, 더하자/Verb, 면/Eomi, 좋/Adjective, 은/Eomi, 사람/Noun, 이랑/Josa, 처음/Noun, 으로/Josa, 같이/Josa, 본/Verb, 영화/Noun, 라는/Josa, 거/Noun, 그럼/Adjective, 에도/Eomi, 도저히/Noun, 쉴드/Noun, 를/Josa, 칠/Noun, 수/Noun, 없/Adjective, 을/Eomi, 정도/Noun, 로/Josa, 노잼/Noun, 이었/Verb, 단/Noun, 게/Josa, 아쉬/Adjective, 울/PreEomi, 따름/Noun, 이다/Josa 각 분석기가 리뷰 1만건을 분석하는 데 걸린 시간은 아래 표와 같습니다. (실험 환경 : Intel i5-4690, 32GB RAM, Nvidia GTX-1080, MS Windows 10) |  구분  |  꼬꼬마  | 코모란  | 트위터 | | :-----: | :-----: | :----: | :---: | | 소요시간(초) | 160.434 | 13.152 | 9.815 |  ## 어떤 분석기를 써야할까? 말뭉치 종류나 상황에 따라 다른 분석기를 써야할 겁니다. 제 실험을 일반화해서 적용하기엔 무리가 있습니다. 다만 제 느낌상 아래와 같은 상황에 해당 분석기를 쓰면 좋을 것 같습니다. - 빠른 분석이 중요할 때 : **트위터** - 정확한 품사 정보가 필요할 때 : **꼬꼬마** - 정확성, 시간 모두 중요할 때 : **코모란** 가장 좋은 방법은 보유하고 있는 말뭉치 일부를 테스트용으로 형태소 분석을 해보는 것입니다. 아래 예제코드가 있으니 참고하시기 바랍니다. ```python import time from konlpy.tag import Kkma, Twitter, Komoran pos_taggers = [('kkma', Kkma()), ('twitter', Twitter()), ('Komoran', Komoran())] results = [] for name, tagger in pos_taggers:   tokens = []   process_time = time.time()   for text in texts:     tokens.append(tagger.pos(text))   process_time = time.time() - process_time   print('tagger name = %10s, %.3f secs' % (name, process_time))   results.append(tokens) ``` 
deepNLP␞ 딥러닝 기반 자연어처리 기법 연구가 봇물을 이루고 있습니다. 최근 연구트렌드를 정리한 페이퍼가 나와서 눈길을 끄는데요. 바로 아래 논문입니다. > *Young, T., Hazarika, D., Poria, S., & Cambria, E. (2017). [Recent Trends in Deep Learning Based Natural Language Processing.](https://arxiv.org/pdf/1708.02709) arXiv preprint arXiv:1708.02709.* 저자의 허락을 받아 한국어로 번역해 전문 게재합니다. 가급적 직역하고 용어는 한국어와 영어를 병기했습니다. 본 블로그에도 관련 내용이 있다면 '본 블로그' 표시를 하고 링크를 걸어두었습니다. 실력이 미천해 오역이 많을 텐데요(ㅠㅠ). 댓글이나 이메일로 의견 주시면 적극 수정 반영하겠습니다. 좀 더 쉬운 표현이나 내용 보완 제시도 환영입니다. 한번 업로드했다고 끝이 아니라 지속적으로 수정, 보완해나갈 예정입니다!  본 논문의 목차는 다음과 같습니다.  * 목차 {:toc}  ## Abstract 딥러닝 기법은 데이터의 계층적인 표현(hiarchical representation)을 학습하는 다층 레이어(multiple processing layer)를 사용한다. 그리고 딥러닝은 많은 도메인에서 최첨단(state-of-the-art) 결과를 내고 있다. 최근 다양한 모델 디자인과 기법들이 자연언어처리(Natural Language Processing) 분야에서 꽃피고 있다. 본 논문에서는 수많은 NLP 과제에 적용된 의미 있는 딥러닝 모델과 기법을 검토하고, 이들의 성취에 관해 자세히 설명한다. 또한 다양한 모델들을 비교, 대조함으로써 딥러닝 기반 NLP 기법의 과거, 현재, 미래에 대해 이해할 수 있도록 할 것이다.   ## 1. 서론 자연언어처리(NLP)는 인간 언어 분석과 표현(representation)을 자동화하기 위한 계산 기법이다. NLP 연구는 문장 하나 처리하는 데 7분이 소요되던 펀치 카드와 배치 과정(batch processing)의 시대로부터 1초만에 수백만 웹페이지를 처리할 수 있는 구글의 시대로 발전해왔다([Cambria and White, 2014](http://sentic.net/jumping-nlp-curves.pdf)). NLP는 컴퓨터로 하여금 파싱, 품사태깅에서부터 기계번역, 대화시스템에 이르기까지 모든 과업을 수행할 수 있도록 한다. 딥러닝 아키텍처와 알고리즘은 컴퓨터 비전과 패턴인식 같은 분야에서 이미 의미 있는 발전을 이뤘다. 이러한 경향이 나타난 이후, 최근 딥러닝 기법 기반의 NLP 연구가 늘고 있다(그림1).  <a href="http://imgur.com/2Tk7NzN"><img src="http://i.imgur.com/2Tk7NzN.png" width="400px" title="source: imgur.com" /></a> *그림1: 최근 6년 간 ACL, EMNLP, EACL, NAACL에 게재된 딥러닝 논문의 비율(%). (long paper 기준)* 지난 수십년간 NLP 문제를 풀기 위한 머신러닝의 접근은 고차원이면서 sparse한 피처(feature)를 학습한 '얕은 모델(shallow models, 예: SVM/로지스틱 회귀)'에 기반한 것이다. 최근 수 년간 dense vector representation에 기반한 뉴럴네트워크가 다양한 NLP task에서 우수한 성능을 보여줬다. 이러한 트렌드는 워드 임베딩(Milokov et al., [2010](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf), [2013a](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf))과 딥러닝 기법([Socher et al., 2013](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf))의 성공에 힘입은 것이다. 딥러닝은 자동화된 피처 추출 및 표현(multi-level automatic feature representation learning)을 가능하게 한다. 그러나 전통적인 머신러닝에 기반한 NLP 시스템은 사람이 직접 추출한(hand-crafted) 피처에 강하게 의존한다. 이러한 피처들은 추출하는 데 시간이 많이 소요되고 많은 경우 불완전하다. [Collobert et al.(2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)은 간단한 딥러닝 프레임워크를 제시했다. 이 프레임워크는 개체명인식(Named Entity Recognition, NER), 의미역결정(Semantic Role Labeling, SRL), 품사태깅(POS tagging) 같은 일부 NLP 태스크에서 최첨단 기법이다. 그 이후 수많은 복잡한 딥러닝 기반의 알고리즘이 어려운 NLP 문제를 풀기 위해 제안되었다. 우리는 콘볼루션 신경망(Convolutional Neural Network, CNN, [본 블로그](https://ratsgo.github.io/natural%20language%20processing/2017/03/19/CNN/)), 순환신경망(Recurrent Neural Network, RNN, [본 블로그](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)), 재귀신경망(Recursive Neural Network, Recursive NN, [본 블로그](https://ratsgo.github.io/deep%20learning/2017/04/03/recursive/)) 등 주요 딥러닝모델을 검토한다. 아울러 어텐션(attention) 매커니즘, 강화학습(reinforcement learning)과 심층생성모델(Deep generative model)에 대해서도 다룰 것이다. 우리가 아는 한, 오늘날 NLP 연구에 쓰이는 딥러닝 기법들을 일별하는 이런 작업은 최초다. [Goldberg(2016)](http://u.cs.biu.ac.il/~yogo/nnlp.pdf)은 튜토리얼 방식으로 deep NLP 기법을 소개하고, Word2Vec과 CNN 같은 distibutional semantics에 주로 초점을 맞춘다. 그의 논문에서 골드버그는 다양한 딥러닝 아키텍처를 논의하지 않았다. 우리는 이 논문이 deep NLP를 이해하려는 독자들에게 도움이 될 거라 믿는다. 이 논문의 구성은 다음과 같다. 섹션 2에서 우리는 세련된 딥러닝 모델의 근간이 되는 분산표상(distributed representation, [본 블로그](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/29/NNLM/))에 대해 논의한다. 다음으로 우리는 섹션 3, 4, 5에 제시된 다양한 NLP 과제에 쓰이는 CNN, RNN, Recursive NN을 소개한다. 우리는 섹션 6에서 NLP 문제에서의 강화학습 응용사례와 비지도학습 기반 문장 학습 기법의 발전에 대해 살펴볼 것이다. 섹션 7에서는 딥러닝 모델과 메모리 모듈 결합의 최근 트렌드를 소개한다. 섹션8에서는 표준적인 데이터셋에 대해 각 기법별 성능을 비교 검토한다.   ## 2. 분산표상 통계 기반의 자연어처리 기법(Statistical NLP)은 복잡한 자연어를 모델링하는 데 기본 옵션으로 부상했다. 그러나 초기에 이 기법은 악명 높은 '차원의 저주(curse of dimensionality)'로 어려움을 겪었다. 언어모델(Language model)은 결합확률 함수를 학습해야 했기 때문이다. 이 문제는 저차원 벡터공간에 존재하는 단어의 분산표상(distributed representation)을 학습하는 연구의 동기가 되었다([Bengio et al., 2003](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)).  ### A. 단어 임베딩 분산표상으로 표현된 벡터(Distributional vectors) 또는 단어 임베딩(Word Embedding, 그림 2)은 근본적으로는 distributional hypothesis([본 블로그](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/10/frequency/))를 전제로 한다. 이 가정은 비슷한 의미를 지닌 단어는 비슷한 문맥에 등장하는 경향이 있을 것이라는 내용이 핵심이다. 따라서 이 벡터들은 이웃한 단어의 특징을 잡아내고자 한다. 분산표상 벡터의 주된 장점은 이 벡터들이 단어 간 유사성을 내포하고 있다는 점이다. 코사인 유사도 같은 지표를 사용함으로써 벡터간 유사성을 측정할 수 있다. <a href="http://imgur.com/jIzcQVU"><img src="http://i.imgur.com/jIzcQVU.png" width="400px" title="source: imgur.com" /></a> *그림2: $D$차원 벡터로 표현된 단어 벡터. $V$를 전체 단어 수라고 할 때, $D$는 $V$보다 훨씬 작다.* 단어 임베딩은 딥러닝 모델의 첫번째 데이터 처리 계층에 자주 사용된다. 일반적으로, 단어 임베딩은 레이블이 없는 방대한 말뭉치에서 '보조적인 목적함수(예컨대 이웃단어로 중심단어를 예측한다, 각 단어벡터는 일반적인 문법적, 의미적 정보를 내포한다)'를 최적화함으로써 사전 학습된다(Mikolov et al., [2013b](https://arxiv.org/pdf/1301.3781.pdf), [a](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)). 단어 임베딩은 문맥 유사도를 잡아내는 데 효율적이라는 사실이 증명되었다. 또한 임베딩 벡터의 차원이 작은 덕분에 계산이 빠르고 효율적이다. 이러한 임베딩 벡터를 생성하는 모델은 수년 간 얕은(간단한) 뉴럴네트워크였다. 좋은 임베딩을 생성하는 데 있어 깊은 구조의 뉴럴네트워크가 필요하지 않았다. 그러나 딥러닝 기반의 NLP 모델은 언제나 이러한 임베딩 벡터를 활용해 단어, 구, 문장을 표현한다. 이는 사실 전통적인 단어 빈도수 기반의 모델과 딥러닝 기반의 모델 간의 가장 큰 차이점이다. 단어 임베딩은 NLP 문제의 광범위한 범위에서 최첨단(state-of-the-art) 결과를 이끌어냈다([Weston et al., 2011](http://www.thespermwhale.com/jaseweston/papers/wsabie-ijcai.pdf); [Socher et al., 2011a](http://ai.stanford.edu/~ang/papers/icml11-ParsingWithRecursiveNeuralNetworks.pdf); [Turney and Pantel, 2010](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/jair10.pdf)). 예컨대 [Glorot et al.(2011)](http://www.icml-2011.org/papers/342_icmlpaper.pdf)은 도메인 특성에 맞는 감성 분류를 위한 stacked denoisiong autoencoder 모델에 단어 임베딩을 사용했다. [Hermann and Blunsom(2013)](http://www.karlmoritz.com/_media/hermannblunsom_acl2013.pdf)은 단어 임베딩을 활용해 문장 합성을 학습하기 위한 combinatory categorial autoencoders를 제안했다. 이러한 광범위한 사용은 NLP 태스크를 수행하는 딥러닝 모델에서의 임베딩 효과와 중요성을 보여준다. 워드 임베딩은 주로 문맥(context)을 통해 학습된다. 1990년대에는 몇몇 연구의 발전(Dumais, 2004; [Elman, 1991](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.866&rep=rep1&type=pdf); [Glenberg and Robertson, 2000](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.134.9807&rep=rep1&type=pdf))이 분산의미론(distributional semantics) 연구의 기초를 세웠다. 이후 발전은 이러한 초기 업적의 변형들로써, 잠재디리클레할당(Latent Dirichlet Allocation, [Blei et al., 2003](https://endymecy.gitbooks.io/spark-ml-source-analysis/content/%E8%81%9A%E7%B1%BB/LDA/docs/Latent%20Dirichlet%20Allocation.pdf), [본 블로그](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/06/01/LDA/))과 같은 토픽 모델과 언어모델(Language models, [Bengio et al., 2003](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf))의 탄생을 이끌었다. 이러한 업적들은 표현학습(representation learning, [본 블로그](https://ratsgo.github.io/deep%20learning/2017/04/25/representationlearning/))의 토대를 마련했다. [Bengio et al.(2003)](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)은 단어의 분산표상을 학습하는 신경 언어모델(neural language model)을 제안했다(그림3, [본 블로그](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/29/NNLM/)).  <a href="http://imgur.com/0XHb4xE"><img src="http://i.imgur.com/0XHb4xE.png" width="400px" title="source: imgur.com" /></a> *그림3: [Bengio et al.(2003)](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)가 제시한 신경 언어모델. $C(i)$는 $i$번째 단어의 벡터이다.*  [Collbert and Weston(2008)](https://ronan.collobert.com/pub/matos/2008_nlp_icml.pdf)은 사전 학습된 단어 임베딩의 유용성을 처음 보여줬다. 그들은 현재 많은 연구의 기초를 형성하는 뉴럴네트워크 아키텍처를 제안했다. 이 연구는 또한 NLP 과제의 유용한 도구로서 단어 임베딩의 지위를 확립했다. 하지만 엄청난 인기를 끌고 있는 단어 임베딩 기법은 바로 [Milokov et al.(2013a)](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf), ([본 블로그](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/))이다. 이들은 고품질의 단어 벡터를 효율적으로 구축하기 위해 continous-bag-of-words(CBOW)와 skip-gram 모델을 제안했다. [Pennington et al.(2014)](http://www.aclweb.org/anthology/D14-1162)는 Word2Vec과는 달리 본질적으로 빈도 기반의 단어 임베딩 기법([본 블로그](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/09/glove/))이다. 우선 단어공기행렬(word co-occurrence count matrix)을 생성한 뒤 빈도 수를 정규화하고 로그 스무딩을 실시한다. 저차원 벡터를 얻기 위해 재구축 오차(reconstruction loss)를 최소화하는 방식으로 이 행렬을 factorize한다. 다음 장에서는 [Mikolov et al. (2013a)](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)이 제안한 Word2Vec 기법에 대해 설명한다.  ### B. Word2Vec 단어 임베딩은 CBOW와 skip-gram 모델을 제안한 Mikolov et al. ([2013b](https://arxiv.org/pdf/1301.3781.pdf), [a](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)) ([본 블로그](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/))에 의해 비약적인 발전을 이뤘다. CBOW는 $k$개만큼의 주변 단어가 주어졌을 때 중심 단어의 조건부확률을 계산한다. skip-gram 모델은 CBOW와 정반대로, 중심단어가 주어졌을 때 주변단어를 예측한다. 문맥에서 한 단어만 고려하는 CBOW 모델의 단순화한 버전을 생각해보자. 이는 기본적으로 바이그램 모델을 모사한 것이다. 그림4와 같이 CBOW 모델은 1개의 은닉층을 가진 simple fully connected neural network이다.  <a href="http://imgur.com/0sxat55"><img src="http://i.imgur.com/0sxat55.png" width="400px" title="source: imgur.com" /></a> *그림4: Word2Vec의 CBOW 모델([Mikolov et al., 2013b](https://arxiv.org/pdf/1301.3781.pdf))* 개별 단어 임베딩의 한가지 한계는 두개 이상의 단어(예: 'hot potato' 같은 숙어, 'Boston Globe' 같은 개체명)의 조합이 개별 단어 벡터의 조합으로 표현될 수 없다는 것이다. 이런 문제의 한 가지 해결책은 [Mikolov et al. (2013a)](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)에서 살펴본 바와 같이 동시등장단어(word coocurrence)에 기반한 구문을 식별하고 이들을 별도로 학습시키는 것이다. 보다 최근의 기법은 레이블이 없는 데이터로부터 n-gram 임베딩을 직접적으로 학습시키는 방법이다([Johnson and Zhang, 2015](https://arxiv.org/pdf/1504.01255.pdf)).  또다른 한계는 주변 단어의 작은 window 내에만 기반한 임베딩을 학습하는 데서 비롯된다. 때때로 good과 bad 같은 단어가 거의 같은 임베딩을 공유한다([Socher et al., 2011b](http://www.aclweb.org/anthology/D11-1014)). 이는 감성분석 같은 task에서는 문제가 된다([Wang et al., 2015a](http://www.aclweb.org/anthology/P15-1130)). 때로는 이러한 임베딩은 상반된 극성을 갖는 단어가 의미상 유사한 단어로 클러스터링된다. 이는 감성분석에 사용되는 다운스트림 모델이 이러한 대조적인 극성을 구별하지 못하게 만들어 성능 저하로 이어진다. [Tang et al. (2014)](http://ir.hit.edu.cn/~dytang/paper/sswe/14ACL.pdf)는 sentiment specific word embedding(SSWE)을 제안함으로써 이러한 문제를 해결했다. 그들은 임베딩을 학습하는 동안 손실함수에 정답 극성을 포함시켰다. 단어 임베딩에 대한 일반적인 주의사항은 임베딩이 사용된 어플리케이션에 크게 의존한다는 것이다. [Labutov and Lipson (2013)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.387.455&rep=rep1&type=pdf)은 단어 벡터를 재학습하여 현재 task space에 맞추기 위해 task specific embedding을 제안했다. 아무런 사전 지식없이 임베딩을 학습시키는 것은 많은 시간과 리소스를 필요로 하기 때문에 이는 매우 중요하다. [Mikolov et al. (2013b)](https://arxiv.org/pdf/1301.3781.pdf)는 negative sampling 기법을 제안함으로써 이 문제를 해결하려고 했다. 표1은 딥러닝 모델에 자주 사용되는 임베딩 프레임워크들을 나열한 것이다. | Framework    | Language | URL                   | | --------------- | -------- | ---------------------------------------- | | S-Space     | Java   | https://github.com/fozziethebeat/S-Space | | Semanticvectors | Java   | https://github.com/semanticvectors/   | | Gensim     | Python  | https://radimrehurek.com/gensim/     | | Pydsm      | Python  | https://github.com/jimmycallin/pydsm   | | Dissect     | Python  | http://clic.cimec.unitn.it/composes/toolkit/ |  ### C. 문자 임베딩 단어 임베딩은 문법적, 의미적 정보를 잡아낼 수 있다. 그러나 품사태깅이나 개체명인식 같은 태스크에서는 단어 내부의 형태 정보 또한 매우 유용하다. 문자 수준의 자연어이해(Natural Language Understanding) 시스템 구축은 어느 정도 관심을 끌고 있다([Kim et al., 2016](https://arxiv.org/pdf/1508.06615.pdf); [Dos Santos and Gatti, 2014](http://anthology.aclweb.org/C/C14/C14-1008.pdf); [Santos and Guimaraes, 2015](http://www.anthology.aclweb.org/W/W15/W15-3904.pdf); [Santos and Zadrozny, 2014](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.646.4491&rep=rep1&type=pdf)). 특정 NLP 태스크에 있어서는 형태적으로 복잡한 언어에 대한 개선된 결과가 보고된다. [Santos and Guimaraes (2015)](http://www.anthology.aclweb.org/W/W15/W15-3904.pdf)는 단어 임베딩과 함께 문자 수준 임베딩을 개체명인식 문제에 적용해 포르투갈어와 스페인어 말뭉치에서 state-of-the-art 수준의 결과를 냈다. [Kim et al. (2016)](https://arxiv.org/pdf/1508.06615.pdf)은 문자 임베딩만 사용한 neural language model을 구축해 긍정적인 결과를 보였다. [Ma et al. (2016)](http://www.cs.cmu.edu/~dyogatam/papers/yogatama+etal.acl2015short.pdf)은 개체명인식에서 사전 학습된 레이블 임베딩을 학습하기 위해 문자 trigram을 포함해 몇몇 임베딩 기법을 활용했다. 문자 임베딩은 미등재단어(the unknown word) 이슈에 자연스럽게 대처하게 된다. 단어는 개별 문자의 결합이기 때문이다. 텍스트가 단어뿐 아니라 문자의 결합으로 구성되고, 단어의 의미가 문자들의 합성에 대응되는 언어(예컨대 중국어)에서는, 문자 수준의 시스템 구축은 단어 분할(word segmentation)을 피하기 위한 자연스런 선택이다([Chen et al., 2015a](http://nlp.csai.tsinghua.edu.cn/~lzy/publications/ijcai2015_character.pdf)). 따라서 이런 언어에 딥러닝 기법을 적용하는 연구들은 단어보다 문자 임베딩을 선호하는 경향이 있다([Zheng et al., 2013](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.593.885&rep=rep1&type=pdf)). 예를 들면 [Peng et al. (2017)](http://sentic.net/radical-embeddings-for-chinese-sentiment-analysis.pdf)은 radical 기반의 처리가 감성 분류 성능을 크게 개선할 수 있음을 입증했다. 그들이 제안한 계층적 임베딩은 문자 수준의 의미뿐 아니라 감성 정보까지 포함한다.   ## 3. 콘볼루션 신경망 워드 임베딩이 인기를 끌고 그 성능 또한 검증된 이후, 단어 결합이나 n-gram으로부터 높은 수준의 피처를 추출해내는 효율적인 함수의 필요성이 증대됐다. 이러한 추상화된 피처들은 감성분석, 요약, 기계번역, 질의응답(QA) 같은 다양한 NLP 문제에 사용될 수 있다. 콘볼루션 신경망은 컴퓨터 비전 분야에서 뛰어난 성능으로 인해 자연스런 선택이었다([Krizhevsky et al., 2012](https://www.nvidia.cn/content/tesla/pdf/machine-learning/imagenet-classification-with-deep-convolutional-nn.pdf); [Sharif Razavian et al., 2014](http://www.csc.kth.se/~azizpour/papers/ha_cvpr14w.pdf); [Jia et al., 2014](http://ucb-icsi-vision-group.github.io/caffe-paper/caffe.pdf)). 문장 모델링에서 CNN을 활용하는 것은 [Colobert and Weston(2008)](https://ronan.collobert.com/pub/matos/2008_nlp_icml.pdf)로 거슬러 올라간다. 이 연구는 다범주 예측 결과를 출력하기 위해 multi-task learning을 사용했다. 품사태깅, 청킹, 개체명인식, 의미역결정, 의미적으로 유사한 단어 찾기, 랭귀지모델 같은 NLP 과제 수행을 위해서다. 참조테이블(look up table)은 각 단어를 사용자가 정의한 차원의 벡터로 변형해 사용된다. 따라서 $n$개의 단어로 이뤄진 입력문장 {$s_1, s_2, .., s_n$}은 참조테이블을 활용해 벡터들의 나열인 {$w_{s_1}, w_{s_2}, ..., w{s_n}$}으로 변환된다. (그림 5)  <a href="http://imgur.com/jiKkHc3"><img src="http://i.imgur.com/jiKkHc3.png" width="300px" title="source: imgur.com" /></a> *그림5: [Colobert and Weston(2008)](https://ronan.collobert.com/pub/matos/2008_nlp_icml.pdf)이 제안한 CNN 프레임워크. 그들은 단어 범주 예측에 이 모델을 사용했다* 이는 학습 과정에서 단어 벡터(가중치)가 학습되는 초기 단어 임베딩 기법의 아이디어로 생각할 수 있다. [Collobert et al. (2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)은 넘쳐나는 NLP 문제를 해결하기 위해 그의 이전 업적을 확장해 일반적인 CNN 기반의 프레임워크를 제안했다. [Colobert and Weston(2008)](https://ronan.collobert.com/pub/matos/2008_nlp_icml.pdf)과 [Collobert et al. (2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)은 NLP 연구자들 사이에 CNN이 큰 인기를 끌도록 촉발시켰다. CNN이 이미 컴퓨터 비전 태스크에서 괄목할 만한 성능을 보인 상황에서 사람들이 CNN의 성능을 믿는 것은 쉬웠다. CNN은 문장의 잠재적인 semantic represention을 만들어내기 위해 입력 문장으로부터 핵심적인 n-gram 피처를 추출하는 능력을 갖고 있다. 이 분야의 선구적인 업적은 [Collobert et al. (2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf), [Kalchbrenner et al. (2014)](http://www.aclweb.org/anthology/P14-1062), [Kim(2014)](http://www.aclweb.org/anthology/D14-1181)이다([본 블로그](https://ratsgo.github.io/natural%20language%20processing/2017/03/19/CNN/)). 이들은 후속 연구에서 CNN 기반의 네트워크가 크게 확산되도록 했다. 다음 장에서는 단순 CNN 기반 문장 모델링 네트워크의 작동을 설명한다.  ### A. CNN 기본구조 #### 1) 문장 모델링 문장의 $i$번째 단어에 해당하는 임베딩 벡터를 $w_i$, 임베딩 벡터의 차원수를 $d$라고 두자. $n$개 단어로 이뤄진 문장이 주어졌을 때, 문장은 $n$ x $d$ 크기의 임베딩 행렬로 표현할 수 있다. 그림 6은 CNN 프레임워크의 입력 문장을 나타낸다. <a href="http://imgur.com/1BEaoqD"><img src="http://i.imgur.com/1BEaoqD.png" width="400px" title="source: imgur.com" /></a> *그림6: 텍스트 처리를 위한 콘볼루션 신경망. [Zhang and Wallace(2015)](https://arxiv.org/pdf/1510.03820.pdf)* $w_i$, $w_{i+1}$, ..., $w_j$의 결합(concatenation)을 $w_{i:i+j}$라 두자. 콘볼루션은 이 값에 수행된다. 콘볼루션 필터 $k$는 차원수가 $hd$인 벡터이다. 이 필터는 $h$개 단어벡터에 적용된다. 예를 들면 콘볼루션 필터에 의해 새로 추출된 피처 $c_i$는 $w_{i:i+h-1}$를 활용해 생성된다. 식은 다음과 같다. $$ { c }_{ i }=f\left( { w }_{ i:i+h-1 }\cdot { k }^{ T }+b \right) $$  위 식에서 스칼라 $b$는 bias term이며 $f$는 하이퍼볼릭탄젠트 같은 비선형 활성함수이다. 필터 $k$는 피처맵을 생성하기 위해 동일한 가중치를 사용하며 모든 가능한 윈도우에 적용된다.   $$ c=\left[ { c }_{ 1 },{ c }_{ 2 },...,{ c }_{ n-h+1 } \right] $$  CNN에서 콘볼루션 필터(커널로 불리기도 한다)의 수는 전형적으로 수백개다. 필터의 폭은 각기 다르며, 각 필터는 n-gram의 특정 패턴을 추출한다. 콘볼루션 레이어는 대개 맥스풀링 계층, 즉 $\hat { c } =max(c)$이 후행한다. 맥스풀링은 $c$에 대해 최대값을 취함으로써 입력값을 서브샘플링한다. 이 전략을 쓰는 데는 두 가지 이유가 있다. 첫째, 맥스풀링은 일반적으로 분류에 필요한 고정 길이의 출력을 제공한다. 따라서 필터의 크기가 각기 다름에도 맥스풀링은 입력값을 항상 고정된 차원의 출력으로 매핑한다. 둘째, 맥스풀링은 전체 문장에서 가장 핵심적인 n-gram 피처를 유지하면서 출력의 차원을 줄인다. 이는 개별 필터가 문장 내 어느 지점에 있든 특정 피처(예를 들어 '부정')를 추출할 수 있고 이를 최종적인 문장 표현(representation)에 덧붙일 수 있기 때문에 변함없는 방식(invariant manner)으로 수행된다. 단어 임베딩은 랜덤 초기화하거나 레이블 없는 방대한 말뭉치에서 사전학습될 수 있다. 후자는 특히 정답 데이터의 양이 적을 때 성능 향상에 때로는 유용하다([Kim, 2014](http://www.aclweb.org/anthology/D14-1181), [본 블로그](https://ratsgo.github.io/natural%20language%20processing/2017/03/19/CNN/)). 콘볼루션 계층과 맥스풀링의 이런 조합은 보다 깊은 CNN 네트워크를 만들기 위해 종종 겹쳐 쌓게 된다. 이러한 sequential convolution은 풍부한 의미 정보를 포함하는 고도로 추상화된 표현을 잡아내 문장의 분석을 개선할 수 있도록 한다. 깊은 콘볼루션 구조의 필터(커널)은 문장 피처의 전체 요약을 만들기까지 문장의 넓은 부분을 커버하게 된다.  #### 2) 윈도우 접근법 지금까지 기술한 CNN 아키텍처는 완전한 자연어 문장을 벡터로 표현한다. 그러나 개체명인식, 품사태깅, SRL 같은 많은 NLP 문제는 단어 단위의 예측이 필요하다. 이런 태스크에 CNN을 적용하기 위해, 윈도우(window) 접근법이 쓰인다. 이는 단어의 범주(tag)가 기본적으로 이웃 단어에 의존할 것이라고 가정한다. 따라서 각 단어에 대해, 고정된 크기의 윈도우가 가정되고, 윈도우 내에 있는 하위 문장들이 고려된다. 독립형(standalone) CNN은 앞서 설명한 바와 같이 이러한 하위 문장에 적용되며 예측은 윈도우 중심에 있는 단어에 기인한다. 이러한 접근에 따라, [Poria et al. (2016a)](http://sentic.net/aspect-extraction-for-opinion-mining.pdf)는 문장 각 단어에 aspect[^1] 혹은 non-aspect 태그를 붙이기 위해 multi-level deep CNN을 제안했다. 언어적 패턴의 셋과 결합되어 이들의 앙상블 분류기는 aspect detection에 있어 좋은 성능을 냈다. 단어 수준 분류의 주요 목표는 일반적으로 전체 문장에 레이블 시퀀스(sequence)를 할당하는 것이다. Conditional Random Field(CRF) 같은 구조화된 예측 기법은 때때로 인접한 클래스 레이블 간의 의존성을 더 잘 포착한다. 그리고 이 기법은 결국 전체 문장에 최대 스코어를 내는 결합된(cohesive) 레이블 시퀀스를 생성한다([Kirillov et al., 2015](https://arxiv.org/pdf/1511.05067.pdf)). 문맥적 범위를 넓히기 위해, 전통적인 윈도우 접근법은 종종 time-dealy neural network(TDNN)와 결합된다([Waibel et al., 1989](http://www.cs.toronto.edu/~fritz/absps/waibelTDNN.pdf)). 여기에서 콘볼루션은 시퀀스 전체의 모든 윈도우에서 수행된다. 이런 콘볼루션들은 일반적으로 필터의 폭이 사전에 정의된다는 점에서 제약을 받는다. 따라서 전통적인 윈도우 접근법은 레이블이 달린 단어 주변의 윈도우에 있는 단어들만 고려하는 반면, TDNN은 문장 내 모든 윈도우들을 동시에 고려한다. 때때로 TDNN 레이어는 CNN 아키텍처처럼 쌓아져(stack) 하위 계층에서 로컬 피처, 상위 계층에서 글로벌 피처를 추출한다([Collobert et al., 2011](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)).  ### B. CNN 어플리케이션 이 장에서는 NLP 문제에 CNN을 적용한 주요 연구를 소개한다. [Kim(2014)](http://www.aclweb.org/anthology/D14-1181)는 감성, 주관성, 질문유형 분류를 포함한 다양한 문장 분류 문제에 이미 기술한 아키텍처를 실험했다. 이 연구는 간단하지만 효율적인 네트워크여서 아마추어 연구자들에 의해 빠르게 적용되었다([본 블로그](https://ratsgo.github.io/natural%20language%20processing/2017/03/19/CNN/)). 특정 과업 학습 후 랜덤하게 초기화된 콘볼루션 필터는 목적하는 태스크에 유용한 특정한 n-gram 피처 감지기(detector)가 됐다(그림7). 그러나 [Kim(2014)](http://www.aclweb.org/anthology/D14-1181)의 아키텍쳐는 장거리 의존성(long distance dependencies)을 모델링할 수 없는 등 많은 단점을 지닌다. <a href="http://imgur.com/yCQbgIl"><img src="http://i.imgur.com/yCQbgIl.png" width="400px" title="source: imgur.com" /></a> *그림7: 7-gram 필터(커널)로 학습된 고빈도 7-gram. 각 필터는 특정 종류의 7-gram에 민감하다. [Kim(2014)](http://www.aclweb.org/anthology/D14-1181)* 이러한 이슈는 [Kalchbrenner et al.(2014)](http://www.aclweb.org/anthology/P14-1062)에 의해 효과적으로 처리된다. 이들은 문장의 의미를 모델링하기 위한 dynamic convolutional neural network(DCNN)을 제안했다. 이들은 dynamic k max pooling 전략을 제안했다. 이는 시퀀스 $p$가 주어졌을 때 가장 활동적인(active) $k$개의 피처를 뽑는 방법이다. 선택은 피처의 순서를 보존하지만, 특정 위치에는 민감하지 않다(그림8).  <a href="http://imgur.com/WDVOZIH"><img src="http://i.imgur.com/WDVOZIH.png" width="400px" title="source: imgur.com" /></a> *그림8: DCNN의 서브그래프. dynamic k max pooling을 사용하면 상위 계층의 작은 너비의 필터가 입력문장에서 관계된 구문을 멀리 떨어뜨릴 수 있다. [Kalchbrenner et al.(2014)](http://www.aclweb.org/anthology/P14-1062)* [Kalchbrenner et al.(2014)](http://www.aclweb.org/anthology/P14-1062)는 문장 모델을 만들기 위해 TDNN의 개념을 기반으로 dynamic k max pooling 전략을 추가했다. 둘의 조합은 작은 폭의 필터가 입력문장의 긴 범위를 커버할 수 있게 한다. 그림8에서 상위의 피처는 집중적이고 짧거나, 전역적이고 입력문장처럼 길 수도 있는 매우 가변적인 범위를 가진다. 이들은 감성 분류, 질의 유형 분류를 포함한 다양한 task에 이 네트워크를 적용했고, 의미있는 결과를 얻었다. 요컨대 이 연구는 문맥적 의미를 모델링하는 데 있어 개별 필터의 범위(range)에 대해 언급했고, 필터의 도달 범위를 확장하는 방법론을 제안했다. 감성분석 문제는 또한 극성(polarity)에 관계된 aspect[^1]의 효과적인 추출을 필요로 한다([Mukerjee and Liu, 2012](https://www.cs.uic.edu/~liub/publications/ACL-2012-aspect-extraction.pdf)). [Ruder et al. (2016)](https://www.aclweb.org/anthology/S/S16/S16-1053.pdf)은 좋은 결과를 얻기 위해 워드 임베딩과 aspect vector를 결합한(concatenate) 값을 입력으로 하는 CNN을 적용했다.  CNN은 텍스트 길이에 따라 성능이 달라진다. 이런 상이함은 Johnson and Zhang(2015)와 같은 많은 연구에 나타난다. 장문의 텍스트에 대한 CNN 모델의 성능은 좋았던 반면 짧은 텍스트에선 반대였다. [Wang et al.(2015b)](http://www.aclweb.org/anthology/P15-2058)는 짧은 텍스트의 표현(representation)을 모델링하는 데 CNN을 제안했다. 저자들은 단문의 외부적 지식이 사용된 multi-scale semantic units를 도입한 의미론적 클러스터링(semantic clustering)을 제안했다. CNN은 이러한 유닛들을 결합하고 전체적인 표현(represention)을 만들어내는 데 쓰인다.  사실 고도의 문맥정보에 대한 이러한 요구는 CNN 기반 모델에 대한 경고(caveat)로 생각될 수 있다. CNN 기반 모델을 사용해 단문을 분석하는 작업은 추가적인 정보와 외부 지식을 필요로 한다. 이런 사실은 [Poria et al.(2016)](https://arxiv.org/pdf/1610.08815.pdf)에서도 관찰된다. 저자들은 CNN 네트워크를 활용해 트위터 텍스트에서 빈정대는 부분을 찾아내는 기법(sarcasm detection)을 제안했다. 감정, 감성, 개성 데이터셋으로 사전 학습된 형태의 보조적인 지원이 state-of-the-art 성능을 이끌어내는 데 사용됐다. CNN은 또한 다른 task에서도 널리 쓰인다. 예를 들면 [Denil et al. (2014)](https://arxiv.org/pdf/1406.3830.pdf)는 요약을 위해 문장을 구성하는 단어의 의미를 문서의 의미로 매핑시키는 데 DCNN을 적용했다. 이 연구의 핵심은 학습과정뿐 아니라 텍스트의 자동요약을 위한 인사이트를 제공하는 새로운 시각화 기술의 도입에 있다. QA 분야에서는 [Yih et al. (2014)](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/SingleRelationQA-YihHeMeek-ACL14.pdf)가 질의에 답할 때 지식베이스(Knowledge Base)에서 어떤 사실을 찾아봐야 하는지 결정하기 위해 질의와 KB 사이의 의미적 유사성을 측정하는 방안을 제시했다. 의미론적 표현(semantic representation)을 생성하기 위해, 그림6에 있는 CNN과 유사한 CNN이 사용됐다. 분류 문제를 풀기 위한 세팅과 달리, 정답셋으로는 클래스 레이블 대신 긍정 혹은 부정적인 텍스트 쌍을 쓴다(예: 쿼리-문서).  이후 [Dong et al. (2015)](http://www.aclweb.org/anthology/P15-1026)는 다중 aspect[^1]로부터 질의를 분석하고 이해하는 한편 질의의 표현(representation)을 만들기 위한 multi-column CNN(MCCNN)을 소개했다. MCCNN은 입력 질의에서 응답 유형과 문맥을 구성하는 aspect로부터 정보를 추출하기 위해 다수의 column network를 쓴다. KB의 개체(entities)와 관계를 벡터로 표현함으로써, 그들은 후보가 되는 응답에 순위를 매기기 위하여 질의-응답 쌍을 사용하여 CNN 모델을 학습시켰다. [Severyn and Moschitti(2016)](https://arxiv.org/pdf/1604.01178.pdf)은 또한 CNN 네트워크를 질의와 응답 문장의 최적 표현(representation)을 모델링하는 데 사용했다. 그들은 질의와 응답 쌍 사이에 단어를 매칭시킴으로써 임베딩에서 추가적인 피처를 제안했다. 이러한 파라메터들은 네트워크에 의해 튜닝된다. 이런 간단한 네트워크는 state-of-the-art 성능을 내는 기법에 필적하는 결과를 산출할 수 있었다. CNN 모델은 또한 분류를 넘어서는 의미론적 일치(semantic matching)가 필요한 특정 NLP 태스크에도 적합하다([Hu et al., 2014](https://papers.nips.cc/paper/5550-convolutional-neural-network-architectures-for-matching-natural-language-sentences.pdf)). 그림 6의 CNN 아키텍처와 비슷한 모델이 정보 검색을 목적으로 [Shen et al. (2014)](http://www.iro.umontreal.ca/~lisa/pointeurs/ir0895-he-2.pdf)에 의해 탐색되었다. CNN은 질의와 문서를 고정된 차원의 의미공간에 투영(project)하는 데 사용된다. 이 의미공간에서는 쿼리와 문서 간 코사인 유사도가 특정 쿼리에 해당하는 문서의 랭킹을 매기는 데 쓰인다. 모델은 단어 시퀀스에서의 일시적인 context window를 고려함으로써 쿼리나 문서에서의 풍부한 문맥 구조 추출을 시도한다. 이 모델은 n-gram 수준에서의 문맥 피처를 잡아낸다. 그리고 나서 핵심 n-gram은 전체를 아우르는 문장 벡터를 형성하기 위해 결합(aggregate)되는 콘볼루션과 맥스풀링 계층에 의해 발견된다.  CNN은 문장에서 가장 중요한 정보를 뽑기 위한 방법과 연결되어 있다. 그러나 기존의 맥스풀링 전략은 문장에서 가치 있는 정보를 종종 잃어버린다. 다중 이벤트 모델링(multiple-event modeling)에서 이러한 정보 손실 문제를 극복하기 위해, [Chen et al. (2015b)](https://pdfs.semanticscholar.org/ca70/480f908ec60438e91a914c1075b9954e7834.pdf)는 수정된 풀링 전략, 즉 dynamic multi-pooling CNN(DMCNN)을 제안했다. CNN은 본질적으로 로컬 연결성(local connectivity), 가중치 공유, 풀링 등의 특징이 있다. 이러한 속성은 많은 task에서 고도로 요구되는 불변성(invariance)을 어느 정도 보장한다. 음성 인식 또한 이러한 불변성을 필요로 한다. 이 때문에 [Abdel-Hamid et al. (2014)](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CNN_ASLPTrans2-14.pdf)는 하이브리드 CNN-HMM 모델을 사용했다. 이 변동성은 종종 화자 차이에 기인한 음성 신호에서 종종 발견된다. [Abdel-Hamid et al. (2014)](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CNN_ASLPTrans2-14.pdf)는 또한 파라메터를 줄여 계산복잡성을 낮췄다. [Palaz et al. (2015)](https://ronan.collobert.com/pub/matos/2015_cnnspeech_interspeech.pdf)는 CNN 기반의 음성 인식 시스템에 대한 집중적인 분석을 수행했다. 그들은 원시 입력(raw input)과 음성(phone) 사이의 관계를 직접적으로 모델링하는 CNN의 능력을 입증했고, 강건한(robust) 자동 스피치 인식 시스템을 만들어냈다. 기계번역 같은 작업에는 순차적인 정보와 장기 의존성에 대한 인내(perseverance)가 필요하다. 따라서 구조적으로 이러한 작업들은 이러한 피처들을 잃어버리는 CNN 네트워크에 적합하지 않다. 그럼에도 [Tu et al. (2015)](http://www.aclweb.org/anthology/P15-2088)는 번역 쌍들 간 의미적 유사성과 번역대상 문장의 문맥을 모두 고려해 이 문제를 다뤘다. 비록 이 방법은 시퀀스 인내 문제를 다루지는 않지만, 다른 벤치마크 연구들과 비교해 견줄 만한 결과를 냈다. 전반적으로, CNN은 contextual window 내에 있는 의미적 단서를 추출하는 데 고도로 효율적이다. 그러나 CNN은 매우 많은 데이터를 필요로 한다. CNN 모델은 방대한 양의 데이터를 요구하는 다수의 학습 파라메터를 포함한다. CNN은 데이터가 부족할 때는 문제가 된다. CNN의 다른 이슈는 먼 거리의 문맥 정보를 모델링하기가 불가능하고 그들의 표현(repesentation)에서 시퀀셜한 순서를 보존할 수 없다는 것이다. 문장 모델링의 [Kalchbrenner et al. (2014)](http://www.aclweb.org/anthology/P14-1062), 기계번역의 [Tu et al. (2015)](http://www.aclweb.org/anthology/P15-2088)가 약간 다뤄지긴 했지만, 이 문제는 여전히 중요한 이슈로 남아있다. 따라서 Recursive NN과 같은 네트워크가 이런 학습에 적합하다.   ## 4. Recurrent Neural Networks Recurrent Neural Network([Elman, 1990](http://psych.colorado.edu/~kimlab/Elman1990.pdf))는 순차적인 정보를 처리하는 네트워크다([본 블로그](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)). 전통적인 뉴럴 네트워크와 달리, RNN은 모든 입력값이 독립적이라고 가정한다. 'recurrent'라는 용어는 모델이 입력 시퀀스의 각 인스턴스에 대해 같은 작업을 수행하고 아웃풋은 이전 연산및 결과에 의존적이라는 데에서 붙었다. 일반적으로 recurrent unit에 토큰을 하나씩 입력함으로써 고정 크기의 벡터가 시퀀스를 표현하기 위해 생성된다. 이런 방식으로 RNN은 이전 연산결과를 '기억'하고, 현재 연산 과정에서 이 정보를 활용한다. 이러한 템플릿은 랭귀지 모델링(Mikolov et al., [2010](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf), [2011](https://github.com/yihui-he/Natural-Language-Process/blob/master/Extensions%20of%20recurrent%20neural%20network%20language%20model.pdf); [Sutskever et al., 2011](http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf)), 기계번역([Liu et al., 2014](http://www.aclweb.org/anthology/P14-1140.pdf); [Auli et al., 2013](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/EMNLP2013RNNMT.pdf); [Sutskever et al., 2014](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)), 음성인식([Robinson et al., 1996](http://www.cstr.ed.ac.uk/downloads/publications/1996/rnn4csr96.pdf); [Graves et al., 2013](https://arxiv.org/pdf/1303.5778.pdf); [Graves and Jaitly, 2014](https://arxiv.org/pdf/1701.02720.pdf); [Sak et al., 2014](https://arxiv.org/pdf/1402.1128.pdf)), 이미지 캡셔닝([Karpathy and Fei-Fei, 2015](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf)) 등과 같은 많은 NLP 작업에 적합하다. 이로 인해 최근 수년 간 NLP 어플리케이션에 RNN이 널리 보급됐다.  ### A. RNN 필요성 이번 장에서 우리는 수많은 NLP 태스크에서 인기를 끌고 있는 RNN의 기본 속성에 대해 살펴본다. RNN은 데이터를 순차적으로 처리하기 때문에, 언어에서 고유한 순차적인 성격을 포착할 수 있는 능력이 있다. 단어는 이전 단어를 바탕으로 의미를 갖게 된다. 이와 관련한 간단한 예시는 'dog'와 'hot dog' 간의 의미 차이일 것이다. RNN은 이러한 문맥 의존성을 모델링하기 위해 만들어졌으며 연구자들이 CNN보다 RNN을 사용하는 강한 동기가 되었다. RNN이 시퀀스 모델링에 적합한 다른 요인은 매우 긴 문장, 단락, 심지어 문서([Tang et al., 2015](http://aclweb.org/anthology/D15-1167))를 포함해 다양한 텍스트 길이를 모델링할 수 있는 능력이다. CNN과 달리 RNN은 무제한 컨텍스트를 포착할 수 있는 유연한 계산 step을 가진다. 임의의 길이의 입력값을 처리할 수 있는 이러한 능력은 RNN을 사용하는 주요 연구의 셀링포인트 가운데 하나가 됐다([Chung et al., 2014](https://arxiv.org/pdf/1412.3555.pdf)). 다수의 NLP 태스크는 또한 전체 문장에 대해 의미론적 모델링을 요구한다. 이것은 고정된 차원의 하이퍼스페이스 내에 문장의 요지(gist)를 만들어내는 것과 관련이 있다. 이들 인스턴스는 RNN에 의해 적절히 포착된다. 전체 문장이 고정된 벡터로 요약되고 나서 가변 길이의 타겟 시퀀스로 매핑되는 기계번역([Cho et al., 2014](https://arxiv.org/pdf/1406.1078.pdf)) 같은 작업에 RNN 사용이 증가했다. RNN은 또한 시간 분산 조인트 처리(time distributed joint processing)를 위한 네트워크 지원을 제공한다. 품사태깅([Santos and Zadrozny, 2014](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.646.4491&rep=rep1&type=pdf)) 같은 시퀀스 레이블링 작업의 대부분은 이러한 domain에 기반한 것이다. 보다 구체적인 사용사례는 문서분류([Chaturvedi et al., 2016](http://dl.acm.org/citation.cfm?id=2989708)), 다범주 텍스트 범주화([Chen et al., 2017](http://sentic.net/convolutional-and-recurrent-neural-networks-for-text-categorization.pdf)), 멀티모달 감성분석([Poria et al., 2017](http://sentic.net/context-dependent-sentiment-analysis-in-user-generated-videos.pdf); [Zadeh et al., 2017](https://arxiv.org/pdf/1707.07250.pdf); [Tong et al., 2017](https://arxiv.org/pdf/1705.02735.pdf)), 주관성 디텍션([Chaturvedi et al., 2017](http://www.sciencedirect.com/science/article/pii/S0016003217303009)) 등이 있다. 이미 서술한 사실들은 연구자들이 RNN을 선택하는 동기가 되는 몇가지 이유다. 그러나 RNN이 다른 네트워크보다 우월하다고 결론을 내리는 것은 잘못된 것이다. 최근에 여러 연구는 CNN이 RNN보다 우월하다는 증거를 제시한다. 언어모델링(Langurage modeling) 같은 RNN에 적합한 태스크일지라도, CNN은 RNN보다 경쟁력 있는 성능을 달성했다([Dauphin et al., 2016](https://arxiv.org/pdf/1612.08083.pdf)). CNN과 RNN은 문장을 모델링할 때 다른 목적(함수)를 갖는다. RNN이 경계없는 긴 문장을 생성하려고 하는 반면, CNN은 가장 중요한 n-gram을 추출하려고 한다. 둘다 n-gram 피처를 잡아내는 데 효율적이지만, 단어 순서에 대한 민감도가 지역적으로(locally) 제한되며 장기(long-term) 의존성은 보통 무시된다. [Yin et al. (2017)](https://arxiv.org/pdf/1702.01923.pdf)은 RNN과 CNN 성능에 관한 흥미있는 인사이트를 제시한다. 감성분류, QA, 품사태깅을 포함하는 여러 NLP task를 평가한 후에 그들은 '완전한 승자는 없다'고 결론 내렸다. 각 네트워크의 성능은 태스크가 요구하는 글로벌 시맨틱(global semantics)에 의존한다. 아래에서는 최근 연구에서 광범위하게 사용되는 RNN 모델 중 일부에 대해 설명한다.  ### B. 네트워크 구조 #### 1) RNN 기본 구조 <a href="http://imgur.com/6kjGKVJ"><img src="http://i.imgur.com/6kjGKVJ.png" width="400px" title="source: imgur.com" /></a> *그림9: 간단한 RNN 구조* NLP의 맥락에서 RNN은 주로 Elman network([Elman, 1990](http://psych.colorado.edu/~kimlab/Elman1990.pdf))에 기반을 두고 있으며 원래는 3개 계층으로 이뤄진 네트워크다([본 블로그](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)). 그림 9는 일반적인 RNN을 나타낸다. 그림에서 $x_t$는 $t$시점의 입력값이며, $s_t$는 $t$ 시점의 히든 스테이트(hidden state)를 나타낸다. $s_t$ 계산은 다음 식과 같다.  $$ { s }_{ t }=f\left( U{ x }_{ t }+W{ s }_{ t-1 } \right) $$  $s_t$는 현재 입력 및 이전 단계의 히든 스테이트를 기반으로 계산된다. 함수 $f$는 하이퍼볼릭탄젠트, ReLU와 같은 비선형 변환이며 $U, V, W$는 모든 시점에서 공유된다. NLP의 맥락에서 $x_t$는 일반적으로 one-hot 벡터 또는 임베딩 벡터다. $x_t$는 때때로 텍스트가 추상적으로 표현된 벡터일 수도 있다. $o_t$는 네트워크의 출력이다. RNN의 히든 스테이트는 일반적으로 가장 중요한 요소로 간주된다. 앞서 언급했듯이 히든 스테이트는 다른 time step의 정보를 누적한 네트워크의 메모리 요소로 간주될 수 있다. 그러나 실제에선 이러한 간단한 RNN 네트워크는 악명 높은 배니싱 그래디언트 문제(Vanishing gradient problem)로 인해, 네트워크에서 이전 레이어의 파라메터를 학습하고 업데이트하는 걸 매우 어렵게 만든다. 이러한 제한은 LSTM, GRU 및 ResNet과 같은 다양한 네트워크에 의해 극복되었다.  #### 2) Long Short-Term Memory LSTM([Hochreiter and Schmidhuber, 1997](http://www.bioinf.jku.at/publications/older/2604.pdf); [Gers et al., 1999](https://pdfs.semanticscholar.org/1154/0131eae85b2e11d53df7f1360eeb6476e7f4.pdf), 그림 10)은 간단한 RNN에 forget gate를 추가했다. 이러한 독특한 매커니즘을 통해 배니싱 그래디언트 문제, 익스플로딩 그래디언트 문제(exploding gradient problem_를 모두 극복할 수 있다([본 블로그](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)). <a href="http://imgur.com/NV7jQ0X"><img src="http://i.imgur.com/NV7jQ0X.png" width="400px" title="source: imgur.com" /></a> *그림10: LSTM과 GRU 게이트. [Chung et al.(2014)](https://arxiv.org/pdf/1412.3555.pdf)* vanilla RNN과 달리 LSTM을 사용하면 오차가 무제한적인 time step에 역전파될 수 있다. 3개의 gate, 즉 input/forget/output gate로 구성되며 히든 스테이트는 아래 식에 따라 계산된다.  $$ x=\begin{bmatrix} { h }_{ t-1 } \\ { x }_{ t } \end{bmatrix}\\ { f }_{ t }=\sigma \left( { W }_{ f }\cdot x+{ b }_{ f } \right) \\ { i }_{ t }=\sigma \left( { W }_{ i }\cdot x+{ b }_{ i } \right) \\ o_{ t }=\sigma \left( { W }_{ o }\cdot x+{ b }_{ o } \right) \\ { c }_{ t }={ f }_{ t }\odot { c }_{ t-1 }+{ i }_{ t }\odot \tanh { ({ W }_{ c }\cdot x+{ b }_{ c }) } \\ { h }_{ t }={ o }_{ t }\odot \tanh { ({ c }_{ t }) } $$ #### 3) Gated Recurrent Units GRU([Cho et al., 2014](https://arxiv.org/pdf/1406.1078.pdf))라 불리는 RNN의 변형은 대부분의 task에서 LSTM과 경험적으로 유사한 성능을 내면서 구조적으로는 더 간단하다([본 블로그](https://ratsgo.github.io/deep%20learning/2017/05/13/GRU/)). GRU는 reset gate와 update gate의 두 개 gate로 구성되며 LSTM처럼 메모리를 보호한다. GRU는 LSTM보다 효율적인 RNN이 될 수 있다. GRU의 작동은 다음과 같다.  $$ z=\sigma \left( { U }_{ z }\cdot { x }_{ t }+{ W }_{ z }{ h }_{ t-1 } \right) \\ r=\sigma \left( { U }_{ r }\cdot { x }_{ t }+{ W }_{ r }{ h }_{ t-1 } \right) \\ { s }_{ t }=\tanh { ({ U }_{ z }\cdot { x }_{ t }+{ W }_{ s }\cdot ({ h }_{ t-1 }\odot r)) } \\ { h }_{ t }=(1-z)\odot { s }_{ t }+z\odot { h }_{ t-1 } $$  연구자들은 종종 적절한 RNN 게이트를 선택해야하는 딜레마에 직면한다. 이는 NLP분야를 연구하는 사람들도 마찬가지다. 역사를 통틀어 RNN 변형에 대한 대부분의 선택은 heuristic한 경향을 보였다. [Chung et al. (2014)](https://arxiv.org/pdf/1412.3555.pdf)는 NLP task가 아니지만, 위에서 언급한 세 가지 RNN 변형들에 대한 비판적 비교 평가를 수행했다. 그들은 다성 음악 모델링 및 음성 신호 모델링과 관련된 task 성능을 평가했다. 그들의 평가는 전통적인 단순 RNN(하이퍼볼릭탄젠트 사용)에 비해 gated unit(LSTM, GRU)의 우월성을 분명히 보여주었다(그림 11). 그러나 이들은 LSTM과 GRU 가운데 어느 것이 더 좋은지에 대해선 구체적인 결론을 내릴 수 없었다. 이러한 사실은 다른 연구에서도 잘 나타나므로, 사람들은 둘 중 하나를 선택할 때 컴퓨팅 파워 같은 다른 요소를 고려하는 경우가 종종 있다. <a href="http://imgur.com/UscN9NJ"><img src="http://i.imgur.com/UscN9NJ.png" title="source: imgur.com" /></a> *그림11: 반복횟수와 계산시간과 관련한 학습곡선들. y축은 로그 스케일로 나타낸 모델의 음의 로그우도에 해당한다. [Chung et al. (2014)](https://arxiv.org/pdf/1412.3555.pdf)*  ### C. 어플리케이션 #### 1) 단어 수준 분류를 위한 RNN RNN은 단어 수준 분류에서 많이 쓰이고 있다. 이런 인기는 RNN의 state-of-the-art 수준의 성능 덕분이다. [Lample et al., (2016)](https://arxiv.org/pdf/1603.01360.pdf)은 개체명인식을 위한 bidirectional LSTM 모델을 제안했다. 네트워크는 타겟 단어 주변의 임의의 긴 맥락 정보를 포착해 두 개의 고정된 크기의 벡터를 반환한다. 그 위에 또 하나의 fully-connected 레이어가 있다. 그들은 최종 개체명 태깅에 CRF 레이어를 썼다. RNN은 또한 언어모델링(Language modeling) 면에서 빈도 기반의 기존 방법론보다 상당한 개선을 보여줬다. 이 분야 주목할 만한 연구는 [Graves(2013)](https://arxiv.org/pdf/1308.0850.pdf)이다. 그는 긴 범위의 문맥 구조에서 복잡한 시퀀스를 모델링하는 데 RNN이 효율적임을 보여줬다. 그는 또한 은닉층이 여러 개인 deep RNN을 제안했다. 이 연구는 NLP를 넘어선 태스크에도 RNN의 사용을 확립시켰다. 이후 [Sundermeyer et al. (2015)](https://www.lsv.uni-saarland.de/fileadmin/teaching/seminars/ASR-2015/DL-Seminar/From_Feedforward_to_Recurrent_LSTM_Neural_Networks_for_Language_Modeling.pdf)은 뒷 단어 예측시 feed-forward neural network를 RNN으로 대체함으로써 얻는 이득을 비교했다. 이 연구에서 그들은 기존의 빈도 기반의 언어모델보다 성능이 대폭 향상된 뉴럴 네트워크 아키텍처에서 일반적인 계층구조를 제안했다. 그들이 언급한 중요한 점은 이것이 통계적 기계번역과 같은 다양한 다른 업무에 적용 가능하다는 사실이다([Sundermeyer et al., 2014](https://www-i6.informatik.rwth-aachen.de/publications/download/936/SundermeyerMartinAlkhouliTamerWuebkerJoernNeyHermann--TranslationModelingwithBidirectionalRecurrentNeuralNetworks--2014.pdf)). [Kim et al. (2016)](https://arxiv.org/pdf/1508.06615.pdf)과 [Lample et al. (2016)](https://arxiv.org/pdf/1603.01360.pdf)은 형태적(morphological) 정보를 포함한는 문자 기반의 표현(representation) 사용을 탐색했다. 베이스라인인 단어 기반의 LSTM 모델보다 나은 성능을 나타낸다는 점에서, 문자 기반의 모델이 문자로부터 의미, 철자(orthographic) 정보 모두를 추출할 수 있다는 걸 보여준다. 문자 기반 모델링은 러시아어, 중국어 같이 형태가 복잡한 텍스트에서 강화된 입력값 정보를 제공한다. 아울러 문자들은 방대한 말뭉치를 요구하는 단어와 달리 보통 훨씬 작은 입력공간에 존재한다. 그러나 단어 기반의 처리가 우세한 분야가 많다. 따라서 이 분야에서 확실한 승자는 아직 모른다.  #### 2) 문장 수준 분류를 위한 RNN Wang et al. (2015a)는 LSTM으로 트위터 문장을 인코딩하는 모델을 제안했다. 이 모델의 히든 스테이트는 감성 극성을 예측하는 데 사용된다. 이러한 간단한 전략은 좀 더 복잡한 DCNN 구조([Kalchbrenner et al., 2014](http://www.aclweb.org/anthology/P14-1062))와 비교해도 좋은 성능을 나타냈다. DCNN은 CNN 모델이 장기 의존성을 포착할 수 있도록 디자인되었다. 저자들은 또한 LSTM 게이트가 'not'이라는 단어가 감성의 극성을 반전시키는 걸 포착할 수 있음을 보였다. CNN과 유사하게, RNN의 히든 스테이트는 또한 텍스트 사이의 의미적 일치(semantic matching)에 쓰일 수 있다. 대화시스템에서 [Low et al. (2015)](http://www.sigdial.org/workshops/conference16/proceedings/pdf/SIGDIAL40.pdf)는 Dual-LSTM으로 메세지를 후보 응답과 매칭시키는 모델을 제안했다. Dual-LSTM은 메세지와 응답을 고정된 크기의 벡터로 인코딩하고, 그리고 나서 후보 응답의 순위를 매기기 위해 둘을 내적한다.  #### 3) 문장 생성을 위한 RNN NLP 분야에서 도전적인 과제는 자연어를 생성하는 일이다. 이는 RNN의 또다른 어플리케이션이기도 하다. 텍스트 혹은 시각적 데이터가 주어졌을 때, deep LSTM은 기계번역, 이미지 캡셔닝 등 태스크에서 합리적인 성능을 보였다. 그런 사례에서 RNN은 디코더(decoder)로 불린다([본 블로그](https://ratsgo.github.io/natural%20language%20processing/2017/03/12/s2s/)). [Sutskever et al. (2014)](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)에서 저자들은 시퀀스와 다른 시퀀스를 매핑시키는 일반적인 deep LSTM encoder-decoder 프레임워크를 제안했다. 하나의 LSTM은 소스 시퀀스를 고정된 크기의 벡터로 인코딩한다. 소스 시퀀스는 기계번역의 경우 원래 언어의 텍스트, 질의응답에서는 질의, 대화시스템에서는 메세지가 된다. 이렇게 인코딩된 고정된 크기의 벡터는 디코더로 불리는 또다른 LSTM의 초기 상태(initial state)로 쓰인다. 추론 과정에서 디코더는 토큰을 하나씩 생성하고, 직전에 생성된 토큰으로 히든 스테이트를 업데이트한다. Beam Search는 최적 시퀀스를 근사하는 데 자주 사용된다. [Sutskever et al. (2014)](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)는 종단간(end-to-end) 기계번역을 위한 4개 계층으로 이뤄진 LSTM을 실험했고, 좋은 성능을 보여줬다. [Vinyals and Le(2015)](https://arxiv.org/pdf/1506.05869.pdf)는 동일한 프레임워크를 인간 대화를 모델링하는 데 적용했다. 1억개 이상의 메세지-응답 쌍을 학습했을 때, LSTM 디코더는 오픈 도메인에서 아주 흥미로운 응답을 생성할 수 있다. [Li et al. (2016a)](http://www.aclweb.org/anthology/P16-1094)는 개별 화자의 인물정보를 내포하는 constant persona vector를 디코더 입력값으로 사용할 것을 제안했다. 위의 사례들에서 언어는 텍스트 입력값을 표현하는 의미 벡터들에 주로 기반해 생성된다. 유사한 프레임워크가 이미지 기반의 언어 생성에서도 성공적으로 사용되고 있다. 이미지 기반의 언어 생성에서는 가시적 피처(visual feature)가 LSTM 디코더를 조건부화하는 데 쓰인다. (그림 12) <a href="http://imgur.com/sbOFU81"><img src="http://i.imgur.com/sbOFU81.png" width="400px" title="source: imgur.com" /></a> *그림12: 이미지를 벡터로 임베딩하는 CNN과 결합된 LSTM 디코더. 이미지 캡션을 생성한다. [Vinyals et al. (2015a)](https://arxiv.org/pdf/1411.4555.pdf)* 비주얼 QA는 텍스트와 이미지 둘 모두에 기반한 언어 생성을 요구하는 또다른 태스크이다. [Malinowski et al. (2015)](https://arxiv.org/pdf/1505.01121.pdf)는 CNN에 의해 모델링된 입력 이미지와 LSTM으로 모델링된 텍스트를 조건으로 이미지 캡션의 시퀀스를 예측하는 종단간(end-to-end) 딥러닝 모델을 최초로 제시했다(그림 13). [Kumar et al.(2015)](https://arxiv.org/pdf/1506.07285.pdf)는 4개의 하위 모듈을 가진 Dynamic Memory Network(DMN)이라는 정교한 네트워크를 제안했다. <a href="http://imgur.com/XYFaLb0"><img src="http://i.imgur.com/XYFaLb0.png" width="400px" title="source: imgur.com" /></a> *그림13: Neural-image QA. [Malinowski et al. (2015)](https://arxiv.org/pdf/1505.01121.pdf)*  ### D. 어텐션 매커니즘 기존의 인코더-디코더 프레임워크가 직면한 하나의 잠재적인 문제는 인코더가 때로는 해당 작업과 완전히 관련되지 않은 정보까지도 인코딩해야 한다는 사실이다. 입력값이 길거나 정보가 아주 많은 경우, 그리고 선택적인 인코딩이 불가능할 경우 문제가 발생한다. 예를 들면, 문서 요약 작업은 입력값은 오리지날 텍스트이고 출력은 축약된 버전으로 하는 시퀀스 간(seqeunce-to-sequence) 학습 문제로 풀 수 있다. 길이가 매우 길 수도 있는 텍스트의 모든 정보를 고정 크기의 벡터로 인코딩하는 것은 직관적으로 기대하기 어렵다. 기계 번역에서도 비슷한 문제가 보고되었다([Bahdanau et al., 2014](https://arxiv.org/pdf/1409.0473.pdf)). 반면에, 텍스트 요약과 기계 번역 같은 작업에서 입력 텍스트와 출력 텍스트 사이에 일정한 정렬(alignment)이 존재한다. 요약이나 번역에서 각 토큰 생성 단계는 입력 텍스트의 특정 부분과 매우 관련이 있다. 어텐션 매커니즘은 디코더가 입력 시퀀스를 다시 참조할 수 있게 하여 위의 문제를 완화하려고 시도한다. 디코더는 마지막 히든 스테이트와 생성된 토큰에 더하여 'context' 벡터에 대해 조건부화된다. [Bahdanau et al. (2014)](https://arxiv.org/pdf/1409.0473.pdf)는 기계 번역에 어텐션 매커니즘을 처음으로 적용했다. 어텐션 매커니즘은 특히 긴 시퀀스에 대해 모델의 성능을 향상시킨다. 그들의 연구에서, 입력된 히든 스테이트 시퀀스에 대한 어텐션 시그널은 디코더의 마지막 계층에 의해 다층 퍼셉트론으로 결정된다. 어텐션 시그널을 시각화하면 소스와 타겟 랭귀지 간의 명확한 정렬(alignment)를 보여줄 수 있다(그림14). <a href="http://imgur.com/wiKydaR"><img src="http://i.imgur.com/wiKydaR.png" width="400px" title="source: imgur.com" /></a> *그림14: 단어 정렬 행렬. [Bahdanau et al. (2014)](https://arxiv.org/pdf/1409.0473.pdf)* [Rush et al. (2015)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.697.980&rep=rep1&type=pdf)는 유사한 접근법으로 요약에 적용했다. 입력 문장은 어텐션 매커니즘을 통해 출력 단어를 조건짓는다. 여러 분야에서 성공을 거두면서 어텐션 기반의 모델이 NLP 연구자들 사이에서 주목 받기 시작했다. 이미지 캡셔닝에서 [Xu et al.(2015)](https://arxiv.org/pdf/1502.03044.pdf)는 입력 이미지의 다른 부분으로 LSTM 디코더를 조건부화했다. 어텐션 시그널은 이전의 히든 스테이트 및 CNN이 뽑아낸 피처에 의해 결정됐다. [Vinyals et al. (2015b)](https://arxiv.org/pdf/1412.7449.pdf)는 파싱 트리를 선형화(linearing)함으로써 구문 파싱 문제를 시퀀스 간 학습 문제로 풀었다. 어텐션 매커니즘은 이 작업에서도 효율적(data-efficient)임이 입증됐다. 입력 시퀀스를 참조하는 또다른 단계는 대화 생성과 텍스트 요약과 같은 작업에 유용한 특정 조건([Vinyals et al., 2015c](https://arxiv.org/pdf/1506.03134.pdf)) 하에서 입력 단어 또는 하위 시퀸스를 출력 시퀀스에 직접 복사하는 것이 있다. 복사나 생성은 디코딩하는 동안 각 스텝에서 선택된다. ([Paulus et al., 2017](https://arxiv.org/pdf/1705.04304.pdf)) aspect[^1] 기반의 감성분석에서, [Wang et al.(2016)](https://aclweb.org/anthology/D16-1058)은 aspect 임베딩을 사용한 어텐션 기반의 해법을 제안했다(그림 15). 어텐션 모듈은 분류할 aspect에 영향을 주는 문장의 선택 영역에 초점을 둔다.  <a href="http://imgur.com/9PQQaLe"><img src="http://i.imgur.com/9PQQaLe.png" width="500px" title="source: imgur.com" /></a> *그림15: 어텐션 매커니즘을 사용한 aspect 분류. [Wang et al.(2016)](https://aclweb.org/anthology/D16-1058)* 그림 16과 같이, (a)에서 'service'라는 aspect를 기준으로 보면, 어텐션 모듈은 'fastest delivery times'이라는 문구에 동적으로 초점을 맞춘다. (b)에서 'food'라는 aspect를 기준으로 보면, 모델은 'tasteless'과 'too sweet'라는 문구를 찾아낸다. <a href="http://imgur.com/hDHJoeD"><img src="http://i.imgur.com/hDHJoeD.png" width="500px" title="source: imgur.com" /></a>  반면 [Tang et al. (2016)](https://arxiv.org/pdf/1605.08900.pdf)은 멀티플-홉 어텐션(multiple-hop attention)을 사용하는 메모리 네트워크에 기반한 해법을 채택했다. 이는 또한 'MemNet([Weston et al., 2014](https://arxiv.org/pdf/1410.3916.pdf))'이라고도 알려져 있다. 메모리상의 멀티플 어텐션(multiple attention) 계산계층은 메모리의 정보 영역 대부분에 대한 검색을 향상시키고 결과적으로 분류를 돕는다. 이들의 연구는 이 영역에서 최첨단 기술이다. 어텐션 모듈의 직관적인 적용 가능성을 감안할 때, 어텐션 매커니즘은 점점 더 많은 어플리케이션에 채택되고 있다.  ## 5. Recursive Neural Networks Recurrent Neural Network는 시퀀스(순차적인 데이터) 모델링에 강점을 지닌 기법이다. 그러나 자연언어는 단어와 단어가 계층적인 방식으로 구(phrase)로 결합되는 재귀적인(recursive) 구조를 나타낸다. 이러한 구조는 문장 구성성분 분석 트리(constituency parsing tree)로 표현될 수 있다. 이 때문에 문장의 문법적 구조 해석을 보다 용이하게 하기 위해 트리 구조 모델이 사용되었다([Tai et al., 2015](http://www.aclweb.org/anthology/P15-1150)). 특히 Recursive Neural Network에서 각 노드는 자식 노드의 표현(representation)에 의해 결정된다([본 블로그](https://ratsgo.github.io/deep%20learning/2017/04/03/recursive/)). [Socher et al. (2013)](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)은 구문(pharase), 문장 수준 감성 예측에 이 모델을 적용했다([본 블로그](https://ratsgo.github.io/deep%20learning/2017/06/24/RNTN/)). 저자는 이 연구에서 그림 17과 같이 파싱 트리의 모든 노드(단어)에 대해 감성 스코어를 시각화했다. 여기에선 전체 문장의 감성에 큰 영향을 미치는 'not' 또는 'but' 같은 단어에 대한 모델의 민감도가 나타난다. <a href="http://imgur.com/3VWM6fb"><img src="http://i.imgur.com/3VWM6fb.png" width="400px" title="source: imgur.com" /></a> LSTM은 [Tai et al. (2015)](http://www.aclweb.org/anthology/P15-1150)가 제안한 트리 구조에도 적용되었다([본 블로그](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)). 그래디언트 배니싱 문제(Gradient Vanishing Problem)를 피하기 위해서다. 이 모델은 감성 분석(Sentiment analysis)과 문장 관련성 테스트(sentence relatedness test)에서 linear LSTM 모델보다 개선됐다.  ## 6. 강화학습과 비지도학습  ### A. 문장생성을 위한 강화학습 강화학습(Reinforcement Learning)은 보상(reward)을 얻기 전에 행동(action)을 수행하도록 에이전트(agent)를 학습시키는 기법이다. [Paulus et al. (2017)](https://arxiv.org/pdf/1705.04304.pdf)은 기존의 지도 학습 기반의 단어 예측 기법과 강화학습을 결합한 생성요약(abstractive summarization) 모델을 제안했다. 기존의 RNN 기반 언어생성기(language generator)는 일반적으로 현재 히든 스테이트(hidden state)와 이전 토큰(token, 단어)이 주어졌을 때 정답 단어가 나타날 우도(likelihood)를 최대화함으로써 학습된다. [Teacher forcing](https://www.quora.com/What-is-the-teacher-forcing-in-RNN)이라 불리는 기법은 RNN 학습 과정에서 이전 스텝의 정답 단어들을 다음 스텝의 입력값으로 넣는다. 그러나 추론(inference) 과정에서는 이전 토큰은 모델 자체에서 생성된 토큰으로 대체된다.[^2] '노출 편향(expose bias, [Bengio et al., 2015](https://arxiv.org/pdf/1506.03099.pdf); [Ranzato et al., 2015](https://arxiv.org/pdf/1511.06732.pdf))'라고 불리는 학습과 추론 사이의 이러한 불일치는 생성된 시퀀스에 따라 빠르게 누적될 수 있는 오류를 야기할 수 있다.[^3] 단어 수준의 최대 우도 전략의 또다른 문제점은 학습목표(training objective)가 테스트 측정지표(test metric)과 다르다는 사실이다. 기계번역, 대화시스템 등을 평가하는 데 쓰이는 측정지표(BLUE, ROUGE)가 단어 수준 학습 전략으로 어떻게 최적화될 수 있는지 분명하지 않다. 경험적으로, 단어 수준 최대 우도로 학습된 대화시스템은 둔하고 근시안적인 반응을 생성하는 경향([Li et al., 2016b](https://arxiv.org/pdf/1606.01541.pdf))이 있고, 단어 수준 최우도 기반의 텍스트 요약도 역시 비간섭적(incoherent)이거나 반복적인 요약을 생성하는 경향이 있다([Paulus et al., 2017](https://arxiv.org/pdf/1705.04304.pdf)). 강화학습은 위의 문제를 어느 정도 해결할 수 있는 잠재력을 제공한다. [Ronzato et al.(2015)](https://arxiv.org/pdf/1511.06732.pdf)는 시퀀스 생성 작업(예: 텍스트 요약, 기계번역, 이미지 캡셔닝)을 위한 RNN 기반의 모델을 학습시키기 위해 강화학습 알고리즘([Williams, 1992](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf))를 적용했고, 이전의 지도학습(supervised learning method) 기법과 비교해 개선을 이끌어냈다. 이러한 프레임워크에서 시퀀스 생성모델(RNN)은 환경(단어와 컨텍스트 벡터)과 상호작용하는 에이전트로 간주된다. 이 에이전트의 파라메터는 정책을 정의한다. 정책의 실행으로 에이전트는 각 time step에서 시퀀스의 다음 단어를 예측하는 행동(action)을 취한다. 행동을 취한 다음 에이전트는 내부 상태(RNN의 히든 유닛)를 업데이트한다. 에이전트가 시퀀스의 끝에 도달하면 보상을 받는다. 이 보상은 수행할 태스크에 맞게 연구자가 정의할 수 있다. 대화시스템을 연구한 [Li et al. (2016b)](https://arxiv.org/pdf/1606.01541.pdf)는 생성 문장에 대해 3가지 보상(응답의 용이성, 정보 흐름 및 의미의 일관성)을 정의했다. 강화학습 이외의 다른 접근법은 적대적인 학습 기술(the adversarial training technique, GAN)을 사용하는 것이다([Goodfellow et al., 2014](https://arxiv.org/pdf/1406.2661.pdf)). 생성기(generator)의 학습 목표는 생성된 시퀀스와 진짜 시퀀스를 구별하도록 학습된 다른 판별자(discriminator)를 속이는 것이다. 생성기 G와 판별자 D는 min-max 게임에서 함께 학습되며, 생성기는 판별자가 실제 시퀀스와 구별할 수 없는 시퀀스를 생성한다. 이 접근법은 특정 자극(예: 이미지 캡셔닝에서의 소스 이미지)을 조건으로 하는 GAN([Goodfellow et al., 2014](https://arxiv.org/pdf/1406.2661.pdf))의 변형으로 볼 수 있다. 이같은 프레임워크는 정책 그래디언트(policy gradient)를 가진 강화학습 패러다임 하에서도 실현될 수 있다. 대화시스템의 경우 판별자는 사람과 기계가 생성한 대화를 구분하는 [튜링 테스트](https://en.wikipedia.org/wiki/Turing_test)와 유사하다. ([Li et al., 2017](https://arxiv.org/pdf/1701.06547.pdf))  ### B. 비지도학습 기반 문장 표현 문장에 대한 분산표상(distributed representation)도 단어 임베딩처럼 비지도(unsupervised) 방식으로 학습할 수 있다. 이러한 비지도학습의 결과는 임의의 문장을, 의미와 문법적 속성이 내재한 고정 크기의 벡터에 매핑하는 '문장 인코더'이다. 일반적으로 학습과정을 위해 보조적인 작업(task)을 정의해야 한다. 단어 임베딩을 위한 skip-gram 모델([Mikolov et al., 2013b](https://arxiv.org/pdf/1301.3781.pdf))과 유사하게, 문장 임베딩을 위한 skip-thought 모델([Kiros et al., 2015](https://arxiv.org/pdf/1506.06726.pdf))이 제안됐다. skip-thought 모델에서 보조적인 과제는 주어진 문장 앞뒤에 있는 두 개의 인접 문장을 예측하는 것이다. 여기에는 seq2seq 모델이 사용됐다. 하나의 LSTM이 문장을 벡터(분산표상)로 인코딩한다. 두 개의 다른 LSTM은 이 벡터를 디코딩하여 타겟 시퀀스를 생성한다. 학습을 마친 인코더는 문장의 피처(feature)를 뽑아내는 추출기로 볼 수 있다(단어 임베딩 또한 동시에 학습된다). [Kiros et al. (2015)](https://arxiv.org/pdf/1506.06726.pdf)는 문장 분류(sentence classification) 문제로 학습된 문장 인코더의 품질을 검증했다. 정적인 특징 벡터(static feature vector)[^5] 기반의 단순 선형 모델로 경쟁력 있는 결과를 보여주었다. 그러나 문장 인코더는 학습 과정에서 미세 조정(fine-tune)될 수 있다. [Dai and Le(2015)](https://arxiv.org/pdf/1511.01432.pdf)는 오토인코더(autoencoder, [Rumelhart et al., 1985](http://www.cs.toronto.edu/~fritz/absps/pdp8.pdf))와 유사하게, 인코딩된 문장 자체를 재구축(reconstruct)하는 디코더를 사용했다. 언어모델링(Language modeling)은 LSTM 인코더를 학습할 때 보조적인 작업으로 사용될 수도 있다. 감독 신호(supervision signal)는 다음 토큰의 예측에서 비롯된다. [Dai and Le(2015)](https://arxiv.org/pdf/1511.01432.pdf)는 다양한 작업에서 사전 학습된 파라메터를 LSTM 모델의 초기값으로 쓰는 실험을 수행했다. 그들은 방대한 비지도 말뭉치로 사전 학습된 문장 인코더가 단어 임베딩만 사전학습해 사용하는 것보다 더 나은 정확성을 보임을 입증하였다. 아울러 다음 토큰을 예측하는 것은 문장 자체를 재구축(reconstruct)하는 것보다 더 나쁜 보조 목표인 것으로 판명됐다. LSTM의 히든 스테이트는 단기(shor-term) 기억에만 충실하기 때문이다.  ### C. 심층생성모델 사실적인 이미지 생성 관련 최근의 성공은 심층생성모델(deep generative model)을 텍스트에 적용하는 일련의 노력을 이끌었다. 그러한 연구의 약속은 [잠재코드공간(latent code space)](https://www.quora.com/How-do-I-understand-the-latent-code-in-adversarial-networks)에서 실제 문장을 생성하면서 자연어의 풍부한 구조를 발견하는 것이다. 이 장에서는 이러한 목표를 달성하기 위한 VAE(Variational autoencoder, [Kingma and Welling, 2013](https://arxiv.org/pdf/1312.6114.pdf))과 GAN(Generative Adversarial Network, [Goodfellow et al., 2014](https://arxiv.org/pdf/1406.2661.pdf))의 최근 연구를 검토한다. 표준적인 오토인코더는 자연어 문장 생성에 실패한다([Bowman et al., 2015](https://arxiv.org/pdf/1511.06349.pdf)). 잠재공간(latent space)에 어떤 제약도 가하지 않기 때문이다. 이들 문장의 표현(representation)은 히든 스페이스(hidden space)에서 작은 영역을 차지할 수 있고, 히든 스페이스 대부분의 영역은 반드시 실제 문장에 매핑되지는 않는다([Zhang et al., 2016](https://c4209155-a-62cb3a1a-s-sites.googlegroups.com/site/nips2016adversarial/WAT16_paper_20.pdf?attachauth=ANoY7cpVX1ttnvDJEStBi0JIQS1JAGSrJXtO2j-PneyYchePEJdeKqO0x_tp3SLVjyfcKaUn6oLwv_329RtELCiCAKgk1XVAQ4Cd44Bd2YHGCnxulhNEwAXqaUBjxljbAQ9f1GJmVhxrcK82qd5heF1ZYq36-6f5PYM7HERW_Xmf3uS0vRc0cTCNALZ7CJBIBM1R-3UNbpa-Py_mhyRShEkD3FT4FcgavlMkQCoepEHBO0w351tYxd8%3D&attredirects=0)). 표준적인 문장 오토인코더는 문장에 확률을 할당하거나 새로운 문장을 뽑는 데 사용될 수 없다([Bowman et al., 2015](https://arxiv.org/pdf/1511.06349.pdf)).  VAE는 적절한 샘플을 뽑을 수 있도록 하는 히든 코드 스페이스(hidden code space)에 사전 분포(prior distribution)를 부과한다. 그것은 결정론적인 인코더 기능(deterministic encoder function)을 학습된 사후확률 인식(posterior recognition) 모델로 대체함으로써 오토인코더 아키텍처를 수정한다. 모델은 데이터를 잠재표현(latent representation)으로 인코딩하는 인코더와 잠재공간에서 샘플을 생성하는 생성자(generator) 모델로 구성된다. 이 모델은 관측된 데이터의 로그 우도에 대한 변량적 하한(variational lower bound)을 최대화함으로써 학습된다.  [Bowman et al. (2015)](https://arxiv.org/pdf/1511.06349.pdf)는 전체 문장의 분산잠재표상(distributed latent representations)을 통합한 RNN 기반의 VAE 생성 모델을 제안했다(그림 18). vanilla RNN 언어 모델과 달리, 이 모델은 명시적인 전역 문장 표현(global sentence representation)에서 작동한다. 이 문장에 대한 사전확률(prior)로부터 뽑은 샘플은 다양하고 세련된 문장을 만들었다. <a href="http://imgur.com/Ho71NcR"><img src="http://i.imgur.com/Ho71NcR.png" width="400px" title="source: imgur.com" /></a> [Hu et al. (2017)](https://arxiv.org/pdf/1703.00955.pdf)은 지정된 의미를 가진 엉킴 없는(disentangled) 잠재 표현을 학습함으로써 속성이 제어되는 문장 생성 기법을 제안했다. 저자들은 구조화된 변수 집합을 사용하여 VAE의 잠재코드(latent code)를 만들었는데, 각각은 중요하고 독립적인 문장의 피처를 타겟으로 한다. 모델은 VAE와 속성 판별자(attribute disciminators)를 포함한다. 그럴듯한 텍스트를 생성하기 위해 생성자를 훈련시켜 실제 문장을 재구축(recontruct)하는 한편, 판별자는 생성자가 구조화된 코드와 일관된 속성을 생성하도록 강제한다. 다수의 정답 없는 문장과 소수의 정답 문장을 학습했을 때, [Hu et al.(2017)](https://arxiv.org/pdf/1703.00955.pdf)은 모델이 영어의 두 가지 주요 속성(시제, 감성)에 맞는 그럴듯한 문장들을 생성할 수 있음을 보여줬다. GAN은 생성모델의 다른 종류이다. GAN은 두 가지 경쟁 네트워크로 구성된다. 생성자 네트워크는 잠재 공간에서 데이터 인스턴스로 잠재 표현을 인코딩한다. 반면 판별자 네트워크는 실제 데이터와 생성자가 만든 인스턴스를 구별하기 위해 생성자와 동시에 학습된다. GAN은 실제 데이터 분포인 $p(x)$를 명시적으로 표상하지는(represent) 않는다. [Zhang et al. (2016)](https://c4209155-a-62cb3a1a-s-sites.googlegroups.com/site/nips2016adversarial/WAT16_paper_20.pdf?attachauth=ANoY7cpVX1ttnvDJEStBi0JIQS1JAGSrJXtO2j-PneyYchePEJdeKqO0x_tp3SLVjyfcKaUn6oLwv_329RtELCiCAKgk1XVAQ4Cd44Bd2YHGCnxulhNEwAXqaUBjxljbAQ9f1GJmVhxrcK82qd5heF1ZYq36-6f5PYM7HERW_Xmf3uS0vRc0cTCNALZ7CJBIBM1R-3UNbpa-Py_mhyRShEkD3FT4FcgavlMkQCoepEHBO0w351tYxd8%3D&attredirects=0)은 실제 텍스트를 생성하기 위한 적대적인 학습에 LSTM과 CNN을 적용한 프레임워크를 제안했다. 잠재코드(latent code) 'z'는 매 time step마다 LSTM 생성자(generator)에 입력되었다. CNN은 실제 데이터와 생성된 샘플을 구별하는 이진 문장 분류기 역할을 수행했다. GAN을 텍스트에 적용할 때 문제점은 판별자로부터 나온 그래디언트가 제대로 역전파될 수 없다는 점이다. [Zhang et al.(2016)](https://c4209155-a-62cb3a1a-s-sites.googlegroups.com/site/nips2016adversarial/WAT16_paper_20.pdf?attachauth=ANoY7cpVX1ttnvDJEStBi0JIQS1JAGSrJXtO2j-PneyYchePEJdeKqO0x_tp3SLVjyfcKaUn6oLwv_329RtELCiCAKgk1XVAQ4Cd44Bd2YHGCnxulhNEwAXqaUBjxljbAQ9f1GJmVhxrcK82qd5heF1ZYq36-6f5PYM7HERW_Xmf3uS0vRc0cTCNALZ7CJBIBM1R-3UNbpa-Py_mhyRShEkD3FT4FcgavlMkQCoepEHBO0w351tYxd8%3D&attredirects=0)에서 이 문제는 단어 예측을 항상 'soft'하게 함으로써 해결되었다. [Yu et al. (2017)](https://arxiv.org/pdf/1609.05473.pdf)은 생성자를 stochatic policy로 모델링함으로써 이 문제를 우회할 것을 제안했다. 보상 신호(reward signal)는 완전한 시퀀스에서 판단된 GAN 판별자로부터 나온 것이며, 몬테카를로 탐색을 사용하여 중간 상태-행동 단계(intermidiate state-action steps)로 다시 전달된다.  심층학습모델 평가는 어렵다. 텍스트의 경우 고정된 문법 규칙으로 학습 데이터를 만든 다음, 생성된 샘플이 미리 정의한 문법과 일치하는지 여부로 생성모델을 평가할 수 있다([Rajeswar et al., 2017](https://arxiv.org/pdf/1705.10929.pdf)). 또다른 전략은 학습에 쓰지 많은 양의 테스트 데이터에서 샘플의 BLEU 점수를 평가해보는 것이다. 학습에 쓰지 않은 실제 데이터와 유사한 문장을 생성하는 능력은 모델의 품질 척도로 간주된다([Yu et al., 2017](https://arxiv.org/pdf/1609.05473.pdf)).   ## 7. 메모리 네트워크 어텐션(attention) 매커니즘은 인코더에서 만들어진 히든 벡터(hidden vector)들을 저장한다. 디코더는 각 토큰을 생성하고 있는 중에 이 벡터들에 액세스할 수 있다. 여기서 인코더의 히든 벡터들은 모델의 '내부 메모리(internal memory)' 항목으로 볼 수 있다. 최근에는 모델이 상호작용할 수 있는 메모리의 형태로 뉴럴 네트워크들을 연결하는 것에 대한 관심이 급증했다. [Weston et al. (2014)](https://arxiv.org/pdf/1410.3916.pdf)는 질의응답(QA)을 위한 메모리 네트워크를 제안했다. 이 작업(task)에서 일련의 진술(statements, 메모리 항목)은 질의를 잠재적으로 뒷받침하는 사실로써 모델에 입력된다. 모델은 질의과 이전에 검색한 메모리를 기반으로 한번에 하나의 항목을 검색하도록 학습됐다. 대규모 현업 QA에서 (주체, 관계, 대상)이라는 트리플 형태로 방대한 지식이 메모리로 사용됐다. [Sukhbaatar et al. (2015)](https://arxiv.org/pdf/1503.08895.pdf)는 이러한 작업을 확장하여, 메모리 항목이 어텐션 매커니즘을 통해 'soft'한 방식으로 검색되어 종단간(end-to-end) 학습을 가능하도록 하는 'end-to-end memory network'를 제안했다. 메모리에서 여러번 정보 검색을 수행하면 좋은 성능을 내며, 모델은 특정 질의에 대한 답변을 위해 몇 가지 뒷받침하는 사실을 검색하고 추론할 수 있다. (그림 19)  <a href="http://imgur.com/BCquE8b"><img src="http://i.imgur.com/BCquE8b.png" width="400px" title="source: imgur.com" /></a> [Sukhbaatar et al. (2015)](https://arxiv.org/pdf/1503.08895.pdf)는 언어 모델링을 위한 모델의 특별한 사용법을 보여주었다. 여기에서 문장의 각 단어는 메모리 항목으로 간주된다. 멀티홉(mulitiple hop)을 사용하여, 모델은 deep LSTM 모델에 필적하는 결과를 산출했다.  또한 Dynamic Memory Networks(DMN, [Kumar et al., 2015](https://arxiv.org/pdf/1506.07285.pdf))는 입력 표현(representation), 어텐션 및 응답 매커니즘을 위한 뉴럴 네트워크를 사용하여 이전의 메모리 기반 모델을 개선했다. 이 모델은 모든 데이터 인스턴스가 <메모리, 질문, 답변> 트리플 포맷으로 캐스팅될 수 있으므로 광범위한 범위의 NLP 문제(QA, 품사태깅, 감성분석)에 적용할 수 있다. [Xiong et al.(2016)](https://arxiv.org/pdf/1603.01417.pdf)은 visual QA에 동일한 모델을 적용하여 '메모리 모듈'이 시각적 신호에도 적용 가능함을 입증했다.   ## 8. 기법별 성능 표준적인 데이터셋에 대한 최근 개발된 딥러닝 기법의 성능을 표2~7에 요약 제시했다.  ### A. 품사태깅 | Paper                  | Model               | WSJ-PTB (per-token accuracy %) | | :--------------------------------------- | :--------------------------------- | :----------------------------- | | [Gimenez and Marquez(2004)](http://nlp.lsi.upc.edu/papers/gimenez03.pdf) | SVM with manual feature pattern  | 97.16             | | [Collobert et al.(2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf) | MLP with word embeddings + CRF   | 97.29             | | [Santos and Zadrozny(2014)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.646.4491&rep=rep1&type=pdf) | MLP with character+word embeddings | 97.32             | | [Huang et al.(2015)](https://arxiv.org/pdf/1508.01991.pdf) | LSTM                | 97.29             | | [Huang et al.(2015)](https://arxiv.org/pdf/1508.01991.pdf) | Bidirectional LSTM         | 97.40             | | [Huang et al.(2015)](https://arxiv.org/pdf/1508.01991.pdf) | LSTM-CRF              | 97.54             | | [Huang et al.(2015)](https://arxiv.org/pdf/1508.01991.pdf) | Bidirectional LSTM-CRF       | 97.55             | | [Kumar et al.(2015)](https://arxiv.org/pdf/1506.07285.pdf) | DMN                | 97.56             | **[표2] 품사태깅** WSJ-PTB(the Wall Street Journal part of the Penn Treebank Dataset) 말뭉치에는 117만개 토큰이 포함돼 있으며 품사태깅 시스템 개발과 평가에 널리 쓰이고 있다. [Gimenez and Marquez (2004)](http://nlp.lsi.upc.edu/papers/gimenez03.pdf)는 일곱개의 단어 window에서 수작업으로 정의한 피처를 기반으로 one-against-all SVM을 사용하여, 몇 가지 기본적인 n-gram 패턴을 다음과 같이 이진 피처로 평가했다. "이전 단어는 'the'이다", "앞의 두 태그는 DT(한정사) NN(일반명사)이다" 등.  품사태깅 문제의 한가지 특징은 인접한 태그 간에 의존성이 강하다는 점이다. 왼쪽에서 오른쪽으로 태그를 붙이는 간단한 방법을 사용하여, [Gimenez and Marquez (2004)](http://nlp.lsi.upc.edu/papers/gimenez03.pdf)는 피처 엔지니어링(feature engineering)[^4]을 통해서만 인접 태그간의 종속성을 모델링했다. 피처 엔지니어링을 위한 노력을 줄이기 위해, [Collobert et al. (2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)은 다층 퍼셉트론(multi-layer perceptron)에 의한 단어 임베딩에만 의존했다. CRF(Conditional Random Field)는 [Collobert et al.(2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)에서 유용함이 입증되었다. [Santos and Zadrozny(2014)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.646.4491&rep=rep1&type=pdf)는 단어 임베딩을 문자 임베딩과 합쳐(concatenate) 형태적(morphological) 단서들을 더 잘 활용한다. [Santos and Zadrozny(2014)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.646.4491&rep=rep1&type=pdf)는 CRF를 고려하지 않았지만, 이 모델의 예측은 문맥 window 내에서 이뤄지기 때문에, 인접 태그 간 종속성이 암시적으로 모델링된 것이라 볼 수 있다. [Huang et al. (2015)](https://arxiv.org/pdf/1508.01991.pdf)는 워드 임베딩과 수작업으로 설계한 단어 수준 피처(feature)를 합치고(concatenate) 긴 문맥을 모델링하기 위해 bidirectional LSTM을 사용했다. 분석 결과 양방향성(bidirectionality)과 CRF 둘 모두 모델 성능을 높이는 데 기여했다. 7장 메모리 네트워크 장에서 이미 언급한 바 잇는 DMN([Kumar et al., 2015](https://arxiv.org/pdf/1506.07285.pdf))은 품사태깅에도 적용될 수 있다. DMN은 RNN의 각 히든 스테이트를 메모리 항목으로 처리함으로써 컨텍스트에 여러번 집중할 수 있다.  ### B. 파싱 | Parsing type     | Paper                  | Model                  | WSJ         | | :------------------- | :--------------------------------------- | :--------------------------------------- | :------------------ | | Dependency Parsing  | [Chen and Manning(2014)](http://cs.stanford.edu/~danqi/papers/emnlp2014.pdf) | Fully-connected NN with features including POS | 91.8/89.6 (UAS/LAS) | | Dependency Parsing  | [Weiss et al.(2015)](http://www.petrovi.de/data/acl15.pdf) | Deep fully-connected NN with features including POS | 94.3/92.4 (UAS/LAS) | | Dependency Parsing  | [Dyer et al.(2015)](http://www.cs.cmu.edu/~lingwang/papers/acl2015.pdf) | Stack LSTM                | 93.1/90.9 (UAS/LAS) | | Constituency Parsing | [Petrov et al.(2006)](https://pdfs.semanticscholar.org/d84b/9507ff9687a900fde451f27106d930c1b838.pdf) | Probabilistic context-free grammars (PCFG) | 91.8 (F1 Score)   | | Constituency Parsing | [Zhu et al.(2013)](http://www.aclweb.org/anthology/P13-1043.pdf) | Feature-based transition parsing     | 91.3 (F1 Score)   | | Constituency Parsing | [Vinyals et al.(2015b)](https://arxiv.org/pdf/1412.7449.pdf) | seq2seq learning with LSTM+Attention   | 93.5 (F1 Score)   | **[표3] 파싱** *UAS/LAS = Unlabeled/labeled Attachment Score; WSJ = Wall Street Journal Section of Penn Treebank* 파싱(parsing, 구문분석)에는 두 가지 유형이 있다. 하나는 개별 단어를 이들 사이의 관계를 고려해 연결하는 의존구문분석(dependency parsing)과 텍스트를 반복적으로 하위 구문으로 분리하는 구성성분분석(constituency parsing)이다. 전이 기반 의존구문분석(transition-based dependency parsing)은 문장 길이가 선형적(linear)이기 때문에 널리 사용되는 선택이다. 구문분석기(parser)는 순차적으로 단어를 읽어들여 구문 구조(syntactic structure)에 점진적으로 결합시키는 일련의 결정을 내린다([Chen and Manning, 2014](http://cs.stanford.edu/~danqi/papers/emnlp2014.pdf)). 각 time step에서 사용 가능한 트리 노드를 포함하는 스택(stack), 읽지 않은 단어와 dependency arc의 집합을 포함하는 버퍼(buffer)를 기반으로 결정된다. [Chen and Manning(2014)](http://cs.stanford.edu/~danqi/papers/emnlp2014.pdf)는 하나의 히든 레이어가 있는 뉴럴 네트워크를 사용하여 매 time step마다 의사결정을 모델링했다. 입력 레이어에는 스택 및 버퍼와 arc label의 집합으로부터 나온 특정 단어, 품사의 태그(tag), arc label의 임베딩이 포함되어 있다. [Tu et al. (2015)](http://www.aclweb.org/anthology/P15-2088)는 2개의 은닉층이 있는 더 깊은 모델을 사용함으로써 [Chen and Manning(2014)](http://cs.stanford.edu/~danqi/papers/emnlp2014.pdf)의 연구를 확장시켰다. 그러나 [Tu et al. (2015)](http://www.aclweb.org/anthology/P15-2088), [Chen and Manning(2014)](http://cs.stanford.edu/~danqi/papers/emnlp2014.pdf) 모두 수작업에 의존한 피처 선택에 의존했으며, 제한된 수의 마지막(latest) 토큰들만 고려했다. [Dyer et al. (2015)](http://www.cs.cmu.edu/~lingwang/papers/acl2015.pdf)는 긴 이력을 모델링하기 위한 stack LSTM을 제안했다. LSTM 스택의 말단 포인터는 트리 노드의 스택이 push되고 pop될 때 위치를 변경한다. 전이 기반 의존구문 분석(Transition-based parsing)은 구성성분분석(constituency parsing)에도 적용되었다. [Zhu et al. (2013)](http://www.aclweb.org/anthology/P13-1043.pdf)은 피처(품사정보, 스택과 버퍼의 상위 몇 단어의 구성성분 레이블/constitute label)에 대한 전이 행동(transition action)을 기반으로 한다. [Vinyals et al. (2015b)](https://arxiv.org/pdf/1412.7449.pdf)는 레이블의 선형 시퀀스(linear sequence)로 파싱트리를 표현함으로써 이 문제에 seq2seq 학습 기법을 적용했다.  ### C. 개체명 인식 | Paper                  | Model                  | CoNLL 2003 (F1 %) | | ---------------------------------------- | ---------------------------------------- | ----------------- | | [Collobert et al.(2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf) | MLP with word embeddings+gazetteer    | 89.59       | | [Passos et al.(2014)](http://www.aclweb.org/anthology/W14-1609) | Lexicon Infused Phrase Embeddings    | 90.90       | | [Chiu and Nichols(2015)](https://arxiv.org/pdf/1511.08308.pdf) | Bi-LSTM with word+char+lexicon embeddings | 90.77       | | [Luo et al.(2015)](http://aclweb.org/anthology/D15-1104) | Semi-CRF jointly trained with linking  | 91.20       | | [Lample et al.(2016)](https://arxiv.org/pdf/1603.01360.pdf) | Bi-LSTM-CRF with word+char embeddings  | 90.94       | | [Lample et al.(2016)](https://arxiv.org/pdf/1603.01360.pdf) | Bi-LSTM with word+char embeddings    | 89.15       | **[표4] 개체명 인식** CoNLL 2003은 네 가지 유형의 개체명(사람, 위치, 조직, 기타 항목)이 중심인 NER 표준 영어 데이터셋이다. NER은 이러한 어휘집(lexicon)이 매우 유용할 수 있는 NLP 문제 가운데 하나다. [Collobert et al. (2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)은 지명사전(gazetteer)이 추가된 데이터를 바탕으로 한 뉴럴 네트워크로 경쟁력 있는 결과를 처음으로 달성했다. [Chiu and Nichols(2015)](https://arxiv.org/pdf/1511.08308.pdf)는 어휘집(lexicon) 피처, 문자 임베딩, 단어 임베딩을 합치고(concatenate) 이를 bidirectional LSTM 입력값으로 넣었다. 반면 [Lample et al. (2016)](https://arxiv.org/pdf/1603.01360.pdf)은 문자와 단어 임베딩에만 의지했다. 방대한 비지도 말뭉치로 사전 학습된 임베딩을 쓰면 어휘집(lexicon) 없이도 좋은 결과를 얻을 수 있었다. [Lample et al.(2016)](https://arxiv.org/pdf/1603.01360.pdf)의 비교로 입증된 것처럼, CRF는 품사태깅과 마찬기지로 NER 성능도 끌어올렸다. [Passos et al. (2014)](http://www.aclweb.org/anthology/W14-1609)는 skip-gram 모델을 수정하여 관련 어휘집(lexicon)으로부터 정보를 leverage할 수 있는 엔티티 유형 관련 단어 임베딩을 보다 잘 학습하도록 제안했다. [Luo et al. (2015)](http://aclweb.org/anthology/D15-1104)는 엔티티와 엔티티-지식베이스(KB) 연결을 동시에 최적화했다.  ### D. 의미역 결정 | Paper                  | Model                  | CoNLL2005 (F1 %) | CoNLL2012 (F1 %) | | ---------------------------------------- | ---------------------------------------- | ---------------- | ---------------- | | [Collobert et al.(2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf) | CNN with parsing features        | 76.06      |         | | [Tackstrom et al.(2015)](https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/43251.pdf) | Manual features with DP for inference  | 78.6       | 79.4       | | [Zhou and Xu(2015)](http://www.aclweb.org/anthology/P15-1109) | Bidirectional LSTM            | 81.07      | 81.27      | | [He et al.(2017)](https://homes.cs.washington.edu/~luheng/files/acl2017_hllz.pdf) | Bidirectional LSTM with highway connections | 83.2       | 83.4       | **[표7] 의미역 결정** 의미역 결정(Semantic Role Labeling, SRL)은 문장에서 술어(predicate)-논항(argument) 구조를 발견하는 것을 목표로 한다. 각 목표 동사(술어)에 대해, 동사의 의미역을 취하는 문장의 모든 구성요소가 인식된다. 전형적인 의미 논항은 행위주, 대상, 도구 등이며 위치, 시간, 방법, 원인 등도 포함된다([Zhou and Xu, 2015](http://www.aclweb.org/anthology/P15-1109)). 표7은 CoNLL 2015 및 2012 데이터셋에서 여러 모델의 성능을 보여준다. 전통적인 SRL 시스템은 여러 단계로 구성된다. 파싱 트리를 생성한 뒤 트리의 노드가 주어진 동사의 논항을 나타내는지 판별한 다음, 해당 SRL 태그를 결정한다. 각 분류 과정은 많은 피처를 추출하여 통계 모델(statistical model)로 전달하는 과정을 대개 수반한다. ([Collobert et al., 2011](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)) [Tackstrom et al. (2015)](https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/43251.pdf)는 술어가 주어지면 파싱 트리를 기반으로 하는 일련의 피처로 구성요소의 범위와 해당 술어에 대한 의미역 후보들에 점수를 매긴다. 그들은 효율적인 추론을 위한 동적 프로그래밍(dynamic programming) 알고리즘을 제안했다. [Collobert et al., (2011)](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)은 추가적인 참조 테이블의 형태로 제공된 파싱 정보에 의해 보강된 CNN을 사용하여 유사한 결과를 얻었다. [Zhou and Xu(2015)](http://www.aclweb.org/anthology/P15-1109)는 임의의 긴 문맥을 모델링하기 위해 bidirectional LSTM을 제안했는데, 파싱 트리 정보 없이도 성공적인 것으로 판명되었다. [He et al. (2017)](https://homes.cs.washington.edu/~luheng/files/acl2017_hllz.pdf)은 이 연구를 더욱 확장해 'highway connection'을 소개했다.   ### E. 감성분류 | Paper                  | Model              | SST-1 | SST-2 | | ---------------------------------------- | ------------------------------- | ----- | ----- | | [Socher et al.(2013)](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf) | Recursive Neural Tensor Network | 45.7 | 85.4 | | [Kim(2014)](http://www.aclweb.org/anthology/D14-1181) | Multichannel CNN        | 47.4 | 88.1 | | [Kalchbrenner et al.(2014)](http://www.aclweb.org/anthology/P14-1062) | DCNN with k-max pooling     | 48.5 | 86.8 | | [Tai et al.(2015)](http://www.aclweb.org/anthology/P15-1150) | Bidirectional LSTM       | 48.5 | 87.2 | | [Le and Mikolov(2014)](https://cs.stanford.edu/~quocle/paragraph_vector.pdf) | Paragraph Vector        | 48.7 | 87.8 | | [Tai et al.(2015)](http://www.aclweb.org/anthology/P15-1150) | Constituency Tree-LSTM     | 51.0 | 88.0 | | [Kumar et al.(2015)](https://arxiv.org/pdf/1506.07285.pdf) | DMN               | 52.1 | 88.6 | **[표5] 감성분류** Stanford Sentiment Treebank(SST) 데이터셋에는 영화 리뷰 웹사이트인 Rotten Tomatoes에서 가져온 문장들이 들어있다. 이 데이터셋은 [Pang and Lee(2005)](http://www.cs.cornell.edu/home/llee/papers/pang-lee-stars.pdf)에 의해 제안되었고, 이어서 [Socher et al. (2013)](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)에 의해 확장되었다. 주석 체계는 CMU-MOSI라 불리는 감성분석을 위한 새로운 데이터 세트에 영감을 불어넣었다. CMU-MOSI는 감성이 다중모달 설정(multi-modal setup)으로 연구된다([Zadeh et al., 2016](http://ieeexplore.ieee.org/document/7742221/)). [Socher et al. (2013)](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)과 [Tai et al. (2015)](http://www.aclweb.org/anthology/P15-1150)는 모두 구성성분분석(constituency parsing) 트리에 의존하는 Recursive Network다. 이들의 차이점은 문장을 모델링할 때 vaniila RNN에 대한 LSTM의 효과를 보여준다. 반면 tree-LSTM은 linear bidirectional LSTM보다 우수한 성능을 보이며, 잠재적인 트리 구조가 자연 문장의 문법적 특성을 더 잘 포착할 수 있음을 의미한다. [Kim(2014)](http://www.aclweb.org/anthology/D14-1181)와 [Kalchbrenner et al. (2014)](http://www.aclweb.org/anthology/P14-1062)는 모두 콘볼루션 계층을 사용했다. [Kim(2014)](http://www.aclweb.org/anthology/D14-1181) 모델은 그림6과 유사하지만, [Kalchbrenner et al. (2014)](http://www.aclweb.org/anthology/P14-1062)는 k-max 풀링 레이어를 컨볼루션 레이어와 섞어서 계층적인 방식으로 모델을 구성했다.  ### F. 기계번역 | Paper                  | Model                  | WMT2014 English2German | WMT2014 English2French | | ---------------------------------------- | ---------------------------------------- | ---------------------- | ---------------------- | | [Cho et al.(2014)](https://arxiv.org/pdf/1406.1078.pdf) | Phrase table with neural features    |            | 34.50         | | [Sutskever et al.(2014)](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) | Reranking phrase-based SMT best list with LSTM seq2seq |            | 36.5          | | [Wu et al.(2016)](https://arxiv.org/pdf/1609.08144.pdf) | Residual LSTM seq2seq + Reinforcement learning refining | 26.30         | 41.16         | | [Gehring et al.(2017)](https://arxiv.org/pdf/1705.03122.pdf) | seq2seq with CNN             | 26.36         | 41.29         | | [Vaswani et al.(2017)](https://arxiv.org/pdf/1706.03762.pdf) | Attention mechanism           | 28.4          | 41.0          | **[표6] 기계번역** *각 수치는 BLEU 스코어* 구문 기반의 통계적 번역(SMT) 프레임워크(Koehn et al., 2003)는 번역모델을 소스 및 타겟 문장에서 일치하는 구문의 번역확률(translation probabilities)로 처리했다(factorize). [Cho et al. (2014)](https://arxiv.org/pdf/1406.1078.pdf)는 RNN 인코더-디코더를 사용하여 소스 구문과 해당 대상 구문의 번역확률을 학습하는 모델을 제안했다. 이렇게 구문 쌍을 점수화하는 방식은 번역 성능을 향상시켰다. 반면 [Sutskever et al. (2014)](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)는 4개 층의 LSTM seq2seq 모델을 사용하여 SMT 시스템에서 생성된 최상위 1000개 후보 번역본을 다시 채점했다. [Wu et al. (2016)](https://arxiv.org/pdf/1609.08144.pdf)은 residual connection뿐 아니라 어텐션 connection이 있는 8개 인코더와 8개 디코더 계층으로 이뤄진 deep LSTM 네트워크를 학습시켰다. [Wu et al. (2016)](https://arxiv.org/pdf/1609.08144.pdf)은 BLUE 점수를 최적화하기 위해 강화학습을 사용하여 모델을 학습했다. 그러나 그들은 이 방법으로 BLUE 스코어를 개선한 것은 사람의 번역 품질 평가에는 반영되지 않는다는 걸 알게 됐다. 최근에 [Gehring et al. (2017)](https://arxiv.org/pdf/1705.03122.pdf)은 더 나은 병렬화(parallelization)을 위해 convolutional seq2seq를 제안했다. [Vaswani et al. (2017)](https://arxiv.org/pdf/1706.03762.pdf)은 self-attention-based 모델을 제안했다.  ### G. 질의응답 | Paper                  | Model               | bAbI (Mean accuracy %) | Farbes (Accuracy %) | | ---------------------------------------- | ---------------------------------- | ---------------------- | ------------------- | | [Fader et al.(2013)](http://www.aclweb.org/anthology/P13-1158) | Paraphrase-driven lexicon learning |            | 0.54        | | [Bordes et al.(2014)](https://arxiv.org/pdf/1404.4326.pdf) | Weekly supervised embedding    |            | 0.73        | | [Weston et al.(2014)](https://arxiv.org/pdf/1410.3916.pdf) | Memory Networks          | 93.3          | 0.83        | | [Sukhbaatar et al.(2015)](https://arxiv.org/pdf/1503.08895.pdf) | End-to-end Memory Networks     | 88.4          |           | | [Kumar et al.(2015)](https://arxiv.org/pdf/1506.07285.pdf) | DMN                | 93.6          |           | **[표8] 질의응답** 질의응답 문제는 다양한 형태로 나타난다. 일부는 방대한 지식베이스(KB)를 사용해 오픈도메인 질의에 답변하고, 다른 일부는 몇몇 문장이나 단락을 바탕으로 질의에 답을 한다. [Fader et al. (2013)](http://www.aclweb.org/anthology/P13-1158)은 전자의 경우로, 이들이 대규모 QA 데이터셋을 대상으로 수행한 실험결과는 표 8에 있다. 각 질의는 단일 관계(single-relation) 쿼리를 통해 답변을 얻을 수 있다. 후자의 연구는 bAbI 관련 실험들이다. 이 데이터셋은 모델이 올바른 답을 내기 위해 여러 가지 관련 사실을 추론할 것을 요구한다. 여기에는 관련 사실을 검색하고 그 이유를 추론하는 모델의 능력을 테스트하는 20개 과제가 포함돼 있다. 각 과제는 기본적인 상호참조(coreference)와 크기 추론(size reasoning) 등과 같이 각기 다른 기술에 중점을 둔다. 단일 관계 쿼리에 응답하는 학습의 핵심 문제는 데이터베이스에서 관련 사실을 찾는 것이다. [Fader et al.(2013)](http://www.aclweb.org/anthology/P13-1158)은 질의 구문(question paraphrasing) 데이터셋을 기반으로 자연언어의 패턴을 데이터베이스의 개념(엔티티, 관계, 질의 패턴)에 매핑하는 어휘집(lexicon)을 학습함으로써 이 문제를 해결할 것을 제안했다. [Bordes et al. (2014)](https://arxiv.org/pdf/1404.4326.pdf)는 질의와 KB 트리플을 dense vector로 임베딩하고, 이들을 내적해 점수를 매겼다. [Weston et al. (2014)](https://arxiv.org/pdf/1410.3916.pdf)는 메모리 네트워크의 프레임워크 내에서 문제를 해결하기 위해 KB를 장기 기억(long-term memory)으로 취급했다. [Sukhbaatar et al. (2015)](https://arxiv.org/pdf/1503.08895.pdf)는 bAbI 데이터세트에서 학습 과정에서 모델이 실제 뒷받침하는 팩트에 대해 알지 못하게 함으로써 기존의 메모리 네트워크 모델([Weston et al., 2014](https://arxiv.org/pdf/1410.3916.pdf))을 개선했다. 반면 [Kumar et al. (2015)](https://arxiv.org/pdf/1506.07285.pdf)는 [Sukhbaatar et al. (2015)](https://arxiv.org/pdf/1503.08895.pdf)과 [Weston et al. (2014)](https://arxiv.org/pdf/1410.3916.pdf)가 메모리를 임베딩했던 것과 같이 neural bag-of-words 모델 대신에 뉴럴 시퀀스(neural sequence) 모델(GRU)을 사용했다.  ### F. 대화 시스템 | Paper                  | Model                  | Twitter Conversation Triple Dataset (BLEU) | Ubuntu Dialogue Dataset (recall 1@10 %) | | ---------------------------------------- | ---------------------------------------- | ---------------------------------------- | --------------------------------------- | | [Ritter et al.(2011)](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/mt_chat.pdf) | SMT                   | 3.60                   |                     | | [Sordoni et al.(2015)](http://www.aclweb.org/anthology/N/N15/N15-1020.pdf) | SMT+neural reranking           | 4.44                   |                     | | [Li et al.(2015)](https://arxiv.org/pdf/1510.03055.pdf) | LSTM seq2seq               | 4.51                   |                     | | [Li et al.(2015)](https://arxiv.org/pdf/1510.03055.pdf) | LSTM seq2seq with MMI objective     | 5.22                   |                     | | [Lowe et al.(2015)](http://www.sigdial.org/workshops/conference16/proceedings/pdf/SIGDIAL40.pdf) | Dual LSTM encoders for semantic matching |                     | 55.22                  | | [Dodge et al.(2015)](https://arxiv.org/pdf/1511.06931.pdf) | Memory Networks             |                     | 63.72                  | | [Zhou et al.(2016)](http://ir.hit.edu.cn/~zhaosq/paper/EMNLP2016.pdf) | Sentence-level CNN-LSTM encoder     |                     | 66.15                  | **[표9] 대화시스템** 두 가지 유형의 대화시스템이 개발되었다. 생성기반모델(generative-based model)과 검색기반모델(retireval-based model)이 바로 그것이다. 표 9에 제시된 트위터 대화 트리플 데이터셋(Twitter Conversation Triple Dataset)은 일반적으로 생성 기반 대화 시스템을 평가하는 데 사용되며 트위터 대화 인스턴스가 포함돼 있다. 일반적으로 사용되는 평가척도 하나는 BLEU이다([Papineni et al., 2002](http://www.aclweb.org/anthology/P02-1040.pdf)). 그러나 자동 평가 척도는 대부분 완전히 신뢰할 수 없고 사람의 평가가 추가적으로 필요하다. [Ritter et al. (2011)](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/mt_chat.pdf)은 메시지를 적절한 응답으로 "번역"하기 위해 구문 기반의 통계적 기계번역(SMT) 프레임워크를 사용했다. [Sordoni et al. (2015)](http://www.aclweb.org/anthology/N/N15/N15-1020.pdf)는 문맥에 민감한 RNN 인코더-디코더 프레임워크를 사용하여 SMT에 의해 생성된 1000개 최상의 응답을 재검토했다. [Li et al. (2015)](https://arxiv.org/pdf/1510.03055.pdf)는 흥미롭고 다양한 응답을 생성하기 위해 학습목표를 기존의 로그우도 최대화에서 상호정보량(mutual information) 최대화로 대체해 실험한 결과를 보고했다. 두 실험 모두 4개 층의 LSTM 인코더-디코더 프레임워크에서 테스트됐다. 응답 검색 과제는 후보 응답의 저장소(repository)에서 최상의 응답을 선택하는 것으로 정의된다. 이런 모델은 정답이 k-1개의 무작위 응답과 혼합되는 reall1@k 척도에 의해 평가될 수 있다. 우분투 대화 데이터셋(Ubuntu Dialogue Dataset)은 우분투 문제 해결 관련 온라인 채팅을 여러번 스크래핑해서 만들어졌다([Lowe et al., 2015](http://www.sigdial.org/workshops/conference16/proceedings/pdf/SIGDIAL40.pdf)). [Lowe et al. (2015)](http://www.sigdial.org/workshops/conference16/proceedings/pdf/SIGDIAL40.pdf)는 메시지와 응답을 인코딩하기 위해 LSTM을 사용했고, 두 문장 임베딩을 내적해 후보들에 순위를 매겼다. [Zhou et al. (2016)](http://ir.hit.edu.cn/~zhaosq/paper/EMNLP2016.pdf)은 [Serban et al. (2016)](https://arxiv.org/pdf/1507.04808.pdf)과 유사하게, 문장 수준의 CNN 임베딩 위에 LSTM 인코더를 사용하여 인간 대화의 multi-turn 특성을 보다 잘 활용하는 기법을 제안했다. [Dodge et al. (2015)](https://arxiv.org/pdf/1511.06931.pdf)는 과거의 대화가 메모리로 취급되고, 최신 발언이 응답될 '질의'로 간주되었던 메모리 네트워크 프레임워크에 문제를 제기했다. 저자들은 문장에 대해 간단한 neural bag-of-word 임베딩을 사용하면 경쟁력 있는 결과를 얻을 수 있음을 보여주었다.  ## 9. 향후 트렌드 딥러닝은 많은 양의 계산과 데이터를 활용하는 기법으로, 수작업 피처 엔지니어링을 거의 하지 않아도 된다([LeCun et al., 2015](http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html?foxtrotcallback=true)). 분산표상(distributed representation)을 활용한 다양한 딥러닝 모델들이 NLP 문제의 새로운 최첨단(state-of-the-art) 방법이 되었다. 우리는 이러한 추세가 계속될 것이라 기대한다. 강화학습과 비지도 학습을 활용한 NLP 어플리케이션이 더 많이 나올 것으로 예상된다. 강화학습은 특정 목표를 최적화하기 위해 NLP 시스템을 학습하는 자연스러운 방법을 제시하고, 비지도 학습은 큰 데이터에서 풍부한 언어 구조를 학습할 수 있음을 약속한다. 또한 현실세계에서 언어가 종종 다른 신호(signal)에 근거하거나 상호관련되기 때문에 멀티모달(multimodal) 학습에 대해 더 많은 연구가 이뤄지기를 기대한다. 마지막으로 우리는 내부 메모리(데이터에서 배운 상향적 지식)가 외부 메모리(지식베이스로부터 상속된 지식)로 풍부해진 보다 깊은 학습모델이 나오기를 기대한다. [Symbolic AI와 Sub-symbolic AI](http://futureai.media.mit.edu/wp-content/uploads/sites/40/2016/02/Symbolic-vs.-Subsymbolic.pptx_.pdf)를 결합하는 것은 NLP에서 자연어이해(NLU)에 이르는 길을 걷는 열쇠가 될 것이다. 머신러닝에 의존하면 과거 경험을 바탕으로 '올바른 추측'을 하기가 수월해진다. 왜냐하면 Sub-symbolic 기법은 상관관계(correalation)를 인코딩하고, 의사결정과정은 확률적이기 때문이다. 그러나 자연어이해는 그 이상을 요구한다. Noam Chomsky의 말을 인용하면, "엄청난 양의 데이터를 컴퓨터에 던지고 통계분석을 통해 과학적 발견을 얻지 말라. 이해하는 방식이 아니라 이론적인 통찰력을 가져야 한다."    ------ [^1]: aspect란 자연어 화자의 의견(opinion)이 표현되는 주제(topic)이다. 예컨대 '이 스마트폰은 색깔이 예쁘다'라는 리뷰의 aspect는 '디자인'이다. [^2]: 이와 관련해서는 [이곳](https://ratsgo.github.io/natural%20language%20processing/2017/03/12/s2s/)을 참고 [^3]: 역자가 이해한 바로는, 두번째 단어는 첫번째 단어 예측 결과에 직접적인 영향을 받으므로 테스트 과정에서 첫번째 단어 예측이 오답일 경우 이후 예측이 엉망이 된다. [^4]: 피처 엔지니어링이란 해당 분야의 도메인 지식을 활용하여 기계학습 알고리즘을 작동시키기 위한 입력 특징(feature)을 추출하는 과정을 말한다. 손으로 한땀한땀 만들어내는 수작업에 가깝다. 딥러닝은 이러한 피처 엔지니어링의 도움을 받지 않고도 높은 성능으로 주목을 받고 있다.
median␞ 이 글에서는 데이터를 대표하는 값을 찾는 몇 가지 방법을 소개하였습니다. 너무도 쉽고 당연해 그냥 넘길 수 있는 지표들이지만 'Back to the basic'의 마음가짐으로 정리해봤습니다. 이 글은 '밑바닥부터 시작하는 데이터과학(조엘 그루스, 인사이트 펴냄)'과 '일반통계학(김우철 외, 영지문화사)' 두 책을 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 평균 가장 널리쓰이는 지표는 **평균(mean)**일 것입니다. 특성값들을 모두 더한 뒤 전체 개체 수로 나눈 산술평균으로 정의됩니다. 예컨대 다음과 같이 우리나라 15세 이상 기혼여성을 대상으로 출생아 수를 조사한 결과가 다음과 같다고 가정해봅시다. 출생아 수의 평균은 특성값과 상대도수를 곱해 모두 더한 값이 됩니다. | 특성값(출생아 수) | 0  | 1  | 2  | 3  | 4  | 5  | ... | | :--------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | |  상대도수  | .058 | .151 | .303 | .175 | .113 | .083 | ... | 일반적으로 평균은 가느다란 막대 위해 상대도수에 비례하는 질량의 물체를 각 특성값의 위치에 놓을 때 균형점의 위치가 됩니다. 평균은 해당 집단의 균형점으로서의 균형위치를 나타냅니다.  ## 분위수 모집단 분포의 위치를 나타내는 대표값으로서 **제$p$백분위수(pth percentile)**가 있습니다. 특성값을 작은 것부터 순서대로 나열하였을 때 $p$% 이상의 특성값이 그 값보다 작거나 같고, 또한 $(100-p)$%의 특성값이 그 값보다 크거나 같게 되는 값으로 정의됩니다. 특히 제25백분위수를 **제1사분위수(first quartile)**, 제50백분위수를 **중앙값(median)**, 제75백분위수를 **제3사분위수(third quartile)**이라고 하며 각각 $Q_1$, $Q_2$, $Q_3$로 표시합니다. 이 가운데 모중앙값 $Q_2$는 모평균 $μ$와 같이 모집단 분포의 중심위치를 나타내며 특성값이 연속적인 무한 모집단의 경우에는 밀도곡선의 전체 넓이를 이등분하는 점이 됩니다. 모중앙값은 추정 이론의 어려움 때문에 모평균처럼 통상적으로 고려되는 추론의 대상은 아니지만, **비모수통계학(non-parametric statistics)**에선 중요 고려 대상이 됩니다. 제$p$백분위수를 파이썬 코드로 나타내면 다음과 같습니다. ```python def percentile(x, p):   p_index = int(p * len(x))   return sorted(x)[p_index] ```   ## 중앙값 중앙값을 파이썬 코드로 나타내면 다음과 같습니다. ```python def median(v):   n = len(v)   sorted_v = sorted(v)   midpoint = n // 2   if n % 2 == 1:     # 데이터 포인트의 개수가 홀수면 중앙값을 반환     return sorted_v[midpoint]   else:     # 데이터 포인트의 개수가 짝수면 두 중앙값의 평균을 반환     lo = midpoint - 1     hi = midpoint     return (sorted(v)[lo] + sorted(v)[hi]) / 2 ```   ## 산포 **산포(dispersion)**란 모집단에서 특성값이 흩어져 있는 상태를 뜻합니다. 산포에 관련된 대표적인 측도로 **분산(variance)**이 있습니다만 이 글 다른 꼭지에서 따로 다루겠습니다. 가장 간단한 형태의 산포 측도는 가장 큰 값과 작은 값의 차이를 나타내는 범위(range)일 겁니다. 다음과 같습니다. ```python def data_range(x):   return max(x) - min(x) ```   ## 사분위수 범위 산포를 나타내는 다른 지표로 **사분위수범위(interquantile range)**가 있습니다. 제3사분위수와 제1사분위수의 차로 정의되며, 모집단에서 가운데 50% 특성값의 범위를 나타냅니다. 몇몇 이상치가 주는 영향을 제거해 모집단의 산포를 가늠하는 데 유용한 지표로 알려져 있습니다. 사분위수범위의 파이썬 코드는 다음과 같습니다. ```python # 몇몇 이상치가 주는 영향을 제거해 관측치 편차 비교할 때 유용 def interquantile_range(x):   return percentile(x, 0.75) - percentile(x, 0.25) ```   ## 최빈값 데이터에 제일 자주 등장하는 특성값을 나타냅니다. ```python from collections import Counter def mode(x):   # 최빈값이 하나보다 많다면 list를 반환   counts = Counter(x)   max_count = max(counts.values())   return [x_i for x_i, count in counts.items() if count == max_count] ```   ## 평균을 0으로 맞추기 분산과 공분산을 구하려면 데이터의 평균을 0으로 맞추는 것이 여러모로 편리합니다. 이를 위한 함수를 정의했습니다. ```python def de_mean(x):   #x의 모든 데이터 포인트에서 평균을 뺌   n = len(x)   x_bar = sum(x) / n   return [x_i - x_bar for x_i in x] ```   ## 분산과 표준편차 분산은 데이터의 평균과 각 특성값의 차(편차)를 제곱하여 산술평균한 것입니다. 표준편차는 분산의 제곱근입니다. 분산과 표준편차가 작을 수록 평균값에서 특성값들 사이의 거리가 가깝다는 걸 의미합니다. 이와 관련된 파이썬 코드는 다음과 같습니다. ```python # 분산 def variance(x):   n = len(x)   deviations = de_mean(x)   sum_of_squares = sum([x_i ** 2 for x_i in deviations])   return sum_of_squares / (n - 1) # 표준편차 def standard_deviation(x):   return variance(x) ** 0.5 ```   ## 공분산과 상관관계 상관계수(correlation coefficient)는 두 확률변수의 직선관계가 얼마나 강하고 어떤 방향인지를 나타냅니다. 상관계수에 각 확률변수의 표준편차에 해당하는 값을 곱한 것을 공분산(covariance)이라고 합니다. 파이썬 코드는 다음과 같습니다. ```python import numpy as np def covariance(x, y):   n = len(x)   return np.dot(de_mean(x), de_mean(y)) / (n - 1) def correlation(x, y):   stdev_x = standard_deviation(x)   stdev_y = standard_deviation(y)   if stdev_x > 0 and stdev_y > 0:     return covariance(x, y) / stdev_x / stdev_y   else:     return 0 ```  
sentimentdict␞ 이번 글에서는 통계 기반 감성사전 구축 방법에 대해 살펴보도록 하겠습니다. 이 글은 고려대 강필성 교수님 강의와 [Hur et al.(2016)](http://ac.els-cdn.com/S0020025516306016/1-s2.0-S0020025516306016-main.pdf?_tid=78f198fe-5989-11e7-9811-00000aacb361&acdnat=1498383443_5601767d8c2a2f859323480fb98553e1)을 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 모델의 가정 이 모델은 평점 정보가 있는 영화 리뷰를 대상으로 합니다. 가정은 이렇습니다. 긍정적인 어휘가 쓰인 리뷰의 평점 분포는 전체 분포보다 오른쪽에 있을 것이고, 반대로 부정적인 어휘는 왼쪽에 있을 것이라는 겁니다. 이를 그림으로 나타내면 다음과 같습니다.  <a href="http://imgur.com/2kdiYUf"><img src="http://i.imgur.com/2kdiYUf.png" width="400px" title="source: imgur.com" /></a>  이 모델은 각 단어별 평점의 분포가 t분포를 따를 것이라고 가정합니다. 다음과 같이 **t-test**를 실시하여 **검정통계량**이 일정 수치를 넘으면 해당 단어를 긍정 범주, 일정 수치보다 작으면 부정 범주로 할당하게 됩니다. > $H_0$ : 전체 평균과 해당 단어의 평균 평점이 동일하다. > > $H_1$ : 전체 평균과 해당 단어의 평균 평점이 같지 않다.  ## 검정통계량 아래 식에서 $w_q$는 영화 리뷰 말뭉치에 $q$번째로 등장한 단어, $r_{i,j}$는 $i$번째 사용자가 $j$번째로 작성한 리뷰의 평점, $R(r_{i,j},w_q)$는 $i$번째 사용자가 $j$번째로 작성한 리뷰에 $q$번째 단어가 쓰였을 경우 해당 리뷰의 평점($r_{i,j}$)을 가리킵니다. 만약 해당 리뷰에 $w_q$가 포함돼 있지 않을 경우 $R(r_{i,j},w_q)$은 0이 됩니다. 한편 $m$은 전체 사용자 수, $n_i$는 $i$번째 사용자가 작성한 리뷰의 총수, $n(w_q)$는 $w_q$의 빈도수를 뜻합니다.  $$ \begin{align*} Score({ w }_{ q })=E({ w }_{ q })&=\frac { 1 }{ n({ w }_{ q }) } \sum _{ i=1 }^{ m }{ \sum _{ j=1 }^{ { n }_{ i } }{ R({ r }_{ i,j },{ w }_{ q }) } }\\Var({ w }_{ q })&=\frac { 1 }{ n({ w }_{ q })-1 } \sum _{ i=1 }^{ m }{ \sum _{ j=1 }^{ { n }_{ i } }{ { \left\{ R({ r }_{ i,j },{ w }_{ q })-Score({ w }_{ q }) \right\} }^{ 2 } } } \end{align*} $$  **가설검정**을 위한 검정통계량 $T_w$와 t분포의 자유도 $v$는 다음과 같습니다. $W$는 전체 단어, $w$는 가설검정 대상이 되는 개별 단어를 가리킵니다. $s^2_w$는 $Var(w)$, $E(w)$는 $Score(w)$를 뜻합니다.  $$ \begin{align*} { T }_{ w }&=\frac { E(W)-E(w) }{ \sqrt { \frac { { s }_{ W }^{ 2 } }{ n(W) } +\frac { { s }_{ w }^{ 2 } }{ n(w) } } } \\ v&=\frac { { \left\{ { s }_{ W }^{ 2 }/n(W)+{ s }_{ w }^{ 2 }/n(w) \right\} }^{ 2 } }{ \frac { { \left\{ { s }_{ W }^{ 2 }/n(W) \right\} }^{ 2 } }{ n(W)-1 } +\frac { { \left\{ { s }_{ w }^{ 2 }/n(w) \right\} }^{ 2 } }{ n(w)-1 } } \end{align*} $$   ## 가설검정 $w$에 대한 검정통계량 $T_w$와 자유도 $v$가 주어졌을 때 가설검정은 다음과 같이 실시합니다. (유의수준=$α$)  $$ Positive\quad if\quad { T }_{ w }>t(\alpha ,v)\\ Negative\quad if\quad { T }_{ w }<t(\alpha ,v)\\ Neutral\quad if\quad otherwise $$  ## 실험결과 Hur et al.(2016)의 실험 결과 일부는 다음과 같습니다. 통계 기반의 기법으로도 감성 어휘를 골라내는 데 좋은 성능을 나타냄을 알 수 있습니다.  <a href="http://imgur.com/jcrhIGI"><img src="http://i.imgur.com/jcrhIGI.png" title="source: imgur.com" /></a>  
LUfactorization␞ 이번 포스팅에선 **LU 분해(LU factorization)**에 대해 알아보도록 하겠습니다. 그에 앞서 LU factorization을 이해하기 위한 몇 가지 개념을 짚어보도록 하겠습니다. 이번 글은 [고려대 박성빈 교수님]([hyperspace@korea.ac.kr](mailto:hyperspace@korea.ac.kr))과 [한양대 이상화 교수님](http://www.kocw.net/home/search/kemView.do?kemId=977757) 강의를 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 확대행렬, 기본행연산, 가우스행렬, 행상등, 역행렬... 우선 선형대수학의 기초 용어 몇 가지를 정의하고 넘어가겠습니다. 아래의 경우에는 제 개인적으로도 정리용도로 남겨두는 것이니 선형대수학이 생소하신 분들은 스킵하셔도 무방할 것 같습니다.  > **확대행렬(augmented coefficient matrix)** : 1차 연립방정식의 계수와 상수항으로 이뤄진 행렬 > **가우스행렬/행사다리꼴(row-echelon matrix)** : 다음 세 가지를 만족하는 행렬이다. (1) 영행이 있다면 그것은 영행이 아닌 행의 아래에 있다. (2) 영행이 아닌 행의 첫번째 0이 아닌 원소를 그 행의 **선도원소(leading entry)**라 하고 모든 선도원소는 1이다. (3) 영행이 아닌 연속된 두 행이 있을 때 각각 i번째 행과 i+1번째 행이라 한다면 i번째 행의 선도원소는 i+1번째 행의 선도원소보다 왼쪽에 있다(역계단모양) > **추축열(pivot column)** : 가우스행렬의 각 행별로 선도원소에 대응하는 열을 추축열이라 한다. (pivot=non-zero) 추축열의 수와 방정식의 수가 같아야 연립방정식의 해가 유일하다. 추축열은 가우스행렬 열벡터들이 만드는 열공간의 기저가 된다. > **기약가우스행렬(reduced echelon matrix)** : 가우스행렬 A에 대하여 i번째 행의 선도원소가 j번째 열에 있다면 j번째 열의 다른 모든 원소는 0이다(가우스행렬이면서 선도원소 위, 아래 모든 수가 0인 행렬) 아래 예시에서 A, B는 가우스행렬, C, D는 기약가우스행렬입니다. 가우스행렬이든 기약가우스행렬이든 구하는 이유는 선도원소에 해당하는 연립방정식의 해를 바로 찾을 수 있기 때문입니다. C는 x, y, z, 상수에서 도출한 확대행렬에서 얻어진 기약가우스행렬이라고 한다면, x의 해는 4, y=7, z=-1입니다. $$A=\begin{bmatrix} 1 & 0 & 2 & 3 \\ 0 & 1 & 1 & 4 \\ 0 & 0 & 0 & 1 \end{bmatrix},\quad B=\begin{bmatrix} 1 & 1 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{bmatrix}\\ C=\begin{bmatrix} 1 & 0 & 0 & 4 \\ 0 & 1 & 0 & 7 \\ 0 & 0 & 1 & -1 \end{bmatrix},\quad D=\begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$$ A에서 추축열은 1, 2열입니다. 선형대수학에서 추축열은 대단히 중요한 개념인데요, 해당 행렬의 열 벡터들이 만드는 **열 공간(column space)**의 **기저(basis)**가 되기 때문입니다. (열 공간과 기저는 추후에 살펴보겠습니다) A열의 추축열이 아닌 3열은 추축열인 1열을 2배한 뒤 2열을 더하면(선형결합으로) 만들어 낼 수 있습니다. > **기본행연산(elementary row operation)** : 임의의 확대행렬을 가우스행렬로 만드는 연산을 기본행연산이라고 한다. 기본행연산은 연립방정식의 **소거법**과 동일하다. 기본행연산에는 3개 방법이 있다. (1) **행 교환**(row switching transformations) : 행 순서를 바꿔도 해(영공간)가 바뀌지 않는다. (2) **상수 곱셈**(row-multiplying transformations) : 임의의 행 전체에 0이 아닌 상수를 곱해도 해가 바뀌지 않는다. (3) **한 행의 배수를 다른 행에 더함**(row-addition transformations) : 임의의 행에 c배를 하고 이것을 다른 행에 더해도 해가 바뀌지 않는다. > **행상등(row-equivalent)** : 행렬 A에 기본행연산을 적용하여 행렬 B를 얻을 수 있는 경우 A와 B는 행상등이라고 한다. > **단위행렬(identity matrix)** : 주대각선이 전부 1이고 나머지 원소는 0을 값으로 갖는 n x n 정방행렬. 단위 행렬은 행렬곱셈의 항등원이다. > **역행렬(inverse matrix)** : n차 정방행렬 A에 대하여 AB=BA=I을 만족하는 행렬 B가 존재할 때 B를 A의 역행렬이라하고, 이때 A를 가역(invertible) 또는 정칙행렬이라 한다. 만일 이와 같은 B가 존재하지 않으면 A를 **특이행렬(singular matrix)**이라 한다. > **위수(rank)** : 행렬 A에 기본행연산을 적용하여 가우스행렬로 만들었을 때 영행이 아닌 행의 수를 위수라고 한다. 위수는 가우스행렬의 추축열의 수, 그리고 행렬 A의 **차원(dimension)** 수(기저의 수)와 일치한다.  > **자유변수(free variable)** : 말 그대로 아무 값이나 가져도 되는 미지수. 임의의 가우스행렬 A의 위수가 열의 개수보다 작으면 자유변수가 1개 이상 존재한다.  > **기본행렬(elementary matrix)** : 임의의 단위행렬에 대해 한 번의 기본행연산을 해서 얻어지는 행렬을 기본행렬(E)이라고 한다. 행렬 A에 E를 곱한 EA는 A에 기본행연산을 해서 얻은 행렬과 같다. 기본행렬과 관련한 예를 들어보겠습니다. 3x3 단위행렬의 첫번째 행에 3배를 해준 뒤 두번째 행에 더해준((3) 유형의 기본행 연산) 기본행렬 E는 아래와 같습니다. 이를 행렬 A에 같은 유형의 기본행연산을 한 직접 결과와 비교해 보면 정확하게 일치합니다. $$A=\begin{bmatrix} 1 & 2 & 3 \\ 1 & 0 & 1 \\ 1 & 1 & 2 \end{bmatrix},\quad E=\begin{bmatrix} 1 & 0 & 0 \\ 3 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}\\ EA=\begin{bmatrix} 1 & 0 & 0 \\ 3 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}\begin{bmatrix} 1 & 2 & 3 \\ 1 & 0 & 1 \\ 1 & 1 & 2 \end{bmatrix}=\begin{bmatrix} 1 & 2 & 3 \\ 4 & 6 & 10 \\ 1 & 1 & 2 \end{bmatrix}\\ A=\begin{bmatrix} 1 & 2 & 3 \\ 1 & 0 & 1 \\ 1 & 1 & 2 \end{bmatrix}\longrightarrow \begin{bmatrix} 1 & 2 & 3 \\ 4 & 6 & 10 \\ 1 & 1 & 2 \end{bmatrix}$$  이상 논의를 종합하여 정리해보겠습니다. > **Thorem** : 임의의 행렬 A와 B가 행상등하면 행렬 B에 대해 유한번의 기본행연산을 해서(=유한개의 기본행렬을 곱해서) A를 얻을 수 있다. 모든 기본행렬은 역행렬이 존재(가역)이고, 그 역행렬 또한 기본행렬이다. 행렬 A에 대해 유한 번의 기본행연산을 하여 단위행렬 I를 얻을 수 있을 때(=A와 I가 행상등일 때) 같은 기본행연산을 I에 대해 적용하여 A의 역행렬을 구할 수 있다. n x n 행렬 A가 가역(역행렬이 존재)이면 nx1 벡터 B에 대한 행렬방정식 AX=B는 유일한 해를 갖는다. n x n 행렬 A가 단위행렬 I와 행상등이면 AX=0의 해는 유일하다. AX=0의 해가 유일하면 행렬 A는 단위행렬 I와 행상등이다. 또한 mxn 행렬 A와 n차원 벡터 x, m차원 벡터 b로 이뤄진 'Ax=b'에 대하여 아래 명제들은 서로 **동치(logical equivalence)**입니다. 즉, 모든 명제가 동시에 참이거나 동시에 거짓입니다.  > Ax=b는 유일한 해를 갖는다. > b는 계수행렬 A의 열벡터의 선형결합으로 표시된다. > 계수행렬 A의 열벡터는 m차원 실수공간을 **생성(span)**한다. > A는 모든 행에 **pivot positon**을 하나 가진다.  ## LU 분해 LU 분해란 기본행연산에 의해 단위행렬(indentity matrix)로 변환할 수 있는 임의의 행렬 A를 아래와 같이 **하삼각행렬(Lower triangular matrix)**과 **상삼각행렬(Upper triangular matrix)**의 곱으로 분해하는 것입니다.  $$A=LU=\begin{bmatrix} 1 & 0 & 0 & 0 \\ * & 1 & 0 & 0 \\ * & * & 1 & 0 \\ * & * & * & 1 \end{bmatrix}\begin{bmatrix} ▣ & * & * & * & * \\ 0 & ▣ & * & * & * \\ 0 & 0 & 0 & ▣ & * \\ 0 & 0 & 0 & 0 & 0 \end{bmatrix}$$ 행렬 A에 대해 유한번(k)의 기본행연산을 수행해 가우스행렬로 변환한 것이 상삼각행렬 U입니다. 행렬 A에 대한 기본행연산은 A와 기본행렬의 곱으로 나타낼 수 있고, 기본행렬의 역행렬은 기본행렬이기 때문에 아래와 같이 쓸 수 있습니다. $${ E }^{ k }{ E }^{ k-1 }{ E }^{ k-2 }...{ E }^{ 1 }A=U\\ A={ ({ E }^{ k }{ E }^{ k-1 }{ E }^{ k-2 }...{ E }^{ 1 }) }^{ -1 }U=LU$$ 따라서 하삼각행렬 L은 행렬 A에 대한 기본행연산의 **history**가 되는 것입니다. 임의의 행렬 A에 대한 LU분해 결과는 유일함이 증명되어 있습니다. LU 분해의 이점은 무엇일까요? 만일 A가 LU로 분해될 수 있으면 Ax=b라는 방정식은 LUx=b로 변환됩니다. Ux=y로 두면 Ax=b는 Ly=b로 고쳐 풀 수 있습니다. L과 U는 이미 미지수를 구하기 편하도록 정리된 형태이기 때문에 아무리 미지수가 많더라도 빠른 시간에 방정식의 해를 구할 수 있습니다.  해의 존재성 여부나 **행렬식(determinant)**도 빠르게 확인 가능합니다. 상삼각행렬이든 하삼각행렬이든 삼각행렬의 행렬식은 모든 대각성분의 곱과 같습니다. 따라서 A가 LU분해가 되어 있을 경우 A의 행렬식은 L의 행렬식과 U의 행렬식을 각각 L, U의 모든 대각성분을 곱해 간단히 구할 수 있습니다. A의 행렬식이 0인지 여부로 해의 존재성 여부도 확인할 수 있습니다. 아울러 삼각행렬은 역행렬 구하기도 쉽죠. 또 LU 분해는 **특이값 분해** 등 각종 행렬 분해와도 깊은 연관을 지니고 있습니다. 한편 지금까지는 LU 분해는 **행 교환(row interchange)**을 하지 않고 기본행연산을 수행했다는 가정 하에 설명을 드렸는데요. 행 교환 또한 행렬 곱 형태로 나타낼 수 있습니다. 예컨대 1행과 2행을 교환해주는 역할을 하는 3 x 3 크기의 **permutraion matrix** P는 다음과 같습니다. $$P=\begin{bmatrix} 0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{bmatrix}$$ 보시다시피 단위행렬(indentity matrix)와 거의 유사한 꼴을 지녔으나 1의 위치가 다소 다릅니다. permutation matrix의 특징은 아래와 같습니다. - 단위행렬과 행의 개수가 같다. - 모든 행과 열에 1이 단 한 개 존재한다. - 역행렬(=교환한 행을 원래대로 돌려놓는 역할 수행)은 그 전치행렬과 같다. permutation matrix까지 고려하면 LU분해는 최종적으로 아래와 같이 쓸 수 있습니다. $$PA=LU\\ A={ P }^{ T }LU$$ 
determinants␞ 이번 글에서는 행렬식에 대해 살펴보겠습니다. 이번 글은 고려대 박성빈 교수님 강의와 David C. Lay의 Linear Algebra (4th edition)을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 행렬식의 정의 **행렬식(determinant)**은 행렬을 대표하는 값으로 n x n (n은 2 이상)의 정방행렬 $A$에 대해 다음과 같이 정의됩니다. $detA_{11}$이란 $A$에서 1행과 1열을 제외한 행렬의 행렬식을 의미합니다. 2 x 2 행렬의 요소값이 $a,b,c,d$라고 할 때 행렬식은 $ad-bc$입니다.  $$ \begin{align*} detA&={ a }_{ 11 }det{ A }_{ 11 }-{ a }_{ 12 }det{ A }_{ 12 }+...+{ (-1) }^{ 1+n }det{ A }_{ 1n }\\ &=\sum _{ j=1 }^{ n }{ { (-1) }^{ 1+j }{ a }_{ 1j }det{ A }_{ 1j } } \end{align*} $$ $A$가 다음 행렬이라고 칩시다. $$ A=\begin{bmatrix} 1 & 5 & 0 \\ 2 & 4 & -1 \\ 0 & -2 & 0 \end{bmatrix} $$ $detA$는 다음과 같이 계산할 수 있습니다.  $$ \begin{align*} detA&={ a }_{ 11 }det{ A }_{ 11 }-{ a }_{ 12 }det{ A }_{ 12 }+{ a }_{ 13 }det{ A }_{ 13 }\\\\ &=1\cdot det\begin{bmatrix} 4 & -1 \\ -2 & 0 \end{bmatrix}-5\cdot det\begin{bmatrix} 2 & -1 \\ 0 & 0 \end{bmatrix}+0\cdot det\begin{bmatrix} 2 & 4 \\ 0 & -2 \end{bmatrix}\\\\ &=1(0-2)-5(0-0)+0(-4-0)=-2 \end{align*} $$ 지금까지는 행렬식을 구할 때 $A$의 첫번째 행을 쓰는 걸 기준으로 설명해드렸는데 사실 어떤 행이나 열을 택해서 구해도 행렬식은 같은 값이 나옵니다. 행렬식 계산을 일반화해서 나타내면 아래와 같습니다. 이 때 $C_{ij}$를 **(i,j)-cofactor**라고 합니다.  $$ \begin{align*} &{ C }_{ ij }={ (-1) }^{ i+j }det{ A }_{ ij }\\\\ use\quad ith\quad row\quad :\quad &detA={ a }_{ i1 }det{ C }_{ i1 }+{ a }_{ i2 }det{ C }_{ i2 }+...+{ a }_{ in }det{ C }_{ in }\\\\ use\quad jth\quad col\quad :\quad &detA={ a }_{ 1j }det{ C }_{ 1j }+{ a }_{ 2j }det{ C }_{ 2j }+...+{ a }_{ nj }det{ C }_{ nj } \end{align*} $$  ## 행렬식의 성질 행렬식의 성질은 다음과 같습니다. >(1) 행렬 $A$의 임의의 행에 스칼라 곱을 한 뒤 다른 행에 더해 $B$를 만들었을 때 두 행렬의 행렬식은 같다. > >(2) 행렬 $A$의 임의의 행을 다른 행과 바꾸어 $B$를 만들었을 때 $detB=-detA$ > >(3) 행렬 $A$의 임의의 행에 스칼라 곱을 해 $B$를 만들었을 때 $detB=kdetA$ > >(4) **삼각행렬(triangular matrix)**의 행렬식은 주 대각원소들의 곱과 같다. > >(5) 행렬 $A$가 **가역(invertible)**임과 $detA≠0$임은 동치입니다. > >(6) $detA^T=detA$ > >(7) $detAB=(detA)(detB)$  ## 선형시스템의 해와 행렬식 **크래머의 법칙(Cramer's Rule)**은 다음과 같습니다. $n*n$ 크기의 행렬 $A$가 가역이고, 임의의 $n$차원 벡터 $b$에 대해 $Ax=b$가 유일한 해를 갖는다면 $x$의 $i$번째 요소값인 $x_i$는 아래 식과 같습니다.  $$ x_{ i }=\frac { det{ A }_{ i }(b) }{ detA } $$ $e$는 $n*n$ 크기의 **단위행렬(identity matrix)**의 열벡터를 뜻하는데요. $A_i(b)$는 단위행렬의 $i$번째 열벡터 $e_i$를 $b$로 대체한 행렬에 $A$를 곱한 행렬을 가리킵니다. 다음과 같습니다. $$ \begin{align*} A\cdot { I }_{ i }(x)=&A\begin{bmatrix} { e }_{ 1 } & ... & x & ... & { e }_{ n } \end{bmatrix}\\ &=\begin{bmatrix} { Ae }_{ 1 } & ... & Ax & ... & A{ e }_{ n } \end{bmatrix}\\ &=\begin{bmatrix} { a }_{ 1 } & ... & b & ... & a_{ n } \end{bmatrix}\\ &={ A }_{ i }(b) \end{align*} $$ 크래머의 법칙을 활용하면 행렬식만으로도 선형 시스템의 해를 구할 수 있게 됩니다.  ## 역행렬과 행렬식 **기본행연산** 말고도 역행렬을 구할 수 있는 방법이 있습니다. 행렬식을 이용하는 것입니다. 다음과 같습니다. $$ \begin{align*} { A }^{ -1 }&=\frac { 1 }{ detA } \begin{bmatrix} { C }_{ 11 } & { C }_{ 21 } & ... & { C }_{ n1 } \\ { C }_{ 12 } & { C }_{ 22 } & ... & { C }_{ n2 } \\ ... & ... & ... & ... \\ { C }_{ 1n } & { C }_{ 2n } & ... & { C }_{ nn } \end{bmatrix}\\ &=\frac { 1 }{ detA } adjA \end{align*} $$  ## 행렬식의 기하학적 성질 : 부피 행렬식을 기하학적으로 살펴보겠습니다. $detA=detA^T$가 성립하고, 두 개 열벡터의 위치를 바꾸거나 임의의 열에 스칼라곱을 한 뒤 다른 열에 더해도 행렬식의 크기가 바뀌지 않으므로 임의의 $2*2$ 행렬 $A$를 아래와 같은 형태로 변형해 행렬식을 구해도 됩니다.  $$ \left| det\begin{bmatrix} a & 0 \\ 0 & d \end{bmatrix} \right| =\left| ad \right| $$ 이를 그림으로 나타내면 $2*2$ 행렬 $A$의 행렬식은 일종의 **넓이**로 이해할 수 있습니다. <a href="http://imgur.com/qPBOBWA"><img src="http://i.imgur.com/qPBOBWA.png" width="200px" title="source: imgur.com" /></a> 이를 일반화해서 생각해 보겠습니다. $2*2$ 행렬 $A$의 영벡터가 아닌 열벡터를 각각 $a_1, a_2$, 그리고 임의의 스칼라를 $c$라고 둡시다. 아래 그림을 보겠습니다.  <a href="http://imgur.com/ZM77X8c"><img src="http://i.imgur.com/ZM77X8c.png" width="450px" title="source: imgur.com" /></a>  위 그림을 보시면 $a_1$과 $a_2+ca_1$이 이루는 직사각형의 넓이와 $a_1$과 $a_2$가 이루는 평행사변형의 넓이가 같습니다. 행렬식의 성질에 의해 임의의 열에 스칼라곱을 한 뒤 다른 열에 더해도 행렬식의 크기가 바뀌지 않으므로 자명한 사실입니다. 마찬가지로 $3*3$ 크기 행렬의 행렬식은 일종의 **부피**로 이해할 수 있습니다. 아래 그림과 같습니다.  <a href="http://imgur.com/l6pttjr"><img src="http://i.imgur.com/l6pttjr.png" width="200px" title="source: imgur.com" /></a>  이를 또 일반화해서 나타내면 아래와 같습니다. <a href="http://imgur.com/efEXej2"><img src="http://i.imgur.com/efEXej2.png" width="500px" title="source: imgur.com" /></a>   ## 선형변환과 행렬식 선형변환 $T: R^2 → R^2$에 대응하는 $2*2$ 크기의 **표준행렬(standard matrix)** $A$가 있다고 칩시다. $S$가 $R^2$에 존재하는 도형일 때 면적과 관계된 식과 그림은 다음과 같습니다.  $$ \left\{ area\quad of\quad T(S) \right\} =\left| detA \right| \cdot \{ area\quad of\quad S\} $$ <a href="http://imgur.com/yoUtSnh"><img src="http://i.imgur.com/yoUtSnh.png" width="200px" title="source: imgur.com" /></a> 마찬가지로 3차원에서는 아래와 같이 정의됩니다.  $$ \left\{ volume\quad of\quad T(S) \right\} =\left| detA \right| \cdot \{ volume\quad of\quad S\} $$  
gcd␞ 이번 글에서는 최대공약수와 최소공배수를 찾는 알고리즘에 살펴보도록 하겠습니다. 이 글은 위키피디아와 [이곳](https://www.programiz.com/python-programming/examples/hcf)을 참고하였습니다. 그럼 시작하겠습니다.  ## 최대공약수 $x$의 약수이면서 $y$의 약수인 수 중 최대값을 $x$와 $y$의 최대공약수라고 합니다. 최대공약수를 구하는 가장 간단한 방법은 1~($x$와 $y$ 중 작은 값) 범위에서 공약수(둘 모두 나머지가 0)를 모두 구해 이 가운데 최대값을 구하는 방법입니다.  그런데 우리는 최대값에만 관심이 있으므로 역순, 즉 ($x$와 $y$ 중 작은 값)~1까지의 범위를 탐색해 가장 처음 발견한 공약수를 최대공약수로 삼으면 더 좋을 것입니다. 파이썬으로 구현한 코드는 다음과 같습니다. ```python def computeHCF(x, y):   # 두 수 가운데 작은값 찾기   if x > y:     smaller = y   else:     smaller = x   # smaller~1까지의 범위를 역순으로 탐색   for i in range(smaller + 1, 1, -1):     # 처음 공약수를 발견하면 그 수를 hcf에 저장하고     # 탐색 종료     if ((x % i == 0) and (y % i == 0)):       hcf = i       break   return hcf ``` 유클리드 호제법(Euclidean algorithm)을 이용할 수도 있습니다. 1071과 1029의 최대공약수를 유클리드 호제법을 활용해 계산하면 다음과 같습니다. > (1) 1071은 1029로 나누어 떨어지지 않기 때문에 1071을 1029로 나눈 나머지를 구한다 : **42** > > (2) 1029는 42로 나누어 떨어지지 않기 때문에 1029를 42로 나눈 나머지를 구한다 : **21** > > (3) 42는 21로 나누어 떨어진다 > > (4) 1071과 1029의 최대공약수는 21이다. 유클리드 호제법으로 최대공약수를 구하는 파이썬 코드는 다음과 같습니다. ```python def computeHCF_euc(x, y):  # y가 0이 될 때까지 반복  while(y):    # y를 x에 대입    # x를 y로 나눈 나머지를 y에 대입    x, y = y, x % y  return x ```    ## 최소공배수 $x$와 $y$의 공통된 배수 가운데 최소값을 최소공배수라고 합니다. 최소공배수를 구하는 가장 간단한 방법은 다음과 같습니다. ```python def lcm(x, y):  # 두 수 가운데 큰 값 찾기  if x > y:    greater = x  else:    greater = y  # greater의 값을 1씩 증가시키면서 반복  while(True):    # greater가 x와 y로 모두 나누어 떨어질 경우    # 최소공배수이므로 이 값을 lcm에 저장하고 반복문 종료    if((greater % x == 0) and (greater % y == 0)):      lcm = greater      break    greater += 1  return lcm ``` 최대공약수와 최소공약수 사이의 관계와 유클리드 호제법을 활용해 구할 수도 있습니다. 예컨대 $x=ab$이고 $y=bc$라면 $x$와 $y$의 최대공약수는 $b$, 최소공배수는 $abc$입니다. $xy=ab^2c$이므로 이를 최대공약수 $b$로 나눠주면 최소공배수를 구할 수 있습니다.  우리는 이미 유클리드 호제법을 활용해 최대공약수를 구하는 알고리즘을 구현해 놓았으므로 이를 다시 활용합니다. 다음과 같습니다. ```python def lcm(x, y):  lcm = (x*y)//computeHCF_euc(x,y)  return lcm ``` 
VAEs␞ 이번 글에서는 **Variational AutoEncoder**(VAE)의 발전된 모델들에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. PyTorch 코드는 [이곳](https://github.com/GunhoChoi/PyTorch-FastCampus)을 참고하였습니다. VAE의 기본적 내용에 대해서는 [이곳](https://ratsgo.github.io/generative%20model/2018/01/27/VAE/)을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.   ## Conditional VAE Conditional VAE(CVAE)란 다음 그림과 같이 기존 VAE 구조를 지도학습(supervised learning)이 가능하도록 바꾼 것입니다. *encoder*와 *decoder*에 정답 레이블 $y$가 추가된 형태입니다.  <a href="https://imgur.com/uhYATU8"><img src="https://i.imgur.com/uhYATU8.png" width="400px" title="source: imgur.com" /></a>  *encoder*에서 $z$를 만들 때 $y$ 정보가 추가됩니다. PyTorch 코드는 다음과 같습니다. ```python def Q(X, c):   inputs = torch.cat([X, c], 1)# (X,y)   z = encoder(inputs)   z_mu = z[:,:Z_dim]   z_var = z[:,Z_dim:]   return z_mu, z_var ``` *decoder*에서 $x$를 복원할 때 $y$ 정보가 필요합니다. PyTorch 코드는 다음과 같습니다. ```python def P(z, c):   inputs = torch.cat([z, c], 1) # (Z,y)   x = decoder(inputs)   return x ``` CVAE의 손실함수는 $y$의 추가로 수식은 달라지지만, 코드상으로는 기존 VAE와 동일합니다. 마지막 아웃풋에 VAE처럼 $x$만 있기 때문입니다. 다음과 같습니다. ```python def sample_z(mu, log_var):   eps = Variable(torch.randn(mb_size, Z_dim))   return mu + torch.exp(log_var / 2) * eps.cuda() # Forward z_mu, z_var = Q(X, c) z = sample_z(z_mu, z_var) X_sample = P(z, c) # Loss recon_loss = nn.functional.binary_cross_entropy(X_sample, X, size_average=False) / mb_size kl_loss = torch.mean(0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1. - z_var, 1)) loss = recon_loss + kl_loss ``` 학습된 CVAE에 아래 그림과 같이 실제 손으로 3이라고 쓴 그림과 함께 label 정보를 바꿔가며 입력하게 되면 다음과 같이 출력된다고 합니다. 다시 말해 CVAE 모델이 데이터 분포를 학습할 때 범주 정보까지 함께 고려하게 된다는 의미입니다. <a href="https://imgur.com/wcAwFWe"><img src="https://i.imgur.com/wcAwFWe.png" title="source: imgur.com" /></a>   ## Adversarial Autoencoder Adversarial Autoencoder(AAE)란 VAE에 GAN를 덧입힌 구조입니다. 다음 그림과 같습니다. GAN과 관련 자세한 내용은 [이곳](https://ratsgo.github.io/generative%20model/2017/12/20/gan/)을 참고하시면 좋을 것 같습니다.  <a href="https://imgur.com/LnDYyPj"><img src="https://i.imgur.com/LnDYyPj.png" width="600px" title="source: imgur.com" /></a>  AAE에서는 기존 VAE 구조가 기존 GAN에서의 생성자(generator) 역할을 합니다. 생성자의 *encoder*는 데이터 $x$를 받아서 잠재변수 $z$를 샘플링하고, 생성자의 *decoder*는 이로부터 다시 $x$를 복원합니다. AAE가 기존 VAE와 다른 점은 기존 GAN의 구분자(discriminator) 역할을 하는 네트워크가 추가되었다는 점입니다. 이 구분자는 생성자의 *encoder*가 샘플링한 가짜 $z$와 $p(z)$로부터 직접 샘플링한 진짜 $z$를 구분하는 역할을 합니다. 이렇게 복잡한 네트워크를 만든 이유는 VAE 특유의 단점 때문입니다. VAE는 사전확률 분포 $p(z)$를 표준정규분포로 가정하고, $q(z$\|$x)$를 이와 비슷하게 맞추는 과정에서 학습이 이루어집니다. VAE 아키텍처가 이처럼 구성되어 있는 이유는 표준정규분포와 같이 간단한(?) 확률함수여야 샘플링에 용이하고, KLD 계산을 쉽게 할 수 있기 때문입니다. (자세한 내용은 [이곳](https://ratsgo.github.io/generative%20model/2018/01/27/VAE/) 참고) 그런데 실제 데이터 분포가 정규분포를 따르지 않거나 이보다 복잡할 경우 VAE 성능에 문제가 발생할 수 있습니다. 그런데 GAN의 경우 모델에 특정 확률분포를 전제할 필요가 없습니다. GAN은 데이터가 어떤 분포를 따르든, 데이터의 실제 분포와 생성자(모델)가 만들어내는 분포 사이의 차이를 줄이도록 학습되기 때문입니다. (자세한 내용은 [이곳](https://ratsgo.github.io/generative%20model/2017/12/20/gan/) 참고) VAE의 *regularization term*을 GAN Loss로 대체할 경우 사전확률과 사후확률 분포를 정규분포 이외에 다른 분포를 쓸 수 있게 돼 모델 선택의 폭이 넓어지는 효과를 누릴 수 있습니다. 어쨌든 개별 데이터 샘플 $x_i$와 사전확률분포 $p(z)$에서 뽑은 $z_i$에 대해 AAE의 학습과정은 다음과 같습니다.  <a href="https://imgur.com/5S0GPMe"><img src="https://i.imgur.com/5S0GPMe.png" width="600px" title="source: imgur.com" /></a> AAE의 PyTorch 코드는 다음과 같습니다. 우선 생성자(*encoder, decoder*)와 구분자를 정의합니다. ```python # Encoder Q = torch.nn.Sequential(   torch.nn.Linear(X_dim, h_dim),   torch.nn.ReLU(),   torch.nn.Linear(h_dim, z_dim)) # Decoder P = torch.nn.Sequential(   torch.nn.Linear(z_dim, h_dim),   torch.nn.ReLU(),   torch.nn.Linear(h_dim, X_dim),   torch.nn.Sigmoid()) # Discriminator D = torch.nn.Sequential(   torch.nn.Linear(z_dim, h_dim),   torch.nn.ReLU(),   torch.nn.Linear(h_dim, 1),   torch.nn.Sigmoid()) ```  Step1의 *reconstruction error*를 계산하는 과정은 다음과 같습니다. ```python """ Reconstruction phase """ z_sample = Q(X) X_sample = P(z_sample) recon_loss = nn.binary_cross_entropy(X_sample, X) ``` Step2의 구분자 학습을 위한 손실을 구하는 과정은 다음과 같습니다. 생성자의 *encoder*가 샘플링하는 $z$는 가짜, $p(z)$로부터 직접 뽑는 $z$는 진짜라고 레이블을 부여합니다. ```python # Discriminator z_real = Variable(torch.randn(mb_size, z_dim)) z_fake = Q(X) D_real = D(z_real) D_fake = D(z_fake) D_loss = -torch.mean(torch.log(D_real) + torch.log(1 - D_fake)) ``` Step3의 생성자 학습을 위한 손실을 구하는 과정은 다음과 같습니다. ```python # Generator z_fake = Q(X) D_fake = D(z_fake) G_loss = -torch.mean(torch.log(D_fake)) ```   ## GAN vs VAE GAN과 VAE의 차이점을 도식적으로 나타낸 표는 다음과 같습니다 | Model | Optimization              | Converge   | Image Quality | Generalization  | 비고               | | ----- | --------------------------------------- | ------------- | ------------- | ---------------- | ------------------------------ | | VAE  | Stochastic Gradient Descent       | Local Minimum | 부드럽고 흐리다   | 오버피팅 경향이 상대적으로 큼 | -               | | GAN  | Alternating Stochastic Gradient Descent | Saddel points | 선명하나 아티팩트가 많다 | 새로운 영상을 잘 생성해냄  | Mode collapsing 문제 발생, 수렴이 어렵다 | GAN과 VAE의 장점을 모두 취해 만든 연구로는 Energy-based GAN(EBGAN), Stack GAN 등이 있습니다.   ## Sketch RNN Sketch RNN은 VAE에 RNN 구조를 덧입힌 아키텍처입니다. *encoder*와 *decoder*에 RNN를 썼습니다. 다음 그림과 같습니다. <a href="https://imgur.com/qssmRdT"><img src="https://i.imgur.com/qssmRdT.png" title="source: imgur.com" /></a>
network␞ 이번 글에서는 문서를 **네트워크**로 표현하는 방법론에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의를 참고로 했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 네트워크? **네트워크(network)**란 **간선(edge)**으로 연결된 **꼭지점(node)**들의 집합을 의미합니다. 일반적인 의미에서 **그래프(graph)**와 유사한 개념입니다. 다양한 분야에서 쓰이는 관련용어를 한번 정리해보겠습니다. | Points |   Lines   |   Domain   | | :------: | :------------: | :--------------: | | Vertices |  Edges,Arcs  |    Math    | | Nodes  |   Links   | Computer Science | | Sites  |   Bonds   |   Physics   | | Actors | Ties,Relations |  Sociology   | | Keyword | Co-occurrence |  Text Mining  | 네트워크의 종류는 아래처럼 크게 네 가지로 나눌 수 있습니다. **무방향(Undirected)** 네트워크는 간선의 방향성이 없는 네트워크를, **방향(Directed)** 네트워크는 방향성이 있는 네트워크를 의미합니다. 간선의 가중치가 있는지 여부에 따라 **binary**, **valued** 네트워크로 나뉩니다. 텍스트 마이닝에서는 무방향 네트워크가 더 자주 쓰입니다. <a href="http://imgur.com/hKJDAnP"><img src="http://i.imgur.com/hKJDAnP.png" width="600px" title="source: imgur.com" /></a>  ## 네트워크 표현 <a href="http://imgur.com/WINw1k4"><img src="http://i.imgur.com/WINw1k4.png" width="400px" title="source: imgur.com" /></a> 위와 같은 무방향 네트워크는 아래와 같이 **인접행렬(adjacency matrix)**로 표현할 수 있습니다. 인접행렬의 각 요소를 보면 어느 꼭지점들이 간선으로 연결되어 있는지를 알 수 있습니다. binary 네트워크에서는 꼭지점이 간선으로 연결돼 있을 경우 1, 그렇지 않으면 0으로 표시됩니다(Valued 네트워크라면 인접행렬의 요소값이 가중치값이 됩니다). 무방향 네트워크는 방향성이 존재하지 않기 때문에 인접행렬이 **대칭행렬(symmetric matrix)**입니다. | 구분 | a  | b  | c  | d  | e  | | :--: | :--: | :--: | :--: | :--: | :--: | | a  | 0  | 1  | 0  | 0  | 0  | | b  | 1  | 0  | 1  | 0  | 0  | | c  | 0  | 1  | 0  | 1  | 1  | | d  | 0  | 0  | 1  | 0  | 1  | | e  | 0  | 0  | 1  | 1  | 0  | 마찬가지로 아래와 같은 방향 네트워크도 인접행렬로 표현할 수 있습니다. 방향 네트워크는 무방향 네트워크와 달리 인접행렬이 대칭행렬이 아님을 확인할 수 있습니다. <a href="http://imgur.com/etVaHEq"><img src="http://i.imgur.com/etVaHEq.png" width="400px" title="source: imgur.com" /></a> | 구분 | a  | b  | c  | d  | e  | | :--: | :--: | :--: | :--: | :--: | :--: | | a  | 0  | 1  | 0  | 0  | 0  | | b  | 1  | 0  | 0  | 0  | 0  | | c  | 0  | 1  | 0  | 1  | 1  | | d  | 0  | 0  | 0  | 0  | 1  | | e  | 0  | 0  | 1  | 1  | 0  | 꼭지점의 수가 많아질수록 인접행렬은 0이 많은 **희소행렬(sparse matrix)** 형태가 됩니다. 그만큼 메모리를 많이 잡아먹는다는 뜻입니다. 이 때문에 상당수 네트워크 처리 라이브러리는 인접행렬 말고 아래와 같이 **Adjacency List**, **Arc List** 형태로 네트워크를 분석합니다. 아래는 첫 예시인 무방향 binary 네트워크를 표현한 것입니다. > **Adjacency List** > > a\|b > > b\|a c > > c\|b d e > > d\|c e > > e\|c d  > **Arc List** > > a b > > b a > > b c > > c b > > c d > > c e > > d c > > d e > > e c > > e d  ## 네트워크 시각화 네트워크를 시각화하는 방법은 무수히 많이 존재합니다. 예컨대 아래 네 개의 네트워크는 얼핏 보면 다른 것 같지만 동일한 네트워크인 걸 알 수 있습니다. <a href="http://imgur.com/Xklw7j6"><img src="http://i.imgur.com/Xklw7j6.png" width="600px" title="source: imgur.com" /></a> 네트워크를 시각화하는 알고리즘도 많이 제안되었는데요. 이들 알고리즘이 지향하는 큰 원칙은 이렇습니다. 꼭지점이 한쪽으로 쏠리거나 간선이 겹치는 걸 최소화하고, 간선의 길이는 균일하게 맞추며, 전체적인 네트워크의 모양은 가급적 대칭적인 구조가 되게끔 하라 등등입니다.  ## 네트워크의 속성 네트워크의 몇 가지 속성을 살펴보겠습니다. **크기(size)** : 간선의 개수 **밀도(density)** : 실제 간선의 수 / 이론적으로 가능한 모든 간선의 수 (꼭지점이 n개일 경우 n * (n - 1) ) **Out-degree** : 하나의 꼭지점에서 다른 꼭지점으로 나가는(out) 간선 수의 합 (방향 네트워크에서 정의) **In-degree** : 다른 꼭지점에서 하나의 꼭지점으로 들어오는(in) 간선 수의 합 (무방향 네트워크에서 정의)  ## 꼭지점의 속성 개별 꼭지점의 속성을 따지는 지표는 몇 가지 있습니다.  ### 1. 연결성(conectivity) 임의의 한 꼭지점이 다른 꼭지점과 어떻게 연결되어 있는지 나타내는 지표입니다. **도달가능성(reachablity)** : 꼭지점과 꼭지점 사이에 간선으로 연결돼 있어야 '도달 가능'하다고 정의됩니다. **거리(Distance)** : 도달가능할 경우 몇 단계를 거처야 해당 꼭지점에 도달할지를 따지는 지표입니다. **경로 개수(Number of paths)** : 도달 가능한 경로가 몇 가지가 있는지를 따지는 지표입니다.  ### 2. 중심성(centrality) 임의의 꼭지점이 네트워크 상에서 얼마나 중심에 위치하고 있는지 나타내는 지표입니다. 대개 중심에 위치한 꼭지점은 중요한 꼭지점으로 인식됩니다. 이 때문에 중심성은 곧 중요도로 받아들여지기도 합니다. 그 정의와 예시 그림은 아래와 같습니다. **중개중심성(degree centrality)** : 한 꼭지점에 연결된 간선의 수 <a href="http://imgur.com/7ukue0I"><img src="http://i.imgur.com/7ukue0I.png" width="600px" title="source: imgur.com" /></a> **근접중심성(closeness centrality)** : 특정 꼭지점이 그를 제외한 다른 꼭지점과 얼마나 가까이에 있는지를 나타내는 지표. 해당 꼭지점의 도달 가능 거리 총합의 **역수(inverse)**로 정의됩니다.  <a href="http://imgur.com/EfH9ZtU"><img src="http://i.imgur.com/EfH9ZtU.png" width="600px" title="source: imgur.com" /></a> **중개중심성(betweenness centrality)** : 한 꼭지점의 중개중심성은 그 꼭지점을 제외한 다른 두 꼭지점을 잇는 최단거리에 해당 꼭지점이 얼마나 많이 등장하는지 빈도로 정의됩니다. <a href="http://imgur.com/fPlwyEb"><img src="http://i.imgur.com/fPlwyEb.png" width="600px" title="source: imgur.com" /></a> **고유벡터중심성(eigenvector centrality)** : 중요한 꼭지점에 연결된 꼭지점일 수록 그 중요도가 높아지는 지표입니다. 인접행렬 **고유벡터(eigenvector)**의 각 요소가 각 꼭지점의 고유벡터중심성입니다.
docclassification␞ 이번 글에서는 딥러닝이 주목받기 전인 2000년대 초반까지의 문서 분류 방식에 대해 살펴보도록 하겠습니다. [AK Nassirtoussi(2015)](http://www.sciencedirect.com/science/article/pii/S0957417414004801)는 금융 관련 문서들로 주가를 예측하는 연구를 했었는데요, 도메인이 금융에 특화돼 있긴 하지만 기존 문서 분류 연구들을 잘 정리해놓은 것 같다는 생각에 이를 인용해봤습니다. 그럼 시작하겠습니다.  ## 문서 전처리 2000년대 초반 연구에서는 비정형데이터를 정형데이터로 변환하는 데 **TF-IDF**가 많이 쓰인 점을 확인할 수 있습니다. 토픽모델링 기법인 **Latent Dirichlet Allocation**을 입력 벡터로 만든 연구도 눈에 띕니다. 요즘엔 구글에서 2013년 개발한 **Word2Vec**이나 미국 스탠포드에서 개발한 **GloVe** 등을 주로 쓰고 있다는 점을 생각하면 격세지감이네요. TF-IDF에 대해 자세한 내용은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/28/tfidf/)을, Word2Vec에 대해서는 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/), GloVe는 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/09/glove/)을 참고하시면 좋을 것 같습니다. <a href="http://imgur.com/JlGAbLy"><img src="http://i.imgur.com/JlGAbLy.png" title="source: imgur.com" /></a>  ## 분류 모델 분류 모델로는 **서포트 벡터 머신(SVM)** 계열 비중이 압도적입니다. 그도 그럴 것이 딥러닝 이전 뛰어난 성능으로 많은 주목을 받았던 모델 때문이 아닌가 생각합니다. 이밖에 **선형회귀**, **나이브 베이지안**, **K-NN** 같은 비교적 간단한 모델도 분류기로 많이 쓰였습니다. 요즘에는 **Convolutional Neural Networks**, **Recurrent Neural Networks**, **Recursive Neural Networks** 등 딥러닝 모델들이 각광받고 있습니다.  SVM에 대한 자세한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/)을, 나이브 베이지안 모델은 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/18/naive/), K-NN은 [이곳](https://ratsgo.github.io/machine%20learning/2017/04/17/KNN/)을 참고하면 좋을 것 같습니다. 아울러 CNN은 [이곳](https://ratsgo.github.io/natural%20language%20processing/2017/03/19/CNN/), Recurrent Neural Networks는 [이곳](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/), Recursive Neural Networks는 [이곳](https://ratsgo.github.io/deep%20learning/2017/04/03/recursive/)을 보시면 좋을 것 같습니다. <a href="http://imgur.com/ORYsKWB"><img src="http://i.imgur.com/ORYsKWB.png" title="source: imgur.com" /></a>  ## Appendix 제가 인용한 논문입니다.  Nassirtoussi, A. K., Aghabozorgi, S., Wah, T. Y., & Ngo, D. C. L. (2015). Text mining of news-headlines for FOREX market prediction: A Multi-layer Dimension Reduction Algorithm with semantics and sentiment. *Expert Systems with Applications*, *42*(1), 306-324. 표에 언급된 논문 목록입니다. Wuthrich, B., Cho, V., Leung, S., Permunetilleke, D., Sankaran, K., & Zhang, J. (1998). Daily stock market forecast from textual web data. In 1998 IEEE international conference on systems, man, and cybernetics (Vols. 3 and 2723, pp. 2720–2725). Peramunetilleke, D., & Wong, R. K. (2002). Currency exchange rate forecasting from news headlines. Australian Computer Science Communications, 24, 131–139. Werner, A., & Myrray, Z. F. (2004). Is all that talk just noise ? The information content of internet stock message boards. Journal of Finance, 1259–1294. Mittermayer, M. A. (2004). Forecasting intraday stock price trends with text mining techniques. In Proceedings of the 37th annual Hawaii international conference on system sciences, 2004 (p. 10). Das, S. R., & Chen, M. Y. (2007). Yahoo! for Amazon: Sentiment extraction from small talk on the web. Management Science, 53, 1375–1388. Soni, A., van Eck, N. J., & Kaymak, U. (2007). Prediction of stock price movements based on concept map information. In IEEE symposium on computational intelligence in multicriteria decision making (pp. 205–211). Zhai, Y., Hsu, A., & Halgamuge, S. K. (2007). Combining news and technical indicators in daily stock price trends prediction. In Proceedings of the fourth international symposium on neural networks: advances in neural networks, Part III (pp. 1087–1096). Nanjing, China: Springer-Verlag. Rachlin, G., Last, M., Alberg, D., & Kandel, A. (2007). ADMIRAL: A data mining based financial trading system. In IEEE symposium on computational intelligence and data mining, 2007. CIDM 2007 (pp. 720–725). Tetlock, P. C., Saar-Tsechansky, M., & Macskassy, S. (2008). More than words: Quantifying language to measure firms’ fundamentals. The Journal of Finance, 63, 1437–1467. Mahajan, A., Dey, L., & Haque, S. M. (2008). Mining financial news for major events and their impacts on the market. In IEEE/WIC/ACM international conference on web intelligence and intelligent agent technology, 2008. WI-IAT ‘08 (Vol. 1, pp. 423–426). Butler, M., & Kešelj, V. (2009). Financial forecasting using character N-gram analysis and readability scores of annual reports. In Y. Gao & N. Japkowicz (Eds.). Advances in artificial intelligence (Vol. 5549, pp. 39–51). Berlin, Heidelberg: Springer. Schumaker, R. P., & Chen, H. (2009). Textual analysis of stock market prediction using breaking financial news: The AZF in text system. ACM Transactions on Information Systems, 27, 1–19. Lugmayr, A., & Gossen, G. (2012). Evaluation of methods and techniques for language based sentiment analysis for DAX 30 stock exchange – a first concept of a ‘‘LUGO’’ sentiment indicator. In Lugmayr, A., Risse, T., Stockleben, B., Kaario, J., Pogorelc, B., & Serral Asensio, E. (Eds.). SAME 2012 – fifth international workshop on semantic ambient media experience. Yu, Y., Duan, W., & Cao, Q. (2013). The impact of social and conventional media on firm equity value: A sentiment analysis approach. Decision Support Systems. Hagenau, M., Liebmann, M., & Neumann, D. (2013). Automated news reading: Stock price prediction based on financial news using context-capturing features. Decision Support Systems, 55, 685–697. Jin, F., Self, N., Saraf, P., Butler, P., Wang, W., & Ramakrishnan, N. (2013). Forexforeteller: Currency trend modeling using news articles. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 1470–1473). Chicago, IL, USA: ACM. Chatrath, A., Miao, H., Ramchander, S., & Villupuram, S. (2014). Currency jumps, cojumps and the role of macro news. Journal of International Money and Finance, 40, 42–62. Bollen, J., Huina, M., & Zeng, Xiao-Jun (2010). Twitter mood predicts the stock market. Journal of Computational Science, 2, 1–8. Vu, T. T., Chang, S., Ha, Q. T., & Collier, N. (2012). An experiment in integrating sentiment features for tech stock prediction in twitter. In Proceedings of the workshop on information extraction and entity analytics on social media data (pp. 23–38). Mumbai, India: The COLING 2012 Organizing Committee. Pui Cheong Fung, G., Xu Yu, J., & Wai, L. (2003). Stock prediction: Integrating text mining approach using real-time news. In Proceedings. 2003 IEEE international conference on computational intelligence for financial engineering (pp. 395–402). Schumaker, R. P., Zhang, Y., Huang, C.-N., & Chen, H. (2012). Evaluating sentiment in financial news articles. Decision Support Systems, 53, 458–464. Li, F. (2010). The information content of forward-looking statements in corporate filings—a Naïve Bayesian machine learning approach. Journal of Accounting Research, 48, 1049–1102. Li, C. H., Yang, J. C., & Park, S. C. (2012). Text categorization algorithms using semantic approaches, corpus-based thesaurus and WordNet. Expert Systems with Applications, 39, 765–772. Huang, C.-J., Liao, J.-J., Yang, D.-X., Chang, T.-Y., & Luo, Y.-C. (2010). Realization of a news dissemination agent based on weighted association rules and text mining techniques. Expert Systems with Applications, 37, 6409–6413. Groth, S. S., & Muntermann, J. (2011). An intraday market risk management approach based on textual analysis. Decision Support Systems, 50, 680–691.
terms␞ 이번 글에서는 머신러닝과 딥러닝 관련 다양한 용어들을 정리하였습니다. 이 글은 기본적으로 구글에서 정리해 놓은 [용어 사전 리스트](https://developers.google.com/machine-learning/glossary/)를 기본으로 위키피디아 등 자료를 참고해 정리하였습니다. 그럼 시작하겠습니다.  ## activation function 이전 계층의 모든 입력값의 가중합을 받아서 다음 계층에 보낼 출력값을 산출하는 함수. 대개 ReLU나 시그모이드 같은 비선형함수가 적용된다.  ## loss 모델의 예측과 정답 사이에 얼마나 차이가 있는지 나타내는 **측도(measure)**. 이 값을 정하기 위해서는 손실함수(loss function)이 정의되어 있어야 한다. 예컨대 선형회귀 모델에서 손실함수는 대개 Mean Squared Error, 로지스틱회귀에서는 로그우도가 쓰인다.  *여기에서 측도란 1차원에서의 길이, 2차원에서의 넓이, 3차원에서의 부피 등의 개념을 일반의 집합으로까지 확장한 개념이다. 즉 집합의 ‘크기’에 상당하며, 적분이론은 이 개념을 기초로 하는 경우가 많다.*  ## prior belief 모델을 학습하기 전 데이터에 대한 당신의 믿음. 예컨대 딥러닝 모델 파라메터에 대한 L2 정규화는 해당 파라메터들이 작고 0을 중심으로 정규분포를 이룬다는 사전믿음을 전제한다.  ## regularization 모델 복잡도(complexity)에 대한 패널티(penalty). 정규화는 과적합을 예방하고 일반화 성능을 높이는 데 도움을 준다. 정규화에는 L1 정규화, L2 정규화, 드롭아웃, early stopping 등이 있다.  ## squared loss 선형회귀에 쓰이는 손실함수. L2 Loss로도 불린다. 이 함수는 모델이 예측한 값과 실제값 간 차이(오차)의 제곱이다. 미분이 가능하다는 장점이 있다. 하지만 오차를 '제곱'하기 때문에 잘못된 예측 혹은 이상치(outlier)에 의해 그 값이 큰 영향을 받게 된다는 단점이 있다. (추가 내용 : [Quora](https://www.quora.com/When-is-square-loss-not-good-for-loss-function-for-regression))  ## absolute loss 모델이 예측한 값과 실제값 간 차이(오차)의 절대값. L1 Loss로도 불린다. L1 Loss는 L2 Loss에 비해 이상치에 덜 민감하다는 장점이 있지만 0인 지점에서 미분이 불가능하다는 단점이 있다.  ## L1 regularization 정규화의 일종. 모델 가중치의 L1 norm(가중치 각 요소 절대값의 합)에 대해 패널티를 부과한다. 대부분의 요소값이 0인 sparse feature에 의존한 모델에서 L1 정규화는 불필요한 피처에 대응하는 가중치들을 정확히 0으로 만들어 해당 피처를 모델이 무시하도록 만든다. 다시 말해 변수선택(feature selection) 효과가 있다는 말이다. 이는 L2 정규화와 대조된다.  *2차원상 L1 norm의 자취는 마름모꼴이어서 미분이 불가능한데 이같은 성질과 깊은 관련을 맺고 있는듯하다. [이곳](https://ratsgo.github.io/machine%20learning/2017/05/22/RLR/) 참고.*  ## L2 regularization 정규화의 일종. 모델 가중치의 L2 norm의 제곱(가중치 각 요소 제곱의 합)에 대해 패널티를 부과한다. L2 정규화는 아주 큰 값이나 작은 값을 가지는 outlier 모델 가중치에 대해 0에 가깝지만 0은 아닌 값으로 만든다. 이는 L1 정규화와 대조된다. L2 정규화는 선형모델의 일반화 능력을 언제나 항상 개선시킨다.  ## structural risk minimization 알고리즘은 다음과 같은 두 가지 목표를 만족시켜야 한다. - 예측력이 좋은 모델 (예컨대 손실이 가장 적은 모델) - 가급적 간단한 모델 (예컨대 강한 수준의 정규화가 이뤄진 모델) 예컨대 학습데이터에 대해 손실 최소화와 정규화를 동시에 달성한 모델은 structural risk minimization이 이뤄진 알고리즘이라 할 수 있다. structural risk minimization는 empirical risk minimization 개념과 대조된다.  ## empirical risk minimization 학습데이터에 대해 손실이 적은 모델을 선택하는 것. structural risk minimization 개념과 대조된다.  ## least squares regression L2 loss를 최소화함으로써 학습된 선형회귀 모델.  ## generalized linear model least squares regression의 일반화된 버전. 가우시안 노이즈에 기반한 모델도 있고 포아송 노이즈나 범주형 노이즈(categorical noise) 같은 다른 종류의 노이즈에 기반한 모델도 있다. generalized linear model의 예시는 다음과 같다. - logistic regression - multi-class regresstion - least squares regression generalized linear model의 파라메터는 convex optimization 기법으로 구한다. generalized linear model은 다음 두 가지 속성이 있다. - 최적 generalized linear model의 예측 평균은 학습 데이터 정답의 평균과 같다. - 최적 로지스틱 회귀 모델이 예측한 확률의 평균은 학습 데이터 정답의 평균과 같다. generalized linear model의 예측력은 피처에 의해 제한된다. 딥러닝 모델과 달리 generalized linear model은 (학습데이터에 없는)새로운 피처를 학습할 수 없다.  ## Kernel Support Vector Machines (KSVMs) 입력 데이터 벡터를 고차원 공간에 매핑함으로써 positive class와 negative class 사이의 마진(margin)을 최대화하는 결정경계(decision boundary)를 찾는 분류 알고리즘. 예컨대 100차원짜리 입력데이터가 주어졌을 때 KSVMs는 이러한 입력데이터를 100만 차원 공간으로 매핑한다. KSVMs는 hinge loss라고 불리는 손실함수를 사용한다.  ## hinge loss 학습데이터 각각의 범주를 구분하면서 데이터와의 거리가 가장 먼 결정경계(decision boundary)를 찾기 위해 고안된 손실함수의 한 부류. 이로써 데이터와 경계 사이의 마진(margin)이 최대화된다. KSVMs이 바로 hinge loss를 손실함수로 쓴다. 이진 분류문제에서 모델의 예측값 $y'$(스칼라), 학습데이터의 실제값 $y$(-1 또는 1) 사이의 hinge loss는 다음과 같이 정의된다.  $$ loss=\max { \left\{ 0,1-\left( y'\times y \right) \right\} } $$  $y'×y$를 $x$축, hinge loss를 $y$축으로 놓고 그래프를 그리면 다음과 같다.   <a href="https://imgur.com/J59cih1"><img src="https://i.imgur.com/J59cih1.png" width="300px" title="source: imgur.com" /></a>  위 그래프의 의미를 이해하려면 SVM의 목적식부터 살펴야 한다. SVM에서 plus-plane보다 위에 있는 관측치들은 $y=1$이고 $y'$, 즉 $w^Tx+b$가 1보다 크다. 반대로 minus-plane보다 아래에 있는 점들은 $y=-1$이고 $w^Tx+b$가 -1보다 작다. 따라서 SVM이 그 손실을 0으로 두려는 관측치 $x$는 아래와 같은 식을 만족한다.  $$ y' \times y={ y }({ w }^{ T }{ x }+b)\ge 1 $$  그런데 여기에서 만약 $y'×y$가 1 미만의 값을 가진다면 해당 관측치 $x$는 plus-plane과 minus-plane 사이, 즉 마진(margin) 내에 존재한다. $y'×y$가 1 이상이라면 손실을 무시(=0)하고, 1보다 작으면 작을수록 손실 또한 크도록 유도한 것이 hinge loss 수식이 의미하는 바다. hinge loss는 로지스틱 회귀의 손실함수, 크로스 엔트로피와 깊은 관련을 맺고 있다. 로지스틱 회귀의 경우 $y'×y$가 1 이상의 값을 가질 경우 손실이 0에 가까워지지만 완전히 0이 되지는 않는다. 자세한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/10/04/comparison/) 참고.  ## independently and identically distributed (i.i.d) 동일하고(변화하지 않고) 이전에 뽑은 값에 영향을 받지 않는(독립인) 확률분포를 따르는 확률변수들의 집합(collection). 예컨대 특정 시점에 웹페이지에 접속하는 방문자들은 i.i.d일 수 있다. 짧은 시간이기 때문에 분포는 변화하지 않는다. 또한 한 방문자의 접속은 다른 방문자의 접속과 일반적으로 독립(independent)이다. 그러나 분석 기간을 길게 하면 웹페이지 방문이 계절마다 다를 수 있다(이 경우 분포가 변화한다는 점에서 i.i.d가 아니다) 앞면이 나오는 경우를 1, 그렇지 않은 경우를 0으로 하는 확률변수가 있고 동전을 네 번 던질 경우 이 확률변수들의 집합은 i.i.d다. 앞면이 나올 확률이 네 차례 모든 실험에서 0.5로 동일하고, 현재 실험은 이전에 앞면이 나왔든 뒷면이 나왔든 상관없이 독립이기 때문이다.  ## inference 머신러닝에서 추론(inference)는 학습된 모델을 레이블이 달리지 않은 데이터(unlabeled examples)에 적용해 예측하는 과정을 가리킨다. 통계학에서 추론은 일부 관측된 데이터가 주어졌을 때 해당 분포의 파라메터를 추정하는 과정을 가리킨다.  ## perplexity 모델이 과업을 얼마나 잘 수행하고 있는지 나타내는 측도(measure) 중 하나. 예컨대 스마트폰 사용자가 몇 개 철자를 타이핑했을 때 해당 사용자에게 자동 완성된 단어 리스트를 보여주는 과업을 수행하고 싶다고 치자. 이 작업에 대한 perplexity $P$는 사용자가 입력하려고 하는 실제 단어(정답)가 모델이 제시하는 후보 리스트에 포함되도록 하기 위해 제공해야 하는 추측의 수를 가리킨다. perplexity는 다음과 같이 크로스 엔트로피와 관계가 있다.  $$ P={ 2 }^{ -crossentropy } $$  ## stationarity 데이터의 분포가 하나 이상의 차원에서 일정하게 유지되는 데이터 집합의 속성. 가장 일반적으로 그 차원은 시간이며, 데이터가 stationarity하다는 것은 시간이 지나도 데이터가 변하지 않는다는 걸 의미한다.  ## synthetic feature 입력 피처에는 존재하지 않지만 하나 이상의 피처로부터 도출된 피처. 합성피처(synthetic feature)의 종류는 다음과 같다. - feature cross - 하나의 피처를 두 개의 피처로 나누기(dividing) - buckting 피처 하나만을 대상으로 정규화(normalize)나 스케일링해서 생성된 피처는 합성피처에 속하지 않는다.  ## feature cross 개별 피처들을 곱셈 또는 카테시안 곱으로 cross시켜 생성한 합성피처의 일종. feature cross는 피처간 비선형(nonlinear) 관계를 표현하는 데 도움을 준다.  ## bucketing 연속적인(continous) 피처를 버켓(bucket) 또는 빈(bin)이라 불리는 여러 개의 이진 피처로 나누는 것. 대개 해당 피처 값(value)의 범위를 바탕으로 나눈다. 예컨대 온도를 연속적인 floating-point 피처로 표시하는 대신, 이산적인(discrete)한 빈으로 분리할 수 있다. 가령 0~15도, 15~30도, 30~50도에 해당하는 데이터를 각각의 빈에 넣는 방식이다.
GRU␞ 이번 글에서는 **Recursive Neural Networks(RNN)**의 대표적인 셀 가운데 하나인 **Gated Recurrent Unit(GRU)**에 대해 살펴보도록 하겠습니다. 이 글은 기본적으로 미국 스탠포드 대학의 CS231n, CS224d 강좌를 참고로 하되 고려대학교 데이터사이언스 연구실의 김해동 석사과정이 만든 자료를 정리하였음을 먼저 밝힙니다. 김해동 석사과정은 GRU의 **순전파(forward propagation)**와 **역전파(backward propagation)** 과정을 알기 쉽게 설명하였습니다. 기본적인 RNN 구조와 **Long-Short Term Memory(LSTM)** 셀에 대해 궁금하신 분은 [이곳](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)을 참고하시기 바랍니다. 그럼 시작하겠습니다.   ## GRU 개요 GRU는 LSTM의 장점을 유지하면서도 계산복잡성을 확 낮춘 셀 구조입니다. GRU도 **Gradient Vanishing/Explosion 문제**를 극복했다는 점에서 LSTM과 유사하지만 게이트 일부를 생략한 형태입니다. GRU는 크게 **update gate**와 **reset gate** 두 가지로 나뉩니다.  두 게이트 모두 현 시점의 입력값($x_t$)과 직전 시점 은닉층값($h_{t-1}$)을 반영해 구합니다. **활성함수**($σ$)는 시그모이드를 씁니다.  $$ \begin{align*} update\quad gate\quad :\quad { z }_{ t }=\sigma ({ W }^{ (z) }{ x }_{ t }+{ U }^{ (z) }{ h }_{ t-1 })\\ reset\quad gate\quad :\quad { r }_{ t }=\sigma ({ W }^{ (r) }{ x }_{ t }+{ U }^{ (r) }{ h }_{ t-1 }) \end{align*} $$  $W, U$는 각각 입력값과 은닉층값과 **선형결합**하는 **파라메터**이고요. 위 첨자 $z, r$은 각각 update gate, reset gate에 속한다는 뜻입니다. 자 이제부터는 기억(memory)에 관련된 과정입니다. 우선 현 시점($t$)에서 기억해둘 만한 정보를 아래와 같이 정의합니다.  $$ \tilde { { h }_{ t } } =\tanh { (W{ x }_{ t }+{ r }_{ t }\odot U{ h }_{ t-1 }) } $$  위 식을 해석하면 이렇습니다. 현 시점 정보($Wx_t$)와 과거 정보($Uh_{t-1}$)를 반영하되, 과거 정보를 얼마나 반영할지는 reset gate 값에 의존한다는 이야기입니다.  reset gate의 활성함수는 시그모이드이므로 0~1 사이의 범위를 갖습니다. $r_t$값이 0이라면 과거 정보를 모두 잊고, 1이라면 과거 정보를 모두 기억합니다. $r_t$값에 상관없이 현재 정보는 반영됩니다. 위 식의 활성함수는 하이퍼볼릭탄젠트입니다. -1~1 사이의 범위를 갖습니다. 위 식엔 update, reset gate와 달리 $W,U$에 위 첨자가 없는데, 아예 다른 파라메터라는 점에 주의해야 합니다. 한편 ⊙는 Hadamard product(요소별 곱셈)를 뜻합니다. 다음 상태(state)로 업데이트하는 식은 아래와 같습니다.  $$ { h }_{ t }={z }_{ t }\odot { h }_{ t-1 }+(1-{ z }_{ t })\odot \tilde { { h }_{ t } } $$  위 식을 해석하면 이렇습니다. $h_{t-1}$는 과거 정보, $h_t$ 틸다는 현재 정보입니다. 이를 얼마나 조합할지 결정하는 건 update gate의 $z_t$입니다.  update gate의 활성함수는 시그모이드이므로 0~1 사이의 범위를 갖습니다. $z_t$가 0이라면 과거 정보를 모두 잊고, 현재 정보만을 기억합니다. $z_t$가 1이라면 과거 정보를 모두 기억하지만, 현재 정보는 모두 무시합니다. GRU 셀을 그림([출처](http://colah.github.io/posts/2015-08-Understanding-LSTMs/))으로 나타내면 아래와 같습니다. <a href="http://imgur.com/rehjrBZ"><img src="http://i.imgur.com/rehjrBZ.png" width="400px" title="source: imgur.com" /></a>   ## GRU의 순전파 이제부터 본격적으로 GRU의 순전파와 역전파에 대해 설명할 예정인데요. 기본적인 방식에 관해서는 [이 글](https://ratsgo.github.io/deep%20learning/2017/05/14/backprop/)을 참고하시면 좋을 것 같습니다.  GRU의 순전파를 계산그래프로 나타내면 아래 그림과 같습니다. 그림으로 보면 복잡해보이지만 지금까지 설명드린 수식과 완전히 동일합니다. 다만 $h_t$에 $W_{out}$을 곱해 $y_t$를 만드는 과정은 엄밀히 말해 GRU 셀 내부 작동은 아니지만 이해를 돕기 위하여 셀 내부에 그렸습니다. <a href="http://imgur.com/nenqTrN"><img src="http://i.imgur.com/nenqTrN.png" title="source: imgur.com" /></a> 어쨌든 $t$ 시점의 GRU 셀의 입력은 $x_t$, $h_{t-1}$, 출력은 $h_t$입니다. GRU 셀과 연결된 **Softmax-with-Loss** 계층은 $y_t$를 입력으로 받아 $t$ 시점의 Loss $L_t$를 출력합니다.  우리가 업데이트해야 할 파라메터는 $U^{z}$, $U^r$, $U$, $W^z$, $W^r$, $W$입니다.   ## GRU의 역전파 $t$ 시점의 GRU 셀이 Softmax-with-Loss 노드로부터 최초로 받는 그래디언트는 $∂L_t/∂y_t$입니다. 아래 그림에서는 이를 편의상 $dy_t$라고 적었습니다. 이후 모든 표기는 이 방식을 따랐습니다. $h_t$와 $y_t$는 곱셈 노드로 연결돼 있기 때문에 $dW_{out}$과 $dh_t$는 흘러들어온 그래디언트 $dy_t$에 순전파 때 입력 신호들을 서로 바꾼 값을 각각 곱한 값입니다. $dh_t$ 틸다는 흘러들어온 그래디언트 $dh_t$에 Hadamard product의 로컬 그래디언트를 곱해 구합니다. 우선 위쪽부터 살펴보겠습니다. $dr_t$ 틸다는 흘러들어온 그래디언트 $dh_t$ 틸다에 하이퍼볼릭탄젠트의 로컬 그래디언트를 곱해 구합니다. $dr_t$는 흘러들어온 그래디언트 $dr_t$ 틸다에 Hadamard product의 로컬 그래디언트를 곱해 구합니다. $dinput_r$은 흘러들어온 그래디언트 $dr_t$에 시그모이드 함수의 로컬 그래디언트를 곱해 구합니다. $dUh_{t-1}$은 흘러들어온 그래디언트 $dr_t$ 틸다에 Hadamard product의 로컬 그래디언트를 곱해 구합니다.  <a href="http://imgur.com/SLhyNgK"><img src="http://i.imgur.com/SLhyNgK.png" title="source: imgur.com" /></a> 이제 아래쪽을 살펴보겠습니다. $dz_t$는 흘러들어온 그래디언트 $dh_t$에 Hadamard product의 로컬 그래디언트를 곱해 구합니다. $dinput_z$는 흘러들어온 그래디언트 $dz_t$에 시그모이드 함수의 로컬 그래디언트를 곱해 구합니다. $dWx_t$는 흘러들어온 그래디언트 $dh_t$ 틸다에 하이퍼볼릭탄젠트의 로컬 그래디언트를 곱해 구합니다. $input_r$과 $input_r$은 덧셈 노드로 연결돼 있으므로 흘러들어온 그래디언트가 그대로 전파됩니다.  이상을 종합하면 우리가 구해야 하는 $dW_x$와 $dU_h$는 아래와 같습니다. $dh_t$는 $∂L_t/∂h_t$를 의미하기 때문에 $cvx$를 기준으로 위 그림 위쪽은 모두 $∂h_t/∂W_x$를 계산하는 과정이라고 이해하면 될 것 같습니다. 마찬가지로 $cvx$를 기준으로 위 그림 위쪽은 모두 $∂h_t/∂U_h$를 구하는 과정으로 보면 됩니다.  $$ \begin{align*} \frac { \partial { L }_{ t } }{ \partial { W }_{ x } } &=\begin{bmatrix} d{ input }_{ z }{ \cdot x }_{ t } & d{ input }_{ r }\cdot { x }_{ t } & dW{ x }_{ t }{ \cdot x }_{ t } \end{bmatrix}=\frac { \partial { L }_{ t } }{ \partial { y }_{ t } } \frac { \partial { y }_{ t } }{ \partial { h }_{ t } } \frac { \partial { h }_{ t } }{ \partial { W }_{ x } } =\frac { \partial { L }_{ t } }{ \partial { h }_{ t } } \frac { \partial { h }_{ t } }{ \partial { W }_{ x } } \\ \frac { \partial { L }_{ t } }{ \partial { U }_{ h } } &=\begin{bmatrix} d{ input }_{ z }{ \cdot h }_{ t-1 } & d{ input }_{ r }\cdot h_{ t-1 } & dUh_{ t-1 }{ \cdot h }_{ t-1 } \end{bmatrix}=\frac { \partial { L }_{ t } }{ \partial { y }_{ t } } \frac { \partial { y }_{ t } }{ \partial { h }_{ t } } \frac { \partial { h }_{ t } }{ \partial { U }_{ h } } =\frac { \partial { L }_{ t } }{ \partial { h }_{ t } } \frac { \partial { h }_{ t } }{ \partial { U }_{ h } } \end{align*} $$   ## the backpropagation through time (BPTT) 지금까지 설명해드린 그림들은 $t$ 시점의 셀 하나를 보여드렸습니다. 그런데 셀을 다양하게 구성해 RNN 네트워크를 구성할 수 있습니다. GRU 역전파시 그래디언트는 아래 그림의 파란색 셀 개수만큼 재귀적으로 합쳐져 전파됩니다. <a href="http://imgur.com/Q8zv6TQ"><img src="http://i.imgur.com/Q8zv6TQ.png" width="500px" title="source: imgur.com" /></a> 다시 $t$ 시점의 GRU 셀로 돌아가보겠습니다. $δ_t$는 흘러들어온 그래디언트 $dh_t(=∂L_t/∂h_t)$에 Hadamard product의 로컬 그래디언트 $∂h_t/∂h_{t-1}$를 곱해 구합니다. 이를 수식으로 정리하면 아래와 같습니다.  $$ { \delta }_{ t }=\frac { \partial { L }_{ t } }{ \partial { y }_{ t } } \frac { \partial y_{ t } }{ \partial { h }_{ t } } \frac { \partial h_{ t } }{ \partial { h }_{ t-1 } } $$  여기서 $h_{t-1}$은 $t-1$ 시점의 GRU 셀의 출력 결과라는 점에 주목해야 합니다. 다시 말해 $δ_t$는 적색 화살표를 따라 $t-1$ 시점의 GRU 셀로 흘러들어간다는 이야기입니다. <a href="http://imgur.com/2QzVDbi"><img src="http://i.imgur.com/2QzVDbi.png" title="source: imgur.com" /></a> 이번엔 $t-1$ 시점의 GRU 셀을 살펴 보겠습니다. $δ_t$는 $t-1$ 시점의 Loss인 $L_{t-1}$로부터 전파되는 그래디언트 $dh_{t-1}$과 합쳐져 역전파되는 걸 확인할 수 있습니다. 이렇듯 GRU 셀은 직전 시점의 정보를 받아 다음 스텝으로 순전파하기 때문에 역전파시엔 그래디언트가 재귀적으로 합쳐져 흘러 들어갑니다. <a href="http://imgur.com/ifTLRcA"><img src="http://i.imgur.com/ifTLRcA.png" title="source: imgur.com" /></a>    ## 수식으로 이해하는 GRU 역전파 시퀀스 길이가 3인 GRU 구조를 도식적으로 나타내면 그림과 같습니다. 우리는 파라메터 $W_x$와 $U_h$를 업데이트하는 데 관심이 있다는 걸 상기하고 아래 설명을 천천히 따라가 봅시다. <a href="http://imgur.com/JludLEw"><img src="http://i.imgur.com/JludLEw.png" width="600px" title="source: imgur.com" /></a> $δ_3$은 아래 식과 같습니다. 흘러들어온 그래디언트 $dh_3(=∂L_3/∂h_3)$에 Hadamard product의 로컬 그래디언트 $∂h_3/∂h_2$를 곱해 구합니다.  $$ { \delta }_{ 3 }=\frac { \partial L_{ 3 } }{ \partial { h }_{ 3 } } \frac { \partial h_{ 3 } }{ \partial { h }_{ 2 } } =\frac { \partial { L }_{ 3 } }{ \partial { y }_{ 3 } } \frac { \partial y_{ 3 } }{ \partial { h }_{ 3 } } \frac { \partial h_{ 3 } }{ \partial { h }_{ 2 } } $$  $δ_2$는 흘러들어온 그래디언트 $δ_3+dh_2(=∂L_2/∂h_{2})$에 로컬 그래디언트 $δh_2/δh_1$를 곱해 구합니다.  $$ { \delta }_{ 2 }=({ \delta }_{ 3 }+\frac { \partial L_{ 2 } }{ \partial { h }_{ 2 } } )\frac { \partial h_{ 2 } }{ \partial { h }_{ 1 } } =(\frac { \partial { L }_{ 3 } }{ \partial { y }_{ 3 } } \frac { \partial y_{ 3 } }{ \partial { h }_{ 3 } } \frac { \partial h_{ 3 } }{ \partial { h }_{ 2 } } +\frac { \partial L_{ 2 } }{ \partial { y }_{ 2 } } \frac { \partial y_{ 2 } }{ \partial { h }_{ 2 } } )\frac { \partial h_{ 2 } }{ \partial { h }_{ 1 } } $$  자 이제 $∂L_1/∂W_x$를 구할 준비가 다 되었습니다. 아래 식과 같습니다. 자세히 살펴보시면 두번째 시점과 세번째 시점에서 전파된 그래디언트가 모두 반영이 되고 있는 점을 확인할 수 있습니다.  $$ \begin{align*} \frac { \partial L_{ 1 } }{ \partial { W }_{ x } } &=({ \delta }_{ 2 }+\frac { \partial L_{ 1 } }{ \partial { y }_{ 1 } } \frac { \partial y_{ 1 } }{ \partial { h }_{ 1 } } )\frac { \partial h_{ 1 } }{ \partial { W }_{ x } } \\ &=\left\{ (\frac { \partial { L }_{ 3 } }{ \partial { y }_{ 3 } } \frac { \partial y_{ 3 } }{ \partial { h }_{ 3 } } \frac { \partial h_{ 3 } }{ \partial { h }_{ 2 } } \frac { \partial h_{ 2 } }{ \partial { h }_{ 1 } } +\frac { \partial L_{ 2 } }{ \partial { y }_{ 2 } } \frac { \partial y_{ 2 } }{ \partial { h }_{ 2 } } \frac { \partial h_{ 2 } }{ \partial { h }_{ 1 } } )+\frac { \partial L_{ 1 } }{ \partial { y }_{ 1 } } \frac { \partial y_{ 1 } }{ \partial { h }_{ 1 } } \right\} \frac { \partial h_{ 1 } }{ \partial { W }_{ x } } \\ &=\frac { \partial { L }_{ 3 } }{ \partial { y }_{ 3 } } \frac { \partial y_{ 3 } }{ \partial { h }_{ 3 } } \frac { \partial h_{ 3 } }{ \partial { h }_{ 2 } } \frac { \partial h_{ 2 } }{ \partial { h }_{ 1 } } \frac { \partial h_{ 1 } }{ \partial { W }_{ x } } +\frac { \partial L_{ 2 } }{ \partial { y }_{ 2 } } \frac { \partial y_{ 2 } }{ \partial { h }_{ 2 } } \frac { \partial h_{ 2 } }{ \partial { h }_{ 1 } } \frac { \partial h_{ 1 } }{ \partial { W }_{ x } } +\frac { \partial L_{ 1 } }{ \partial { y }_{ 1 } } \frac { \partial y_{ 1 } }{ \partial { h }_{ 1 } } \frac { \partial h_{ 1 } }{ \partial { W }_{ x } } \end{align*} $$  같은 방식으로 $∂L_2/∂W_x, ∂L_3/∂W_x$을 구해 모두 더하면 아래와 같습니다.  <a href="http://imgur.com/XEwbfCz"><img src="http://i.imgur.com/XEwbfCz.png" width="500px" title="source: imgur.com" /></a>  이를 일반화하여 식을 정리하면 아래와 같습니다. 같은 방식으로 $U_h$에 대한 그래디언트도 구할 수 있습니다.  $$ \sum _{ t=1 }^{ 3 }{ \sum _{ k=1 }^{ t }{ \frac { \partial { L }_{ t } }{ \partial { y }_{ t } } } } \frac { \partial { y }_{ t } }{ \partial { h }_{ t } } \frac { \partial { h }_{ t } }{ \partial { h }_{ k } } \frac { \partial { h }_{ tk } }{ \partial { W }_{ x } } $$ 
word2vecpos2␞ 이번 글에서는 [지난 글](https://ratsgo.github.io/natural%20language%20processing/2017/05/04/word2vecpos/)에 이어 **Word2Vec**으로 임베딩한 단어 벡터가 **품사**의 종류와 어떤 연관을 맺고 있는지 살펴보도록 하겠습니다. 목차는 다음과 같습니다.  * 목차 {:toc}  ## 실험 설계 제가 세운 가정을 정리하면 아래와 같습니다. 이 가정과 관련해 자세히 알고 싶으신 분은 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/04/21/wordclass/)을 참고하시면 좋을 것 같습니다. > (1) 한국어 품사 분류의 가장 중요한 기준은 기능이다. > > (2) 한국어 단어의 기능은 분포와 밀접한 관련이 있다. > > (3) Word2Vec은 말뭉치의 분포 정보를 학습에 반영한다. > > (4) Word2Vec으로 임베딩된 단어 벡터엔 품사 정보가 내재해 있을 것이다. > > (5) 같은 품사에 해당하는 단어 벡터는 서로 유사할 것이다. 이번 실험에 사용한 말뭉치는 영화 리뷰 사이트 '왓챠'에서 수집한 655만306개의 리뷰입니다. 여기에 KoNLPy의 **코모란 형태소 분석기**를 적용하여 형태소 분석을 실시하였습니다. 예컨대 아래와 같습니다. > **영화같은 인생 인생같은 영화** > > 영화/NNG, 같/VA, 은/ETM, 인생/NNG, 인생/NNG, 같/VA, 은/ETM, 영화/NNG 이렇게 분석한 말뭉치에 Word2Vec 기법을 적용했습니다. 하이퍼파라메터 조합은 아래와 같습니다. > **embedding 차원 수** : 100 > > **window 크기** : 3 > > **min_count** : 100 > > **Skip-Gram 적용** <br> ## 명사 Word2Vec으로 임베딩한 명사 단어벡터와 **코사인 유사도**가 가장 높은 단어 100개를 우선 뽑았습니다. 예컨대 아래와 같습니다. > **사회** : 자본주의, 세태, 사회구조, 제도, 사법, 부조리, 체제, 병폐, 계급, 시스템... 여기에서 코모란 분석기의 품사 태깅 결과를 참고해 유사 단어의 품사를 확인했습니다. '사회'의 경우 유사단어 100개 모두가 명사임을 알 수 있었습니다. 이런 방식으로 '사람', '때' 등 10개 명사의 유사단어 품사를 확인한 결과 100개 중 평균 94개가 명사인 것으로 나타났습니다.  이를 토대로 생각해 보면 Word2Vec으로 임베딩된 단어벡터에 명사라는 품사 정보가 내재해 있다고 볼 여지가 있는 것 같습니다. 다시 말해 명사와 유사한 단어는 명사라는 이야기입니다. | 형태소  | 명사 빈도(개) | | :----: | :------: | |  사람  |  100  | |  때  |  79  | |  일  |  94  | |  말  |  85  | |  사회  |  100  | |  속  |  85  | |  문제  |  100  | |  문화  |  100  | |  집  |  97  | |  경우  |  100  | | **평균** | **94** | <br>  ## 조사 명사와 같은 방식으로 조사도 조사했습니다. 100개 유사 단어 가운데 조사가 평균 10.83개로 다소 적은 수치를 나타냈습니다. 다만 100개 가운데 절반 가량이 명사라는 점에 비춰볼 때 조사는 명사와 자주 같이 등장한다(결합한다)는 문법적 사실을 간접적으로 알 수 있었습니다. | 형태소  | 명사 빈도(개) | 조사 빈도(개) | | :----: | :-------: | :-------: | |  -이  |  44   |  17   | |  -가  |  54   |  17   | | -께서  |  75   |   4   | | -에서  |  69   |   9   | |  -을  |  41   |  18   | |  -를  |  60   |  14   | |  -에  |  59   |  14   | | -에게  |  55   |  13   | |  -께  |  76   |   3   | | -한테  |  54   |  10   | | -더러  |  43   |   6   | |  -로  |  55   |  15   | | -으로  |  64   |  13   | |  -의  |  38   |   6   | |  -과  |  60   |  15   | |  -와  |  69   |  13   | | -보다  |  34   |   7   | | -처럼  |  37   |  11   | | -만큼  |  30   |   9   | | -같이  |  47   |   4   | |  -만  |  49   |  12   | |  -도  |  19   |  12   | |  -은  |  32   |  20   | |  -는  |  40   |  18   | | -조차  |  32   |   9   | | -마저  |  29   |   8   | | -까지  |  54   |   9   | | -부터  |  56   |   6   | | -나마  |  66   |   2   | | **평균** | **49.69** | **10.83** | <br>  ## 동사 동사의 경우 유사단어 100개 가운데 동사가 평균 53.78개로 집계됐습니다. 동사는 형용사와 문법적 성질이 비슷하다고 하는데요. 형용사 빈도를 세어보니 동사보다는 적은 3개였습니다. 이 역시 Word2Vec으로 임베딩된 단어벡터에 동사라는 품사 정보가 내재해 있다고 볼 여지가 있는 것 같습니다. | 형태소  | 동사 빈도(개) | 형용사 빈도(개) | | :----: | :-------: | :-------: | |  하-  |  37   |   4   | |  있-  |  20   |  15   | |  되-  |  51   |   5   | |  보-  |  31   |   2   | |  가-  |  56   |   0   | |  받-  |  64   |   1   | |  읽-  |  42   |   1   | |  잡-  |  87   |   1   | |  자-  |  24   |   1   | | 던지-  |  82   |   0   | |  뛰-  |  80   |   2   | |  믿-  |  67   |   3   | |  살-  |  63   |   2   | |  쉬-  |  54   |   6   | |  앓-  |  38   |   2   | | 흐르-  |  70   |   2   | |  피-  |  38   |   3   | |  솟-  |  64   |   4   | | **평균** | **53.78** |  **3**  | 위 표에서 '있-'을 주목할 만 합니다. '있-'은 동사적 성질(stay)과 형용사적 성질(exist)을 동시에 지니고 있는 어휘인데요. 100개 유사단어 가운데 형용사가 15개로 다른 어휘들보다 상대적으로 많고, 동사 개수와도 큰 차이를 보이지 않는 걸 확인할 수 있습니다.  <br>  ## 형용사 형용사의 경우에는 동사보다 형용사 빈도가 높음을 확인할 수 있었습니다. '멀-'만 형용사보다 동사가 많은데요. 동사(눈이 멀다)와 형용사(거리가 멀다) 용법 두 개가 있고, 코모란 분석기가 이 둘을 구별하지 않기 때문 아닌가 풀이됩니다. | 형태소  | 동사 빈도(개) | 형용사 빈도(개) | | :----: | :-------: | :-------: | |  없-  |  12   |  27   | | 그렇-  |  10   |  16   | |  같-  |   9   |  24   | | 다르-  |  18   |  16   | |  크-  |  16   |  26   | |  많-  |   4   |  43   | |  좋-  |  10   |  39   | | 힘들-  |   6   |  54   | |  검-  |   9   |  19   | | 시끄럽- |  13   |  31   | | 거칠-  |   0   |  23   | | 빠르-  |   5   |  21   | |  멀-  |  38   |  16   | |  높-  |  13   |  26   | | 아름답- |   1   |  24   | | **평균** | **10.93** | **27**  | <br>  ## 부사 부사의 경우에도 역시 부사 빈도가 높음을 확인할 수 있었습니다.  | 형태소  | 용언 빈도(동사+형용사, 개) | 부사 빈도(개) | | :----: | :--------------: | :-------: | |  더  |    9     |  44   | |  다시  |    15    |  38   | |  안  |    10    |  38   | |  잘  |    20    |  32   | |  가장  |    4     |  57   | |  함께  |    10    |  14   | |  바로  |    2     |  42   | |  모두  |    1     |  49   | |  없이  |    14    |  30   | |  다  |    10    |  37   | |  참  |    4     |  68   | | **평균** |   **9**    | **40.81** | <br> ## 감탄사 감탄사 분석 결과는 아래와 같습니다. | 형태소  | 감탄사 빈도(개) | | :----: | :-------: | |  그래  |  24   | |  아  |  36   | |  뭐  |  28   | | **평균** | **29.33** | <br> ## 어미 어미는 독자적인 품사는 아니지만 분석 결과가 꽤 흥미로워서 소개합니다. 어미와 유사한 단어벡터는 어미라는 사실을 실험적으로 확인했습니다. | 형태소  | 어미 빈도(개) | | :----: | :-------: | |  -다  |  93   | |  -요  |  78   | | -구나  |  93   | |  -군  |  91   | |  -네  |  86   | |  -냐  |  76   | |  -니  |  71   | | -니까  |  70   | |  -라  |  76   | |  -지  |  47   | |  -고  |  66   | |  -며  |  37   | | **평균** | **73.67** | <br> ## Appendix 위 실험 결과 표를 만드는 데 기초가 된 유사단어 리스트를 첨부합니다. 각 단어별로 코사인 유사도 기준 상위 100개 리스트입니다.  *어미* ### -다 <p class="message"> 군, 음, 습니다, 네요, 구나, 구만, 지만, 네, 더라, 군요, 고요, 잖아, 다구, 던, 구요, 지요, 으니까, 다는, 다만, 어요, 으나, 다네, 단다, 거든, 다지만, 구먼, 더군요, 다더니, 더라는, 도다, 소이다, 나, 지만요, 거든요, 다던데, 으니, 다지, 잖아요, 다라는, 더라고, 소, 으므로, 다라고, 죠, 을까, 거늘, 는데, 습니다만, 다던, 다니, 더라구요, 으려나, 더군, 단, 답니다, 다는데, 다면, 읍니다, 은가, 던가, 다며, 으니깐, 다구요, 구려, 을지라도, 건만, 으니까요, 다고, 으리라, 대, 던데, 다더라, 다니까, 다거나, 는데요, 텐, 다란, 그렇지만, 습니까, 을뿐더러, 는디, 으면서도, 더냐, 으며, 은데, 을까요, 을, 던지, 당, 더라니, 허나, 듯이, 다만, 고, 을지언정, 물론, 이희수, 더라면, 는가, ㄴ데 </p> <br> ### -요 <p class="message"> ㅂ니다, ㄴ다구, ㄹ게요, 세, ㅂ시다, ㄹ테니까, 자, 오, ㄹ까요, ㅂ니까, 렴, 라네, 에요, ㄹ텐데, 니깐, 니까, ㄹ래요, 라구, 니, ㄹ지니, ㄴ단다, 세, ㄴ다, ㅂ니다요, 랍니다, 아, 소서, 임마, 는구나, 니까요, ㄴ다니, ㄹ께, 마, ㅂ쇼, ㄹ걸, 여보, 그럼, 믄, 냐구, 라니까, 그러면, ㄴ다지, 도, 거라, 라던, ㄹ세, 옵, ㄴ다니까, 야, 어라, 옵니다, ㄴ데요, ㄴ디, 리다, ㄴ다는데, 보세, ㄴ가요, 건들, 더군요, 니다, 느, 면, 아야지, ㄴ단, 워, 이시여, 는군, 힘내, ㄹ라, 엉, 제발, 다오, 더라구요, 리라는, 라던데, 려나, 죠, 쉿, 이여, 아라, 려구요, ㅂ시오, 미영, 어요, 니라, Go, ㄴ대도, 왈, 되, 라든, 라면서, 라는데, 야, 행, 말, 아유, 구요, ㄴ다던데, 올시다, 나요 </p> <br> ### -구나 <p class="message"> 군, 구만, 다, 군요, 구먼, 네, 죠, 잖아, 더라, 잖아요, 단다, 습니다, 다라고, 지요, 다니, 네요, 다네, 고요, 다라는, 을까, 소이다, 거늘, 더라는, 다구, 음, 거든요, 다지, 도다, 던가, 으니까, 소, 대, 더군요, 다는, 구요, 을가, 다더니, 습니까, 냐, 더군, 구, 나, 읍니다, 다니까, 다란, 지만요, 거든, 다구요, 으려나, 을까요, 대요, 구려, 어요, 단, 다지만, 더냐, 다는데, 나요, 잖니, 란다, 다더라, 지만, 다던데, 라니, 답니다, 던데, 다던가, 다만, ㄹ까, 건만, ㄴ데, ㄴ데요, 라더니, 다고, 아니, 으니, 그나저나, 냐면, 같애, ㄴ가요, 거냐, 건가, 는데, 다던, 게다, 아, 을런지, 로구나, 으니깐, 랍니다, 는디, 은가, 플랜맨, 냐구, ㅂ니까, 담, ㄹ가, 는데요, 으니까요, 니까요 </p> <br> ### -군 <p class="message"> 구만, 구나, 다, 군요, 네, 구먼, 네요, 더라, 고요, 지요, 습니다, 잖아, 음, 소, 구요, 죠, 더라는, 다더니, 으니까, 더군, 단다, 도다, 다네, 다구, 지만요, 다만, 다지만, 지만, 다구요, 잖아요, 대, 소이다, 다지, 습니까, 어요, 더군요, 구려, 나, 다던데, 던데, 더냐, 읍니다, 으니, 다는데, 더라구요, 거든요, 다니까, 냐, 더라고, 다라는, 거늘, 다니, 던가, 으려나, 구, 을까, 답니다, 는디, 다라고, 다는, 거든, 으니깐, 다더라, 던데요, 습니다만, 그나저나, 나요, 으나, 더라구, 을까요, 다거나, 습, 더라고요, ㄴ데, 은가, 는데, 는데요, 다란, 단, 다고, 따, 담, 대요, 쨌든, 잖니, 다면, 킹왕짱, 을가, 으면, 아니, 려나, 당, 다며, 텐, 니, 으니까요, 냐구, 을런지, 어쨌든, 던지 </p> <br> ### -네 <p class="message"> 더라, 구만, 군, 네요, 구먼, 음, 다, 는디, 잖아, 구나, 더라는, 다구, 고요, 더군요, 더군, 는데, 구요, 습니다, 지요, 다니, 대, 나, 어요, 냐, 거든, 더라구요, 잖아요, 군요, 소, 던데, 당, 으니까, 는데요, 다네, 구려, 다지, 으니, 단다, 더라고, 다니까, 지만요, 다던데, 다더니, 구, 다만, 읍니다, 죠, 던가, 나요, 따, 던지, 다지만, 더니, 으려나, 다는데, 는구나, 엉, 건만, 던데요, 어라, 다구요, 다며, 더라고요, 대요, 더냐, 으니깐, 든데, 습, 다던가, 답니다, 는구먼, 더라구, 다면서, 거든요, 도다, 지만, 노, 아, 다더라, 습니다만, 으면, 응, 드럽, 니, 더라니, 소이다, 으나, 는지, 습니까, 다가, 재밋네, 지당, 잘못했어, 는데다가, ㅋㅋㅋㅋㅋ, 웃겨, 대서, 는군, 허허, 냐구 </p> <br> ### -냐 <p class="message"> 냐고, 대, ㅂ니까, 거냐, 구만, 냐구, 더냐, 죠, 던가, 네, 냐, 던지, 냔, 나요, 노, 느냐, 냐면, 냐는, 래요, 잖아, 도데, 거늘, 라든, 다던가, 뭐람, ㄴ데요, 잖아요, 야, 라지, 라구, 습니까, 는가, 도대체, 군, 잖니, 거지, 나, 다더라, 더라, 랴, ㅁㅊ, ㄹ까요, 지요, 든가, ㄴ가요, 는지, 냐며, 구먼, 재밋지, 느냐고, 대체, 구나, 까, 시발, 다구, 씨발, 든, 야, 단다, 라니까, 모야, ㄹ가, 구, 다구요, 아냐, 다면서, 겨, 야, ㄴ가, ㄹ까, 는디, 거든, ㅅㅂ, 든지, 을까, 다더니, 란다, 더군, 라더니, 라네, 라더라, 다지만, 던데, ㄴ다면서, 게요, 얘, 려나, ㅆㅂ, 으냐, 걔, 을까요, ㅉㅉ, ㄹ진데, 아악, 지, 응, ㄴ디, 다던데, 어, 어야지 </p> <br> ### -니 <p class="message"> 니깐, 니까, 면, 려다, 자니, 구, 랴, 습, 요, 려다가, 구먼, 아도, 더니, 려니, ㄴ걸, 네, ㄹ수록, 는데, 어, 래서, 아두, 라지, 생각해보면, 라니까, 아서, 랄까, 길래, ㄹ려다가, 구만, 더라, 려구요, ㄴ대도, 도, 려나, 막상, 자시, 아야지, 더라는, 으려다, ㄴ지라, 꽈, ㄹ걸, 라, 군, 려는데, 건데, 으니, 나, ㄴ들, 면서, 그래, 서, 던지, 라는데, ㄴ다면, ㄹ라, 노, 건만, ㄴ데, 까, 이것저것, 앗, 오, 어라, 라서, 어쩌다, 라지만, 자, 믄, 띄엄띄엄, 냐, 고, ㄹ려, 그리워서, 며, 꼬, 감회, 음, 보고, 그럼, 테, 싶, 간, 다면, 다가, 볼 걸, 곰곰이, 리오, 나발, 재밋, 으면, 아라, 파, 어서, 인피, 까보, 려니까, 더라도, ㄴ지 </p> <br> ### -니까 <p class="message"> 니깐, 니, 라서, 므로, ㄹ텐데, 면, 니까요, 라니까, 라지만, ㄴ데, 란다, 라구, ㄴ데요, 라면, ㅂ니다만, ㅂ니다, ㄹ테니까, 라네, 에요, ㄴ지라, 잖아, 그래서, 라니, 그럼, 그러니까, 라는데, 요, 더라, 잖아요, ㄴ걸요, 더라구요, 원래, 라더니, ㄹ까요, 라, 라도, ㅂ니까, 랍니다, 려다가, ㄴ걸, 그래요, 라던데, 아도, ㄹ걸, 려나, ㄴ대도, 땜시, 사랑하니까, ㄴ다니까, ㄴ가요, 죠, ㄹ려다가, 빠순이, 그러니, 떄문에, 걍, ㄹ게요, ㅂ니다요, 그래, 랴, 야, 근데, ㄴ다면, 랄까, ㄹ지라도, 래도, 야, 그러면, 그냥, 라며, ㄴ다지만, 암만, 더라고, ㄹ수록, 라면서, 어머, 그래도, 건데, 재밋긴한데, 일단, 더라고요, 으니까, 재밋다, 거든, 어차피, 왜냐면, 려니까, ㄴ다니, 재밋어, 구만, 지만, 무조건, 래서, 라는지, 그럭, 보니, 더라도, 든지, ㄹ래요, 아무리 </p> <br> ### -라 <p class="message"> 라고, 라니까, 라서, 라며, 라구, 란다, 라는데, ㄴ지라, 라는, 라면, 니만큼, 라지만, 에요, 라니, 라더니, 라네, 라면서, 니깐, 란, 니까, ㄹ까, 라거나, 라던, 라야, 라느니, 라더라, 랄까, 래서, 랍니다, 야, 랄, ㄴ데요, 하나라, 므로, 자, ㄴ데, ㄹ텐데, ㄴ가요, 니, 곤, 니라, 라던데, 로구나, 라도, 라던가, ㅂ니다만, 라든가, 이, 거늘, ㄹ지라도, ㄴ가, 까지, 과언, 라라, ㄴ지, ㄹ까란, 면, 괜히, 라던지, 든, 단지, ㅂ니다, 그리워서, ㅂ니까, 인양, ㄹ런지, 아니, 히가시노, 냐며, 거니, ㄹ까라는, 라든지, ㄴ듯, 던가, ㄴ다고, ㄹ까요, 옵니다, 여자라서, 냐, 요, ㄴ디, 능사, 다라고, 단순히, 더라도, 일거, ㄹ가, 떄문에, ㄹ락, 길래, 마크 트웨인, 라든, 랄랄라, 인척, ㄴ가라는, 라, 혹, 라고, 이반, 냐고 </p> <br> ### -지 <p class="message"> 않, 내지, 살지, 결코, 절대로, 주진, 졸지, 도, 답지, 주지, 거나, 을뿐더러, 절대, 남진, 얼토당토, 전혀, 달갑, 오질, 딱히, 그리, 그다지, 고야, 덜, 도록, 으리라고, 믿겨지지, 느니만, 되, 는군, 리라고, 다거나, 않, 쉽사리, 나진, 기죽, 매끄럽, 더군, 끝내, 게, 특별히, 쉽, 조차, 고, 는다니, 네, ㄹ걸, 누, 나, 가지, 는다, 적당히, 서슴, 적, ㄹ게, 오히려, 잡지, 네요, 으리라, 꼬지, 하지, 지만요, 냐고, 다며, 이지, ㄹ락, 군, 쉬이, 는구먼, 금방, 는구나, ㄹ지, 개의, ㄹ지언정, 으리라는, 다지, 는다고, 예기, 사랑은 없다, 지만, 으리란, 더라, 시덥, 더라고, 우물쭈물, 탐탁, ㄴ다지, 다, 심지어, 영화ㅜ, 대수롭, 맘먹, 냐며, 한치, 만만, 소, 거든, 으면, 다느니, 습니다만, 더냐 </p> <br> ### -고 <p class="message"> 면서, 거나, 구, 으면서도, 며, 으면서, 으며, ㄴ데다, 고서라도, 다가, 대서, 고라도, 던지, 자니, 그러면서, 되, 재밋고, 하고, 지만, 척, 게, 는데다가, 나, 던가, 아야지, 도록, 적당히, 다거나, ㄴ대도, 다, ㄴ데다가, 고서, 고요, 다며, 니, 도, 을뿐더러, 더라도, 는데, 만큼, 든가, 노라고, 힘껏, ㄹ걸, 거니와, 보다, 나, 엄청, ㄴ걸, 지독히, 마냥, 그만큼, 막상, 던데요, ㅁ, 시종일관, 어서, 어요, 자라는, 더니, 무진장, 더라, 글쎄다, 막, 자마자, 절도, 자는, 어도, 음, 도, 재밋는영화, 어찌나, 쓸데없이, 지, 아서, 적잖이, 마저, 다느니, 건만, 구요, 대, 또, 이토록, 맵시, 자, 곤, ㄹ수록, 채, 노라면, 으니까, 려는데, 네, 자시, 듯이, 너무너무, 굉장히, 케릭터와, 든데, 으니, 려다 </p> <br> ### -며 <p class="message"> 면서, 으며, 끊임없이, 고, 자며, 마음껏, 라며, 남몰래, 다가, 연신, 그러면서, 듯, ㄴ다거나, 려는데, 곧잘, 조용히, ㄴ다, 느라, 시종, 가벼이, 동시, 자유로이, 고라도, 하여금, ㄴ다기, 맘껏, 모습, 부지런히, 뒤로하, 끝없이, 게끔, 함께, 자연스레, 힘껏, 맞대, ㄹ지라도, 번갈, 자, 다함께, 줄곧, 으면서, 인양, 하염없이, 순간, 는데서, 덤덤히, 니, 기어코, 기어이, 뒤치, 아야만, 차분히, 말없이, 이내, ㄴ다며, ㄹ지언정, 순간순간, 담담히, 졸이, 슬쩍, 정신없이, 다시금, 악물, 고픈, 같이, 락, 노라고, 자니, 던지, 조심스레, 안타까워하, 려거든, 듯이, 자고, ㄴ다고, 즉흥, 고서라도, 노라면, 틈틈이, 내내, 이리저리, 려니, 래서, 아등바등, 건만, 소년기, 되짚, 한껏, 이따금씩, 없이, 대신, 고야, 역동, 거침없이, 찬찬히, 마구, 하루하루, 슬그머니, 종횡무진, 끌어안 </p> <br> *조사* ### -이 <p class="message"> 은, 주가, 을, 게, 이야말로, 과, 으로부터, 망상이, 클리셰가, 케릭터들이, 이란, 이안, 다만, 그런데, 게다가, 능력자, 이, 아무래도, 오히려, 더욱이, 허나, 퀄리티가, 게다, 도, 또한, 어쨌거나, 더군다나, 으로써, 그러나, 그리고, 여러모로, 부가, 케릭터가, 으로서, 이나, 그래서, 그럼에도 불구하고, 연식, 추후, 시빌워가, 라스트씬은, 그렇지만, 조력자, 근데, 아, 이남, 당연지사, 연개, 오토봇, 물론, 잖아, 초인, 소말리아 해적, 가지치기, 장이, 가까이, 아이언맨 1, 게, 더라구요, 이야, 그래도, 비록, 더라, 탈것, 클리셰들이, 엔딩크래딧이, 이, 가, 만, 먼치킨, 자베르, 박력, 아마도, 건, 브가, 발레리나, 마저, 사사롭, 어선지, 적어지, 하지만, 아무튼, 이랑, 아가사 크리스티, 그나저나, 뚜렷이, 응집력, 더더욱, 더군요, 드문드문, 빌런, 마찰, ㄹ까란, 제각각, 이몽, 괜히, 괴리, 물거품, 어쨋든, 소유자 </p> <br> ### -가 <p class="message"> 는, 를, 브가, 와, 유가, 케릭터가, 퓨리오사가, 게, 게다가, 삼총사, 정석이, 란, 클리셰가, 우선, 어쩌면, 그런데, 야말로, 늘, 만약, 그리고, ps, 로부터, 만일, 타입, 가, 허나, 그나저나, 다가, 크리스토프 발츠, 와, 로, 비록, 그렇지만, 메인, 로써, 물론, 시빌워가, 아마, 드가, 근데, 다만, 로서, 랑, 로체스터, ㅎㅎㅎㅎ, 야, 철인, 정말로, 또한, 월트, 영화장르, 주가, 먼치킨, 또래, 더군다나, 미장셴이, 아무래도, 그래서, 외적, 다, 을뿐더러, 아마도, 미니언즈가, 도, 나, 멘토, 더구나, 이, 전환점, 지조, 마법사, 빅뱅이론, 베놈, 케릭터들이, 여야, 로, 자비스, 루비, 혼연일체, 오 마이 갓, 단짝, 수혜자, 유모, 게다, 분명, 헬레나 본햄 카터, 그러나, 메시아, 지니, 무적, 쿵푸 팬더, 하지만, 미라, 크리스티나 아길레라, 일단, 여태, 시리우스 블랙, 섹드립이, 삶이, 게 </p> <br> ### -께서 <p class="message"> 께, 님, 시, 감사합니다, 말씀, 친히, 왈, 고맙습니다, 이시여, 선생, 만수무강, 저희, 동림, 목사, 사랑합니다, 하사, 제, 부디, 계시, ㅂ시오, 키팅, 모시, 분, 강림, 할아버지, 니스, 교수, 담임선생, 어머니, 어머님, 부장, 아버님, 수고, 지사, 선배, 한테, 칼 세이건, 안녕하세요, 강사, 님, 고마워요, 소서, 아주머니, 제발, 예수님, 아드님, 나문희, 스탤론, 주시, 양반, 예비, 죄송, 여러분, 할머니, 도와주, 하나님, 뵙, 으시, 어요, ㄹ게요, 신부, 할머님, gv, 에게, 하느님, 은퇴, 사랑해요, 이제, 준이, 이레, 소싯적, 스님, 현역, 극성, 아부지, 형님, 할배, 펜더, 안내, 선생님, 집사, 해주시, 이순재, 클락, 담임, 옹, 그분, 클리닉, 드리, 예수, 아저씨, 유언, 김영, 윗세대, 트럼보, 김성근, 정정, 토크, 바비, ㄹ래요 </p> <br> ### -에서 <p class="message"> 에서부터, 서, 으로부터, 에, 근처, 여지껏, 축소판, 로부터, 아마, 아마도, 빌딩, 바깥, 레온, 연등, 공항, 에게서, SH, 지금껏, 여태껏, 이후, 미러, 사, 스튜디오, 으로, 주간, 엘레베이터, 병점, 지하철, 블라인드, 탈출, 서바이벌, 암전, 언젠가, 화재, 홀로, 기차역, 교실, 요새, 대면, 곧장, 깜깜, 뛰치, 포항, 거울, 배회, 회로, 김포, 영화의 전당, 폐허, 평행, 격투, 올여름, 고사, 수족관, 최초, 마피아게임, 미시, 텐트, 기획전, 연수, 영작, 포화, 지하, 비좁, 첫, 조그마, 박차, 하이라이트, 대형, 이탈자, 소우주, 카운트다운, 드뎌, 경쟁, 결투, 맨, 드디어, 동굴, 산골, 약체, 창살, 앞, 출장, 하루빨리, 백미, 때, 릴레이, 결국, 폴리스, 터미널, 뚫, 이제껏, 활공, 시뮬레이션, 대전, 세상 밖으로, 에다, 주민, 실제로, 약육강식 </p> <br> ### -을 <p class="message"> 을, 은, 으로써, 이, 최대한, 과, 어서라도, 버프를, 를, 내러티브를, 아서라도, 클리쉐를, 조차, 찝찝함을, 퀄리티를, 아가사 크리스티, 으로부터, 이나마, 케릭터를, 스스로, 놓, 이나, 이야말로, 독자, 나마, 대망, 으로서, 만, 왓챠를, 마저, 어다, 조차, 또는, 이란, 기어이, 교차점, 다가가, 기껏, ㄹ, 담담히, ㄴ걸, 클리셰들을, 다발, 으로, 충실히, 게끔, 원대, 무수, 과감히, 빡침을, 교차로, 기꺼이, 어드벤쳐 영화, 문턱, 각자, 답안지, 톨스토이, 려거든, 대신, 유대, 주, 직접, 자신, 사사롭, 게든, 다시금, 한풀이, 몸소, 장발장, 아야만, 모조리, 어른아이, 하여금, 복제인간, 두, 정성스레, 상대, 기어코, 과, 각기, 언가, 애쓰, 양면, 능욕, 미리, 아름다움, 올바르, 성취감, 다가서, 본 아이덴티티, 꼬옥, 마저, 내, 통합, FPS 게임, 혹은, 통과의례, 관철, 지폐, 며 </p> <br> ### -를 <p class="message"> 가, 을, 퀄리티를, 내러티브를, 릉, 는, 시빌워를, 마츠코를, 클리쉐를, 찝찝함을, 룰, 와, ㄹ, 을, 왓챠를, 케릭터를, 로써, 란, 로부터, 클리셰들을, 로, 미니언즈를, 라도, 뭘, 백그라운드, ㄴ답시고, 와, 랑, 만, 로서, 원형, 폴아웃, 미라, 장본인, 구심점, 휼륭한, 기껏, 태어나, 원전, 게끔, 또는, 여태껏, 클리셰만, ㄴ걸, 부흥, 야말로, 묵시록, 지금껏, 성장, 정신분석학, 훌륭히, 여지껏, 자라, 시간이동, 나아가, 브라이언 윌슨, 김연아, 쾌거, 안락사, 메리포핀스, 아서라도, 사라 코너, 하프, 자고, 통상, 뒷걸음질, 직접, 오이디푸스, 창조주, 셰릴, 아야만, 마이너리티 리포트, 달라스 바이어스 클럽, 케빈에 대하여, 언가, 극장판 애니메이션, 평행, 링컨, 바로, 자산, 그토록, 멸망, 타임라인, 고퀄의, 되, 최대한, 메트릭스, 려면, 며, 우선, 완전범죄, 팬덤, 셰르, 열렬히, 곧잘, 심상, 혹은, 유일무이, 자전, 정당성 </p> <br> ### -에 <p class="message"> 퀄리티에, 케릭터에, 시빌워에, 클리셰에, 에서, 에도, 에다가, 내러티브에, 깊이, 에, 에다, 까지, 일본 문화, 에, 거니와, 언저리, 보고서, 뒤집기, 한참, 액스맨, 하지만, 그리고, 떄문에, 에서부터, 욕망이라는 이름의 전차, 보고, 회의감, 전무, 히로스에, 커녕, 깊숙히, 매스컴, 시의, 고서, 으로, 천사와 악마, 고찰, 접근법, 후광, 으로부터, 라는데, 불투명, 맥아담스의, 엔딩크래딧, 연속성, 니만큼, 자만심, 세남자, 변수, ㄴ지라, 데포, 넘어서, 의, 민초, 거들, 격변, 대공황, 왓챠에, 에게, 대열, 이해도, 개뿔, 과, 캐서린 제타 존스, 거의, 광풍, 편안히, 아마, 윤회사상, 아낌없, 로써, 전망, 그러나, 통찰, 어려움, 마련, 깊숙이, 사이비 종교, 찬가, 의구심, 경외감, 라지만, 러시아 영화, 정세, ㅂ니다만, 다발, 지대, 무수, KOFA, 더 드림, 숱하, 들어가, 애정, 논하, 다섯손가락, 무성, 전사자, 주홍글씨, 혹은, 치고 </p> <br> ### -에게 <p class="message"> 한테, 에게서, 께, 로써, 한테서, 한때, 로부터, 모욕감, 어딨을까, 께서, 왈, 어쩌면, 위로, 하여금, 으로서, 응원, 단짝, 로서, 극성, 괴롭히, 선물, 뮤즈, 언젠가, 그리하여, 예비, 으로써, 훗날, 격려, 열렬히, 헌정, 애도, 반기, 마음속, 사랑해요, 이제, 입문자, 와, 화이팅, 곁, 향하, 의, 보살피, 가엽, 미래파, 우상, 보내, 우매, 묵념, 이여, 쫒는, 떠나가, 너, 광식이, 빈자리, 고맙, 진정, 너희, 저, 이력, 혼내, 진정, 뭇, 또는, 안녕, 과연, 알아주, 보듬, 배려, 건네, 그러므로, 헌사, 한풀이, 데려가, 대우, 돕, 나, 사용설명서, 선망, 구원, 행운아, 조련, 광태, 누구, 도전장, 영화에서처럼, 존경, 어리석, 공로, 처방전, 빠순이, 양성, 소싯적, ㄹ진데, 김성근, 감싸, 젊, 안기, 사랑해, 밀어내, 그러자 </p> <br> ### -께 <p class="message"> 께서, 말씀, 한테, 드리, 감사합니다, 에게, 드리, 죄송, 님, 시, 존경, 애도, 감사, 노고, 수고, 만수무강, 분, 고맙습니다, 묵념, 키팅, 삼가 고인의 명복을 빕니다, 하사, 저희, 관계자, 님, 아버님, 사랑합니다, 고인의 명복을 빕니다, 선배, 어머니, 할머니, 주시, 안부, 할아버지, 선생, 제, 혼내, 장병, 모시, 계시, 자녀, 코멘트, 힘내, 화이팅, 보살피, 사죄, 예비, 경의, 의원, 명복, 화이팅, 헌정, 회원, 장군, 아부, 고마움, 부모님, 추천, 주무시, 그분, 공경, 김성근, 친히, 여러분, 격려, 경례, ㄹ게요, 아드님, 부탁, 평론가, 니스, 땡큐, 동림, 할배, 왈, 어르신, 은혜, ㅂ니다, 사랑해요, 추모, 영화평론가, 제보, 선생님, 아부지, 어요, 고맙, 보내, 선조, 미안, 강연, 독립운동가, 스탤론, 정정, 표시, 나문희, 할머님, 표하, 교수, 지인, 목사 </p> <br> ### -한테 <p class="message"> 에게, 왈, 께, 한테서, 쟤, 괴롭히, 야, 맨날, 랑, 께서, 그래요, 혼내, 야, 새끼, 다니까, 아, 에게서, 아씨, 어머, 사랑해요, 그나저나, 꼬시, 씹새끼, 명치, 이새끼, 그러니까, 아부, ㅠㅠㅠㅠㅠㅠ, 걔, 보고, 혼나, 불쌍, 데려가, 얘, 싸인, 극성, 전화번호, 좋아, 데리, 요새, 솔직히, 엄하, 호되, 구박, 어지간히, 월급, 아휴, 부들부들, 한때, ㅁㅊ, 은거, 이제, 개년, 전화, 멕이, ㅡㅜ, 언니, 착한, 하여간, 오빠, 이대, 쌤, 단짝, 빡친다, 누나, 리모콘, 어머나, 이봐, 네, 등짝, 개새끼, 후임, 에이, 으니라구, 노무, 호구, 웃겼어, 쎄, 츤데레, 임마, 이랑, 뽀뽀, 얘, 다짜고짜, 미안, 신랑, 흡, 와이프, 시발, 살, 쎄, 뺨, 코스프레, 짜식, 씨발, 흐엉, 닮음, 멋졍, 삼촌, 여 </p> <br> ### -더러 <p class="message"> 뿐, ㄴ데, 야, 이야, 더라도, 에요, ㄹ지라도, 을뿐더러, 뿐, 조차, 지만, 없다ㅠㅠ, 도, 거니와, 트집, 잖아, 은데, 따름, ㅂ니다만, 만큼, 그렇지만, 조차, 아, ㄴ데다가, 웃어넘기, 더러, 그저, 단지, 거늘, 다만, 영, 다거나, 일부, 정도, 흠잡, 무시, 데, 거나, 직무, 수준, 형언, 소재지, 일, 음슴, 예외, 게, 만, 없, 나무라, 다더니, 건, 뜬구름, 용납, 란다, 잡음, 폐가, 다, 결코, ㄴ데요, 지만요, 을지언정, 그러니, 매도, ㄹ텐데, 내세우, 껀, 별나, 마사, 부재, 부지, 아우성, ㄴ가, ㄴ지라, 고사하고, 흠, 꽁트, 극히, 케릭터, 실패작, 여간, 잖아요, 라더니, 매한가지, 인대, 마저, 게다, 아무것, 지경, 폄하, 징징대, 장난치, 탐내, 까지, 다지만, 투정, 언정, 경우, 형용, 들이, 법 </p> <br> ### -로 <p class="message"> 으로, 퀄리티로, 루, 로, 클리셰로, 로부터, 로써, 로서, 지게, 처럼, 때로, 같이, 기왕, 퀄리티와, 부정교합, 배기, 를, 진실로, 활로, 왕조, 로랑, 대중화, 사카, 새로, 픽셀, 는, 플랫폼, 가, 애로, 파라노, 발명, 엄밀히, 와, 릉, 토대, 주로, 려면, 야말로, 역주, 진공, 스트로, 소개팅, 무성, 불후, 가로, 다, 이윽고, 문학작품, 아스가르드, ㄴ다라고, 까지, 통하, 태산, 뒤바꾸, 고작, 간단히, 퀄리티의, 사랑이라는 이름으로, 테입, 달리, 마스터피스, 제외, 매개, 줄줄이, 그럴싸, 레퍼런스, 쭉, 냉, 대충대충, 영화의 역사, 영하, 쯤, 비로소, 덧붙이, 분기, 독하게, 순서대로, 빼, 칼라, 단순히, 에픽, 매트릭스 시리즈, 완성형, 어로, 피로, 고어 영화, 일일, ㄴ다고, 무난히, 미니시리즈, 착상, 대략, 항목, 봉우리, 맞물리, 그리스신화, 하수구, 삼, 비디오 게임, 대로 </p> <br> ### -으로 <p class="message"> 로, 으로써, 으로서, 순행, 통하, 으로부터, 활로, 에서, 미시, 스티븐 달드리, 클리셰로, 에서부터, 대로, 개인, 통속극, 다각, 없이, 퀄리티로, 진실로, 앵글로, 무난히, 미타니 코키, 횡, 서사, 쭉, 박탈감, 가벼이, 터미네이터 시리즈, 낯설게 하기, 전시, 영화 각본, 을, 오로지, 실질, 순서대로, 스크린, 피로, 에, 아울러, 신비주의, 연대기, 히컵의, 시각, 기념비, 허나, 무조건, 다각도, 병렬, 뜻밖에, 그치, 충분히, 까지, 해리 포터 시리즈, 가로, 기록물, 은, 텍스트, 사고, 독자, 때로, 지극히, 궁극, 카세 료, 심미, 일방, 자발, 일러스트, 여지없이, 이율배반, 세계, 덩그러니, 건축가, 만능주의, 조성희, 중의, 무념, 양가, 측면, 참신, 십분, 객관, 디즈니사, 표면, 인문학, 밑그림, 봉사, 서사시, 본격, 단순히, 용도, 일차원, 다층, 거스, 번갈, 주로, 훌륭히, 이, 과, 달리, 이용 </p> <br> ### -의 <p class="message"> 의, 그리고, 과, 둘러싸, 와, 또는, 빚어내, 진의, 지니, 완의, 혹은, 맞바꾸, 그야말로, 데칼코마니, 만남, 내러티브의, 이야말로, 끝없, 부정교합, 오직, 루크의, 영원하다, 넘어서, 아름다움, 러셀크로우의, 가운데, 넘나들, 쫒는, 스티븐킹, 선보이, 오로지, 가려진, 오가, 가히, 뒤흔들, 그, 및, 사상, 페르소나, 아우르, 클리셰의, 오롯이, 집대성, 명불허전, 언제나, 비록, 아마도, 교차점, 진정, 어쩌면, 달리, 가져다주, 진정, 모두, 낳는다, 단연, 이전, feat, 미니언즈의, 이자, 마침내, 케릭터의, 그러나, 끊임없, 향하, 즉, 더불, 블롬캠프의, 미키루크의, 여느, 항상, 니만큼, 각기, 라이벌, amp, 에게서, 부재, 통하, 대하, 현재, 인하, 곧, 비롯, 정점, 좀먹, 역시, 관통, 명실상부, 고뇌, 양대, 본래, 단짝, 뒤바꾸, 마치, 창조물, 어떻든, 초월, 은, 위대, 로서 </p> <br> ### -과 <p class="message"> 와, 과, 이랑, 사뭇, 달리, 으로써, 극치, 이랑, ㅁ, 그리고, 사이, 이랑, 또는, 궤, 만남, 공존, 으로서, 시네마스코프, 확연히, 유대, 별개, 이외, 관계없, 와, 마저, 카터, 으로부터, 드와, 혹은, 너와 나, 외, 상이, 놀라움, 당혹감, 경계선, 교차점, 차원, 이란, 보다, 함속, 한끗차이, 상반, 확연, 미묘, 콜라보, 마저, 넘어서, 집합체, 이야말로, 으면서도, 과, 대조, 엄연히, 끈끈, 절박, 찝찝함과, 경계, 미학, 약간, amp, 다기, 처지, 부조화, 그러나, 간극, 변주곡, 결정체, 조화, 이나, 양면, 대결, 다르, 불가피, 오만, 차이, 상하, 셀리그, 괴리감, 랑, 아키, 대담, 데칼코마니, 불경, 마피아게임, 데, 부재, 특유, 비례, 조우, 괴리, 덜하, 재회, 감촉, 관계, 커녕, 아둔, 형제, 무마, 탈출기, 깨 </p> <br> ### -와 <p class="message"> 와, 랑, 과, 르와, 이랑, 아키, 랑, 만남, 너와 나, 단짝, 오와, 모녀, 재회, 유대, 드와, 나와 나, 로부터, 데칼코마니, 로써, 서로, 네, 유사, 에리카, 카터, 또는, 별개, 그리고, 아버지와 아들, 다른 나라에서, 나카, 확연히, 신구, 간, 야, 궤, 관계없, 처지, 교차점, 데, 사뭇, 이자벨, 달리, 형제, 앨, 판박이, 혹은, 차원, 는, 언터쳐블, 전과, 스랑, 합작품, 안느, 올리비에, 에게, 로서, 버지니아, 카미, 그레이, 조우, 선재, 대니, 레이어, 니키, 과, 세리, 북소리, 종교와 과학, 온도, 이랑, 좁히, 콩고, 여느, 평행, 당신과 나, 트랜센던스, 별반, 찰떡, 대조, 다, 자던, 사생아, 로이드, 다른, 막스, 썸, 루피, 학, 앙, 탈출기, 대결, 누, 쉐일린, 결별, 상반, 각기, 패거리, 각각, 루베, 남과 북 </p> <br> ### -보다 <p class="message"> 보다, 훨씬, 못지않, 훨, 훨신, 보더, 만큼, 달리, 분명, 낫, 아무래도, 이외, 더, 물론, 외, 하지만, 오히려, 압승, 이젤, 로써, 그렇지만, 솔직히, 이쪽, 이상이, 그래서, 이상, 역시, 라기, 덜하, 덜, 처럼, 그러나, 다기, 조금, 월등, 능가, 과연, 비기닝, 라는데, 무트, 확실히, vs, 글쎄, 정말로, 허나, 한층, 차라리, 웃겼지만, 단, 더군다나, 그래도, 리얼스틸, 아이언맨2, 헌데, 보통, 치고, 커녕, 그리고, 이전, 로서, 진정, 사뭇, 비록, 쪽, 다던데, 글쌔, 과, 기왕이면, 반면, 날이 갈수록, 비하, 어쨋든, 로저, 개인, 지만, 개뿔, 이남, 그런데, 제일, 적어도, VS, 시네마스코프, 다만, 뺨치, 그만큼, 재밋지만, 의외로, 고로, 쪼금, 콜라보레이션, 좀, 더더, 단지, 재밋었는데, 나아지, 엄연히, 가깝, bbbb, 중, 더욱 </p> <br> ### -처럼 <p class="message"> 마냥, 같이, 마치, 듯이, 듯, 같, 인양, 그대로, 달리, 한낮, 같이, 해질녘, 똑같이, 스르르, 색색, 파도처럼, 두서없이, lt, 새빨갛, 만큼, 비닐, 다름없, 감촉, 흐르는 강물처럼, 오색, 못지않, 천천히, 앵글로, 눈송이, 보다, 겹쳐지, 철없이, 연애의 온도, 그림자, 꽃잎, 따라, 꽃할배, 여름날, 뿌옇, 즉, 이따금, 마따나, 느닷없이, 아스라이, 스치, 로, 깃털, 에서부터, 비애, 마냥, 둘러싸, 바람, 마저, 이윽고, 천, 새까맣, 파묻히, 핑크빛, 대신, 같애, 일장춘몽, 겹치, 틈바구니, 서서히, 눈앞, 흙탕물, 속, 분홍빛, 대로, 흐드러지, 마저, 함께, 솜, 때로, 소나기, 불현듯, 실은, 무심히, 복수혈전, 천방지축, 매직, 뺨치, ㄴ다던가, 음표, 문득, 대로, 빗대, 엉키, 새하얗, 이따금씩, 살며시, 에게서, 본뜨, 들꽃, 어쩌면, 때때로, 부러진 화살, 비치, 기왕, 문득문득 </p> <br> ### -만큼 <p class="message"> 만큼, 그만큼, 보다, 여전히, 무척, 그만큼, 못지않, 분명, 충분히, 변함없이, 확실히, 정말, 역시, 이만큼, 이상, 훨씬, 이만큼, 적어도, 너무나, 그다지, 대단히, 의외로, 엄청나, 정말로, 가장, 매우, 달리, 제법, 처럼, 꽤, 유난히, 대로, 허나, 훨신, 반비례, 여전, 파괴력, 만치, 조차, 해상 전투, 지만, 이상이, 건대, 그럼에도 불구하고, 넘어서, 언제나, 결코, 은, 영원하다, 굉장히, 비례, 뿐, 분명히, 금물, 정도, 차이점, 그러나, 글쎄요, 단연코, 남다르, 만, 어마어마, 단연, 상당, 마저, 으뜸, 압승, 뛰어넘, 아주, 너무, 리만치, 크기, 그래도, 거니와, 최대한, 날이 갈수록, 절반, 극장판 애니메이션, 덜하, 다름없, 상당히, 마저, 단지, 가히, 클리셰지만, 그야말로, 나름, 엄청, 유독, 대비, 그렇지만, 제이슨 스태덤, 치어리딩, 콜라보레이션, 더불, 아직, 물론, 뛰어남, 별반, 또한 </p> <br> ### -같이 <p class="message"> 처럼, 마냥, 같, 빠짐없이, 같이, 눈송이, 똑같이, 다름없, 하나하나, 더미, 인양, 간혹, 요괴, 꽃잎, 눈사람, 철없이, 시리얼, 하나하나, 갑자기, 모이, 케릭터들이, 냄새나, 솜, 가끔가다, 얼빠지, 케릭터들의, 마시멜로, 로, 엮이, 착하, 못지않, 알록달록, 뒤엉키, 족족, 케릭터, 소품, 이따금, 같애, 어쩜, 귀엽, 기타 등등, 새빨갛, 무슈, 예쁘, 마른, 꾸밈없이, 케릭터들, 샌디, 죄다, 배기, 파묻히, 톡톡, 얼음, 맛나, 노랗, 옷깃, 일러스트, 등장인물, 년놈, 오밀조밀, 낙엽, 씩, 바닷, 씌, 기왕, 플라스틱, 진짜진짜, 마저, 심지어, 줄줄이, 루, 색색, 스르르, 털, 금붕어, 올리브, 전부, 스웨터, 해질녘, 달리, 마냥, 깃털, 으려다가, 미꾸라지, 몬스터, 렙터, 몽글몽글, 끼리, 눈알, 마치, 등등, 야무지, 하다못해, 맞물리, 시커멓, 둘러싸, 은근, 이쁘, 얽히, 오색 </p> <br> ### -만 <p class="message"> 만, 뿐, 오직, 단지, 만, 오로지, 충분히, 겉, 밖에, 족하, 마저, 충분, 그럭저럭, 클리셰만, 뿐, 덤, 라도, 그냥저냥, 조차, 만큼, 모음집, 도, 단순히, 아무것, 승부, 그런대로, 별, 오롯이, 미만, 최소한, 얼핏, 치환, 순전히, 단, ㄱㅊ, 분명, 이외, 어쨌거나, 그만, 가스파르 울리엘, 그나마, 을, 외형, 그렇지만, 일단, 본전, 돌려막기, 그것, 개똥철학, 클립, 더러, 위주, 한예슬, 논외, 마저, 바즈, 중무장, 실컷, 를, 탱탱, 라도, 물론, 그저, 비단, 만큼, 정작, 왕좌의 게임, 파울, 별셋, 또렷이, 방자전, 쯤, 딱, 맹탕, 나름, 적어도, 제법, 허나, 똑똑히, 이젤, 괜찮, 치어리딩, 그래도, 에바 그린, 소개서, 다만, 장난치, 몇몇, 은, 신은경, 이름값, 조차, 눈요기, 두, 이, 잠깐, 이퀼리브리엄, 골격, 늘상, 을 </p> <br> ### -도 <p class="message"> 조차, 또한, 조차, 두, 심지어, 는, 마저, 거니와, 도, 불구, 은, 퀄리티도, 마저, 물론, 다행히, ㄴ, 을뿐더러, 더군다나, 아무것, 그렇지만, ㄴ데다가, 역시, 그럼에도 불구하고, 고요, 그런데, 뭣, ㄴ데다, 에도, 허나, 모두, 더러, 그러나, 그러면서, 까지, 는데다가, 그래도, 하물며, 만, 게다가, 충분히, 까, 음슴, 다, 왠지, 빠짐없이, 적어도, 선도, 음, 지만, 으면서도, 이, 이나, 더라, 다만, 못지않, 솔직히, 지체, 도, 딱히, 그러므로, 여전히, 고, 구요, 아무, 던데요, 뛰어난 것, 아무튼, 케릭터는, 맹맹, 그냥, 헌데, 특별히, 나, 네요, 그리고, 그저, 그다지, 쥐뿔, 분명, 아직, 실은, 웃겼고, 별것, 더군요, 어선지, 일수, 저, 하지만, 미래엔, 의외로, 전혀, 어쩜, 어쩌면, 던데, 못하, 가끔, 단지, 단, 자니, 대체로 </p> <br> ### -은 <p class="message"> 이, 이야말로, 이나, 그럼에도 불구하고, 을, 그렇지만, 그러나, 그래도, 어쨌거나, 과, 이란, 허나, 도, 이야, 그리고, 퀄리티는, 다만, 는, , 또한, 어차피, 건, 어쨌든, 으로부터, 어쩌면, 으로서, 더라도, 아이언맨 1, 그러므로, 아마도, 그러니, 카우보이 비밥, 내러티브는, 만큼, 적어도, 헌데, 재밌닼ㅋㅋ, 역시, 로구나, 비록, 일순, 라면, 라스트씬은, 보니, 그런데, 의, 어쨋든, 으로써, 역시, 클리셰는, 하지만, 미타니 코키, 이, 아무래도, 이나, 블롬캠프의, 래도, ㄴ, 재밋네요, 케릭터는, 그러니까, 단지, 기왕이면, 로다, ㄴ들, 공성전, 그래서, 물론, 실버 서퍼, 아마, 아이스 에이지, 미래엔, 문제해결, 연개, 즉, 에요, 이, 지만, 건, 아연, 게임 오버, 혹, 메카닉, 거의, 라더니, 이여, 크리스토퍼 리브, 인트로, 무공, 실은, 이당, 이예, 아, ps, 이참, 근데, 까지, 이랑, 재밋, 든 </p> <br> ### -는 <p class="message"> ㄴ, 가, 도, 퀄리티는, 적어도, 그렇지만, 란, 로서, 그럼에도 불구하고, 를, 솔직히, 또한, 어쨌든, 은, 그래도, 야말로, 와, 그러나, 로써, 우선, 그러므로, 허나, 클리셰는, 어쩌면, 내러티브는, 글쎄, 그런데, 그리고, 말하자면, 사랑한다면, 늘, 글쌔, 일단, 다만, 그럼, 가, 건, 다빈치코드, 와, 졸렸음, 물론, 피오, 랑, 을뿐더러, ps, 케릭터는, 더라도, 의, 근데, 하긴, 야, 음, 이전, 그러니까, 아무래도, 쿵푸 팬더, 역시, 남자가 사랑할 때, 헌데, 스티븐킹, 건, 하지만, 로, 어쨋든, 생각해보면, 실버 서퍼, 분명, 찝찝함은, 두, 껀, 휼륭한, 바람의 검심, 미래엔, 역시, 그러면, 나, 면, 지만, 더군다나, 올시다, 실베스터 스탤론, 액스맨, 재밋었다, 러시아워, 터미네이터2, 그러니, 삼총사, 합작품, 그래서, 크리스티나 아길레라, 로맨틱코미디 영화, 재밋긴한데, 어쨌거나, 자체, 프로토콜, 래도, 데스노트, 스타트, 사라 코너, 요건 </p> <br> ### -조차 <p class="message"> 조차, 마저, 마저, 도, 아무것, 아무, 전혀, 도무지, 절대로, 밖에, 끝끝내, 아무런, 한치의, 좀처럼, 만치, 결코, 따위, 함부로, 미동, 도저히, 일말, 쉽사리, 미처, 끝내, 심지어, 차마, 쉬이, 또한, 밖, 거니와, 최소한, 한순간, 한치, 대신, 애당초, 절대, 커녕, 단번에, 을뿐더러, 겨를, 아직, ㄹ지언정, 만큼, 아무, 온전히, 도리어, 거부, 때때로, 느니만, 채, 한시, 다행히, 잊, 도통, 스스로, 만, 용납, 에도, 떨치, 을, 얽매이, 적어도, ㄹ래야, 하물며, 이외, 완전히, 기어이, 더러, 도록, 으리라는, 종종, 너무나, 내지, 가늠, 어떠, 고사하고, 만큼, 는데다가, 누, 굴레, 눈꼽, 쥐뿔, 허락, 공명, 이다지, 그다지, 감당, 무수, 그저, 불구, 벗어나, 배반, 떼, 씻, 곧잘, 선뜻, 잠시, 아예, 가리, 유혹 </p> <br> ### -마저 <p class="message"> 마저, 조차, 조차, 심지어, 또한, 모두, 도리어, 커녕, 끝내, 너무나, 완전히, 몹시, 이내, 끝끝내, 도, 전부, 금세, 한순간, 그러면서, 결국, 때때로, 모조리, 게다가, 허나, 상쇄, 그러나, 대신, 여전히, 리만치, 동시, 그럼에도 불구하고, 내러티브와, 어쩐지, 그야말로, 그지없, 지독히, 하다못해, 오히려, 다행히, 인하, 만, 리만큼, 시각적, 그리고, 아무것, 결국, ㄴ데다, 어느새, 불구, 정작, ㄴ데다가, 연개, 결코, 을뿐더러, 단번에, 처럼, 이다지, 비록, 부조화, 과, 버리, 따위, 역시, 으되, 완벽히, 물론, 무마, 여전, 증발, 짓눌리, 온통, 뚝, 이외, 곧잘, 만큼, 본래, 한껏, 금새, 상응, 과, 함몰, 못내, 모든, 다소, 종국, 조악, 케릭터와, 그저, 승화, 남김없이, 쌩뚱맞은, 미장셴, 는데다가, 게으름, 난데없, 한치의, 희석, 을지언정, 외, 맥없이 </p> <br> ### -까지 <p class="message"> 부터, 까, 엔딩크래딧, 에서부터, 서부터, 까지, 여태, 직전, 빠짐없이, 끝, 거기, 크래딧, 엔딩크레딧, 장판, 무렵, 꾸준히, 서, 모두, 크레딧, ㄴ데다, 쭉, 쭈욱, 여기, 겨우, 전부, ㄴ데다가, 유지, 도, 미장셴, 엔딩 크레딧, 중반, 심지어, 분전, 긴장, 엔딩크래딧이, 자락, 이르, 에, 쯤, 에다, 트리니티, 부, 삼박자, 초, 초장, 처음, 마저, 벌써, 즈음, 초지, 빈틈없이, 다, 이미, 텐션, 든가, 기세, 마저, 두루두루, 긴장감, 한결같이, 어찌어찌, 을까요, 발끝, 설마, 전, 차근차근, 중후반, 최상, 절정, 에다가, 뭥미, 순서대로, 흥미로움, 이대로, 이클립스, 이만큼, 예사, 아우르, 라도, 하강, ㄴ데, 중주, 소피아 코폴라, 멀리뛰기, 벼랑, 시작, 완주, 욕망이라는 이름의 전차, 라면서, 다다르, 냉랭, 간신히, 정색, 거의, 마야, 나가사와 마사미, 대망, 게다가, 도입, 슬슬 </p> <br> ### -부터 <p class="message"> 에서부터, 까지, 서부터, 처음, 끝, 무렵, 벌써, 부, 자마자, 즈음, 도입, 시작, 초장, 첨, 엔딩크래딧이, 언제, 이미, 중반, 슬슬, 엔딩크래딧, 이때, 이후, 심상, 뜨악, 더니만, 중후반, 더라니, 에러, 까, 초반, 초, 거의, 마다, 쭉, 범상, 쭈욱, 여태, 첫, 조짐, 남다르, 알아보, 보기, 보고, 데이빗 예이츠, 종반, 멀리뛰기, 설마, 열, 들어서, 때, 그전, 갑자기, 직전, 쯤, 더니, 전, 전부, 러시아 영화, 급격히, 자락, 혹, 단추, 이르, 헉, 하락세, 이제, 블리자드, 마다, 웃겼는데, 절정, 려니까, 줄곧, 난생, 미비, 혹성탈출, 예사, 오프닝, 오호, 는데, 한결같이, PC, 우선, 애초, 그제서야, 까지, 재밋었는데, 발단, 전, 분만, 하이스쿨 뮤지컬, 됬는데, 일단, 항상, 출생, 에다가, 접어들, 크레딧, 이탈자, 중학교, 욱일승천기 </p> <br> ### -나마 <p class="message"> 이나마, 잠시, 간접, 대리, 위안, 일상, 다시금, 게라도, 뒤늦, 바라보, 시각, 더욱이, 하여금, 어렴풋이, 최대한, 포만감, 틈바구니, 시야, 되돌아보, 심연, 스크린, 안기, 경험, 고마움, 체험, 피상, 상속, 인식, 투영, 막연, 돌아보, 성찰, 들여다보, 새로이, 적잖, 발돋움, 빡침을, 한줄기, 을, 안착, 도피처, 사유, 환기, 금세, 저편, 생활, 엿보, 오랫동안, 객관, 뼈저리, 관조, 회한, 잠시, 속, 안양, 패션계, 품, 뒤로하, 유년, 환멸, 소소한 이야기, 회의, 그제서야, 최초, 뒤덮이, 반추, 유년기, 제공, 이내, 다면, 황폐, 고단, 인도, 향유, 조그마, 잠기, 면면, 됬다, 말미암, 애환, 나도, 입장, 단번에, 시선, 끄트머리, 깨달음, 행복을 찾아서, 휴식, 자취, 사색, 응어리, 계기, 수렁, 생경, 됬지만, 다각, 삼, 도리어, 온전히, 과거 </p> <br> *명사* ### 사람 <p class="message"> 여인, 여자, 놈, 남자, 젊은이, 보통 사람들, 지구인, 독일인, 생각하는 사람, 일반인, 등장 인물, 녀석, 종교인, 동물, 년놈, 현대인, 미국인, 당신, 시민, 주민, 이웃, 군인, 주인공, 인물, 사내, 아이, 지인, 사회인, 남학생, 등장인물, 자, 권력자, 연인, 유명인, 인간, 학생, 자국민, 타인, 민초, 도시인, 기독교인, 친구, 어르신, 선임, 회사원, 아랍인, 예술가, 위인, 지식인, 좋은 사람, 승객, 이방인, 민간인, 일본인, 여대생, 어린애, 동족, 짐승, 청년, 그분, 후임, 종족, 당사자, 정치인, 여인네, 서양인, 생물, 여학생, 군중, 소년, 외국인, 산악인, 낭만주의자, 커플, 상대방, 여자애, 손님, 여고생, 출연자, 참가자, 유태인, 구성원, 남정네, 교도관, 팀원, 양놈, 주인, 수컷, 인격, 자식, 유가족, 알바생, 독립투사, 관람객, 작자, 투자자, 소비자, 선원, 얼간이, 육식동물 </p> <br> ### 때 <p class="message"> 떄, 무렵, 즈음, 마다, 어리, 그때, 마다, 시절, 적, 초등학교, 자마자, 멋모르, 토요명화, 중간고사, 순간, 주말의 명화, 생일날, 비디오 테이프, 당시, 언젠가, 처음, 엔딩크래딧이, 기세, 수록, 때로, 뻔, 텐가, 청소년기, 는데, 명화극장, 비디오테이프, 졸업식, 연등, 국민학교, 쿠아, ㄴ다기에, 일요일 아침, 때, 다음날, 학년, 1월 1일, 중고등학교, 비올, 당혹감, 이후, 토요일, 이때, 전날, 비디오, 크리스마스 이브, 고비, 부터, 비디오테잎, 비로소, 정도, 고삼, 그날, 중고등학생, 보라, 주간, 직전, 수학여행, 중학교, 에프, 난생, 수나무, 몰래, 지경, 그러자, 이불속, 매주, 재방송, 첨, 교실, 비로서, 동창, 담임선생, 팔로, 차례, 티비, 합창, 또래, 장마철, 면서, 무심코, 보고, 법, 유년, 데, 한창, 겉잡, 아부지, 소싯적, 학교, 시기, 대면, 중학생, 유년기, 파사, 외할머니 </p> <br> ### 일 <p class="message"> 일, 일어나, 사건, 해프닝, 일탈, 사회생활, 업무, 벌어지, 일이, 반응, 시련, 고객, 저지르, 짓, 사업, 직업, 모임, 악행, 위급, 구실, 선임, 행동, 생활, 근무, 고용, 상황, 취업, 발생, 노동, 고난, 물건, 경우, 상속, 불행, 거짓말, 가정, 부작용, 정규, 불량품, 리액션, 고충, 정치인, 사정, 오지랖, 공무원, 경험, 선택, 주변, 작전, 매일, 영위, 운동, 자살, 나날, 불평, 진급, 짓거리, 장애물, 다툼, 불량, 처분, 대기업, 약물, 조건, 증상, 실명, 공작, 실제로, 운, 활동, 환경, 연애담, 회사원, 삶, 제품, 인적, 불청객, 외상, 년놈, 족보, 발발, 원인, 소동, 여권, 시리얼, 헤프닝, 취재, 어려움, 주어지, 독버섯, 반란, 생겨나, 페이스북, 전전긍긍, 프레젠테이션, 조작, 지진, 버릇, 진학, 후임 </p> <br> ### 말 <p class="message"> 말, 수식, 말씀, 형용, 설명, 한마디, 수식어, 얘기, 생각, 뜻, 대답, 주장, 형언, 표현, 호칭, 두말, 평하, 명언, 고백, 거짓말, dad, 언급, 표기, 반박, 굿럭, 마디, 조언, 문장, 지칭, 유언, 코멘트, 제안, 대사, 구절, 이름, 증명, 문자, 전달, 항변, 번복, 통역, 부탁, 단어, 잘 알지도 못하면서, 변명, 말하자면, 막말, 물어보, 맹세, 미사여구, 미영, 이루, 자부, 요약, Jane, serious, 개소리, 오겡끼데스까, 전하, 욕, 그러면, 선언, 의역, 입증, 경청, 형용사, 거절, 염병, 한말, 구구절절, 마따나, 혼잣말, 투덜거리, 이순재, 글자, 확신, Why, 변호, 돌, 규정, 번역, 속담, ME, 장담, stay, 이동진, 평, 표시, 칭찬, 인용, 동의, 명명, father, 샷건, 노랫말, 왈가왈부, 거론, 동감, 애원, 답하 </p> <br> ### 사회 <p class="message"> 자본주의, 세태, 사회구조, 제도, 사법, 부조리, 체제, 병폐, 계급, 시스템, 폭압, 체계, 현대, 계층, 개인주의, 현시대, 부정부패, 이데올로기, 미디어, 전체주의, 물질만능주의, 정치, 신자유주의, 공리주의, 매스미디어, 물질주의, 공동체, 부패, 실태, 윤리, 관료주의, 국가, 민주주의, 고발, 비판, 기성세대, 집단, 공권력, 규범, 기득, 사법부, 약자, 민영화, 이기주의, 대한민국, 경제, 자본가, 관료, 인권, 현대사, 독재, 권위, 오늘날, 질서, 현주소, 모순, 중산층, 시대, 사회주의, 다문화, 의료보험, 교리, 빈부격차, 불합리, 언론, 가부장, 생태계, 사회상, 노예제도, 내부고발자, 성차별, 정책, 파시즘, 외모지상주의, 정부, 의료, 풍자, 권력자, 인신매매, 행태, 문화, 억압, 여성혐오, 만연, 가부장제, 기업, 인종차별, 불평등, 노동, 이해관계, 기계화, 정치판, 보수, 규제, 권력, 하층민, 패권주의, 파시스트, 검찰, 우화 </p> <br> ### 속 <p class="message"> 틈바구니, 바깥, 가운데, 함속, 꿈속, 안팎, 진흙탕, 머릿속, 파묻히, 잿빛, 물속, 사이사이, 머릿, 너머, 갇히, 마음속, 사이, 소용돌이, 가슴속, 앞, 한가운데, 곳곳, 이면, 회색빛, 네모나, 한복판, 늪, 허우적대, 혼재, 둘러싸, 공간, 저편, 어둠, 어두움, 텅텅, 갖힌, 바닷속, 아비규환, 정사각형, 궁전, 방안, 저마다, 위, 내면, 틈새, 눈앞, 심연, 무채색, 허우적거리, 중심, 바닷, 쓰레기장, 총천연색, 진흙, 연못, 피어나, 창고, 밝음, 뒤편, 둘러싸이, 가득히, 덮힌, 안쪽, 숲, 깊숙이, 가려진, 이곳저곳, 상속, 일상, 구멍, 찻잔, 혼돈, 홍수, 켠, 어지럽히, 사무실, 깊숙히, 대도시, 무간지옥, 무의식, 냉정과 열정 사이, 안, 강정, 수렁, 모노톤, 아래, 내부, 음지, 땅속, 빈집, 골짜기, 도처, 진공, 현대, 몸속, 밑바닥, 뒤덮히, 포화, 웅덩이, 암흑 </p> <br> ### 문제 <p class="message"> 성차별, 문제점, 오류, 병폐, 차이, 이슈, 장애, 사회구조, 윤리, 체계, 제도, 관심사, 딜레마, 직무, 원인과 결과, 인종차별, 화두, 젠더, 사회, 증거, 논의, 불평등, 이해관계, 빈부격차, 인종, 논쟁, 인간관계, 계급, 한계, 견해, 인과, 폐해, 에니그마, 비리, 개인주의, 사태, 넌센스, 정치, 컴플렉스, 피해자, 난제, 고질, 갈등, 동성애자, 우선순위, 제재, 교리, 종교, 회의, 성과, 복지, 원인, 논란, 차별, 사법, 여성혐오, 관계, 인권, 유색, 세태, 모순, 몰이해, 통계, 개신교, 이데올로기, 성소수자, 학문, 공리주의, 논리, 잘못된 것, 변수, 알레고리, 성범죄자, 가치관, 문화, 성범죄, 약자, 범주, 보수, 가해자, 경제, 징후, 트랜스젠더, 현상, 계층, 절차, 상관관계, 분쟁, 불화, 동성애, 횡포, 소수자, 헛점, 근본, 아동학대, 구조, 미디어, 필수요소, 침해, 유기 </p> <br> ### 문화 <p class="message"> 인종, 다문화, 대중문화, 언어, 신세대, 민족주의, 계급, 정서, 지역, 사회, 부르주아, 일본 문화, 복지, 이슬람, 외교, 실태, 현대, 개방, 젠더, 프랑스, 종교, 매체, 군국주의, 세계사, 국가, 경제, 서구, 인도, 아시아, 서브컬쳐, 제도, 전통, 컨텐츠, 교리, 유럽, 정치, 좌파, 동남아, 근대사, 국적, 인종차별, 패권주의, 제국주의, 산업, 계층, 이데올로기, 인권, 견해, 중동, 서양, 터키, 물질주의, 인디영화, 인도네시아, 학문, 불교, 동성애, 물질만능주의, 업계, 개인주의, 컬쳐, 성소수자, 노예제도, 동양, 가부장제, 병폐, 성차별, 각국, 식민지, 빈부격차, 분야, 현주소, 중국, 민족, 남미, 관료주의, 노동, 보수, 인류학, 우월주의, 차별, 담론, 전체주의, 양식, 사회주의, AV, 자연주의, 화폐, 미디어, 기성세대, 천주교, 전라도, 노동자, 사회상, 생활상, 누벨바그, 나라, 아방가르드, 기성, 콘텐츠 </p> <br> ### 집 <p class="message"> 자취방, 편의점, 쇼파, 거실, 서점, 맥도날드, 우리집, 고향, 횟집, 부엌, 방구석, 동네, 이불속, 동물원, 소파, 미용실, 빵집, 남극, 병원, 백화점, 안방, 호텔, 모텔, 음식점, 침대, 마트, 가게, 문방구, 집안, 점심, 산속, 방, 근처, 식당, 다락방, 화성, 옷장, 캠핑, 회관, 박물관, 수학여행, 기숙사, 감방, 장롱, 디비디, 빈집, 우리 집, 강릉, 필리핀, 이웃집, 옆, 텐트, 창고, 아파트, 카페, 아쿠아리움, 몰래, 목욕탕, 골방, 농장, 수족관, 대여점, 벤치, 차안, 농사짓, 트럭, 미술관, 포항, 술집, 공원, 냉장고, 시골, 감옥, 대문, 지하실, 그곳, 초밥, 정원, 벽장, 통영, 놀이동산, 주방, 바닷가, 지하철, 사무실, 골목, 골목길, 소풍, 영화관, 옥상, 성당, 출장, 혼자, 경찰서, 크리스마스 이브, 광산, 식탁, 쫓겨나, 언덕, 놀이공원 </p> <br> ### 경우 <p class="message"> 사례, 케이스, 컨텐츠, 부류, 기회, 변수, 이유, 부작용, 원인과 결과, 리메이크 영화, 요인, 수요, 사태, 요소, 행태, 단서, 분야, 용어, 오류, 인지도, 확률, 경향, 치료제, 이슈, 결과, 종류, 나라, 영화, 콘텐츠, 징후, 법, 옴니버스 영화, 몰이해, 영화 리뷰, 일, 참사, 에피소드, 견해, 물타기, 실수, 영화장르, 문제, 원인, 알고리즘, 인과관계, 인재, 예시, 행위, 상당수, 속설, 것, 장치, 호응, 상황, 패러디 영화, 모티브, 어휘, 넌센스, 부분, 공감대, 내부고발자, 개입, 주범, 이야깃거리, 재료, 이해도, 징크스, 형용사, 인기, 괴작, 성과, 반면, 포비아, 전례, 환경, 완성도, 게, 트러블, 모티프, 제재, 창작물, 성범죄, 연도, 영화 시나리오, 실례, MSG, 기대치, 캐릭터, 후자, 퀄리티, 영상물, 추종자, 제도, 시나리오, 뉘앙스, 사건, 독립 영화, 위기, 스핀오프, 동기 </p> <br> *동사* ### 하- <p class="message"> 하, 하긴, 해보, 하, 할거, 하면 된다, 하구, 줄창, 하긴, 시키, 돕, 열심히, 말, 해, 우베, 내심, 해지, 부추기, 다짐, 하나라, 뭣하, 알, 말, 쩝, 그치, 꾀하, 지켜보, 칭하, 라고, 바쁘, 간절히, ㄴ다고, 고르, 매번, 키득키득, 그만두, 열중, 꺼리, ㄴ다라고, 징징대, 내보, 청하, 야하, 반신반의, 계속, 외, 연습, 가져가, 도와주, 바라, 신중히, 달, 임하, 엔드, 구장, 무트, 애원, 하지만, 부끄러워하, 아라고, 알아보, 생각, 그것, 대, 아무튼, 불리, 내, 쿵푸허슬, 해내, 일절, 그래야, 들어주, 쓰잘데, 바르, 결심, 아쉬워하, 전념, 쫓아가, 찔끔찔끔, 거리, 피하, 갓파, 막연히, 애쓰, 구걸, 본전, 자부, 심, 마땅히, 라, 다르, 됬지, 논하, 보, 부지런히, 치켜세우, 되, 으리라고, 얘기, 구 </p> <br> ### 있- <p class="message"> 있, 없, 잇, 잇달, 없, 없다ㅠㅠ, 수, 넘치, 관계없, 었, 음슴, 가지, 쏠쏠, 낫, 지니, 있다, 계시, 제로, 변함없, 왕실, 극대치, 다분, 갖, 각자, 았, 한자리, 여유, 떨어지, 상관없, 분명히, 터무니없, 충분, 저마다, 숨, 중요시, 충분히, 차치, 밖, 다름없, 바로, 상당, 쩌, 볼품없, 어처구니없, 온전히, 빈틈없, 두서없, 많, 싶, 보듬, 살아가, 생동, 소소한 이야기, 는, 전해질, 가져다주, 함의, 문제없, 자만, 동시, 엿보, 공존, 왈가왈부, 여실, 옴니버스 영화, 경쟁력, ㄹ, 으리란, 머물, 전무, 으랴, 부족하다, 인정, 부대끼, 도무지, 예법, 형편없, 양립, 부여, 따라붙, 자부심, 결여, 불가사의, 아이러니, 두, 중시, 아, 반비례, 일순, 수용, 어렵, 존재, 부럽, 쩖, 곳곳, 터놓, 재력, ㄹ래야, 효용, 주 </p> <br> ### 되- <p class="message"> 됬다, 되, 됬을, 됬으면, 되, 바뀌, 도와주, 계기, 생기, 못되, 됬지만, 만들, 거듭나, 망가지, 풀리, 아서도, 탄생, 설령, 같아지, 뒤바뀌, 우연찮, 아니, 깨지, 철들, 공교롭, 아니, 비로서, 시키, 굳어지, 걸리, 하, 깨어나, 인걸, 변하, 안됬다, 끝나, 덜되, 사라지, 풀어지, 이루어지, 나타나, 앞지르, 찢어지, 더러워지, 변모, 벗겨지, 비로소, 살아나, 됬는데, 과언, 갈아타, 늙, 뽑히, 붉어지, 뒤늦, 예비, 허다, 어쩌다, 태어나, 흐트러지, 또는, 라면, 깨어지, 땡기, 뒤집히, 전직, 만약, 커지, 체 게바라, 넘어지, 잡혀가, 바로, 나오, 질리, 생겨나, 성립, 시들, 꼬이, 들어서, 과부, 죽, 엎어지, 언젠가, 훗날, 불러내, 주객, 아마, 하락, 낸시, 달라지, 데이빗 예이츠, 격, 고착, 잡히, 답, 시키, 되살아나, 으로서, 애완동물, 떠오르 </p> <br> ### 보- <p class="message"> 찾아보, 본, 감상, 재밋는영화, 영화관, 극장가, 극장, 봄, 관람, 본건, 접하, 보고, 복습, 살펴보, 볼걸, 깔깔대, 보기, 봄ㅋㅋ, 재밋게, 시청, 볼, 만나, 보고 또 보고, 나오, 참고, 재밌는 영화, 안보, 보구, 보고, 볼 걸, 즐기, 깔깔거리, 보고싶다, 다녀오, 보아주, 보, 잠들, 낄낄대, 빡치고, 고르, 불멸의 이순신, 쳐다보, 보다, 지켜보, 보신, 졸렸음, 개봉, 재밌, 읽, 이거, 섭렵, 영드, 보고 싶다, tv, 졸, 다시, 맛보, 정독, 넷플릭스, 재미있, 본거지, 보, 들여다보, 좋아하, 티비, 미니언즈를, 빡치는, 별생각, 재밋음, 듣, 뵈, 무서워하, 보면, 세번, 심야, 뵙, 밤새, 투니버스, 반신반의, 재밋었음, 놀라, 재방송, 둘러보, 재밋네요, 레미제라블, 채널, 울, 아이스에이지, imax, 재밌닼ㅋ, 시달소, 바라보, 안타까워하, 낭패, 엔딩크래딧, 서편제, 웬만, 영홬, 재밋게봄, 즐거워하 </p> <br> ### 대하- <p class="message"> 관하, 고찰, 입각, 탐구, 의하, 통찰, 몰이해, 성찰, 근원, 상관관계, 동경, 막연, 비하, 통하, 인하, 물음, 답변, 담론, 깃들, 열망, 신앙, 빗대, 존재론, 말미암, 또는, 지대, 사후, 동시, 목마르, 찬가, 향하, 사랑과 결혼, 집착, 질문, 예찬, 따르, 유무, 사형제도, ㄴ가라는, 회의, 믿음, 헌사, 본질, 관련, 철학, 불신, 둘러싸, 애정, 이면, 피상, 찬미, 담기, 도전, 회한, 천착, 모독, 윤리, 접근, 예우, 접근법, 인종 차별, 저변, 역학, 근거, 알량, 관계없이, 방법론, 속성, 덕택, 근본, 굶주리, 사로잡히, 대처, 맹목, 가치관, 윤회사상, 대항, 갈망, 헌신, 쓰기, 충성심, 전사자, 기인, 고마움, 불평등, 이외, 존엄사, 견해, 정당성, 임하, 애증, 경외, 심층, 보편, 의, 비유, 안락사, 다시금, 동경, 기반 </p> <br> ### 위하- <p class="message"> 의하, 통하, 향하, 위해, 워밍업, 포석, 프로젝트, 겨냥, 아서라도, 잡기, 희생, 디딤돌, 급급, 발판, 감행, 빙자, 기나길, 수단, ㄴ답시고, 반쪽, 으려는, 직전, 자처, 전초전, 택하, 대신, 사투, 바치, 밑밥, 떄문에, 안간힘, 짜리, 초석, 투쟁, 밑거름, 삼만, 분투, 값비싸, 생존, 목적, 일보, 여정, 도모, 인하, 려는, 덕후, 본뜨, 몸부림, 원하, 느라, 기꺼이, 억지로, 준비, 려던, 완수, 제물, 랍시고, 바쁘, 기원, 맞바꾸, 자아, 포함, 심리치료, 으려던, 훌륭히, 구하, 빌미, 징검다리, 힘들, 전우, 둘러싸, 잃어버리, 긴긴, 달려오, 고군분투, 착실히, 되찾, 편의, 노리, 찾, 려고, 부단히, 진혼곡, 급조, 다오, 이용, 갉, 갱생, 모집, 관하, 앞두, 도약, 염두, 대하, Feat, 바라, 인공호흡, 찾아가, 로부터, 생계 </p> <br> ### 가- <p class="message"> 달려가, 돌아가, 갈수, 들어가, 끌려가, 데려가, 나가, 행, 다녀오, 몰, 뛰어가, 부치, 산, 갈수록, 들어오, 뛰어들, 돌아오, 넘어가, 가, 안감, 건너가, ㄱㄱ, 오, 가져가, 날아가, 방황하는 칼날, 못가, 접어들, 나아가, 날라가, 캠핑, 잡혀가, 이사, 떠나, 걸어가, 돌, 들어서, 되돌아가, 산적, 끌, 가시, 출장, 오, 수학여행, 갈, 흘러가, 서쪽, 기어오르, 넘어오, 내려오, 여행가, 잡아가, 동쪽, 강릉, 사, 안드로메다, 인도, 필리핀, 갈, 근처, 갈래, 다가가, 남쪽, 팔, 발리, 배낭여행, 달나라, 굴러가, 살, 떠돌, 귀향, 주인, 베로나, 정복, 도착, 떠내려가, 곧장, 미용실, 히말라야, 정하, 돌진, 금방, 흘러오, 리스본, 산속, 이어지, 달려오, 내달리, 끌어가, 되돌아오, 첩첩산중, 가야, 올라오, 쫓겨나, 헤매, 뛰어오, 치솟, 달아나, 간, 날 </p> <br> ### 받- <p class="message"> 안받, 인정받, 얻, 갚, 당하, 돌려받, 버림받, 대우, 대접, 당하, 강요받, 막, 빼앗, 앓, 끌어안, 물려받, 주진, 떠안, 욕먹, 적잖, 낳, 깎, 추앙, 이어받, 일삼, 아카데미상, 주, 닫, 면하, 주지, 치솟, 응하, 치료, 오스카상, 먹, 되찾, 수상, 주기, 아카데미, 기뻐하, 찾, 오스카, 선고, 뺏, 상처, 노벨상, 입, 돌려놓, 맡, 내놓, 도둑맞, 마땅, 상, 겪, 보듬, 수상, 빼먹, 홀대, 요청, 아카데미 작품상, 틀어막, 행사, 살아남, 칭송, 옮, 삼, 구박, 악영향, 몰아넣, 굴하, 낚, 본받, 올려놓, 고마워하, 치유, 털어놓, 껴안, 사과, 보호, 휩쓸, 서슴, 바로잡, 얻어맞, 뽑, 거머쥐, 미움, 보답, 갈라놓, 위로, 삶, 마지않, 담, 돕, 핍박, 아카데미 여우주연상, 물려주, 돌려주, 풀어놓, 끝마치, 닦 </p> <br> ### 보이- <p class="message"> 알리, 드러내, 나타내, 가르치, 빛내, 받치, 일깨우, 드러나, 비추, 여실히, 그리, 내보이, 깨우치, 느끼, 밝히, 내비치, 메우, 안기, 선보이, 두드러지, 띄, 읽히, 까발리, 뽐내, 여과, 적나라, 가감, 끌어내, 꾸미, 파헤치, 다루, 엿보이, 부각, 단적, 가리, 여실, 끝내, 꼬집, 담아내, 들어내, 보일, 비치, 전하, 펼치, 채우, 넓히, 높이, 풀어내, 매만지, 나타나, 보듬, 없애, 몸소, 파고들, 대변, 묻어나, 이끌, 살리, 던지, 폭로, 민낯, 끌어올리, 증명, 잡아내, 도드라지, 꿰뚫, 풀, 투영, 가르키, 높히, 극명, 돋보이, 메꾸, 감싸, 뒷받침, 띄우, 상기, 혼내, 녹이, 전달, 재확인, 심, 어루만지, 지키, 불어넣, 발가벗기, 제시, 시키, 들추어내, 극명히, 들추, 집어내, 강조, 각인, 어우르, 드리우, 볼품없, 과시, 충족, 챙기 </p> <br> ### 읽- <p class="message"> 책, 소설책, 소설, 정독, 원서, 만화책, 희곡, 읊, 꺼내, 권, 듣, 서적, 쓰, 단편소설, 일기장, 적, 동화책, 단편 소설, 옮기, 추리소설, 그림책, 들추, 시집, 국사, 위인전, 자서전, 뱉, 두껍, 외우, 문학작품, 읽히, 알랭 드 보통, 역사책, 찢, 훑, 원작, 논문, 성경, 웹툰, 곱씹, 모비딕, 감상문, 씻, 오만과 편견, 넘기, 뒤집, 해설, 도서, 고전문학, 되짚, 받침, 에세이, 블로그, 헤집, 영화 리뷰, 씹, 리뷰, 평론, 국어, 인터넷소설, 지문, 원본, 퇴마록, 짚, 셰익스피어, 유서, 찾아보, 알아듣, 더듬, 겪, 연극, 어톤먼트, 메리 포핀스, 접하, 헤아리, 찍, 만화, 쓰다듬, 들어주, 자평, 심리학, 연애소설, 저자, 내려가, 알아먹, 무라카미 하루키, 베스트셀러, 써내, 끊, 써먹, 빌리, 접, 피카소, 풀, 덮, 섞, 책장, 보, 살펴보, 꿰뚫 </p> <br> ### 잡- <p class="message"> 붙잡, 다잡, 뽑, 밟, 쫓, 휘어잡, 잡히, 가져가, 꽂, 잡아먹, 찾, 박, 갈피, 끌어안, 부여잡, 잡아가, 묶, 붙들, 맞잡, 잡기, 토끼, 머리채, 뻗, 때려잡, 껴안, 뒤쫓, 올려놓, 발목, 들여놓, 빼앗, 멱살, 꺾, 좇, 닦, 갖, 쫓아가, 모으, 짚, 뺏, 흔들, 내려놓, 마리, 낚, 잡아내, 헤집, 맡, 내놓, 막, 사로잡, 몰아넣, 앉, 넣, 고르, 매달, 풀어놓, 짓밟, 잘라먹, 놓, 끌, 삼, 떠안, 감, 집어넣, 걷, 휘감, 자리, 닫, 데려오, 이어받, 노려보, 타, 걷어차, 꿰뚫, 꼽, 빨아먹, 휘청, 쥐, 놓, 깍, 해치, 깎, 뿌리치, 되찾, 맞히, 갚, 훑, 균형, 놓치, 붙, 주저앉, 손, 태우, 꼬집, 잃, 끊, 자르, 안받, 우겨넣, 익살맞, 꿰 </p> <br> ### 자- <p class="message"> 잠, 잠들, 졸, 밤새, 낮잠, 몰디브, 끄, 어제, 화장실, 영화관, 눕, 빡쳐서, 혼자, 잣, 오늘밤, 심야, 모텔, 다음날, 주무시, 둘이, 거실, 소파, 뛰쳐나오, 파, 깨어나, 배고프, 소주, 모히또, 달아나, 밤새, 술, 손잡, 도망가, 뛰쳐나가, 맥주, 세번, 새벽, 벌떡, 생일날, 몰래, 이불속, 고모, 집, 눈뜨, 쇼파, 귤, 포항, 울, 자취방, 일주일, 나중, 뒷자리, 하마터면, 해외여행, 놓, 깔깔거리, 이서, 여자친구, 세수, 째, 캔디맨, 침대, 극장, 조깅, 이어폰, 소개팅, 담그, 참, 딴, 밤길, 다가, 밤, 마시, 조조, 얌전히, 앉, 같이, 극장가, 사, 야근, 한밤중, 움츠리, 낮술, 대성통곡, 푹신, 앞자리, 한잔, 골방, 오늘, 배낭여행, 겄, 일간, 음료수, 얼떨결, 비가, 결혼, 김, 우물, 밤잠, 큰소리 </p> <br> ### 던지- <p class="message"> 날리, 내던지, 가르키, 심, 남기, 일침, 띄우, 질문, 넌지시, 화두, 찌르, 집, 뿌리, 두드리, 미끼, 건네, 안기, 뭉개, 내밀, 새기, 내려치, 꽂, 돌, 치우, 물음, 흔들, 올리, 흩, 묻, 들이밀, 직구, 보내, 떠넘기, 맡기, 뱉, 퍼붓, 휘두르, 집어던지, 도전장, 씌우, 카운터, 긁, 터트리, 구기, 내리치, 들이대, 두들기, 세우, 가르치, 접, 떠먹, 쑤시, 터뜨리, 돌맹이, 내보이, 휘갈기, 후려갈기, 얹, 때리, 콕, 어지럽히, 꼬집, 짚, 건네주, 멍석, 돌멩이, 내비치, 꽂히, 내뱉, 후려치, 부수, 울리, 알리, 따끔, 되묻, 싣, 치켜세우, 뒤흔들, 겨누, 흩뿌리, 얹히, 숙이, 틀, 잠재우, 뒤집, 읊, 들추, 꾸기, 넘기, 꺼내, 삼키, 적시, 스트라이크, 싸지르, 힌트, 눕히, 받치, 경고, 지피, 내리 </p> <br> ### 뛰- <p class="message"> 뛰어다니, 달리, 날아다니, 쿵쾅거리, 구르, 흔들, 댕기, 두드리, 건너, 움직이, 두들기, 쓰러뜨리, 걷, 쿵쿵, 내리치, 날, 심장, 숨차, 날으, 꺽, 부딪히, 요동치, 뛰어오르, 부딪치, 후리, 헐떡이, 휘젓, 쏘, 부시, 저리, 싸우, 두근두근, 가르, 들썩거리, 방방, 누비, 후려갈기, 쿵쾅쿵쾅, 때리, 타, 두근거리, 덮치, 부수, 슝슝, 뛰어내리, 굴리, 겨루, 부러지, 뒤치, 움츠러들, 뛰어놀, 돌아다니, 뜨거워지, 드릴, 콩닥콩닥, 쾅, 미끄러지, 찌르, 주무르, 날아가, 꺾, 나르, 휘, 다니, 후려치, 얻어터지, 기어가, 뻗, 달려오, 넘어지, 드럼, 휘날리, 장풍, 날아오르, 내달리, 가로지르, 벌렁, 지르, 찢어지, 펄럭이, 펄펄, 오금, 펴, 헤치, 엎치, 물리치, 땀나, 울리, 울렁이, 활, 내려치, 뛰어오, 치키, 갈기, 달구, 발가락, 부서지, 작두, 똥줄, 세차 </p> <br> ### 믿- <p class="message"> 거르, 맘먹, 인정받, 규정짓, 속이, 비웃, 옳, 아끼, 옮, 배우, 미워하, 알아주, 탐내, 넘보, 붙잡, 일컫, 다신, 책임지, 기르, 만지, 모시, 칭하, 말리, 빌, 믿기, 닥치, 의심, 확신, 꿇, 인정, 꿀리, 로버트 로드리게즈, 저버리, 알아보, 챙기, 탐하, 놓아두, 신뢰, 안목, 맡기, 가리, 외치, 발등, 에이브럼스, 쫓, 되묻, 기대, 반기, 들어주, 치켜세우, 사단, 카메룬, 기죽, 내키, 따지, 돌려받, 잊, 권하, 불리우, 추리, 사리, 절정기, 더럽히, 오로지, 어리석, 두려워하, 욕보이, 이중인격, 레오나르도 디카프리오, 종잡, 명불허전, 내려놓, 역시, 다물, 꼽, 던칸, 막, 카메론 크로우, 알, 지키, 뜻대로, 혹하, 실천, 숭배, 모, 조니뎁, 재확인, 트레이드, 불리, 응하, 겁먹, 밀, 데이빗, 갚, 모건 프리먼, 눈여기, 미덥, 본받, 성선설, 톰 행크스 </p> <br> ### 살- <p class="message"> 살아가, 살수, 잘살, 살아오, 살아남, 지내, 살길, 연명, 하루하루, 굴러가, 가꾸, 살아야 한다, 영위, 몸부림치, 태어나, 뛰놀, 자라, 뛰어놀, 걸어가, 돌아가, 돌아다니, 못살, 기어가, 살아나, 버티, 뛰어가, 대접, 순응, 움직이, 해매, 움츠리, 날, 삶, 담그, 정착, 자라나, 산다, 낙오, 나아가, 살지, 구하, 불타, 돌보, 누리, 머물, 변두리, 멀쩡히, 웅크리, 떠돌, 열심히, 사시, 들여다보, 팍팍, 쫓겨나, 변하, 도망가, 간직, 헤엄치, 부유, 악착같이, 허덕이, 허우적거리, 먹고살, 보금자리, 거닐, 뒹굴, 뛰어다니, 터전, 자립, 우아한 세계, 들여놓, 부지런, 헤매, 정글, 지키, 그리워하, 성실, 선량, 탐하, 아등바등, 이곳, 고단, 좇, 달아나, 죽, 조망, 살펴보, 팔딱팔딱, 기어오르, 바쁘, 치이, 쓸모, 물려주, 아파하, 구경, 각자, 부대끼, 다스리, 뛰어들, 팔리 </p> <br> ### 쉬- <p class="message"> 숨, 가쁘, ㄹ새, 틈, 늦추, 편히, 몰아치, 멈추, 내쉬, 헐떡이, 버티, 떼, 안톤, 막히, 턱, 기어가, 달리, 한숨, 멎, 놓아주, 주무시, 한시, 새, 놓치, 조이, 졸리, 지치, 편안히, 깜빡, 잠들, 거치, 돌리, 인정사정, 뻗, 잠시, bbbbb, 움직이, 참, 쭈욱, 느리, 말리, 헤엄치, 푹푹, 놀래, 숨차, 쫓아가, 트이, 따라가, 맥클레인, 닐슨, 여유, 견디, 잠자, 몰아붙이, 쭉쭉, 내달리, 쫓아오, 뵈, 쪼이, 카, 움켜쥐, 새, 살피, 지겹, 졸, 웃겨주는, 숨통, 즐기, 굴리, 쓰러지, 끊어질, 눈치, 꼼짝, 팔딱팔딱, 부릅뜨, 방방, 마렵, 졸음, 비틀거리, 젓, 잊, 감질나, 휘몰아치, 건너, 템포, 깨우, 빵빵, 입담, 뒤지, 근심, 잠깐, 지루, 끄, 바짝, 꺼지, 지침, 팡, 죽이, 실없이, 스피드 </p> <br> ### 앓- <p class="message"> 끙끙, 시달리, 우울증, 에이즈, 겪, 정신분열증, 불면증, 정신병, 증, 괴로워하, 환자, 실연, 트라우마, 독, 증후군, 조울증, 받, 떠안, 물어뜯, 괴로움, 걸리, 털어놓, 뒤쫓, 암세포, 외상, 열병, 찾아다니, 끓, 몸살, 끌어안, 움츠리, 병자, 증세, 익사, 허덕이, 고통, 멍들, 부글부글, 닳, 자폐증, 할퀴, 당하, 일주일, 탈탈, 억누르, 과대망상, 웅크리, 단기, 조증, 아파하, 들끓, 허우적대, 병들, 심장마비, 갈구, 붙들, 자괴감, 헤로인, 허우적거리, 증상, 불타, 부여잡, 색정, 왕따, 독신, 치료제, 핥, 쇠약, 해매, 분개, 괴롭힘, 중2병, 짝사랑, 곤경, 기억상실증, 발작, 뺏기, 리비도, 좀먹, 두통, 알콜중독, 헤집, 제제, 목마르, 외로움, 괴롭, 괴롭히, 병, 옭아매, 헤매, 세포, 치료, 빨아먹, 참, 신경증, 방랑, 산전수전, 공포증, 후유증, 콤플렉스 </p> <br> ### 흐르- <p class="message"> 흘러내리, 넘실거리, 넘실대, 휘몰아치, 쏟아지, 물밀, 스치, 고이, 솟구치, 번지, 퍼지, 철철, 흩날리, 파도처럼, 스며들, 흘러나오, 사그라들, 끓, 흘러들, 저물, 요동치, 지나가, 밀려오, 이어지, 북받치, 출렁이, 흘러가, 뚝뚝, 몰아치, 세월, 핏물, 밀려들, 주르륵, 강물, 차오르, 사라지, 쓸리, 스러지, 지나, 주륵주륵, 찾아들, 아름다운 선율, 잔잔히, 흔들리, 음표, 선율, 흘러오, Pop, 흘려보내, 눈물이 주르륵, 비바람, 감돌, 일렁이, 붉어지, 식은땀, 부서지, 흘리, 흩뿌리, 달아오르, 갈라지, 꽃피, 좔좔, 거스르, 넘치, 튀기, 구름, 흐드러지, 세차, 피어오르, 시들, 움츠러들, 들끓, 깔리, 쌓이, 미끄러지, 맺히, 흩어지, 불길, 유유히, 적시, 아련히, 낭자, 가로지르, 덜컹, 묻어나, 갔, 뒤섞이, 요동, 펼쳐지, 몰려오, 펴지, 뜨거워지, 녹아내리, 드리우, 부글부글, 어우러지, 젖, 휘날리, 계절, 펄펄 </p> <br> ### 피- <p class="message"> 피우, 꽃, 한송이, 시들, 진흙, 모래, 흐드러지, 피어나, 들꽃, 연꽃, 풀밭, 담구, 바닷물, 담배, 봉숭아, 바람, 피, 베, 비바람, 꽃잎, 뒹굴, 이슬, 낙엽, 가로등, 기름, 불, 내리쬐, 붉, 걷히, 새싹, 위스키, 햇빛, 새, 기, 말리, 볕, 아스팔트, 잔디, 매니큐어, 장미꽃, 흙, 핏물, 푸르, 피어오르, 촛불, 벚꽃, 구르, 소금, 잡초, 부러지, 난로, 꺼지, 대지, 나뒹굴, 번지, 달구, 햇볕, 계곡, 도화지, 흘러들, 담그, 해바라기, 쓸리, 초록빛, 달빛, 눈밭, 노을, 스러지, 내리, 끓, 비누, 물들이, 흙탕물, 웅덩이, 잉크, 불, 휘날리, 불타, 꺾이, 밭, 모금, 부서지, 담벼락, 불길, 송이, 무르, 흙먼지, 펄럭이, 코피, 맨발, 펴, 덮이, 폭포, 등지, 헤엄치, 보드카, 서성이, 세수, 굽, 심지 </p> <br> ### 솟- <p class="message"> 치솟, 샘솟, 솟구치, 내려앉, 차오르, 들끓, 솟아나, 솟아오르, 가라앉, 끓, 넘실거리, 흘러내리, 오르, 뛰어오르, 낭떠러지, 펄펄, 휘감, 날, 부여잡, 불타, 달아나, 쭈뼛, 활활, 얼어붙, 뻗, 엔돌핀, 우뚝, 주저앉, 쏟, 기어오르, 꿈틀, 날아가, 맑, 끓어오르, 타오르, 피어오르, 고이, 골짜기, 내리치, 번지, 치닫, 내뿜, 검붉, 부글부글, 수놓, 젖, 불타오르, 날수, 뚝, 돋아나, 돋, 남, 전갈, 돌, V8, 말미암, 뿜, 뭍, 비누, 잉크, 밟, 발바닥, 출렁이, 흥건, 올라오, 페달, 불끈, 날라가, 붓, 되살아나, 꽂, 팡팡, 스미, 붉, 식은땀, 물방울, 흘러들, 냄비, 나진, 밀려오, 녹, 날, 흙먼지, 넘쳐흐르, 꺾, 박, 꺾이, 빨아먹, 달아오르, 뻗치, 들여놓, 북받치, 핏물, 일렁이, 사방, 몸속, 연료, 닿, 엔진, 드넓 </p> <br> *형용사* ### 없- <p class="message"> 있, 음슴, 없, 없다ㅠㅠ, 있, 전무, 문제없, 없이, 형편없, 두서, 쓸모없, 잇, 상관없, 별다르, 볼품없, 가망, 눈꼽, 없어짐, 애당초, 하등, 밖, 재미없, 두서없, 제로, 수, 고사하고, 쓸데없, 겨를, 찐빵, 어쩌, 딱히, 이루, 터무니없, 관계없, 도무지, 난데없, 아무런, 읍, 볼일, 전무, 떨어지, 앙꼬, 지장, 덜하, 두드러지, 따위, 아무, 조차, 안남, 을뿐더러, 이외, 못되, 전부일, 으리란, 변함없, 결코, 실종, 더러, 나무라, 이견, 쏠쏠, 정신없, 어처구니, 다름없, 범접, 한치의, 쩖, 느닷없, 어이, 어처구니없, 어렵, 연개, 아니, 필요, 사빠, 싫, 부질없, 어이없, 안중, 으랴, 손색없, 사라지, 걷잡, 순, 일수, 그지없, 사납, 겉잡, 쥐뿔, 잇달, 생기, 다더니, 있다, 조차, 당연지사, 불명확, 신경안, 도저히, 만치, 틀리 </p> <br> ### 그렇- <p class="message"> 그래요, 그러, 이렇, 그럼, 저렇, 다르, 흐음, 이러, 그러, 이, 애석, 졸렸다, 그렇지만, 그리, 이리, 더욱이, 그런, 일, 하긴, 그냥, 지나치, 졸렸음, 아쉽, 당황, 뭐, 그저, 여자라서, 그런데, 재밋었는데, 글쎄, 근데, 밋밋, 별로, 저러, ㅂㄹ, 밍밍하다, 코웃음, 음, 난리, 끌리, 그래서, 워낙, 가물가물, 실망, 쩝, 재밌, 애초, 서두, 외려, 절, 우습, 헷갈리, 공교롭, 별로, 어색, 그르, 심심, 얘, 무난, 아무렇, 엄청, 쟤, 자자, 밍숭맹숭, 다던데, 너무, 영국영화, 똑같이, 어수선, 오히려, 최근작, 안타깝, 야하, 그러니까, 가물, TV시리즈, 그래도, 아무튼, 솔직히, 서럽, 어리둥절, 그, 반갑, 던데, ㅡㅜ, 어떻, 아리송, 글쎄요, 답, 틀리, 더더욱, 비슷비슷, 평소, 혹, 혹하, 모르겟지만, 싱겁, 애매, 그리도, 일부러 </p> <br> ### 같- <p class="message"> 같애, 처럼, 똑같, 같이, 마냥, 닮, 꿈같, 듯, 다름없, 같, 좆같, 비슷, 흡사, 그런, 랄까, 머지않, 많, 다, 마치, 같이, 마냥, 별반, 좋, 수많, 영화ㅠ, 야, 느낌, 괜찮, 프리즌브레이크, 틀림없, 느낌ㅋㅋ, 다르, 맞, 일루셔니스트, 한국화, 유사, 파리대왕, 훨, 빼닮, 같아지, 영호ㅓ, 달리, 집기, 뿐, 작, 밍숭맹숭한, 영화인, 전래, 점잖, 짝퉁, 믹스, 은데, 일수, 능글맞, ㄴ듯, 이솝우화, 보다, 맞닿, 그리스신화, 그것이 알고 싶다, 실사판, 익살맞, 시답잖, 핥, 못지않, 섞, 폐쇄공포증, 느니만, 인줄, 훨신, 콜라보레이션, 한결같, 검, 뜨뜻미지근, 이왕, 즉, 농익, 고퀄리티, 왜냐하면, 분명, 슈워, 낡, 닦, 아냐, 뿐, ㄴ가, 은, 개살구, 잦, 르포, 실낱같, 불길, 착상, 주옥같, 관련, 판의 미로, 워킹데드, 으면서도, 애꿎, 잔치 </p> <br> ### 어떻- <p class="message"> 과연, 저렇, 도대체, 어찌, 게든, 왜, 이렇, 대체, 언제, 정녕, 도데, 아서든, 어째서, 얼마나, 전생, 어쩌다, 저거, 오죽, 는가, 무슨, 느냐, 려나, 인도인, 아니, 뭐람, 어떤, 저러, 어쩜, 저리, 게라도, 는지, 어떡하, 진작에, ㄴ다는데, 관건, 으려나, ㄴ다던데, 언제, 어떠, S2, 왜, 뭐, 진작, 을까, 애당초, 됬지만, ㄴ다니, 뭘, 만약, 만일, 누가, 고작, 저런, 무엇, 급하, 흐음, 바로, 아마, 이따, 이러, 아무렴, 어떻하, ㅂㄷㅂㄷ, 이, 글쎄요, 궁금, 실제로, 는구나, ㄴ다던, 2601, 노예, 굳이, ㅉㅉ, 아서라도, 이쯤, 냐, 글쎄, 쯧, 을까요, 당연히, 대수, 더구나, 어디, 계속, ㄹ려, 절레절레, 그렇, 잘못된, 그럼, 무어, 저리, 맘대로, 1986, ㄹ꼬, ㄹ까라는, 든, 냐, 문제, 누구, 또 </p> <br> ### 이렇- <p class="message"> 저렇, 이리, 이토록, 이다지, 어쩜, 왤케, 그리, 이만큼, 어떻, 이런, 왜, 이, 이러, 저리, 참, 그리도, 그렇, 드럽, 정말, 너무, 다니, 어찌나, 얼마나, 자고로, 쓸데없이, 참으로, 지나치, 대체, 요런, 엄청, 저러, 이만큼, 가뜩이나, 도대체, 뭐람, 원체, 겁나, 게, 어째서, 굉장히, 넘, 답, 대차, ㅈㄴ, 저런, 죄다, 하고, 공상과학 영화, 맙소사, 게라도, 아휴, 어지간히, 어떡하, 꽤, 어쩌다가, 얘, 애당초, 이따, 는구나, 만치, 진짜, 꺅, 억세, 딴, 워낙, PC, 디스토피아 영화, 굳이, 어머나, 됬다, 아주, 정녕, 대단히, 원래, 기왕, 참, 더욱이, 칫솔, 영국영화, 줄이, 저토록, 모야, 항상, 너무나, 몰라보, 하여간, 제법, 모름지기, ㄴ데다가, 든가, 94, 가장, 뭐, 무지막지, 너무너무, 한결같이, 야, 눈물이 주룩주룩, 서방, 던지 </p> <br> ### 다르- <p class="message"> 달라지, 별반, 달리, 틀리, 확연히, 다른, 똑같, 차이, 차이점, 무관, 관계없, 사뭇, 딴판, 비슷, 엄연히, 일맥상통, 동떨어지, 상관, 비교, 달라지는 것, 똑같이, 어긋나, 상관없, 정반대, 상관없이, 흡사, 괴리감, 남다르, 유사, 상이, 하등, 확연, 닮, 그렇, 새롭, 차별, 편차, 바뀌, 성별, 생김새, 갭, 별개, 색다르, 관계없이, 겹치, 맞닿, 겹쳐지, 이질감, 판박이, 연관, 뒤떨어지, 같아지, 동일, 상반, 기존, 덜하, 괴리, 엇갈리, 각각, 여타, 다름없, 밀접, 반반, 피부색, 맞, 아쉽, 낯설, 이누도 잇신, 역차별, 별나, 껄끄럽, 단절, 공통점, 비슷비슷, 변하, 부대끼, 격차, 각자, 빗나가, 반대, 크기, 레지던트이블, 궤, 사랑의 방식, 차이나, 나아지, 동등, 뒤쳐지, 불공평, 에러, 싱겁, 머지않, 당연지사, 당혹, 따로, 지향, 겉모습, 문제, 같, 각기 </p> <br> ### 크- <p class="message"> 커다랗, 크나크, 스펙, 커지, 크기, 적, 엄청나, 작, 조그맣, 작아지, 거대, 많이, 어마어마, 스케일, 타, 이맥스, 스팩, 별다르, 세, 강하, 적어지, 터, 큐, 우드, 조그마, 비중, 쎄, 깊, 심하, 적잖, 터, 로이, 약하, 강력, 던지라, 지, 굉장, 세, 펌, 무지막지, 규모, 셰인, 파급, 절감, 격하, 외적, 뼈저리, 하지, 남다르, 안기, 많, 리프, 한, 도드라지, 낮, 괜하, 아무런, 리어, 라이트, 저조, 중대, 다면, 트, 지대, 법, 덩치, 넓, 상당, 줄, 폭넓, 스텐, 실망감, 높, 높히, 빅, 드라마틱, 임팩트, 실망, 미미, 생기, 익스, 폭, 뼘, 줄어들, ㅂㄹ, 서럽, 재밋엇다, 파장, 진하, 갭, 넓히, 기여, 주되, 부풀리, 자잘, 다치, 기대치, 우즈, 무겁, 삼삼 </p> <br> ### 많- <p class="message"> 적, 많이, 수많, 얕, 잦, 작, 짧, 높, 낮, 이런저런, 깊, 적잖, 폭넓, 좋, 심하, 주옥같, 약하, 하찮, 여러, 쓸데없, 강하, 수두룩, 무수히, 사공, 좁, 넓, 늘어나, 괜찮, 몇몇, 낯익, 짙, 시답잖, 해묵, 몇몇, 풍부, 불필요, 빈번, 다양, 이래저래, 쓸모없, 할애, 들, 호평, 산재, 애꿎, 대부분, 숱하, 별별, 여럿, 수없이, 즐비, 좆같, 상당수, 자주, 귀찮, 쏟, 길, 혹평, 같, 재밋다고, 다분, 곁가지, 감명, 한꺼번에, 케케묵, 과도, 크, 방대, 활용도, 방정맞, 상당, 대거, 각종, 적어지, 과, 간혹, 갖가지, 잡다, 과다, 늦, 어리석, 뛰어나, 비좁, 미흡, 터무니없이, 풍성, 모든, 사소, 외적인, 얇, 시원찮, 자잘, 왜색, 온갖, 재미없, 복잡, 왕창, 궂, 옅, 쓸데 </p> <br> ### 좋- <p class="message"> 괜찮, 재미있, 재밌, 좋, 조음, 밝, 나쁘, 높, 굳, 많, 시원찮, 좋으다, 싫, 한결같, 뛰어나, 주옥같, 언짢, 좆같, 알맞, 재밌는 영화, 똑같, 방정맞, 옳, 재밋당, 굿, 한결, 멋있, 훌륭, 개떡, 참신, 좋앙, 낮, 흡족, 잦, 이뻤다, 재미없, 나쁘지 않아, 맑, 재밋고, 좋다ㅠㅠ, 형편없, 별로, 귀찮, 좋겟다, 재밋, 짧, 좋닼ㅋ, 즐겁, 재밋었음, 재밋다, 반갑, 뛰어남, 낯익, 글쎄다, 아쉽, 예쁘, 뛰어난 것, 재미나, 꿈같, 멋지, 이뻤음, 재밋는, 나쁜 영화, 훌룡한, 수준급, 인상, 별루, 깊, 아쉽, 돋, 재밋었다, 발군, 풍성, 맡, 으련만, 일단, 이뻤고, 너무너무, 쩔었음, 능글맞, 좋아하, 하시모토 아이, 흠잡, 잘, 얕, 그렇지만, 퀄이, 풍부, 농익, 조타, 괜츈, 짙, 이쁘, 익살맞, 참, 들어맞, 찰떡, 물론, 출중, 무르익 </p> <br> ### 힘들- <p class="message"> 어렵, 버겁, 힘겹, 괴롭, 드물, 바쁘, 싫, 쉽, 까다롭, 역부족, 껄끄럽, 우습, 어려움, 버거워, 고달프, 고되, 수월, 못, 안쓰럽, 고역, 피곤, 곤란, 어지럽, 느라, 숨쉬기, 좀처럼, 불편, 슬프, 느라고, 두렵, 벅차, 외롭, 애쓰, 부끄럽, 춥, 지겹, 민망, 시, 아쉽, 무섭, 앞서, 꺼리, 숨차, 아깝, 지치, 안타깝, 거북, 지난, 길, 더디, 기쁘, 십상, 어린것, 서툴, 늦, 애처롭, 무리, 귀찮, 역겹, 마련, 고생, 이르, 졸리, 혼잡, 급급, 서글프, 성실히, 속상하, 아프, 편하, 재미있, 시빌워는, 기, 눈물겹, 창피, 그지없, 가혹, 덥, 지리멸렬, 못하, 겹, 치아, 얄밉, 재밌, 서투르, 낯설, 부럽, 더럽, 으시, 험난, 서럽, 위하, 애달프, 천만다행, 상스럽, 안됬다, 고맙, 구질구질, 려니, 불가 </p> <br> ### 검- <p class="message"> 붉, 사제, 검붉, 녹색, 하얗, 푸르, 시커멓, 드넓, 새하얗, 얇, 연못, 새까맣, 푸른, 솜, 들꽃, 뱀, 파랗, 봉우리, 빤스, 검정색, 벌거벗, 붕대, 백색, 희, 잡초, 도화지, 모래, 회색, 노랗, 꽃, 전갈, 흰색, 맑, 칠흑, 빨갛, 초록, 정령, 빨간색, 흰, 새빨갛, 아스팔트, 구름, 갈색, 분홍색, 천사, 참새, 덮힌, 발가벗, 아래, 안개, 지붕, 어둠, 바다, 골짜기, 칼날, 초록색, 얼어붙, 물감, 잉크, 넓, 색색, 봉숭아, 핏자국, 검정, 리본, 하늘, 뒤덮이, 갑옷, 까맣, 별빛, 헐벗, 웅덩이, 위, 내려앉, 하얀색, 태양, 천장, 검, 투명, 검은색, 수놓, 초록빛, 순백, 비닐, 파란, 웨딩드레스, 금빛, 갈대, 잔해, 진흙, 캔버스, 썩, 장미꽃, 달빛, 덮이, 지폐, 강물, 먹물, 짙, 굵 </p> <br> ### 시끄럽- <p class="message"> 정신없, 사납, 어지럽, 요란, 징그럽, 더럽, 떠들, 부산, 시끌벅적, 상스럽, 지르, 피곤, 꽥, 소란, 빽빽, 무섭, 역겹, 비명, 산만, 메스껍, 어수선, 귀엽, 졸리, 법석, 예쁘, 지저분, 괴롭, 분주, 지겹, 답답, 난잡, 갑갑, 번잡, 실없, 마렵, 재미없, 수다, 우습, 이쁘, 춥, 웃겼다, 요란, 지름, 조용, 쓸데없이, 소리, 왁자지껄, 횡설수설, 어질어질, 졸렸다, 지루, 느리, 웃기, 수다, 드럽, 야, 호들갑, 자빠지, 너저분, 덥, 잔인, 따분, 칙칙, 깜짝깜짝, 날뛰, 징징대, 휘황찬란, 안쓰럽, 졸림, 정신없이, 지치, 큰소리, 단조롭, 재밌닼ㅋ, 외롭, 똥꼬, 간지럽, 신나, 어두컴컴, 현란, 울렁거리, 시종일관, 떨, 방방, 낭자, 나대, 부럽, 질퍽, 어둡, 뛰어다니, 단조, 찝찝했다, 경쾌, 얌전, 길, 총소리, 어이없, 지루, 밉, 뻣뻣 </p> <br> ### 거칠- <p class="message"> 투박, 차갑, 부드럽, 차분, 과격, 둔탁, 느리, 간결, 건조, 딱딱, 상스럽, 난폭, 담백, 우악, 서툴, 날렵, 날카롭, 우아, 지저분, 매섭, 직설, 질척, 담담, 세련, 단아, 맹렬, 유려, 매끈, 탁하, 예리, 심플, 유연, 애처롭, 직선, 서투르, 저돌, 경쾌, 무덤덤, 축축, 냉혹, 끈적, 깨끗, 냉랭, 섬세, 강렬, 과묵, 너저분, 우스꽝스럽, 격렬, 정제, 정교, 냉정, 덤덤, 제멋대로, 점잖, 뻣뻣, 편안하다, 리드미, 뜨겁, 어둡, 어지럽, 미끈, 솔직, 어수룩, 올곧, 농염, 느긋, 질퍽, 칙칙, 대담, 침착, 난잡, 빠르, 처연, 진솔, 퍽퍽, 묵직, 무디, 신속, 단조롭, 원색, 활기차, 말끔, 세밀, 불안정, 삐뚤, 수다, 깔끔, 조용, 요란, 음울, 헐겁, 우직, 명징, 무미건조, 고루, 단백, 어수선, 가늘, 괴팍 </p> <br> ### 빠르- <p class="message"> 느리, 속도, 스피디, 템포, 더디, 신속, 급박, 유연, 스피드, 느릿느릿, 순조롭, 휙휙, 속도감, 간결, 진행, 전개, 재빠르, 가쁘, 느긋, 어지럽, 시원시원, 둔탁, 날렵, 급하, 느슨, 흐물흐물, 점프, 현란, 매끄럽, 둔하, 루즈, 정신없, 산만, 급격, 정교, 깔끔, 호쾌, 단조롭, 갑작스럽, 리드미, 흥미진진, 리듬감, 거칠, 화끈, 급작스럽, 딱딱, 조밀, 부드럽, 쾌속, 경쾌, 심플, 직선, 과격, 어수선, 들쑥날쑥, 정신없이, 유려, 평이, 덜컹거리, 매끈, 리듬, 막힘없이, 역동, 격렬, 난잡, 두서없, 박진감, 차분, 느릿한, 몰아치, 긴박, 지지부진, 빈번, 플로우, 술술, 호흡, 착착, 촘촘, 일직선, 간단, 과감, 쭉쭉, 흘러가, 고속, 성기, 알차, 짧아지, 동선, 치밀, 쉽, 평탄, 짜치, 엉성, 길, 간단명료, 딱딱, 붕붕, 순탄, 가늘, 쫀쫀한 </p> <br> ### 힘들- <p class="message"> 프리, 낯설, 험하, 동떨어지, 나아지, 가깝, 어리, 무디, 머나멀, 눈멀, 넓, 매, 매이, 조셉, 얼, 데, 모건, 늙, 내치, 좁히, 멀리, 늘, 펄, 삐뚤, 레인맨, 머, 서, 씌, 두렵, 뜨, 떠밀리, 찌들, 옅, 사다코, 길들이, 비치, 이자벨, 헤이, 덮이, 가리우, 성숙, 여물, 둘러싸이, 더 가까이, 너그럽, 천국, 잊히, 시시, 니콜, 지, 떠나가, 로건, 세리, 짧아지, 서쪽, 키드, 카프, 오와, 넌, 가리, 미덥, 붕, 미카엘, 토시, 처지, 까마득, 디카, 프리, 설, 너머, 저편, 다카, 딸리, 에이다, 시리, 아득, 조고, 익, 커지, 서글프, 훗날, 타이, 기, 가엽, 접히, 빗, 뜨이, 아득히, 물들, 미란, 괴롭, 오, 걸어도 걸어도, 남기, 깃, 쓰이, 세르, 범, 텅, 파랗 </p> <br> ### 높- <p class="message"> 낮, 높이, 높히, 낮추, 상승, 폭넓, 저하, 얕, 넓, 평점, 많, 저조, 최저, 뛰어나, 적, 만족도, 하락, 좋, 좁, 괜찮, 현저히, 최하, 초고, 얇, 점수, 깊, 완성도, 수위, 약하, 높이, 기대치, 하찮, 높이, 그래프, 퀄리티와, 밀도, 짙, 깎, 별점, 떨어지, 급상승, 향상, 악명, 치솟, 드넓, 평균, 퀄리티가, 작, 적잖, 올려놓, 인지도, 퀄리티, 뛰어남, 깍, 떨어뜨리, 퀄이, 뛰어난 것, 밝, 활용도, 형편없, 증가, 강하, 수직, 월등, 심하, 우수, 저, 호평, 로튼, 야박, 난이도, 상향, 끌어올리, 넓히, 옅, 지능, 감소, 잦, 상당, 타율, 진입, 풍부, 감명, 굵, 떨어트리, 채도, 마이너스, 순도, 엄청나, 바닥, 평가, 대중, 신빙, 품질, 불투명, 안받, 이해도, 미달, 인색, 양호 </p> <br> ### 높- <p class="message"> 아름답, 단어, 눈부시, 예쁘, 처연, 애달프, 슬프, 황홀, 감미, 애절, 어여쁘, 멋지, 아름다운 선율, 수려, 푸르르, 우아, 싱그럽, 화사, 신비, 순수, 매혹, 영롱, 서글프, 고즈넉, 애잔, 찬란히, 이쁘, 찬란, 풍경, 애틋, 서정, 경이롭, 농염, 장엄, 시리, 잔혹, 반짝거리, 아련, 몽환, 가냘프, 차갑, 쓸쓸, 낭만, 따사, 구슬프, 고풍, 숭고, 웅장, 따스, 아름다운 그녀, 애처롭, 푸르, 처절, 비통, 풍광, 강렬, 관능, 아름다운 청춘, 색감, 적막, 다채, 섬세, 창백, 유려, 고요, 설경, 흐드러지, 포근, 근사, 가슴 아프게, 고귀, 절절, 원색, 깨끗, 경이, 따뜻, 뜨겁, 청초, 부드럽, 황량, 척박, 새하얗, 투명, 쓰라리, 청량, 롭, 잉그리드 버그만, 기괴, 아리땁, 천진, 따듯, 청아, 오색, 아릿, 달콤, 금빛, 흑백, 아리, 끔직, 처량, 비정, 수수 </p> <br> *부사* ### 더 <p class="message"> 훨씬, 더욱, 더더, 더욱더, 덜, 더 스토리, 훨신, 더더욱, 훨, 한층, 오히려, 얼마나, 더하, 가장, 보다, 이만큼, 보다, 덜하, 제일, 더, 을수록, 광장히, 보더, 확실히, ㄹ수록, 굉장히, 다듬, 무척, 다기, 아주, 백, 못지않, 조금, 워낙, 그나마, 제법, 특별히, 더없이, 재일, 줄이, 상당히, 너무, 유독, 이왕이면, 수록, 좀, 가다듬, 템플, 보태, 더라면, 매우, 이나마, 이젤, 더 게임, 라도, 쪼끔, 더 가까이, 나아지, 이쪽, 젤, 쪼금, 엄청, 충분히, 지, 은근히, 한결, 이토록, 그다지, 외려, 분명, 울프, 그만큼, 진정, 더 드림, 추리력, 10000, 반감, 괜시리, 내성, 으려나, 날이 갈수록, 겁나, 대단히, 딥, 그것이 알고싶다, 페스, 줄스의, 스웨덴, 오리진, 최대한, 비기닝, 만큼, 강화, 정말로, 차라리, 연애의 온도, 꽤, 배, 테이큰2, 의외로 </p> <br> ### 다시 <p class="message"> 또다시, 또, 다시금, 번, 새로이, 조만간, 새로, 다시, 돌이키, 매년, 나중, 꼭, 세번, 자꾸자꾸, 두고두고, 언젠가, 우연히, 한번, 새삼, 재평가, 보고 또 보고, 새삼스레, 보고 싶다, 매번, 찾아보, 다음날, 또, 곱씹, 되새기, 문뜩, 보, 새롭, 되짚, 불멸의 이순신, 뒤늦, 찬찬히, 되돌, 카사블랑카, 재, 주행, 문득문득, 문득, 뒤돌, 돌아보, 1월 1일, 꺼내, 계속, 곧바로, 보고싶다, 째, 원점, 다신, 검색, 곰곰히, 날자, 어쩌다, 두세, 반드시, 이따금, 자마자, 이제서야, 심호흡, 예전, 되새김질, 복습, 불현듯, 쯤, 보, 최진실, 진가, 이어서, 얼른, 최근, 드뎌, 일전, 아차, 오랜만, 그제서야, 곰곰이, 만나, 이제야, 재방송, 제대, 어김없이, 살아생전, 그제야, 기념, 뒤돌아보, 지렸다, 당장, 십수, 기회, 지금, 달라스 바이어스 클럽, 감회, 확인, 몇, 장진영, 유심히, 진면목 </p> <br> ### 안 <p class="message"> 못, 도안, 안보, 안, 않, 안남, 많이, 안감, 아무래도, 모르, 자주, 안됬다, 솔직히, 안나, 귀신, 도저히, 헷갈려서, 빡쳐서, 모르겟지만, 요새, 도무지, 언제, 안받, 못, 음슴, 못쓰, 쏙, 웃겨서, 이안, 마누라, 금방, 얘, 맨날, 괜히, 여자라서, 됬는데, 이쪽, ㄴ다고, 얼추, 더라구요, 싫어하, 계속, 더더, 신경안, 잘못, 외국, 랑, 원체, 별로, 이제, 던데요, 자꾸자꾸, 도통, 흑발, 어지간, 자꾸, 주원이, 그쪽, 노래방, 진작, 않, 이제야, 엄청, 재밋었음, 덜, 확실히, 분명히, 이상, 영, 먼저, 저절로, 절로, 좋겟다, 나오, 좀처럼, 웬만, 좋아하, 거르, 상관없, 아마, 나, ㄴ다는데, 안가, 첨, 똑똑히, 일단, 는구먼, 유재석, 보고, 제발, 크루엘라, 무전기, 장근석, 이랑, ㄹ걸, 장화홍련, 나중, 암만, 보통, 더라고 </p> <br> ### 잘 <p class="message"> 자알, 훌륭히, 제대로, 적절히, 충실히, 대충, 완벽히, 재밋게, 맛깔, 멋지, 열심히, 얼추, 적확, 기가, 정확히, 뚜렷이, 그럴듯하, 잘, 명확히, 잘못, 정확, 찰떡, 재미나, 재밋당, 탁월, 구성지, 현대극, 그럴싸, 절묘, 꼼꼼히, 찰지, 기똥차, 준수, 영리, 실감, 뛰어나, 야무지, 적절, 알맞, 영국 영화, 정성껏, 특화, 유명, 훌륭, 확실히, 세밀, 골고루, 로버트 다우니, 자세히, 깔끔히, 능숙, 말끔, 좋, 쌔끈한, 완벽, 틈틈히, 매끈, 최적, 정밀, 못, 지게, 섬세, 리얼, 충실, 훌룡한, 오밀조밀, 어렵, 근사, 맛나, 많이, 날줄, 재미있, 반듯, 괜찮, 쩔었음, 쉽, 탄탄히, 생생히, 기막히, 는지, 선명히, 대강, 성실히, 캐치, 웃김ㅋㅋㅋ, 재밌, 려고, 괜츈, 소홀, 두루두루, 코믹, 맛있, 촘촘히, 세세, 빼어나, 오래, 세부, 띄엄띄엄, 꼼꼼, 톡톡히 </p> <br> ### 가장 <p class="message"> 제일, 젤, 재일, 유일, 굉장히, 이토록, 단연코, 역사상, 더없이, 매우, 유독, 정말로, 단연, 중, 무척, 참으로, 상당히, 정말, 너무나, 젤로, 대단히, 얼마나, 이만큼, 유난히, 참, 리만치, 더욱, 광장히, 그토록, 해리 포터 시리즈, 제법, 손꼽히, 훨씬, 더, 꽤, 진정, 아주, 단언, 의외로, 분명, 다섯손가락, 유일무이, 지극히, 만큼, 엄청, 너무, 특별히, 더더욱, 여지껏, 그만큼, 워낙, 만큼, 그다지, 사상, 분명히, 무지, 지금껏, 극장판 애니메이션, 가장, 근래, 훨신, 못지않, 여태껏, 디스토피아 영화, 으뜸, 더욱더, 전무후무, 몹시, 대체로, 생애, 항상, 은근히, 올해, 영화ㅡ, 이젤, 모처럼, 드물, 여러모로, 통틀, 건대, 첫, 애니메이션 영화, 그나마, 예시, 너무너무, 자스민, 애니메이션영화, 그중, 어찌나, TOP, 최초, 극히, 여전히, 본보기, 사례, 그리, 여태, 언제나, 최대한, 저토록 </p> <br> ### 함께 <p class="message"> 같이, 나란히, 더불, 김영, 상민, 부모님, 동시대, 하님, 동행, 다함께, 손잡, 쌍벽, 외할머니, 하나가 되어, 산책, 함성, 동반자, 양대, 산맥, 일출, 마중, 매미, 지우, 포세이돈, 동반, 어서, 자메이카, 밤새, 동시, 친구, 영화의 전당, 오래오래, 공유, 연인, 조우, 대면, 배웅, 저승, 한잔, 협업, 마주, 설리반, 번갈, 소꿉친구, 유대감, 제자, 교차점, 강릉, 씨름, 염원, 제사, 사이좋, 공명, 그리워하, 계곡, 재회, 한가, 결별, 여생, 합주, 며, 맞대, 셀린, 만남, 맞바꾸, 면회, 사색, 강호, 하루빨리, 겹쳐지, 필히, 우쿨렐레, 키팅, 환희, Extreme, 현, 쇼파, 교류, 자연스레, 소망, 이수, 관계없이, 사별, 나문희, 달리, 벤치, 교감, 류이치 사카모토, 첼로, 소파, 아울러, 마음껏, 공존, 헤어지, 몰래, 만나, 비견, 어머니, 졸업식, 협동 </p> <br> ### 바로 <p class="message"> 이야말로, 정녕, 곧, 진정, 만약, 야말로, 아마도, 과연, 전부, 하필, 혹시, 아마, 진정, 우리학교, 드디어, 만일, 그러니까, 애당초, 빌어먹, 마치, 정말로, 왜, 어쩌다, 하필이면, 고작, 이시여, 꼭, 뭐람, 진짜, 영화의 장르, 영화 장르, 고사, 백미, 비로소, 아니, 어째서, 당장, 최초, 자마자, 문득, 모든, 웬, 사토라레, 우연히, 끝장, 매드 맥스, 어느날 갑자기, 보구, 폴리스, 지금, 원래, 뭥미, 묘미, 아니, 이른바, 설마, 정답, 반대편, 정점, 반드시, ㄴ가요, 뙇, 분명, 미팅, 연애의 목적, 틀림없이, 먼저, 유일, 어쩌다가, 맙소사, 씨팔, 시초, 올여름, 신세계, 그제서야, 햐, 비단, 먼저, gt, 경미, 마침, lt, 시발점, 수혜자, 명백히, 정령, 어떤, 방점, 올ㅋ, 마침내, 하이스쿨 뮤지컬, 불현듯, 오마, 직접, ㅂ니까, 그때 그 사람들, 위풍당당 행진곡, 어떻, 보고, 첫날 </p> <br> ### 모두 <p class="message"> 전부, 모두, 다, 모조리, 모든, 두루두루, 또한, 골고루, 빠짐없이, 마저, 마저, 몽땅, 고루, 완전히, 데칼코마니, 삼박자, 두루, 각각, 완벽히, 대부분, 심지어, 배경 음악, 하나하나, 각자, 및, 각각, 나머지, 죄다, 이미, 온전히, 등등, 물론, 오롯이, 미장셴, 시각적, 아우르, 허나, 각자, 저마다, 그리고, 당연히, 철저히, 삼위일체, 물론, 결국, 등, 대다수, 포함, 미술, 케릭터, 비록, 개별, 기타 등등, 각기, 하모니, 양쪽, 둘, 아울러, 조화, 남녀노소, 셋, 특히, 개개인, 남김없이, 분배, 그럼에도 불구하고, 일부, 앙상블, 대체로, 각, 제각기, 으려다, 케릭터와, 들, 의, 기타등등, 거의, 은데다, 미장셴과, 훌륭히, 내러티브와, 몇몇, 까지, 완전, 하나하나, 오로지, 어차피, 아트웍, 면면, 그러나, 너무나, 그야말로, 다만, 음악, 도, 언제나, 우선, 소품, 충분히, 박자 </p> <br> ### 없이 <p class="message"> 아무, 아무런, 가벼이, 겨를, 없, 별다르, 별생각, 한치의, 정신없이, 망설임, 으면서, ㄹ새, 막힘없이, 무심코, 간단히, 꾸밈없이, 면서, 그럭, 인정사정, 마저, 무념, 덤덤히, 음슴, 편안히, 일절, 살상, 말없이, 며, 꾸밈, 거리낌, 몰아치, 일말, 으로, 한순간, 금포로, 무심히, 쓸데없, 그냥, 가볍, 조용히, 빠짐없이, 살육, 군더더기, 조차, 얼떨결, 불명확, 거침없이, 틈, 비우, 내려놓, 싹, 같이, 실없이, 끔, 두서없이, 마냥, 마다, 다라고, 그러면서, 다가, 무지막지, 때우, 마저, 조차, 마다, 무난히, 안, 집어치우, 낄낄대, 빼, 가끔, 자고, 멍하니, 섹드립, 때때로, 파도처럼, 같이, 미동, 여름철, 찬찬히, 직진, 멋모르, 시종일관, 기교, 론, 상세, 잇달, 자잘, 안, 사전, 는데서, 러브신, 뭣하, 팝콘, 꺼리, 무진장, 시원시원, 따라, 으며, 무 </p> <br> ### 다 <p class="message"> 전부, 모두, 죄다, 모조리, 몽땅, 두루두루, 싹, 골고루, 모든, 하나하나, 빠짐없이, 거진, 으려다, 한꺼번에, 족족, 거의, 별별, 해먹, 나머지, 으려다가, 일단, 뭐, 당연히, 진짜, 크래딧, 기껏, 대부분, 엔딩크래딧이, 이서, 모두, 어차피, 막상, 빼, 산전수전, 잖아요, 나, 정작, 어영부영, 거의, 배경 음악, 따로, 이것저것, 고루, 셋, 트리니티, 다, 등등, 여럿, 좆, 말끔히, 쏙, 다시피, 통째, 집어치우, 기타 등등, 남김없이, 완전, ㅠㅡㅠ, 쓸어버리, 때려, 모으, 려다, 비슷비슷, 주걸륜, 순서대로, 그제서야, 제끼, 삼박자, 합치, 꾸역꾸역, 진작에, 이수혁, 합하, 꼭, 왤케, 완전히, 걍, 까놓, 성우진, 먹, 가지, 방금, 섭렵, 겨우, 히가시노, 볶, 이랑, 이미, 윤종신, 갈아엎, 원래, 너무너무, 케릭터, 반제, 차치, 름, 어이쿠, 나소, 자마자, 참 </p> <br> ### 참 <p class="message"> 참으로, 정말, 굉장히, 너무, 매우, 넘, 무척, 너무나, 너무너무, 어찌나, 아주, 상당히, 정말로, 몹시, 대단히, 제일, 엄청, 겁나, 얼마나, 넘넘, 원체, 의외로, 더없이, 워낙, 제법, 무진장, 왤케, 광장히, 꽤, 증말, 이참, 진짜, 젤, 이토록, 이리, 분명, 이렇, 가장, 대체로, 그리도, 어쩜, 정말, 은근, 썩, 그리, 은근히, 어쩐지, 참, 너므, 그만큼, 여러모로, 유독, 드럽, 실로, 진짜진짜, 이만큼, 아따, 어쨋든, 특히, 이다지, 물론, 여전히, 조르, 어지간히, 므, 어쨌든, 이세영, 나름, 하시모토 아이, 더더욱, 한결같이, 마냥, 원래, 훨씬, 복래, 리만치, 아무튼, 그나저나, 아무리, 왠지, 영, 그다지, 더욱이, 게다가, 저토록, 류덕환, 근데, 케릭터와, 변함없이, 역시, 항상, 이런, 하여간, bbbb, 무지무지, 재일, 꾀, ㄴ데다가, 훨, 하도 </p> <br> *감탄사* ### 그래 <p class="message"> 아이구, 그러, 뭐, 어, 으음, ㅈㅅ, 엄, 래, 솔, ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ, 모, 시발, 슈바, 창수, Aㅏ, 브라더, ㅠㅠㅠㅠㅠㅠㅠㅠ, 웁, 우, 어어, 무쌍, 2728, 야, 아, 머, 음, 슈, 우, 오, 썅, 미녀삼총사, 엉, 럽, 응, 트랜스, 아, 아무렴, 아앙, 뤼, 밍숭맹숭, 워, 퍽, 갓, 내사랑, 판, 아따, 오오, 힝, 리, 이, 유, 오, 니까, 호오, 시렁, 야, 페어, 지, 휘, 티어, ㅆ, 잉, 세르, 아아, 아니, ㅁㅊ, 임마, 캐, 좋아, ㄹ랑, ㅂㅅ, 흠흠, 매, 씨발, 아이고, 라더라, 사납, 채닝테이텀, 우스, 내셔널, 디아, 인제, S2, 훔, 쾅, X, 지못미, 61, 갓, 잉, 시빌워는, 구, 후우, 어머나, ㅍ, 구, 든데, 윌리스, 재밋긴한데, 쨌든 </p> <br> ### 아 <p class="message"> 오, 아아, 으아, 시발, ㅅㅂ, 어휴, 캬, 악, 씨발, 아으, 어, 젠장, 진짜, ㅅ, 야, 하하하하, 아앙, 아휴, ㅋㅋㅋㅋㅋ, ㅠㅠ, 빡쳐, ㅏ, ㅜㅜ, 모, 응, 으악, ㅋㅋㅋㅋ, 어머, ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ, 와아, 엉, 휴, ㅠㅠㅠㅠㅠㅠㅠㅠ, ㅠㅠㅠ, 흐, 으, ㅆ, 윽, ㅋㅋㅋㅋㅋㅋㅋㅋㅋ, 시바, 음, 근데, ㅋㅋㅋㅋㅋㅋㅋ, 하하, 잉, 썅, 아이고, ㅋㅋㅋ, 워후, ㅠㅠㅠㅠㅠㅠㅠ, 증말, ㅆㅂ, ㅋㅋㅋㅋㅋㅋ, 이게뭐람, ㅠㅜ, 허허, ㅠㅠㅠㅠ, 오, ㅠ, 아, 우, ㅜ, 좋아, 하, 하하하하, ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ, 하하하, 와우, 어이쿠, 우, ㅡㅡ, 아이구, 오오, ㅜㅜㅜ, ㅋㅋㅋㅋㅋㅋㅋㅋ, 흐엉, 그나저나, ㅠㅠㅠㅠㅠ, 아하, 꺅, 사랑해요, ㅡ, ㅂ, ㅠㅠㅠㅠㅠㅠ, 으앙, 짜식, ㅁ, ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ, 어어, ㅜㅠ, 앗, 임마, 크으, 으음, 헤헤, ㅠㅠㅠㅠㅠㅠㅠㅠㅠ, 무서웡, ㅋㅋ, 조, ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ </p> <br> ### 뭐 <p class="message"> 잉, 뭐람, 이게뭐람, 모야, 그래, 으음, Aㅏ, 쉣, ㅆ, 햐, 재밌, 어, 이, 올ㅋ, 시발, ㅁㅊ, 어어, 흐, ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ, 재밋지, 어머나, 씨발, 엉, 오, SO, 쟤, 짜식, 재밋엇는데, 도대체, 왜, Wow, 응, 재밋긴한데, ㅉㅉ, ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ, S2, 모, ㅅㅂ, 빡쳐, 야, 좋아, 흐음, ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ, 별별, 시렁, 이건, 후훗, 아따, 2728, 어머, 웬일, 씨팔, 어이쿠, 요것, ㅆㅂ, 썅, 귀여워, 아, 악, oh, 바이바이, 하하하하, 하하, 얘, 뭐, 더럽, 아이구, ㄱ, 나소, 으응, 아까, 모르겟음, 아휴, ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ, ㅍ, 323, 오 마이 갓, ㅇㅇㅇ, 오마이갓, 원투, 이누야샤, 흐엉, 에이, 웃김ㅋㅋㅋ, 후우, ㅋㅋㅋㅋㅋㅋ, 기즈모, 당초, 재밋어, 도데, ㅋㅋㅋㅋ, 라든, 잼슴, ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ, ㅈㅅ, 대체, 데헷, 우, 아앙, 다 </p> <br> ### 글쎄 <p class="message"> 글쎄요, 글쎄다, 음, 글쌔, 솔직히, 분명, 보통, 아무래도, soso, 흐음, ㅂㄹ, 어쨌든, 적어도, 그다지, 별로, 모르겟지만, 그래도, 그렇지만, 물론, 그럭저럭, 일단, 대체로, 딱히, 그냥저냥, 뭐, 별루, 당연히, ㅍㅌㅊ, 이영화, 빵점, 재밋었는데, 어쨋든, 그럭, 으음, 그냥, 분명히, 역시, so, 괜츈, 합격, 괜찮, 밍밍하다, 순전히, 확실히, 로서, 역시, ㄱㅊ, 그저, 재밋긴한데, 그런데, 나쁘지 않아, 어쨌거나, 무교, 재밋었음, 그런대로, 로써, 나름, 와우, 영, 요새, 졸렸다, 재밋는데, 항상, 근데, 재밋었다, 우선, 이외, 말하자면, 후자, 쩝, 논외, 아니, 학, 문제없, 흠, 시망, 어떻든, 카우보이 비밥, 평균, 하지만, 상당히, 외, 다만, 개인의 취향, 웃겼지만, 던데, 아무튼, 오글거렸다, 연기면, 노노, 이것, 보통, 명불허전, 비하, 하긴, 이, 아마, 둘째, 후지다, 자체 </p> <br>
KC␞ 이번 글에서는 **K-평균 군집화(K-means Clustering)**에 대해 살펴보겠습니다. (줄여서 KC라 부르겠습니다) 이번 글은 고려대 강필성 교수님과 역시 같은 대학의 김성범 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 알고리즘 개요 KC는 대표적인 [분리형 군집화 알고리즘](https://ratsgo.github.io/machine%20learning/2017/04/16/clustering/) 가운데 하나입니다. 각 군집은 하나의 **중심(centroid)**을 가집니다. 각 개체는 가장 가까운 중심에 할당되며, 같은 중심에 할당된 개체들이 모여 하나의 군집을 형성합니다. 사용자가 사전에 군집 수($k$)가 정해야 알고리즘을 실행할 수 있습니다. $k$가 **하이퍼파라메터(hyperparameter)**라는 이야기입니다. 이를 수식으로 적으면 아래와 같습니다. $$X={ C }_{ 1 }{ \cup C }_{ 2 }{ ...\cup C }_{ K },\quad { C }_{ i }\cap { C }_{ j }=\phi \\ \\ argmin_{ C }{ \sum _{ i=1 }^{ K }{ \sum _{ { x }_{ j }\in { C }_{ i } }^{ }{ { \left\| { x }_{ j }-{ c }_{ i } \right\| }^{ 2 } } } }$$  ## 학습 과정 KC는 **EM 알고리즘**을 기반으로 작동합니다. EM알고리즘은 크게 **Expectation** 스텝과 **Maximization** 스텝으로 나뉘는데요. 이를 수렴할 때까지 반복하는 방식입니다. 동시에 해를 찾기 어려운 문제를 풀 때 많이 사용되는 방법론입니다. KC의 경우 (1) 각 군집 중심의 위치 (2)각 개체가 어떤 군집에 속해야 하는지 멤버십, 이 두 가지를 동시에 찾아야 하기 때문에 EM 알고리즘을 적용합니다. 군집 수 $k$를 2로 정했습니다. 우선 군집의 중심(빨간색 점)을 랜덤 초기화합니다. <a href="http://imgur.com/hgNzXsc"><img src="http://i.imgur.com/hgNzXsc.png" width="500px" title="source: imgur.com" /></a> 모든 개체들(파란색 점)을 아래 그림처럼 가장 가까운 중심에 군집(녹색 박스)으로 할당합니다. 이것이 Expectation 스텝입니다. <a href="http://imgur.com/OFn22dM"><img src="http://i.imgur.com/OFn22dM.png" width="500px" title="source: imgur.com" /></a> 이번엔 중심을 군집 경계에 맞게 업데이트해 줍니다. 이것이 Maximization 스텝입니다. <a href="http://imgur.com/UmBgHhf"><img src="http://i.imgur.com/UmBgHhf.png" width="500px" title="source: imgur.com" /></a> 다시 Expectation 스텝을 적용합니다. 바꿔 말해 모든 개체들을 가장 가까운 중심에 군집(보라색 박스)으로 할당해주는 작업입니다. <a href="http://imgur.com/DWmbUxP"><img src="http://i.imgur.com/DWmbUxP.png" width="500px" title="source: imgur.com" /></a> Maximization 스텝을 또 적용해 중심을 업데이트합니다. Expectation과 Maximization 스텝을 반복 적용해도 결과가 바뀌지 않거나(=해가 수렴), 사용자가 정한 반복수를 채우게 되면 학습이 끝납니다. <a href="http://imgur.com/OBhtsbV"><img src="http://i.imgur.com/OBhtsbV.png" width="500px" title="source: imgur.com" /></a>  ## KC의 특징과 단점 KC는 각 군집 중심의 초기값을 랜덤하게 정하는 알고리즘인데요. 아래 그림처럼 초기값 위치에 따라 원하는 결과가 나오지 않을 수도 있습니다. <a href="http://imgur.com/jNTOXNQ"><img src="http://i.imgur.com/jNTOXNQ.png" width="600px" title="source: imgur.com" /></a> 군집의 크기가 다를 경우 제대로 작동하지 않을 수 있습니다. <a href="http://imgur.com/IH8FAfq"><img src="http://i.imgur.com/IH8FAfq.png" width="500px" title="source: imgur.com" /></a> 군집의 밀도가 다를 경우에도 마찬가지입니다. <a href="http://imgur.com/pJmhpQ6"><img src="http://i.imgur.com/pJmhpQ6.png" width="500px" title="source: imgur.com" /></a> 데이터 분포가 특이한 케이스도 군집이 잘 이루어지지 않습니다. <a href="http://imgur.com/v37p0Gi"><img src="http://i.imgur.com/v37p0Gi.png" width="500px" title="source: imgur.com" /></a> 이 때문에 KC를 실제 문제에 적용할 때는 여러번 군집화를 수행해 가장 빈번히 등장하는 군집에 할당하는 **majority voting** 방법을 쓰는 경우가 많다고 합니다. KC의 계산복잡성은 $O(n)$으로 [계층적 군집화(Hiarchical clustering)](https://ratsgo.github.io/machine%20learning/2017/04/18/HC/)와 비교해 그리 무겁지 않은 알고리즘이기 때문입니다.
AR␞ 이번 글에서는 *Auto Regressive Model*(AR)에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept 자기 자신을 입력으로 하여 자기 자신을 예측하는 모형을 *Auto Regressive Model*(AR)이라고 합니다. 그 개념도와 likelihood 식은 다음과 같습니다.  <a href="https://imgur.com/tcApyOc"><img src="https://i.imgur.com/tcApyOc.png" width="300px" title="source: imgur.com" /></a>  $$ \begin{align*} p\left( x \right) =&\coprod _{ i }^{ }{ p\left( { { x }_{ i } }|{ { x }_{ 1 },...,{ x }_{ i-1 } } \right) } \\ =&p\left( { x }_{ 1 } \right) p\left( { x }_{ 2 }|{ x }_{ 1 } \right) ...p\left( { { x }_{ i } }|{ { x }_{ 1 },...,{ x }_{ i-1 } } \right) \end{align*} $$  저해상도 이미지/영상을 고해상도로 변환하는 작업을 *Super Resolution*(SR)이라고 합니다. SR을 AR modeling 관점에서 이해할 수 있습니다. 아래 그림처럼 고해상도 이미지/영상을 픽셀 단위로 예측하는 경우, $x_i$를 예측할 때는 이전의 모든 픽셀 예측 결과를 활용하게 됩니다.  <a href="https://imgur.com/8tbMCVx"><img src="https://i.imgur.com/8tbMCVx.png" width="200px" title="source: imgur.com" /></a>  앞으로 설명해드릴 PixelRNN과 PixelCNN은 SR을 AR modeling으로 해결해 보려는 시도들입니다.   ## PixelRNN *Recurrent Neural Network*(RNN)는 시퀀스 데이터 처리에 특화된 아키텍처이므로 SR을 AR modeling으로 풀 때 적용해 봄직한 시도입니다. 아래 그림의 빨간색 픽셀을 예측할 때 이전의 모든 시퀀스 정보를 RNN 아키텍처에 넣어서 예측이 가능합니다.  <a href="https://imgur.com/S1vAlSR"><img src="https://i.imgur.com/S1vAlSR.png" width="300px" title="source: imgur.com" /></a>  ## PixelCNN *Convolutional Neural Network*(CNN)는 본래 시퀀스 데이터 처리와는 직접 관련이 없으나 아래 그림처럼 *Masked Convolution Filter*를 사용하면 AR modeling이 가능합니다. 예측해야 하는 시점의 픽셀(아래 행렬의 정중앙 픽셀)과 아직 예측하지 않은 시점의 픽셀에 해당하는 필터 값을 0으로 설정해 두고, 이를 일반적인 *conv layer*에 적용하면 CNN을 가지고 AR modeling을 할 수 있습니다.  <a href="https://imgur.com/HVdp5tc"><img src="https://i.imgur.com/HVdp5tc.png" width="400px" title="source: imgur.com" /></a>   ## WaveNet *WaveNet*은 음성 생성에 *Masked Convolution Filter*를 활용한 사례입니다. *conv filter*를 아래처럼 설정해 두면 현 시점 예측 때 과거 다양한 시점의 데이터를 사용하게 됩니다.  <a href="https://imgur.com/289PXST"><img src="https://i.imgur.com/289PXST.png" width="450px" title="source: imgur.com" /></a>  
selectionsort␞ 이번 글에서는 **선택정렬(selection sort)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의와 위키피디아를 정리하였음을 먼저 밝힙니다. 파이썬 코드는 [이곳](http://interactivepython.org/courselib/static/pythonds/SortSearch/TheSelectionSort.html)을 참고하였습니다. 그럼 시작하겠습니다.   ## concepts 선택정렬은 위치 변경 횟수를 줄여, [버블정렬](https://ratsgo.github.io/data%20structure&algorithm/2017/11/05/bubblesort/)을 일부 개선한 기법입니다. 선택정렬의 작동 원리는 다음과 같습니다.  <a href="https://imgur.com/3Goa2af"><img src="https://i.imgur.com/3Goa2af.png" width="600px" title="source: imgur.com" /></a>  버블정렬은 왼쪽에 있는 값이 비교 대상인 오른쪽에 있는 값보다 크면 자리를 바꿔줬는데 반해, 선택정렬은 일단 최대값(혹은 최소값)을 찾은 뒤에야 이 값을 정해진 위치로 보내주게 됩니다. 다시 말해 비교 횟수 측면에서는 버블정렬과 선택정렬이 같고 둘 모두 $O(n^2)$의 계산복잡성을 갖지만 자리이동(*swap*) 측면에서는 선택정렬이 효율적입니다. 위 그림 예시의 경우 9번의 *iteration*에서 9번의 자리이동(*iteration*당 1번의 *swap*)이 있었습니다.   ## 파이썬 구현 선택정렬의 파이썬 코드는 다음과 같습니다. ```python def selectionSort(alist):  for fillslot in range(len(alist)-1,0,-1):    positionOfMax=0    for location in range(1,fillslot+1):      if alist[location]>alist[positionOfMax]:        positionOfMax = location     temp = alist[fillslot]    alist[fillslot] = alist[positionOfMax]    alist[positionOfMax] = temp ``` 
duality␞ 이번 글에서는 **Duality**와 관련된 개념들을 살펴보도록 하겠습니다. 이 글은 미국 카네기멜런대학 [강의](http://www.stat.cmu.edu/~ryantibs/convexopt/)를 기본으로 하되 영문 위키피디아 또한 참고하였습니다. 그럼 시작하겠습니다.   ## concept 최적화 이론에서 **쌍대성**(雙對性; duality)이란 어떤 최적화 문제가 **원초문제(the primal problem)**와 **쌍대문제(the dual problem)**의 두 가지 관점에서 볼 수 있다는 원칙입니다. 쌍대문제의 상한은 *primal problem*의 하한(a lower bound)이 됩니다. 선형계획법(linear programming)를 예로 들어보겠습니다. 다음과 같이 주어진 선형 조건을 만족시키면서 선형인 목적함수 $c^Tx$를 최소화하는 문제입니다. ($c$는 $n$차원. $b$는 $m$차원, $h$는 $r$차원 벡터, $A$는 $m×n$, $G$는 $r×n$ 행렬)  $$ \begin{align*} &\min_{ x }&&{ { c }^{ T }x } \\ &subject\quad to\quad &&Ax=b\\ &&&Gx\le h \end{align*} $$  위 식은 행렬-벡터 형식인데요. 이를 스칼라 형태의 식으로 살펴보면 등식 형태의 제약식이 $m$개, 부등식 형태의 제약식이 $r$개가 있고, 이를 만족하면서 목적함수를 최대화시키는 $n$개의 미지수를 찾는 문제라고도 이해할 수 있습니다. 제약식 양변에 $u$, $v$라는 벡터를 곱해 봅시다. 여기에서 $v≥0$, 즉 벡터 $v$의 모든 요소는 0 이상의 값을 지닙니다. 따라서 위 식에서 부등식 형태의 제약식은 부등호 방향이 바뀌지 않습니다.  $$ { u }^{ T }Ax={ u }^{ T }b\\ { v }^{ T }Gx\le { v }^{ T }h $$  위 두 개 식을 더하고, 정리해 주면 다음과 같은 형태가 됩니다.   $$ \begin{align*} { u }^{ T }Ax+{ v }^{ T }Gx&\le { u }^{ T }b+{ v }^{ T }h\\ \left( { u }^{ T }A+{ v }^{ T }G \right) x&\le { u }^{ T }b+{ v }^{ T }h\\ { \left( { A }^{ T }u+{ G }^{ T }v \right) }^{ T }x&\le { u }^{ T }b+{ v }^{ T }h\\ { \left( -{ A }^{ T }u-{ G }^{ T }v \right) }^{ T }x&\ge -{ u }^{ T }b-{ v }^{ T }h\\ \therefore \quad { c }^{ T }x&\ge -{ u }^{ T }b-{ v }^{ T }h \end{align*} $$  위 식에서 볼 수 있듯 $-A^Tu-G^Tv$가 $c$가 되도록 하면, *primal problem*의 목적함수 $c^Tx$의 하한(a lower bound)은 $-u^Tb-v^Th$가 됩니다. 따라서 $-A^Tu-G^Tv=c$, $v≥0$이라는 제약식을 만족시키면서, $-u^Tb-v^Th$를 최대화하는 문제가 *primal problem*과 동일해질 겁니다. 결론적으로 말해 아래와 같은 형태가 *primal problem*와 쌍을 이루는 *dual problem*이 됩니다. *primal problem*에서는 주어진 식을 만족하는 벡터 $x$를 찾는 것이었으나 *dual problem*에서는 벡터 $u, v$를 찾는 문제가 됩니다.  $$ \begin{align*} &\max_{ u,v }&&{ -{ b }^{ T }{ u }-{ h }^{ T }{ v } } \\ &subject\quad to\quad && -{ A }^{ T }{ u }-{ G }^{ T }{ v } = c\\ &&&v\ge 0 \end{align*} $$    ## 라그랑지안적 접근 *primal problem*과 *dual problem*을 **라그랑주 승수법**(Lagrange multiplier method)과 연관지어 살펴볼 수도 있습니다. 라그랑주 승수법이란 최적화하려는 값에 형식적인 라그랑주 승수(multiplier) 항을 더하여, 제약된 문제를 제약이 없는 문제로 바꾸는 방법입니다. 라그랑주 승수법 관련 자세한 내용은 [이곳](https://m.blog.naver.com/mindo1103/90154212128)이나 [이곳](http://untitledtblog.tistory.com/96)을 참고하시면 좋을 것 같습니다. 전 챕터에 이어 선형계획법 예시를 가지고 *primal*과 *dual* 문제를 살펴보겠습니다. *primal problem*을 다시 살펴보겠습니다.  $$ \begin{align*} &\min_{ x }&&{ { c }^{ T }x } \\ &subject\quad to\quad &&Ax=b\\ &&&Gx\le h \end{align*} $$  위 *primal problem*을 라그랑주 승수 벡터 $u$와 $v$를 도입해 라그랑주 함수 $L$을 만들면 다음과 같은 형태가 됩니다. 단 여기에서 $v≥0$, 즉 벡터 $v$의 모든 요소는 0 이상의 값을 지닙니다.  $$ L\left( x,u,v \right) ={ c }^{ T }x+{ u }^{ T }\left( Ax-b \right) +{ v }^{ T }\left( Gx-h \right)\le{c}^{T}x $$  그런데 위 식 우변의 두번째 항은 항상 0입니다($∵Ax=b$). 세번째 항은 항상 0 이하의 값을 갖습니다($∵Gx≤h, v≥0$) 따라서 $L$은 목적함수 $c^Tx$보다 항상 작거나 같습니다. 여기에서 $C$를 원초문제의 제약식을 만족하는 $x$의 집합, $f^*$를 우리가 찾으려는 최적값이라고 할 때 다음 식이 성립합니다.  $$ { f }^{ * }\ge \min _{ x\in C }{ L\left( x,u,v \right) } \ge \min _{ x }{ L\left( x,u,v \right) } $$  위 부등식의 의미는 이렇습니다. 제약조건이 있는 것보다는, 없는 환경에서 해당 식의 값을 더 작게 만들 수 있을 겁니다. 위 부등식 가운데 오른쪽 마지막 항을 $g(u,v)$라 두겠습니다. $g(u,v)$를 **라그랑지 듀얼 함수**(Lagrange dual function)이라고도 부릅니다. 그러면 $g(u,v)$는 어떤 값을 지닐까요? 차근차근 구해보겠습니다.  우선 $g(u,v)$는 그 정의상 $L$의 최소값 즉, $min_x{L(x,u,v)}$입니다. $L$은 우리가 알고 싶은 미지수로 편미분한 결과가 0이 되는 지점에서 최소값을 갖습니다. $L$을 $x$로 편미분한 결과는 다음과 같습니다.  $$ \frac { \partial L }{ \partial x } ={ c }^{ T }+{ u }^{ T }A+v^{ T }G=0\\ \therefore \quad c=-{ A }^{ T }u-{ G }^{ T }v $$  따라서 위 식을 $L$에 대입해 풀면 $g(u,v)$를 구할 수 있습니다.  $$ \begin{align*} L\left( x,u,v \right)&= { c }^{ T }x+{ u }^{ T }\left( Ax-b \right) +{ v }^{ T }\left( Gx-h \right)\\&\Rightarrow { \left( -{ A }^{ T }u-{ G }^{ T }v \right) }^{ T }x+{ u }^{ T }\left( Ax-b \right) +{ v }^{ T }\left( Gx-h \right) \\ &=-u^{ T }Ax-v^{ T }Gx+u^{ T }Ax-u^{ T }b+v^{ T }Gx-{ v }^{ T }h\\ &=-u^{ T }b-{ v }^{ T }h\\&=g(u,v) \end{align*} $$  우리는 이미 $f^*≥g(u,v)$라는 관계를 확인했으므로, primal problem의 최소값을 찾는 것은 $g(u,v)$를 최대화하는 문제와 동일하다는 걸 확인할 수 있습니다. 단 라그랑주 승수법을 적용하는 과정에서 가정한 두 가지 조건, 즉 $-A^Tu-G^Tv=c$, $v≥0$을 만족해야 합니다.  따라서 우리는 다음과 같이 *dual problem*으로 다시 쓸 수 있습니다. 이는 당초 *primal problem*과 쌍을 이룹니다.  $$ \begin{align*} &\max_{ u,v }&&{ -{ b }^{ T }{ u }-{ h }^{ T }{ v } } \\ &subject\quad to\quad && -{ A }^{ T }{ u }-{ G }^{ T }{ v } = c\\ &&&v\ge 0 \end{align*} $$  라그랑지안적 접근의 장점은 지금까지 설명해드렸던 선형계획법 이외에도 임의의 최적화 문제에 대해 모두 적용할 수가 있다는 점입니다. 다시 말해 라그랑주 승수법을 적용해 다양한 유형의 *primal problem*를 *dual problem*으로 바꿔풀 수가 있습니다. 이제 최적화 문제를 일반적인 케이스에 적용해 봅시다. 다음과 같은 *primal problem*이 주어졌다고 칩시다.  $$ \begin{align*} &\min _{ x }&&{ f\left( x \right) } \\ &subject\quad to\quad &&{ h }_{ i }\left( x \right) \le 0,\quad i=1,...,m\\ &&&{ l }_{ j }\left( x \right) =0,\quad j=1,...,r \end{align*} $$  라그랑지안 함수 $L$과 라그랑지 듀얼함수 $g$를 각각 정의합니다. 이미 살펴봤듯이 부등식 형태의 제약식에 붙는 라그랑주 승수(multiplier) $u_i$는 모두 0 이상의 값을 지녀야 합니다.  $$ \begin{align*} L\left( x,u,v \right) =&f\left( x \right) +\sum _{ i=1 }^{ m }{ { u_{ i }h }_{ i }\left( x \right) } +\sum _{ j=1 }^{ r }{ { v_{ i }l }_{ j }\left( x \right) } \\ g\left( u,v \right) =&\min _{ x }{ L\left( x,u,v \right) } \end{align*} $$  $f^*≥g(u,v)$이므로 dual problem은 다음과 같이 쓸 수 있습니다. primal problem에서는 주어진 식을 만족하는 벡터 $x$를 찾는 것이었으나 dual problem에서는 벡터 $u, v$를 찾는 문제가 됩니다. 아울러 최소 문제가 최대 문제로 바뀌었습니다.  $$ \begin{align*} &\max_{ u,v }&&{ { g }(u,v) } \\ &subject\quad to\quad &&u\ge 0 \end{align*} $$  한편 *dual problem*은 항상 *convex* 문제가 됩니다. $g(u,v)$를 아래와 같이 자세히 뜯어보면 *convexity*를 보존하는 연산만 수행이 되기 때문입니다. *convexity*를 보존하는 연산에 대해서는 [이곳](https://ratsgo.github.io/convex%20optimization/2017/12/26/convexfunction/)을 참고하면 좋을 것 같습니다.  <a href="https://imgur.com/3Wi5yWE"><img src="https://i.imgur.com/3Wi5yWE.png" width="500px" title="source: imgur.com" /></a>   ## duality gap $g(u,v)$는 $f$-star의 하한(a lower bound)입니다. 이를 바꾸어 말하면 *dual problem*의 목적함수 $g(u,v)$를 최대화하는 것은 *primal problem*의 목적함수를 최소화하는 문제가 됩니다. 그런데 *primal problem*의 해와 *dual problem*의 해가 반드시 같지는 않습니다. 아래 부등식에서 $f$의 최적값과 $g(u,v)$ 사이에 차이가 존재할 수 있음을 확인할 수 있습니다. 이를 *duality gap*이라고 합니다.  $$ { f }^{ * }\ge \min _{ x }{ L\left( x,u,v \right) }=g(u,v) $$  $f$의 최적값과 $g(u,v)$ 사이에 위와 같은 관계를 지니면 *weak dual*이라고 합니다. 그런데 아래와 같은 관계를 지니면 *strong dual*이라고 합니다. *duality gap*이 없음을 확인할 수 있습니다. $$ { f }^{ * }=g(u,v) $$  *primal problem*의 목적함수와 제약식이 특정 조건을 만족하면 *strong duality* 속성을 지니게 된다고 합니다. 이것이 *Slater's condition*입니다. 다음과 같습니다.  <a href="https://imgur.com/BYkYE9D"><img src="https://i.imgur.com/BYkYE9D.png" width="500px" title="source: imgur.com" /></a>
surinjection␞ 이번 글에서는 **전사함수**(全射函數;surjection)와 **단사함수**(單射函數;injection)를 선형대수학의 선형변환 관점에서 살펴보도록 하겠습니다. 이번 글 역시 고려대 박성빈 교수님 강의를 참고로 했습니다. 그러면 시작하겠습니다.  ## 선형변환과 표준행렬 $V$와 $W$를 벡터공간이라고 하고, 벡터공간 $V$의 원소 $A$, $B$와 실수 $k$에 대하여 아래 두 가지 성질을 모두 만족할 때 $T$를 $V$에서 $W$로의 **선형변환(linear transformation)**이라고 합니다. > $T(A+B) = T(A) + T(B)$ > > $T(kA) = kT(A)$, 즉 $k=0$일 때 $T(0)=0$ 여기서 모든 선형변환은 행렬 곱의 형태로 나타낼 수 있는데요, 임의의 선형변환 $T$가 $n$차원 벡터공간에서 $m$차원으로 **사상(mapping)**한다고 할 때 선형변환 $T$는 위 정의에 의해 아래와 같이 다시 쓸 수 있습니다. $$ \begin{align*} x&=\begin{bmatrix} { x }_{ 1 } \\ { x }_{ 2 } \\ ... \\ { x }_{ n } \end{bmatrix}={ x }_{ 1 }\begin{bmatrix} 1 \\ 0 \\ ... \\ 0 \end{bmatrix}+{ x }_{ 2 }\begin{bmatrix} 0 \\ 1 \\ ... \\ 0 \end{bmatrix}+...+{ x }_{ n }\begin{bmatrix} 0 \\ 0 \\ ... \\ 1 \end{bmatrix}\\ &={ x }_{ 1 }{ e }_{ 1 }+{ x }_{ 2 }{ e }_{ 2 }+...+{ x }_{ n }{ e }_{ n } \\ \\ T(x)&={ x }_{ 1 }T({ e }_{ 1 })+{ x }_{ 2 }T({ e }_{ 2 })+...+{ x }_{ n }T({ e }_{ n })\\ &=\begin{bmatrix} T({ e }_{ 1 }) & T({ e }_{ 2 }) & ... & T({ e }_{ n }) \end{bmatrix}\begin{bmatrix} { x }_{ 1 } \\ { x }_{ 2 } \\ ... \\ { x }_{ n } \end{bmatrix}\\ &=Ax \end{align*} $$ 위 식에서 행렬 $A$를 선형변환 $T$를 나타내는 **표준행렬(standard matrix)**이라 부르고, $T$는 $A$에 의해서 표현된 선형변환이라고 부릅니다.  $T$에 대응하는 표준행렬은 유일합니다. 증명해보겠습니다. 만약 표준행렬이 $A$, $B$ 이렇게 두 개 있다고 가정해 보겠습니다. 선형변환 T에 임의의 기본벡터 $e_i$를 넣으면 아래와 같은 식이 됩니다. $$T({ e }_{ i })=A{ e }_{ i }=B{ e }_{ i }$$ 여기에서 $Ae_i$는 행렬 $A$의 $i$번째 열벡터와 같고, $Be_i$는 행렬 $B$의 $i$번째 열벡터입니다. 위 식이 성립한다는 건 행렬 $A$, $B$의 열이 서로 같다는 의미이기 때문에 $A$와 $B$는 동일한 행렬이라 말할 수 있습니다. 따라서 $T$에 대응하는 표준행렬은 유일합니다.   ## 전사함수 수학에서 전사함수 또는 **위로의 함수(onto)**는 **공역(codomain)**과 **치역(range)**이 일치하는 함수입니다. $n$차원 벡터공간의 벡터 $x$를 $m$차원 벡터공간의 벡터 $b$로 사상하는 선형변환 $T$를 $Ax=b$라고 둡시다. 전사함수는 $b$에 대응하는 $x$가 적어도 하나 존재하는 경우를 말합니다. 이를 그림으로 설명하면 아래와 같습니다. <a href="http://imgur.com/moQGOsS"><img src="http://i.imgur.com/moQGOsS.png" width="500px" title="source: imgur.com" /></a> 위 그림의 왼쪽은 전사함수가 아닌 경우를 말합니다. 정육면체가 $m$차원 공간이라고 상상해 봅시다. 선형변환 $T$는 **정의역(domain)**에 있는 원소들을 정육면체를 둘로 가르는 하늘색 평면에 옮기고 있는 모습을 확인할 수 있습니다. 여기에서 $m$차원 벡터 $b$가 정육면체 안에 있으나 하늘색 평면 바깥에 존재한다고 가정해봅시다. 이 경우 $b$에 대응하는 $x$는 존재하지 않는다는 사실 또한 알 수 있습니다. (공역>치역) 반대로 오른쪽 그림의 경우 어떤 $b$를 상정하더라도 그에 대응하는 $x$가 존재합니다. 이게 바로 전사함수입니다. (공역=치역)  ## 단사함수 그럼 단사함수 또는 **일대일(one-to-one) 함수**를 살펴볼까요? 전사함수 설명 때와 동일하게, $n$차원 벡터공간의 벡터 $x$를 $m$차원 벡터공간의 벡터 $b$로 사상하는 선형변환 $T$를 $Ax=b$라고 둡시다. 단사함수란 $b$에 대응하는 $x$가 최대 한 개 존재하는 경우를 일컫습니다. 이를 그림으로 도시하면 아래와 같습니다. <a href="http://imgur.com/gXR4ewY"><img src="http://i.imgur.com/gXR4ewY.png" width="500px" title="source: imgur.com" /></a> 위 그림의 왼쪽은 단사함수가 아닌 경우를 말합니다. $m$차원 벡터 $b$에 대응하는 $n$차원 벡터 $x$가 여러개이기 때문입니다. 반대로 오른쪽 그림의 경우 $b$에 대응하는 $x$는 단 하나 존재합니다. 이 경우 단사함수라고 부릅니다.   ## 전단사와 선형 연립방정식 (1) 4차원 벡터공간에서 3차원 공간으로 사상하는 선형변환 $T$에 대응하는 표준행렬 $A$는 다음과 같다고 둡시다. $$A=\begin{bmatrix} 1 & -4 & 8 & 1 \\ 0 & 2 & -1 & 3 \\ 0 & 0 & 0 & 5 \end{bmatrix}$$ 우선 $T$가 전사함수인지를 살펴보겠습니다. 정의역(4차원) 벡터를 $x$, 공역(3차원) 벡터를 $b$라고 두면 $T$는 아래와 같이 쓸 수 있습니다. $$Ax=b$$ $T$가 전사함수인가 아닌가라는 질문은 임의의 $b$에 대해 해가 적어도 하나 존재하는가라는 질문과 동일합니다. 이 문제를 풀기 위해 선형 연립방정식 관련 네 가지 명제를 소개합니다. 이들은 하나가 참이면 모두 참이고, 하나가 거짓이면 모두 거짓인 **동치(equivalent)** 관계입니다. 자세한 내용은 [이곳](https://ratsgo.github.io/linear%20algebra/2017/03/25/LUfactorization/)을 참고하시기 바랍니다. >(1) $Ax=b$가 해를 갖는다. > >(2) $b$는 계수행렬 $A$의 열벡터 간 선형결합으로 표시된다. > >(3) 계수행렬 $A$의 열벡터는 $m$차원 벡터공간을 **생성(span)**한다. > >(4) $A$는 모든 행에 **pivot positon**을 하나 가진다. 표준행렬 $A$는 **가우스행렬(echelon form)** 형태입니다. $A$의 행 개수는 3개인데, pivot position(선도 원소가 영이 아닌 행) 또한 3개(요소값 기준 : 1,2,5)이므로 위 네 가지 동치명제에 의해 해가 존재함을 알 수 있습니다. 따라서 $T$는 전사함수입니다. $T$가 단사함수인지 가려볼까요? A의 세번째 열($[8,-1,0]^T$)은 **추축열(pivot column**;pivot position에 대응하는 열)이 아니군요. $A$를 선형 연립방정식의 계수행렬로 상정해 본다면 이 열에 대응하는 $x_3$은 어떤 값을 가지든 상관없는 **자유변수(free variable)**입니다. 바꿔 말하면 $b$에 대응하는 $x$가 유일하지 않다는 이야기입니다. 따라서 $T$는 단사함수가 아닙니다.  ## 전단사와 선형 연립방정식 (2) $n$차원 벡터를 $m$차원 벡터로 사상하는 임의의 선형변환 $T$에 관해 세 가지 정리를 하고 넘어가겠습니다. > (a) 표준행렬 $A$의 열벡터가 $m$차원 벡터공간을 생성(span)할 때 $T$는 전사함수이다. > > (b) $T(x)$가 단사함수이면 $T(x)=0$은 자명해($x=0$)를 유일해로 갖는다. 그 역도 성립한다. > > (c) 표준행렬 $A$의 열벡터가 서로 선형독립일 때 $T$는 단사함수이다. 그 역도 성립한다. 우선 (a)를 살펴보겠습니다. $T$를 $Ax=b$ 꼴로 둘 때 $b$는 $A$의 열벡터와 $x$의 선형결합인데요. $A$의 열벡터가 생성하는 벡터집합이 $m$차원 벡터공간을 모두 채우고 있다면(=$A$의 열벡터가 $m$차원 공간을 생성) $x$가 어떤 값을 갖더라도 $Ax=b$가 성립합니다. 다시 말해 임의의 $b$에 대응하는 $x$가 적어도 하나 존재합니다. (b)와 관련해 $T$는 **선형성(linearity)** 조건을 만족하기 때문에 $T(0)=0$입니다. $T(x)$가 단사함수라면 $Ax=b$ 형식에서 단 하나의 해만 존재해야 합니다. 따라서 $T(x)$가 단사함수라면 $T(x)=0$은 자명해($x=0$)를 유일한 해로 갖습니다.  한편 $T$가 단사함수가 아니어서 임의의 $b$에 대응하는 $x$가 서로 다른 벡터 $u$, $v$가 존재한다고 가정해 봅시다. 즉, $T(u)=b, T(v)=b$가 성립한다는 이야기입니다. $T$는 선형성 조건을 만족하므로 $T(u-v)=T(u)-T(v)=b-b=0$입니다. 그런데 $u-v≠0$이므로 $T(x)=0$은 하나 이상의 비자명해를 갖습니다. 이 말은 $T(x)=0$이 자명해를 유일해로 갖는다면 $T(x)$가 단사함수이라는 명제와 동치입니다. 이번엔 (c)를 보겠습니다. $A$의 열벡터가 선형독립이라는 얘기는 $T$를 $Ax=b$ 꼴의 연립방정식으로 생각할 때 해가 영벡터뿐이라는 얘기와 같습니다. 따라서 (c)는 명제 (b)에 의해 참입니다. 이제 예를 들어보겠습니다. 선형변환 $T$가 아래와 같습니다. $$T({ x }_{ 1 },{ x }_{ 2 })=(3{ x }_{ 1 }+{ x }_{ 2 },5{ x }_{ 1 }+7{ x }_{ 2 },{ x }_{ 1 }+3{ x }_{ 2 })\\ T(x)=\begin{bmatrix} 3{ x }_{ 1 }+{ x }_{ 2 } \\ 5{ x }_{ 1 }+7{ x }_{ 2 } \\ { x }_{ 1 }+3{ x }_{ 2 } \end{bmatrix}=\begin{bmatrix} 3 & 1 \\ 5 & 7 \\ 1 & 3 \end{bmatrix}\begin{bmatrix} { x }_{ 1 } \\ { x }_{ 2 } \end{bmatrix}=Ax$$ 우선 단사함수 여부를 가려보겠습니다. 표준행렬 $A$의 열벡터는 임의의 스칼라곱을 해서 비교해도 같아지지 않으므로 서로 선형독립임을 알 수 있습니다. (c)에 의해 $T$는 단사함수입니다.  하지만 $A$의 행 개수는 세 개 인데 열 개수는 두 개뿐이므로 모든 행에 pivot position이 있는 건 아닙니다. 전챕터 (1)~(4) 정리에 의해 $A$의 열벡터는 3차원 공간을 생성할 수 없습니다. $T$는 전사함수가 아닙니다.  이 문제를 가우스소거법에 의한 연립방정식($Ax=b$) 풀이로도 접근해서 풀어보겠습니다. **확대행렬(augmented matrix)**로 나타내 기본행 연산을 한 결과는 아래와 같습니다. $$\begin{bmatrix} 3 & 1 & { b }_{ 1 } \\ 5 & 7 & { b }_{ 2 } \\ 1 & 3 & { b }_{ 3 } \end{bmatrix} \sim \begin{bmatrix} 1 & 3 & { b }_{ 3 } \\ 0 & -8 & { b }_{ 2 }-5{ b }_{ 3 } \\ 0 & 0 & { b }_{ 1 }-{ b }_{ 2 }+2{ b }_{ 3 } \end{bmatrix}$$ $b_1-b_2+2b_3=0$이면 해가 있지만, 0이 아니면 해가 존재하지 않습니다. 따라서 전사함수가 아닙니다. $T$를 그림으로 나타내면 아래와 같습니다. <a href="http://imgur.com/5ci8UJI"><img src="http://i.imgur.com/5ci8UJI.png" width="200px" title="source: imgur.com" /></a> 위 그림을 보시면 $T$에 의해 2차원 평면이 3차원으로 사상(mapping)되는 걸 확인할 수 있습니다. 변환 후 3차원 공간 전체를 채우지 못하는 것 또한 볼 수 있는데요, 여기서도 역시 우리는 이 변환이 전사함수가 아님을 알 수 있습니다. 다만 이렇게 그림으로 이해할 수 있는 건 3차원까지이고요, 그보다 높은 차원의 선형변환 $T$가 전사, 단사임을 확인하려면 지금까지 말씀드렸던 정리와 절차에 대해 확인하는 과정을 거쳐야 합니다.   ## 마치며 지금까지 전사함수와 단사함수를 선형대수학의 선형변환 관점에서 살펴보았습니다. 임의의 선형변환이 전사이면서 단사함수이려면 사상 전후의 차원이 같아야 합니다(2차원=>2차원, 3차원=>3차원).  그런데 사상 후 차원이 커질 경우 단사함수 조건을 만족하지만 전사함수이진 않습니다. 바꿔 말해 일대일 대응 성질은 만족하지만 치역이 공역보다 작다는 이야기입니다.  반대로 차원을 줄일 경우 전사함수이지만 단사함수는 아닙니다. 공역을 빠짐없이 채우게 돼 치역과 일치하지만, 그에 대응하는 정의역 벡터 $x$가 여러 개가 될 수 있기 때문입니다.  이를 상식적으로 이해해보면 큰 공간을 작은 공간으로 줄일 때 빽빽해지고, 작은 공간을 큰 공간으로 늘릴 때 듬성듬성해진다고 이해하셔도 좋을 것 같다는 생각입니다.  선형변환은 선형 연립방정식의 해를 찾는 과정과 본질적으로 다르지 않기 때문에 선형대수학이라는 학문이 하나의 체계를 이루는 것 같다는 느낌도 듭니다. 질문이나 의견 있으시면 이메일이나 댓글로 알려주시면 감사하겠습니다. 여기까지 읽어주셔서 진심으로 감사드립니다.
voice␞ 이번 글에서는 한국어의 피동 표현에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 태(態) **태(態, voice)**란 [의미역](https://ratsgo.github.io/korean%20linguistics/2017/06/04/thetarole/)이 문법적 관계로 실현되는 방식을 가리키는 문법범주입니다. 동사에 붙는 문법적 표지(예컨대 어미)로 표시됩니다. `태`와 관련해 행위자, 피행위자의 두 참여자를 갖는 사태가 문장으로 표현될 때 크게 두 가지 부류로 나눠 생각해볼 수 있습니다. 첫번째는 **능동문**입니다. [한국어의 일반적인 문장 연결규칙](https://ratsgo.github.io/korean%20linguistics/2017/07/14/sov/)에 따라 행위자가 주어로, 피행위자가 목적으로 실현되는 문장입니다. 다음 예문과 같습니다. - 경찰이 도둑을 잡았다. 두번째는 **피동문**입니다. 능동문에서 행위자, 피행위자 등장 순서에 역전이 일어나고, 동사에 이것을 알리는 표지(예문에서는 `-히-`)가 붙은 문장입니다. 다음과 같습니다. - 도둑이 (경찰에게) 잡**혔**다. 위 예문에서 살펴볼 수 있듯, 능동문을 피동문으로 바꾸는 데(즉 `태`가 바뀌는 데) 아래 세 절차를 따릅니다. 1. 능동문의 목적어는 피동문의 주어가 된다. 2. 능동문의 주어는 부사어로 나타나거나 생략된다. 3. 동사의 형태가 바뀐다.  한편 피동문의 정의상(능동문의 목적어가 피동문의 주어가 됨) 타동문(목적어를 가진 문장)으로부터만 피동문이 만들어질 수 있습니다.    ## 한국어의 피동 표지 한국어 피동문 동사에 붙는 피동 표지는 크게 '접미사'와 '보조동사구성'이 있습니다. 차례대로 살펴보겠습니다.   ### 접미사에 의한 피동 표현 피동 접미사는 `-이/히/리/기-`가 있습니다. 다음 예문과 같습니다. - 보- → 보**이**- - 먹- → 먹**히**- - 들- → 들**리**- - 믿- → 믿**기**- 그러나 한국어의 모든 동사가 위와 같은 피동접미사를 취할 수 있는 건 아닙니다. 다음과 같은 종류의 동사에는 `-이/히/리/기-`가 붙을 수 없습니다. - **수여 동사** : 주다, 받다, 드리다, 바치다 등 - **수혜 동사** : 얻다, 잃다, 찾다, 돕다, (은혜를)입다, 사다 등 - **지각 동사** : 알다, 배우다, 바라다, 느끼다 등 - **대칭 동사** : 만나다, 닮다, 싸우다 등 - 좋아하다, 슬퍼하다, 사랑하다, 공부하다, 조사하다 등 - 모든 사동사 접미사에 의한 피동표현에서 능동문에서 주어였던 것은 어떻게 표시가 될까요? 유형별로 살펴 보겠습니다. - **유정 명사인 경우 '-에게'** : 경찰이 도둑을 잡았다. → 도둑이 **경찰에게** 잡혔다. - **무정 명사인 경우 '-에'** : 흰 눈이 온 들판을 덮었다. → 온 들판이 **흰 눈에** 덮였다. - **능동문에 이미 '-에게'나 '-에'가 있는 경우에는 '-에 의해(서)'**  김 씨가 박 씨에게 집을 팔았다. → 집이 **{\*김 씨에게, 김 씨에 의해}** 박 씨에게 팔렸다.  도둑들이 보물을 강 밑에 묻었다. → 보물이 **{\*도둑들에게/도둑들에 의해}** 강 밑에 묻혔다. 그러나 예외도 상당히 많습니다. 아래 예문은 유정 명사에 해당해 '-에게'를 써야 할 것 같지만, '-에 의해(서)'가 자연스러운 표현임을 확인할 수 있습니다. - 진이가 종이를 찢었다. → 종이가 진이**{\*에게/에 의해}** 찢겼다. - 진이가 전화를 끊었다. → 전화가 진이**{\*에게/에 의해}** 끊겼다.   ### 보조동사 구성에 의한 피동표현 다음과 같이 보조동사 구성 `-어지-`로 피동 표현을 만들 수도 있습니다. - 만들- → 만들**어지**- - 이루- → 이루**어지**- 피동 보조동사 구성 `-어지-`는 피동 접미사에 의한 피동 표현이 불가능한 경우에 그 빈 자리를 메워 주는 구실을 하는 것으로 보입니다. 사동문이 주로 이 방식으로 피동문을 만듭니다. - 의견이 좁**혀지**다. - 사실이 밝**혀지**다. - 대회가 늦추**어지**다. - 얼룩이 지**워지**다. 피동 접미사가 붙을 수 있는 동사에도 `-어지-`가 연결되는 경우가 있습니다. - 나뉘다-나누어지다 - 닫히다-닫아지다 - 믿기다-믿어지다 - 쓰이다-써지다 ``` <참고> 위 예문의 '쓰이다'는 동사 '쓰다'에 피동 접미사 '-이-'가 붙은 형태입니다. 다음 예문과 같습니다. 예) 철수가 비석에 제작 경위를 썼다(주동문) → 비석에 제작 경위가 쓰여 있었다(피동문) 그런데 이와 별개로 타동사의 목적어가 주어가 되면서 타동사에 '-어 있-'이 결합하면 결과상(과거 사태의 결과가 지속됨)을 나타낼 수 있었습니다. 이런 방식이 중세 국어에서는 꽤 생산적이었습니다. 다음 예문과 같습니다. 예) 비석 제작 경위가 써 있었다. (제작 경위를 쓴 결과가 지속됨) 예) 벽에 글씨가 써 있다. (글씨를 쓴 결과가 지속됨) 예) 방에 불이 켜 있다. (불 켜진 상태가 지속됨) ``` 보조동사 구성에 의한 피동 표현에서 능동문의 주어는 주로 `-에 의해`로 실현됩니다. 다음 예문과 같습니다. - 정부가 통일세 관련 특별법을 만들었다. → 통일세 관련 특별법이 정부**에 의해** 만들어졌다. 하지만 `-에게`, `-에`, `-로(부터)`가 실현되는 경우도 있습니다. - 진이는 민이를 길들였다. → 민이는 진이**에게** 길들여졌다. - 날카로운 말이 내 가슴을 할퀴었다. → 날카로운 말**에** 내 가슴은 할퀴어졌다. - 흙이 그 자리를 메웠다. → 그 자리는 흙**으로** 메워졌다. - 세계 전체가 압력을 가했다. → 세계 전체**로부터** 압력이 가해졌다. 피동 보조동사 구성 `-어지-`와 관련해 특이한 사례들이 있습니다. 다음과 같습니다. - 넘어지다, 떨어지다, 쓰러지다, 무너지다, 부러지다, 자빠지다 위 동사들을 살펴보면 '넘어지다'와 '떨어지다'를 제외하면 어간의 어원을 밝혀적지 않는다는 걸 확인할 수 있습니다. 예컨대 '무너지다'의 경우 '문다'라는 동사의 어간 '문-'에 피동 보조동사 구성 `-어지-`가 결합해 '무너지다'가 되는 것이 윗 글에서 언급된 사례였습니다. 그러나 한국어에는 붕괴(崩壞)라는 의미의 '문다'라는 동사가 없으므로 특수한 사례로 취급하는 것입니다. 그런데 이들 동사들도 피동의 의미가 있고, 그 짝이라 할 만한 타동사들도 있습니다. 그 타동사들은 능동문에서 `-뜨리다`를 취하면서 피동 표현시 그것을 `-어지다`로 바꾸어 규칙적으로 피동사를 만드는 듯한 모습을 보여줍니다. - 넘어뜨리다-넘어지다, 떨어뜨리다-떨어지다, 쓰러뜨리다-쓰러지다, 무너뜨리다-무너지다, 부러뜨리다-부러지다, 자빠뜨리다-자빠지다  `-어지-`가 있어 피동 표현 같지만 피동문이 아닌 구문들도 꽤 있습니다. `-어지-`는 피동문을 만들 수 있는 타동사뿐 아니라, 그럴 수 없는 형용사/자동사와도 결합하기 때문입니다. `-어지-`가 형용사와 결합하면 상태 변화를 나타냅니다. 다음 예문과 같습니다. - 날씨가 좋아졌다. - 길이 넓어졌다. - 여드름이 없어졌다. `-어지-`가 자동사와 결합하면 어떤 힘에 의해 그렇게 됨을 나타냅니다. 다음 예문과 같습니다. - 졸업을 하고 나니 선생님 댁에 잘 가지지 않는다. - 억지로 울려니까 잘 울어지지 않는다. 위 예문들은 의미상 피동과 상통하는 것 같지만, 짝이 되는 능동문이 없다는 점에서 특이합니다. 피동문은 '짝이 되는 능동문이 존재'하고, '동사에 피동 표지가 붙는다'는 특징을 가지고 있으므로, 형용사나 자동사와 결합한 `-어지-` 구문을 피동문으로 인정하기 어렵습니다. 한편 피동사에 다시 `-어지-`가 덧붙는 경우도 있습니다. 대개 `-어지-`를 군더더기로 써 잘못 쓴 경우입니다. 다음 예문의 경우 `-어지-`를 빼고 쓰는게 맞습니다. - 요즈음 젊은이들에게 잘 **{\*읽혀지는/읽히는}** 소설 - 생각**{\*되어지다/되다}** 그런데 때에 따라서는 두 형태가 공존하면서 독자적인 영역을 만들어 가는 양상을 보입니다. - 이 논문은 주제가 매우 참신해 보인다(*보여진다). - 이 논문은 주제가 매우 참신하다고 보여진다(??보인다).   ### X되-, X당하-, X받- 어근(語根)이라 할 만한 요소($X$)에 `되-`, `당하-`, `받-`이 붙어 피동 표현을 만드는 경우도 잇습니다. 다음 예문과 같습니다. - 정복하다-정복되다 - 강요하다-강요받다 - 모욕하다-모욕당하다 - 배치하다-배치되다/배치받다 - 오해하다-오해되다/오해받다   ## 피동의 기능 피동의 기능 가운데 첫번째로 언급할 만한 내용은 행위자 논항에 스포트라이트가 비춰지지 않게 한다는 것입니다. 피동문으로 표현할 경우 행위자 정체를 모를 때 행위자를 표현하지 않을 수 있고, 행위자의 정체 또한 밝히지 않을 수 있게 할 수 있습니다. 다음 예문처럼 누가 살인자인지 모르는 상황이라면 행위자 정체를 굳이 밝히지 않은 피동문이 더 자연스럽습니다. - **능동문** : 누군가가 진이를 살해했다. - **피동문** : 진이가 살해되었다. 피동문은 피행위자 논항을 맨 앞에 적기 때문에 피행위자 논항을 부각시키는 효과가 있습니다. 다시 말해 피동문은 사태를 (행위자 대신) 피행위자의 관점에서 기술한 문장이라는 말입니다. 다음 예문에서 그 뉘앙스 차이를 느낄 수 있습니다. - **능동문** : 민이가 진이를 잡았다. (민이가 잡았다는 사태를 부각) - **피동문** : 진이가 민이에게 잡혔다. (진이가 잡혔다는 사태를 부각) 피동문은 **[주제](https://ratsgo.github.io/korean%20linguistics/2017/07/11/senttopic/) 연속성(topic continuity)**을 보장합니다. 다음 예문처럼 연이어 있는 문장이라면 괄호 안 능동문보다는 괄호 밖 피동문이 더 자연스럽습니다. 진이를 주인공으로 한 주제의 연속성이 보장되고 있기 때문입니다. - **진이는** 아침에 일어나서 밥을 먹고 학교로 향했다.  **진이는** 길을 건너다가 차에 치였다. (차가 진이를 치었다)  **진이는** 병원으로 실려 갔다. (구급차가 진이를 병원으로 싣고 갔다) 피동문은 주어에만 적용될 수 있는 통사과정을 피행위자에 적용하기 위한 사전 조처 성격도 있습니다. 다음 예문과 같습니다. - 그$i$가 [$e_i$ 대통령 후보로 지명되]려고 노력했다.  *그$i$가 [당원들이 $e_i$ 대통령 후보로 지명하]려고 노력했다.   ## 능동문과 피동문이 대응을 이루지 않는 경우 능동문에 대응하는 피동문, 혹은 피동문에 대응하는 능동문이 존재하지 않는 경우가 꽤 있습니다. 유형별로 살펴보겠습니다. 우선 능동문의 목적어가 무정명사인 경우 능동문에 대응하는 피동문이 존재하지 않을 수 있습니다. 다음 예문과 같습니다. - 진이가 칭찬을 들었다. / ?칭찬이 진이에게 들렸다. - 진이가 책을 다 읽었다. / ?책이 진이에게 다 읽혔다. - 진이가 문고리를 잡았다. / ?문고리가 진이에게 잡혔다. - 진이가 길을 물었다. / ?길이 진이에게 물어졌다. 의지나 의도를 가진 주체를 설정하기 어려운 경우엔 피동문에 대응하는 능동문이 존재하지 않을 수 있습니다. 예문과 같습니다. - *누가 날씨를 풀었다. / 날씨가 풀렸다. - *누가 더위를 한풀 꺾었다. / 더위가 한풀 꺾였다. - *누가 일을 산더미처럼 쌓았다. / 일이 산더미처럼 쌓였다. 능동문의 주어가 무정명사인 경우 피동문에 대응하는 능동문이 존재하지 않을 수 있습니다. 예문과 같습니다. - ?나무가 열매를 열었다. / 나무에 열매가 열렸다. - ?바람이 문을 열었다. / 문이 바람에 열렸다. 그 원인에는 동사, 상황, 인간 주어 중심의 한국어 특성을 반영한 게 아닌가 하는 해석도 제기됩니다. 영어와 비교해 세 가지를 살펴보겠습니다. 각각 위 세 가지 *case*에 대응됩니다.  영어는 사건, 속성을 명사구로 표현하는 일이 흔합니다. 반면 한국어는 동사, 형용사로 풀어 표현하는 것이 자연스럽습니다. - (공항 안내 방송에서) Your attention, please. / 안내 말씀 드리겠습니다. - He is a good swimmer. / 그는 수영을 잘 한다. 영어는 주어 자리에 인간을 놓는 경향이 강합니다. 반면 한국어는 인간을 전면에 드러내지 않고 상황 중심으로 표현하는 경향이 있습니다. - I've lost a button. / 단추가 떨어졌다. - Finally we've come to conclusion. / 마침내 결론을 내렸다. 영어는 무정물을 주어로 한 타동 표현을 자연스럽게 사용합니다. 반면 한국어는 인간을 주체로 한 표현이나 상황 중심적인 표현으로 바꾸는 것이 자연스럽습니다. - This road will take you to the station. / 이 길을 따라가면 역이 나옵니다. - Horror made her dumb. / 그녀는 두려워서 말 한 마디 못 했다. 한편 한국어에서는 피동문을 만들 수 없는 타동사들이 존재합니다. 이 경우엔 능동문에 대응하는 피동문이 존재하지 않는다는 이야기입니다. 다음과 같습니다. - 선생님이 학생을 **가르친다**. - 진이가 심리학을 **공부한다**. - 이웃을 **돕는다**. - 아이들을 **웃긴다**.    ## 피동과 타동성 피동의 정의상 타동문(목적어를 가진 문장)으로부터만 피동문이 만들어질 수 있습니다. 아울러 능동문의 목적어는 주어가 되고, 새로운 목적어가 만들어지지 않으므로 피동문은 대개 자동문입니다. 그러나 이러한 경향성에 예외가 좀 있습니다. 목적어가 있는 피동문이 존재한다는 이야기입니다. 다음 예문과 같습니다. - 개가 토끼를 다리를 물었다. → 토끼가 개에게 다리를 물렸다. 위 예문의 경우 능동문에 목적어가 둘 있어서, 둘 중 하나(토끼)가 피동문의 주어로, 나머지(다리)가 피동문의 목적어로 남았다는 해석이 가능합니다. 그러나 피동문의 주어가 무정물일 경우에는 수용성이 떨어집니다. 다음 예문과 같습니다. - 철수가 책상을 귀퉁이를 잡았다. → ??책상이 철수에게 귀퉁이를 잡혔다. 다만 무정물이 특정 유정물의 소유가 되는 등 유정물의 이해관계와 밀접한 관련이 있다면 수용성이 높아집니다. 다음 예문과 같습니다. - 사람들이 내 차를 문짝을 수없이 긁었다. → 내 차는 문짝을 수없이 긁혔다. 위 예문(내 차를 문짝을)이나 첫번째 예문(토끼를 다리를)처럼 두 목적어가 전체-부분 관계일 때 목적어가 잔류하는 피동문이 가능한 걸 확인했습니다. 그러나 상위개념-하위개념, 대상-수량 같은 관계일 때에는 목적어가 잔류하는 피동문이 불가능합니다. 다음 예문과 같습니다. - **상위개념-하위개념** : 바둑이가 **아이들을, 여자아이들을** 물었다. → *아이들은 바둑이에게 여자아이들을 물렸다. - **대상-수량** : 주인은 **강아지를 세 마리를** 팔았다. → *강아지가 주인에 의해 세 마리를 팔렸다. 한편 아래 예문처럼 능동문에 목적어가 둘 있지 않아도, 피동 주어(아버지)와 목적어(비상금)가 소유주-소유물 관계일 때 목적어 있는 피동문이 성립할 수 있습니다. 아울러 그것이 '피해'의 의미를 가질 때 잘 쓰입니다. - 어머니가 아버지에게서 비상금을 빼앗았다. → 아버지는 어머니에게 비상금을 빼앗겼다. - 진이는 월급을 깎였다. / *진이는 빚을 깎였다.
avltree␞ 이번 글에서는 **AVL 트리**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의와 위키피디아를 정리하였음을 먼저 밝힙니다. 파이썬 코드는 [이곳](https://gist.github.com/girish3/a8e3931154af4da89995)을 참고하였습니다. 그럼 시작하겠습니다.   ## concepts AVL 트리란 서브트리의 높이를 적절하게 제어해 전체 트리가 어느 한쪽으로 늘어지지 않도록 한 [이진탐색트리(Binary Search Tree)](https://ratsgo.github.io/data%20structure&algorithm/2017/10/22/bst/)의 일종입니다. 트리의 높이가 $h$일 때 이진탐색트리의 계산복잡성은 $O(h)$이기 때문에 균형된 트리를 만들어 $h$를 줄이고자 하는 발상에서 비롯됐습니다. AVL 트리의 핵심 개념 가운데 하나가 **Balance Factor(BF)**입니다. 왼쪽 서브트리의 높이에서 오른쪽 서브트리의 높이를 뺀 것입니다. 두 서브트리의 높이가 같거나 잎새노드라면 BF는 0입니다(empty tree의 BF는 -1로 정의). 다음 그림을 보겠습니다.  <a href="https://imgur.com/JxjSEnO"><img src="https://i.imgur.com/JxjSEnO.png" width="200px" title="source: imgur.com" /></a> 위 이진탐색트리의 루트노드의 BF는 -1입니다. 왼쪽 서브트리의 높이는 1, 오른쪽은 2이기 때문입니다. 9의 BF는 1입니다. 9의 왼쪽 서브트리의 높이는 1, 오른쪽 서브트리는 존재하지 않아 0이기 때문입니다. 잎새노드인 3, 5, 7은 서브트리가 전혀 없기 때문에 BF는 0이 됩니다. BF가 클 수록 불균형 트리라고 할 수 있겠습니다. AVL 트리는 요소를 삽입(insert)하거나 삭제(delete)하는 과정에서 서브트리를 재구성해 트리 전체의 균형을 맞춥니다. 삽입/삭제 연산시 BF가 일정 값 이상(보통 2) 혹은 이하(-2)로 바뀐 노드를 기준으로 그 서브트리들의 위치를 *rotation*하는 방식을 취합니다. *rotation*에는 두 가지 방식이 있는데 삽입 연산을 중심으로 살펴 보겠습니다.   ## single rotation 삽입 연산시 *single rotation*은 다음과 같은 방식으로 수행합니다. $U$는 주어진 이진탐색트리의 루트노드, $V$는 $U$의 왼쪽 자식노드, $Z$는 $U$의 오른쪽 서브트리입니다. $X$와 $Y$는 각각 $V$의 왼쪽, 오른쪽 서브트리를 가리킵니다. $X$, $Y$, $Z$의 높이가 모두 $h$라고 가정해 보겠습니다. 여기에서 $X$에 새로운 요소를 하나 추가해 보겠습니다. 이 경우 $V$와 $U$의 BF는 각각 1, 2가 됩니다.  <a href="https://imgur.com/KmJ4H8Z"><img src="https://i.imgur.com/KmJ4H8Z.png" width="250px" title="source: imgur.com" /></a>  $U$는 'BF가 2 이상, 2 이하일 때 *rotation*을 실시한다'는 조건에 부합합니다. $U$의 왼쪽 자식노드인 $V$를 기준으로 *single rotation*을 아래와 같이 실시해 줍니다. 기존 트리 구조에서 $Z$를 잡아 당겨 내려서 $V$를 새로운 루트노드로 만드는 겁니다. 요소 하나가 추가된 $X$의 높이만 $h+1$이고 나머지는 모두 $h$인 점을 감안하면 *rotation* 실시 후의 $U$, $V$의 BF는 각각 0, 0이 되어 균형 트리를 이룹니다.  <a href="https://imgur.com/1HaEZv0"><img src="https://i.imgur.com/1HaEZv0.png" width="250px" title="source: imgur.com" /></a>  *single rotation*을 일반화한 그림은 다음과 같습니다.  <a href="https://imgur.com/q3VrlhW"><img src="https://i.imgur.com/q3VrlhW.png" width="400px" title="source: imgur.com" /></a>  요소 하나 추가하는 데 이렇게까지 복잡하게 할 필요가 있을까 싶기도 합니다. 하지만 AVL 트리는 기본적으로 이진탐색트리라는 점에 유의해야 합니다. 삽입 연산을 수행하더라도, 부모노드는 왼쪽 자식노드보다 크거나 같고, 오른쪽 자식노드보다는 작거나 같다는 성질이 깨지지 않도록 해야 한다는 이야기입니다.  구체적인 예를 들어 볼까요. 아래 트리에서 0.8을 삽입해 보겠습니다. 0.8은 5보다 작으므로 3과 비교하고, 3보다 작으므로 1과 비교하고, 1보다 작고 1의 자식노드가 없습니다. 따라서 0.8이 들어갈 위치는 1의 왼쪽 자식노드가 됩니다. 기존의 이진탐색트리라면 여기에서 삽입 연산을 마칩니다.  <a href="https://imgur.com/etDYy8r"><img src="https://i.imgur.com/etDYy8r.png" width="400px" title="source: imgur.com" /></a> 하지만 서브트리 $X$에 0.8이 추가되면서 $V$와 $U$의 BF는 각각 1, 2이 됐습니다. $V$를 기준으로 *rotation*을 해줍니다. 이를 수행한 결과는 상단 우측 그림과 같습니다. 우선 모든 노드의 BF가 1 이하여서 균형을 이루고 있는 점을 확인할 수 있습니다.  이번엔 *rotation* 수행 결과로 이진탐색트리 속성이 깨졌는지 여부를 살펴볼까요? '중위탐색(inorder traverse) 결과가 정렬된 리스트를 이룬다'는 [이진탐색트리의 기본 속성](https://ratsgo.github.io/data%20structure&algorithm/2017/10/22/bst/)을 활용해 보겠습니다. 중위탐색은 왼쪽 서브트리-노드-오른쪽 서브트리 순으로 순회하는 방식입니다. 상단 우측 그림을 중위탐색으로 읽은 결과 요소 하나를 추가했는데도 이진탐색트리의 속성을 만족하고 있음을 살펴볼 수 있습니다. > 0.8, 1, 3, 4, 5, 8 *single rotation*은 *rotation*을 한 차례 수행해 위와 같이 원하는 결과를 얻을 수 있는 경우를 가리킵니다. 삽입 연산의 *single rotation*은 다음 두 가지 경우에 $V$($U$의 자식노드, BF 절대값이 1이하)를 중심으로 실시합니다. ($U$는 BF의 절대값이 2 이상이면서 새 노드와 가장 가까운 조상 노드) - $V$가 $U$의 왼쪽 자식노드, $V$의 왼쪽 서브트리에 새 노드 삽입 : $V$를 기준으로 *right rotation* - $V$가 $U$의 오른쪽 자식노드, $V$의 오른쪽 서브트리에 새 노드 삽입 : $V$를 기준으로 *left rotation*  *left/right rotation*를 직관적으로 나타낸 그림은 각각 다음과 같습니다.  <a href="https://imgur.com/ifikmO7"><img src="https://i.imgur.com/ifikmO7.png" width="400px" title="source: imgur.com" /></a> <a href="https://imgur.com/UdJtIAZ"><img src="https://i.imgur.com/UdJtIAZ.gif" title="source: imgur.com" /></a>   ## single rotation의 파이썬 구현 *left rotation*의 파이썬 코드는 다음과 같습니다. ```python   def lrotate(self):     # 현재 트리의 기존 root를 A라고 두자     A = self.node     # 기존 root의 right child를 B라고 두자     B = self.node.right.node     # B의 left child(위 그림에서 베타)를 T라고 두자     T = B.left.node         # B를 새로운 root로 지정     self.node = B     # A를 root(B)의 새로운 left child로 지정     B.left.node = A     # T(위 그림에서 베타)를 A의 새로운 right child로 지정     A.right.node = T ``` *right rotation*은 위의 반대로 수행하면 됩니다. ```python   def rrotate(self):     A = self.node     B = self.node.left.node     T = B.right.node         self.node = B     B.right.node = A     A.left.node = T ```    ## double rotation *rotation* 한 차례만으로 원하는 삽입 결과를 내지 못하는 케이스가 존재합니다. 다음 두 가지 경우 *double rotation*을 수행해 줍니다. ($U$는 BF의 절대값이 2 이상이면서 새 노드와 가장 가까운 조상 노드, $V$는 $U$의 자식노드이면서 BF 절대값이 1이하) - $V$가 $U$의 왼쪽 자식노드, $V$의 오른쪽 서브트리에 새 노드 삽입 - $V$가 $U$의 오른쪽 자식노드, $V$의 왼쪽 서브트리에 새 노드 삽입 아래 그림과 같은 트리 구조에서 $B$에 새로운 요소를 추가한다고 가정해 보겠습니다 (동그라미는 노드, 세모는 서브트리를 가리킵니다) 이렇게 되면 요소 하나를 삽입한 후의 $U$, $V$, $W$의 BF는 각각 2, -1, 1이 됩니다. 따라서 $U$를 루트노드로 하는 서브트리가 재구성 대상이 되겠습니다.   <a href="https://imgur.com/g6zGbqx"><img src="https://i.imgur.com/g6zGbqx.png" width="200px" title="source: imgur.com" /></a>  그런데 $V$는 $U$의 왼쪽 자식노드이고, 새 노드는 $V$의 오른쪽 서브트리에 추가됐으므로 *double rotation*을 수행해 줍니다. 여기에서 $W$는 $V$의 오른쪽 자식노드입니다. 다음과 같습니다. - 첫번째 : $W$를 중심으로 *left rotation* 수행 ($A$를 잡아 당겨 내리는 과정) - 두번째 : $W$를 중심으로 *right rotation* 수행 ($D$를 잡아 당겨 내리는 과정)  <a href="https://imgur.com/qCsLMlQ"><img src="https://i.imgur.com/qCsLMlQ.png" title="source: imgur.com" /></a>  요소 삽입 후 서브트리들 가운데 $C$의 높이만 $h-1$이고 나머지는 모두 $h$인 점을 감안하면 *double rotation* 수행 후 $U$, $V$, $W$의 BF는 각각 -1, 0, 0이 되어서 균형을 이룹니다. 다음 그림과 같습니다.  <a href="https://imgur.com/zQiwLCl"><img src="https://i.imgur.com/zQiwLCl.png" width="300px" title="source: imgur.com" /></a>  구체적인 예를 들어보겠습니다. 하단 좌측그림과 같은 트리에 3.5를 추가한다고 가정해 봅시다. 3.5는 5보다 작으므로 3과 비교하고, 3보다 크므로 4와 비교하고, 4보다는 작고 4의 자식노드가 없습니다. 따라서 3.5가 들어갈 위치는 4의 왼쪽 자식노드가 됩니다. 기존의 이진탐색트리라면 여기에서 삽입 연산을 마칩니다.  <a href="https://imgur.com/Kom2gD0"><img src="https://i.imgur.com/Kom2gD0.png" width="400px" title="source: imgur.com" /></a>  하지만 3.5가 추가되면서 $V$와 $U$의 BF는 각각 -1, 2가 됐습니다. $U$를 루트노드로 하는 서브트리가 재구성 대상입니다. 그런데 $V$는 $U$의 왼쪽 자식노드이고, 새 노드(0.8)는 $V$의 오른쪽 서브트리에 추가됐므로 *double rotation*을 수행해 줍니다. $W$를 중심으로 *left rotation*을 수행한 뒤 다시 $W$를 중심으로 *right rotation*을 합니다. 이렇게 트리를 재구성하면 $W$가 루트노드가 됩니다. 이를 수행한 결과는 상단 우측 그림과 같습니다. 삽입이 우리가 원하는 대로 됐는지 볼까요? 우선 모든 노드의 BF가 1 이하여서 균형을 이루고 있는 점을 확인할 수 있습니다. 상단 우측 그림의 트리를 중위탐색으로 읽은 결과는 다음과 같습니다. 정렬된 순서대로 출력돼 이진탐색트리의 속성을 만족하고 있음을 살펴볼 수 있습니다. > 1, 3, 3.5, 4, 5, 8   ## 시나리오별 rotation 지금까지 설명한 내용을 네 개 시나리오별로 정리하면 다음과 같습니다. ($U$는 BF의 절대값이 2 이상인 노드)  <a href="https://imgur.com/s88CtUh"><img src="https://i.imgur.com/s88CtUh.png" width="300px" title="source: imgur.com" /></a>  - 시나리오1 : $U$의 왼쪽 자식노드의 왼쪽 서브트리 $A$에 새 노드 삽입 : *single right rotation* - 시나리오2 : $U$의 왼쪽 자식노드의 오른쪽 서브트리 $B$에 새 노드 삽입 : *double rotation(left-right)* - 시나리오3 : $U$의 오른쪽 자식노드의 왼쪽 서브트리 $C$에 새 노드 삽입 : *double rotation(right-left)* - 시나리오4 : $U$의 오른쪽 자식노드의 오른쪽 서브트리 $D$에 새 노드 삽입 : *single left rotation* 이를 구현한 파이썬 코드는 다음과 같습니다. ```python   def rebalance(self):     # 현재 노드(루트)~잎새노드에 이르는 경로의     # 모든 노드에 대해 Balance Factor 업데이트     self.update_heights(False)     self.update_balances(False)         # 현재 노드(루트, 위 그림에서 U)의 BF 절대값이 2 이상이면     # 불균형트리이므로 rotation 수행     while self.balance < -1 or self.balance > 1:       # U의 Balance Factor가 2 이상이면       # U의 왼쪽 서브트리 높이가 오른쪽보다 크므로       # 시나리오1 혹은 시나리오2에 해당       if self.balance > 1:         # U의 왼쪽 자식노드의 왼쪽 서브트리보다         # 오른쪽 서브트리의 높이가 클 경우 시나리오2에 해당         # 우선 single left rotation         if self.node.left.balance < 0:           self.node.left.lrotate()           # rotation이 됐으므로 BF 업데이트           self.update_heights()           self.update_balances()         # U의 왼쪽 자식노드의 왼쪽 서브트리가         # 오른쪽 서브트리보다 높이가 클 경우 시나리오1에 해당         # single right rotation (시나리오2도 이 작업 수행)         self.rrotate()         # rotation이 됐으므로 BF 업데이트         self.update_heights()         self.update_balances() 		  # U의 Balance Factor가 -1 이하이면       # U의 오른쪽 서브트리 높이가 왼쪽보다 크므로       # 시나리오3 혹은 시나리오4에 해당       if self.balance < -1: 			  # U의 오른쪽 자식노드의 오른쪽 서브트리보다         # 왼쪽 서브트리의 높이가 클 경우 시나리오3에 해당         # 우선 single right rotation         if self.node.right.balance > 0:           self.node.right.rrotate()           # rotation이 됐으므로 BF 업데이트           self.update_heights()           self.update_balances()         # U의 오른쪽 자식노드의 왼쪽 서브트리보다         # 오른쪽 서브트리보다 높이가 클 경우 시나리오4에 해당         # single left rotation (시나리오2도 이 작업 수행)         self.lrotate()         # rotation이 됐으므로 BF 업데이트         self.update_heights()         self.update_balances() ```   ## 삽입/삭제 연산 AVL 트리의 삽입 연산은 기본적으로 이진탐색트리와 동일합니다. 다만 마지막에 우리가 이미 정의해놓은 rebalance 함수를 호출하는 과정 하나가 다를 뿐입니다. ```python   def insert(self, key):     tree = self.node     newnode = Node(key)     # empty tree일 경우     if tree == None:       # 새 값(key)을 empty tree의 루트(node)에 넣음       self.node = newnode       # 이 루트의 left/right에 새 empty tree 선언       self.node.left = AVLTree()       self.node.right = AVLTree()       debug("Inserted key [" + str(key) + "]")     # 현재 보고 있는 node가 비어있지 않고     # 새 값이 현재 node의 값보다 작으면     # 왼쪽 서브트리에 삽입 (재귀함수 호출)     elif key < tree.key:       self.node.left.insert(key)     # 새 값이 현재 node의 값보다 크면     # 오른쪽 서브트리에 삽입 (재귀함수 호출)     elif key > tree.key:       self.node.right.insert(key)     else:       debug("Key [" + str(key) + "] already in tree.")     # 현재 노드(루트)에 대해 rebalancing     # 재귀함수 형태로 호출되므로 트리 전체의 루트~새 잎새노드     # 경로의 모든 노드에 대해 계산을 수행하게 됨     self.rebalance() ``` 삭제 연산도 이진탐색트리와 동일합니다. 다만 삭제 후에 Balance Factor가 깨진 노드가 있을 수 있으니 이를 위해 rebalance를 해 줍니다.    ## insert example 다음 숫자들을 순서대로 넣어 AVL 트리를 구축해 보겠습니다.  > 3, 2, 1, 4, 5, 6, 7, 16, 15, 14 1까지는 잎새노드에 붙이는 방식으로 삽입하면 됩니다.   <a href="https://imgur.com/wdJh60D"><img src="https://i.imgur.com/wdJh60D.png" width="150px" title="source: imgur.com" /></a>  그런데 1을 삽입하고 보니, 루트노드인 3의 왼쪽 서브트리 높이는 2, 오른쪽은 0이어서 BF는 2가 됐습니다. 루트노드를 기준으로 *rotation*을 수행해야 합니다. 그런데 2 노드는 루트노드의 **왼쪽** 자식노드이고, 새 노드(1)는 2 노드의 **왼쪽** 서브트리에 추가됐으므로 *single rotation(right)*을 수행해 줍니다. 다음과 같습니다.  <a href="https://imgur.com/KBkWut8"><img src="https://i.imgur.com/KBkWut8.png" width="170px" title="source: imgur.com" /></a>  4, 5를 순서대로 붙여 줍니다. 다음과 같습니다.  <a href="https://imgur.com/AXR4xZx"><img src="https://i.imgur.com/AXR4xZx.png" width="250px" title="source: imgur.com" /></a>  그런데 5을 삽입하고 보니, 루트노드의 BF는 -2입니다. 3 노드의 BF도 -2입니다. AVL 트리에서는 둘 중에 3 노드(BF가 2 이상이고 잎새노드로부터 가장 가까운 노드)를 기준으로 *rotation*을 수행합니다. 그런데 4는 3의 **오른쪽** 자식노드이고, 5는 3의 **오른쪽** 서브트리에 삽입됐으므로 *single rotation(left)*를 수행해 줍니다. 다음과 같습니다.  <a href="https://imgur.com/MlraT9I"><img src="https://i.imgur.com/MlraT9I.png" width="200px" title="source: imgur.com" /></a>  6을 삽입합니다.  <a href="https://imgur.com/qZJhduT"><img src="https://i.imgur.com/qZJhduT.png" width="250px" title="source: imgur.com" /></a>  6을 삽입하고 보니 루트노드의 BF가 -2입니다. 4 노드는 루트노드의 **오른쪽** 자식노드이고, 새 노드(6)는 4 노드의 **오른쪽** 서브트리에 삽입됐으므로 루트노드를 기준으로 *single rotation(left)*를 수행해 줍니다. 다음과 같습니다.  <a href="https://imgur.com/26GKpLZ"><img src="https://i.imgur.com/26GKpLZ.png" width="230px" title="source: imgur.com" /></a>  7을 삽입합니다.  <a href="https://imgur.com/ZqPqOyw"><img src="https://i.imgur.com/ZqPqOyw.png" width="270px" title="source: imgur.com" /></a>  7을 삽입하고 보니 5 노드의 BF가 -2입니다. 6은 5 노드의 **오른쪽** 자식노드이고, 새 노드(7)는 5 노드의 **오른쪽** 서브트리에 삽입됐습니다. 따라서 5 노드를 기준으로 *single rotation(left)*를 수행해 줍니다. 다음과 같습니다.  <a href="https://imgur.com/3EE5tz8"><img src="https://i.imgur.com/3EE5tz8.png" width="250px" title="source: imgur.com" /></a>  16과 15를 삽입합니다.  <a href="https://imgur.com/sc83aLP"><img src="https://i.imgur.com/sc83aLP.png" width="280px" title="source: imgur.com" /></a>  15를 삽입하고 보니 7 노드의 BF가 -3입니다. 16은 7 노드의 **오른쪽** 자식노드이고, 새 노드(15)는 16 노드의 **오른쪽** 서브트리에 삽입됐습니다. 따라서 7 노드를 기준으로 *double rotation*을 수행해 줍니다. 다음과 같습니다.  <a href="https://imgur.com/ShDutBi"><img src="https://i.imgur.com/ShDutBi.png" width="300px" title="source: imgur.com" /></a>  14를 삽입합니다.  <a href="https://imgur.com/XQQBXJV"><img src="https://i.imgur.com/XQQBXJV.png" width="300px" title="source: imgur.com" /></a>  14를 삽입하고 보니 6 노드의 BF가 -2입니다. 15는 6 노드의 **오른쪽** 자식노드이고, 새 노드(14)는 15 노드의 **왼쪽** 서브트리에 삽입됐습니다. 따라서 6 노드를 기준으로 *double rotation*을 수행해 줍니다. 다음과 같습니다.   <a href="https://imgur.com/7C3IlIr"><img src="https://i.imgur.com/7C3IlIr.png" width="300px" title="source: imgur.com" /></a>    ## 계산복잡성 AVL 트리의 계산복잡성을 분석해 보겠습니다. 우선 삽입 연산부터 살펴보겠습니다. AVL 트리는 이진탐색트리의 일종입니다. 이진탐색트리 삽입 연산의 계산복잡성은 트리의 높이가 $h$일 때 $O(h)$입니다. 그런데 AVL 트리는 여기에 추가로, 삽입 후에 Balance Factor를 계산하고, BF의 절대값이 2 이상이면서 새 잎새노드와 가장 가까운 조상노드에 대해 *rotation*을 수행해 줍니다.  BF 계산 대상은 새 잎새노드~루트노드에 이르는 경로의 모든 노드들이므로 $O(h)$만큼의 계산량이 필요합니다. AVL 트리(이진탐색트리)가 기본적으로 연결리스트로 구현되고, *rotation* 연산은 부모-자식 간의 관계만 변경해 주면 되기 때문에, *single*이든 *double*이든 계산복잡성은 $O(1)$입니다. 따라서 AVL 트리 삽입 연산의 계산복잡성은 BF 계산과 *rotation* 연산을 고려하더라도 $O(h)$가 됩니다. AVL 트리 삭제 연산 역시 이진탐색트리와 동일한 $O(h)$입니다. AVL 트리는 여기에 더해 삭제 후에 BF를 계산하고, BF가 높아 균형이 깨진 노드에 대해 *rotaion*을 수행합니다. 각각 $O(h)$, $O(1)$이 추가됩니다. 따라서 AVL 트리 삭제 연산 역시 BF 계산과 *rotation* 연산을 고려하더라도 $O(h)$가 됩니다.  요컨대 AVL 트리 삽입/삭제 연산은 트리의 높이 $h$에 의존적이라는 이야기입니다. AVL 트리 노드 수가 $n$개일 때 높이 $h$의 하한은 $2\log_2{n}$이라고 합니다. 따라서 AVL 트리의 계산복잡성은 $O(h)=O(\log{n})$이 됩니다. 이는 $O(n)$인 이진탐색트리보다 낮은 것입니다. *rotation* 같은 복잡한 과정을 거쳐 트리의 높이를 줄여 계산량을 감소시키는 데 성공한 셈이죠.    ## 전체 코드 파이썬 전체 코드는 [이곳](https://gist.github.com/ratsgo/45fa66d15f2f865bf20647983339784b)에 있습니다. 저도 저장 용도로 남깁니다.
KNN␞ 이번 글에서는 **K-최근접이웃(K-Nearest Neighbor, KNN) 알고리즘**을 살펴보도록 하겠습니다. 이번 글은 고려대 강필성 교수님, 김성범 교수님 강의를 참고했습니다. 그럼 시작하겠습니다.  ## 모델 개요 KNN은 새로운 데이터가 주어졌을 때 기존 데이터 가운데 가장 가까운 $k$개 이웃의 정보로 새로운 데이터를 예측하는 방법론입니다. 아래 그림처럼 검은색 점의 범주 정보는 주변 이웃들을 가지고 추론해낼 수 있습니다. 만약 $k$가 1이라면 오렌지색, $k$가 3이라면 녹색으로 **분류(classification)**하는 것이지요. 만약 **회귀(regression)** 문제라면 이웃들 종속변수($y$)의 평균이 예측값이 됩니다. <a href="http://imgur.com/gLBo1gX"><img src="http://i.imgur.com/gLBo1gX.png" width="400px" title="source: imgur.com" /></a> 사실 KNN은 학습이라고 할 만한 절차가 없습니다. 그도 그럴 것이 새로운 데이터가 들어왔을 때, 그제야 기존 데이터 사이의 거리를 재서 이웃들을 뽑기 때문입니다. 그래서 KNN을 모델을 별도로 구축하지 않는다는 뜻으로 **게으른 모델(Lazy model)**이라고 부르는 사람도 있습니다. 조금 점잖게 **Instance-based Learning**이라고 불리기도 합니다. 데이터로부터 모델을 생성해 과업을 수행하는 **Model-based learning**과 대비되는 개념으로, 별도 모델 생성과정 없이 각각의 관측치(instance)만을 이용하여 분류/회귀 등 과업을 수행한다는 취지입니다.  KNN의 **하이퍼파라메터(Hyper parameter)**는 탐색할 이웃 수($k$), 거리 측정 방법 두 가지입니다. $k$가 작을 경우 데이터의 지역적 특성을 지나치게 반영하게 됩니다(overfitting). 반대로 매우 클 경우 모델이 과하게 정규화되는 경향이 있습니다(underfitting). 아래 그림은 범주가 두 개인 데이터의 분류 경계면을 나타낸 것입니다. $k$의 크기에 따라 분류 경계면에 단순해지는 걸 확인할 수 있습니다.  <a href="http://imgur.com/6Ub8CXe"><img src="http://i.imgur.com/6Ub8CXe.png" width="700px" title="source: imgur.com" /></a> 다만 KNN 알고리즘이 이러한 경계면을 직접 만드는 것은 절대 아니고, 새로운 데이터가 주어졌을 때 어느 범주로 분류되는지를 보기 좋게 시각화했다는 점에 주의하셔야 합니다.  ## 거리 지표 KNN은 거리 측정 방법에 따라 그 결과가 크게 달라지는 알고리즘입니다. 몇 가지 살펴보겠습니다. ### Euclidean Distance 가장 흔히 사용하는 거리 척도입니다. 두 관측치 사이의 직선 최단거리를 의미합니다. $$ \begin{align*} X&=({ x }_{ 1 },{ x }_{ 2 },...,{ x }_{ n })\\ Y&=({y }_{ 1 },{ y }_{ 2 },...,{ y }_{ n })\\ { d }_{ (X,Y) }&=\sqrt { { ({ x }_{ 1 }-{y }_{ 1 }) }^{ 2 }+...+{ ({ x }_{ n }-{ y }_{ n }) }^{ 2 } } \\ &=\sqrt { \sum _{ i=1 }^{ n }{ { ({ x }_{ i }-{ y }_{ i }) }^{ 2 } } } \end{align*} $$  예시는 아래와 같습니다. <a href="http://imgur.com/WMpRLvC"><img src="http://i.imgur.com/WMpRLvC.png" width="350px" title="source: imgur.com" /></a> $${ d }_{ (A,B) }=\sqrt { { (0-2) }^{ 2 }+{ (3-0) }^{ 2 }+{ (2-0) }^{ 2 } } =\sqrt { 17 } $$  ### Manhattan Distance A에서 B로 이동할 때 각 좌표축 방향으로만 이동할 경우에 계산되는 거리입니다. 뉴욕 맨해튼의 한 빌딩에서 다른 빌딩으로 이동하려면 격자 모양의 길을 따라가야 하는데요, 이를 떠올려보면 쉽습니다. **Taxi cab Distance**라고도 불립니다.  $${ d }_{ Manhattan(X,Y) }=\sum _{ i=1 }^{ n }{ \left| { x }_{ i }-{ y }_{ i } \right| } $$ 아래 그림([출처](http://rfriend.tistory.com))의 세 경로는 맨해튼 거리 기준으로는 같은 거리입니다. <a href="http://imgur.com/hXR6RFw"><img src="http://i.imgur.com/hXR6RFw.png" width="400px" title="source: imgur.com" /></a>  ### Mahalanobis Distance 변수 내 분산, 변수 간 공분산을 모두 반영하여 거리를 계산하는 방식입니다. 변수 간 상관관계를 고려한 거리 지표입니다. $${ d }_{ Mahalanobis(X,Y) }=\sqrt { { (\overrightarrow { X } -\overrightarrow { Y } ) }^{ T }{ \Sigma }^{ -1 }(\overrightarrow { X } -\overrightarrow { Y } ) } \\ { \Sigma }^{ -1 }=inverse\quad of\quad covariance\quad matrix$$ $X, Y$ 사이의 마할라노비스 거리를 $c$, $X$를 $(x_1, x_2)$, $Y$를 $(0,0)$로 두고 위 식을 풀면 아래와 같이 쓸 수 있습니다. 타원의 방정식 꼴입니다. $${ x }_{ 1 }^{ 2 }{ s }_{ 1 }+2{ x}_{ 1 }{ x }_{ 2 }{ s }_{ 2 }+{ x }_{ 2 }^{ 2 }{ s }_{ 4 }={ c }^{ 2 }\\ { \Sigma }^{ -1 }=\begin{bmatrix} { s }_{ 1 } & { s }_{ 2 } \\ { s }_{ 3 } & { s }_{ 4 } \end{bmatrix}$$ 위 식에서 $c$를 1로 고정시켜 놓고, 공분산행렬을 바꾸면 마할라노비스 거리가 어떻게 달라지는지 살펴보겠습니다. 아래 그림들에 나오는 타원 위의 점들은 마할라노비스 거리 기준으로는 모두 같은 거리입니다. 공분산행렬이 **항등행렬(identity matrix)**일 때 마할라노비스 거리는 유클리디언 거리와 동일합니다. $$\Sigma ={ \Sigma }^{ -1 }=\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$$ <a href="http://imgur.com/WUGQ0UK"><img src="http://i.imgur.com/WUGQ0UK.png" width="300px" title="source: imgur.com" /></a> $$\Sigma =\begin{bmatrix} 4 & 0 \\ 0 & 1 \end{bmatrix},\quad { \Sigma }^{ -1 }=\begin{bmatrix} 1/4 & 0 \\ 0 & 1 \end{bmatrix}$$ <a href="http://imgur.com/YM4Ce6p"><img src="http://i.imgur.com/YM4Ce6p.png" width="300px" title="source: imgur.com" /></a> $$\Sigma =\begin{bmatrix} 4 & \sqrt { 2 } \\ \sqrt { 2 } & 1 \end{bmatrix},\quad { \Sigma }^{ -1 }=\begin{bmatrix} 1/2 & -\sqrt { 2 } \\ -\sqrt { 2 } & 2 \end{bmatrix}$$ <a href="http://imgur.com/o4MIppL"><img src="http://i.imgur.com/o4MIppL.png" width="300px" title="source: imgur.com" /></a> 바로 위 그림의 공분산은 그대로 두고, 이제는 $c$를 바꿔보겠습니다. $c$의 값에 따른 변화는 아래 그림과 같습니다. <a href="http://imgur.com/yO1Z2gS"><img src="http://i.imgur.com/yO1Z2gS.png" width="300px" title="source: imgur.com" /></a> 마지막으로 유클리디언 거리와 비교해 보겠습니다. 아래와 같은 데이터가 주어졌을 때 유클리디언 거리 측정 기준으로는 데이터의 중심과 $A$와의 거리는 $B$와의 거리보다 멉니다. 하지만 마할라노비스 거리 기준으로는 $A$가 가깝습니다. 변수 간 양의 상관관계가 강해서 그 방향과 동떨어진 $B$가 마할라노비스상 거리가 꽤 멀게 계산되기 때문입니다. 이렇듯 마할라노비스 거리는 거리 측정시 변수 내 분산, 변수 간 공분산/상관관계를 모두 고려합니다. <a href="http://imgur.com/ernTmI0"><img src="http://i.imgur.com/ernTmI0.png" width="400px" title="source: imgur.com" /></a>  ### Correlation Distance 데이터의 **pearson correlation**을 거리 척도로 직접 사용합니다. 개별 관측치 하나하나가 아니라 데이터 전체의 경향성을 비교하기 위한 척도입니다. 다시 말해 두 개 데이터 패턴의 유사도를 반영할 수 있습니다. 상관계수는 -1에서 1 사이의 범위를 가지므로, Correlation Distance의 범위는 0에서 2 사이입니다. 0이면 두 데이터의 패턴이 매우 유사한 것이고 2이면 그렇지 않다고 해석할 수 있습니다. $${ d }_{ Corr(X,Y) }=1-\rho _{ XY }$$ 예컨대 아래 그림의 경우 좌측은 Correlation Distance가 가깝게(패턴이 유사), 우측은 멀게 나타날 것입니다. <a href="http://imgur.com/UqHKLcc"><img src="http://i.imgur.com/UqHKLcc.png" width="400px" title="source: imgur.com" /></a>  ### Rank Correlation Distance 데이터의 **Spearman Rank Correlation**을 거리 척도로 직접 사용합니다. 나머지 특징은 correlation distance와 같습니다. $${ d }_{ RankCorr(X,Y) }=1-\rho _{ XY }\\ \rho _{ XY }=1-\frac { 6 }{ n({ n }^{ 2 }-1) } \sum _{ i=1 }^{ n }{ { (rank({ x }_{ i })-rank({ y }_{ i })) }^{ 2 } } $$ 예컨대 지역별 계절 기온 순위(rank)가 아래처럼 주어졌다고 가정해 봅시다. | 지역 | 봄  | 여름 | 가을 | 겨울 | | :--: | :--: | :--: | :--: | :--: | | 서울 | 3  | 1  | 2  | 4  | | 뉴욕 | 3  | 1  | 2  | 4  | | 시드니 | 2  | 4  | 3  | 1  | 그렇다면 서울-뉴욕 간 Rank correlation distance는 아래와 같습니다. $${ d }_{ RankCorr(Seoul,NewYork) }=1-\rho =1-1=0\\ \rho =1-\frac { 6 }{ 4({ 4 }^{ 2 }-1) } \left\{ { (3-3) }^{ 2 }+{ (1-1) }^{ 2 }+{ (2-2) }^{ 2 }+{ { (4-4 }) }^{ 2 } \right\} =1$$ 서울-시드니 간 Rank correlation distance는 아래와 같습니다. $${ d }_{ RankCorr(Seoul,Sydney) }=1-\rho =1-(-1)=2\\ \rho =1-\frac { 6 }{ 4({ 4 }^{ 2 }-1) } \left\{ { (3-2) }^{ 2 }+{ (1-4) }^{ 2 }+{ (2-3) }^{ 2 }+{ { (4-1 }) }^{ 2 } \right\} =-1$$  ## best K 찾기 R 내장 데이터인 iris에 대해 KNN을 수행하였습니다. best K는 데이터마다 다르기 때문에 탐욕적인 방식으로 찾아야 합니다. 아래 그림을 볼까요? <a href="http://imgur.com/qJqbhu7"><img src="http://i.imgur.com/qJqbhu7.png" width="500px" title="source: imgur.com" /></a> $k$를 1부터 10까지 1씩 증가시키면서 오분류율을 점검했습니다. 그 결과 best K는 7로 확인이 되네요. 그런데 iris 말고 다른 데이터에서 $k$가 증가할 수록 오분류율이 계속 낮아진다면 $k$ 범위를 더 넓혀서 탐색할 필요가 있습니다.  아울러 best K를 찾기 위해서는 학습데이터와 검증데이터를 나누고, $k$값에 변화를 주면서 실험을 해야 하는데요. 이런 모든 과정을 대신 해주는 패키지가 R에 있어서 편리하게 사용할 수 있습니다. 분류 문제에 best K를 찾기 위한 코드는 아래와 같습니다. ```R # find best k (classification) library(kknn) knntr <- train.kknn(Target ~ ., data, kmax=10, distance=2, kernel="rectangular") knntr$MISCLASS knntr$best.parameters ```  ## combining rule 1-NN을 제외한 KNN은 주변 이웃의 분포에 따라 예측 결과가 충분히 달라질 수 있습니다. 가장 단순한 결정 방식은 **다수결(Majority voting)**입니다. 이웃들 범주 가운데 빈도 기준 제일 많은 범주로 새 데이터의 범주를 예측하는 것입니다. **가중합(weighted voting)** 방식도 있습니다. 거리($d$)가 가까운(=유사도가 높은) 이웃의 정보에 좀 더 가중치를 줍니다. $1/(1+d)$, $1/(1+d^2)$, $exp(-d)$ 등 단조감소함수이기만 하면 무엇이든 가중치 산출 함수로 쓸 수 있다고 합니다.  ## cut-off 기준 설정 이진분류 문제를 푼다고 할 때 우리가 예측해야 할 관측치 주변 이웃의 범주 비율 정보가 'A : 0.7, B : 0.3'이라고 가정해 봅시다. 별 다른 처리를 하지 않는다면 우리는 이 관측치를 A로 분류하게 됩니다. 두 범주가 절반씩 있을 거라는 상식에서 비롯된 생각입니다. 그런데 범주 간 비율이 불균형한 데이터일 땐 여기에 주의를 해야 합니다. 예컨대 제조업 정상/불량 데이터를 분류하는 문제의 경우 학습데이터에선 정상 관측치가 대다수일 겁니다. 여기에서 새 관측치 주변 이웃의 범주 비율 정보가 '정상 : 0.8, 불량 : 0.2'이라면 불량으로 판정하는 게 합리적일 것입니다. 요컨대 컷오프 기준을 설정할 때 학습데이터 범주의 **사전확률(prior probability)**을 고려해야 한다는 것입니다.  ## KNN 수행시 주의점 KNN 수행 전 반드시 변수를 **정규화(Normalization)**해 주어야 합니다. 가상의 아래 표를 보시죠. | 도시 | 인구(명) | 미세먼지농도(㎍/㎥) | | :--: | :---: | :---------: | | 서울 | 1000만 |   200   | | 시애틀 | 67만 |   40   | 도시별 정보를 모아서 유사한 환경을 지닌 도시를 뽑는 문제를 풀어봅시다. 위 표 기준으로는 거리/유사성 측정시 미세먼지농도 정보는 전혀 반영이 되지 않을 겁니다. 인구 변수에 해당하는 숫자가 훨씬 크기 때문입니다. 따라서 변수별로 평균과 분산을 일치시키는 정규화 작업을 반드시 KNN 적용 전 수행해 주어야 합니다.  ## KNN의 장단점 KNN은 학습데이터 내에 끼어있는 노이즈의 영향을 크게 받지 않으며 학습데이터 수가 많다면 꽤 효과적인 알고리즘이라고 합니다. 특히 마할라노비스 거리와 같이 데이터의 분산을 고려할 경우 매우 **강건(robust)**한 방법론으로 알려져 있습니다. 네이버, 카카오 등 현업에서도 KNN을 두루 사용하고 있는 것으로 전해집니다.  아울러 $k$가 1인 1-NN의 오차 범위는 다음과 같다는 사실이 증명되어 있습니다. (Idealerr=주어진 데이터에 적합 가능한 가장 이상적인 모형의 오차) 바꿔 말해 1-NN에 한해서는 모델 성능을 어느 정도 보장할 수 있다는 이야기입니다.  $$ Err(1-NN)\le 2\times IdealErr $$  그러나 최적 이웃의 수(k)와 어떤 거리척도가 분석에 적합한지 불분명해 데이터 각각의 특성에 맞게 연구자가 임의로 선정해야 하는 단점이 있습니다.  또 새로운 관측치와 각각의 학습 데이터 사이의 거리를 전부 측정해야 하므로 계산 시간이 오래 걸리는 한계점이 존재합니다.  이 때문에 **Locality Sensitive Hashing**, **Network based Indexer**, **Optimized product quantization** 등 KNN의 계산복잡성을 줄이려는 시도들이 여럿 제안되었습니다. 인스턴스 간 거리를 모두 계산하지 않고도 마치 그렇게 한 것처럼 결과를 내는 방법론들입니다. 이에 대해서는 추후에 다시 정리할 계획입니다.  여기까지 읽어주셔서 감사합니다.  
pointer␞ 이번 글에서는 **포인터(pointer)** 개념에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의를 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 개념 포인터란 다른 변수의 메모리 공간주소를 가리키는 변수를 가리킵니다. 포인터는 C, C++ 등과 같은 언어에서는 프로그래머가 직접 제어할 수 있고, 파이썬 등과 같은 언어에서는 완전히 숨겨져 사용할 수 없습니다. 하지만 프로그래머가 사용할 수 없다고 해서 해당 언어에서 포인터가 전혀 쓰이지 않는 건 아니어서 그 개념을 알고 있을 필요가 있습니다.   ## 예시 포인터를 명시적으로 다룰 수 있는 C언어에서 다음과 같은 코드가 있다고 칩시다. ```c int i, *pi, **ppi; i = 5; pi = &i; ppi = &pi; ``` 위 코드를 그림으로 나타내면 다음과 같습니다.  <a href="https://imgur.com/N8JLxU6"><img src="https://i.imgur.com/N8JLxU6.png" width="350px" title="source: imgur.com" /></a>  $i$, $pi$, $ppi$가 가리키는 메모리 주소와 그 실제값은 다음과 같습니다.  | Variable | Address | Value | | :------: | :-----: | :---: | |  $i$  |  100  |  5  | |  $pi$  |  104  | 100 | | $ppi$  |  108  | 104 |  각 notation의 의미와 그 notation이 가리키는 값은 다음과 같습니다.  | Usage |   Meaning   | Value | | :-----: | :---------------: | :---: | | $pi$  |   $i$의 주소   | 100 | | $*pi$ |   $i$의 실제값   |  5  | | $\&pi$ |   $pi$의 주소   | 104 | | $ppi$ |   $pi$의 주소   | 104 | | $*ppi$ | $pi$의 실제값=$i$의 주소 | 100 | | $**ppi$ |   $i$의 실제값   |  5  |
compare␞ 이번 글에서는 **discriminative model**과 **generative model**을 비교해보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## discriminative model *discriminative model*이란 데이터 $X$가 주어졌을 때 레이블 $Y$가 나타날 조건부확률 $p(Y$\|$X)$를 직접적으로 반환하는 모델을 가리킵니다. 레이블 정보가 있어야 하기 때문에 지도학습(supervised learning) 범주에 속하며 $X$의 레이블을 잘 구분하는 **결정경계(decision boundary)**를 학습하는 것이 목표가 됩니다. *discriminative model*은 [generative model]()에 비해 가정이 단순하고, 학습데이터 양이 충분하다면 좋은 성능을 내는 것으로 알려져 있습니다. 선형회귀와 로지스틱회귀는 *disciminative model*의 대표적인 예시입니다.  ## generative model *generative model*이란 데이터 $X$가 생성되는 과정을 두 개의 확률모형, 즉 $p(Y)$, $p(X$\|$Y)$으로 정의하고, 베이즈룰을 사용해 $p(Y$\|$X)$를 간접적으로 도출하는 모델을 가리킵니다. *generative model*은 레이블 정보가 있어도 되고, 없어도 구축할 수 있습니다. 전자를 [지도학습기반의 *generative model*]()이라고 하며 [선형판별분석](https://ratsgo.github.io/machine%20learning/2017/03/21/LDA/)이 대표적인 사례입니다. 후자는 [비지도학습 기반의 *generative model*]()이라고 하며 가우시안믹스처모델, [토픽모델링](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/06/01/LDA/)이 대표적인 사례입니다. *generative model*은 *discriminative model*에 비해 가정이 많습니다. 그 가정이 실제 현상과 맞지 않는다면 *generative model*의 성능은 *discriminative model*보다 성능이 좋지 않을 수 있지만, 가정이 잘 구축되어 있다면 이상치에도 강건하고 학습데이터가 적은 상황에서도 좋은 예측 성능을 보일 수 있습니다. *generative model*은 **범주의 분포(distribution)**을 학습하는 것이 목표가 됩니다. 또한 *generative model*은 일반적인 [베이지안 추론](https://ratsgo.github.io/statistics/2017/06/30/bayesinfer/)과 마찬가지로 학습데이터가 많을 수록 *discriminative model*과 비슷한 성능으로 수렴하는 경향이 있다고 합니다. 아울러 *generative model*은 $p(X$\|$Y)$을 구축하기 때문에 이 모델을 활용해 $X$를 샘플링할 수도 있습니다.   ## data distribution 여기에서 '데이터의 분포'라는 개념이 아리송합니다. 예를 들어보겠습니다. 우리가 가진 데이터가 사람 얼굴 사진이라고 칩시다. 이미지 크기가 64×64×3이라면 우리의 데이터($x$)는 이만한 크기의 벡터들일 것입니다. 이 사진(벡터)들을 어떤 기준에 따라 일렬로 세웠다고 가정해 보겠습니다.  <a href="https://imgur.com/FVhbZOx"><img src="https://i.imgur.com/FVhbZOx.png" width="500px" title="source: imgur.com" /></a>  우리가 가지고 있는 사진 데이터셋이 동양인들 중심이라면 검은 머리색을 하고 있는 사진이 나타날 확률은 꽤 높을 수 있습니다. 바꿔 말해 검은 머리색을 하고 있는 사진들을 $x$축에 표시하면 $x_3$ 언저리에 위치하고 $p_{data}(x_3)$은 가장 높은 값을 가지게 될 것이라는 얘기입니다. 반대로 머리색이 금발인 사진들이 $x_4$쯤에 위치하고 $p_{data}(x_4)$는 낮은 값을 가집니다. 더 나아가, 처음 보는 이상한 사진들이라면 발생확률이 0에 가까울 것입니다. *generative model*의 목적 가운데 하나는 데이터의 분포를 학습하는 것입니다. 다시 말해 우리가 구축하려는 모델에 데이터를 넣으면 실제 데이터의 확률에 가깝게 값을 반환하게끔 만들고 싶다는 이야기입니다. 이를 도식화한 그림은 다음과 같습니다.  <a href="https://imgur.com/ZXQz3r1"><img src="https://i.imgur.com/ZXQz3r1.png" width="400px" title="source: imgur.com" /></a>    ## Deep Generative Model *Deep Generative Model*이란 딥러닝을 활용한 *generative model*입니다. 데이터의 분포(distribution)를 학습하고, 이로부터 새로운 데이터 $X$를 생성하는 것이 목적입니다. 딥러닝은 데이터의 분포를 모사하거나, 벡터 간 변환에 뛰어난 성능을 지니기 때문에 최근 *generative model*에 딥러닝 기법이 널리 쓰이고 있습니다. *Deep Generative Model*을 도식화한 그림은 다음과 같습니다.  <a href="https://imgur.com/SgRIzIP"><img src="https://i.imgur.com/SgRIzIP.png" width="500px" title="source: imgur.com" /></a>   ## 차이 다음 그림들은 *disciriminative model*과 *generative model* 간 차이를 직관적으로 나타낸 것입니다.  <a href="https://imgur.com/4leE3wr"><img src="https://i.imgur.com/4leE3wr.jpg" width="400px" title="source: imgur.com" /></a> *generative model은 사후확률을 간접적으로, disciriminative model은 직접적으로 도출한다.*  <a href="https://imgur.com/alus0zQ"><img src="https://i.imgur.com/alus0zQ.png" width="400px" title="source: imgur.com" /></a> *generative model은 데이터 범주의 분포를, disciriminative model은 결정경계를 학습한다.*  
treecode␞ 이번 포스팅에선 한번에 하나씩의 설명변수를 사용하여 예측 가능한 규칙들의 집합을 생성하는 알고리즘인 **의사결정나무(Decision Tree)**를 파이썬 코드로 구현하는 법을 다뤄보도록 하겠습니다. 이 글은 '밑바닥부터 시작하는 데이터과학(조엘 그루스 지음, 인사이트 펴냄)'을 정리하였음을 먼저 밝힙니다. 의사결정나무에 대한 일반적인 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/03/26/tree/)을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.  ## 분석 대상 데이터 주어진 학습데이터는 다음과 같습니다. 클래스는 True, False 두 개입니다. ```python inputs = [   ({'level': 'Senior', 'lang': 'Java', 'tweets': 'no', 'phd': 'no'}, False),   ({'level': 'Senior', 'lang': 'Java', 'tweets': 'no', 'phd': 'yes'}, False),   ({'level': 'Mid', 'lang': 'Python', 'tweets': 'no', 'phd': 'no'}, True),   ({'level': 'Junior', 'lang': 'Python', 'tweets': 'no', 'phd': 'no'}, True),   ({'level': 'Junior', 'lang': 'R', 'tweets': 'yes', 'phd': 'no'}, True),   ({'level': 'Junior', 'lang': 'R', 'tweets': 'yes', 'phd': 'yes'}, False),   ({'level': 'Mid', 'lang': 'R', 'tweets': 'yes', 'phd': 'yes'}, True),   ({'level': 'Senior', 'lang': 'Python', 'tweets': 'no', 'phd': 'no'}, False),   ({'level': 'Senior', 'lang': 'R', 'tweets': 'yes', 'phd': 'no'}, True),   ({'level': 'Junior', 'lang': 'Python', 'tweets': 'yes', 'phd': 'no'}, True),   ({'level': 'Senior', 'lang': 'Python', 'tweets': 'yes', 'phd': 'yes'}, True),   ({'level': 'Mid', 'lang': 'Python', 'tweets': 'no', 'phd': 'yes'}, True),   ({'level': 'Mid', 'lang': 'Java', 'tweets': 'yes', 'phd': 'no'}, True),   ({'level': 'Junior', 'lang': 'Python', 'tweets': 'no', 'phd': 'yes'}, False) ] ```   ## 엔트로피 구하기 분기된 영역의 엔트로피를 구하는 코드는 다음과 같습니다. ```python import math from collections import Counter, defaultdict def entropy(class_probabilites):   # 클래스에 속할 확률을 입력하면 엔트로피 계산   # 확률이 0인 경우는 제외함   return sum(-p * math.log(p, 2) for p in class_probabilites if p is not 0) def class_probabilities(labels):   # 레이블의 총 개수 계산 : ex) 5   total_count = len(labels)   # Counter(labels) = {Class0 : 3, Class1 : 2}   # class0 prob = 0.6, class1 prob = 0.4 반환   return [float(count) / float(total_count) for count in Counter(labels).values()] def data_entropy(labeled_data):   # 데이터를 받아서 레이블 정보만 뺀 뒤 리스트로 저장   # ex) labels = [0, 0, 0, 1, 1]   labels = [label for _, label in labeled_data]   # 클래스 비율 계산   probabilities = class_probabilities(labels)   # 클래스 비율을 토대로 엔트로피 계산   return entropy(probabilities) def partition_entropy(subsets):   # subset은 레이블이 있는 데이터의 list의 list   # 그에 대한 엔트로피를 계산한 뒤 모든 subset의 엔트로피 합친 값 반환   total_count = sum(len(subset) for subset in subsets)   # subset A의 엔트로피는 A 요소별 엔트로피의 합 * A의 영역 비율   return sum(data_entropy(subset) * len(subset) / total_count for subset in subsets) def partition_by(inputs, attribute):   # attribute 기준으로 inputs를 부분 집합으로 분리   # attribute 변수 내에 3개 값이 있다면 그룹수 = 3   # ex) level 기준 = Senior, Mid, Junior 3개 그룹   groups = defaultdict(list)   for input in inputs:     # 특정 attribute의 값을 불러옴     key = input[0][attribute]     # 이 input을 올바른 list에 추가     groups[key].append(input)   return groups def partition_entropy_by(inputs, attribute):   # 주어진 파티션에 대응되는 엔트로피를 계산   partitions = partition_by(inputs, attribute)   return partition_entropy(partitions.values()) ```   ## Tree 구축하기 데이터에 재귀적 분기를 실시해 분기된 영역의 순도를 높이는 작업을 반복합니다. 다음과 같습니다. ```python from functools import partial def build_tree(inputs, split_candidates=None):   # 첫 분기라면 입력 데이터의 모든 변수가 분기 후보   if split_candidates is None:     # 'lang', 'tweets', 'phd', 'level' 모두 후보     split_candidates = inputs[0][0].keys()   # 입력 데이터에서 범주별 개수를 세어 본다   num_inputs = len(inputs)   num_class0 = len([label for _, label in inputs if label])   num_class1 = num_inputs - num_class0   # class0(true)이 하나도 없으면 False leaf 반환   if num_class0 == 0: return False   # class1(false)이 하나도 없으면 Ture leaf 반환   if num_class1 == 0: return True   # 파티션 기준으로 사용할 변수가 없다면   if not split_candidates:     # 다수결로 결정     # class0(true)가 많으면 true,     # class1(false)가 많으면 false 반환     return num_class0 >= num_class1   # 아니면 가장 적합한 변수를 기준으로 분기   best_attribute = min(split_candidates,             key=partial(partition_entropy_by, inputs))   partitions = partition_by(inputs, best_attribute)   new_candidates = [a for a in split_candidates            if a != best_attribute]   # 재귀적으로 서브트리를 구축   subtrees = { attribute_value : build_tree(subset, new_candidates)         for attribute_value, subset in partitions.iteritems()}   # 기본값   subtrees[None] = num_class0 > num_class1   return (best_attribute, subtrees) ```   ## 예측하기 학습된 Tree와 새로운 데이터가 주어졌을 때 해당 데이터가 어떤 범주에 속하는지를 맞추는 예측 코드는 다음과 같습니다. ```python def classify(tree, input):   # 주어진 tree를 기준으로 input을 분류   # 잎 노드이면 값 반환   if tree in [True, False]:     return tree   # 그게 아니면 데이터의 변수로 분기   # 키로 변수값, 값으로 서브트리를 나타내는 dict 사용   attribute, subtree_dict = tree   # 만약 입력된 데이터 변수 가운데 하나가   # 기존에 관찰되지 않았다면 None   subtree_key = input.get(attribute)   # 키에 해당하는 서브트리가 존재하지 않을 때   if subtree_key not in subtree_dict:     # None 서브트리를 사용     subtree_key = None   # 적절한 서브트리를 선택   subtree = subtree_dict[subtree_key]   # 그리고 입력된 데이터를 분류   return classify(subtree, input) ```   ## 코드 실행 학습 및 예측 실행 코드는 다음과 같습니다. ```python tree = build_tree(inputs) print(classify(tree,     { "level" : "Junior",      "lang" : "Java",      "tweets" : "yes",      "phd" : "no"} )) # -> True print(classify(tree,     { "level" : "Junior",      "lang" : "Java",      "tweets" : "yes",      "phd" : "yes"} )) # -> False ``` 
bst␞ 이번 글에서는 자료구조의 일종인 **이진탐색트리(Binary Search Tree)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님, 그리고 역시 같은 대학의 김황남 교수님 강의와 위키피디아를 정리하였음을 먼저 밝힙니다. 파이썬 코드는 [이곳](https://gist.github.com/jakemmarsh/8273963)을 기본으로 하되 중위순회 등 요소를 제가 추가하였습니다. 그럼 시작하겠습니다.   ## concepts 이진탐색트리란 이진탐색(binary search)과 연결리스트(linked list)를 결합한 자료구조의 일종입니다. 이진탐색의 효율적인 탐색 능력을 유지하면서도, 빈번한 자료 입력과 삭제를 가능하게끔 고안됐습니다.  예컨대 이진탐색의 경우 탐색에 소요되는 계산복잡성은 $O(\log{n})$으로 빠르지만 자료 입력, 삭제가 불가능합니다. 연결리스트의 경우 자료 입력, 삭제에 필요한 계산복잡성은 $O(1)$로 효율적이지만 탐색하는 데에는 $O(n)$의 계산복잡성이 발생합니다. 두 마리 토끼를 잡아보자는 것이 이진탐색트리의 목적입니다. 이진탐색트리는 다음과 같은 속성을 지니며 아래 그림과 같습니다. <a href="https://imgur.com/nCYjtI7"><img src="https://i.imgur.com/nCYjtI7.png" width="300px" title="source: imgur.com" /></a> - 완전이진트리이다. - 각 노드의 왼쪽 서브트리에는 해당 노드의 값보다 작은 값을 지닌 노드들로 이루어져 있다. - 각 노드의 오른쪽 서브트리에는 해당 노드의 값보다 큰 값을 지닌 노드들로 이루어져 있다. - 중복된 노드가 없어야 한다. - 왼쪽 서브트리, 오른쪽 서브트리 또한 이진탐색트리이다. 이진탐색트리를 순회할 때는 중위순회(inorder) 방식을 씁니다. (왼쪽 서브트리-노드-오른쪽 서브트리 순으로 순회) 이렇게 하면 이진탐색트리 내에 있는 모든 값들을 정렬된 순서대로 읽을 수 있습니다. 다음 예시와 같습니다.  <a href="https://imgur.com/SSusVoP"><img src="https://i.imgur.com/SSusVoP.png" width="250px" title="source: imgur.com" /></a> > 중위순회 : 1, 3, 5, 7, 8, 10 한편 트리 순회와 관련 자세한 내용은 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/10/21/tree/)을 참고하시면 좋을 것 같습니다.   ## operations 이진탐색트리의 핵심 연산은 검색(retreive), 삽입(insert), 삭제(delete) 세 가지입니다. 이밖에 이진탐색트리 생성(create), 이진탐색트리 삭제(destroy), 해당 이진탐색트리가 비어 있는지 확인(isEmpty), 트리순회(tree traverse) 등의 연산이 있습니다. 파이썬 코드는 다음과 같습니다. ```python class Node:   def __init__(self, val):     self.val = val     self.leftChild = None     self.rightChild = None class BinarySearchTree:   def __init__(self):     self.root = None   def setRoot(self, val):     self.root = Node(val) ```   ### retreive/find 아래 이진탐색트리에서 10을 탐색(retreive, search)한다고 가정해 봅시다. 이진탐색트리는 부모노드가 왼쪽 자식노드보다 크거나 같고, 오른쪽 자식노드보다 작거나 같다는 점에 착안하면 효율적인 탐색이 가능합니다. <a href="https://imgur.com/SSusVoP"><img src="https://i.imgur.com/SSusVoP.png" width="250px" title="source: imgur.com" /></a> 우선 루트노드(7)와 10을 비교합니다. 10은 7보다 큽니다. 따라서 왼쪽 서브트리(1, 3, 5)는 고려할 필요가 없습니다. 탐색공간이 대폭 줄어든다는 얘기입니다. 이번엔 오른쪽 서브트리의 루트노드(8)과 10을 비교합니다. 10은 8보다 큽니다. 따라서 오른쪽 서브트리의 루트노드(10)과 10을 비교합니다. 원하는 값을 찾았습니다.  요컨대 10을 탐색할 때 비교하는 값은 다음과 같습니다. > 7, 8, 10 이번엔 4를 탐색해보겠습니다. 위와 같은 방식으로 4를 탐색할 때 비교하는 값은 다음과 같습니다. > 7, 3, 5 하지만 5까지 비교했는데도 원하는 값(4)을 찾지 못했습니다. 그 다음은 5의 왼쪽 서브트리를 비교할 차례인데 5는 트리의 잎새노드(leaf node)여서 서브트리가 존재하지 않습니다. 이 경우 '값을 찾지 못했다'고 반환하고 탐색을 종료합니다. 이진탐색트리의 탐색 연산에 소요되는 계산복잡성은 트리의 높이(루트노드-잎새노드에 이르는 엣지 수의 최대값)가 $h$일 때 $O(h)$가 됩니다. 최악의 경우 잎새노드까지 탐색해야 하기 때문입니다. 이 때 $h$번 비교 연산을 수행합니다. 파이썬 코드는 다음과 같습니다. ```python   def find(self, val):     if (self.findNode(self.root, val) is False):       return False     else:       return True   def findNode(self, currentNode, val):     if (currentNode is None):       return False     elif (val == currentNode.val):       return currentNode     elif (val < currentNode.val):       return self.findNode(currentNode.leftChild, val)     else:       return self.findNode(currentNode.rightChild, val) ```   ### insert 이번엔 삽입 연산을 살펴 보겠습니다. 새로운 데이터는 트리의 잎새노드에 붙입니다. 예컨대 탐색 예시에서 제시한 트리에 4를 추가한다고 가정해 봅시다. 아래와 같습니다.  <a href="https://imgur.com/HBthwOc"><img src="https://i.imgur.com/HBthwOc.png" width="250px" title="source: imgur.com" /></a>  그런데 위 트리에서 7과 3사이에 4를 추가해도 이진탐색트리의 속성이 깨지지 않음을 확인할 수 있습니다. 하지만 이진탐색트리가 커질 경우 이렇게 트리의 중간에 새 데이터를 삽입하게 되면 서브트리의 속성이 깨질 수 있기 때문에 삽입 연산은 반드시 잎새노드에서 이뤄지게 됩니다. 이진탐색트리의 가장 왼쪽 잎새노드는 해당 트리의 최소값, 제일 오른쪽 잎새노드는 최대값이 됩니다. 만약 위 트리에서 100을 추가하려고 한다면 제일 오른쪽 잎새노드의 오른쪽 자식노드를 만들고 여기에 붙이면 됩니다.  이진탐색트리의 삽입 연산에 소요되는 계산복잡성은 트리의 높이(루트노드-잎새노드에 이르는 엣지 수의 최대값)가 $h$일 때 $O(h)$가 됩니다. 삽입할 위치의 잎새노드까지 찾아 내려가는 데 $h$번 비교를 해야 하기 때문입니다. 물론 탐색 연산과 비교해 삽입이라는 계산이 추가되긴 하나, 연결리스트 삽입의 계산복잡성은 $O(1)$이므로 무시할 만한 수준입니다. 파이썬 코드는 다음과 같습니다. ```python   def insert(self, val):     if (self.root is None):       self.setRoot(val)     else:       self.insertNode(self.root, val)   def insertNode(self, currentNode, val):     if (val <= currentNode.val):       if (currentNode.leftChild):         self.insertNode(currentNode.leftChild, val)       else:         currentNode.leftChild = Node(val)     elif (val > currentNode.val):       if (currentNode.rightChild):         self.insertNode(currentNode.rightChild, val)       else:         currentNode.rightChild = Node(val) ```   ### delete 삭제 연산은 탐색, 삽입보다는 약간 복잡합니다. 삭제 결과로 자칫 이진탐색트리의 속성이 깨질 수 있기 때문입니다. 가능한 세 가지 경우의 수를 모두 따져보겠습니다. 먼저 삭제할 노드에 **자식노드가 없는 경우**(case 1)입니다. 이 케이스라면 해당 노드(아래 예시에서 42)를 그냥 없애기만 하면 됩니다. 다음과 같습니다.  <a href="https://imgur.com/d8sOy3z"><img src="https://i.imgur.com/d8sOy3z.png" width="150px" title="source: imgur.com" /></a>   이번엔 삭제할 노드에 **자식노드가 하나 있는 경우**(case 2)입니다. 이 케이스라면 해당 노드를 지우고, 해당 노드의 자식노드와 부모노드를 연결해주면 됩니다. 아래 트리에서 20을 삭제한다고 칩시다.   <a href="https://imgur.com/RqCRxO9"><img src="https://i.imgur.com/RqCRxO9.png" width="500px" title="source: imgur.com" /></a>  20을 루트노드로 하는 서브트리의 모든 값은 20의 부모노드인 30보다 작거나 같습니다. 이진탐색트리의 속성 때문입니다. 따라서 20을 지우고, 20의 하나뿐인 자식노드(25)와 부모노드(30)를 연결해도 이진탐색트리의 속성이 깨지지 않는 걸 확인할 수 있습니다. 마지막으로 삭제할 노드에 **자식노드가 두 개 있는 경우**(case 3)를 살펴보겠습니다. 아래 트리에서 16을 삭제해야 한다고 칩시다. 그런데 기존처럼 16을 무작정 지우게 되면 13의 위치가 애매해집니다. 계산복잡성을 줄이기 위해서는 트리의 요소값들을 크게 바꾸지 않고 원하는 값(16)만 삭제할 수록 좋은데, 아무래도 새로운 방법을 고민해 봐야 할 것 같습니다.   <a href="https://imgur.com/yKzDYZu"><img src="https://i.imgur.com/yKzDYZu.png" width="500px" title="source: imgur.com" /></a>  이해를 돕기 위해 16을 삭제하기 전 위 트리 각 요소를 중위순회 방식(왼쪽 서브트리-노드-오른쪽 서브트리 순으로 순회)으로 읽어보겠습니다. 다음과 같이 정렬된 순으로 나타나 이진탐색트리 속성을 만족하고 있음을 확인할 수 있습니다. > 4, 10, 13, 16, 20, 22, 25, 28, 30, 42 이 리스트와 예시 그림을 보면 16의 왼쪽 서브트리에 속한 모든 값은 16보다 작고, 오른쪽 서브트리에 속한 모든 값은 16보다 큰 것을 확인할 수 있습니다. 특히 13을 predecessor(삭제 대상 노드의 왼쪽 서브트리 가운데 최대값), 20을 successor(삭제 대상 노드의 오른쪽 서브트리 가운데 최소값)라고 합니다. 트리를 중위순회 방식으로 늘여뜨려 표시하면 16 바로 앞에 13이 있고, 바로 뒤에 20이 있기 때문에 각각 이런 이름이 붙은 것 같습니다. 따라서 아래와 같이 삭제할 노드인 16 위치에 20을 복사해 놓고, 기존 20 위치에 있던 노드를 삭제하게 되면 정렬된 순서를 유지(=이진탐색트리 속성을 만족)하면서도 원하는 결과를 얻을 수 있게 됩니다. 이는 위 그림에서도 확인할 수 있습니다. (물론 16 위치에 predecessor인 13을 놓고, 기존 13 위치에 있던 노드를 삭제해도 원하는 결과를 얻을 수 있습니다) > 4, 10, 13, ~~16~~ **20**, ~~20~~, 22, 25, 28, 30, 42 이진탐색트리 구조상 successor(삭제 대상 노드의 오른쪽 서브트리의 최소값)는 자식노드가 하나이거나, 하나도 존재하지 않습니다. 각각 살펴보면 다음과 같습니다. - successor의 자식노드가 하나인 케이스 : 위 예시 그림과 같습니다. 삭제 대상 노드의 오른쪽 서브트리가 30을 루트노드로 하는 트리일 때, 이 트리의 맨 왼쪽 노드인 20은 하나의 자식노드(25)를 갖습니다. - successor의 자식노드가 존재하지 않는 케이스 : 삭제 대상 노드의 오른쪽 서브트리가 아래 그림과 같을 때에는 successor는 자식노드를 가지지 않습니다.  <a href="https://imgur.com/po0R4GB"><img src="https://i.imgur.com/po0R4GB.png" width="400px" title="source: imgur.com" /></a> 마찬가지로 왼쪽 서브트리의 맨 오른쪽 노드인 predecessor 또한 자식노드가 하나이거나, 하나도 존재하지 않습니다. 따라서 자식노드가 두 개인 경우(case 3)에는 다음과 같이 삽입 연산을 수행하면 됩니다(successor 기준). 1. 삭제 대상 노드의 오른쪽 서브트리를 찾는다. 2. successor(1에서 찾은 서브트리의 최소값) 노드를 찾는다. 3. 2에서 찾은 successor의 값을 삭제 대상 노드에 복사한다. 4. successor 노드를 삭제한다. 4번 successor 노드를 삭제하는 과정은 case 1나 case2에 해당합니다. 이미 언급했듯이 successor는 자식노드가 하나이거나, 하나도 존재하지 않기 때문입니다.  이번엔 삽입연산의 계산복잡성을 따져 보겠습니다. Big-O notation으로는 최악의 케이스를 고려해야 하므로 가장 연산량이 많은 case 3(삭제 대상 노드의 자식노드가 두 개인 경우)이 분석 대상입니다.  트리의 높이가 $h$이고 삭제대상 노드의 레벨이 $d$라고 가정해 보겠습니다. 1번 과정에서는 $d$번의 비교 연산이 필요합니다. 2번 successor 노드를 찾기 위해서는 삭제 대상 노드의 서브트리 높이($h-d$)에 해당하는 비교 연산을 수행해야 합니다. 3번 4번은 복사하고 삭제하는 과정으로 상수시간이 걸려 무시할 만 합니다. 종합적으로 따지면 $O(d+h-d)$, 즉 $O(h)$가 됩니다.   ### traverse 이진탐색트리의 중위순회 파이썬 코드는 다음과 같습니다. ```python   def traverse(self):     return self.traverseNode(self.root)   def traverseNode(self, currentNode):     result = []     if (currentNode.leftChild is not None):       result.extend(self.traverseNode(currentNode.leftChild))     if (currentNode is not None):       result.extend([currentNode.val])     if (currentNode.rightChild is not None):       result.extend(self.traverseNode(currentNode.rightChild))     return result ```    ## 한계점 이진탐색트리 핵심 연산인 탐색, 삽입, 삭제의 계산복잡성은 모두 $O(h)$입니다. 트리의 높이에 의해 수행시간이 결정되는 구조입니다. 그러나 트리가 다음과 같은 경우 문제가 됩니다.  <a href="https://imgur.com/XR4fujQ"><img src="https://i.imgur.com/XR4fujQ.png" width="150px" title="source: imgur.com" /></a>  위 그림의 경우 노드 수는 적은 편인데 높이가 4나 됩니다. 균형이 안 맞기 때문입니다. 극단적으로는 $n$개의 노드가 크기 순으로 일렬로 늘어뜨려져 높이 또한 $n$이 되는 경우도 이진트리탐색에 해당합니다. 결과적으로 이진탐색트리의 계산복잡성은 $O(n)$이라는 얘기입니다. 이래가지고서는 탐색 속도가 $O(\log{n})$으로 빠른 이진탐색을 계승했다고 보기 어렵습니다. 이 때문에 트리의 입력, 삭제 단계에 트리 전체의 균형을 맞추는 이진탐색트리의 일종인 **AVL Tree**가 제안되었습니다.  
bayesinfer␞ 이번 글에서는 베이지안 추론에 대해 살펴보도록 하겠습니다. 이 글은 '밑바탁부터 시작하는 데이터과학(조엘 그루스 지음, 인사이트 펴냄)'과 ‘Think Bayes(앨런 B. 다우니 지음, 권정민 옮김, 한빛미디어 펴냄)’을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 문제 정의와 베타분포 동전이 하나 있습니다. 우리는 이 동전이 공평한 동전인지 아닌지 알아보고 싶습니다. 이 동전을 던졌을 때 앞면이 나올 확률이 $p$라고 한다면 이 $p$가 어떤 값인지 추정해보고 싶은 겁니다. 동전던지기 실험은 **이항분포**를 따릅니다. 이항분포란 성공확률이 $p$이고, 그 결과가 성공 혹은 실패뿐인 실험을 $n$번 반복시행할 때 성공횟수의 분포를 가리킵니다.  이항분포 파라메터 $p$의 **사전확률**은 **베타분포**를 따릅니다. 여기에서 사전확률이란 데이터를 관측하기 전 가설로 세운 확률을 뜻합니다. 이 때문에 우리가 알고 싶은 앞면이 나올 확률 $p$는 베타분포를 사전분포로 사용하게 됩니다. 베타분포도 정규분포처럼 중심이 높은 포물선 형태를 갖는데요. 베타분포의 파라메터는 $α$와 $β$이며 그 중심은 다음과 같습니다. > $α$ / ($α + β$) $p$의 사전확률과 관련해 $α$는 성공(앞면), $β$는 실패(뒷면)와 연관이 있고 $α, β$의 크기는 믿음의 크기와 관련이 있습니다. 만약 동전에 대해 어떤 선입견도 취하고 싶지 않다면 $α, β$를 모두 1로 정하면 됩니다. 앞면이 55%의 경우로 나타난다고 '굳게' 믿고 있다면 $α$를 55로, $β$를 45로 가정할 수도 있습니다. 이항분포 파라메터 $p$의 **사후확률** 역시 베타분포를 따릅니다. 여기에서 사후확률이란 데이터를 확인한 이후의 가설 확률을 가리킵니다. 바로 우리가 알고 싶은 값이죠. 사후확률은 사전확률의 업데이트 버전 정도로 이해하면 좋을 것 같습니다.  ## 추론 과정 동전을 여러번 던져서 앞면이 $h$번, 뒷면이 $t$번 나왔다고 칩시다. 베이즈 규칙을 활용해 유도하면 $p$의 사후확률 분포는 파라메터가 $α+h, β+t$인 베타분포를 따른다고 합니다. 이제 동전을 10번 던져서 앞면을 3번 관측했다고 가정해 보겠습니다. 실험 대상 동전이 공평한 동전이라고 생각해 $α, β$를 모두 1로 두었다고 하면, 앞면이 나올 확률 $p$의 사후분포는 파라메터가 1+3, 1+7인 베타분포가 될 겁니다. 공평한 동전이라는 생각이 다소 강하게 들어 $α, β$를 각각 20으로 정했었다면 $p$의 사후분포는 Beta(20+3, 20+7)이 됩니다. 즉, 동전이 뒷면으로 살짝 편향되었다는 것으로 믿음이 바뀔 것을 의미합니다. 앞면이 잘 나오는 동전이라는 확신 때문에 $p$의 사전분포를 Beta(30, 10)로 두었다면 사후분포는 Beta(30+3, 10+7)이 됩니다. 이 경우 동전이 아직도 앞면이 편향되어 있다고 믿지만, 처음 생각했던 것보다는 덜 강하게 믿는다는 걸 뜻합니다. 데이터 관측 후 $α, β$ 변화에 따른 $p$의 사후분포 변화는 다음 그림과 같습니다. 예컨대 Beta(4,8)의 경우 중심이 0.33인데요, $p$의 사후확률이 0.33일 가능성이 제일 높다는 뜻으로 받아들일 수 있습니다. <a href="http://imgur.com/P7L4A8W"><img src="http://i.imgur.com/P7L4A8W.png" width="400px" title="source: imgur.com" /></a> 동전을 많이 던져볼 수록 관측 전 가정한 사전분포는 점점 의미가 없어집니다. 예를 들어 편향된 동전이라는 사전 믿음이 아무리 강했을지라도 동전을 2000번 던져서 앞면에 1000번 나왔다면 생각을 바꿀 수밖에 없기 때문입니다. 데이터가 충분하다면 서로 다른 사전확률을 가지고 시작한다고 해도 동일한 사후확률로 수렴하는 경향이 있습니다. 이러한 과정을 통해 $p$가 가지는 값을 확률적으로 추정할 수 있게 됩니다. 이를 베이지안 추론이라고 합니다. 이는 **p-value**을 이용한 가설검정 결과와는 접근 방식이 근본적으로 다릅니다. 예컨대 다음과 같습니다. > **베이지안 추론** : 관측한 데이터와 사전분포를 고려해볼 때 동전의 앞면이 나올 확률이 49~51%일 경우는 5%밖에 되지 않는다 > > **가설검정** : 동전이 공평하다면 이렇게 편향된 데이터를 관측할 경우는 5%밖에 되지 않는다 베이지안 추론 과정은 사전에 가설을 세운 뒤 실험(데이터 관측) 결과로 가설을 조금씩 업데이트하면서 완성됩니다. 평소 우리가 경험적으로 체감하고 있는 확률들(예컨대 전철에서 자리가 날 확률, 휴강을 할 확률 등등)은 사실 베이지안 추론과 본질상 다르지 않은 것 같습니다.  ## 시각화 위 그림을 만드는 데 사용한 파이썬 코드는 다음과 같습니다. ```python import math from matplotlib import pyplot as plt def B(alpha, beta):   return math.gamma(alpha) * math.gamma(beta) / math.gamma(alpha + beta) def beta_pdf(x, alpha, beta):   # [0, 1] 구간 밖에서는 밀도가 없음   if x < 0 or x > 1:     return 0   return x ** (alpha - 1) * (1 - x) ** (beta - 1) / B(alpha, beta) xs = [x / 100.0 for x in range(0,100)] plt.plot(xs,[beta_pdf(x,alpha=4,beta=8) for x in xs],'-',label='Beta(4,8)') plt.plot(xs,[beta_pdf(x,alpha=23,beta=27) for x in xs],'--',label='Beta(23,27)') plt.plot(xs,[beta_pdf(x,alpha=33,beta=17) for x in xs],':',label='Beta(33,17)') plt.legend() plt.title('Beta pdfs') plt.show() ```   ## 구현 동전을 250번 던졌는데 앞면은 140번, 뒷면은 110번 나왔다고 칩시다. 앞면이 나온 확률 x 100을 $x$라고 할 때 코드는 다음과 같습니다. thinkbayes.py는 [이곳](http://greenteapress.com/wp/think-bayes/)에서 내려받을 수 있습니다. ```python import thinkbayes as tb class Euro(tb.Suite):   """Represents hypotheses   about the probability of heads."""   def Likelihood(self, data, hypo):     """Computes the likelihood of the data     under the hypothesis.     hypo: integer value of x,     the probability of heads (0-100)     data: tuple of (number of heads, number of tails)     """     x = hypo / 100.0     heads, tails = data     # 이항분포의 우도함수     like = x**heads * (1-x)**tails     return like ``` Euro 클래스는 앞면과 뒷면이 나올 확률이 동일하다는 가정에서 출발해 관측 결과를 업데이트한 값을 반환합니다. 다음과 같이 관측 결과를 업데이트한 뒤 suite 객체에 포함된 MaximumLikelihood 함수를 호출하면 56(=140/250*100)이 반환됩니다.  한편 suite.Mean() 함수는 가설(x)에 사후확률을 곱한 값을 모두 더한 평균값을 반환하는데요. 호출 결과 55.95238095가 나왔습니다. ```python # 가설 설정(x=1~100) 및 객체 선언 suite = Euro(xrange(0,101)) # 관측치 업데이트 data = (140, 110) suite.Update(data) # 최대 우도에 해당하는 x 반환 suite.MaximumLikelihood() # 평균 반환 suite.Mean() ``` $x$의 사전분포는 베타분포입니다. 베타분포의 모양은 $α, β$ 에 따라 달라지는데요. 만약 사전분포가 $α, β$에 대한 베타분포이고, 앞면 $h$와 뒷면 $t$의 데이터를 가지고 있다면 사후확률은 $α+h, β+t$에 대한 베타분포가 됩니다. 이를 구현한 코드는 다음과 같습니다. ```python # 베타분포 선언, alpha=beta=1 beta = tb.Beta() # 관측치 업데이트 # alpha = 1 + 140 # beta = 1 + 110 beta.Update(data) # 베타분포의 중심(평균) 반환 print beta.Mean() ``` beta.Mean()은 베타분포의 중심을 출력해줍니다. 그 결과는 0.5595238로 suite.Mean()의 결과와 동일합니다. 
rbtree␞ 이번 글에서는 **Red-Black(RB) 트리**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아를 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concepts RB 트리는 다음 다섯 가지 속성을 만족하는 [이진탐색트리(Binary Search Tree)](https://ratsgo.github.io/data%20structure&algorithm/2017/10/22/bst/)의 일종입니다. 1. 모든 노드는 빨간색, 검은색 둘 중 하나다. 2. 루트노드는 검은색이다. 3. 모든 잎새노드(NIL)는 검은색이다. 4. 어떤 노드가 빨간색이라면 두 개 자식노드는 모두 검은색이다. (따라서 빨간색 노드가 같은 경로상에 연이어 등장하지 않는다) 5. '각 노드~자손 잎새노드 사이의 모든 경로'에 대해 검은색 노드의 수가 같다. RB 트리의 예는 다음 그림과 같습니다. 위 다섯가지 속성을 만족하고 있음을 확인할 수 있습니다.  <a href="https://imgur.com/VTJrloJ"><img src="https://i.imgur.com/VTJrloJ.png" width="400px" title="source: imgur.com" /></a>  노드의 높이 $h$는 해당 노드로부터 잎새노드에 이르는 가장 긴 경로의 엣지 수를 가리킵니다. 임의의 노드 $x$의 Black-height는 $x$부터 잎새노드에 이르는 경로상에 있는 검은색 노드의 수로 $bh(x)$라고 표기합니다. $x$가 검은색 노드일 경우 1을 빼주며 잎새노드(NIL)의 $bh$는 0입니다. $h$와 $bh$를 계산하는 예시는 다음과 같습니다.  <a href="https://imgur.com/QEaR7se"><img src="https://i.imgur.com/QEaR7se.png" width="400px" title="source: imgur.com" /></a>   ## insert RB 트리의 삽입연산은 이진탐색트리의 삽입과 동일합니다. 그런데 삽입 후에도 RB 트리 다섯 가지 속성을 유지하고 있어야 합니다. 이 속성을 유지하기 위해 몇 가지 작업을 수행해 줍니다. (이진탐색트리의 연산을 기본으로 하되 이후 추가 작업을 수행해준다는 점에서 [AVL 트리](https://ratsgo.github.io/data%20structure&algorithm/2017/10/27/avltree/)와 유사합니다) 삽입할 새 요소 $z$는 빨간색으로 둡니다. $z$와 검정색 부모노드를 공유하는 형제노드(sibling node)를 $y$라고 두겠습니다.    ### case1 (case 1-1) $y$가 빨간색이면서 $z$가 *left child*인 경우입니다. 아래 그림에서 $z$가 삽입되면서 빨간색 노드가 연이어 등장하게 됐습니다. RB 트리의 네 번째 속성에 위배된다는 이야기죠. 이 경우 노드의 색을 바꿔서 다시 칠해 줍니다.  <a href="https://imgur.com/g3Om3my"><img src="https://i.imgur.com/g3Om3my.png" width="600px" title="source: imgur.com" /></a>  (case 1-2) $y$가 빨간색이면서 $z$가 *right child*인 경우에도 색을 바꿔서 다시 칠해 줍니다.  <a href="https://imgur.com/9AVDc8r"><img src="https://i.imgur.com/9AVDc8r.png" width="600px" title="source: imgur.com" /></a>   ### case2, case3 (case2) $y$가 검은색이면서 $z$가 *right child*인 경우에도 빨간색 노드가 연이어 등장해 RB 트리의 네 번째 속성에 위배됩니다. case2인 경우 *double rotation*을 수행해 줍니다.  (case3) $y$가 검은색이면서 $z$가 *left child*인 경우에는 *single rotation*을 수행해 줍니다. *single rotation*과 *double rotation* 관련 자세한 내용은 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/10/27/avltree/)을 참고하시면 좋을 것 같습니다.  <a href="https://imgur.com/0f8o1t1"><img src="https://i.imgur.com/0f8o1t1.png" width="600px" title="source: imgur.com" /></a>   ### 정리 시나리오별 *rotation* 수행은 다음과 같이 합니다. 삽입된 노드가 꺾여 있는 형태면 일단 *rotation*을 한 번 수행해 이것을 펴주고, 펴진 형태의 노드에 대해 *rotation*을 한 번 더 수행합니다. 이미 펴져 있는 형태로 노드가 삽입된 경우라면 *rotation*을 한 번만 수행합니다.  <a href="https://imgur.com/XSzopC5"><img src="https://i.imgur.com/XSzopC5.png" width="600px" title="source: imgur.com" /></a>   ## insert example 다음 숫자들을 차례대로 RB 트리에 삽입해 보겠습니다. > 10, 85, 15, 70, 20, 60, 30, 50 삽입되는 새 노드의 색깔은 빨간색입니다. 그런데 10은 루트노드이므로 RB 트리의 1번 속성을 맞추기 위해 검정색으로 바꿔 줍니다. 다음과 같습니다.  <a href="https://imgur.com/vr0XNmD"><img src="https://i.imgur.com/vr0XNmD.png" width="300px" title="source: imgur.com" /></a>  85, 15를 삽입합니다. 그런데 빨간색 노드가 연이어 등장해 RB 트리의 4번 속성을 위반했네요. 그런데 새로 삽입된 15와 검은색 부모노드를 공유하는 형제노드(그림에는 안그려져 있지만 10의 왼쪽 자식노드는 검은색 NIL 노드입니다)가 검은색이고, 빨간색 두 노드가 꺾여져 있는 형태이므로 *double rotation*을 수행해 줍니다.  <a href="https://imgur.com/SfQ1gSp"><img src="https://i.imgur.com/SfQ1gSp.png" width="500px" title="source: imgur.com" /></a>  70을 삽입합니다. 빨간색 노드가 연이어 등장했습니다. 그런데 70과 검정색 부모를 공유하는 형제노드 10이 빨간색입니다. case1에 해당하므로 색을 15와 70은 빨간색, 10과 85는 검정색으로 다시 칠해 줍니다. 그런데 15는 루트노드이므로 검정색으로 그대로 놔둡니다.  <a href="https://imgur.com/fYdi7Sz"><img src="https://i.imgur.com/fYdi7Sz.png" width="550px" title="source: imgur.com" /></a>  20을 삽입합니다. 빨간색 노드가 연이어 등장했습니다. 그런데 20과 검정색 부모를 공유하는 형제노드 NIL(85의 *right child*)이 검정색입니다. 새로 삽입된 20이 노드 모양이 펴져 있는 형태이므로 case3에 해당하며 *single rotation*을 수행해 줍니다.  <a href="https://imgur.com/K2gnVme"><img src="https://i.imgur.com/K2gnVme.png" width="600px" title="source: imgur.com" /></a>  60을 삽입합니다. 빨간색 노드가 연이어 등장했습니다. 그런데 60과 검정색 부모를 공유하는 형제노드 85의 색이 빨간색입니다. case1에 해당하므로 70과 60의 색을 빨간색으로, 20과 85의 색을 검정색으로 다시 칠해 줍니다.  <a href="https://imgur.com/lTWbjJF"><img src="https://i.imgur.com/lTWbjJF.png" width="600px" title="source: imgur.com" /></a>  30을 삽입합니다. 빨간색 노드가 연이어 등장했습니다. 그런데 30과 검정색 부모를 공유하는 형제노드 NIL(20의 *left child*)이 검정색입니다. 그리고 꺾여 있는 형태로 case2에 해당합니다. *double rotation*을 수행합니다.  <a href="https://imgur.com/VbvI0T4"><img src="https://i.imgur.com/VbvI0T4.png" width="600px" title="source: imgur.com" /></a>  50을 삽입합니다. 빨간색 노드가 연이어 등장했습니다. 이번엔 조금 복잡하므로 차례대로 살펴보겠습니다.  - 50과 검정색 부모를 공유하는 형제노드 20이 빨간색입니다. case1에 해당합니다. 30과 50을 빨간색, 20과 60을 검정색으로 칠해 둡니다. - 70, 30을 보니 빨간색 노드가 연이어 등장했습니다. 그런데 30과 검정색 부모를 공유하는 형제노드 10이 검정색입니다. 아울러 15, 70, 30이 꺾여져 있는 형태이므로 case2에 해당합니다. *double rotaion*을 수행해 줍니다.  <a href="https://imgur.com/5WtB5YM"><img src="https://i.imgur.com/5WtB5YM.png" width="700px" title="source: imgur.com" /></a>   ## delete RB 트리에서 검정색 노드를 삭제할 때는 삭제 연산으로 RB 트리의 속성이 깨지지 않도록 해야 합니다. 이는 삽입 연산 때 고려했던 것과 유사한 방식으로 *rotation*을 구현함으로써 해결할 수 있습니다. 다만 빨간색 노드를 삭제할 때는 그냥 삭제를 수행하면 된다고 합니다.   ## 계산복잡성 RB 트리 전체 높이를 $h$라고 할 때 삽입, 삭제, 검색 등 RB 트리의 계산복잡성은 $O(h)$입니다. 그런데 RB 트리의 노드 수가 $n$개라면 높이 상한은 $2\log{n+1}$이라고 합니다. 따라서 RB 트리의 계산복잡성은 $O(\log{n})$이 됩니다.
dynamic␞ 이번 글에서는 **다이내믹 프로그래밍(Dynamic Programming)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아를 참고해 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept 다이내믹 프로그래밍이란 계산 결과를 **저장(Memoization)**해 두었다가 재활용하는 기법입니다. 본질적으로는 모든 경우의 수를 다 계산해보는 전역 탐색(exhaustive search) 기법입니다만, 이미 저장해 둔 계산 결과를 다시 써먹는 방식으로 반복되는 계산을 줄입니다.  다이내믹 프로그래밍은 원 문제를 작은 부분문제로 쪼개어 푼 뒤 그 결과를 합치는 **분할정복(divide and conquer)**과는 차이가 있습니다. 분할정복 문제는 부분문제가 서로 독립적일 때 적용하는 기법입니다. 분할정복은 부분문제의 해를 재사용하지 않고 그저 합치기만 합니다. 하지만 다이내믹 프로그래밍은 부분문제가 서로 겹칠 때 씁니다. 덕분에 부분문제의 해(solution)를 재사용할 수 있습니다.  다이내믹 프로그래밍은 *optimal value*와 *optimal solution*을 찾는 데 관심이 있습니다. 따로 설명드리겠지만, 행렬 스칼라 곱 연산을 다이내믹 프로그래밍으로 풀 경우 스칼라 곱 최소 횟수가 *optimal value*, 이 횟수에 대응하는 행렬 곱 순서가 *optimal solution*이 됩니다. 행렬 스칼라 곱 연산과 관련해서는 이따가 자세히 살펴보겠습니다.  이 글에서는 다이내믹 프로그래밍을 적용할 수 있는 몇 가지 예시를 살펴보도록 하겠습니다. 다만 다이내믹 프로그래밍 기법의 일종인 *Assembly-Line Scheduling*과 비터비 알고리즘(viterbi algorithm)은 [은닉마코프모델](https://ratsgo.github.io/machine%20learning/2017/03/18/HMMs/), [최대엔트로피마코프모델](https://ratsgo.github.io/machine%20learning/2017/11/04/MEMMs/), [Conditional Random Fields](https://ratsgo.github.io/machine%20learning/2017/11/10/CRF/) 등 시퀀스 예측 모델에 많이 쓰이기 때문에 [이 글](https://ratsgo.github.io/data%20structure&algorithm/2017/11/14/viterbi/)에서 별도로 다루었습니다.    ## Rod Cutting *Rod cutting* 문제는 우리가 가지고 있는 통나무를 어떻게 쪼개서 팔아야 최대 수익을 낼 수 있는지를 따지는 겁니다. 예컨대 통나무 길이에 따라 다음과 같이 시장 가격이 매겨졌다고 칩시다. (길이의 단위는 미터, 가격은 만원) | 길이 $i$ | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | | :------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | | 가격 $p_i$ | 1  | 5  | 8  | 9  | 10 | 17 | 17 | 20 | 고려해야 할 경우의 수는 꽤 많습니다. 가령 길이가 4미터인 통나무를 자르는 가짓수는 아래와 같이 8가지나 됩니다. 여기서 최대 이익을 내는 *optimal solution*은 길이가 2미터인 통나무 두개로 쪼개 파는 경우입니다. 이 때 *optimal value*는 10만원이 됩니다. ($n$미터 통나무라면 고려해야할 경우의 수는 $2^{n-1}$가지)  <a href="https://imgur.com/gZjcpXr"><img src="https://i.imgur.com/gZjcpXr.png" width="500px" title="source: imgur.com" /></a>  그런데 문제를 자세히 살펴보면 부분문제가 겹친다는 걸 알 수 있습니다. 가령 1미터짜리 통나무의 *optimal value*는 1입니다(문제 정의상 더 잘게 자를 수 없으므로). 2미터의 *optimal value*는 다음과 같이 구합니다. - **1미터짜리 통나무+1미터짜리 통나무를 자르는 모든 경우의 수 가운데 최적 solution** : 가격표에서 가져온 1 + 직전 계산결과(1미터짜리의 *optimal value*) 1 = 2 - **자르지 않고 2미터짜리 통나무 통째로 파는 경우** : 가격표에서 가져온 5 - **가장 큰 값 선택** : $max(2, 5)=5$ 3미터의 *optimal value*는 다음과 같이 구합니다. - **1미터짜리 통나무+2미터짜리 통나무를 자르는 모든 경우의 수 가운데 최적 solution** : 가격표에서 가져온 1 + 직전 계산결과(2미터짜리의 *optimal value*) 5 = 6 - **2미터짜리 통나무+1미터짜리 통나무를 자르는 모든 경우의 수 가운데 최적 solution** : 가격표에서 가져온 5 + 직전 계산결과(1미터짜리의 *optimal value*) 1 = 6 - **자르지 않고 3미터짜리 통나무 통째로 파는 경우** : 가격표에서 가져온 8 - **가장 큰 값 선택** : $max(6,6,8)=8$ 우리의 관심인 4미터의 *optimal value*는 다음과 같이 구합니다. - **1미터짜리 통나무+3미터짜리 통나무를 자르는 모든 경우의 수 가운데 최적 solution** : 가격표에서 가져온 1 + 직전 계산결과(3미터짜리의 *optimal value*) 8 = 9 - **2미터짜리 통나무+2미터짜리 통나무를 자르는 모든 경우의 수 가운데 최적 solution** : 가격표에서 가져온 5 + 직전 계산결과(2미터짜리의 *optimal value*) 5 = 10 - **3미터짜리 통나무+1미터짜리 통나무를 자르는 모든 경우의 수 가운데 최적 solution** : 가격표에서 가져온 8 + 직전 계산결과(1미터짜리의 *optimal value*) 1 = 9 - **자르지 않고 4미터짜리 통나무 통째로 파는 경우** : 가격표에서 가져온 9 - **가장 큰 값 선택** : $max(9,10,9,9)=10$ 이를 파이썬으로 구현한 코드는 다음과 같습니다([출처]()). 약간 손질하였습니다. ```python INT_MIN = -32767 def cutRod(price, n):  	# val : optimal value   # 0으로 초기화   val = [0 for x in range(n+1)]   for i in range(1, n+1):     max_val = INT_MIN     for j in range(i):      	 if max_val < price[j] + val[i-j-1]:       	max_val = price[j] + val[i-j-1]     val[i] = max_val   return val[n]  arr = [1, 5, 8, 9, 10, 17, 17, 20] size = len(arr) print("Maximum Obtainable Value is " + str(cutRod(arr, size))) ```   ## Longest Common Subsequence 최장공통부분수열(Longest Common Subsequence) 문제 또한 다이내믹 프로그래밍으로 풀 수 있습니다. 이를 풀려면 먼저 공통수열의 길이를 구해야 합니다. 3가지 경우가 있을 수 있습니다. - `case1` 수열 $A$와 $B$의 마지막 원소가 공통부분 수열인 경우 : *abcd*와 *ad*의 LCS 길이는 2이다. 이는 *abc*와 *a*의 LCS 길이에 1을 더한 것과 같다. - `case2` 수열 $A$의 마지막 원소가 공통부분 수열이 아닌 경우 : *abcd*와 *ac*의 길이는 2이다. 이는 *abc*와 *ac*의 LCS 길이와 같다. - `case3` 수열 $B$의 마지막 원소가 공통부분 수열이 아닌 경우 : *abcd*와 *ade*의 길이는 2이다. 이는 *abcd*와 *ad*의 LCS 길이와 같다. 수열 $A$와 $B$의 마지막 원소가 서로 같다면 `case1`에 해당하고, 다르다면 `case2`이거나 `case3`에 해당합니다. 그런데 우리는 제일 긴 수열에 관심이 있으므로 `case2`, `case3` 가운데 최대값을 취합니다. 입력 문자열 길이에 해당하는 행렬(0으로 초기화)을 만들어 놓고 행렬을 위와 같은 규칙을 바탕으로 업데이트합니다. 이를 파이썬으로 구현한 코드는 다음과 같습니다. ```python def lcs(a, b):   lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]   # row 0 and column 0 are initialized to 0 already   for i, x in enumerate(a):     for j, y in enumerate(b):       if x == y:         lengths[i+1][j+1] = lengths[i][j] + 1       else:         lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1]) ``` *optimal value*를 찾았으니 이제는 *optimal solution*을 찾을 차례입니다. 위 코드를 바탕으로 *ABCBDAB*, *BDCABA* 두 수열의 LCS 길이를 아래 그림처럼 구했다고 칩시다. <a href="https://imgur.com/RAjAqcq"><img src="https://i.imgur.com/RAjAqcq.png" width="300px" title="source: imgur.com" /></a> 위 행렬 계산은 우측 하단 모서리인 (7, 6)에서 시작합니다. 대상 칸의 값과 바로 위 칸의 값(4)이 같으면 한 칸 위로 옮깁니다. 다르다면 대상 칸의 값과 바로 왼쪽 칸의 값을 비교해 같으면 한 칸 왼쪽으로 옮깁니다. 바로 위 칸과 왼쪽 칸 모두 대상 칸의 값과 다르다면 해당 위치의 원소가 공통수열의 원소에 해당하므로 결과 *result* 변수에 저장하고, 대각선으로 한 칸 옮깁니다. 이를 구현한 파이썬 코드는 다음과 같습니다. ```python   # read the substring out from the matrix   result = ""   x, y = len(a), len(b)   while x != 0 and y != 0:     if lengths[x][y] == lengths[x-1][y]:       x -= 1     elif lengths[x][y] == lengths[x][y-1]:       y -= 1     else:       result = a[x-1] + result       x -= 1       y -= 1   return result ```    ## Matrix chain multiplication  행렬끼리의 곱셈은 곱셈 순서에 따라 스칼라 곱 횟수에 큰 차이가 날 수 있습니다. 예컨대 행렬 $A$의 차원수가 2×3, $B$는 3×4, $C$는 4×5이고 셋을 곱한다고 가정해 봅시다. $(AB)C$의 경우 2×3×4+2×4×5, 총 64회의 스칼라곱 연산을 수행해야 합니다. 그런데 $A(BC)$의 경우 3×4×5+2×3×5, 총 90회의 스칼라곱 연산을 수행해야 합니다. 행렬 곱을 수행하기 전에 스칼라 곱 횟수를 미리 가늠해서 전체적인 계산량을 줄이려는 것이 이 문제의 관심이 되겠습니다. 그런데 행렬 곱셈은 다음과 같이 부분문제가 서로 겹치기 때문에 다이내믹 프로그래밍을 적용할 수 있습니다.  - $ABC$ : $(AB)C$, $A(BC)$ - $ABCD$ : $(AB)(CD)$, $A(BC)D$, ... - ... 이를 파이썬으로 구현한 코드는 다음과 같습니다([출처](http://www.geeksforgeeks.org/dynamic-programming-set-8-matrix-chain-multiplication/)). 약간 손질하였습니다. ```python def MatrixChainOrder(p):   n = len(p)   m = [[0 for x in range(n)] for x in range(n)]   for L in range(2, n):     for i in range(1, n - L + 1):       j = i + L - 1       m[i][j] = float('inf')       for k in range(i, j):         # q = cost/scalar multiplications         q = m[i][k] + m[k + 1][j] + \         	p[i - 1] * p[k] * p[j]         if q < m[i][j]:           m[i][j] = q   return m[1][n - 1] ``` 위 코드에서 $p$는 행렬 크기를 나타냅니다. 예컨대 [1,2,3,4]라면 행렬 $A$의 차원수가 1×2, $B$는 2×3, $C$는 3×4이고 셋을 곱한다는 뜻입니다. 
CAM2␞ 이번 글에서는 문장이 주어졌을 때 극성(polarity)을 분류하고, 해당 극성으로 분류되는 데 가장 큰 영향을 끼친 단어나 구를 찾아내는 모델에 대해 설명해 보도록 하겠습니다. 이 글은 고려대 강필성 교수님 지도로 출간된 아래 제 석사 졸업논문을 쉽게 풀어쓴 것입니다. 아울러 데모도 준비해 두었습니다.  <embed type="text/html" src="http://54.180.16.64:8000/" style="width:90%" height="200">  
milano␞ 지난 4일부터 1주일 간 이탈리아를 여행하고 있다. 마지막 행선지는 '세계 패션 중심' 밀라노(Milano). 명성에 걸맞게 내로라할 만한 명품 브랜드 상점들이 거리에 즐비했다. 간판과 쇼윈도부터 행인들의 눈길을 확 끈다. 물건 그 자체보다는 감성과 경험을 내세운다. (내 입장에서)처음 보는 브랜드인데도 쇼윈도만 유심히 보면 이 가게가 뭘 팔고 뭘 내세울지 한 눈에 이해할 수 있었다. 책 한 권 팔더라도 고급지다(서점 *Rizzoli*). 브랜딩이니, 마케팅이니, 플랫폼이니 고민해야 하는 순간이 온다면 오늘 거닐었던 밀라노 거리 상점들을 잊지 말아야겠다. *(2018년 2월 10일 밀라노)*  <img src="https://ratsgo.github.io/public/img/mil1.jpeg"> <img src="https://ratsgo.github.io/public/img/mil2.jpeg"> <img src="https://ratsgo.github.io/public/img/mil3.jpeg"> <img src="https://ratsgo.github.io/public/img/mil4.jpeg">     
japan␞ 여러 지인이 추천한 올해의 책 가운데 하나가 바로 [학교에서 가르쳐주지 않는 일본사](http://book.naver.com/bookdb/book_detail.nhn?bid=12333229)였다. 요지는 이렇다.  '일본은 1868년 메이지유신이 선포된 지 40여 년만에 세계 질서를 주도하는 열강의 대열에 오르는 기염을 토했다. 하지만 일본이 순식간에 그런 기적을 일궈냈다고 보는 건 오해다. 17세기 초반 에도 막부 성립에서 19세기 중반 메이지유신 이전까지 에도시대 260여년동안 권위와 시장 간의 긴장, 경제의 분화와 전문화, 인적/물적 이동성의 확대 등 드라마틱하고 익사이팅한 축적을 거쳐 포텐이 터진 결과다.' 저자는 20여 년 간 외교관 생활을 하다가 한일관계에 기여할 수 있는 자신만의 영역을 개척해보고 싶다는 생각으로 외교부를 그만두고 최근 서울에서 우동집을 하고 있다. 독특한 저자 이력만큼이나 책 제목도, 논지도 눈길을 끌기에 충분했다. ~~다소 일본 중심적인 시각인 것 같다, 그래서 '우리나라 학교에서 가르쳐 주지 않는 일본 역사'라는 느낌도 들지만..~~ 인상적인 구절 몇 개 정리해본다. (*2017. 12. 24. 전주*) <br> - 한국의 역사 교과서에 등장하는 에도시대의 일본은 임진왜란 때 납치한 도공이나 조선통신사에게 한 수 배우며 선진 문물을 습득한 문명의 변방국이다. 고대 중화문명 확산 경로의 선후관계에서 비롯된 한국인들의 일본에 대한 문화적 우월감은 에도시대로까지 자연스럽게 연장되고 고정관념화되어 있다. 단언컨대, 일본의 근세 260여 년을 그런 식으로 바라보는 나라는 한국뿐이다. - **천하보청**의 묘미는 국가에서 거두는 국부(國富)가 고스란히 인프라로 전환되었다는 것이다. 만약 쇼군이 중앙의 군주로서 징세, 즉 화폐나 현물의 형태로 생산량의 일정 부분을 거두어 갔다면 그 과정에서 많은 비효율과 왜곡된 자본 축적/잉여가 발생하였을 것이다. 일본은 천하보청에 따라 세금 징수가 아니라 '결과물' 형태로 의무를 부과했기 대문에 관리비용 등의 매몰비용(sunk cost)이나 착복으로 인한 증발 없이 모든 투입이 실물 인프라로 이어졌다. (중략) 현대 경제학으로 말하면 승수효과가 매우 높은 재정정책이 절묘한 타이밍에 시행된 것이다. (중략) 말단에서 세금의 형태로 걷히는 생산물은 천하보청을 거치면서 노임, 자재 대금 형태로 재분배되었다. 이러한 직접적인 자원 투입의 결과로 높은 수준의 공공인프라가 창출되자 한층 더 경제활동이 촉진되고, 이는 다시 말단 세금 납부자의 생활 개선으로 이어졌다.  \* 천하보청(天下普請) : 쇼군이 다이묘들에게 부과하는 공공사업 역무(役務). 에도 막부 초대 쇼군 도쿠가와 이에아스는 에도성, 하천 정비 및 농수로/운하망/상하수도 건설 등 인프라 건설에 다이묘들을 동원했다. - **참근교대**에는 막대한 비용이 소요된다. 적게는 100명에서 많게는 500명 이상의 대규모 인원이 수백 킬로미터가 넘는 거리를 이동하는데, 소요되는 비용은 전적으로 다이묘가 부담해야 했다. (중략) 가장 큰 혜택을 본 것은 교통, 숙박의 요지와 에도, 오사카 등 대도시의 상공인과 노동자였다. (중략) 많은 천하보청이 참근교대와 연계되어 시행되었다. 참근교대에 수반하여 고카이도(五街道)라 불리는 간선도로가 대대적으로 확충되고, 에도성을 비롯한 도시기반 건설에 필요한 자재의 운송을 위하여 해로와 수로가 정비되었다. 18세기 초엽에 미곡을 비롯한 각종 물자의 집산지인 오사카로부터 에도를 연결하는 복수의 민영 정기항로가 개설되었고, 18세기 말엽에는 전국을 연결하는 상업 해운망이 완성되었다. 해운망의 발달은 미곡, 술, 간장, 각종 생필품, 지역 특산물이 오사카로 집산되었다가 에도에 공급되면서 전국적으로 유통되는 데 기여하였고.. (중략) 다이묘라는 재향 지배층의 의무적 소비 지출 증가가 상인 및 도시노동자 계층의 소득으로 흡수되는 현상은 현대적으로 말하면 일종의 낙수효과(trickle down effect)가 발생했다고 할 수 있다.  \* 참근교대제(參勤交代制) : 쇼군이 모든 번(藩)의 다이묘들로 하여금 1년 단위로 정기적으로 에도와 그들의 영지를 오가게 하는 일종의 '인질 제도'. - 안게리아겐고와게에는 'handkerchief'가 하나후키로 번역되어 있다. 한국말로 하면 '코닦기' 정도의 의미이다. 일본에는 없는 물건이지만 그 용도를 파악하여 적절한 대역어를 조어한 것이다. 이보다 더 관념적인 단어에 대해서는 더 많은 고민이 필요하다. 'liberty'를 자유(自由)로, 'economy'를 경제(經濟)로, 'physics'를 물리(物理)로, 'chemistry'를 화학(化學)으로 번역한 것에서 볼 수 있듯이 일본에 없는 관념을 번역하기 위해 사전의 편찬자들은 서양의 개념을 수용한 후 그를 자국어로 변용하는 언어의 재창조 작업에 몰두하였다. 최초로 그러한 임무가 맡겨진 사람들 입장에서는 단어 하나하나가 문화의 충돌이었고 문명의 이양이었다. 일본의 근대화 과정에서 번역이 갖는 의미는 각별하다. 일본의 근대화에는 서구의 관념을 일본의 관념으로 변환시키고 내재화하는 과정이라 할 수 있다. 개항 이후 이루어진 일본의 급속한 근대화는 그보다 100년 전 부터 수많은 지식인들의 고뇌가 담긴 '언어의 통로'가 있었기에 가능한 것이었다. (최초의 <u>영일사전은 1814년 일본 막부 주도</u>로 만들어졌다는 점 언급) (중략) 참고로, 최초의 **영한사전은** (선교사) <u>언더우드(H. G. Underwood)가 집필</u>한 '한영 영한자전'이다. 조선에는 마땅한 인쇄시설이 없어 <u>1890년 요코하마</u>에서 발행되었다. (괄호 안 및 강조표시는 인용자)  \* 안게리아겐고와게(諳厄利亞言語和解) : 1811년 나가사키에서 만들어진 영어의 기본체계와 기초 어휘가 정리된 책자(사전). - 중국은 그 부당한 처사(불평등 상호 조약)를 영국에게 당했고, 일본은 미국에게 당했고, 조선은 일본에게 당했다. 한국의 역사 교육은 이러한 불평등의 강요가 얼마나 천인공노할 짓인지를 만천하에 드러내는 데에 초점이 맞춰져 있다. 강요의 주체인 일본의 정의롭지 못함과 무도함을 밝히는 것을 교육의 목표로 삼는다. 그것은 그것대로 각국의 가치관과 교육관에 따라 그럴 수 있다. 일본도 한국과 마찬가지로 구미 열강 세력에 당한 불평등에 대해 분개하고 분노한다. 그러나 일본의 역사 교육은 거기에서 머무르지 않는다. '유럽으로부터 불평등한 조항을 강요당한 것은 일본의 사법제도가 그들로부터 인정받지 못한 탓이다. 그들로부터 인정을 받을 수 있는 사법제도를 구축하고 불평등을 해소해야 한다.' 당시 일본의 위정자들은 그렇게 생각했다. 1854년 개국 이래 불평등조약의 개정은 일본 사회의 지상과제가 되었다. 내로라하는 뜻있는 지식인들이 구미로 건너가 그들의 법제를 습득하고 외국의 전문가를 초빙해 지도를 청하고 국가 지성의 총력을 기울여 법제의 근대화에 매진한다. 이러한 노력의 결과, 1880년 형법과 형사소송법 제정을 필두로 1889년 헌법, 1896년 민법 등 소위 '법전'이라 불리는 6법 체계가 완성되었다. 유럽의 법제를 철저히 연구하여 제정한 법률들이다. 유럽국들이 더 이상 법체계의 이질성, 미성숙성을 이유로 불평등을 강요할 수 없도록 준비를 단단히 한 일본은 당당하게 기존의 불평등 조항의 파기와 개정을 요구한다. 일본 정부는 1892년 포르투갈의 영사재판권을 포기시키고, 1894년 청일전쟁의 승리를 기화로 영국을 강하게 몰아붙여 기존의 불평등조약을 개정한 '일영통상항해조약'을 체결하고 사법 주권을 회복하였다. 유럽세력의 좌장인 영국과 조약을 개정하면 그다음부터는 일사천리이다. 20세기가 되기 전에 일본은 구미 국가들과의 관계에서 사법 주권을 회복하였다. 불평등조약을 강요당한 분함을 계기로 대등한 관계로 인정받겠다는 집념이 기어코 불평등조약의 폐기를 이끌어냈고, 그러한 굴욕이 오히려 조기 근대화의 자극제로 작용한 것이다. 이러한 집단 지성 축적의 스토리와 그 기틀을 닦은 지식인들의 고뇌와 성취의 에피소드가 후세에 전해져 일본인들의 역사관과 세계관을 형성하였다. 일본인들은 그렇게 역사를 바라보고, 가르치고, 배운다. 그리고 그것이 가장 깨끗한 설욕이라고 생각한다. 스스로 강요당한 불평등을 조선에 다시 강요한 일본을 부도덕하고 악한 나라라고 비판하는 것은 자유이다. 그러나 일본은 스스로 주권을 회복하였고 조선은 회복하지 못하였다. 그 역사로부터 배워야 할 것은 없는가? 이것이 한국의 역사관이 답을 찾아야 할 올바른 질문이라고 생각한다.   
SVM3␞ 이번 글에서는 서포트 벡터 머신(SVM)의 변형인 **Kernel-SVM**에 대해 살펴보도록 하겠습니다. 이 글 역시 고려대 강필성 교수님과 역시 같은 대학의 김성범 교수님 강의를 정리했음을 먼저 밝힙니다. SVM의 일반적인 내용에 대해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/)을, **C-SVM**에 대해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/29/SVM2/)을 참고하시기 바랍니다. 그럼 시작하겠습니다.   ## Kernel-SVM의 목적의식 SVM은 두 범주를 잘 분류하면서 **마진(margin)**이 최대화된 **초평면(hyperplane)**을 찾는 기법입니다. 기본적으로 선형분류를 한다는 것이죠. 하지만 어떤 직선을 그어도 두 범주를 완벽하게 분류하기 어려운 경우도 많습니다. Kernel-SVM은 이 문제를 해결하기 위해 제안됐습니다. 먼저 아래 그림을 보겠습니다.  <a href="http://imgur.com/4i3ILsZ"><img src="http://i.imgur.com/4i3ILsZ.png" width="400px" title="source: imgur.com" /></a>  그림에서도 알 수 있듯 Kernel-SVM의 핵심 아이디어는 이것입니다. > 원공간(**Input Space**)의 데이터를 선형분류가 가능한 고차원 공간(**Feature Space**)으로 매핑한 뒤 두 범주를 분류하는 초평면을 찾는다.  ## mapping function  여기에서 가장 중요한 것은 Input Space와 Featuer Space 사이를 매핑해주는 함수 $Φ$입니다. 예를 들어 $Φ$가 아래와 같이 정의돼 있다고 칩시다.  $$ \Phi :({ x }_{ 1 },{ x }_{ 2 })\rightarrow ({ x }_{ 1 }^{ 2 },{ x }_{ 2 }^{ 2 },\sqrt { 2 } { x }_{ 1 },\sqrt { 2 } { x }_{ 2 },\sqrt { 2 } { x }_{ 1 }{ x }_{ 2 },1) $$  $Φ$는 $R^2$에 속한 입력을 받아서 그보다 고차원인 $R^6$으로 변환해 줍니다. 이렇게 되면 원래는 선형분리가 불가능했던 XOR문제가 선형분리가 가능한 데이터로 바뀌게 됩니다. 아래와 같습니다.  <a href="http://imgur.com/n3MjAFi"><img src="http://i.imgur.com/n3MjAFi.png" width="500px" title="source: imgur.com" /></a>  그러면 SVM에 $Φ$를 어떻게 적용하는지 살펴보겠습니다. Hard-margin SVM과 Soft-Margin SVM의 라그랑지안 Dual 식은 동일하며 다음과 같습니다. ($L_D$ 제약식은 생략)  $$ \max { { L }_{ D }({ \alpha }_{ i }) } =\sum _{ i=1 }^{ n }{ { \alpha }_{ i } } -\frac { 1 }{ 2 } \sum _{ i=1 }^{ n }{ \sum _{ j=1 }^{ n }{ { \alpha }_{ i }{ { \alpha }_{ j }y }_{ i }{ y }_{ j }{ x }_{ i }^{ T }{ x }_{ j } } } $$  Kernel-SVM은 $Φ$로 변환된 고차원 공간에서 두 범주를 분류하는 초평면을 만들기 때문에 $x_i^T$와 $x_j$에 $Φ$를 적용해 주어야 합니다. 식은 다음과 같이 쓸 수 있습니다.  $$ \max { { L }_{ D }({ \alpha }_{ i }) } =\sum _{ i=1 }^{ n }{ { \alpha }_{ i } } -\frac { 1 }{ 2 } \sum _{ i=1 }^{ n }{ \sum _{ j=1 }^{ n }{ { \alpha }_{ i }{ { \alpha }_{ j }y }_{ i }{ y }_{ j }{ \Phi ({ x }_{ i }) }^{ T }{ \Phi ({ x }_{ j }) } } } $$   ## Kernel Trick! 그런데 커널을 도입하게 되면 연산량이 폭증하게 됩니다. 그도 그럴 것이 모든 관측치에 대해 고차원으로 매핑하고 이를 다시 **내적(inner product)**해야 하기 때문입니다. 고차원 매핑과 내적을 한방에 할 수는 없을까요? 이를 위해 도입된 것이 바로 **커널(Kernel)**입니다. 커널 $K$는 다음과 같이 정의됩니다.  $$ K({ x }_{ i },{ x }_{ j })={ \Phi ({ x }_{ i }) }^{ T }{ \Phi ({ x }_{ j }) } $$ 매핑함수 $Φ$는 **선형변환(Linear Transformation)**이고 그에 해당하는 **표준행렬(standard matrix)**을 $A$라고 두면 다음과 같이 쓸 수 있습니다.  $${ \Phi (x) }=Ax$$  그러면 $K$는 다음과 같이 다시 쓸 수 있습니다.  $$K({ x }_{ i },{ x }_{ j })={ \Phi ({ x }_{ i }) }^{ T }{ \Phi ({ x }_{ j }) }={ x }_{ i }^{ T }{ A }^{ T }A{ x }_{ j }$$  여기에서 $Φ$를 $m$차원에서 $n$차원으로 매핑해주는 함수라고 가정해 봅시다. 그러면 각각의 차원수는 다음과 같습니다.  > (1) $x_i^T$ : (1 x m) > > (2) $A^T$ : (m x n) > > (3) $A$ : (n x m) > > (4) $x_j$ : (m x 1)  따라서 $K$의 결과는 스칼라가 됩니다. 그런데 $K(x_i, x_i)$인 경우 항상 0 이상의 값을 지녀야 할 겁니다. 또 $K(x_i, x_j)=K(x_j, x_i)$을 만족해야 할 겁니다. 이러한 맥락에서 $K(x_i,x_j)$로 구성된 행렬은 **positive semi-definite matrix**여야 하며 **대칭행렬(symetric matrix)**이어야 합니다. 이와 관련된 **Mercer's Theorem**은 다음과 같습니다.  <a href="http://imgur.com/MgO8GAo"><img src="http://i.imgur.com/MgO8GAo.png" width="550px" title="source: imgur.com" /></a>  위 조건을 만족하는 임의의 함수는 모두 커널 함수로 쓸 수 있습니다. 그 종류는 다음과 같습니다.  $$ \begin{align*} linear\quad &:\quad K({ x }_{ 1 },{ x }_{ 2 })={ x }_{ 1 }^{ T }{ x }_{ 2 }\\ polynomial\quad &:\quad K({ x }_{ 1 },{ x }_{ 2 })={ ({ x }_{ 1 }^{ T }{ x }_{ 2 }+c) }^{ d },\quad c>0\\ sigmoid\quad &:\quad K({ x }_{ 1 },{ x }_{ 2 })=\tanh { \left\{ a({ x }_{ 1 }^{ T }{ x }_{ 2 })+b \right\} } ,\quad a,b\ge 0\\ gaussian\quad &:\quad K({ x }_{ 1 },{ x }_{ 2 })=exp\left\{ -\frac { { \left\| { x }_{ 1 }-{ x }_{ 2 } \right\| }_{ 2 }^{ 2 } }{ 2{ \sigma }^{ 2 } } \right\} ,\quad \sigma \neq 0 \end{align*} $$  ## Gaussian Kernel polynomial 커널을 쓰는 경우 사용자가 지정한 $d$가 Feature space의 차원이 됩니다. 그러면 가우시안 커널은 어떨까요? $2σ^2=1$이어서 분모가 생략된 간단한 형태를 보겠습니다. $$ \begin{align*}\\ K({ x }_{ 1 },{ x }_{ 2 })&=exp\left\{ -{ ({ x }_{ 1 }-{ x }_{ 2 }) }^{ 2 } \right\} \\ &=exp(-{ x }_{ 1 })exp(-{ x }_{ 2 })exp(2{ x }_{ 1 }{ x }_{ 2 })\end{align*} $$ 테일러급수 정리에 의해 $exp(2x_ix_2)$를 다음과 같이 쓸 수 있습니다.  $$ exp(2{ x }_{ 1 }{ x }_{ 2 })=\sum _{ k=0 }^{ \infty }{ \frac { { 2 }^{ k }{ x }_{ 1 }^{ k }{ x }_{ 2 }^{ k } }{ k! } } $$  따라서 가우시안 커널은 Input Space가 몇 차원이 됐든 무한대 차원의 Feature Space로 매핑한다는 얘기입니다.   ## Kernel의 효과 기존 SVM에 해당하는 Linear 커널은 선형 분류경계면을 만들어냅니다. Polynomial 등 이 글에서 소개하는 커널은 비선형 경계면이 만들어집니다. 다음과 같습니다.  <a href="http://imgur.com/uVpdEym"><img src="http://i.imgur.com/uVpdEym.png" width="400px" title="source: imgur.com" /></a>  이번엔 가우시안 커널을 보겠습니다. gamma는 지수의 분모에 해당하는 하이퍼 파라메터인데요. 작을수록 마진이 넓어지는 걸 확인할 수 있습니다.  <a href="http://imgur.com/RciJQCj"><img src="http://i.imgur.com/RciJQCj.png" width="400px" title="source: imgur.com" /></a> 
negative␞ 이번 글에서는 한국어의 부정 표현에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 부정문 **부정소**란 어떤 문장에 덧붙어 그 명제의 진위를 정반대로 바꾸는 일을 하는 요소를 가리킵니다. 한국어에서 대표적인 부정소로는 **안**, **못**이 있습니다. **부정문(否定文)**이란 부정소가 들어있는 문장입니다.  한국어에선 긍정문과는 잘 결합하지 않고 부정문과만 결합하는 특정한 단어들이 있습니다. 이런 단어들을 **부정극어**라고 합니다. 예컨대 다음과 같은 종류가 있습니다.  - 결코, 전혀, 절대로, 과히, 그다지, 비단, 별로, 통, 도무지, 도저히 등 - 더 이상, 하나도, 한 $X$도(한 개도, 한 대도, 한 자루도 등), 아무도, 추호도, 조금도 등 <u>한국어에서는 부정극어와 호응하는 특성으로 부정문의 범위를 정합니다.</u> 다시 말해 부정극어가 자연스럽게 끼어 들어갈 수 있으면 해당 문장을 부정문으로 보는 것입니다. 한국어에서는 대체로 '안'이나 '못'이 있는 문장과 부정극어가 어울립니다.  그러나 '안'이나 '못'이 없지만, 부정극어를 허용하는 문장이 있습니다. 예컨대 다음과 같습니다. 아래 예문은 부정문으로 인정하는 견해가 다수입니다(부정극어 '전혀'와 호응, 모른다는 '알지 못하다'와 대응). - 그는 진이가 한 일을 **전혀** 모른다. 아래 예문의 '비전문적이다'는 의미상 '전문적이다'를 부정하는 것이라 하더라도, 부정적인 뜻의 어휘를 만든 것일 뿐 통사적으로 부정문이라고 보기는 어렵습니다(다시 말해 부정적인 뜻의 어휘를 서술어로 하는 통사적 긍정문임). 부정극어 '전혀'와 호응하지 않기 때문입니다. - *그 지식은 전혀 비전문적이다. - 그 지식은 전혀 전문적이지 않다 부정의 의미를 나타내는 접두사 미(未), 무(無), 비(非), 불(不), 몰(沒)이 결합한 경우, 문장 전체의 뜻은 부정적이라 하더라도 통사적으로는 부정문으로 보지 않습니다.   ## 부정법의 종류와 특징 부정법을 종류와 특징을 차례대로 살펴보겠습니다.  ### '안' 부정법 '안' 부정법에는 부정 부사 '안'을 쓰는 **단형부정**과 부정 보조동사 구성 '-지 않-'을 쓰는 **장형부정**이 있습니다. '$X$하-' 꼴의 동사를 단형으로 부정할 때, '안 $X$하-'보다는 '$X$ 안 하-'를 선호하는 경향이 있습니다. 예컨대 다음과 같습니다. - 공부 안 하- '$X$하-' 꼴의 형용사를 단형으로 부정할 때에는 '안 $X$하-'를 선호합니다.  - 안 깨끗하-, 안 화려하- '안' 부정법은 의지, 상황, 능력, 불급 등 특별한 의미가 없는 평범한 부정을 나타낼 때 쓰입니다. 다음 예문과 같습니다. - 오늘은 비가 오지 않는다. 주체의 의지에 의해 어떤 행위를 하지 않음(의지 부정)을 나타낼 때도 '안' 부정법이 쓰입니다. 주어가 의지를 가질 수 있고 서술어가 행위동사인 경우에만 '안'이 의지 부정의 의미로 해석됩니다. 다음 예문과 같습니다. - 진이는 밤새 한잠도 자지 않았다. - 진이는 고기를 안 먹는거야, 못 먹는 거야? 반면 주어가 의지는 있지만 능력이 없는 경우에는 '안' 부정문을 쓸 수 없습니다. 다음 예문은 이 때문에 비문입니다. - *진이는 대문이 잠겨서 집에 들어가지 않는다. - *진이는 회사에서 1년을 견디지 않았다.   ### '못' 부정법 '못' 부정법에는 부정 부사 '못'을 쓰는 단형부정과, 부정 보조동사 구성 '-지 못하-'를 쓰는 장형부정이 있습니다. 어떤 행위를 할 능력이 없음(능력 부정)을 나타낼 때 '못' 부정법을 씁니다. 다음 예문과 같습니다. - 진이는 이 바위를 못 든다. 주체의 의지와 상관 없이 상황에 의해 어떤 행위를 하지 못함(상황 부정)을 나타낼 때도 '못' 부정법을 씁니다. 다음 예문과 같습니다. - 밖이 시끄러워서 잠을 자지 못했다. 의지를 가질 수 있는 주어가 나타나야 '못' 부정법이 '능력 부정'이나 '상황 부정'으로 해석될 수 있습니다. 그러나 다음 예문처럼 의지를 가질 수 없는 주어가 나타난 경우에 '못' 부정법을 기본적으로 쓸 수 없습니다. - *비가 오지 못했다. - *내용이 외워지지 못한다. - *날씨가 춥지 못하다. '못' 부정법은 형용사문에서도 기본적으로 쓰이지 않습니다. 형용사가 드러나는 상태는 주어의 의지나 능력과 관계가 없는 경우가 많기 때문입니다. 하지만 때로는 의지를 가질 수 없는 주어와 '못'이 어울리는 경우도 있습니다. 아래 예문의 경우 '못'은 상황이 화자의 기대에 미치지 못함(불급(不及)부정)을 나타냅니다. - 엑스레이가 이 물질을 통과하지 못했다. - 살림이 넉넉하지 못해서 대접이 소홀했습니다. (형용사와 함께 쓰이는 경우 장형부정만 가능) 한편 부정 보조용언 '않-', '못하-'가 [동사 활용](https://ratsgo.github.io/korean%20linguistics/2017/05/09/verb/)을 보일 것인지, [형용사 활용](https://ratsgo.github.io/korean%20linguistics/2017/05/09/verb/)을 보일 것인지는 '-지' 앞 용언의 품사에 따릅니다. 다음 예문과 같습니다. - **동사** : 진이가 책을 읽지 {않는다, *않다}. - **형용사** : 나는 배가 아프지 {*않는다, 않다}. - **동사** : 진이가 잠을 자지 {못한다, *못하다}. - **형용사** : 살림이 넉넉하지 {*못한다, 못하다}.   ### '말다' 부정법 '안' 부정법과 '못' 부정법은 평서문, 의문문에 쓰이고, '말다' 부정법은 명령문, 청유문에 쓰입니다. 다음 예문과 같습니다. - 책을 읽지 {말아라, *않아라, 못해라}. - 책을 읽지 {말자, *않자, *못하자}. 바람을 나타내는 동사 '바라다, 희망하다, 원하다, 기대하다' 등이 쓰일 때에는 명령이나 청유가 아닌 문장에서도 쓰일 수 있습니다.  - 나는 네가 미국에 가지 {말기를/않기를} 바란다. 당위를 나타내는 경우에도 쓰일 수 있습니다. - 너는 미국에 가지 {말아야/않아야} 한다.   ### 특수 어휘에 의한 부정법 '없다', '모르다', '아니다' 세 가지가 있습니다. 이들 세 어휘는 부정극어와 어울려 쓰일 수 있기 때문에 특수 어휘에 의한 부정법이라는 별도 범주로 분류해 둔 것입니다. '없다'는 '있다(형용사 *exist*)'의 부정어 노릇을 합니다. 다음 예문과 같습니다. - 책이 여기에 있다. - 책이 여기에 없다. 동사인 '있다(*stay*)'나 '계시다'는 '안' 부정문이나 '못' 부정문으로 부정합니다. 다음 예문과 같습니다. - 저놈이 잠시도 가만히 안 있는다. - 선생님은 저기에 안 계신다. 보조동사 구성 '-어 있-', '-고 있-'에서의 '있다'도 부정어로 '없다'를 취하지 않습니다. 다음 예문과 같습니다. - *아이들이 놀고 없어요. - 아이들이 놀고 있지 않아요. '모르다'는 '알다'의 부정어 노릇을 합니다. 다만 부정의 정도를 좀 완화할 때에는 '알지 못하다'로도 쓰일 수 있습니다. 다음 예문과 같습니다. - 나는 그 사람을 모른다. - 나는 그 사람을 알지 못한다. '아니다'는 다음과 같이 '이다'의 부정어 노릇을 합니다. - 진이는 회사원이다. - 진이는 회사원이 아니다. 단, '$X$적이-' 꼴의 술어를 부정할 때는 특수형 '-이 아니-'뿐 아니라 장형 '-지 않-'도 가능합니다. - 보수적이 아니다. - 보수적이지 않다.   ## 단형부정 vs 장형부정 의문문에서 '안(단형부정)'을 이용하면, 화자가 어떤 긍정적인 전제를 가지고 있었으나 상황을 보니 그 전제가 부정될 개연성이 있다고 판단되어, '그 전제가 부정되는 것이 맞는지'를 확인하는 기능으로 쓰이는 경향이 있습니다. 다음 예문과 같습니다. - 너 오늘 수업 들으러 안 가? '안'이 쓰일 때 화자는 부정문으로 표현될 수 있는 내용을 마음 속에 품고 있습니다. 위 예문 기준으로는 '청자가 오늘 수업 들으러 안 간다'는 문장이 화자 마음 속에 있다는 뉘앙스로 읽힙니다. 반면 '-지 않-(장형부정)'을 이용하면 화자가 긍정적인 전제를 가지고 있으면서 청자에게 동의를 요청하는 기능으로 쓰이는 경향이 있습니다. 다음 예문과 같습니다. - 너 오늘 수업 들으러 가지 않아? '-지 않-'이 쓰일 때 화자는 긍정문으로 표현될 수 있는 내용을 마음 속에 품고 있습니다. 위 예문 기준으로는 '청자가 오늘 수업 들으러 간다'는 문장이 화자 마음 속에 있다는 뉘앙스로 읽힙니다. 부정의 작용역 차이도 나타납니다. 다음 예문과 같습니다. - 학생이 다 안 왔어.  → 1차적 해석 : 부정소가 동사만 부정의 범위에 포함하는 것, 즉 "온 사람이 없음"  → 2차적 해석 : 부정소가 수량 표현까지 부정의 범위에 포함하는 것, 즉 "일부만 왔음" - 학생이 다 오지 않았어.  → 부정소가 수량 표현까지 부정의 범위에 포함하는 것, 즉 "일부만 왔음"  → 부정소가 동사만 부정의 범위에 포함하는 것, 즉 "온 사람이 없음" 다른 예문을 보겠습니다. - 진이가 민이만 안 때렸어.  → 1차적 해석 : "진이가 안 때린 유일한 사람이 민이임" - 진이가 민이만 때리지 않았어.  → "진이가 때린 사람이 민이 외에도 있음"  → "진이가 안 때린 유일한 사람이 민이임" 단형부정문과 달리 장형부정문은 용언 뒤에 보조사가 첨가될 수 있습니다. 다음 예문과 같습니다. - 진이는 예쁘지**는** 않다. 단형부정은 단정적인 부정, 장형부정은 완곡한 부정의 효과를 냅니다. 부정부사 '안'을 수정하고 싶은 정보 앞에 위치시키면 좀 더 강력한 수정의 효과를 볼 수 있습니다. 반면 장형부정 '-지 않-'을 보조사 '는'과 함께 사용하면 부분적인 수정의 효과를 볼 수 있습니다. 다음 예문과 같습니다. - **단정적인 부정** : 안 예쁘다. 안 그래. - **완곡한 부정** : 예쁘지는 않다. 그렇지는 않아. 위와 같은 단형부정과 장형부정의 차이는 서술어가 동사일 때보다 형용사일 때 더 잘 나타납니다. 형용사는 그 특성상 정도성 개념과 깊은 관련을 맺고 있기 때문입니다. 예컨대 형용사 '예쁘다'의 경우 못생김과 예쁨의 양극단에서 어떤 지점을 나타낸다고 볼 수 있습니다. 이를 단형부정, 장형부정의 의미상 차이와 연결지어 그림으로 표현하면 다음과 같습니다.  <a href="https://imgur.com/wO8PtwH"><img src="https://i.imgur.com/wO8PtwH.png" width="400px" title="source: imgur.com" /></a>  '안'을 쓰는 단형부정은 격식적이지 않은 상황, 즉 일상 구어에서 잘 쓰입니다. 다만 사용 빈도가 낮은 용언, 어간 음절수가 많은 용언은 '안'보다는 '-지 않-'과 결합하는 예가 많습니다. 다음 예문과 같습니다. - 굶주리지 않-, 예사롭지 않-, 우유부단하지 않- '교육자답다' 등 "$X$의 자격을 갖추고 있음"의 의미를 나타내는 '$X$답-' 꼴의 형용사는 단형부정으로 잘 부정되지 않습니다.
stack␞ 이번 글에서는 **스택(stack)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의와 위키피디아를 정리하였음을 먼저 밝힙니다. 파이썬 코드는 [이곳](https://github.com/TheAlgorithms/Python/blob/master/data_structures/Stacks/Stack.py)을 기본으로 하되 조금 수정하였습니다. 그럼 시작하겠습니다.   ## concept 스택이란 목록 한쪽 끝에서만 자료를 넣거나 뺄 수 있는 자료구조의 일종입니다. 이때 자료를 넣는 것을 '밀어넣는다'는 의미의 푸시(push), 반대로 넣어둔 자료를 꺼내는 것을 팝(pop)이라고 합니다. 팝으로 꺼내진 자료는 가장 최근에 보관한 자료가 됩니다(**Last In First Out, LIFO**) 책이 쌓여있는(stack) 걸 상상하면 직관적으로 이해할 수 있는데요. 스택은 책더미 속에서 가장 나중에 올려놓은 책부터 꺼낼 수 있는 것과 같은 이치입니다.  <a href="https://imgur.com/DaNczdX"><img src="https://i.imgur.com/DaNczdX.png" width="500px" title="source: imgur.com" /></a>  6, 4, 2를 차례로 푸시하고, 두번 팝 한 다음에 7을 푸시한다고 가정해보겠습니다. 다음 그림과 같습니다.  <a href="https://imgur.com/QjRPiID"><img src="https://i.imgur.com/QjRPiID.png" width="300px" title="source: imgur.com" /></a>   ## operation 스택의 핵심 연산(operation)은 푸시와 팝입니다. 푸쉬를 구현한 파이썬 코드는 다음과 같습니다. ```python class Stack(object):   def __init__(self, limit = 10):     self.stack = []     self.limit = limit   # for printing the stack contents   def __str__(self):     return ' '.join([str(i) for i in self.stack])   # for pushing an element on to the stack   def push(self, data):     if len(self.stack) >= self.limit:       print('Stack Overflow')     else:       self.stack.append(data) ``` 위 코드상으로는 스택 길이를 *limit*라는 변수로 제어하고 있습니다. 물론 스택 길이를 굳이 제어하지 않아도 됩니다. 정해진 스택 길이 *limit*를 만족하는 상태인 스택에 추가 요소를 푸쉬할 경우 스택 오버플로우(stack overflow) 경고메세지를 출력합니다. 팝을 구현한 파이썬 코드는 다음과 같습니다. 스택 길이가 0 이하라면 팝을 할 수 없으므로 스택 언더플로우(stack underflow) 문제가 발생합니다. 이 코드에선 -1을 출력하도록 했습니다. ```python   # for popping the uppermost element   def pop(self):     if len(self.stack) <= 0:       return -1     else:       return self.stack.pop() ``` 스택의 핵심 연산은 아니지만 정의해놓으면 편리한 것이 바로 픽(peek)입니다. 스택의 경우 그 정의상 팝을 해야만 스택에 최근 저장된 자료를 확인할 수 있는데요. 픽은 팝을 하지 않고도 최근 저장된 자료를 엿볼(peek) 수 있습니다. ```python   def peek(self):     if len(self.stack) <= 0:       return -1     else:       return self.stack[len(self.stack) - 1] ``` 파이썬 코드에서 이미 눈치 채셨겠지만 스택은 리스트, 연결리스트 등 다양한 자료구조로 구현이 가능합니다. 위 파이썬 코드의 경우 리스트를 활용해 스택이 구현됐습니다. 리스트를 활용할 경우 푸쉬 연산은 리스트에 새 자료를 붙이는(append) 형태로, 팝 연산은 파이썬 자체의 팝(pop) 연산이 적용됐습니다. 그런데 스택의 정의에만 맞다면 위 형태 말고도 다양하게 구현할 수 있습니다. 리스트든 연결리스트든 팝, 푸쉬, 픽 연산의 계산복잡성은 $O(1)$입니다.   ## 활용 : 재귀함수 스택은 프로그래머도 모르는 사이에 여러 곳에서 쓰이고 있습니다. 재귀함수 호출이 모두 스택 형태로 이뤄지게 됩니다. 이와 관련해 다음 그림을 보겠습니다. <a href="https://imgur.com/R6iBX1Y"><img src="https://i.imgur.com/R6iBX1Y.png" width="500px" title="source: imgur.com" /></a> 함수 $A$를 실행하다가 $B$를 호출하고, 다시 $B$를 실행하다가 $B$를 호출하고, $C$와 $D$도 마찬가지의 과정을 거쳤다고 칩시다. 그러면 함수 실행 결과를 반환하는 과정은 호출 순서의 정반대가 됩니다. 다시 말해 $D$의 연산 결과를 받아야지만 $C$가 이를 바탕으로 계산을 마칠 수 있고, 이는 $B$와 $A$도 마찬가지입니다.  각 함수의 메모리 주소값이 스택에 저장되어 있고, 스택은 Last In First Out 원칙을 따르기 때문에 함수 결과의 반환 순서는 호출 결과의 반대가 되는 것입니다.   ## 활용 : 사칙연산 숫자와 숫자 사이에 연산자를 넣어 표기하는 방법을 중위표기법(infix notation)이라 합니다. 예컨대 아래의 표기는 2와 3을 '더한다'는 뜻이 됩니다. > 2 **+** 3 중위표기법은 괄호 연산자가 필요없는 전위표기법(+ 2 3)이나 후위표기법(2 3 +)과는 다르게 괄호가 매우 중요합니다. 연산 수행 순서를 명시적으로 나타내야 할 때가 발생하기 때문이죠. 예컨대 아래의 표기에서는 2와 3을 더하는 연산이 먼저 수행됩니다. > (2 + 3) × 4 그런데 후위표기법에서는 위와 같은 식을 아래와 같이 쓰게 돼 괄호가 필요 없습니다. > 2 3 + 4 × 연산의 우선순위(the priority of operands, precednece rule)은 모호하게 해석할 수 있는 수식에서 어느 연산을 먼저 계산할 것인가를 결정하는 명시적인 규칙입니다. 중위표기법에서는 다음과 같은 순위가 표준적으로 쓰입니다. 자세한 내용은 [이곳](https://ko.wikipedia.org/wiki/%EC%97%B0%EC%82%B0%EC%9D%98_%EC%9A%B0%EC%84%A0%EC%88%9C%EC%9C%84)을 참고하시면 좋을 것 같습니다. > (, ) > ×, / > +, - 중위표기법은 사람에게는 친숙하지만 컴퓨터로 구문분석하기가 어렵습니다. 이 때문에 프로그램 내부에서는 연산자를 연산 대상의 뒤에 쓰는 후위표기법(postfix notation)이 쓰인다고 합니다. 후위표기법은 괄호가 없고 수식 계산시 식을 앞에서 읽어 나가면서 차례대로 처리를 하면 됩니다. 이 때 쓰이는 것이 바로 스택입니다. 컴퓨터가 중위표기법으로 표현된 수식을 계산하는 과정은 크게 두 단계로 나눠서 생각해볼 수 있습니다. 1. 전위표기법으로 표현된 수식을 후위표기법으로 변환 2. 후위표기법으로 표현된 수식을 계산 중위표기법으로 쓰인 다음 식을 계산한다고 칩시다. 이를 후위표기법으로 변환하면 다음과 같습니다.  $$ A+B\times C+\left( D\times E+F \right) \times G\\ \Rightarrow \quad ABC\times +DE\times F+G\times + $$  1번 과정의 일반적 절차는 다음과 같습니다. - 계산대상 숫자가 나오면 *output* 변수에 저장한다. - 왼쪽 괄호 $($가 나오면 스택에 푸쉬(저장)한다. - 오른쪽 괄호 $)$가 나오면 스택에 이미 저장돼 있는 왼쪽 괄호 $($ 사이에 있는 모든 요소를 팝을 한다. - 덧셈, 곱셈기호 등 연산자가 나오면 해당 연산자보다 연산 우선순위가 낮거나 같은 연산자가 나올 때까지 스택에서 팝을 해서 *output*에 저장하고, 해당 연산자를 스택에 푸쉬한다. - 식의 끝에 다다르면 스택에 있는 모든 요소를 팝을 한다. 위 절차에 따라 위 식을 후위표기법으로 변환해 보겠습니다. 아래 표와 같습니다. |    현재 위치    |  output   | stack | | :-----------------: | :-----------: | :---: | | **A**+B×C+(D×E+F)×G |    A    |    | | A**+**B×C+(D×E+F)×G |    A    |  +  | | A+**B**×C+(D×E+F)×G |   AB    |  +  | | A+B**×**C+(D×E+F)×G |   AB    | +×  | | A+B×**C**+(D×E+F)×G |   ABC   | +×  | | A+B×C**+**(D×E+F)×G |   ABC×+   |  +  | | A+B×C+**(**D×E+F)×G |   ABC×+   | +(  | | A+B×C+(**D**×E+F)×G |  ABC×+D   | +(  | | A+B×C+(D**×**E+F)×G |  ABC×+D   | +(× | | A+B×C+(D×**E**+F)×G |  ABC×+DE  | +(× | | A+B×C+(D×E**+**F)×G |  ABC×+DE×  | +(+ | | A+B×C+(D×E+**F**)×G |  ABC×+DE×F  | +(+ | | A+B×C+(D×E+F**)**×G | ABC×+DE×F+  |  +  | | A+B×C+(D×E+F)**×**G | ABC×+DE×F+  | +×  | | A+B×C+(D×E+F)×**G** | ABC×+DE×F+G | +×  | |  A+B×C+(D×E+F)×G  | ABC×+DE×F+G+× |    | 후위표기법으로 표현된 수식을 계산하는 2번 과정의 일반적 절차는 다음과 같습니다.  - 숫자를 만나면 스택에 푸쉬한다. - 연산자를 만나면 두 개 요소를 팝을 하고, 두 요소에 연산자에 해당하는 연산을 적용한 후, 그 값을 다시 푸쉬한다. 예컨대 다음과 같은 식을 계산한다고 칩시다. (답은 40) > 중위표기법 : 5×4+6+7×2 > > 후위표기법 : 54×6+72×+ |   현재 위치   | stack | | :-----------: | :----: | | **5**4×6+72×+ |  5  | | 5**4**×6+72×+ | 5,4  | | 54**×**6+72×+ |  20  | | 54×**6**+72×+ | 20,6 | | 54×6**+**72×+ |  26  | | 54×6+**7**2×+ | 26,7 | | 54×6+7**2**×+ | 26,7,2 | | 54×6+72**×**+ | 26,14 | | 54×6+72×**+** |  40  | 1번 작업의 계산복잡성은 $O(n)$, 2번 작업 역시 $O(n)$이 됩니다. 연산자와 숫자 개수를 모두 합쳐 $n$개일 경우 모든 요소를 한번씩은 다 훑어야 하기 때문입니다.
nounontology2␞ 이번 글에서는 국립국어원에서 만든 표준국어대사전의 명사 분류 체계에 대해 살펴보도록 하겠습니다. 자료는 [국립국어원 언어정보나눔터](https://ithub.korean.go.kr/)에서 내려받아 제 나름대로 정리한 것임을 밝힙니다. 그럼 시작하겠습니다.  ## 개요 및 대분류 표준국어대사전 명사 분류 체계는 0~7단계로 나뉩니다. 대분류에 해당하는 0~1단계는 다음과 같습니다. **온** (0단계) : 전부, 모두 - 구체물 (1단계) - 집단 (1단계) - 장소 (1단계) - 추상적 대상 (1단계) - 사태 (1단계)   이번 글에서는 추상적 대상, 사태를 포괄합니다. 구체물, 집단, 장소를 보시려면 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/05/17/nounontology/)을 참고하세요. 이 글의 목차는 다음과 같습니다.  * 목차 {:toc}  ## 추상적 대상 **추상적 대상**이란 시, 공간적 延長(extension)을 갖지 않고 감각기관을 통해 지각될 수 없는 대상입니다. 하위 범주(2단계)로는 금전, 시간, 방법, 기술, 역할, 범주, 속성, 단위, 방향, 사실/명제, 기호, 기호체계, 자연법칙, 규범, 관습, 권력, 권리, 의무, 학문과목, 제도, 종교, 사조, 예술, 텍스트, 작품, 방송물, 산업, 역사, 상, 벌, 분야, 범위, 경로, 추상적 부분, 관계추상적대상, 개념, 기준, 상황, 개체상황, 영상, 수학적대상, 물리학적대상, 인지공간, 추상적장애물 등이 있습니다. 그 예는 다음과 같습니다. <p class="message"> 가격대(價格臺), 가계(家計), 가로줄눈, 가리마, 가망(可望), 가사(家事), 가풍(家風), 각급(各級), 갈래, 개론(槪論), 개별(個別), 개중(個中), 객관(客觀), 객체(客體), 거개(擧皆), 건곤(乾坤), 검도(劍道), 격식(格式), 경리(經理), 경중(輕重), 계정(計定), 계통(系統), 고풍(古風), 골계(滑稽), 골프(golf), 곱절, 공덕(功德), 공력(功力), 공로(功勞), 공리(公利), 공립(公立), 공소시효(公訴時效), 공수(攻守), 공식(公式), 공예(工藝), 공지사항(公知事項), 공해(公害), 공훈(功勳), 과반의석(過半議席), 과보(果報), 과정(課程), 관광상품(觀光商品), 관련사항(關聯事項), 관료주의(官僚主義), 관심사(關心事), 광고내용(廣告內容), 광범위(廣範圍), 교과(敎科), 교과과정(敎科課程), 교수계단(敎授階段), 교의(敎義), 구태, 국사(國事), 군사문화(軍事文化), 궂은일, 귀감, 규범(規範), 규정(規定), 근대문명(近代文明), 근대문물(近代文物), 근본(根本), 금융(金融), 기본원리(基本原理), 꽃놀이패(___覇), 낌새, 나랏일, 난점(難點), 난제(難題), 내선일체(內鮮一體), 내심(內心), 내역(內譯), 노고(勞苦), 노무(勞務), 노인복지(老人福祉), 논란거리(論難__), 농무(農務), 누(累), 대종(大宗), 대중매체(大衆媒體), 대중문화(大衆文化), 대책, 댓가, 덤터기, 동선(動線), 동음(同音), 똥줄, 뜻밖, 레슬링(wrestling), 레퍼토리(repertory), 마사(馬事), 마수(魔手), 만반(萬般), 만상(萬象), 만약(萬若), 만일(萬一), 말문(_門), 매사(每事), 맹목(盲目), 맹점(盲點), 명리(名利), 명목(名目), 명복(冥福), 명예(名譽), 명의(名義), 목숨, 무공(武功), 무시무종(無始無終), 무훈(武勳), 문명(文明), 문물(文物), 문의사항(問議事項), 문자서비스(文字___), 문제(問題), 문학사(文學士), 물론(勿論), 물정(物情), 물질문명(物質文明), 미디어(media), 미스터리(mystery), 바탕, 발자취, 배구(排球), 배꼽시계(__時計), 배달(倍達), 배드민턴(badminton), 백년대계(百年大計), 범사(凡事), 법망(法網), 보기, 보험(保險), 부모덕(父母德), 부패고리(腐敗__), 북핵문제(北核問題), 비목(費目), 비점(沸點), 빙점(氷點), 사념(思念), 사려(思慮), 사론(私論), 사료(史料), 사사(私事), 사생활(私生活), 사안(事案), 사활(死活), 사회문제(社會問題), 사회보험(社會保險), 사회복지(司會福祉), 상궤(常軌), 상벌(賞罰), 상식(常識), 샅바씨름, 생계(生計), 생령(生靈), 생리위생(生理衛生), 생명(生命), 생명보험(生命保險), 생존보험(生存保險), 서력(西曆), 석사과정(碩士課程), 선업(先業), 선택사항(選擇事項), 성령(聖靈), 세상사(世上事), 세속(世俗), 세원(稅源), 소아(小我), 소청(所請), 속마음, 손때, 송구(送球), 수구(水球), 수비벽(守備壁), 수수께끼, 수영(水泳), 스모(相撲), 스케줄(schedule), 승기(勝機), 시공(時空), 시공간(時空間), 시스템(system), 시의(時宜), 식이요법(食餌療法), 신구(新舊), 신상정보(身上情報), 신조(信條), 신지식(新知識), 실기(實技), 실리(實利), 실무(實務), 실존(實存), 실질(實質), 심벌(symbol), 심중(心中), 심층구조(深層構造), 심혈(心血), 심혼(心魂), 씨름, 아무짝, 아성(牙城), 악몽(惡夢), 악상(樂想), 안건(案件), 야구(野球), 약형태(弱形態), 양감(量感), 양상(樣相), 언어경계선(言語境界線), 얼, 여운(餘韻), 역점(力點), 연구대상(硏究對象), 영혼(靈魂), 예산안(豫算案), 예식(例式), 오행(五行), 외견상(外見上), 외관상(外觀上), 외교문제(外交問題), 외래문화(外來文化), 요구사항(要求事項), 요구수준(要求水準), 요구조건(要求條件), 요청안(要請案), 용건(用件), 용무(用務), 용역(用役), 운명(運命), 원안(原案), 원죄(原罪), 위업(偉業), 유도(柔道), 유종(有終), 육갑(六甲), 육상(陸上), 은공(恩功), 은덕(恩德), 은전(恩典), 은총(恩寵), 은행계좌(銀行計座), 은행구좌(銀行口座), 음계(音階), 음양(陰陽), 음양오행(陰陽五行), 의료복지(醫療福祉), 의리(義理), 의무행정(醫務行政), 의안(議案), 의외(意外), 의의(意義), 의제(議題), 이데올로기(ideologie), 이설(異說), 이순(耳順), 이슈(issue), 이점(利點), 이치(理致), 이해(利害), 이해득실(利害得失), 인과(因果), 인맥(人脈), 인문(人文), 인신(人身), 인심(人心), 인연(因緣), 인원(人員), 인적(人跡), 일거리, 일련(一連), 일례(一例), 일명(一命), 일생일사(一生一死), 일소천금(一笑千金), 임명동의안(任命同意案), 입론(立論), 잠재수요(潛在需要), 전국구(全國區), 전기안전(電氣安全), 전훈(戰勳), 정교(政敎), 정신문화(精神文化), 정통(正統), 조롱거리(嘲弄__), 조준선(照準線), 존망(存亡), 주먹뺨, 주색(酒色), 진부(眞否), 질료(質料), 차명계좌(借名計座), 차변(借邊), 추가부담(追加負擔), 취업률(就業率), 친일문제(親日問題), 커리큘럼(curriculum), 태몽(胎夢), 텔레파시(telepathy), 판로(販路), 퍼즐(puzzle), 페어(fair), 편리(片利), 표층(表層), 풍물(風物), 프로스포츠(pro sports), 프로젝트(project), 피차간(彼此間), 필봉(筆鋒), 하나하나, 하키(hockey), 학술(學術), 학습자료(學習資料), 학예(學藝), 한가락, 행렬(行列), 행서(行書), 행운(幸運), 허례허식(虛禮虛飾), 현실(現實), 형사(刑事), 혜안(慧眼), 혼(魂), 혼백(魂魄), 환락(歡樂), 획득형질(獲得形質), 후사(後事) </p>  ### 금전 <p class="message"> 고리사채(高利私債), 고액자산(高額資産), 공천헌금(公薦獻金), 구제금융(救濟金融), 국고보조금(國庫補助金), 국록(國祿), 국민기금(國民基金), 국민연금(國民年金), 국방예산(國防豫算), 국비(國費), 국채(國債), 금융자본(金融資本), 금일봉(金一封), 금전(金錢), 기부금(寄附金), 기준시가(基準市價), 노름빚, 농가부채(農家負債), 능력급(能力給), 대출금(貸出金), 대출금리(貸出金利), 대출이자(貸出利子), 돈, 반액(半額), 배당금(配當金), 보상금(補償金), 보조금(補助金), 보증금(保證金), 보험금(保險金), 본전(本錢), 비상금(非常金), 비자금([U+7955]資金), 빚, 사재(私財), 사채(私債), 생돈(生_), 선거기탁금(選擧寄託金), 성금(誠金), 세뱃돈(歲拜_), 소액(少額), 수익금(收益金), 수익자산(收益資産), 수재의연금(水災義捐金), 역산(逆産), 영리자본(營利資本), 영치금(領置金), 예산액(豫算額), 예상액(豫想額), 예치금(預置金), 예탁금(預託金), 외국자본(外國資本), 외채(外債), 외환보유고(外換保有高), 외환보유액(外換保有額), 월수(月收), 위탁금(委託金), 위험수당(危險手當), 유동자산(流動資産), 융자금(融資金), 일수(日收), 입출금(入出金), 자본금(資本金), 잠정가격(暫定價格), 장기대여금(長期貸與金), 재부(財富), 재산(財産), 재정(財政), 재화(財貨), 정착금(定着金), 지불액(支拂額), 지원금(支援金), 짐삯, 착수금(着手金), 추가비용(追加費用), 추경예산(追更豫算), 출연료(出演料), 할당액(割當額) </p> #### 세금 <p class="message"> 간접세(間接稅), 강제징수(强制徵收), 관세(關稅), 국민혈세(國民血稅), 국세(國稅), 벌금(罰金), 법인세(法人稅), 부가가치세(附加價値稅), 상속세(相續稅), 상속증여세(相續贈與稅), 세금(稅金), 세액(稅額), 소득세(所得稅), 수입세(輸入稅), 양도소득세(讓渡所得稅), 인지세(印紙稅), 잡세(雜稅), 조세(租稅), 종합소득세(綜合所得稅), 지방세(地方稅), 지세(地稅), 환경부담금(環境負擔金) </p> #### 비용 <p class="message"> 계약금(契約金), 공공요금(公共料金), 공과금(公課金), 공사비(工事費), 공전(工錢), 과태료(過怠料), 광고료(廣告料), 광고비(廣告費), 교육비(敎育費), 국가예산(國家豫算), 군비(軍備), 급행요금(急行料金), 기성회비(期成會費), 기회비용(機會費用), 납부금(納府金), 노자(路資), 노잣돈(路資_), 누진요금(累進料金), 당비(黨費), 대선자금(大選資金), 대여료(貸與料), 등록금(登錄金), 로열티(royalty), 미납요금(未納料金), 뱃삯, 버스요금(bus__), 보험료(保險料), 복리후생비(>福利厚生費), 복비(福費), 본인부담금(本人負擔金), 부금(賦金), 사망보상금(死亡報償金), 사비(私費), 사용료(使用料), 사용자비용(使用者費用), 생산물지대(生産物地代), 생산비(生産費), 생활비(生活費), 선금(先金), 선전비(宣傳費), 세비(歲費), 세출(歲出), 소개비(紹介費), 소매가격(小賣價格), 소작료(小作料), 송금수수료(送金手數料), 수수료(手數料), 수학여행비(修學旅行費), 수험료(受驗料), 숙박료(宿泊料), 숙박비(宿泊費), 시설이용료(施設利用料), 시설투자비(施設投資費), 시험연구비(試驗硏究費), 식대(食代), 식비(食費), 신문구독료(新聞購讀料), 실비(實費), 안팎노자(__路資), 여비(旅費), 연구개발비(硏究開發費), 연구비(硏究費), 예약금(豫約金), 요금(料金), 운영비(運營費), 운임(運賃), 웃돈, 원고료(原稿料), 월세(月貰), 위자료(慰藉料), 유통비용(流通費用), 음식비(飮食費), 응시료(應試料), 의료보험료(醫療保險料), 이용요금(利用料金), 인건비(人件費), 임대료(賃貸料), 임대보증금(賃貸保證金), 입원비(入院費), 입장료(入場料), 입찰가(入札價), 자릿세(__貰), 자비(自費), 전기요금(電氣料金), 전비(戰費), 전세금(傳貰金), 전셋돈(傳貰__), 전화요금(電話料金), 전후배상금(戰後賠償金), 제작비(製作費), 주거비(住居費), 주차료(駐車料), 주차요금(駐車料金), 진료비(診療費), 진찰료(診察料), 집세(_貰), 차비(車費), 초기투자비(初期投資費), 최저생계비(最低生計費), 추곡수매가(秋穀收買價), 치료비(治療費), 카드수수료(card___), 통행요금(通行料金), 팁(tip), 프리미엄(premium), 학회지원비(學會支援費), 학회참가비(學會參加費), 한계생산비(限界生産費), 혼잡통행료(混雜通行料), 회비(會費), 회원가입비(會員加入費), 후생비(厚生費) </p> #### 소득 <p class="message"> 고료(稿料), 광고수익(廣告收益), 광고수입(廣告收入), 국민소득(國民所得), 급료(給料), 기아품삯(饑餓__), 노임(勞賃), 당기순이익(當期純利益), 마진(margin), 매출액(賣出額), 보너스(bonus), 보수(報酬), 본봉(本俸), 봉급(俸給), 봉록(俸祿), 불로소득(不勞所得), 상금(賞金), 상여금(賞與金), 세입(稅入), 소득(所得), 수당(手當), 수익(收益), 순소득(純所得), 순수입(純收入), 시세차익(時勢差益), 실수입(實收入), 연금(年金), 연봉(年俸), 월급(月給), 이중소득(二重所得), 인세(印稅), 장학금(奬學金), 저임금(低賃金), 정치자금(政治資金), 주급(週給), 철야수당(徹夜手當), 초과수익(超過收益), 초과이윤(超過利潤), 최저임금(最低賃金), 평균연봉(平均年俸), 평균임금(平均賃金) </p>  ### 시간 **시간**이란 사건이 과거로부터 현재를 거쳐 미래로 진행되는 경험의 연속체입니다. <p class="message"> 경우(境遇), 고금(古今), 공식일정, 광음(光陰), 그때, 기간(期間), 기한(期限), 누대(累代), 단계(段階), 등교시간(登校時間), 때, 말미, 매월(每月), 매주(每週), 밤낮, 배차시간(配車時間), 봄풀내기, 불시(不時), 사시사철(四時四_), 상시(常時), 세월(歲月), 소풍날(逍風), 수개월(數箇月), 시간(時間), 시기(時期), 시대(時代), 시일(時日), 시절(時節), 시점(時點), 시효(時效), 아까, 앞일, 영업시간(營業時間), 잠시간(暫時間), 찬스(chance), 천고(千古), 추모기간(追慕期間), 타이밍(timing), 항시(恒時) </p> #### 순환시간 **순환시간**이란 시간 축 상의, 순환적으로 반복되는 부분입니다. <p class="message"> 겨울방학(__放學), 공휴일(公休日), 그믐, 근무시간(勤務時間), 기말(期末), 김장철, 내중일(內中日), 바캉스(vacance), 방학(放學), 방학기간(放學期間), 봄여름, 삭망(朔望), 상달(上_), 상순(上旬), 새해, 생리휴가(生理休暇), 생시(生時), 성수기(盛需期), 세기말(世紀末), 세밑(歲_), 수업시간(授業時間), 시즌(season), 신년(新年), 신학기(新學期), 여름휴가(__休暇), 여름휴가철(__休暇_), 연말(年末), 연말연시(年末年始), 연초(年初), 열흘날, 오뉴월(五六月), 요일(曜日), 우기(雨期), 월례(月例), 월말(月末), 월별(月別), 월차(月次), 유월(六月), 일주년(一週年), 정초(正初), 주말(週末), 찬물때, 평일(平日), 하루하루, 하순(下旬), 한겨울밤, 해빙기(解氷期), 휴가(休暇), 휴식시간(休息時間), 휴일(休日) </p> 기념일/명절 : 1년을 단위로 해서 반복되며, 특정 사건을 기념하기 위해 정해 놓은 날 <p class="message"> 광복절(光復節), 국경일(國慶日), 기념일(紀念日), 기일(忌日), 노동절(勞動節), 단오(端午), 단오절(端午節), 대보름(大__), 법정공휴일(法定公休日), 법정기념일(法定紀念日), 보름, 생신(生辰), 생일(生日), 설, 설날, 성가정주일(聖家庭主日), 성가정축일(聖家庭祝日), 성금요일(聖金曜日), 성목요일(聖木曜日), 세시(歲時), 신정(新正), 어린이날, 오순절(五旬節), 중양절(重陽節), 중추가절(仲秋佳節), 추석(秋夕), 추석명절(秋夕名節), 추수감사절(秋收感謝節), 칠석(七夕), 크리스마스(Christmas), 탄신(誕辰) </p> 절기 : 1년을 단위로 해서 반복되며, 기후적 조건에 의해 특징지어지는 계절상의 날 <p class="message"> 경칩(驚蟄), 곡우(穀雨), 대서(大署), 대한(大寒), 말복(末伏), 삼복(三伏), 소서(小暑), 수릿날, 아기동지(__冬至), 입동(立冬), 입추(立秋), 입춘(立春), 입하(立夏), 절기(節氣), 처서(處暑), 청명(淸明), 초복(初伏), 추분(秋分), 춘분(春分) </p> 계절 : 1년을 단위로 해서 반복되는, 기후적 조건에 의해 특징지어지는 기간 <p class="message"> 가을, 가을철, 겨울, 겨울철, 계절(季節), 만추(晩秋), 봄, 봄철, 사계(四季), 사철(四_), 성하(盛夏), 양춘가절(陽春佳節), 엄동(嚴冬), 여름, 여름철, 올봄, 이른봄, 장마철, 철, 첫여름, 초가을(初__), 초겨울(初__), 초여름(初__), 춘계(春季), 춘추(春秋) </p> 요일 : 1주일을 단위로 해서 반복되는 날 <p class="message"> 금요일(金曜日), 목요일(木曜日), 수요일(水曜日), 월요일(月曜日), 일요일(日曜日), 주일(主日), 토요일(土曜日), 화요일(火曜日) </p> 하루중 단계 : 하루를 단위로 해서 반복되는 특정 기간 <p class="message"> 간밤, 그저께, 긴긴밤, 깜깜밤중(___中), 낮, 달밤, 대낮, 밤중(_中), 백주(白晝), 사시(巳時), 상오(上午), 새벽, 새벽녘, 석양(夕陽), 심야(深夜), 아침, 아침결, 야경(夜更), 야밤(夜_), 야밤중(夜_中), 야음(夜陰), 여명(黎明), 오시(午時), 오전(午前), 오후(午後), 자시(子時), 자정(子正), 저녁, 저녁나절, 정오(正午), 조조(早朝), 주간(晝間), 주야(晝夜), 초경(初更), 초저녁(初__), 하오(下午), 해거름, 해질녘 </p> 달 <p class="message"> 사월(四月), 삼월(三月), 섣달, 시월(十月), 오월(五月), 이월(二月), 일월(一月), 정월(正月), 칠월(七月), 팔월(八月) </p>  #### 수량시간 **수량시간**이란 시간 축 상의, 일정한 폭을 갖는 부분. 시간적 길이에 의해 규정되는 시간 축 상의 부분입니다. <p class="message"> 격세(隔世), 격일(隔日), 나날, 나흘, 날짜, 누차(屢次), 다년(多年), 단기(短期), 단기간(短期間), 달포, 닷새, 만대(萬代), 만세(萬世), 매일(每日), 며칠, 반일(半日), 백년(百年), 백일(百日), 사나흘, 사흘, 삽시간(_時間), 세기(世紀), 세대(世代), 수년(數年), 수일(數日), 순간(瞬間), 순식간(瞬息間), 야간(夜間), 억대(億代), 여드레, 역대(歷代), 연도(年度), 연일(連日), 연중(年中), 연한(年限), 열흘, 엿새, 영겁(永劫), 영원(永遠), 오랫동안, 온종일(_終日), 이레, 이태, 이틀, 일거(一擧), 일경(一更), 일년(一年), 일대겁(一大劫), 일생(一生), 일세(一世), 일촌광음(一寸光陰), 잠깐, 잠시(暫時), 장엄겁(莊嚴劫), 전생애(全生涯), 종래(從來), 종신(終身), 종일(終日), 진종일(盡終日), 짬, 찰나(刹那), 천년(千年), 촌각(寸刻), 촌음(寸陰), 칠순(七旬), 평생(平生), 플랫(flat), 필생(筆生), 하루, 하룻밤, 학기(學期), 한나절, 한시(_時), 한평생(_平生), 회기(會期) </p> #### 속성시간 **속성시간**이란 특정 속성에 의해 규정되는, 순환적으로 반복되지 않는 시간 축 상의 부분입니다. <p class="message"> 갑년(甲年), 강점기(强占期), 겨를, 경각(頃刻), 계제(階梯), 고대(古代), 길일(吉日), 난세(亂世), 난시(亂時), 납기(納期), 내용연수(耐用年數), 노경(老境), 노정(路程), 농번기(農繁期), 대목, 마감시간(磨勘時間), 만기(滿期), 말세(末世), 망중한(忙中閑), 밀월(蜜月), 산월(産月), 상중(喪中), 생애(生涯), 생전(生前), 수유기(授乳期), 시간대(時間帶), 신혼(新婚), 여가(餘暇), 연가(年暇), 연휴(連休), 예고기간(豫告期間), 예년(例年), 예정일(豫定日), 원년(元年), 원점(原點), 위험기간(危險期間), 유예기간(猶豫期間), 으스름달밤, 인생(人生), 일생일세(一生一世), 임기(任期), 임시공휴일(臨時公休日), 입원기간(入院期間), 장날(場_), 장시간(長時間), 재임기간(在任期間), 적령기(適齡期), 적시(適時), 전환기(轉換期), 절찬리(絶讚裡), 정년(停年), 정시(定時), 제철, 중세(中世), 평년(平年), 평상시(平常時), 평소(平素), 평시(平時), 풍년(豊年), 하루아침, 한동안, 한참, 현대(現代), 호일(好日), 혼기(婚期), 흉년(凶年) </p> 순간속성시간 <p class="message"> 손익분기점(損益分岐點), 얼떨결, 엉겁결, 완료시(完了時), 위기일발(危機一髮), 일순간(一瞬間), 임시(臨時), 전환점(轉換點), 천시(天時), 천재일시(千載一時), 첫날밤, 첫날저녁, 초야(初夜) </p> 지속속성시간 <p class="message"> 갱년기(更年期), 과도기(過渡期), 못자리철, 보릿고개, 사춘기(思春期), 성세(盛世), 성장기(成長期), 식민시대(植民時代), 여생(餘生), 연휴기간(連休其間), 유통기한(流通期限), 일정기간(一定期間), 전성기(全盛期), 조사기간(調査期間), 중기(中期), 청춘(靑春), 초로(初老), 학창시절(學窓時節), 형기(刑期), 호시절(好時節) </p>  #### 부분시간 **부분시간**이란 과정의 시간적 전개 내에서 시간적 위치에 의해 규정되는 부분입니다. <p class="message"> 끝장, 마지막, 막바지, 막판, 말년(末年), 말로(末路), 말엽(末葉), 말일(末日), 반생(半生), 벽두(劈頭), 상반기(上半期), 새해벽두(__劈頭), 시초(始初), 시한(時限), 애당초(_當初), 연두(年頭), 원래(元來), 원초(原初), 전반기(前半期), 종국(終局), 종말(終末), 종반(終盤), 주중(週中), 주초(週初), 중도(中途), 중반(中盤), 중반기(中盤期), 중순(中旬), 중엽(中葉), 첨, 첫날, 첫판, 초기(初期), 초기단계(初期段階), 초년(初年), 초두(初頭), 초면(初面), 초반(初盤), 초순(初旬), 초엽(初葉), 초일(初日), 초전(初戰), 초창기(草創期), 초판(初_), 초행길(初行_), 최종(最終), 최종단계(最終段階), 최종일(最終日), 최초(最初), 최후(最後), 하반기(下半期), 후반(後半), 후반기(後半期) </p>  #### 화시적시간 **화시적시간**이란 화시적 중심(deictic center)을 기준으로 해서 위치가 정해지는 시간 축 상의 부분입니다. <p class="message"> 금세기(今世紀), 당장(當場), 모일(某日), 어제오늘, 오늘내일(__來日), 차기(次期) </p> 과거 : 시간 축 상의, 발화시 이전의 부분 <p class="message"> 거년(去年), 과거(過去), 그간(_間), 그끄저께, 그제, 기왕(旣往), 기존(旣存), 당대(當代), 당시(當時), 만고(萬古), 상고(上古), 상대(上代), 어저께, 어제, 어젯밤, 엊그제, 예, 예전(_前), 옛날, 옛날옛적, 오래전(__前), 왕년(往年), 작년(昨年), 재래(在來), 재작년(再昨年), 저번(這番), 전번(前番), 전생(前生), 전일(前日), 종전(從前), 지난날, 지난달, 지난번(__番), 지난해, 진작, 최근(最近), 태고(太古), 한때 </p> 현재 : 시간 축 상의, 발화시와 겹치는 부분 <p class="message"> 근년(近年), 근래(近來), 근자(近者), 금년(今年), 금세(今世), 금시(今時), 금주(今週), 당년(當年), 오늘, 오늘날, 올해, 요사이, 요즈음, 요즘, 이날이때, 이날입때, 이맘때, 이제, 작금(昨今), 지금(只今), 차제(此際), 현단계(現段階), 현세(現世), 현시점(現時點), 현재(現在) </p> 미래 : 시간 축 상의, 발화시 이후의 부분 <p class="message"> 그글피, 글피, 내년(來年), 내년도(來年度), 내달(來_), 내일(來日), 내주(來週), 뒷날, 명년(明年), 명일(明日), 모레, 미구(未久), 미래(未來), 미래영겁(未來永劫), 성수겁(星宿劫), 앞날, 이듬해, 이튿날, 이후(以後), 익년(翌年), 장래(將來), 차후(此後), 추후(追後), 향후(向後), 후년(後年), 후일(後日), 훗날(後_) </p>  #### 관계시간 **관계시간**이란 시간 축 상의 다른 부분을 기준으로 해서 위치가 정해지는 시간 축 상의 부분입니다. <p class="message"> 기원후(紀元後), 나중, 늦가을, 다음, 다음날, 당일(當日), 당초(當初), 동시(同時), 동시다발(同時多發), 동시대(同時代), 동일(同日), 동지섣달(冬至__), 막간(幕間), 먼젓번(__番), 미연(未然), 사후(事後), 산후(産後), 생후(生後), 식후(食後), 어간(於間), 연후(然後), 오래간만, 오랜만, 와중(渦中), 유사(有史), 이왕(已往), 이전(以前), 익일(翌日), 일시(一時), 자고(自古), 전날(前_), 전년(前年), 전반(前半), 전야(前夜), 전전(戰前), 정각(正刻), 직전(直前), 직후(直後), 혼전(婚前), 후(後) </p>  #### 역사시간 <p class="message"> 고려시대(高麗時代), 구석기시대(舊石器時代), 구한말(舊韓末), 근대(近代), 근세(近世), 기원전(紀元前), 냉전시대(冷戰時代), 봉건시대(封建時代), 왕조시대(王朝時代), 원시(原始), 일제시대(日帝時代), 전근대(前近代), 청동기시대(靑銅器時代) </p>  ### 방법 **방법**이란 어떤 목표를 달성하기 위해 사용하는 것입니다. <p class="message"> 간략(幹略), 개선안(改善案), 개혁정책(改革政策), 계교(計巧), 계략(計略), 계책(計策), 교통대책(交通對策), 구조조정안(構造調整案), 국가정책(國家政策), 국책(國策), 궁술(弓術), 권모술수(權謀術數), 근본대책(根本對策), 기계화농업(機械化農業), 기공(技工), 기교(技巧), 기법(技法), 깍둑썰기, 노동정책(勞動政策), 노하우(know-how), 논법(論法), 논조(論調), 농법(農法), 다각(多角), 다수결(多數決), 단계교수법(段階敎授法), 단방(單放), 단번(單番), 대량관찰법(大量觀察法), 대북정책(對北政策), 대비책(對備策), 대외정책(對外政策), 대응책(對應策), 도량형(度量衡), 도법(道法), 독법(讀法), 등거리외교(等距離外交), 마법(魔法), 마술(魔術), 명인방법(明認方法), 모드(mode), 목적해석(目的解釋), 몽타주(montage), 묘법(妙法), 묘책(妙策), 물간법(__法), 미봉책(彌縫策), 방도(方途), 방법(方法), 방식(方式), 방어방법(防禦方法), 방책(方策), 방침(方針), 방편(方便), 백방(百方), 백핸드(backhand), 범죄예방책(犯罪豫防策), 별수(別_), 병법(兵法), 복지정책(福祉政策), 비결(秘訣), 비방(秘方), 비법(秘法), 비책(秘策), 사중(四重), 사회안전망(社會安全網), 사후대책(事後對策), 사후약방문(死後藥方文), 산술(算術), 삼각측량법(三角測量法), 삼단논법(三段論法), 삼중(三重), 삼중대위법(三重對位法), 상법(商法), 상형(象形), 상호교수법(相互敎授法), 생계수단(生計手段), 생존전략(生存戰略), 생활양식(生活樣式), 선언추론식(選言推論式), 소명방법(疏明方法), 속기법(速記法), 속독법(速讀法), 속임수(__數), 수단(手段), 수법(手法), 수선법(手選法), 수작업(手作業), 술법(術法), 술수(術數), 술책(術策), 습식(濕式), 승부수(勝負手), 시가법(時價法), 시책(施策), 안정책(安定策), 알고리듬(algorithm), 알고리즘(algorism), 알레고리(allegory), 약식(略式), 양면작전(兩面作戰), 양팔간격(兩_間隔), 어법(漁法), 언로(言路), 엄격대위법(嚴格對位法), 에이엠(AM), 에칭(etching), 여성정책(女性政策), 역법(曆法), 열전기발전(熱電氣發電), 영법(泳法), 오(伍), 온라인시스템(on-line system), 완성종지법(緩聲終止法), 외교정책(外交政策), 요령(要領), 요법(療法), 용법(用法), 원근법(遠近法), 월부(月賦), 유발시험법(誘發試驗法), 은유(隱喩), 음각(陰刻), 음력(陰曆), 음악치료법(音樂治療法), 응급수단(應急手段), 이분법(二分法), 인사정책(人事政策), 인편(人便), 일광요법(日光療法), 일필(一筆), 입력시스템(入力___), 입법조치(立法措置), 입식(立式), 자구책(自救策), 작법(作法), 작전(作戰), 작풍(作風), 장물리, 재벌정책(財閥政策), 적대정책(敵對政策), 전격(電擊), 전략(戰略), 전문경영(專門經營), 전법(戰法), 전세(傳貰), 전술(戰術), 절충못자리(折衷___), 점묘(點描), 접근방법(接近方法), 접근방식(接近方式), 정공(正攻), 정공법(正攻法), 정략(政略), 정시통화(定時通話), 정좌법, 정책(政策), 조립식(組立式), 조작법(操作法), 주관식(主觀式), 주법(奏法), 주생활수단(主生活手段), 주요정책(主要政策), 즉시통화(卽時通話), 지로(giro), 지방흡입술(脂肪吸入術), 직유(直喩), 직접(直接), 직접교수법(直接敎授法), 직통(直通), 진법(陳法), 진흥책(振興策), 차선책(次善策), 차편(車便), 창법(唱法), 책략(策略), 처세술(處世術), 철도편(鐵道便), 첩경(捷徑), 청단(靑短), 최면술(催眠術), 최후수단(最後手段), 추첨식(抽籤式), 치료법(治療法), 치유책(治癒策), 침술(鍼術), 크롤(crawl), 타개책(打開策), 탁마(琢磨), 태클(tackle), 테크닉(technic), 편법(便法), 피해대책(被害對策), 필법(筆法), 필사(必死), 필촉(筆觸), 해결책(解決策), 화법(話法), 활로(活路), 회유책(懷柔策) </p>  ### 기술 <p class="message"> 개심술(開心術), 도술(道術), 독심술(讀心術), 묘기(妙技), 무술(武術), 무예(武藝), 복술(卜術), 사칙(四則), 서도(書道), 서법(書法), 수예(手藝), 수지침(手指鍼), 안마술(按摩術), 연금술(鍊金術), 용병술(用兵術), 웅변술(雄辯術), 의술(醫術), 인술(仁術), 조각술(彫刻術), 주술(呪術), 주특기(主特技), 철공(鐵工), 첨단기술(尖端技術), 침선(針線), 항공술(航空術) </p>  ### 역할 **역할**이란 어떤 대상이 특징적으로 하는 일 또는 하도록 되어 있는 일입니다. <p class="message"> 가사부담(家事負擔), 고임(苦任), 공무(公務), 과업(課業), 구실, 단역(端役), 배역(配役), 병무(兵務), 병참(兵站), 본분(本分), 서무(庶務), 아역(兒役), 악역(惡役), 역할(役割), 일익(一翼), 일자리, 일직(日直), 잡역(雜役), 전업(專業), 전직(前職), 주역(主役), 중책(重責), 직능(職能), 직무(職務), 직분(職分), 책무(責務), 천직(天職), 카메오, 포지션(position), 행정(行政) </p>  #### 직책 **직책**이란 인간 조직 내의 위치에 의해 특징 지어지는 역할을 가리킵니다. <p class="message"> 감투, 고위직(高位職), 공직(公職), 관리직(管理職), 관직(官職), 교직(敎職), 데스크(desk), 말직(末職), 벼슬, 보직(補職), 사무직(事務職), 생산직(生産職), 성직(聖職), 소위장군(昭威將軍), 왕위(王位), 왕좌(王座), 요직(要職), 장교(將校), 전문직(專門職), 조사요원(調査要員), 조직위원(組織委員), 직(職), 직급(織級), 직위(職位), 직책(職責), 참봉(參奉), 참판(參判), 청운(靑雲), 한직(閒職), 현감(縣監), 현역(現役), 현직(現職) </p>  ### 범주 **범주**란 개체들을 어떤 기준에 따라 한데 묶은 것입니다. <p class="message"> 갑충(甲蟲), 계열, 고유계정(固有計定), 공유폴더(共有_), 금융계(金融界), 기종(機種), 단속대상(團束對象), 단위(單位), 동종(同種), 물장군과(_將軍科), 바늘꽃과(___科), 반열(班列), 범주(範疇), 부류(部類), 분꽃과(粉_科), 사회갈래(社會__), 산업별(産業別), 수종(樹種), 어류(漁類), 어족(漁族), 어종(漁種), 업종(業種), 연령층(年齡層), 영장류(靈長類), 인간계(人間界), 인기순위(人氣順位), 일반(一般), 장르(genre), 정치제도(政治制度), 정치질서(政治秩序), 정치체제(政治體制), 정치풍토(政治風土), 종류(種類), 종류별(種類別), 종목(種目), 지렁이강(___綱), 지연(地緣), 차종(車種), 친고죄(親告罪), 카테고리, 타입(type), 토종(土種), 특정(特定), 특종(特種), 팔각목(八脚目), 포유류(哺乳類), 폴더(folder), 품종(品種), 화폐단위(貨幣單位) </p>  ### 속성 **속성**이란 어떤 대상이 지니는, 비교적 지속성이 있는 특성입니다. <p class="message"> 가로세로, 가치(價値), 감각(感覺), 감성(感性), 강산(江山), 강점(强點), 개성(個性), 개연성(蓋然性), 거만(倨慢), 건강체질(健康體質), 걸음걸이, 격차(隔差), 경관(景觀), 경력(經歷), 경사(傾斜), 경위(涇渭), 경치(景致), 계층(階層), 고속(高速), 고용지표(雇用指標), 고유(固有), 고저(高低), 고하(高下), 골상(骨相), 공공(公共), 관계(關係), 관상(觀相), 관운(官運), 관작(官爵), 구도(構圖), 구미(口味), 구비(口碑), 구조(構造), 국가이미지(國家___), 국번(局番), 국위(國威), 국익(國益), 국체(國體), 궁극적(窮極的), 귀가성(歸家性), 귀인대가리(貴人___), 극성(極性), 급(級), 급수(級數), 기(氣), 기내용(機內用), 기백(氣魄), 기본기(基本技), 기세(氣勢), 기술(技術), 기술적(技術的), 기울기, 기자정신(記者精神), 기적적(奇跡的), 기질(氣質), 기풍(氣風), 기후(氣候), 나잇살, 낙제점(落第點), 내구(耐久), 내륙성(內陸性), 내음, 내파음(內破音), 넋, 논리(論理), 논증구조(論證構造), 농업용(農業用), 높낮이, 누명(陋名), 뉘앙스(뉘앙스), 능동성(能動性), 다단계(多段階), 단점(短點), 당세(黨勢), 덕(德), 덕목(德目), 도량(度量), 도시날씨(都市__), 독성(毒性), 돈가치(_價値), 돈방석(_方席), 동심(童心), 동업(同業), 득실(得失), 등급(等級), 등산용, 등위(等位), 디지털(digital), 때깔, 똥배짱, 띠동갑(_同甲), 레벨(level), 말투(_套), 맛, 매일반(_一般), 맵시, 맷집, 멋, 면목(面目), 명(命), 몰골, 몸매, 문양(文樣), 문체(文體), 문화(文化), 물망(物望), 물성(物性), 미(美), 미각(味覺), 미모(美貌), 민생(民生), 민선(民選), 민속(民俗), 밝기, 밥맛, 배산임수(背山臨水), 버릇, 보수성향(保守性向), 보편(普遍), 보편성(普遍性), 보호색(保護色), 복색(服色), 본금새(本__), 본능(本能), 본래(本來), 본색(本色), 본업(本業), 본연(本然), 본직(本職), 본질(本質), 비위(脾胃), 빛깔, 사주(四柱), 산색(山色), 살결, 상세(狀勢), 상습(常習), 색(色), 색깔(色_), 색상(色相), 색조(色調), 색채(色彩), 생태(生態), 서열(序列), 성결(性_), 성별(性別), 성향(性向), 세(勢), 소비성향(消費性向), 소비행태(消費行態), 소지(素地), 속성(屬性), 손맛, 수질(水質), 수집벽(蒐集癖), 수평각(水平角), 순기능(順機能), 술버릇, 숭고미(崇高美), 습관(習慣), 습성(習性), 승산(勝算), 승세(勝勢), 승차감(乘車感), 시류(時流), 시심(詩心), 시영(市營), 시풍(詩風), 시한부(時限附), 식성(食性), 신분(身分), 신수(身手), 신용등급(信用等級), 실용(實用), 실제(實際), 심급(審級), 심도(深度), 심리(心理), 심보(心_), 심성(心性), 쓰임, 쓰임새, 씀씀이, 악덕(惡德), 악독(惡毒), 안색(顔色), 액운(厄運), 야성(野性), 약소(弱小), 약점(弱點), 약효(藥效), 양기(陽氣), 양약(良藥), 양장(洋裝), 어감(語感), 어투(語套), 얼굴색, 연초록(軟草綠), 염기(鹽氣), 영양가(營養價), 영양소(營養素), 오디오(audio), 외래식(外來式), 용도(用途), 용모(容貌), 용태(容態), 우격다짐, 우성(優性), 우열(優劣), 원기(元氣), 원만성(圓滿性), 원상(原狀), 원색(原色), 원판(元_), 원형(原形), 위계(位階), 위계질서(位階秩序), 위로조(慰勞調), 위상(位相), 위풍(威風), 위험부담(危險負擔), 유형(有形), 육감(六感), 음가(音價), 음보(音步), 음색(音色), 음향효과(音響效果), 응분(應分), 응시자격(應試資格), 의식수준(意識水準), 이골, 이모저모, 이목(耳目), 이색(異色), 이재(理財), 이중(二重), 이채(異彩), 이형(異形), 익명(匿名), 인간드라마(人間___), 인간성(人間性), 인명(人命), 인상(人相), 인성(人性), 인품(人品), 일괄구조(一括構造), 일상(日常), 입맛, 자격(資格), 자색(姿色), 자세(姿勢), 자아(自我), 잘잘못, 잠재가치(潛在價値), 장단점(長短點), 장세(場勢), 장족(長足), 재무구조(財務構造), 재색(才色), 재야(在野), 저축성향(貯蓄性向), 적격성(適格性), 적령(適齡), 적법성(適法性), 적성(適性), 전체화면(全體畵面), 점성(粘性), 정규(正規), 정기(精氣), 정서(情緖), 정세(情勢), 정신(精神), 정신운동성(精神運動性), 정예(精銳), 정작, 정체(正體), 정체성(正體性), 정취(情趣), 정치구조(政治構造), 정형(定形), 제반(諸般), 조망(眺望), 종대(縱隊), 종차(種差), 좌우대칭(左右對稱), 죄질(罪質), 죄책(罪責), 주요(主要), 주조(主潮), 주종(主宗), 주홍(朱紅), 주황(朱黃), 중요(重要), 증세(症勢), 지리(地理), 지위(地位), 지질(地質), 지체, 지행(知行), 직업(職業), 진경(眞景), 진상(眞相), 진실(眞實), 진심(眞心), 진위(眞僞), 진정(眞正), 질(質), 질감(質感), 질서(秩序), 짜임, 차림, 참말, 취미(趣味), 취향(趣向), 태깔(態_), 털북숭이, 토질(土質), 투명도(透明度), 패기(覇 氣), 패션(fashion), 편향성(偏向性), 포커스(focus), 품질(品質), 풍미(風味), 풍수(風水), 풍토(風土), 피부색(皮膚色), 필연(必然), 필치(筆致), 핏기(_氣), 하늘빛, 항문성격(肛門性格), 해학(諧謔), 핸디캡(handicap), 행색(行色), 행실(行實), 허(虛), 허스키(husky), 허우대, 허울, 허점(虛點), 험악(險惡), 험준(險峻), 혁혁(赫赫), 현격(懸隔), 현란(絢爛), 현명(賢明), 혈맥(血脈), 혈색(血色), 형색(形色), 형식(形式), 형질(形質), 호봉(號俸), 호사(好事), 호화(豪華), 혼연(渾然), 혼탁(混濁), 홍안(紅顔), 화기(火氣), 화풍(畵風), 화학친화력(化學親和力), 환형(環形), 횡선(橫線), 효력(效力), 효용(效用), 후광(後光), 후신(後身), 휴대용(携帶用), 흠집(欠_), 희대(稀代) </p>  #### 모양 <p class="message"> 가치체계(價値體系), 각선미(脚線美), 겉모양(_模樣), 겉보기, 경물(景物), 구체(球體), 군진(軍陳), 근경(近景), 꼬라지, 눈매, 뒷모습, 만물상(萬物相), 망상구조(網狀構造), 매무새, 면모(面貌), 모습, 모양(模樣), 모양새(模樣_), 무늬, 문살무늬(門___), 문형(文型), 물상(物像), 발자국, 배경(背景), 번개무늬, 벌집무늬, 범발톱, 복식(服飾), 복장(服裝), 볼품, 산세(山勢), 산천물색(山川物色), 생김새, 생활상(生活相), 서체(書體), 설경(雪景), 어형(漁形), 얼굴, 영상(映像), 옆모습, 옷매무새, 옷맵시, 외견(外見), 외관(外觀), 외모(外貌), 외양(外樣), 외형(外形), 우경(雨景), 원경(遠景), 유통구조(流通構造), 윤곽(輪廓), 인간상(人間像), 입모습, 자태(姿態), 잔금무늬, 장면(場面), 전경(全景), 정경(情景), 참모습, 첫눈, 첫인상(_印象), 체격(體格), 체위(體位), 추세(趨勢), 컬러(color), 태도(態度), 파노라마(panorama), 패턴(pattern), 편대(編隊), 폼(form), 표정(表情), 풍경(風景), 풍광(風光), 풍모(風貌), 풍채(風采), 필적(筆跡), 필체(筆體), 해서(楷書), 형상(形狀), 형용(形容), 형체(形體), 형태(形態), 횡대(橫隊), 흉상(凶相) </p>  #### 크기 **크기**란 정도의 차이를 측정할 수 있는 속성을 의미합니다. <p class="message"> 가속도(加速度), 가슴둘레, 각도(角度), 간격(間隔), 간발(間髮), 감도(感度), 강도(强度), 강우량(降雨量), 경사도(傾斜度), 고도(高度), 공산(公算), 광도(光度), 광도계급(光度階級), 광속(光速), 구독료(購讀料), 국민만족도(國民滿足度), 굵기, 규모(規模), 극값(極_), 기동력(起動力), 기압(氣壓), 기온(氣溫), 기준치(基準値), 길이, 깊이, 날개넓이, 너비, 노동량(勞動量), 논밭넓이, 농도(濃度), 능률(能率), 당도(糖度), 당첨확률(當籤確率), 대소(大小), 대외의존도(對外依存度), 덩지, 덩치, 도수, 두께, 면적(面積), 명도(明度), 몸집, 문수(文數), 물살, 밀도(密度), 반경(半徑), 병집선량(病_線量), 볼륨(volume), 부가가치(附加價値), 부가가치생산성(附加價値生産性), 부피, 북위(北緯), 비중(比重), 빈도(頻度), 빈부격차(貧富隔差), 사이즈(size), 상박위(上膊圍), 색도(色度), 생활수준(生活水準), 선호도(選好度), 성량(聲量), 성장세(成長勢), 수능점수(修能點數), 수신감도(受信感度), 수요(需要), 수요량(需要量), 수입액(收入額), 수준(水準), 수증기밀도(水蒸氣密度), 스케일(scale), 습도(濕度), 시차(時差), 식사량(食事量), 신뢰도(信賴度), 신선도(新鮮度), 신장(身長|身丈), 악력(握力), 안압(眼壓), 안전도(安全度), 압력(壓力), 약간(若干), 열량(熱量), 오염도(汚染度), 용적(容積), 위도(緯度), 위세(威勢), 위험수위(危險水位), 유량(流量), 음량(音量), 음역(音域), 음정(音程), 음조(音調), 음질(音質), 의존도(依存度), 인구(人口), 잔량(殘量), 적설량(積雪量), 적재량(積載量), 전폭(全幅), 점도(粘度), 정확도(正確度), 조금, 조도(照度), 조막, 주량(酒量), 줌몸피, 중량(重量), 중소(中小), 지고(地高), 지압(地壓), 지척(咫尺), 직경(直徑), 진도(進度), 진폭(振幅), 질량(質量), 청력(聽力), 체구(體軀), 체적(體積), 촌수(寸數), 최대량(最大量), 출력(出力), 충격각도(衝擊角度), 치마통, 크기, 타임(time), 탄성위치에너지(彈性位置___), 폭(幅), 품, 학업성취도(學業成就度), 한계생산력(限界生産力), 항성밀도(恒星密度), 혈당치(血糖値), 화재하중(火災荷重), 확률(確率), 환경오염도(環境汚染度), 효율(效率), 흡입량(吸入量) </p>  무게 <p class="message"> 근수(斤數), 몸무게, 무게, 체급(體級), 체중(體重), 하중(荷重) </p>  속도 <p class="message"> 급속도(急速度), 빠르기, 속도(速度), 속력(速力), 스피드(speed), 시속(時速), 이탈속도(離脫速度), 초속(秒速), 템포(tempo), 페이스(pace) </p>  길이 <p class="message"> 마루높이, 마신(馬身), 만리(萬里), 머리통, 물고기길이, 바깥둘레, 밤길, 보폭(步幅), 시반지름(視半__), 음길이(音__), 인치(inch), 지름, 체고(體高), 키, 파장(波長) </p>  넓이 <p class="message"> 넓이, 부대면적(附帶面積), 전용면적(專用面積), 평수(坪數) </p>  각도 <p class="message"> 각거리(角距離), 귀마루흘림, 안기울기 </p>  높이 <p class="message"> 높이, 대기권한계(大氣圈限界), 수심(水深), 천애(天涯), 파고(波高), 해발(海拔) </p>  압력 <p class="message"> 혈압(血壓), 화력(火力) </p>  온도 <p class="message"> 미온(微溫), 수온(水溫), 실내온도(室內溫度), 실온(室溫), 온도(溫度), 체열(體熱), 체온(體溫), 초기열(初期熱), 항온(恒溫), 활주로기온(滑走路氣溫) </p>  나이 <p class="message"> 과년(瓜年), 나, 나이, 묘령(妙齡), 수명(壽命), 연령(年齡), 연배(年輩), 연세(年歲), 천수(天壽), 향년(享年), 환갑(還甲), 회갑(回甲) </p>  #### 수량 **수량**이란 어떤 대상이 지니는, 수나 양과 관련된 속성입니다. <p class="message"> 가중치(加重値), 가짓수(__數), 감점(減點), 갑절, 강설량(降雪量), 강수량(降水量), 거래량(去來量), 건수(件數), 건평(建坪), 공급량(供給量), 교통량(交通量), 국민총생산(國民總生産), 국민총지출(國民總支出), 국제금리(國際金利), 권수(卷數), 금리(金利), 기억용량(記憶容量), 노동생산성(勞動生産性), 노동시간(勞動時間), 다과(多寡), 다우지수(dow__), 단수(_數), 달력나이, 대개(大槪), 득점(得點), 등수(等數), 매수(枚數), 모두, 모집정원(募集定員), 무역수지(貿易收支), 물량(物量), 발행부수(發行部數), 분량(分量), 분배액(分配額), 비율(比率), 사용량(使用量), 생산고(生産高), 생산국민소득(生産國民所得), 생산능력지수(生産能力指數), 생산량(生産量), 생산액(生産額), 석차(席次), 성적(成績), 소계(小計), 소모율(消耗率), 소비량(消費量), 소비자잉여(消費者剩餘), 소출(所出), 손익(損益), 수량(數量), 수확(收穫), 수효(數爻), 순익(純益), 숱, 어획량(漁獲量), 엔트로피(entropy), 연습량(練習量), 연평균(年平均), 용량(用量), 위험률(危險率), 이윤(利潤), 인구수(人口數), 일률(_率), 일산(日産), 일일권장량(勸奬量), 일조량(日照量), 일호(一毫), 입학정원(入學定員), 저장량(貯藏量), 적량(適量), 전량(全量), 점수(點數), 점유율(占有率), 정량(定量), 지수(指數), 총계(總計), 총량(總量), 총원(總員), 총점(總點), 총합(總合), 최종합격선(最終合格線), 출산율(出産率), 출생률(出生率), 출석률(出席率), 출하량(出荷量), 층수(層數), 쿼터(quota), 타수(打數), 통권(通卷), 통화도수(通話度數), 판매량(販賣量), 편차(偏差), 평균(平均), 평점(評點), 폐활량(肺活量), 필요량(必要量), 한번(-番), 할당량(割當量), 함량(含量), 합계(合計), 허용치(許容値), 호구(戶口) </p>  비율 <p class="message"> 경제성장률(經濟成長率), 배당수익율(配當收益率), 배율(倍率), 백분율(百分率), 보통사망률(普通死亡率), 비열(比熱), 사고율(事故率), 사망률(死亡率), 성비(性比), 순도(純度), 승률(勝率), 신장률(伸張律), 연리(年利), 이윤율(利潤率), 이율(利律), 이직률(移職率), 인상률(引上率), 저축률(貯蓄率), 주택보급률(住宅普及率), 증가율(增加率), 찬반비율(贊反比率), 청약률(請約率), 축척(縮尺), 탄성률(彈性率), 환율(換率), 황금비율(黃金比率), 후보지지도(候補支持度), 후보지지율(候補支持率), 흡수율(吸收率) </p>  값 : 돈과 관련된 수량 <p class="message"> 가격(價格), 값, 견적(見積), 곡가(穀價), 공급가격(供給價格), 공매보증금(公賣保證金), 공시지가(公示地價), 공정땅값(公正__), 공제금(控除金), 과징금(課徵金), 구매가격(購買價格), 금액(金額), 노동력(勞動力), 누계(累計), 단가(單價), 도매가격(都賣買價格), 땅값, 매매가격(賣買價格), 물가(物價), 물건값(物件_), 물건비(物件費), 벌점(罰點), 분양가(分讓價), 비용(費用), 삯, 산매시세(散賣時勢), 생산가(生産價), 선가(船價), 소비자물가(消費者物價), 수가(酬價), 수매가(收買價), 액수(額數), 옷값, 운송료(運送料), 원가(原價), 원액(元額), 이자(利子), 잉여가치(剩餘價値), 재평가차액(再評價差額), 정가(定價), 정상가격(正常價格), 지가(地價), 차액(差額), 총액(總額), 최저생활비(最低生活費), 최종낙찰가(最終落札價), 치(値), 침대요금(寢臺料金), 판매가(販賣價), 판매액(販賣額), 평가(平價), 평균치(平均値), 표준생활비(標準生活費), 품삯, 화대(花代) </p>  #### 식별속성 **식별속성**이란 개체의 식별에 기준이 되는 속성을 가리킵니다. <p class="message"> 고유브랜드(固有_), 군번(軍番), 메일계정(mail__), 본적(本籍), 생업(生業), 신원(身元), 인지도(認知度), 주민번호(住民番號), 차량번호(車輛番號), 출신(出身), 학번(學番), 현주소(現住所) </p>  이름 : 어떤 대상을 identify할 때 사용하기 위해 그 대상에 부여한 것 <p class="message"> 가명(假名), 가칭(假稱), 곡목(曲目), 관명(官名), 국명(國名), 국호(國號), 당명(黨名), 명색(名色), 명칭(名稱), 법명(法名), 별명(別名), 별칭(別稱), 별호(別號), 병명(病名), 본명(本名), 부제(副題), 브랜드(brand), 세칭(世稱), 속명(俗名), 속칭(俗稱), 연호(年號), 영화제목(映畵題目), 예명(藝名), 원제(原題), 유명브랜드(有名___), 유명상표(有名商標), 이름, 작호(爵號), 제목(題目), 존칭(尊稱), 존함(尊銜), 죄명(罪名), 죄목(罪目), 지명(地名), 지칭(指稱), 직명(職名), 직함(職銜), 천왕(天王), 천황(天皇), 친족명칭(親族名稱), 칭호(稱號), 타이틀(title), 택호(宅號), 통칭(通稱), 표제(標題|表題), 필명(筆名), 학명(學名), 함자(銜字) </p>  (1) 인간이름 : 사람과 관련된 이름 <p class="message"> 성명(姓名), 성씨(姓氏), 성함(姓銜), 시호(諡號), 아명(兒名), 아호(雅號), 악명(惡名), 애칭(愛稱), 호칭(呼稱) </p>  소속 : 어떤 대상이 속한 집단에 의해 결정되는 속성 <p class="message"> 계급(階級), 국적(國籍), 문하(門下), 이중국적(二重國籍), 주소(住所) </p>  계통 : 어떤 대상의 기원 <p class="message"> 명맥(命脈), 모계(母系), 문벌(門閥), 방계(傍系), 부계(父系), 시원(始原), 어원(語原), 여염집(閭閻_), 연원(淵源), 직계(直系), 태생(胎生), 토착(土着), 혈통(血統), 혼혈(混血) </p>  #### 능력 **능력**이란 어떤 대상이 지닌, 어떤 일을 할 수 있는 힘입니다. <p class="message"> 가독성(可讀性), 가창력(歌唱力), 감상력(鑑賞力), 강권(强權), 관능(官能), 교원자격증(敎員資格證), 국가경쟁력(國家競爭力), 국제경쟁력(國際競爭力), 기능성(機能性), 기량(技倆), 기술경쟁력(技術競爭力), 기억력(記憶力), 기예(技藝), 기초학력(基礎學力), 내공(內功), 눈치, 능력(能力), 담력(膽力), 돌파력(突破力), 듣기감각(__感覺), 리더십(leadership), 마력(魔力), 매력(魅力), 모성(母性), 묘수(妙手), 무력(武力), 미력(微力), 사고능력(事故能力), 사고력(思考力), 사리분별력(事理分別力), 상상력(想像力), 상술(商術), 생명력(生命力), 생산력(生産力), 성능(性能), 성장에너지(成長___), 센스(sense), 소질(素質), 솜씨, 수비력(守備力), 수사력(搜査力), 수완(手腕), 수용력(收容力), 수학능력(修學能力), 시력(視力), 식별력(識別力), 신력(神力), 실력(實力), 안목(眼目), 연기력(演技力), 영도력(領導力), 영향력(影響力), 원력(原力), 원식(遠識), 이성(理性), 인식력(認識力), 입심, 자력(自力), 자질(資質), 잠재능력(潛在能力), 잠재력(潛在力), 잠재성장력(潛在成長力), 잡기(雜技), 장기(長技), 저지력(沮止力), 전능(全能), 전문지식(專門知識), 전지전능(全知全能), 접착력(接着力), 정력(精力), 정신력(精神力), 제동력(制動力), 조예(造詣), 조정력(調整力), 주의력(注意力), 지능(知能), 지략(智略), 지력(地力), 지모(智謀), 지음(知音), 지혜(智慧), 진가(眞價), 진력(盡力), 집단응집력(集團凝集力), 체능(體能), 체력(體力), 추리력(推理力), 추진력(推進力), 침투력(浸透力), 카리스마, 통찰력(洞察力), 판단력(判斷力), 패권(覇權), 학력(學力), 호소력(呼訴力), 화술(話術), 효능(效能), 힘 </p>  #### 운 길흉(吉凶), 길흉화복(吉凶禍福), 끗발, 대운(大運), 명운(命運), 무운(武運), 사운(社運), 숙명(宿命), 오복(五福), 요행(僥幸), 운(運), 운수(運數), 일복(_福), 천운(天運), 천행(天幸), 팔자(八字) </p> #### 개인사 <p class="message"> 약력(略歷), 이력(履歷), 전력(前歷), 학벌(學閥) </p> #### 소리속성 <p class="message"> 가짜목소리(假____), 리듬(rhythm), 멜로디(melody), 박자(拍子), 배다리장단, 악센트(accent), 액센트(accent), 억양(抑揚), 여성고음(女聲高音), 장단, 장조(長調), 저조(低調), 짝수박자(_數拍子), 칼장단, 톤(tone) </p> #### 감각 <p class="message"> 공감각(共感覺), 미감(味感), 보기감각(__感覺), 색감(色感), 성감(性感), 순간시(瞬間視), 시각(視覺), 시청각(視聽覺), 오감(五感), 청각(聽覺), 촉각(觸覺), 촉감(觸感), 후각(嗅覺) </p> #### 품격속성 <p class="message"> 감수성(感受性), 격(格), 깡, 덕성(德性), 마음, 마음씨, 매너(manners), 본성(本性), 본심(本心), 불과(佛果), 사람됨, 사람마음, 성격, 성덕(聖德), 성미(性味), 성상(性狀), 성정(性情), 성품(性品), 심덕(心德), 장인의식(匠人意識), 직성(直星), 진면모(眞面貌), 천생(天生), 천성(天性), 체면(體面), 체통(體統), 품격(品格), 품성(品性), 품위(品位), 품행(品行), 효심(孝心) </p>  ### 단위 **단위**란 대상의 수량을 측정할 때 기초가 되는 기준입니다. <p class="message"> 더블(double), 라운드(round), 로그눈금(log__), 모티브, 번지(番地), 벡터(vector), 섭씨(攝氏), 소단위(小段位), 일보(一步), 칼로리(calorie), 학점(學點), 할(割), 횟수(回數) </p>  #### 시간단위 **시간단위**란 시간을 측정할 때 사용되는 단위입니다. <p class="message"> 월간(月刊), 월령(月齡) </p> 기간단위 : 시간 상의 일정한 폭을 나타내는 단위 <p class="message"> 주기(週期), 학년(學年) </p> 시각단위 : 시간축 상의 어떤 점을 가리키기 위해 사용되는 단위  #### 개체단위 **개체단위**란 개체의 수를 세는 데 사용되는 단위입니다. <p class="message"> 켜, 항목(項目) </p>  #### 집합단위 **집합단위**란 일정한 수의 개체들의 집합을 가리키는 단위입니다. <p class="message"> 덩이, 동, 모집단위(募集單位), 묶음, 움큼, 일습(一襲), 한마디 </p>  #### 길이단위 **길이단위**란 공간상의 1차원적인 크기를 측정하는 데 사용되는 단위입니다. <p class="message"> 치수(_數), 피트(feet), 해리(海里) </p>  #### 넓이단위 **넓이단위**란 공간상의 2차원적인 크기를 측정하는 데 사용되는 단위입니다.  #### 부피단위 **부피단위**란 공간상의 3차원적인 크기를 측정하는 데 사용되는 단위입니다. 액체부피단위 : 액체의 부피를 측정하는 데 사용되는 단위 <p class="message"> 홉 </p>  #### 무게단위 **무게단위**란 구체물의 무거운 정도를 측정하는 데 사용되는 단위입니다.  #### 밝기단위 **밝기단위**란 밝은 정도를 측정하는 데 사용되는 단위입니다.  #### 압력단위 **압력단위**란 누르는 힘의 정도를 측정하는 데 사용되는 단위입니다.  ### 방향 **방향**이란 어떤 대상의 이동이나 지향에 있어서 기준이 되는 것입니다. <p class="message"> 극동(極東), 남녘(南_), 남동(南東), 남동쪽(南東_), 남방(南方), 남북(南北), 남서(南西), 남쪽(南_), 남향(南向), 다방면(多方面), 동남쪽(東南_), 동방(東方), 동북(東北), 동서남북(東西南北), 동쪽(東_), 동편(東便), 뒤편(_便), 발전방향(發展方向), 방면(方面), 방위(方位), 방향(方向), 북녘(北_), 북동(北東), 북동쪽(北東_), 북방(北方), 북서(北西), 북쪽(北_), 북측(北側), 북향(北向), 사방(四方), 상하(上下), 상향(上向), 서(西), 서남(西南), 서남쪽(西南_), 서남향(西南向), 서북(西北), 서쪽(西_), 서편(西便), 서향(西向), 세로, 수직(垂直), 오른쪽, 우측(右側), 이쪽, 이쪽저쪽, 일방(一方), 전방(前方), 정동(正東), 정동향(正東向), 정방(丁方), 좌(左), 좌변(左邊), 좌우(左右), 좌향(坐向), 팔방(八方), 풍향(風向), 횡(橫), 후면(後面), 후미(後尾), 후방(後方), 후위(後衛) </p>  ### 사실명제 **사실/명제**란 진리치를 가질 수 있는 것입니다. <p class="message"> 가설(假說), 가언(嘉言), 개관사정(蓋棺事定), 개인정보(個人情報), 공준(公準), 과언(過言), 기밀(機密), 낭보(朗報), 다수의견(多數意見), 대안(代案), 대외비(對外秘), 데이터(data), 멸성제(滅聖諦), 명제(命題), 문의(文義|文意), 법리(法理), 부음(訃音), 비밀(秘密), 비보(悲報), 비사(秘史), 비화(秘話), 사견(私見), 사실(事實), 소극조건(消極條件), 소식(消息), 속설(俗說), 악어이시(惡語易施), 안티테제, 알리바이(alibi), 외신(外信), 원리(原理), 육아정보(育兒情報), 음성정보(音聲情報), 이론(理論), 이용내역(利用內譯), 일설(一說), 전제조건(前提條件), 정보(情報), 조건명제(條件命題), 증거(證據), 지식(知識), 진리(眞理), 테제(these), 톱뉴스(top news), 통설(通說), 평판(評判), 풍설(風說), 해답(解答), 허구(虛構), 허실(虛實), 화제(話題), 희보(喜報), 힌트(hint) </p>  ### 기호 **기호**란 다른 대상을 나타내는, 또는 나타내도록 되어 있는 것입니다. <p class="message"> 각괄호(角括弧), 객어(客語), 계좌번호(計座番號), 고유번호(固有番號), 괄호(括弧), 괘(卦), 기호(記號), 다이어그램(diagram), 라, 레(레), 마크(mark), 번호(番號), 변화기호(變化記號), 보격(補格), 부호(符號), 비밀번호(秘密番號), 상표(商標), 생략표(省略標), 성호(聖號), 세미콜론(semicolon), 소괄호(小括弧), 손톱괄호(__括弧), 스타카토(staccato), 신호(信號), 아이콘(icon), 약호(略號), 엑스(x), 우편번호(郵便番號), 음표(音標), 이탤릭(italic), 일련번호(一連番號), 적십자(赤十字), 전화번호(電話番號), 점괘(占卦), 제곱눈금, 징표(徵表), 콜론(colon), 콤마(comma), 포즈(pause), 표(表), 표징(表徵), 하트(heart), 화재경보(火災警報) </p>  #### 문자 **문자**란 음성언어와의 대응에 의해 성립되는 시각적 기호입니다. <p class="message"> 국문(國文), 국한문(國漢文), 그림문자(__文字), 글씨, 글자(_字), 금문(金文), 금석문(金石文), 금석문자(金石文字), 기역, 꼬부랑글자(____字), 니은, 디귿, 로마자(Roma_), 문자(文字), 미음, 베타(beta), 부수(部首), 사이시옷, 소리글자, 수결(手決), 시그마(sigma), 아, 알파(alpha), 약어(略語), 에스(s), 에프(F), 엔(N), 영문표기(英文表記), 오메가(오메가), 오식(誤植), 오자(誤字), 와이(y), 왜, 외자(_字), 우, 이두(吏讀|吏頭), 이름석자(___字), 이응, 일자(一字), 자막(字幕), 자음(子音), 점자(點字), 철자(綴字), 첨자(添字), 친필(親筆), 키읔, 한글, 한문(漢文), 한자(漢字), 활집창(__<U+9B2F>), 획(劃), 훈민정음(訓民正音) </p>  #### 언어요소 **언어요소**란 언어의 구성요소입니다. <p class="message"> 격언(格言), 경칭(敬稱), 고어(古語), 고언(古言), 구호(口號), 근하신년(謹賀新年), 금언(金言), 덕담(德談), 말, 말씀, 메시지(message), 명구(名句), 명령어(命令語), 명언(名言), 모토(motto), 반미구호(反美口號), 반어(反語), 복음(福音), 비어(卑語), 상성(上聲), 성구(成句), 속담(俗談), 속어(俗語), 숙어(熟語), 슬로건(slogan), 시구(詩句), 시어(詩語), 신어(新語), 암구호(暗口號), 어휘(語彙), 언사(言辭), 언질(言質), 여불비(餘不備), 예문(例文), 용어(用語), 용언(用言), 유언비어(流言蜚語), 육두문자(肉頭文字), 은어(隱語), 의성어(擬聲語), 이적표현(利敵表現), 일언반구(一言半句), 잠언(箴言), 전문어(專門語), 전문용어(專門用語), 전언(傳言), 존댓말(尊待_), 좌우명(座右銘), 필설(筆舌), 학술용어(學術用語), 한자어(漢字語), 훈(訓) </p>  #### 언어단위 **언어단위**란 언어 체계의 위계에서 일정한 위치를 차지하는 단위입니다. <p class="message"> 가름도움줄기, 과거완료(過去完了), 관계대명사(關係代名詞), 구절(句節), 귀절, 꼴그림씨, 낱말, 단모음(單母音), 단문(單文), 단어(單語), 단음(單音), 대명사(代名詞), 도움그림씨, 동명사(動名詞), 두음(頭音), 뒷말, 말경계선(_境界線), 모음(母音), 목적격(目的格), 문장(文章), 서술문(敍述文), 서술부(敍述部), 어절(語節), 운율(韻律), 월, 음소(音素), 음운(音韻), 음절(音節), 이해어휘(理解語彙), 인칭(人稱), 자구(字句), 장음(長音), 접사(接辭), 접어(接語), 종성(終聲), 주격(主格), 주어(主語), 초성(初聲), 추상명사(抽象名詞), 토, 홑소리 </p>  #### 언어범주 <p class="message"> 겹그림씨, 모임이름씨, 보어(補語), 부사(副詞), 불규칙동사(不規則動詞), 불완전동사(不完全動詞), 생각씨, 성조(聲調), 술어(述語), 시제(時制), 실사(實辭), 양성모음(陽性母音), 어근(語根), 어말(語末), 여럿이름씨, 으뜸그림씨, 의문대명사(疑問代名詞), 인칭대명사(人稱代名詞), 접두어(接頭語), 조동사(助動詞), 종결어미(終結語尾), 진행완료시(進行完了時), 처격(處格), 체언(體言), 품사(品詞), 현재진행형(現在進行形) </p>  ### 기호체계 **기호체계**란 기호들로 이루어진 체계입니다. <p class="message"> 랑그(랑그), 반과거(半過去), 소유격(所有格), 수동형(受動形) </p>  #### 언어 **언어**란 인간의 진화 과정에서 자연적으로 형성된 언어입니다. <p class="message"> 고대국어(古代國語), 국한문체(國漢文體), 소리마디, 수화(手話), 시각언어(視覺言語), 언문(言文), 언어(言語), 원어(原語), 자연어(自然語) </p>  언어명 : 특정 언어(langue)의 이름 <p class="message"> 고대영어(古代英語), 노어(露語), 독어(獨語), 독일어(獨逸語), 라틴어(Latin_), 범어(梵語), 불어(佛語), 영어(英語), 우리말, 일어(日語), 중국어(中國語), 한국말(韓國_), 희랍어(希臘語) </p>  속성관계언어 : 특정 속성이나 관계에 의해 규정되는 언어 <p class="message"> 경어(敬語), 구어(口語), 국어(國語), 근대국어(近代國語), 모국어(母國語), 모어(母語), 문어(文語), 반말(半_), 방언(方言), 사어(死語), 사투리, 서울말, 외국어(外國語), 외래어(外來語), 중세국어(中世國語), 지방어(地方語) </p>  #### 비언어기호체계 **비언어기호체계**란 인간이 인위적으로 만들어낸 기호체계입니다. <p class="message"> 간지(干支), 암호(暗號), 음성신호(音聲信號) </p>  ### 자연법칙 **자연법칙**이란 모든 대상이 자연적으로 항상 일정하게 따르는 것입니다. <p class="message"> 법칙(法則), 생리(生理), 섭리(攝理), 정칙(正則) </p>  ### 규범 **규범**이란 인간이 따르도록 되어 있는 것입니다. <p class="message"> 가례(家禮), 강령(綱領), 개정안(改正案), 개혁안(改革案), 검사기준(檢査基準), 게임규칙(game__), 계급도덕(階級道德), 계명(誡命), 계율(戒律), 고제(古制), 공의(公義), 공익(公益), 공중도덕(公衆道德), 관례(慣例), 관습(慣習), 교리(敎理), 교통질서(交通秩序), 국시(國是), 군율(軍律), 규격(規格), 규약(規約), 규율(規律), 규준(規準), 규칙(規則), 근본원칙(根本原則), 금기(禁忌), 금지규정(禁止規定), 급훈(級訓), 기강(紀綱), 기본(基本), 기본원칙(基本原則), 기율(紀律), 내규(內規), 다도(茶道), 다수결원리(多數決原理), 다수결원칙(多數決原則), 단일성원칙(單一性原則), 당규(黨規), 당기(黨紀), 당헌(黨憲), 대의(大義), 도덕(道德), 도덕률(道德律), 도리(道理), 도의(道義), 독트린(doctrine), 룰(rule), 맞춤법(__法), 명분(名分), 문법(文法), 벌칙(罰則), 벌칙규정(罰則規定), 법규(法規), 법도(法度), 보도원칙(報道原則), 본격(本格), 부칙(附則), 불문율(不文律), 사규(社規), 사도(士道), 사회윤리(司會倫理), 사회정의(司會正義), 사회질서(司會秩序), 삼강(三綱), 생명윤리(生命倫理), 생활신조(生活信條), 서식(書式), 수칙(守則), 순리(順理), 시장원리(市場原理), 약관(約款), 에티켓, 여필종부(女必從夫), 예법(禮法), 예의(禮儀), 예의범절(禮儀凡節), 예절(禮節), 오륜(五倫), 원칙(原則), 유속(流俗), 윤리(倫理), 윤리강령(倫理綱領), 율법(律法), 음양원리(陰陽原理), 의(義), 의무사항(義務事項), 이용약관(利用約款), 인륜(人倫), 전통(傳統), 정강(政綱), 정관(定款), 정법(正法), 제례(祭禮), 조례(條例), 조합민주주의(組合民主主義), 준칙(準則), 증거금지(證據禁止), 처벌규정(處罰規定), 천도(天道), 천륜(天倫), 천리(天理), 철칙(鐵則), 총칙(總則), 타율(他律), 토속(土俗), 통칙(通則), 폐습(弊習), 풍기(風紀), 풍속(風俗), 풍습(風習), 학칙(學則), 허례(虛禮), 허식(虛飾), 헌장(憲章), 홍범구주(洪範九疇), 회칙(會則) </p>  #### 법률 <p class="message"> 개혁법안(改革法案), 공법(公法), 관계법(關係法), 국법(國法), 국제법(國際法), 군법(軍法), 근로기준법(勤勞基準法), 금지령(禁止令), 기본법(基本法), 남녀평등권(男女平等權), 노동법(勞動法), 단결금지법(團結禁止法), 단발령(斷髮令), 도로교통법(道路交通法), 독점금지법(獨占禁止法), 민법(民法), 법(法), 법령(法令), 법률(法律), 보호법(保護法), 본령(本令), 부패방지법(腐敗防止法), 상국제법(商國際法), 선거법(選擧法), 세법(稅法), 세율(稅律), 세칙(細則), 시행령(施行令), 실정법(實定法), 실체법(實體法), 악법(惡法), 유신헌법(維新憲法), 율령(律令), 저작권법(著作權法), 정부조직법(政府組織法), 중소기업기본법(中小企業基本法), 처벌법규(處罰法規), 처벌조항(處罰條項), 치외법권(治外法權), 태형(笞刑), 통금(通禁), 특별법(特別法), 판례(判例), 포고령(布告令), 해외이주법(海外移住法), 헌법(憲法), 현행법(現行法), 형법(刑法), 화란경매법(和蘭競賣法), 환경보전법(環境保全法) </p>  ### 관습 <p class="message"> 고례(古禮), 국풍(國風), 발효문화(醱酵文化), 상관습(商慣習), 상례(常例), 습속(習俗), 악습(惡習), 양속(良俗), 유교문화(儒敎文化), 음식문화(飮食文化), 인습(因習), 족벌세습(族閥世襲), 주거문화(住居文化), 차격식(茶格式), 통례(通例), 학벌카스트(學閥___), 혼전동거(婚前同居), 혼전순결(婚前純潔) </p>  ### 권력 **권력**이란 다른 사람에게 영향을 끼칠 수 있는 힘입니다. <p class="message"> 강제력(强制力), 공권력(公權力), 국가권력(國家權力), 권력(權力), 금권(金權), 대권(大權), 독재권력(獨裁權力), 독재정권(獨裁政權), 병권(兵權), 세도(勢道), 세력(勢力), 실권(實權), 실세(實勢), 왕권(王權), 외세(外勢), 절대권(絶對權), 절대권력(絶對權力), 정권(政權), 정치권력(政治權力), 정치력(政治力), 좌파정권(左派政權), 헤게모니 </p>  ### 권리 **권리**란 인간이 지니는 것으로서, 어떤 행위를 하거나 어떤 행위를 받을 수 있게 하는 것입니다. <p class="message"> 관권(官權), 교권(敎權), 교원임면권(敎員任免權), 구분소유권(區分所有權), 국권(國權), 국회해산권(國會解散權), 권리(權利), 권익(權益), 권한(權限), 근로권(勤勞權), 기득권(旣得權), 기본권리(基本權利), 단결권(團結權), 단체교섭권(團體交涉權), 당사자능력(當事者能力), 대상청구권(代償請求權), 모권(母權), 묵비권(默秘權), 물권(物權), 민권(民權), 발언권(發言權), 배상청구권(賠償請求權), 병역거부권(兵役拒否權), 부권(父權), 사유재산권(私有財産權), 사진저작권(寫眞著作權), 삼권(三權), 선거권(選擧權), 선수권(選手權), 소유권(所有權), 수익권(受益權), 신권(神權), 실용특허권(實用特許權), 심의권(審議權), 여권(女權), 여성참정권(女性參政權), 의결권(議決權), 이권(利權), 인권(人權), 임명권(任命權), 임용권(任用權), 자결권(自決權), 자율권(自律權), 재산청구권(財産請求權), 전권(全權), 제작권(製作權), 주권(主權), 주차단속권(駐車團束權), 지휘권(指揮權), 직권(職權), 초야권(初夜權), 친권(親權), 통솔권(統率權), 특권(特權), 특허(特許), 특허권(特許權), 판권(版權), 평등(平等), 피선거권(被選擧權), 행복추구권(幸福追求權) </p>  ### 의무 **의무**란 인간이 어떤 행위를 해야 하는 것입니다. <p class="message"> 개혁과제(改革課題), 과제(課題), 군역(軍役), 급선무(急先務), 노동의무(勞動義務), 당위(當爲), 덕의무(德義務), 병역(兵役), 부역(負役), 사명(使命), 소임(所任), 숙제(宿題), 업(業), 의무(義務), 임무(任務), 제약조건(制約條件), 채무(債務), 책임(責任), 최종책임(最終責任) </p>  ### 학문/과목 **학문/과목**이란 인간의 지적 호기심을 충족하기 위한 활동입니다. <p class="message"> 가치교육학(價値敎育學), 강독(講讀), 강수전기학(降水電氣學), 거시경제(巨視經濟), 경제인류학(經濟人類學), 경제학(經濟學), 고고학(考古學), 고생동물학(古生動物學), 공공관리론(公共管理論), 공생광물학(共生鑛物學), 공중의학(公衆醫學), 공학(工學), 과학(科學), 과학기술(科學技術), 관계논리학(關係論理學), 관념론(觀念論), 광고심리학(廣告心理學), 광물공학(鑛物工學), 광물형태학(鑛物形態學), 광학(光學), 교련(敎鍊), 국문학(國文學), 국어국문학(國語國文學), 국학(國學), 근대경제학(近代經濟學), 근대정치학(近代政治學), 기초과학(基礎科學), 기초학문(基礎學問), 기하(幾何), 기하학(幾何學), 내과(內科), 내용교과(內容敎科), 노년의학(老年醫學), 논리학(論理學), 농학(農學), 능력심리학(能力心理學), 대뇌생리학(大腦生理學), 도학(道學), 동기후학(動氣候學), 동물해부학(動物解剖學), 동양철학(東洋哲學), 동위체지질학(同位體地質學), 동작연구(動作硏究), 목적법학(目的法學), 무의식심리학(無意識心理學), 물리(物理), 물리학(物理學), 미술고고학(美術考古學), 미학(美學), 발생생리학(發生生理學), 법학(法學), 병리학(病理學), 보학(譜學), 분자생물학(分子生物學), 불어불문학(佛語佛文學), 비교발생학(比較發生學), 비교음악학(比較音樂學), 비행기역학(飛行機力學), 사학(史學), 사회학(社會學), 산수(算數), 산학(算學), 상과(商科), 생명공학(生命工學), 생물경제학(生物經濟學), 생물물리화학(生物物理化學), 생물이학(生物理學), 생물학(生物學), 생태학(生態學), 생화학(生化學), 서술기후학(敍述氣候學), 서학(西學), 선박공학(船舶工學), 설명과학(說明科學), 성리학(性理學), 성형외과(成形外科), 세계관학(世界觀學), 세포학(細胞學), 소립자물리학(素粒子物理學), 수리경제학(數理經濟學), 수리생물물리학(數理生物物理學), 수리지질학(數理地質學), 수문기상학(水文氣象學), 수문지구화학(水文地球化學), 수사학(修辭學), 수의학(獸醫學), 수학(數學), 순수경제학(純粹經濟學), 순수학문(純粹學文), 스포츠의학(sports__), 시간생물학(時間生物學), 시학(詩學), 식물기관학(植物器官學), 식물병리학(植物病理學), 식물생화학(植物生化學), 신학(神學), 실과(實科), 심리학(心理學), 약학(藥學), 어학(語學), 언어미학(言語美學), 언어학(言語學), 엔지니어링(engineering), 역사언어학(歷史言語學), 역사학(歷史學), 역학(力學), 영문학(英文學), 외과(外科), 우주진화론(宇宙進化論), 원자로물리학(原子爐物理學), 원자핵물리학(原子核物理學), 위상수학(位相數學), 위상해석학(位相解析學), 위생학(衛生學), 유아교육(幼兒敎育), 유체운동학(流體運動學), 음악(音樂), 음향음성학(音響音聲學), 응용생리학(應用生理學), 의과(醫科), 의식심리학(意識心理學), 의학(醫學), 이론천문학(理論天文學), 이학(理學), 인간공학(人間工學), 인류지리학(人類地理學), 인류학(人類學), 인문과학(人文科學), 인문학(人文學), 인식논리학(認識論理學), 읽기, 잡학(雜學), 장양자론(場量子論), 전공과목(專攻科目), 전통논리학(傳統論理學), 전파기후학(電波氣候學), 정규교과목(正規敎科目), 정신과(精神科), 정신현상학(精神現象學), 정치학(政治學), 제왕학, 중세기문학(中世紀文學), 지구과학(地球科學), 지질식물학(地質植物學), 지학(地學), 천문학(天文學), 철학(哲學), 체육(體育), 체질의학(體質醫學), 체질인류학(體質人類學), 추측통계학(推測統計學), 통계학(統計學), 풍수지리(風水地理), 풍수지리설(風水地理說), 학과(學科), 한대기상학(寒帶氣象學), 한학(漢學), 항공기상학(航空氣象學), 항공우주공학(航空宇宙工學), 형이상학(形而上學), 화성측량학(火星測量學), 화학(化學) </p>  ### 제도 **제도**란 인간의 사회적 행동을 지배하는 체계입니다. <p class="message"> 감시망(監視網), 건강보험(健康保險), 경영시스템(經營___), 경쟁시스템(競爭___), 고정환율제(固定換率制), 공창제도(公娼制度), 과거제도(科擧制度), 관리체제(管理體制), 관제(官制), 관혼상제(冠婚喪祭), 교육제도(敎育制度), 교통체계(交通體系), 구제제도(救濟制度), 군제(軍制), 금융시스템(金融___), 기간임용제(期間任用制), 기부입학제(寄附入學制), 기여입학제(寄與入學制), 모계사회(母系社會), 민정(民政), 법제(法制), 보상체계(補償體系), 복지제도(福祉制度), 봉건(封建), 봉건제(封建制), 부계제(父系制), 부권제(父權制), 사회개량주의(社會改良主義), 소가족제도(小家族制度), 순환휴직제(循環休職制), 시장경제(市場經濟), 십부제(十部制), 왕정(王政), 요금제도(料金制度), 원수정(元首政), 의료보험(醫療保險), 의료보험제(醫療保險制), 의료시스템(醫療___), 의료체계(醫療體系), 의무교육(義務敎育), 이시보험(異時保險), 일부다처(一夫多妻), 일부일부(一夫一婦), 일시금보험(一時金保險), 입시제도(立試制度), 자유경쟁(自由競爭), 전산시스템(電算___), 제도(制度), 졸업인증제(卒業認證制), 주민자치(主民自治), 중앙집권(中央集權), 지배구조(支配構造), 지배체제(支配體制), 지역의보(地域社會), 지원병제도(志願兵制度), 지자제(地自制), 직제(職制), 집단주의(集團主義), 책임경영제(責任經營制), 체제(體制), 학제(學制), 향약(鄕約) </p>  ### 종교 **종교**란 절대적 존재나 사후 세계에 대한 인간의 믿음에 의해 성립되는 문화 체계입니다. <p class="message"> 가톨릭(catholic), 개신교(改新敎), 구교(舊敎), 기독교(基督敎), 도가(道家), 도교(道敎), 무속(巫俗), 미신(迷信), 밀교(密敎), 불교(佛敎), 삼교(三敎), 샤머니즘(shamanism), 신교(新敎), 애니미즘(animism), 유교(儒敎), 유대교(Judea_), 이단(異端), 이슬람(Islam), 종교(宗敎), 천도교(天道敎), 천주교(天主敎), 토테미즘(totemism), 회교(回敎) </p>  #### 종교분파 <p class="message"> 그리스도교(Christos_), 대승불교(大乘佛敎), 선종(禪宗), 소승(小乘), 청교도(淸敎徒) </p>  ### 사조 **사조**란 인간이 가치를 부여하고 따르는 신념의 체계입니다. <p class="message"> 가족주의(家族主義), 개방주의(開放主義), 개인주의(個人主義), 개화사조(開化思潮), 교황지상주의(敎皇至上主義), 교회국가주의(敎會國家主義), 극우(極右), 극좌(極左), 근본주의(根本主義), 냉소주의(冷笑主義), 니힐리즘(nihilism), 다원주의(多元主義), 리얼리즘(realism), 보신주의(保身主義), 사대주의(事大主義), 사상(思想), 사조(思潮), 상업주의(商業主義), 소수정예주의(少數精銳主義), 소영웅주의(小英雄主義), 순종주의(順從主義), 신비주의(神秘主義), 실적주의(實績主義), 애타주의(愛他主義), 엘리트주의(elite__), 연고주의(緣故主義), 우주관(宇宙觀), 유교사상(儒敎思想), 이기주의(利己主義), 이상주의(理想主義), 인도주의(人道主義), 인식비판(認識批判), 인종주의(人種主義), 일방주의(一方主義), 점성술(占星術), 제일주의(第一主義), 조세정의(租稅正義), 조세평등(租稅平等), 주의(主義), 지론(至論), 지상주의(至上主義), 지역주의(地域主義), 집단이기주의(集團利己主義), 차별의식(差別意識), 첨단패션(尖端__), 출세주의(出世主義), 테러리즘(terrorism), 파벌주의(派閥主義), 패러다임(paradigm), 페미니즘(feminism), 한탕주의(__主義), 허무주의(虛無主義), 헬레니즘(Hellenism), 휴머니즘(humanism) </p>  #### 예술사조 <p class="message"> 고전주의(古典主義), 낭만주의(浪漫主義), 노골문학(露骨文學), 로맨티시즘(romanticism), 모더니즘(modernism), 바로크(baroque), 사실주의(寫實主義), 상징주의(象徵主義), 신고전주의(新古典主義), 아방가르드(avant-garde), 에로티시즘(eroticism), 자연주의(自然主義) </p>  #### 정치사조 <p class="message"> 개혁정치(改革政治), 공산주의(共産主義), 공화주의(共和主義), 국수주의(國粹主義), 군국주의(軍國主義), 군사주의(軍事主義), 극우보수(極右保守), 나치즘(Nazism), 멘셰비즘(Menshevism), 민족주의(民族主義), 민주주의(民主主義), 반공산주의(反共産主義), 반공주의(反共主義), 반미주의(反美主義), 볼셰비즘(Bolshevism), 사회주의(社會主義), 선정주의(善政主義), 수정마르크스주의(修正____主義), 수정파사회주의(修正派社會主義), 아나키즘(anarchism), 일제(日帝), 자본주의(資本主義), 자유주의(自由主義), 전체주의(全體主義), 제국주의(帝國主義), 좌경(左傾), 좌익사상(左翼思想), 초국가주의(超國家主義), 파쇼(파쇼), 파시즘(fascism), 회교민주주의(回敎民主主義) </p>  #### 학문사조 <p class="message"> 공리주의(功利主義), 구조주의(構造主義), 맑스주의(Marx__), 문화주의(文化主義), 법실증주의(法實證主義), 비판철학(批判哲學), 사실과학(事實科學), 상대주의(相對主義), 신객관주의(新客觀主義), 실증주의(實證主義), 실학(實學), 합리주의(合理主義), 헤겔주의(Hegel__), 현실주의(現實主義) </p> 이론 <p class="message"> 가격결정론(價格決定論), 거미줄이론(___理論), 경영자혁명(經營者革命), 반대색설(反對色說), 변증법(辨證法), 본능설(本能說), 사제팔정도(四諦八正道), 삼위일체(三位一體), 생산비법칙(生産費法則), 생산비설(生産費說), 순환론(循環論), 식민사관(植民史觀), 실험소설론(實驗小說論), 음양오행설(陰陽五行說), 이기이원론(理氣二元論), 이기일원론(理氣一元論), 전기화학서열(電氣化學序列), 정보이론(情報理論), 정설(定說), 지동설(地動說), 학설(學說) </p>  ### 예술 **예술**이란 아름다움을 추구하는 인간의 행위에 의해 성립되는 문화 체계입니다. <p class="message"> 가면극(假面劇), 고려가요(高麗歌謠), 군중취타(軍中吹打), 도예(陶藝), 문학(文學), 서민문학(庶民文學), 서양문학(西洋文學), 소녀문학(少女文學), 순간사진(瞬間寫眞), 시공간예술(視空間藝術), 시화(詩畵), 예술(藝術), 오페라(opera), 종합예술(綜合藝術), 창극(唱劇), 코미디(comedy) </p>  #### 음악 <p class="message"> 가락, 가요(歌謠), 격양가(擊壤歌), 경기민요(京畿民謠), 계상일(界上一), 고전음악(古典音樂), 곡조(曲調), 관악(管樂), 국악(國樂), 군가(軍歌), 군악(軍樂), 극장음악(劇場音樂), 기악(器樂), 남성고음(男聲高音), 남성저음(男聲低音), 남성중음(男聲中音), 노랫가락, 단조(短調), 대중가요(大衆歌謠), 대중음악(大衆音樂), 댄스음악(dance__), 독창(獨唱), 로큰롤(rock'n'roll), 만가(輓歌), 발라드(ballade), 배경음악(背景音樂), 배꽃타령, 블루스(blues), 성악(聲樂), 아악(雅樂), 악곡(樂曲), 양악(洋樂), 오라토리오(오라토리오), 왈츠(waltz), 응원가(應援歌), 이념시(二念詩), 이중창(二重唱), 재즈(jazz), 전후고취(殿後鼓吹), 찬가(讚歌), 창가(唱歌), 칼립소(calypso), 캐럴(carol), 캐롤(carol), 클래식(classic), 타령, 트로트(trot), 트리오(trio), 팝(pop), 팝송(pop song), 포크송(forksong), 풍악(風樂), 피아노곡(piano_), 향악(鄕樂), 현악(絃樂), 효과음악(效果音樂) </p>  음악요소 <p class="message"> 선율(旋律), 오음(五音), 추임새, 평조(平調), 화음(和音) </p>  음악기호  음악작품 : 소리를 매체로 한 예술작품 <p class="message"> 가극(歌劇), 게송(偈頌), 명곡(名曲), 무곡(舞曲), 서곡(序曲), 세레나데(serenade), 소곡(小曲), 자장가(__歌), 주제곡(主題曲), 중허리시조(中__時調), 타령조(__調), 판소리, 행진곡(行進曲) </p>  (1) 성악곡 : 인간의 목소리를 매체로 한 음악작품 <p class="message"> 가곡(歌曲), 교가(校歌), 굿거리시조(___時調), 김매기소리, 나무꾼노래, 널뛰기노래, 달거리요(___謠), 동요(童謠), 모내기노래, 모심기노래, 무가(巫歌), 민요(民謠), 범패(梵唄), 비가(悲歌), 샹송(chanson), 성가(聖歌), 속요(俗謠), 송가(頌歌), 십팔번(十八番), 아리아(aria), 앞산타령(_山__), 애가(哀歌), 애국가(愛國歌), 영가(靈歌), 유행가(流行歌), 인기가요(人氣歌謠), 잡가(雜歌), 장송곡(葬送曲), 절창(絶唱), 중창곡(重唱曲), 찬송가(讚頌歌), 축가(祝歌), 통속가요(通俗歌謠) </p>  (2) 기악곡 : 악기 소리를 매체로 한 음악작품 <p class="message"> 교향곡(交響曲), 군대행진곡(軍隊行進曲), 농악(農樂), 소나타(sonata), 실내악(室內樂), 심포니(symphony), 취타(吹打) </p>  #### 무용 **무용**이란 인간의 몸동작을 매체로 한 예술입니다. <p class="message"> 가면무(假面舞), 가면무도(假面舞蹈), 대금무(<U+7893>琴舞), 댄스(dance), 무용(舞踊), 발레(ballet), 승무(僧舞), 우방무(右坊舞), 원무(圓舞), 주지탈춤, 지루박(jitterbug), 탱고(tango), 트위스트(twist), 플라멘코(플라멩코), 한삼춤(汗衫_), 행진무용(行進舞踊) </p>  #### 미술 <p class="message"> 그래픽(graphic), 꽃식그림(_式__), 미술(美術), 민화(民畵), 붓글씨, 서예(書藝), 장식도안(裝飾圖案) </p>  #### 영화 <p class="message"> 독립영화(獨立映畵), 성인영화(成人映畵), 순수영화(純粹映畵), 스펙터클영화(spectacle__), 에로비디오(erotic video), 영화(映畵), 입체영화(立體映畵) </p>  #### 연극 <p class="message"> 고대극(古代劇), 극(劇), 블랙코미디(black comedy), 비가극(悲歌劇), 성격극(性格劇), 소극(笑劇), 신극(新劇), 신파극(新派劇), 아동극(兒童劇), 연극(演劇), 창작극(創作劇), 촌극(寸劇), 판토마임(pantomime), 학교극(學校劇), 현대연극(現代演劇) </p>  ### 텍스트 **텍스트**란 기호를 이용하여 지적(intellectual) 내용을 표현한 것입니다. <p class="message"> 가계부(家計簿), 가옥대장(家屋臺帳), 각본(脚本), 각서(覺書), 개요(槪要), 거대담론(巨大談論), 검정교과서(檢定敎科書), 격문(檄文), 견문록(見聞錄), 경구(警句), 경서(經書), 경전(經典), 계간지(季刊誌), 계보(系譜), 고문(古文), 고서(古書), 고전(古典), 고지서(告知書), 고판본(古版本), 곡(曲), 공문(公文), 공문서(公文書), 공식기록(公式記錄), 공한(公翰), 과목(科目), 관련기사(關聯記事), 관보(官報), 광고문(廣告文), 광고문구(廣告文句), 교재(敎材), 국정교과서(國定敎科書), 군글, 극본(劇本), 글, 글귀(_句), 글쪽지(__紙), 금서(禁書), 기관잡지(機關雜誌), 기록(記錄), 기사거리(記事__), 기사광고(記事廣告), 날별표(_別表), 노랫말, 논고(論考), 논문(論文), 논설(論說), 논저(論著), 논집(論集), 논총(論叢), 농서(農書), 누드사진(nude__), 뉴스(news), 뉴스기사(news__), 느낌글, 단방문(單放文), 단평(短評), 담론(談論), 답안(答案), 대본(臺本), 대학신문(大學新聞), 독본(讀本), 독후감(讀後感), 동문(同文), 동화(童話), 르포(르포), 리스트(list), 리포트(report), 만화책(漫畵冊), 메뉴(menu), 메뉴얼(manual), 메모(memo), 메모내용(memo__), 명단(名單), 명문(名文), 명부(名簿), 명세(明細), 모범답안(模範答案), 목록(目錄), 문면(文面), 문헌(文獻), 미문(美文), 민담(民譚), 발표문(發表文), 법률개정안(法律改正案), 법문(法文), 보고서(報告書), 보도(報道), 보도자료(報道資料), 보도지침(報道指針), 부고(訃告), 불서(佛書), 불전(佛典), 비문(碑文), 사문(死文), 사설(社說), 사전(辭典), 상서(上書), 상소(上疏), 새김글, 서목(書目), 서적(書籍), 서지(書誌), 서평(書評), 선생안(先生案), 선언문(宣言文), 성경(聖經), 성명서(聲明書), 성서(聖書), 소고(小考), 소명자료(疏明資料), 수구신문(守舊新聞), 수능문제(修能問題), 수정예산안(修正豫算案), 순애보(純愛譜), 시나리오(scenario), 시사평론(時事評論), 시안(試案), 시조(時調), 시평(時評), 시험문제(試驗問題), 식단(食單), 신문(新聞), 신문기사(新聞記事), 신분증명서(身分證明書), 실록(實錄), 양서(良書), 어록(語錄), 에러메시지(error message), 역서(譯書), 연감(年鑑), 연보(年報), 연습문제(演習問題), 열전(列傳), 왕조실록(王朝實錄), 원문(原文), 원본(原本), 원서(原書), 월간지(月刊誌), 유서(遺書), 육아일기(育兒日記), 인권보고서(人權報告書), 인사기록(人士記錄), 일기(日記), 일람표(一覽表), 일지(日誌), 입사지원서(入社志願書), 입영통지서(入營通知書), 입학통지서(入學通知書), 자료(資料), 자서전(自敍傳), 자술서(自述書), 작문(作文), 잡문(雜文), 잡지(雜誌), 장문(長文), 저서(著書), 저술(著述), 저작물(著作物), 적요(摘要), 전공도서(專攻圖書), 전공서적(專攻書籍), 전면광고(全面廣告), 전보(電報), 전서(全書), 전설(傳說), 정사(正史), 제문(祭文), 조간(朝刊), 조사계획서(調査計劃書), 조사보고서(調査報告書), 조서(調書), 종합보고서(綜合報告書), 주간지(週刊誌), 주요기사(主要記事), 증서(證書), 지문(地文), 지방신문(地方新聞), 차트(chart), 책(冊), 초고(草稿), 초본(抄本), 초안(草案), 축문(祝文), 출근부(出勤簿), 출전(出典), 카피(copy), 칼럼(column), 커버스토리(cover story), 텍스트(text), 톱기사(top__), 투병일기(鬪病日記), 특집(特輯), 편지(便紙), 편지글(便紙_), 평론(評論), 표어(標語), 프린트(print), 학습지도안(學習指導案), 해임건의안(解任建議案), 헌사(獻詞), 혈서(血書), 화보(畵報), 회고록(回顧錄), 훈련통지서(訓練通知書), 희곡(戱曲) </p>  #### 문학텍스트 <p class="message"> 군담소설(軍談小說), 논픽션(nonfiction), 단편(短篇), 독자칼럼(讀者_), 비극(悲劇), 서사문(敍事文), 서사시(敍事詩), 서시(序詩), 서정시(抒情詩), 소네트(sonnet), 소설(小說), 송(頌), 송시(頌詩), 수기(手記), 수필(隨筆), 시(詩), 시편(詩篇), 신변잡기(身邊雜記), 에세이(essay), 영시(英詩), 영웅서사시(英雄敍事詩), 우화(寓話), 운문(韻文), 일월설화(日月說話), 자서전소설(自敍傳小說), 장시(長詩), 장편(長篇), 즉흥시(卽興詩), 축시(祝詩), 콩트(conte) </p>  #### 도표 <p class="message"> 도식(圖式), 배차시간표(配車時間表), 뼈대그림, 설계도(設計圖), 성도(星圖), 성적표(成績表), 세계지도(世界地圖), 시간표(時間表), 실측도(實測圖), 약도(略圖), 정오표(正誤表), 지도(地圖) </p>  #### 텍스트의 부분 가십(gossip), 각주(脚主), 결구(結句), 결론(結論), 결미(結尾), 결어(結語), 경문(經文), 공백(空白), 도판(圖版), 도해(圖解), 도화(圖畵), 머리기사(__記事), 머리말, 머릿기사(__記事), 목차(目次), 문구(文句), 문단(文段), 문맥(文脈), 발문(跋文), 범례(範例), 별항(別項), 본론(本論), 본문(本文), 부록(附錄), 붙임, 비고(備考), 서론(序論), 서문(序文), 서설(序說), 서언(序言), 세목(細目), 에필로그(epilogue), 연예란(演藝欄), 요약(要約), 인덱스(index), 일러두기, 일절(一節), 전개(展開), 전면(全面), 조목(條目), 조항(條項), 종장(終章), 찾아보기, 초장(初章), 총론(總論), 추모란(追慕欄), 추신(追伸), 프롤로그(prologue), 하기(下記), 항(項), 행(行), 허두(虛頭), 후기(後記), 후렴(後斂) </p>  #### 문서 <p class="message"> 강의평가서(講義評價書), 건의서(建議書), 공개질의서(公開質疑書), 공동선언문(共同宣言文), 공소장(公訴狀), 법안(法案), 병적(兵籍), 사업계획서(事業計劃書), 사직청원서(辭職請願書), 사퇴서(辭退書), 생활기록부(生活記錄簿), 서류(書類), 서면(書面), 수표청구서(手票請求書), 숙박계(宿泊屆), 시말서(始末書), 신상명세서(身上明細書), 신원진술서(身元陳述書), 신청서(申請書), 연구계획서(硏究計劃書), 연구보고서(硏究報告書), 음악파일(音樂__), 이력서(履歷書), 진단서(診斷書), 진술서(陳述書), 진정서(陳情書), 첨부서류(添附書類), 카드(card), 탄원서(歎願書), 팩스(fax) </p>  증명서 <p class="message"> 간이영수증(簡易領收證), 건강진단서(健康珍斷書), 검역증명서(檢疫證明書), 결의문(決議文), 계약서(契約書), 공식계약서(公式契約書), 근로계약서(勤勞契約書), 내용증명서(內容證明書), 면죄부(免罪符), 병적증명서(兵籍證明書), 사망신고서(死亡申告書), 선박서류(船舶書類), 세금계산서(稅金計算書), 수강증(受講證), 수령증(受領證), 수료증명서(修了證明書), 신원보증서(身元保證書), 약정서(約定書), 열람권(閱覽券), 영수증(領收證), 예매권(豫賣券), 인감증명서(印鑑證明書), 재학증명서(在學證明書), 졸업장(卒業狀), 졸업증명서(卒業證明書), 증명서(證明書), 증빙서류(證憑書類), 통행증(通行證), 호적(戶籍) </p>  권리증 <p class="message"> 면허증(免許證), 석사(碩士), 수료증(修了證), 신용장(信用狀), 운전면허증(運轉免許證), 자격증(資格證), 졸업증(卒業證), 진찰권(診察券), 특허증(特許證), 학위(學位) </p>  통지서 <p class="message"> 가정통신문(家庭通信文), 명세서(明細書), 세금고지서(稅金告知書), 영장(令狀), 요금고지서(料金告知書), 요금청구서(料金請求書), 체납고지서(滯納告知書), 체포영장(逮捕令狀), 통문(通文), 통지서(通知書), 해고통지서(解雇通知書) </p>  상장 <p class="message"> 상장(賞狀), 상패(賞牌) </p>  #### 편지 <p class="message"> 가정통신(家庭通信), 그림엽서(__葉書), 답서(答書), 답신(答信), 답장(答狀), 문자메시지(文字___), 서간(書簡), 서신(書信), 서찰(書札), 서한(書翰), 연애편지(戀愛便紙), 음성메시지(音聲___), 음악편지(音樂便紙), 전자우편(電子郵便), 전자편지(電子便紙), 지급전보(至急電報), 팬레터(fan letter) </p>  ### 작품 **작품**이란 인간이 예술 행위를 통해 만든 것입니다. <p class="message"> 가작(佳作), 공동작(共同作), 근작(近作), 대작(大作), 대표작(代表作), 데뷔작(debut), 드라마(drama), 명작(名作), 무언무용극(無言舞踊劇), 문학작품(文學作品), 베스트셀러(best seller), 속편(續篇), 습작(習作), 시사만화(時事漫畵), 실패작(失敗作), 압권(壓卷), 애니메이션(animation), 야심작(野心作), 예술작품(藝術作品), 유작(遺作), 작품(作品), 전작(前作), 참극(慘劇), 패러디(parody), 포르노(porno) </p>  ### 방송물 <p class="message"> 고정코너(固定__), 교육방송(敎育放送), 다큐멘터리(documentary), 단막극(單幕劇), 도큐멘터리, 방송드라마(放送___), 사극(史劇), 시에프(C.F.), 연속극(連續劇), 연예프로(演藝__), 영상매체(映像媒體), 영상물(映像物), 위성방송(衛星放送), 일일드라마(日日___), 일일연속극(一日連續劇), 정치드라마(政治___), 주말드라마(週末___), 주말연속극(週末連續劇), 주요뉴스(主要__), 중간광고(中間廣告), 중앙방송(中央放送), 프로그램(program), 휴먼드라마(human drama) </p>  ### 산업 **산업**이란 인간이 생산 행위를 하는 사회적 체계입니다. <p class="message"> 가공업(加工業), 가내공업(家內工業), 건설업(建設業), 건축업(建築業), 경공업(輕工業), 경제(經濟), 계단농업(階段農業), 공업(工業), 광공업(鑛工業), 광업(鑛業), 군수공업(軍需工業), 군수산업(軍需産業), 굴뚝산업(__産業), 기간산업(基幹産業), 낙농(酪農), 농림(農林), 농림업(農林業), 농사(農事), 농업(農業), 도박산업(賭博産業), 산업(産業), 상공업(商工業), 상업(商業), 서비스업(service_), 세계경제(世界經濟), 소개업(紹介業), 수공업(手工業), 양봉업(養蜂業), 어업(漁業), 에너지산업(energy__), 용역산업(用役産業), 운송업(運送業), 유업(乳業), 음반산업(音盤産業), 의료업(醫療業), 의업(醫業), 임업(林業), 저술업(著述業), 정보산업(情報産業), 제조업(製造業), 중공업(重工業), 중화학(重化學), 중화학공업(重化學工業), 첨단산업(尖端産業), 축산(畜産), 취로사업(就勞事業), 허가어업(許可漁業) </p>  ### 역사 **역사**란 인간의 과거의 삶과 관련된 사실들의 체계입니다. <p class="message"> 과학사(科學史), 근대사(近代史), 내력(來歷), 민족사(民族史), 세계사(世界史), 수난사(受難史), 야사(野史), 역사(歷史), 연혁(沿革), 통사(通史), 한국사(韓國史), 현대사(現代史) </p>  ### 상 **상**이란 인간의 긍정적 행위에 대한 보상으로 주어지는 것입니다. <p class="message"> 금상(金賞), 문학상(文學賞), 박사학위(博士學位), 은상(銀賞) </p>  ### 벌 <p class="message"> 과료(科料), 극형(極刑), 단기자유형(短期自由刑), 무기징역형(無期懲役刑), 벌금형(罰金刑), 실형(實刑), 십자가형(十字架刑), 죄형(罪刑), 징역(懲役), 체형(體刑), 총살형(銃殺刑), 형량(刑量) </p>  ### 분야 **분야**란 추상적인 특정 영역입니다. <p class="message"> 경쟁부분(競爭部分), 관련업계(關聯業界), 관련종목(關聯種目), 교계(敎界), 교육과정(敎育課程), 국제정치(國際政治), 군사(軍事), 금융시장(金融市場), 매스미디어(mass media), 문과(文科), 문예(文藝), 방송가(放送街), 버스업계(bus__), 벤처업계(venture__), 부문(部門), 분야(分野), 세제업계(洗劑業界), 시단(詩壇), 야(野), 연극계(演劇界), 연예계(演藝界), 음반업계(音盤業界), 의료(醫療), 재벌체제(財閥體制), 전문분야(專門分野), 정계(政界), 정보통신(精報通信), 정치(政治), 제약업계(製藥業界), 주요업종(主要業種), 지하경제(地下經濟), 직종(職種), 학계(學界), 학원스포츠(學園___), 현대건축(現代建築), 현업(現業) </p>  ### 범위 <p class="message"> 범위(範圍), 상권(商圈), 수하(手下), 순위권(順位圈), 시야(視野), 안정권(安定圈), 양눈시야(兩_視野), 오차범위(誤差範圍), 외연(外延), 일일생활권(一日生活圈), 정치권(政治圈), 조사대상(調査對象), 조직망(組織網) </p>  ### 경로 **경로**란 대상이 시간적, 공간적으로 이동해 간 자취입니다. <p class="message"> 검정과정(檢定課程), 경로(徑路), 공천과정(公薦過程), 궤적(軌跡), 귀로(歸路), 도정(道程), 루트(route), 여로(旅路), 이동경로(移動經路), 입법과정(立法過程), 입법절차(立法節次), 적법절차(適法節次), 절차(節次), 족적(足跡), 종적(<U+8E64>跡), 진로(進路), 채널(channel), 코스(course), 편도(片道), 행적(行績), 향방(向方), 향배(向背) </p>  ### 추상적부분 **추상적부분**이란 추상적 대상의 부분으로서 갖는 특정 기능 또는 특정 속성에 의해 규정되는 것입니다. <p class="message"> 고비, 골자(骨子), 권두(卷頭), 글감, 기층(基層), 냉전구조(冷戰構造), 논외(論外), 단서(端緖), 대략(大略), 대미(大尾), 돌가락, 돌파구(突破口), 두운(頭韻), 말꼬리, 몫, 문항(問項), 보유지분(保有持分), 삼부(三部), 서두(序頭), 서막(序幕), 선두(先頭), 선봉(先鋒), 소절(小節), 수미(首尾), 앞과장(_科場), 양극(兩極), 어두(語頭), 언중(言中), 입문(入門), 저류(底流), 전주(前奏), 제하(題下), 주요관심사(主要關心事), 주제(主題), 줄거리, 중강강술래(中____), 중추기관(中樞機關), 지분(持分), 첫머리, 초점(焦點), 클라이막스(climax), 태반(太半), 특례(特例), 편린(片鱗), 편모(片貌), 플롯(plot), 피날레(피날레), 필두(筆頭), 해당사항(該當事項), 핵(核), 화두(話頭), 흉중(胸中) </p>  ### 관계추상적대상 **관계추상적대상**이란 다른 대상과의 관계에 의해 규정되는 추상적 대상입니다. <p class="message"> 각종(各種), 간극(間隙), 경제구조(經濟構造), 골간(骨幹), 관건(關鍵), 광의(廣義), 궁합(宮合), 귀추(歸趨), 근간(根幹), 근로조건(勤勞條件), 근무조건(勤務條件), 근저(根底), 기로(岐路), 기연(奇緣), 기조(基調), 내막(內幕), 내포(內包), 대가관계(對價關係), 대강(大綱), 대상(對象), 돌발변수(突發變數), 동서고금(東西古今), 두서(頭緖), 딴판, 랭킹(ranking), 매각조건(賣却條件), 매개물(媒介物), 맥락(脈絡), 면허(免許), 모범(模範), 모범사례(模範事例), 미래상(未來像), 베스트(best), 변수(變數), 별도(別途), 복선(伏線), 본말(本末), 부패구조(腐敗構造), 분과(分科), 분배구조(分配構造), 사례(事例), 사항(事項), 사회구조(社會構造), 산업구조(産業構造), 상세구조(詳細構造), 상한(上限), 서사구조(敍事構造), 선례(先例), 성공사례(成功事例), 세부내용(細部內容), 세부사항(細部事項), 세습구조(世襲構造), 순번(順番), 순서(順序), 순위(順位), 순차(順次), 스토리(story), 시작점(始作點), 식순(式順), 신변(身邊), 신상(身上), 실황(實況), 액면(額面), 얼개, 엉터리, 여타(餘他), 연장선(延長線), 예제(例題), 요건(要件), 용례(用例), 위시(爲始), 유례(類例), 유예조건(猶豫條件), 이례(異例), 이야깃거리, 이외(以外), 인과구조(因果構造), 인과응보(因果應報), 일부분(一部分), 일조(一兆), 일종(一種), 일체(一切), 일환(一環), 자체(自體), 자초지종(自初至終), 자취, 쟁점(爭點), 저변(低邊), 저의(底意), 전거(典據), 전례(前例), 전말(顚末), 전모(全貌), 전범(典範), 전부(全部), 전체(全體), 전편(全篇), 전후사연(前後事緣), 정답(正答), 정화(精華), 제재(題材), 조건(條件), 존립근거(存立根據), 종국목적(終局目的), 중추(中樞), 진수(眞髓), 징크스(jinx), 차례(次例), 착안점(着眼點), 척도(尺度), 체계(體系), 체재(體裁), 출처(出處), 판가름터, 판세(_勢), 패러독스(paradox), 포인트(point), 표리(表裏), 하부구조(下部構造), 한고비, 항렬(行列), 핵심(核心), 흉조(凶兆) </p>  #### 이유 **이유**란 어떤 명제를 뒷받침하는 것입니다. <p class="message"> 경제논리(經濟論理), 까닭, 논거(論據), 미명(美名), 빙자(憑藉), 사정(事情), 연유(緣由), 영문, 이유(理由), 터무니 </p>  #### 원인 **원인**이란 어떤 상황이 일어나게 하는 것입니다. <p class="message"> 겁결(怯_), 견인(牽引), 결격사유(缺格事由), 근인(近因), 기반(基盤), 기틀, 단초(端初), 동기(動機), 모티프(motif), 밑바탕, 발단(發端), 변인(變因), 병리(病理), 빌미, 사단(事端), 사인(死因), 성취동기(成就動機), 실마리, 악재(惡材), 요인(要因), 원동(原動), 원동력(原動力), 원인(原因), 원천(源泉), 위험요소(危險要素), 위험요인(危險要因), 위협요소(威脅要素), 위협요인(威脅要因), 주요원인(主要原因), 주요인(主要因), 주원인(主原因), 탓, 패인(敗因), 호재(好材), 화근(禍根), 환경오염원(環境汚染源) </p>  #### 결과 **결과**란 어떤 상황으로 인해 생겨나게 된 것입니다. <p class="message"> 강압효과(强壓效果), 결과(結果), 결말(結末), 공적(功積), 근무성적(勤務成績), 기대효과(期待效果), 매각손(賣却損), 병폐(病弊), 보람, 선전효과(宣傳效果), 성과(成果), 성패(成敗), 소산(所産), 소치(所致), 승부(勝負), 승패(勝敗), 실험값(實驗_), 업보(業報), 역기능(逆技能), 역효과(逆效果), 연구성과(硏究成果), 이익(利益), 잔재(殘滓), 총체(總體), 층(層), 치적(治績), 효과(效果), 효험(效驗) </p>  #### 순서 **순서**란 대상들 사이의 비대칭적 선후 관계에 의해 규정되는 추상적 대상입니다. <p class="message"> 금번(今番), 선후(先後), 어순(語順), 연대순(年代順), 연차(年次), 일차(一次), 일착(一着), 제일(第一), 처음, 최종회(最終回), 타순(打順), 필순(筆順), 효시(嚆矢), 후자(後者) </p>  #### 관계 <p class="message"> 경협(經協), 공생관계(共生關係), 노사관계(勞使關係), 동맹관계(同盟關係), 면식(面識), 사돈(査頓), 상호관계(相互關係), 알음알음, 여야관계(與野關係), 연관(聯關), 연분(緣分), 외교관계( 外交關係), 우호관계(友好關係), 유대(紐帶), 유대관계(紐帶關係), 유착관계(癒着關係), 이해관계(利害關係), 인간관계(人間關係), 인과관계(因果關係), 인과율(因果律), 제휴관계(提携關係), 틈바구니, 호상(互相) </p>  #### 요점 <p class="message"> 논점(論点), 논제(論題), 논지(論旨), 문리(文理), 시종(始終), 연구주제(硏究主題), 요점(要點), 요체(要諦), 주요쟁점(主要爭點), 참뜻, 취지(趣旨), 테마(Thema) </p>  ### 개념 <p class="message"> 뜻, 예비지식(豫備知識), 원칙주의(原則主義), 육아상식(育兒常識), 이데아(idea), 인간관(人間觀), 인생관(人生觀), 일반상식(一般常識), 자연관(自然觀), 절대이념(絶對理念), 추억(追憶), 탄성이론(彈性理論) </p>  ### 기준 <p class="message"> 결격사항(缺格事項), 과표(課標), 권력모형(權力模型), 기준(基準), 미만(未滿), 본위(本位), 선정기준(選定基準), 성립조건(成立條件), 세부기준(細部基準), 시금석(試金石), 이중잣대(二重__), 자격요건(資格要件), 잣대, 제조원가(製造原價), 준거(準據), 표본(標本), 표준(標準), 표준량(標準量), 한계점(限界點), 허용기준(許容基準) </p>  ### 상황 <p class="message"> 가정환경(家庭環境), 계절특수(季節特需), 광경(光景), 교육환경(敎育環境), 구구사정(區區私情), 국가안보(國家安保), 국면(局面), 국운(國運), 국제정세(國際政勢), 군세(軍勢), 권력구조(權力構造), 근로복지(勤勞福祉), 근황(近況), 금슬(琴瑟), 금실(琴瑟), 내부환경(內部環境), 냉전체제(冷戰體制), 대국(大局), 대북관계(對北關係), 대세(大勢), 돌발사태(突發事態), 메커니즘(mechanism), 분위기(雰圍氣), 사세(事勢), 사연(事緣), 사태(事態), 사회현실(司會現實), 생활환경(生活環境), 서정(抒情), 세간사정(世間事情), 세사(世事), 세상물정(世上物情), 세정(世情), 세태(世態), 시국(時局), 시세(時勢), 시황(市況), 실제상황(實際狀況), 실지(實地), 양태(樣態), 여건(與件), 우여곡절(迂餘曲折), 의무화(義務化), 일신상(一身上), 자연(自然), 작황(作況), 잔악상(殘惡相), 적정(敵情), 전황(戰況), 정국(政局), 정적(靜寂), 정치상황(政治狀況), 정태(情態), 정황(情況), 주거환경(住居環境), 주요동향(主要動向), 주차난(駐車難), 주택문제(住宅問題), 지역구도(地域構圖), 처지(處地), 판국(_局), 프라이버시(privacy), 피해실태(被害實態), 한편(_便), 형국(形局), 형세(形勢), 형편(形便), 환경오염(環境汚染) </p>  ### 개체상황 <p class="message"> 말씨, 숨결, 심경(心境), 심기(心氣), 의식세계(意識世界), 정신건강(精神健康), 제정신(_精神) </p>  ### 영상 <p class="message"> 메인화면(main__), 비디오(video), 심상(心象), 이미지(image), 잔상(殘像) </p>  ### 수학적대상 **수학적대상**이란 수학자들에 의해 상정된 대상입니다. <p class="message"> 그래프(graph), 극방정식(極方程式), 등식(等式), 마이너스(minus), 미분(微分), 방정식(方程式), 삼차(三次), 수열(數列), 연산자(演算子), 열화학방정식(熱化學方程式), 예각(銳角), 자승(自乘), 적분(積分), 제곱, 종횡(縱橫), 좌표(座標), 차원(次元), 총합계(總合計), 추론식(推論式), 탄젠트(tangent), 함수(函數), 환산상태식(換算狀態式) </p>  #### 수 **수**란 세는 것과 관련된 수학적 대상입니다. <p class="message"> 백만(百萬), 서수(序數), 숫자(數字), 승수(乘數), 유리수(有理數), 음수(陰數), 임시번호(臨時番號), 제로(zero), 제이(第二) </p>  관계수 : 다른 수와의 관계에 의해 규정되는 수 <p class="message"> 분모(分母), 삼승(三乘), 약수(約數), 차수(次數) </p>  #### 도형 **도형**이란 1차원, 2차원 또는 3차원 공간상의 특징에 의해 규정되는 수학적 대상입니다. <p class="message"> 네모, 다면체(多面體), 대각선(對角線), 도형(圖形), 동그라미, 라인(line), 반원(半圓), 사각형(四角形), 삼각형(三角形), 상사다각형(相似多角形), 선분(線分), 수평곡선(水平曲線), 원뿔(圓_), 원추(圓錐), 일직선(一直線), 입체(立體), 점(點), 점선(點線), 종행(縱行), 직선(直線), 타원(楕圓), 팔각형(八角形) </p>  #### 도형의 부분 <p class="message"> 각(角), 빗변(_邊), 원주(圓周), 접점(接點), 중점(中點), 평각(平角), 호(弧) </p>  #### 관계수학적대상 **관계수학적대상**이란 다른 수학적 대상과의 관계에 의해 규정되는 수학적 대상입니다. <p class="message"> 거리공간(距離空間), 로그(log), 절댓값(絶對_), 증분(增分), 치역(値域), 합(合) </p>  ### 물리학적대상 **물리학적대상**이란 물리학자들에 의해 상정된 추상적 대상입니다. <p class="message"> 대역폭(帶域幅), 동력(動力), 동력원(動力源), 무게중심(__重心), 소립자(素粒子), 수력전기(水力電氣), 압력물머리(壓力___), 약전(弱電), 에너지(energy), 에테르(ether), 열(熱), 응고열(凝固熱), 자류(磁流), 자장(磁場), 전극(電極), 전기(電氣), 전기각도(電氣角度), 전기에너지(電氣___), 전류(電流), 전압(電壓), 정지좌표계(靜止座標系), 주파수(周波數), 태양열(太陽熱), 피로한도(疲勞限度) </p>  #### 힘 <p class="message"> 관성(慣性), 군력(軍力), 만유인력(萬有引力), 부력(浮力), 사력(死力), 수력(水力), 양력(揚力), 영력(營力), 원자력(原子力), 자기력(磁氣力), 자력속(磁力束), 장력(張力), 저항력(抵抗力), 중력(重力), 충격(衝擊), 탄력(彈力), 파괴력(破壞力), 풍력(風力), 풍압(風壓), 한계압력(限界壓力) </p>  #### 파동 <p class="message"> 광파(光波), 뇌파(腦波), 단파(短波), 마이크로파(micro_), 엑스빛살(X__), 음파(音波), 전자기파(電磁氣波), 전자파(電磁波), 전파(電波), 지진파(地震波), 초단파(超短波) </p>  ### 인지공간 **인지공간**이란 인지행위나 심리상태가 일어나는 장소입니다. <p class="message"> 머릿속 </p>  ### 추상적장애물 **추상적장애물**이란 구체물이 아닌 상황이나 심리상태에 의한 장애물입니다. <p class="message"> 고생문(苦生門), 구렁텅이, 불편사항(不便事項), 세파(世波) </p>  ## 사태 **사태**란 시간적 延長(extension)을 가지나 공간적 연장을 갖지 않는 대상입니다. 하위 범주(2단계)로는 정적사태, 행위, 사건, 현상, 상태변화 등이 있습니다.  ### 정적사태 **정적사태**란 정태적 상황을 가리킵니다. <p class="message"> 군수(軍需), 한산(閑散), 현전(現傳) </p>  #### 속성값 **속성값**이란 어떤 대상이 지니는, 비교적 지속성이 있는 특정 속성의 값입니다. 모양속성값 : 시각적으로 구분되는, 윤곽선에 의해 특징지어지는 특성 <p class="message"> 각형(角形), 격자(格子), 겹, 고딕(gothic), 곡선(曲線), 곡선미(曲線美), 광폭(廣幅), 굴곡(屈曲), 궁형(弓形), 균제(均齊), 기형(畸形), 나선(螺旋), 눈꼴, 다단(多段), 다면(多面), 단아(端雅), 대구입(大口_), 대머리, 대자(大字), 도심장형(倒心臟形), 똬리, 뚜껑모양(__貌樣), 마름모꼴, 만곡(彎曲), 말굽꼴, 무형(無形), 반구(半球), 발굽꼴, 범죄형(犯罪型), 변발(<U+8FAE>髮), 본때(本_), 부채꼴, 사각(四角), 삼각(三角), 선형(線形), 세모, 스포츠형(sports_), 신형(新型), 십자(十字), 십자형(十字形), 얼룩무늬, 웨이브(wave), 유선형(流線型), 육각(六角), 일렬(一列), 잔손금, 잔주름, 장방형(長方形), 정방형(正方形), 죽을상(__相), 줄무늬, 지그재그(zigzag), 직각(直角), 직교(直交), 직류(直流), 직사각형(直四角形), 짜임새, 짱구, 초서(草書), 타래, 파상(波狀), 평면(平面), 흉칙 </p>  정도속성값 : 수량화, 수치화가 불가능한 품질 등의 정도를 나타내는 속성값 <p class="message"> 가격수준(價格水準), 강세(强勢), 국가신뢰도(國家信賴度), 국가신용도(國家信用度), 만족도(滿足度), 무료서비스(無料___), 민감성(敏感性), 삼등(三等), 엄밀(嚴密), 예삿일(例事_), 완급(緩急), 완벽(完璧), 완성미(完成美), 완전(完全), 적당량(適當量), 정도문제(程度問題), 중증(重症), 한도(限度), 황금분할(黃金分割), 획기적(劃期的) </p>  (1) 높은 정도 : 수량화, 수치화가 불가능한 품질 등의 정도가 평균/중간 이상임을 나타내는 속성값 <p class="message"> 거대(巨大), 고가(高價), 고견(高見), 고등(高等), 고성능(高性能), 고수익(高收益), 고압(高壓), 고액(高額), 고열(高熱), 고온(高溫), 고율(高率), 고층(高層), 고품격(高品格), 고학력(高學歷), 굴지(屈指), 궁극(窮極), 극단(極端), 극대(極大), 극도(極度), 극렬(極烈), 극치(極致), 극한(極限), 대대적(大大的), 막강(莫强), 만전(萬全), 만점(滿點), 맹위(猛威), 무궁무진(無窮無盡), 무적(無敵), 미증유(未曾有), 발군(拔群), 버금, 부지기수(不知其數), 불세출(不世出), 불후(不朽), 상급(上級), 상위(上位), 상책(上策), 속건성(速乾性), 수준급(水準級), 양질(良質), 연구세심(年久歲深), 영순위(零順位), 완미(完美), 완벽성(完壁性), 우등(優等), 우량(優良), 우수성(優秀性), 우월(優越), 원거리(遠距離), 위험물깊이(危險___), 위험천만(危險千萬), 응급(應急), 의문투성이(疑問___), 의혹투성이(疑惑___), 일품(一品), 장원(壯元), 절경(絶景), 절호(絶好), 젤, 종횡무진(縱橫無盡), 지고지순(至高至順), 천만(千萬), 천부(天賦), 천혜(天惠), 철석(鐵石), 철저(徹底), 첨단(尖端), 초일류(超一流), 최강(最强), 최고(最高), 최고급(最高級), 최고도(最高度), 최고조(最高潮), 최대한(最大限), 최상(最上), 최선(最善), 최신(最新), 최적(最適), 쾌속(快速), 태산(泰山), 특급(特級), 특등(特等), 특선(特選), 풍어(豊漁), 풍작(豊作), 피크(peak), 필수불가결(必須不可缺), 필요불가결, 화급(火急) </p>  (2) 중간 정도 : 수량화, 수치화가 불가능한 품질 등의 정도가 평균/중간임을 나타내는 속성값 <p class="message"> 보통(普通), 상온(常溫), 얼치기, 예사물높이(例事___), 중간치(中間_), 중등(中等), 중키(中_), 중품(中品), 중형(中型) </p>  (3) 낮은 정도 : 수량화, 수치화가 불가능한 품질 등의 정도가 평균/중간 이하임을 나타내는 속성값 <p class="message"> 경범(輕犯), 고작, 극소(極小), 등외(等外), 무가치(無價値), 무미건조(無味乾燥), 미량(微量), 반푼(半_), 불량(不良), 삼류(三流), 약세(弱勢), 예상외(豫想外), 우수마발(牛杏馬勃), 유명무실(有名無實), 저가(低價), 저급(低級), 저리(低利), 저속(低俗), 저온(低溫), 저질(低質), 저차원(低次元), 졸속(拙速), 초급(初級), 초등(初等), 초보(初步), 최소한(最小限), 최악(最惡), 최저생계(最低生計), 추호(秋毫), 통속(通俗), 하(下), 하자(瑕疵), 헐값(歇_), 희귀(稀貴), 희미, 희색(喜色) </p>  수량속성값 : 객관적으로 측정가능한 수나 양의 많고 적음, 또는 측정수치의 높고 낮음을 나타내는 속성값 <p class="message"> 과반수(過半數), 다, 대다수(大多數), 도, 수차(數次), 수천(數千), 수회(數回), 아름드리, 엘(l), 연로(年老), 영하(零下) </p>  (1) 대 : 어떤 대상의 수나 양이 많거나 그 측정단위의 수치가 높음(평균 이상임)을 나타내는 속성값 <p class="message"> 다수(多數), 다액(多額), 대규모적(大規模的), 대량(大量), 대부분(大部分), 대수, 대형(大型), 비일비재(非一非再), 산더미(山__), 상당수(相當數), 십중팔구(十中八九), 장거리(長距離), 장기간(長期間), 장신(長身), 천추(千秋), 초고속(超高速), 초대형(超大型), 최다(最多), 최대(最大), 최장(最長) </p>  (2) 중 : 어떤 대상의 수나 양이나 그 측정단위의 수치가 평균, 보통임을 나타내는 속성값  (3) 소 : 어떤 대상의 수나 양이 적거나 그 측정단위의 수치가 낮음(평균 이하임)을 나타내는 속성값 <p class="message"> 과부족(過不足), 무보수(無報酬), 소규모(小規模), 소량(小量), 소수(少數), 소폭(小幅), 소형(小型), 염가(廉價), 영점(零點), 저율(低率), 최단(最短), 최소(最小), 최저(最低), 최하(最下) </p>  색속성값 : 특정 파장의 빛을 반사하는 특성 <p class="message"> 각색(各色), 갈색(褐色), 검은빛, 검은색(__色), 검정, 검정색(__色), 고색(古色), 곤색(_色), 국방색(國防色), 군청색(群靑色), 까만색(__色), 까망, 깜장, 남색(藍色), 노랑, 녹색(綠色), 누른색, 다갈색(茶褐色), 다홍(_紅), 다홍색(_紅色), 단색(單色), 동색(同色), 무색(_色), 미색(米色), 반백(斑白-), 밤색(_色), 백색(白色), 보라, 보라빛, 보라색(__色), 보랏빛, 보색(補色), 분홍(粉紅), 분홍빛(粉紅_), 분홍색(粉紅色), 붉은빛, 붉은색(__色), 빨간색(__色), 빨강, 삼색(三色), 상록(常綠), 색색(色色), 순백(純白), 순백색(純白色), 신록(新綠), 암갈색(暗褐色), 연분홍(軟粉紅), 오색(五色), 옥색(玉色), 유색(有色), 은빛(銀_), 은색(銀色), 일색(一色), 자주색(紫朱色), 자줏빛(紫朱_), 장밋빛(薔薇__), 잿빛, 적갈색(赤褐色), 적색(赤色), 진분홍빛(津粉紅), 진초록(津草綠), 청록(靑綠), 청색(靑色), 초록(草綠), 초록빛(草綠_), 초록색(草綠色), 칠흑(漆黑), 파랑, 핑크(pink), 하늘색(__色), 하양, 홍색(紅色), 황갈색(黃褐色), 황색(黃色), 회갈색(灰褐色), 회색(灰色), 흑(黑), 흑백(黑白), 흑색(黑色), 흰색(_色) </p>  맛속성값 <p class="message"> 단맛, 쓴맛 </p>  능력속성값 : 어떤 대상이 지닌, 어떤 일을 할 수 있는 힘, 능력과 관련된 속성값 <p class="message"> 가격경쟁력(價格競爭力), 경제력(經濟力), 공신력(公信力), 괴력(怪力), 구매력(購買力), 국방능력(國防能力), 군사력(軍事力), 권능(權能), 권세(權勢), 근력(筋力), 금력(金力), 기력(氣力), 깡다구, 눈썰미, 두각(頭角), 선견지명(先見之明), 설득력(說得力), 심미안(審美眼), 암기력(暗記力), 어휘력(語彙力), 억제력(抑制力), 언변(言辯), 여력(餘力), 역량(力量), 오성(悟性), 완력(腕力), 일당백(一當百), 장점(長點), 재간(才幹), 재량(裁量), 재력(財力), 재주, 저력(底力), 지구력(持久力), 지도력(指導力), 직무능력(職務能力), 진취력(進取力), 창의력(創意力), 창조력(創造力), 천리안(千里眼), 총력(總力), 타력(他力), 특효(特效), 파워(power), 표현력(表現力), 필력(筆力) </p>  인성속성값 : 인간과 관련된 제반 속성값 <p class="message"> 감상주의(感傷主義), 결벽(潔癖), 과묵(寡默), 나잇값, 내장긴장형(內臟緊張型), 뇌긴장형(腦緊張型), 다변(多辯), 달변(達辨), 닭고집(_固執), 닭대가리, 두뇌형(頭腦型), 망령살(妄靈_), 무학(無學), 박명(薄命), 불성(佛性), 사기(士氣), 사디즘(sadism), 억척, 영웅호색(英雄好色), 존귀(尊貴) </p>  (1) 긍정적인 인성속성값 : 긍정적으로 평가되는 인성 <p class="message"> 검소(儉素), 겸양(謙讓), 겸허(謙虛), 과단성(果斷性), 관용적(寬容的), 교양(敎養), 군인정신(軍人精神), 근검(勤儉), 기개(氣槪), 기상(氣像), 기지(奇智), 끼, 덕망(德望), 뚝심, 미성(美聲), 박력(迫力), 박학(博學), 배짱, 불굴(不屈), 불심(佛心), 사명감(使命感), 성실(誠實), 소양(素養), 슬기, 식견(識見), 신기(神技), 신통(神通), 심안(心眼), 싸가지, 싹수머리, 아량(雅量), 얌통머리, 양심(良心), 언행일치(言行一致), 연륜(年輪), 염치머리(廉恥__), 예능(藝能), 예지(銳智), 온유(溫柔), 외유내강(外柔內剛), 용감무쌍(勇敢無雙), 용맹(勇猛), 용맹성(勇猛性), 위트(wit), 유머(humor), 유식(有識), 윤리덕(倫理德), 의기(意氣), 인간미(人間味), 인격(人格), 인내심(忍耐心), 인덕(人德), 인의(仁義), 일소백미(一笑百媚), 재능(才能), 재질(才質), 재치(才致), 절개(節槪), 정절(貞節), 정조(貞操), 정직(正直), 정직성(正直性), 조심성(操心性), 지조(志操), 진취성(進就性), 참을성(__性), 창의(創意), 책임의식(責任意識), 청렴(淸廉), 청백(淸白), 청순(淸純), 총명(聰明), 충(忠), 충성(忠誠), 충의(忠義), 충절(忠節), 충정(忠情), 친절(親切), 침착(沈着), 투지(鬪志), 투혼(鬪魂), 학식(學識), 한숙(-熟), 해박(該博), 호기(豪氣), 효성(孝誠), 후덕(厚德), 희생정신(犧牲精神) </p>  (2) 부정적인 인성속성값 : 부정적으로 평가되는 인성 <p class="message"> 게으름, 결격(缺格), 경솔(輕率), 경솔함(輕率_), 고집불통(固執不通), 극악무도(極惡無道), 나태(懶怠), 낭비벽(浪費癖), 냄비근성(_根性), 다혈(多血), 도벽(盜癖), 독선(獨善), 돈독(_毒), 마각(馬脚), 무계획성(無計劃性), 무관심(無關心), 무지(無知), 무책임(無責任), 박색(薄色), 박약(薄弱), 범죄혐의(犯罪嫌疑), 부덕(不德), 부주의(不注意), 불온(不穩), 비정(非情), 사리사욕(私利私慾), 사심(私心), 사악(邪惡), 성깔, 성깔머리, 소극성(消極性), 승벽(勝癖), 심술딱지(心術__), 아집(我執), 아첨(阿諂), 어거지, 어리석음, 어정, 억지, 오만(傲慢), 오만불손(傲慢不遜), 옹고집(壅固執), 외곬, 우매(愚昧), 우유부단(優柔不斷), 위선(僞善), 이기심(利己心), 인색(吝嗇), 잔인(殘忍), 잔학(殘虐), 잔학성(殘虐性), 잔혹(殘酷), 졸렬, 죄악상(罪惡相), 콤플렉스(complex), 타성(惰性), 탐(貪), 태만(怠慢), 파렴치(破廉恥), 편협(偏狹), 학벌의식(學閥意識), 허욕(虛慾), 흉악(凶惡) </p>  품격속성값 <p class="message"> 격조(格調), 기품(氣品), 신격(神格), 양식(良識), 영욕(榮辱), 위신(威信), 위엄(威嚴), 장인정신(匠人精神), 준법정신(遵法精神) </p>  관계속성값 : 둘 이상의 존재 사이의 상관관계를 나타내는 속성값 <p class="message"> 가연(佳緣), 가외(加外), 갭(gap), 공평(公平), 관련(關聯), 기원(起源), 기초(基礎), 다름, 대결구도(對決構圖), 대결국면(對決局面), 대동소이(大同小異), 대립관계(對立關係), 대립구도(對立構圖), 대립적(對立的), 대비(對比), 대칭(對稱), 독립적, 동계(同系), 동년(同年), 동형(同形), 모순(矛盾), 반대(反對), 반면(反面), 반수(半數), 병존(竝存), 불가분(不可分), 불가침(不可侵), 삼각관계(三角關係), 상관(相關), 상관관계(相關關係), 상극(相剋), 상당(相當), 상대성(相對性), 상동(相同), 상응(相應), 상이(相異), 상호(相互), 상호모순(相互矛盾), 생면부지(生面不知), 소속(所屬), 소이대동(小異大同), 손아래뻘, 손위, 수평(水平), 순접(順接), 슬하(膝下), 시각차(視角差), 쌍쌍(雙雙), 아래뻘, 아웃(out), 안성맞춤(安城__), 알력(軋轢), 앙상블, 양립(兩立), 역비례(逆比例), 연상(年上), 연속(連續), 연접(連接), 연하(年下), 열성(劣性), 예외(例外), 오촌(五寸), 우선(優先), 우위(優位), 유래(由來), 이산(離散), 인접(隣接), 인척간(姻戚間), 임박(臨迫), 접경(接境), 정반대(正反對), 제격(_格), 직결(直結), 차등(差等), 차이(差異), 통일감(統一感), 특별(特別), 특별권력관계(特別權力關係), 특색(特色), 특성(特性), 특유(特有), 특질(特質), 특징(特徵), 푸대접(_待接), 하나, 함유(含有), 함축(含畜), 합법칙성(合法則性), 합치(合致), 해당(該當) </p>  (1) 상이 : 둘 이상의 존재 사이의 상관관계 중 상이함을 표하는 관계속성값 <p class="message"> 별개(別個), 비대칭(非對稱), 오차(誤差), 이율배반(二律背反), 이해상반(利害相反), 임금격차(賃金格差), 차이점(差異點), 터울, 틀림 </p>  (2) 유사일치 : 둘 이상의 존재 사이의 상관관계 중 유사함 또는 일치를 표하는 관계속성값 <p class="message"> 동류(同類), 동명(同名), 명실상부(名實相符), 부합(附合), 음상사(音相似), 일심(一心), 일치단결(一致團結), 일치성(一致性), 적중(的中), 합일(合一) </p>  (3) 우호 : 둘 이상의 존재 사이의 상관관계 중 우호적 관계를 나타내는 관계속성값 <p class="message"> 상하화목(上下和睦), 선린(善隣), 어울림, 지구간(知舊間), 친미(親美), 친밀(親密), 친분(親分), 친선(親善), 친일(親日), 친화(親和), 통정(通情), 화목(和睦) </p>  (4) 소원 : 둘 이상의 존재 사이의 상관관계 중 소원함을 나타내는 관계속성값  (5) 대치적대 : 둘 이상의 존재 사이의 상관관계 중 대치 혹은 적대 관계를 표하는 관계속성값 <p class="message"> 교전관계(交戰關係), 역접(逆接), 저촉(抵觸), 적대관계(敵對關係) </p>  (6) 동등 : 둘 이상의 존재 사이의 상관관계 중 동등함을 나타내는 관계속성값 <p class="message"> 균등(均等), 동급(同級), 동등(同等), 동량(同量), 동수(同數), 동점(同點), 동질(同質), 등가(等價), 등속(等速), 백중(伯仲), 병렬(竝列), 병립(竝立), 병행(竝行), 타이(tie), 평행(平行), 평형(平衡) </p>  (7) 우위 : 둘 이상의 존재 사이의 상관관계 중 우위를 나타내는 관계속성값 <p class="message"> 비교우위(比較優位), 특기(特技), 특장(特長) </p>  (8) 열등 : 둘 이상의 존재 사이의 상관관계 중 열등함을 나타내는 관계속성값 <p class="message"> 열등(劣等), 열세(劣勢) </p>  (9) 포함귀속 : 둘 이상의 존재 사이의 상관관계 중 포함관계를 나타내는 관계속성값 <p class="message"> 배속(配屬), 부속(附屬), 비독립적(非獨立的), 직속(直屬), 포괄(包括), 포함(包含) </p>  (10) 모범 : 둘 이상의 존재 사이의 상관관계 중 모범, 모델을 표하는 관계속성값  방식속성값 : 행위, 사건/현상이 일어나는 모습 또는 상태가 성립되어 있는 모습 <p class="message"> 간이(簡易), 간접(間接), 겹겹, 공공입찰(公共入札), 공기건축(空氣建築), 공업용(工業用), 광고용(廣告用), 구식(舊式), 국영(國營), 국제적(國際的), 군용(軍用), 논스톱(nonstop), 단도직입(單刀直入), 단도직입적(單刀直入的), 단적(端的), 돌비시스템(Dolby system), 라이브(live), 맞춤, 무기명(無記名), 민주적(民主的), 밖여닫이, 변칙(變則), 부조리(不條理), 분업(分業), 붙박이, 비밀리(秘密裏), 상명하복(上命下服), 셀프(self), 속달(速達), 속전(速戰), 수동(手動), 수시(隨時), 신식(新式), 십진법(十進法), 아날로그(analogue), 알파벳순(alphabet_), 여닫이, 역순(逆順), 왕립(王立), 재래식(在來式), 전천후(全天候), 조건부(條件附), 조립건축(組立建築), 주마간산(走馬看山), 주먹구구식(__九九式), 주입식(注入式), 직렬(直列), 천편일률(千篇一律), 프레스코(fresco), 하향식(下向式), 한목소리, 회전식(回轉式) </p>  (1) 순환시간방식속성값 <p class="message"> 연간(年刊), 연례(年例), 제때 </p>  평가속성값 <p class="message"> 경이적(驚異的), 고무적(鼓舞的), 영광(榮光), 영예(榮譽), 오명(汚名), 유용성(有用性), 중요성(重要性), 진풍경(珍風景), 청승, 촌티(村_) </p>  촉감속성값 <p class="message"> 비단결(緋緞_) </p>  소리속성값 <p class="message"> 바리톤(baritone), 잔향(殘響) </p>  #### 상태 <p class="message"> 가관(可觀), 가난, 가변(可變), 가청(可聽), 간고(艱苦), 간난(艱難), 감옥신세(監獄身世), 감촉(感觸), 강박관념(强迫觀念), 개재(介在), 개판, 거국(擧國), 거주(居住), 건성, 건전(健全), 결여(缺如), 결핍(缺乏), 경기(景氣), 계엄(戒嚴), 고갈(枯渴), 고난(苦難), 고립(孤立), 고생(苦生), 고심(苦心), 고위(高位), 고착(固着), 고초(苦楚), 곤경(困境), 곤궁(困窮), 곤란(困難), 곤죽(_粥), 공감(共感), 공명(功名), 공영(共榮), 공유(公有), 공통(共通), 공허(空虛), 공황(恐慌), 과다(過多), 과밀(過密), 과잉(過剩), 과중(過中), 관류(貫流), 구김, 구상(具象), 군웅할거(群雄割據), 궁핍(窮乏), 권태(倦怠), 궐위(闕位), 귀속(歸屬), 귀천상하(貴賤上下), 균형(均衡), 극락(極樂), 금치산(禁治産), 기색(氣色), 기혼(旣婚), 긴급(緊急), 긴장(緊張), 꼬락서니, 난공불락(難功不落), 난리통(亂離_), 난조(亂調), 내우외환(內優外患), 냉전(冷戰), 노동해방(勞動解放), 눈물범벅, 다행(多幸), 단독(單獨), 단신(單身), 동맹(同盟), 뒤범벅, 뒤죽박죽, 듀스(deuce), 딜레마(dilemma), 러브(love), 만루(滿壘), 만수(滿水), 만원(滿員), 매너리즘(mannerism), 몰아, 무궁(無窮), 무급(無給), 무언(無言), 무제(無題), 무죄(無罪), 무직(無職), 문란(紊亂), 미결(未決), 미망(未亡), 미비(未備), 미상(未詳), 미온적(微溫的), 미완(未完), 미정(未定), 미제(未濟), 미지(未知), 미취학(未就學), 미필(未畢), 미혼(未婚), 밀봉(密封), 밀집(密集), 밀폐(密閉), 박두(迫頭), 반라(半裸), 발가숭이, 벌거숭이, 부전(不全), 부정적(否定的), 부조화(不調和), 불능(不能), 불리(不利), 불명(不明), 불우(不遇), 불운(不運), 비례(比例), 비상(非常), 비참(悲慘), 빈곤(貧困), 빈궁(貧窮), 빈발(頻發), 빈약(貧弱), 산산조각(散散__), 살벌(殺伐), 상승세(上昇勢), 상태(狀態), 상황(狀況), 생사고락(生死苦樂), 선명(鮮明), 성관(盛觀), 소매평생(素昧平生), 소식불통(消息不通), 소정(所定), 속곳바람, 속수무책(束手無策), 손님격(__格), 순결(純潔), 순수(純粹), 시급(時急), 시종일관(始終一貫), 식욕(食慾), 신생(新生), 신세(身世), 실상(實狀), 실재(實在), 실적(實績), 실전(失傳), 실정(實情), 실조(失調), 실태(實態), 쌍(雙), 안녕(安寧), 안락(安樂), 안부(安否), 안온(安穩), 안위(安危), 안전(安全), 암중(暗中), 업태(業態), 여부(與否), 여하(如何), 열반(涅槃), 요령부득(要領不得), 우세(優勢), 우호(友好), 원활(圓滑), 위락(慰樂), 위생(衛生), 위헌(違憲), 유별(有別), 유상(有償), 유수(有數), 유죄(有罪), 육박(肉迫), 융성(隆盛), 이완(弛緩), 인기(人氣), 인복(人福), 인해(人海), 일로(一路), 일장(一場), 임의(任意), 재적(在籍), 전면조망(全面眺望), 존립(存立), 존속(存續), 존재(存在), 존폐(存廢), 종속(從屬), 주불(駐佛), 중상(重像), 중성(中性), 중소공지(衆所共知), 중용(中庸), 증상(症狀), 직면(直面), 진공(眞空), 진용(陣容), 질곡(桎梏), 질식(窒息), 착생(着生), 찬연(燦然), 참상(慘狀), 참신(斬新), 참혹(慘酷), 창성(昌盛), 책임무능력(責任無能力), 청결(淸潔), 청정(淸淨), 청탁(淸濁), 층층시하(層層侍下), 치안(治安), 치하(治下), 친목(親睦), 침체(沈滯), 카오스, 탕건바람(宕巾__), 태극(太極), 토끼잠, 통화대기(通話待機), 퇴폐(頹廢), 팽배(彭湃), 편안(便安), 편향(偏向), 표상(表象), 풍요(豊饒), 풍족(豊足), 피폐(疲弊), 필요(必要), 학습자세(學習姿勢), 한창, 항균(抗菌), 해괴망측(駭怪罔測), 행방불명(行方不明), 향락(享樂), 현존(現存), 현행(現行), 현황(現況), 형평(衡平), 호각(互角), 혼자, 혼재(混在), 화재예방(火災豫防), 활주(滑走), 황금만능(黃金萬能), 휴면(休眠) </p>  심리상태 : 유정물의 심리적 상태 <p class="message"> 경로사상(敬老思想), 계급동정(階級同情), 고락(苦樂), 고정관념(固定觀念), 관계관념(關係觀念), 군중심리(群衆心理), 긍지심(矜持心), 기고만장(氣高萬丈), 기대감(期待感), 기분(氣分), 느낌, 대상감정(對象感情), 만감(萬感), 무드(mood), 무사안일(無事安逸), 민족감정(民族感情), 반미감정(反美感情), 반일감정(反日感情), 본마음(本__), 불쾌(不快), 불편(不便), 비관주의(悲觀主義), 비의(悲意), 비탄(悲嘆), 사감(私感), 사분(私分), 성욕(性慾), 자아도취(自我陶醉), 자제심(自制心), 절망감(絶望感), 좌절감(挫折感), 출세욕(出世慾), 친근감(親近感), 친소간(親疎間), 편집(偏執), 해이(解弛), 허가심(虛假心), 회포(懷抱), 흔연 </p>  (1) 외향적 심리상태 : 어떤 대상에 대한 지향성을 갖는 심리상태 <p class="message"> 거리감(距離感), 거부감(拒否感), 경각심(警覺心), 경계심(警戒心), 경모(敬慕), 경복(敬服), 경의(敬意), 고마움, 골머리, 공감대(共感帶), 공분(公憤), 공포감(恐怖感), 교만(驕慢), 궁금증(__症), 귀염, 그리움, 긍지(矜持), 기승(氣勝), 나라사랑, 내리사랑, 노심초사(勞心焦思), 노여움, 노염, 노파심(老婆心), 놀라움, 높임, 만족감(滿足感), 모성애(母性愛), 모순감정(矛盾感情), 무서움, 물욕(物慾), 미움, 민망(民望), 믿음, 반가움, 반감(反感), 배신감(背信感), 부끄러움, 부끄럼, 부담감(負擔感), 부러움, 부아, 분(憤), 분개(憤慨), 분노(憤怒), 분분(忿憤), 분심(憤心), 분통(憤痛), 불만(不滿), 불신(不信), 불쾌감(不快感), 비리의혹(非理疑惑), 사랑, 사의(謝意), 살의(殺意), 색정(色情), 생명존중(生命尊重), 선망(羨望), 선의(善意), 성심(誠心), 성화(成火), 쇼크(shock), 수구초심(首丘初心), 수치(羞恥), 수치심(羞恥心), 순정(純情), 시기심(猜忌心), 시름, 신비감(神秘感), 싫증(_症), 심통(心_), 아쉬움, 악감정(惡感情), 악심(惡心), 악의(惡意), 안근심, 안타까움, 애국심(愛國心), 애증(愛憎), 애착(愛着), 애착심(愛着心), 야속(野俗), 어색(語塞), 억하심정(抑何心情), 연대감(連帶感), 연모(戀慕), 연민(憐憫), 연정(戀情), 열등의식(劣等意識), 열애(悅愛), 염려(念慮), 염치(廉恥), 옛정(_情), 온정(溫情), 욕심(慾心), 우애(友愛), 우의(友誼), 우정(友情), 울화(鬱火), 원(怨), 원한(怨恨), 위기감(危機感), 위기의식(危機意識), 의구심(疑懼心), 의문점(疑問點), 의아(疑訝), 의존심(依存心), 인애(人愛), 일편단심(一片丹心), 자부심(自負心), 자신감(自信感), 잔정(_情), 저항심(抵抗心), 적개심(敵愾心), 적대감(敵對感), 적대심(敵對心), 적의(敵意), 전의(戰意), 절박감(切迫感), 정(情), 정나미(情__), 정분(情分), 정욕(情慾), 조국애(祖國愛), 존경심(尊敬心), 존중심(尊重心), 죄의식(罪意識), 증오(憎惡), 지역감정(地域感情), 진노(嗔怒), 진저리, 진절머리, 질시(疾視), 질투심(嫉妬心), 집착력(執着力), 집착심(執着心), 짝사랑, 찬탄(讚歎), 참사랑, 책임감(責任感), 총동(衝動), 축의(祝意), 충동(衝動), 치정(癡情), 친밀감(親密感), 친숙(親熟), 친애(親愛), 탄복(歎服), 탐닉(耽溺), 탐미(耽美), 탐심(貪心), 탐욕(貪慾), 탐재(貪財), 통한(痛恨), 투시(妬視), 투쟁심(鬪爭心), 포악(暴惡), 한심(寒心), 해방감(解放感), 현실감(現實感), 혐오(嫌惡), 혐오감(嫌惡感), 호감(好感), 호기심(好奇心), 호의(好意), 화(火), 화통, 환멸(幻滅), 홧김(火__), 후환(後患), 후회(後悔), 흠모(欽慕), 흥미(興味), 흥분(興奮), 희구(希求), 희망(希望) </p>  (2) 내재적 심리상태 : 어떤 대상에 대한 지향성을 갖지 않는 심리상태 <p class="message"> 감개(感慨), 격정(激情), 고뇌(苦惱), 고독(孤獨), 공황상태(恐慌狀態), 공황장애(恐慌障碍), 괘념(掛念), 괴로움, 군중고독(群衆孤獨), 근심, 기쁨, 기우(杞憂), 긴박감(緊迫感), 긴장감(緊張感), 낙(樂), 냉가슴(冷__), 냉정(冷情), 당혹(當惑), 당혹감(當惑感), 당황(唐惶), 도덕불감증(道德不感症), 리비도(Libido), 무력감(無力感), 번거로움, 불안(不安), 불안감(不安感), 불행(不幸), 비감(悲感), 비애(悲哀), 비통(悲痛), 설렘, 설움, 성취감(成就感), 소외감(疏外感), 스릴(thrill), 슬픔, 식도락(食道樂), 신명, 신바람, 심신산란(心身散亂), 안도(安堵), 안도감(安堵感), 안락감(安樂感), 암울(暗鬱), 애상(哀傷), 애수(哀愁), 애환(哀歡), 어둠공포(__恐怖), 여정(旅情), 여한(餘恨), 여흥(餘興), 열락(悅樂), 오기(傲氣), 외로움, 우울(憂鬱), 우환, 울분(鬱憤), 육아스트레스(育兒____), 의기소침(意氣銷沈), 의기양양(意氣揚揚), 의기충천(意氣衝天), 의무감(義務感), 이판사판(이판사판), 자괴감(自愧感), 자괴심(自愧心), 자립심(自立心), 자존심(自尊心), 자책감(自責感), 자포자기(自暴自棄), 잔풀호사(__豪奢), 잡념(雜念), 전율(戰慄), 정감(情感), 정념(情念), 조바심, 좌절(挫折), 주눅, 즐거움, 지랄, 집념(執念), 참담(慘澹), 창피(猖披), 청정심(淸淨心), 초조(焦燥), 춘심(春心), 충심(衷心), 취흥(醉興), 치기(稚氣), 치욕(恥辱), 카타르시스, 쾌감(快感), 쾌락(快樂), 쾌재(快哉), 태연(泰然), 패배주의(敗北主義), 평강(平康), 평안(平安), 평온(平穩), 한(恨), 행복(幸福), 행복감(幸福感), 향학열(向學熱), 허무(虛無), 허영심(虛榮心), 허탈감(虛脫感), 형극(荊棘), 환심(歡心), 환희(歡喜), 황홀(恍惚), 황홀감(恍惚感), 회한(悔恨), 흥(興), 흥취(興趣), 희열(喜悅) </p>  신체상태 : 인간이나 동물의 몸의 상태 <p class="message"> 간지럼, 갈증(渴症), 강장(强壯), 건강(健康), 건강상태(健康狀態), 건승(健勝), 건재(健在), 공복(空腹), 공복감(空腹感), 과민(過敏), 굶주림, 기갈(飢渴), 기아(飢餓), 기진맥진(氣盡脈盡), 난청(難聽), 노독(路毒), 노쇠(老衰), 노안(老眼), 노익장(老益壯), 녹초, 뇌사(腦死), 누드(nude), 눈동자피로(_瞳子疲勞), 딸기혀, 만삭(滿朔), 만성(慢性), 만신창이(滿身瘡痍), 만취(漫醉), 무기력(無氣力), 배고픔, 병고(病苦), 병마(病魔), 병세(兵勢), 병중(病中), 불구(不具), 불면(不眠), 불수(不隨), 비대(肥大), 비만(肥滿), 빈사(瀕死), 사경(死境), 산고(産苦), 산기(産氣), 생(生), 생사(生死), 쇠약(衰弱), 숙취(宿醉), 술김, 스트레스(stress), 식욕부진(食慾不振), 신경쇠약(神經衰弱), 신경피로(神經疲勞), 실신(失神), 심신피로(心身疲勞), 아픔, 안일(安逸), 애꾸, 어지러움(語彙力), 여독(旅毒), 영양부족(營養不足), 와병(臥病), 외팔, 욕지기, 이상체질(異常體質), 잔병치레(_病__), 정신분열(精神分裂), 조갈(燥渴), 졸음, 중증장애(重症障碍), 지루(脂漏), 최면(催眠), 춘곤(春困), 충혈(充血), 취중(醉中), 컨디션(condition), 탈구(脫臼), 탈진(脫盡), 팽만(膨滿), 피곤(疲困), 피로(疲勞), 한고(寒苦), 허기(虛飢), 허약(虛弱), 허탈(虛脫), 헛배, 혈기(血氣), 혼미(昏迷), 혼수상태(昏睡狀態), 환각(幻覺) </p>  기색 <p class="message"> 거기(据氣), 노기(怒氣), 살기(殺氣), 생기(生氣), 생동감(生動感), 숨기(_氣), 울상(_相), 태기(胎氣), 험상(險狀), 혈안(血眼), 화색(和色), 희색만면 </p>  질병 및 증세 : 인간에게 발생하는 질병이나 증세 <p class="message"> 간암(肝癌), 간염(肝炎), 간질(癎疾), 감기(感氣), 갑갑증(__症), 거부반응(拒否反應), 건강염려증(健康念慮症), 격통(激痛), 결막염(結膜炎), 결벽증(潔癖症), 결핵(結核), 고름, 고뿔, 고질(痼疾), 고혈압(高血壓), 관절염(關節炎), 광기(狂氣), 광증(狂症), 구강암(口腔癌), 궤양(潰瘍), 귓병(_병), 급성간염(急性肝炎), 급체(急滯), 긴병(_病), 나병(癩病), 냉(冷), 냉증(冷症), 노망(老妄), 노이로제(neurose ), 노인우울증(老人憂鬱症), 노환(老患), 녹내장(綠內障), 농가진(膿痂疹), 뇌막염(腦膜炎), 뇌성마비(腦性痲<U+75F9>), 뇌성소아마비(腦性小兒痲痺), 뇌출혈(腦出血), 다수공포증(多數恐怖症), 다운증후군(Down___), 다한증(多汗症), 당뇨(糖尿), 당뇨병(糖尿病), 대변불통(大便不通), 독감(毒感), 돈콜레라(豚___), 동맥경화(動脈硬化), 동맥경화증(動脈硬化症), 동병(同病), 동상(凍傷), 동통(疼痛), 두드러기, 두통(頭痛), 등골마비(__麻痺), 류머티즘(rheumatism), 마마(__), 만병(萬病), 만성간염(慢性肝炎), 만성질환(慢性疾患), 말라리아(malaria), 매독(梅毒), 맹장염(盲腸炎), 멀미, 멍, 면역결핍증(免疫缺乏症), 명절증후군(名節症候群), 몸살, 몽유병(夢遊病), 무감각증(無感覺症), 무모(無毛), 무좀, 미열(微熱), 발기부전(勃起不全), 발덧, 발열(發熱), 발작(發作), 발작증세(發作症勢), 방광암(膀胱癌), 배탈(_탈), 백내장(白內障), 백혈병(白血病), 변비(便秘), 병(病), 병환(病患), 복통(腹痛), 볼거리, 부스럼, 부종(浮腫), 부황(浮黃), 부황병(浮黃病), 분열증(分裂症), 불감증(不感症), 불결공포(不潔恐怖), 불면증(不眠症), 불임(不妊), 비만증(肥滿症), 비염(鼻炎), 빈혈(貧血), 산통(疝痛), 살몸살, 상사병(相思病), 상처(傷處), 생병(生病), 선상피부염(線狀皮膚炎), 성별도착(性別倒錯), 성병(性病), 성욕도착(性慾倒錯), 성인병(成人病), 소아마비(小兒痲痺), 속병(_病), 손거스러미, 손님마마(__<U+5ABD><U+5ABD>), 수두(水痘), 수면증(睡眠症), 숙환(宿患), 술오한(_惡寒), 습진(濕疹), 식곤증(食困症), 식중독(食中毒), 신경과민(神經過敏), 신경증(身硬症), 신생아중이염(新生兒中耳炎), 신생아폐렴(新生兒肺炎), 신생아황달(新生兒黃疸), 신열(身熱), 신장결석(腎臟結石), 신체장애(身體障<U+7919>), 실어증(失語症), 심장마비(心臟痲痺), 심장병(心臟病), 심장판막증(心臟瓣膜症), 십이지장궤양(十二指腸潰瘍), 쓰라림, 안질(眼疾), 알레르기, 암성궤양(癌性潰瘍), 어질병(__病), 언어흥분(言語興奮), 얼굴신경통(__神經痛), 열병(熱病), 열사병(熱射病), 염병(染病), 염증(炎症), 영양실조(營養失調), 예증(例症), 오줌소태, 오한(惡寒), 옴, 요통(腰痛), 우울증(憂鬱症), 위간경변증(僞肝硬變症), 위강직(胃强直), 위경련(胃痙攣), 위궤양(胃潰瘍), 위병(胃病), 위암(胃癌), 위염(胃炎), 위장병(胃臟病), 위통(胃痛), 음경암(陰莖癌), 의처증(疑妻症), 이경화증(耳硬化症), 인플루엔자(influenza), 임질(淋疾), 작위사고(作爲思考), 잔병(_病), 잡병(雜病), 장염(腸炎), 장중풍(腸中風), 정신병(精神病), 정신분열증(精神分裂症), 정신지체(精神肢體), 정신질환(精神疾患), 젖몸살, 조루(早漏), 조울병(躁鬱病), 주독코(酒毒_), 주부우울증(主婦憂鬱症), 중병(重病), 중이염(中耳炎), 중풍(中風), 중환(重患), 쥐부스럼, 증후군(症候群), 지병(持病), 직업병(職業病), 진통(陣痛), 진폐(塵肺), 질병(疾病), 질환(疾患), 착란(錯亂), 천식(喘息), 천연두(天然痘), 첨단공포(尖端恐怖), 청각장애(聽覺障<U+7919>), 체증(滯症), 총상(銃傷), 축농증(蓄膿症), 출혈(出血), 치매(癡_ (0x5446)), 치질(痔疾), 치통(齒痛), 코각시, 타박상(打撲傷), 통증(痛症), 파상풍(破傷風), 편도선염(扁桃腺炎), 편두통(偏頭痛), 폐결핵(肺結核), 폐렴(肺炎), 폐병(肺病), 폐암(肺癌), 피부병(皮膚病, narg를 npred로 수정), 피부염(皮膚炎), 학질(栖疾), 합병증(合倂症), 항아리손님(缸____), 행려병(行旅病), 허리디스크(__disc), 헛구역질(_嘔逆_), 현기증(眩氣症), 혈청간염(血淸肝炎), 홍역(紅疫), 화농(化膿), 화병(火病), 화장독(化粧毒), 환청(幻聽), 환후(患候), 홧병(火病), 황달(黃疸), 후유증(後遺症) </p>  인지상태 : 사람이 머리 속에 떠올리거나 가지는 것 <p class="message"> 계급의식(階級意識), 고의(故意), 고충(苦衷), 국민의식(國民意識), 깨달음, 깨우침, 노심(勞心), 몰이해(沒理解), 무계획(無計劃), 무분별(無分別), 무작정(無酌定), 부지(不知), 상념(想念), 소명(召命), 속내, 속뜻, 시대사상(時代思想), 열의(熱意), 열정(熱情), 염세(厭世), 의중(意中), 의혹(疑惑), 장삿속, 정신머리(精神__), 주관(主觀), 주책, 중론(衆論), 지(知), 진의(眞意), 초심(初心), 탐구욕(探究慾), 학구열(學究熱), 혐의(嫌疑), 흉금(胸襟) </p>  (1) 의견 <p class="message"> 거부의사(拒否意思), 견지(見地), 계급관념(階級觀念), 공식입장(公式立場), 교육철학(敎育哲學), 국론(國論), 국민여론(國民與論), 국제여론(國際與論), 낙관론(樂觀論), 논변(論辨), 단견(短見), 단상(斷想), 당론(黨論), 독단론(獨斷論), 묘안(妙案), 문제의식(問題意識), 반대의견(反對意見), 발상(發想), 법사상(法思想), 본의(本意), 비견(鄙見), 사고방식(思考方式), 상혼(商魂), 선입견(先入見), 선입관(先入觀), 세계관(世界觀), 세론(世論), 소갈머리, 소감(所感), 소견(所見), 소신(所信), 소심(素心), 시론(時論), 심미관(審美觀), 심증(心證), 아이디어(idea), 억견(臆見), 여론(與論), 역사의식(歷史意識), 용의(用意), 우월의식(優越意識), 우월주의(優越主義), 원의(原義), 원죄의식(原罪意識), 윤리의식(倫理意識), 의향(意向), 이견(異見), 이의(異意), 인권의식(人權意識), 일가견(一家見), 일념(一念), 자아의식(自我意識), 자의(自意), 자의식(自意識), 정론(正論), 지각머리(知覺__), 직업의식(職業意識), 진보성향(進步性向), 진정소발(眞情所發), 집단의식(集團意識), 찬반입장(贊反立場), 초지(初志), 타협안(妥協案), 탁견(卓見), 통념(通念), 편견(偏見), 환상(幻想), 효과의사(效果意思) </p>  (2) 계획 <p class="message"> 궁극목적(窮極目的), 대계(大計), 대망(大望), 모략(謀略), 목적(目的), 목표(目標), 복안(腹案), 비원(悲願), 소망(所望), 소원(所願), 속셈, 숙원(宿願), 실수요(實需要), 실천의지(實踐意志), 야망(野望), 야심(野心), 여망(餘望), 열망(熱望), 염원(念願), 욕구(欲求), 욕망(慾望), 웅지(雄志), 일정(日程), 장래희망(將來希望), 최종목표(最終目標), 타의(他意), 포부(抱負), 흑심(黑心) </p>  상황값 <p class="message"> 가정불화(家庭不和), 개발도상국(開發途上國), 고립무원(孤立無援), 고요, 고용불안(雇傭不安), 고정불변(固定不變), 공개수배(公開手配), 공안(公安), 공포분위기(恐怖雰圍氣), 괴리(乖離), 국정안정(國政安定), 궁지(窮地), 권언유착(勸言癒着), 깜깜무소식(__無消息), 난국(難局), 난립(亂立), 난맥(亂脈), 난장판(亂場_), 남존여비(男尊女卑), 낭패(狼狽), 내림세(__勢), 내재(內在), 농민해방(農民解放), 답보(踏步), 대혼란(大混亂), 데탕트(detente), 도탄(途炭), 두발자유(頭髮自由), 만연(蔓延), 멸종위기(滅種危機), 무법(無法), 무정부상태(無政府狀態), 무질서(無秩序), 무휴(無休), 미개발(未開發), 미달(未達), 미도착(未到着), 민생안정(民生安定), 민생치안(民生治安), 민폐(民弊), 번잡(煩雜), 변화무궁(變化無窮), 변화무상(變化無常), 복락(福樂), 복리(福利), 복지(福祉), 부귀(富貴), 부도사태(不渡事態), 부동(不動), 부실(不實), 부유(浮遊), 부재(不在), 부족(不足), 부진(不振), 북새통, 불결(不潔), 불균형(不均衡), 불변(不變), 불비(不備), 불야성(不夜城), 불확실(不確實), 비번(非番), 산포(散布), 상존(常存), 상충(相衝), 상치(相馳), 상통(相通), 선후도착(先後倒錯), 설상가상(雪上加霜), 성업(盛業), 성행(盛行), 성황(盛況), 세이프(safe), 소강상태(小康狀態), 수세(守勢), 순행(順行), 슬럼프(slump), 시련(試鍊), 신변안전(身邊安全), 신산(辛酸), 심연(深淵), 쑥대밭, 아노미(anomie), 아이러니(irony), 안목소견(眼目所見), 암암리(暗暗裏), 암흑(暗黑), 암흑세계(暗黑世界), 야만(野蠻), 억지춘향이(__春香_), 언어도단(言語道斷), 엄숙(嚴肅), 엄처시하(嚴妻侍下), 엉망, 여반장(如反掌), 여유(餘裕), 역부족(力不足), 연중무휴(年中無休), 예측불허(豫測不許), 오름세(__勢), 오리무중(五里霧中), 오비이락(烏飛梨落), 외환위기(外換危機), 용두사미(龍頭蛇尾), 우후죽순(雨後竹筍), 운수불길(運數不吉), 운영난(運營難), 울음바다, 워크아웃(work out), 위국(危局), 위급(危急), 위기(危機), 위험(危險), 응급상황(應急狀況), 인산인해(人山人海), 일사불란(一絲不亂), 일제강점(日帝强占), 일치(一致), 입시지옥(立試地獄), 자기모순(自己矛盾), 자유(自由), 자율(自律), 자존(自存), 자주(自主), 잔존(殘存), 잠재(潛在), 적기(適期), 적막(寂莫), 적체(積滯), 적합(適合), 전성(全盛), 전운(戰雲), 절대안정(絶對安靜), 점철(點綴), 정숙(靜肅), 정의(正義), 정체불명(正體不明), 제자리걸음, 존립기반(存立基盤), 졸지(猝地), 중과부적(衆寡不敵), 지지부진(遲遲不進), 지행합일(知行合一), 질서정연(秩序整然), 짝짝이, 찬밥신세(__身世), 참혹상(慘酷相), 창해일속(滄海一粟), 천고마비(天高馬肥), 천만다행(千萬多幸), 천신만고(千辛萬苦), 천우신조(天佑神助), 천차만별(千差萬別), 천태만상(千態萬象), 초미(焦眉), 초비상(超非常), 초상집분위기(初喪_雰圍氣), 축제분위기(祝祭雰圍氣), 춘궁(春窮), 충만(充滿), 충일(充溢), 취약(脆弱), 쾌조(快調), 태평(太平|泰平), 파탄(破綻), 파행(跛行), 편재(偏在), 편중(偏重), 편파(偏頗), 평화(平和), 품귀(品貴), 풍비박산(風飛雹散), 풍전등화(風前燈火), 한적(閑寂), 해상위험(海上危險), 형통(亨通), 호조(好調), 호황(好況), 혼돈(混沌), 혼란(混亂), 혼잡(混雜), 화친(和親), 화평(和平), 활황(活況) </p>  관계상태 <p class="message"> 대등, 분포(分布), 비동맹(非同盟), 정경유착(政經癒着) </p>  ### 행위 <p class="message"> 가감(加減), 가공(加工), 가르침, 가매장(假埋葬), 가산(加算), 가족여행(家族旅行), 간섭(干涉), 간행(刊行), 간호(看護), 감당(堪當), 감사(感謝), 감시(監視), 감안(勘案), 감축(減縮), 감행(敢行), 강간(强姦), 강매(强賣), 강요(强要), 강의(講義), 강조(强調), 개량(改良), 개발(開發), 개방(開放), 개봉(開封), 개설(開設), 개업(開業), 개원(開院), 개입(介入), 개정(改正), 개통(開通), 개편(改編), 거래(去來), 거론(擧論), 거절(拒絶), 경례(敬禮), 경유(警衛), 경청(傾聽), 계급독재(階級獨裁), 계몽(啓蒙), 계산(計算), 계승(繼承), 계약(契約), 계획(計劃), 고발(告發), 고백(告白), 고소(告訴), 고양(高揚), 고용(雇用), 고정(固定), 고찰(考察), 골몰(汨沒), 곱셈, 공개(公開), 공격(攻擊), 공부(工夫), 공사(工事), 공생(共生), 공시(公示), 공식활동(公式活動), 공약(公約), 공양(供養), 공연(公演), 공표(公表), 과로(過勞), 과시(誇示), 과음(過飮), 관리(管理), 관여(關與), 관철(貫徹), 관할(管轄), 교육입국(敎育立國), 구사(驅使), 권고사직(勸告辭職), 권선징악(勸善懲惡), 귀경식(歸敬式), 귀양살이, 그네뛰기, 그리기, 글공부(_工夫), 금지처분(禁止處分), 기업결합(企業結合), 기차인공(起差人工), 꼴불견(_不見), 농락(籠絡), 농정(農政), 누설(漏泄), 늦장, 단절(斷絶), 단체행동(團體行動), 단축(短縮), 단합(團合), 단행(斷行), 달맞이, 달성(達成), 담당(擔當), 답습(踏襲), 당일치기(當日__), 대리(代理), 대응(對應), 대조(對照), 대표(代表), 돌출행동(突出行動), 되풀이, 두루치기, 뒷감당(_堪當), 뒷걸음, 뒷받침, 뜨개질, 망연자실(茫然自失), 매개(媒介), 모방(模倣), 모의(模擬), 묵과(默過), 묵인(默認), 박해(迫害), 벼농사(_農事), 보물찾기(寶物__), 보호감호(保護監護), 불역(不易), 사법(司法), 사업(事業), 사형(死刑), 삶, 상정(上程), 새해맞이, 소비자소송(消費者訴訟), 속가래, 속가름, 수준측량(水準測量), 술래잡기(巡邏__), 숲미역, 습격(襲擊), 습득(習得), 승선(乘船), 승진(昇進), 승차(乘車), 승차거부(乘車拒否), 시도(試圖), 시샘, 시장세분화(市場細分化), 시정(是正), 시험(試驗), 시현(示現), 신문광고(新聞廣告), 신물출구(愼勿出口), 신설(新設), 신임(信任), 신청(申請), 신탁(信託), 실시(實施), 실토(實吐), 실현(實現), 심문(審問), 심의(審議), 쓰기, 안내(案內), 안보(安保), 안정(安定), 압도(壓倒), 압수(押收), 애걸(哀乞), 애국(愛國), 애원(哀願), 야기(惹起), 야유(揶揄), 야합(野合), 양도(讓渡), 양성(養成), 언동(言動), 언행(言行), 연애결혼(戀愛結婚), 운집(雲集), 움막살이(_幕__), 원용(援用), 월권(越權), 월권행위(越權行爲), 위법처분(違法處分), 위촉(委囑), 위편삼절(韋編三絶), 유보(留保), 유혹(誘惑), 응축(凝縮), 의거(依據), 의결(議決), 의정(議定), 의존(依存), 이룩, 이수(履修), 이합(離合), 인화(人和), 재분류(再分類), 재추진(再推進), 조처(措處), 조치(措置), 좌우충돌(左右衝突), 좌지우지(左之右之), 준동(蠢動), 중계(中繼), 중신(中_), 증명(證明), 증시(證示), 지적(指摘), 지지(支持), 찜질, 찬송(讚頌), 채신, 책동(策動), 처세(處世), 천거(薦擧), 총동원(總動員), 최종판결(最終判決), 최종확인(最終確認), 축소은폐(縮小隱蔽), 편제(編制), 표결(表決|票決), 풀이, 한턱, 할거(割據), 할부(割賦), 할애(割愛), 할증(割增), 합동(合同), 합산(合算), 합석(合席), 합숙(合宿), 합자(合資), 합주(合奏), 합창(合唱), 항일(抗日), 항전(抗戰), 행동(行動), 행동거지(行動擧止), 행동패턴(行動_), 행락(行樂), 행세(行世), 행위(行爲), 향도(嚮導), 혁파(革罷), 현시(顯示), 현학(衒學), 현혹(眩惑), 혈거(穴居), 효도(孝道), 효행(孝行), 흡인(吸引) </p>  #### 물리적행위 <p class="message"> 가계대출(家計貸出), 가교(架橋), 가동(稼動), 가무(歌舞), 가봉(假縫), 가속(加速), 가식(假飾), 가압(加壓), 가용(加用), 가정파괴(家庭破壞), 가차(假借), 가창(歌唱), 가출(家出), 가칠(加漆), 가투(歌鬪), 간단(間斷), 간선(間選), 감찰(監察), 강경진압(强硬鎭壓), 강압(强壓), 강제(强制), 강타(强打), 강행(强行), 개가(凱歌), 개교(開校), 개그(gag), 개근(皆勤), 개명(改名), 개복(開腹), 개최(開催), 개칭(改稱), 건강검진(健康檢診), 결박(結縛), 겸상(兼床), 겸용(兼用), 경, 계속(繼續), 기립박수(起立拍手), 냉동(冷凍), 논공행상(論功行賞), 농축(濃縮), 대차(貸借), 대항(對抗), 더빙(dubbing), 도급(都給), 도입(導入), 소꿉놀이, 소꿉질, 숨바꼭질, 시행(施行), 안간힘, 압류(押留), 압박(壓迫), 야단(惹端), 약진(躍進), 요식행위(要式行爲), 원예(園藝), 음주(飮酒), 인선(人選), 일독(一讀), 주리, 줄눈나누기, 중주(重奏), 중창(重唱), 집성(集成), 차력(借力), 차용(借用), 참정(參政), 채광(採光), 채록(採錄), 총결집(總結集), 총력전(總力戰), 치맛바람, 풀질, 피동(被動), 피랍(被拉), 하관(下棺), 하달(下達), 합성(合成), 항고(抗告), 호국(護國), 활살자재(活殺自在), 효(孝), 흡착(吸着), 힘자랑 </p>  단독행위 <p class="message"> 가담(加擔), 가미(加味), 가불(假拂), 가세(加勢), 가열(加熱), 가위다리봉사(____奉祀), 가입(加入), 가택방문(家宅訪問), 가필(加筆), 간여(干與), 간척(干拓), 간택(揀擇), 갈무리, 갈이, 감금(監禁), 강강술래, 강제연행(强制移住), 개간(開墾), 개시(開始), 개조(改造), 개찰(改札), 개척(開拓), 갹출(醵出), 거사(擧事), 거출(醵出), 거취(去就), 건배(乾杯), 건조(建造), 검사(檢査), 검산(檢算), 검역(檢疫), 검침(檢針), 게시(揭示), 게양(揭揚), 게재(揭載), 겨냥, 견문(見聞), 견학(見學), 결근(缺勤), 결례(缺禮), 결산(決算), 결석(缺席), 결식(缺食), 경무장(輕武裝), 경영(經營), 경작(耕作), 경질(更迭), 경험(經驗), 계량(計量), 곡예(曲藝), 공개채용(公開採用), 공개투표(公開投票), 공공근로(公共勤勞), 공동대응(共同對應), 공소(公訴), 공작(工作), 공제(控除), 공증(公證), 공천(公薦), 공출(供出), 공헌(貢獻), 과외(課外), 과잉대응(過剩對應), 과잉징수(過剩徵收), 과잉투자(過剩投資), 과적(過積), 관개(灌漑), 관광(觀光), 관급(官給), 관대(款待), 관등(觀燈), 괄목(刮目), 광란(狂亂), 구형(求刑), 군다리미질, 권력남용(勸力濫用), 궐기(蹶起), 급제동(急制動), 기용(起用), 기울기시험(___試驗), 기입(記入), 기표(記票), 기후구분(氣候區分), 깃대춤(旗__), 꺾꽂이, 꽃게잡이, 낙루(落淚), 난사(亂射), 난항(難航), 난행(亂行), 날인(捺印), 남발(濫發), 남장(男裝), 남획(濫獲), 납본(納本), 내부고발(內部告發), 내색(_色), 내습(來襲), 논갈이, 농땡이, 누적(累積), 눈가늠, 눈가량(_假量), 늦잠, 다산(多産), 단명(短命), 단발(單發), 단선(斷線), 단속(團束), 단열(斷熱), 단칸살림, 단타(單打), 당좌예금(當座預金), 대납(代納), 대동(帶同), 대용(代用), 대우(待遇), 대입(大入), 대절(貸切), 대찬성(大贊成), 대체(代替), 대활약(大活躍), 덕낚시, 덕행(德行), 덤핑(dumping), 데뷔(debut), 도굴(盜掘), 도루(盜壘), 도배(塗褙), 도살(屠殺), 도열(堵列), 도주(逃走), 독과점(獨寡占), 독대(獨對), 독살(毒殺), 독식(獨食), 독차지(獨__), 돈벌이, 동냥, 동봉(同封), 동원(動員), 동참(同參), 되맞춤, 뒤걸이, 뒷간질(_間_), 뒷마무리, 드라이(dry), 드라이브(drive), 드라이클리닝(dry cleaning), 듣기, 등공예(藤工藝), 등기(登記), 등록(登錄), 디자인(design), 땅볼(_ball), 떨이, 마감, 막노동(_勞動), 맞이, 매복(埋伏), 매설(埋設), 매수공작(買收工作), 매수인수(買受引受), 매질착색(媒質著色), 면도(面刀), 명명(命名), 모금(募金), 모면(謀免), 모멸(侮蔑), 목격(目擊), 목도(目睹), 몰수(沒收), 몰입(沒入), 몽정(夢精), 무미(貿米), 무시(無視), 무시험검정(無試驗檢定), 무장(武裝), 묵살(默殺), 물사발이기, 미장, 민방위(民防衛), 밀렵(密獵), 밀수(密輸), 밀파(密派), 반납(返納), 반입(搬入), 받아쓰기, 방공(防空), 방송출연(放送出演), 방첩(防諜), 방치(放置), 방향전환(方向轉換), 번지점프(bungee jump), 복상(服喪), 봉축(奉祝), 부각(浮刻), 부기(附記), 불꽃놀이, 불참가(不參加), 불출(不出), 비장(秘藏), 비준(批准), 비치(備置), 비행(飛行), 사격(射擊), 사구(四球), 사냥, 사살(射殺), 사생(寫生), 사역(使役), 사용(使用), 산발(散髮), 산출(産出), 살포(撒布), 삼수(三修), 삼진(三振), 상비(常備), 상용(常用), 생사여탈(生死與奪), 선창(先唱), 선행(先行), 소송행위(訴訟行爲), 송년(送年), 수강신청(受講申請), 술주정(_酒酊), 술타령, 스트라이크(strike), 습자(習字), 승계(承繼), 승마(乘馬), 시범(示範), 시승(試乘), 시식(試食), 시연(試演), 시음(試飮), 시작(始作), 시추(試錐), 식목(植木), 식생활(食生活), 식용(食用), 식인(食人), 식자(植字), 신체검사(身體檢査), 실력행사(實力行使), 실수(失手), 실천(實踐), 실험(實驗), 심미(審美), 심심풀이, 아래위턱, 아부(阿附), 악용(惡用), 악전고투(惡戰苦鬪), 악행(惡行), 안존(安存), 안치(安置), 알현(謁見), 암거(巖居), 암중공작(暗中工作), 압착(壓搾), 앙양(昻揚), 앞장, 애벌, 야단법석(惹端__), 약물검사(藥物檢査), 약육강식(弱肉强食), 약칭(略稱), 얌전, 얼굴값, 엄수(嚴守), 엄호(俺護), 에누리, 여색(女色), 역성, 역이용(逆利用), 역회전(逆回轉), 연체(延滯), 엽색(獵色), 영도(領導), 영접(迎接), 예금(預金), 예시(例示), 예우(禮遇), 예포(禮砲), 오두방정, 오른배지기, 오목가래질(五____), 옷차림, 옹호(擁護), 외박(外泊), 외식(外食), 요란(搖亂), 요술(妖術), 용공(容共), 용납(容納), 우스개, 운휴(運休), 원격조작(遠隔操作), 월반(越班), 위장(僞裝), 유람(遊覽), 유숙(留宿), 유예(猶豫), 유인(誘引), 유지(維持), 유출(流出), 유포(流布), 유흥(遊興), 은둔(隱遁), 은신(隱身), 은폐(隱蔽), 음독(飮毒), 음미(吟味), 음복(飮福), 음차(音借), 응모(應募), 응용(應用), 응전(應戰), 응찰(應札), 이발(理髮), 이서(裏書), 이용(利用), 이탈(離脫), 인내(忍耐), 인멸(湮滅), 인쇄(印刷), 인조(人造), 인증(引證), 인책(引責), 인출(引出), 일, 일거수일투족(一擧手一投足), 일괄(一括), 일람(一覽), 일박(一泊), 일용(日用), 자생(自生), 자조(自助), 자행(恣行), 작위(作爲), 재림(再臨), 쟁기질, 정보보호(情報保護), 제비뽑기, 제웅(除雄), 조신(操身), 조업(操業), 조연(助演), 조절(調節), 조종(操縱), 졸음운전(__運轉), 종군(從軍), 종두(種痘), 종묘(種苗), 주공(主攻), 주도(主導), 주동(主動), 주무(主務), 주산(珠算), 주선(周旋), 주유(注油), 주재(主宰), 주정(酒酊), 주차(駐車), 주최(主催), 주해(註解), 준법(遵法), 준수(遵守), 중매(中媒|仲媒), 중재(仲裁), 중절(中絶), 중판(重版), 중흥(中興), 즉결(卽決), 즉사(卽死), 증정(增訂), 지시(指示), 지양(止揚), 지열(止熱), 지원(支援), 지장(支障), 지정(指定), 지참(持參), 지탱(支撑), 지향(指向), 지혈(止血), 직배(直配), 직역(直譯), 직영(直營), 직조(織造), 직할(直轄), 진격(進擊), 진료(診療), 진압(鎭壓), 진열(陳列), 질색(窒塞), 질주(疾走), 집결(集結), 집계(集計), 집도(執刀), 집무(執務), 집산(集散), 집약(集約), 집적(集積), 집정(執政), 짓, 징용(徵用), 징집(徵集), 차감(差減), 차광(遮光), 차명(借名), 차압(差押), 차출(差出), 착용(着用), 착의(着衣), 찬반(贊反), 찬조(贊助), 참견(參見), 참례(參禮), 참배(參拜), 참수(斬首), 참전(參戰), 참형(斬刑), 창달(暢達), 채굴(採掘), 채근(採根), 채비, 채식(菜食), 채집(採集), 책봉(冊封), 책정(策定), 처결(處決), 처단(處斷), 처리(處理), 처분(處分), 처사(處事), 처신(處身), 처우(處遇), 처참(處斬), 처치(處置), 천대(賤待), 청유(淸遊), 추가모집(追加募集), 추첨(抽籤), 측면지원(側面支援), 치다꺼리, 카드결제(card__), 캐스팅(casting), 타이핑(typing), 테스트(test), 투여(投與), 투입(投入), 투표(投票), 파마(permanent wave), 파종(播種), 판박이(版__), 편물(編物), 편승(便乘), 포석(布石), 포섭(包攝), 표기(表記), 표출(表出), 피서(避暑), 학문(學問), 한잔(_盞), 할복(割腹), 함구(緘口), 해산(解産), 해수욕(海水浴), 해장, 핸들링(handling), 행각(行脚), 행차(行次), 허밍(humming), 허송(虛送), 헤엄, 호강, 호색(好色), 호의호식(好衣好食), 혼방(混紡), 혼사(婚事), 화풀이(火__), 환대(歡待), 환속(還俗), 환영(歡迎), 활동(活動), 활쏘기, 활용(活用), 회부(回附), 회전(回轉), 획책(畵策), 흉내, 흡연(吸煙), 흡입(吸入), 흡혈(吸血), 흥행(興行), 희롱(戱弄), 희생(犧牲) </p>  (1) 몸짓 및 동작 : 신체의 움직임과 직접적인 관련이 있는 행위 <p class="message"> 가위질사위, 갈채(喝采), 개헤엄, 거동(擧動), 거수(擧手), 걷기, 걸음, 걸음마, 격파(擊破), 고갯짓, 공중던지기(空中___), 공중부양(空中浮揚), 광분(狂奔), 구르기, 구보(驅步), 구석차기, 급브레이크(急____), 급정거(急停車), 기립(起立), 기지개, 까치다리걸음, 깍지, 나비상놀음(__狀__), 난무(亂舞), 너털웃음, 널뛰기, 넓이뛰기, 노출(露出), 노크(knock), 놋다리밟기, 다이빙(diving), 달리기, 대성통곡(大聲痛哭), 도약(跳躍), 동작(動作), 드리블(dribble), 뜀뛰기, 리듬체조(rhythm__), 리시브(receive), 립싱크(lip sync), 매스게임(mass game), 면돌이(面__), 모두걸이, 목례(目禮), 몸놀림, 몸부림, 몸짓, 무도(舞蹈), 묵념(默念), 미끄럼, 미동(微動), 미소(微笑), 박수(拍手), 발걸음, 발돋움, 발짓, 배팅(batting), 번트(bunt), 범타(凡打), 보행(步行), 부채질, 블로킹(blocking), 비약(飛躍), 삽입(揷入), 삿대질, 선축(先蹴), 속보(速步), 손놀림, 손짓, 수상스키(水上__), 수선, 수음(手淫), 수평뜀(水平_), 숟갈질, 슛(shoot), 스매싱(smashing), 스윙(swing), 스크럼(scrum), 스텝(step), 스파이크(spike), 승부차기(勝負__), 시늉, 신음(呻吟), 실소(失笑), 심호흡(深呼吸), 안마(按摩), 앙감질, 애무(愛撫), 액션(action), 야투(野投), 양반걸음(兩班__), 양발제기(兩___), 양치, 얼음타기, 역투(力投), 연좌(連坐), 연화보좌(蓮花寶座), 오리걸음, 오열(嗚咽), 왕복달리기(往復___), 운신(運身), 울음, 울음보, 울음보따리, 웃음, 웃음보, 웃음보따리, 워킹(walking), 율동(律動), 응시(凝視), 인기척(人__), 일견(一見), 일소(一笑), 입놀림, 입덧, 입욕(入浴), 입질, 자필(自筆), 잔걸음, 잔기침, 재롱(才弄), 재주넘기, 재채기, 잽(jab), 점잔, 점프(jump), 접영(蝶泳), 정말체조(丁抹體操), 정색(正色), 정좌(正坐), 제기차기, 제스처(gesture), 조깅(jogging), 조준(照準), 종종걸음, 줄넘기, 줄달음질, 줄도망(_逃亡), 직립(直立), 짝짜꿍, 착석(着席), 체조(體操), 총총걸음, 춤, 칼춤, 코방귀, 코웃음, 콧바람, 콧방귀, 탄식(歎息), 탈춤, 태동(胎動), 태세(態勢), 투구변화(投球變化), 투신(投身), 투창(投槍), 투척(投擲), 파안일소(破顔一笑), 팔짱, 펀치(punch), 포복(匍匐), 포복절도(抱腹絶倒), 포옹(抱擁), 폭행(暴行), 하품, 합장(合掌), 햇볕바라기, 헛발질, 헤딩(heading), 헹가래, 호투(好投), 호흡(呼吸), 혼영(混泳), 홀딩(holding), 홈질, 활갯짓, 황소걸음, 휘파람, 흉식호흡(胸式呼吸) </p>  가. 대상성몸짓 <p class="message"> 큰절, 키스(kiss), 토스(toss), 투석(投石) </p>  (2) 이동행위 : 생물이나 무생물의 공간적인 이동을 전제로 하는 행위 <p class="message"> 가장행렬(假裝行列), 강림(降臨), 강제이주(强制移住), 강하(降下), 거북이걸음, 결집(結集), 곤두박질, 귀가(歸家), 귀경(歸京), 귀국(歸國), 귀대(歸隊), 귀성(歸省), 귀양, 귀의(歸依), 귀항(歸航), 귀향(歸鄕), 귀환(歸還), 금의환향(錦衣還鄕), 기항(寄港), 나들이, 낙하(落下), 낙향, 난입(亂入), 남진(南進), 남파(南派), 남하(南下), 남행(南行), 내방(來訪), 내한(來韓), 답파(踏破), 대피(待避), 도망(逃亡), 도일(渡日), 도피(逃避), 도하(渡河), 돌격(突擊), 돌입(突入), 돌진(突進), 동진(東進), 등교(登校), 등단(登壇), 등반(登攀), 등산(登山), 등정(登頂), 망명(亡命), 몽진(蒙塵), 미행(尾行), 밀항(密航), 방미(訪美), 배웅, 번개곤두, 변위(變位), 북벌(北伐), 북상(北上), 북진(北進), 사출(射出), 사택방문(私宅訪問), 산책(散策), 상경(上京), 서행(徐行), 소통(疏通), 소풍(消風), 손수운전(__運轉), 수출입(輸出入), 수학여행(修學旅行), 순환(循環), 승천(昇天), 시가행진(市街行進), 안방출장(_房出張), 야간도주(夜間逃走), 야반도주(夜半逃走), 왕래(往來), 왕복(往復), 외래(外來), 외유(外遊), 외출(外出), 우회(迂廻), 운구(運柩), 운반(運搬), 운송(運送), 운항(運航), 운행(運行), 원정(遠征), 원천징수(源泉徵收), 월남(越南), 월북(越北), 위문(慰問), 유목(遊牧), 육송(陸送), 이관(移管), 이동(移動), 이륙(離陸), 이민(移民), 이송(移送), 이주(移住), 이직(移職), 이첩(移牒), 인솔(引率), 입북(入北), 입산(入山), 입실(入室), 자진출두(自進出頭), 저공비행(低空飛行), 전근(轉勤), 전면주차(前面駐車), 전출(轉出), 전학(轉學), 조기유학(早期留學), 좌회전(左回轉), 주루(走壘), 주말여행(週末旅行), 직진(直進), 직행(直行), 진군(進軍), 진루(進壘), 진행(進行), 집합(集合), 참석(參席), 철군(撤軍), 철도여행(鐵道旅行), 철수(撤收), 초임(初任), 초행(初行), 추월(追越), 추진(推進), 출근(出勤), 출두(出頭), 출석(出席), 출소(出所), 출옥(出獄), 출입(出入), 출장(出張), 출정(出廷), 출타(出他), 출퇴근(出退勤), 취항(就航), 탈주(脫走), 탈출(脫出), 통과(通過), 통근(通勤), 통학(通學), 통행(通行), 퇴각(退却), 퇴거(退去), 퇴근(退勤), 퇴장(退場), 특파(特派), 파견(派遣), 포위(包圍), 피난(避難), 피란(避亂), 피신(避身), 피크닉(picnic), 하교(下校), 하산(下山), 하차(下車), 하행(下行), 항행(航行), 해외출장(海外出張), 행군(行軍), 행진(行進), 호송(護送), 환군(還軍), 환궁(還宮), 환도(還都), 환향(還鄕), 활강(滑降), 활공(滑空), 회군(回軍), 회유(回遊), 횡단(橫斷), 후송(後送), 후퇴(後退), 휴대(携帶) </p>  가. 탑승 <p class="message"> 기마(騎馬), 상선(上船), 탑승(搭乘) </p>  나. 하차 <p class="message"> 중도하차(中途下車), 하선(下船) </p>  다. 돌아다니기 <p class="message"> 가을나들이, 맴돌이, 방랑(放浪), 방황(彷徨), 배회(徘徊), 부랑(浮浪), 산보(散步), 산행(山行), 선회(旋回), 쇼핑(shopping), 순례(巡禮), 순방(巡訪), 순시(巡視), 순찰(巡察), 순항(巡航), 순회(巡廻), 여행(旅行), 연장운행(延長運行), 윤락, 음식기행(飮食紀行), 일소부재(一所不在), 일주(一周), 편력(遍歷), 표류(漂流), 하이킹(hiking), 해외탐방(海外探訪) </p>  라. 출발 <p class="message"> 발진(發進), 발차(發車), 연발(延發), 출격(出擊), 출국(出國), 출동(出動), 출발(出發), 출범(出帆), 출병(出兵), 출항(出航), 후발(後發) </p>  마. 도착 <p class="message"> 기착(寄着), 도달(到達), 도착(到着), 복귀(復歸), 부임(赴任), 상륙(上陸), 생환(生還), 선착(先着), 안착(安着), 연착(延着), 입항(入港), 착륙(着陸), 착지(着地), 표착(漂着) </p>  바. 접근 <p class="message"> 무료입장(無料入場), 위장전입(僞裝轉入), 입성(入城), 진입(進入), 충천(沖天), 침투(浸透) </p>  사. 사동적이동행위 <p class="message"> 계좌이체(計座移替), 급파(急派), 선적(船積), 소환(召喚), 연행(連行), 저수(貯水), 적재(積載), 조달(調達), 출어(出漁), 출하(出荷), 탑재(搭載), 투하(投下), 파병(派兵) </p> - 운반 <p class="message"> 밀반출(密搬出), 반출(搬出), 발송(發送), 봉송(奉送), 사건송치(事件送致), 송달(送達), 송환(送還), 수송(輸送), 압송(押送), 우편배달(郵便配達), 이체(移替), 입고(入庫), 전달(傳達), 출상(出喪) </p> - 배치 <p class="message"> 배열(排列), 병치(倂置), 열거(列擧), 투기(投棄), 포진(布陳) </p>  (3) 지속적 활동 : 일정한 시간동안 이루어지는 행위 <p class="message"> 가업(家業), 가을걷이, 간직, 감리(監理), 감옥생활(監獄生活), 감호(監護), 강습(講習), 강학(講學), 개인활동(個人活動), 개표(開票), 거류(居留), 건가래질(乾___), 건강관리(健康管理), 건사, 건설(建設), 건축(建築), 건투(健鬪), 검문(檢問), 검색(檢索), 검수(檢數), 검시(檢屍), 검안(檢眼), 검약(儉約), 검열(檢閱), 검진(檢診), 검표(檢票), 게임(game), 겨울스포츠(__sports), 결혼생활(結婚生活), 겸업(兼業), 겸임(兼任), 겸직(兼職), 경비(警備), 경선매매(徑先賣買), 경세(經世), 경신(更新), 경원(敬遠), 경정(更正), 경제활동(經濟活動), 계가(計家), 계단갈이(階段__), 계단경작(階段耕作), 계도(啓導), 계류(繫留), 계선(繫船), 계좌추적(計座追跡), 계측(計測), 계투(繼投), 고과(考課), 고교교육(高校敎育), 고구(考究), 고기잡이, 고리대금(高利貸金), 고막매질, 고학(苦學), 고행(苦行), 공납(公納), 공동연구(共同硏究), 공략(攻掠), 공매(公賣), 공모(公募), 공보(公報), 공역(共譯), 공용(共用), 공익근무(公益勤務), 공일(空_), 공저(共著), 공존(共存), 공중보건(公衆保健), 공천심사(公薦審査), 공편(共編), 과식(過食), 과점(寡占), 관람(觀覽), 관리감독(管理監督), 관망(觀望), 관전(觀戰), 관조(觀照), 관찰(觀察), 광고방송(廣告放送), 교육(敎育), 교통통제(交通統制), 구급수술(救急手術), 구독(購讀), 구명운동(救命運動), 구조조정(構造調整), 국고보조(國庫補助), 국방(國防), 국역(國譯), 국정(國政), 국정감사(國政監査), 국정관리(國政管理), 국제무역(國際貿易), 군림(君臨), 군부독재(軍部獨裁), 군사독재(軍事獨裁), 군사작전(軍事作戰), 군정(軍政), 굴착(掘鑿), 규합(糾合), 근속(勤續), 근신(謹愼), 글짓기, 금연운동(禁煙運動), 기거(起居), 기름칠(__漆), 기숙(寄宿), 기식(寄食), 기업광고(企業廣告), 기초공사(基礎工事), 기초관리(基礎管理), 기행(紀行), 긴급수술(緊急手術), 길거리전도(___傳道), 길쌈, 김매기, 김장, 꿈, 끽연(喫煙), 낙선운동(落選運動), 날씨관측(__觀測), 날품팔이, 남녀차별(男女差別), 납땜, 낭독(朗讀), 낭송(朗誦), 낮잠, 내근(內勤), 내부감사(內部監査), 내사(內査), 내조(內助), 냉난방(冷暖房), 노동운동(勞動運動), 노래, 노조활동(勞組活動), 녹취(錄取), 녹화(錄畵), 놀음, 놀이, 농경(農耕), 농성(籠城), 농작(農作), 눈치작전(__作戰), 늦공부(_工夫), 다듬질, 다리품, 다이어트(diet), 단련(鍛鍊), 단식(斷食), 단식농성(斷食籠城), 단체활동(團體活動), 단체훈련(團體訓鍊), 단풍놀이(丹楓__), 대체복무(代替服務), 도매업(都賣業), 도박(賭博), 도보(徒步), 도시계획(都市計劃), 도시생활(都市生活), 도야(陶冶), 도청(盜聽), 독립운동(獨立運動), 독서(讀書), 독습(獨習), 독재(獨裁), 독점(獨占), 독학(獨學), 동면(冬眠), 디스코(disco), 레저(leisure), 로비활동(lobby__), 로케이션(location), 리드(lead), 마약복용(痲藥服用), 만학(晩學), 말글살이, 말글운동(__運動), 메이크업(makeup), 면학(勉學), 면회(面會), 멸균(滅菌), 모금운동(募金運動), 모금행사(募金行事), 모금활동(募金活動), 모내기, 모델링(modelling), 모심기, 모조(模造), 모집(募集), 모집광고(募集廣告), 목공(木工), 목욕(沐浴), 목축(牧畜), 몰두(沒頭), 몸가짐, 몸가축, 몸조심(_操心), 못정떨이, 무논갈이, 무상지원(無償支援), 무장투쟁(武裝鬪爭), 묵도(默禱), 문단속(門團束), 문대령(門待令), 문안시선(問安視膳), 문쥐놀음, 문초(問招), 문화공연(文化公演), 물갈이, 물리치료(物理治療), 물매잡기, 물장난, 미용(美容), 미화(美化), 민사소송(民事訴訟), 민족운동(民族運動), 민주항쟁(民主抗爭), 민중운동(民衆運動), 민중항쟁(民衆抗爭), 밀실정치(密室政治), 밀실행정(密室行政), 바느질, 바둑, 바람몰이, 반대시위(反對示威), 반미시위(反美示威), 반미운동(反美運動), 반미집회(反美集會), 반복학습(反復學習), 반전운동(反戰運動), 반주(伴奏), 반추(反芻), 발호(跋扈), 밤샘, 밤샘농성(_籠城), 밤잠, 방류(放流), 방문(訪問), 방범(防犯), 방비(防備), 방사(放飼), 방송(放送), 방어(防禦), 방영(放映), 방일(放逸), 방적(紡積), 방제(防除), 방직(紡織), 방청(傍聽), 방충(防蟲), 방풍(防風), 방해(妨害), 배너광고(banner__), 배선(配線), 배수(配水), 배영(背泳), 배포(配布), 백업(back-up), 번(番), 벌목(伐木), 벌이, 벌채(伐採), 벌초(伐草), 범죄예방(犯罪豫防), 법정관리(法定管理), 법치(法治), 변역(變易), 변주(變奏), 병간호(病看護), 병구원(病救援), 병작(竝作), 보건(保健), 보건교육(保健敎育), 보관(保管), 보급(普及), 보디빌딩(bodybuilding), 보선(保線), 보수정치(保守政治), 보안(保安), 보양(保養), 보온(保溫), 보완(補完), 보위(保衛), 보유(保有), 보육(保育), 보이콧(boycott), 보장(保障), 보전(保全), 보조(補助), 보존(保存), 보좌(補佐), 보충수업(補充授業), 보탬, 보필(輔弼), 보호(保護), 복무(服務), 복사(複寫), 복습(復習), 복역(服役), 복제(複製), 복토(覆土), 볶음, 볼링(bowling), 봄꿈, 봉사활동(奉仕活動), 봉양(奉養), 봉직(奉職), 봉창(奉唱), 부검(剖檢), 부양(扶養), 부업(副業), 분류(分類), 분무(噴霧), 분사(噴射), 분산(分散), 분전(奮戰), 분투(奮鬪), 비디오텍스(videotex), 비즈니스(business), 비질, 비축(備蓄), 사교(社交), 사대(事大), 사대교린(事大交隣), 사례연구(事例硏究), 사무(事務), 사숙(私淑), 사열(査閱), 사육(飼育), 사전답사(事前踏査), 사회봉사(司會奉仕), 살림, 살림살이, 상근(常勤), 상업광고(商業廣告), 상업방송(商業放送), 상연(上演), 상영(上映), 상임(常任), 색칠(色漆), 생활(生活), 선거운동(選擧運動), 섭정(攝政), 성생활(性生活), 세상살이(世上__), 세일(sale), 셋방살이(貰房__), 소매상(小賣商), 소유(所有), 소일(消日), 소작(小作), 쇼트트랙(short track), 수감생활(收監生活), 수강(受講), 수건돌리기(手巾___), 수상측량(水上測量), 수색(搜索), 수소문(搜所聞), 수신업무(受信業務), 수절(守節), 수행(修行), 수험(受驗), 수형(受刑), 숙면(熟眠), 스케일링(scaling), 스포츠(sports), 습성찜질(濕性__), 시찰(視察), 시판(市販), 식민지배(植民支配), 식민통치(植民統治), 식사(食事), 신문구독(新聞購讀), 신분보장(身分保障), 신선놀음(神仙__), 신앙생활(信仰生活), 신탁통치(信託統治), 신혼살림(新婚__), 실사구시(實事求是), 실생활(實生活), 실습(實習), 실측(實測), 심령연구(心靈硏究), 심부름, 심심파적(__破寂), 쌍지게질(雙___), 안배(按排), 안식(安息), 암약(暗躍), 암중비약(暗中飛躍), 암행(暗行), 애독(愛讀), 애완(愛玩), 애용(愛用), 애장(愛藏), 애창(愛唱), 야생(野生), 야영(野營), 양계(養鷄), 양돈(養豚), 양봉(養蜂), 양육(養育), 양잠(養蠶), 양재(洋裁), 양호(養護), 어로(魚撈), 어학연수(語學硏修), 언론플레이(言論___), 엄선(嚴選), 에스코트(escort), 여기(餘技), 여성차별(女性差別), 여행안내(旅行案內), 연구(硏究), 연날리기(鳶___), 연명(延命), 연수(硏修), 연습(練習), 연애(戀愛), 연애질(戀愛_), 연예(演藝), 연재(連載), 연주(演奏), 연출(演出), 연희(演戱), 열람(閱覽), 염(殮), 염습(殮襲), 엽기(獵寄), 영위(營爲), 영재교육(英才敎育), 예산심의(豫算審議), 예습(豫習), 예심(豫審), 예의주시(銳意注視), 예행연습(豫行演習), 오락(娛樂), 오목(五目), 오찬(午餐), 옥바라지(獄___), 옥살이(獄__), 온천욕(溫泉浴), 왕진(往診), 왜정(倭政), 외줄낚시, 요리(料理), 용달(用達), 우유도일(優遊度日), 운동(運動), 운영(運營), 운용(運用), 운전(運轉), 월동(越冬), 위탁급식(委託給食), 유랑(流浪), 유신(維新), 유영(游泳), 유학(留學), 유희(遊戱), 육성(育成), 육식(肉食), 육아(育兒), 은거(隱居), 은행부기(銀行簿記), 음악방송(音樂放送), 음악치료(音樂治療), 음주단속(飮酒團束), 음풍농월(吟風弄月), 응급조치(應急措置), 응급처치(應急處置), 응원(應援), 응접(應接), 의료봉사(醫療奉仕), 의료서비스(醫療___), 의무사용(義務使用), 의정감시(議政監視), 의정활동(議政活動), 이동서비스(移動___), 이웃돕기, 인권보장(人權保障), 인권보호(人權保護), 인사관리(人事管理), 인사행정(人士行政), 인성교육(人性敎育), 일간(日刊), 일간풍월(一竿風月), 일광욕(日光浴), 일부종사(一夫從事), 임상(臨床), 입원치료(入院治療), 자급자족(自給自足), 자기경영(自己經營), 자기관리(自己管理), 자녀양육(子女養育), 자력갱생(自力更生), 자산관리(資産管理), 자선사업(慈善事業), 자습(自習), 자식교육(子息敎育), 자영(自營), 자원봉사(自願奉仕), 자율학습(自律學習), 작도(作圖), 작업(作業), 잔손질, 잔칼질, 잠복(潛伏), 잠수(潛水), 장난, 장애체험(障碍體驗), 장학(奬學), 재건(再建), 재봉(裁縫), 재수(再修), 재위(在位), 재직(在職), 재학(在學), 저널리즘(journalism), 저녁식사(__食事), 전공(專攻), 전문교육(專門敎育), 전업투자(專業投資), 전인교육(全人敎育), 전지훈련(轉地訓鍊), 전희(前戱), 절개수술(切開手術), 절식(絶食), 절차탁마(切磋琢磨), 점심식사(__食事), 정리(整理), 정무(政務), 정벌칠(正__), 정보활동(情報活動), 제설(除雪), 제염(製鹽), 제초(除草), 제화(製靴), 조경(造景), 조기재배(早期栽培), 조련(調鍊), 조판(組版), 조폐(造幣), 종사(從事), 종업(從業), 좌선(坐禪), 좌욕(坐浴), 주거(住居), 주경야독(晝耕夜讀), 주민생활(住民生活), 주번(週番), 주식투자(株式投資), 주업(主業), 주행(走行), 준법투쟁(遵法鬪爭), 준비(準備), 중개(仲介), 중등교육(中等敎育), 중벌매기(重___), 중앙집사(中央集査), 증권거래(證券去來), 증권투자(證券投資), 지방자치(地方自治), 지배(支配), 지진탐사(地震探査), 진맥(診脈), 진상규명(眞相糾明), 진상조사(眞相調査), 진찰(診察), 집안닦달, 집안살림, 집중탐구(集中探究), 차단(遮斷), 차별(差別), 참가(參加), 참선(參禪), 참여(參與), 채금(採金), 채석(採石), 채점(採點), 채취(採取), 책읽기, 철야(徹夜), 첩보활동(諜報活動), 청소(淸掃), 청춘사업(靑春事業), 체류(滯留), 체질검사(體質檢査), 체질진단(體質診斷), 체험(體驗), 초식(草食), 초음파시험(超音波試驗), 추수(秋水), 춘경(春耕), 출강(出講), 출구조사(出口調査), 출연(出演), 취미생활(趣味生活), 측도(測度), 측량(測量), 치국(治國), 치료(治療), 치성(致誠), 치세(治世), 치유(治癒), 치장(治粧), 친정살이(親庭__), 침묵(沈默), 침묵시위(沈默示威), 칼잠, 캠핑(camping), 커트(cut), 타작(打作), 타진(打診), 탈곡(脫穀), 탐구(探究), 탐독(耽讀), 탐방(探訪), 탐사(探査), 탐색(探索), 탐험(探險), 태교(胎敎), 태업(怠業), 토목(土木), 토벌(討伐), 토성조사(土性調査), 통곡(痛哭), 통독(通讀), 통신서비스(通信___), 통용(通用), 통탄(痛歎), 투병(鬪病), 투쟁(鬪爭), 트레이닝(training), 특근(特勤), 특진(特診), 특활(特活), 파수(把守), 포커(poker), 폭정(暴政), 피구(避球), 피임(避姙), 필기(筆記), 핑퐁(ping pong), 학구(學究), 학업(學業), 한잠, 함양(涵養), 항속(航續), 항해(航海), 해안경비(海岸警備), 해양개발(海洋開發), 향유(享有), 헌정(憲政), 현장답사(現場踏査), 현장체험(現場體驗), 현지답사(現地踏査), 협력플레이(協力___), 호구조사(戶口調査), 호위(護衛), 호화쇼핑(豪華__), 활보(闊步), 활약(活躍), 회식(會食), 후대(厚待), 후속(後續), 후술(後述), 훈련(訓練), 훈육(訓育), 휴식(休息), 휴양(休養) </p>  가. 일 <p class="message"> 가사노동(家事勞動), 간척사업(干拓事業), 격무(激務), 고시공부(考試工夫), 고액과외(高額課外), 공무수행(公務遂行), 공무집행(公務執行), 공직생활(公職生活), 관련사업(關聯事業), 광고마케팅(廣告___), 교대근무(交代勤務), 교도행정(敎導行政), 교육활동(敎育活動), 구태정치(舊態政治), 국무(國務), 군무(軍務), 근로(勤勞), 근무(勤務), 급무(急務), 내무(內務), 노동(勞動), 노력(努力), 노릇, 노역(勞役), 누비, 당무(黨務), 당번(當番), 당직(當直), 당직근무(當直勤務), 대북사업(對北事業), 대필(代筆), 대행(代行), 도강(盜講), 도금(鍍金), 레슨(lesson), 마케팅(marketing), 막일, 만사(萬事), 목회(牧會), 무료진료(無料診療), 방문서비스(訪問___), 방학숙제(放學宿題), 법률서비스(法律___), 법무(法務), 볼일, 부실경영(不實經營), 사령(司令), 세무(稅務), 소관(所官), 수고, 수속(手續), 숙직(宿直), 시범사업(示範事業), 시집살이(媤___), 신용업무(信用業務), 아르바이트(Arbeit), 애프터서비스(after service), 야근(夜勤), 업무(業務), 영농(營農), 영업(營業), 외무(外務), 원격근무(遠隔勤務), 위탁판매(委託販賣), 윤리경영(倫理經營), 음성정보서비스(音聲情報___), 응급진료(應急診療), 응급치료(應急治療), 잔무(殘務), 잔업(殘業), 잔일, 잡무(雜務), 장사, 재무(財務), 재무분석(財務分析), 전자상거래(電子商去來), 정상영업(正常營業), 조역(助役), 족벌경영(族閥經營), 중개무역(仲介貿易), 중노동(重勞動), 직무수행(職務遂行), 철야근무(徹夜勤務), 철야업무(徹夜業務), 체질, 초과근무(超過勤務), 초동수사(初動搜査), 취재활동(取材活動), 프로그래밍(programming), 하역(荷役), 항소심(抗訴審), 행상(行商), 형무(刑務), 회칠(灰漆) </p>  나. 체류 <p class="message"> 노숙(露宿), 민박(民泊), 숙박(宿泊), 숙식(宿食), 안주(安住), 영어생활(囹圄生活), 영외거주(營外居住), 잔류(殘留), 재경(在京), 점거(占據), 정거(停車), 정류(停留), 정박(渟泊), 정주(定住), 정지(停止), 정착(定着), 주둔(駐屯), 징역살이(懲役__), 처가살이(妻家__), 체공(滯空), 칩거(蟄居), 타향살이(他鄕__), 투숙(投宿), 하숙(下宿), 휴거(休居) </p>  (4) 결과행위 : 결과의 내용에 따라 규정되는 행위 <p class="message"> 가결(可決), 가능성(可能性), 가름, 가위다리양자(____養子), 가정교육(家庭敎育), 가중(加重), 각혈(<U+54AF>血), 감군(減軍), 감등(減等), 감봉(減俸), 감세(減稅), 감속(減速), 감식(鑑識), 감압(減壓), 감액(減額), 감원(減員), 감형(減刑), 강등(降等), 개문(開門), 개변(改變), 개비(改備), 개식(開式), 개신(改新), 개작(改作), 개장(開場), 개점(開店), 개제(改題), 개종(改宗), 개축(改築), 개폐(改廢), 개혁(改革), 갱신(更新), 거리녹음(__錄音), 거세(去勢), 건군(建軍), 검거(檢擧), 검출(檢出), 격리(隔離), 격추(擊墜), 격퇴(擊退), 격화(激化), 결성(結成), 결시(缺試), 결장(缺場), 결항(缺航), 겹간통(_間通), 고등훈련(古等訓練), 고용승계(雇用承繼), 골인(goal in), 과반득표(過半得票), 과용(過用), 관통(貫通), 교란(攪亂), 구국(救國), 구성(構成), 구획(區劃), 굴복(屈服), 귀결(歸結), 귀착(歸着), 귀화(歸化), 극기(克己), 극복(克服), 금단(禁斷), 급매(急賣), 기각(棄却), 기권(棄權), 나열(羅列), 낙전(樂戰), 낙찰(落札), 낙태(落胎), 날염(捺染), 낭비(浪費), 냉각(冷却), 논증(論證), 누락(漏落), 다작(多作), 대과(大過), 도치(倒置), 독파(讀破), 둔갑(遁甲), 득도(得道), 득음(得音), 득표(得票), 등극(登極), 등분(等分), 등용(登用|登庸), 마취(麻醉), 만회(挽回), 말소등기(抹消登記), 매국(賣國), 매립(埋立), 매수합병(買收合竝), 매장(埋葬), 매혹(魅惑), 면제(免除), 면직(免職), 무조건항복(無條件降伏), 무혈(無血), 미백, 미불(未拂), 미수(未遂), 믹스(mix), 민족통일(民族統一), 박탈(剝奪), 박피(剝皮), 반분(半分), 반숙(半熟), 발간(發刊), 발주(發注), 발탁(拔擢), 발행(發行), 방수(防水), 방음(防音), 방지(防止), 방진(防塵), 방탄(防彈), 배격(排擊), 배석(陪席), 배아복제(胚芽複製), 배점(配點), 배정(配定), 배차(配車), 배출(排出), 배치(配置), 배태(胚胎), 버림, 벽돌포장(U+7513;_鋪裝), 별첨(別添), 보결(補缺), 보궐(補闕), 보궐선거(補闕選擧), 보리가을, 보리마당질, 보신(保身), 복교(復校), 복면(覆面), 복상사(腹上死), 복속, 복적(復籍), 복직(復職), 복토도둑질(福土___), 봉합(縫合), 부결(否決), 부과(賦課), 부담(負擔), 부실공사(不實工事), 부착(附着), 분가(分家), 분권(分權), 분단(分斷), 분당(分黨), 분리(分離), 분립(分立), 분만(分娩), 분세수(粉洗手), 분식회계(粉飾會計), 분열(分裂), 분할(分割), 분해(分解), 불법화(不法化), 불완전취업(不完全就業), 불참(不參), 불충(不忠), 사면복권(赦免復權), 사우나(sauna), 사전예방(事前豫防), 사치(奢侈), 사퇴(辭退), 사후처리(事後處理), 삭발(削髮), 삭탈(削奪), 산아(産兒), 산회(散會), 삼분(三分), 삼분손일(三分損一), 삼선(三選), 상설(常設), 색인(索引), 생계유지(生計維持), 샤워(shower), 서명(署名), 서명날인(署名捺印), 서사(敍事), 석방(釋放), 선거(選擧), 선결(先決), 선도(先導), 선동(煽動), 선문(選文), 선발(選拔), 선방(善防), 선별(選別), 선양(宣揚), 선용(善用), 선정(選定), 선처(善處), 선출(選出), 선택(選擇), 설거지, 설욕(雪辱), 설정(設定), 섭외(涉外), 성격묘사(性格描寫), 성인방송(成人放送), 세뇌(洗腦), 세로쓰기, 세면(洗面), 세발(洗髮), 세수(洗手), 세안(洗顔), 세차(洗車), 세척(洗滌), 세탁(洗濯), 소득공제(所得控除), 소등(消燈), 소모(消耗), 소비(消費), 소송(訴訟), 소요(所要), 소제(掃除), 소집(召集), 소행(所行), 소화(消化), 속공(速攻), 속기(速記), 속사(速射), 속죄(贖罪), 속행(速行), 솔로(solo), 솔선(率先), 쇄국(鎖國), 수공(手工), 수권(受權), 수련(修鍊), 수록(收錄), 수비(守備), 수양(修養), 수장(水葬), 수합(收合), 수호(守護), 숙달(熟達), 숙련(熟練), 순산(順産), 스카우트(scout), 스크랩(scrap), 승낙(承諾), 승전(勝戰), 신상공개(身上公開), 신승(辛勝), 신장이식(腎臟移植), 실행(實行), 심각(深刻), 싹쓸이, 앞가림, 양단(兩斷), 양분(兩分), 엄폐(掩蔽), 여과(濾過), 역술(譯述), 역임(歷任), 역전승(逆轉勝), 연결(連結), 연계(連繫), 연마(硏磨), 연승(連勝), 연전연승(連戰連勝), 연전연패(連戰連敗), 연패(連敗), 염색(染色), 염소화처리(鹽素化處理), 염장(鹽藏), 영역(英譯), 영입(迎入), 예입(預入), 예치(預置), 예탁(預託), 오진(誤診), 옹립(擁立), 와전(訛傳), 완봉(完封), 완비(完備), 완역(完譯), 완전무장(完全武裝), 완주(完走), 완충(緩衝), 완투(完投), 완화(緩和), 외상, 외자유치( 外資誘致), 용도변경(用途變更), 용해(溶解), 웅비(雄飛), 원서접수(願書接受), 원정출산(遠征出産), 위헌판결(違憲判決), 유예신청(猶豫申請), 유치(誘致), 유폐(幽閉), 육아휴직(育兒休職), 음주측정(飮酒測定), 이간(離間), 이바지, 이임(離任), 이행(履行), 익반죽, 인간복제(人間服制), 인명구조(人命救助), 인민해방(人民解放), 인사개입(人士介入), 인수(引受), 인수분해(因數分解), 인준(認准), 인하(引下), 일괄타결(一括妥結), 일망타진(一網打盡), 일일체험(一日體驗), 일탈(逸脫), 일필휘지(一筆揮之), 임관(任官), 임기응변(臨機應變), 임명(任命), 임시방편(臨時方便), 임시변통(臨時變通), 임용(任用), 임전무퇴(臨戰無退), 입국(入局), 입금(入金), 입도선매(立稻先賣), 입력(入力), 입법(立法), 입법예고(立法豫告), 입신(立身), 입안(立案), 입양(入養), 입찰(入札), 잉태(孕胎), 자결(自決), 자금조달(資金調達), 자급(自給), 자동번역(自動飜譯), 자료수집(資料蒐集), 자립(自立), 자멸(自滅), 자수(自首), 자원(自願), 자율규제(自律規制), 자율편성(自律編成), 자진(自進), 자진납부(自進納付), 자진납세(自進納稅), 자진사퇴(自進辭退), 자초(自招), 자치(自治), 잠입(潛入), 잠적(潛跡), 장거리봉쇄(長距離封鎖), 장려(奬勵), 장만, 장악(掌握), 장전(裝塡), 장착(裝着), 장타(長打), 장해(障害), 재구(再構), 재기(再起), 재발(再發), 재산가압류(財産假押留), 재생(再生), 재연(再演), 재현(再現), 저금(貯金), 저당(抵當), 저장(貯藏), 저축(貯蓄), 적발(摘發), 적용(適用), 적응(適應), 전담(全擔), 전매(專賣), 전면통제(全面統制), 전송(餞送), 전수(傳受), 전시(展示), 전입(轉入), 전자집속(電子集束), 전족(纏足), 전진(前進), 전향(轉向), 전환(轉換), 전후점령(戰後占領), 절교(絶交), 절단(切斷), 절세(節稅), 절수(節水), 절약(節約), 절전(節電), 절제(節制), 점등(點燈), 점령(占領), 점유(占有), 점화(點火), 접(接), 접객(接客), 접견(接見), 접대(接待), 접붙이기(接___), 접속(接續), 접지(摺紙), 접착(接着), 접합(接合), 정당공천(政黨公薦), 정돈(整頓), 정련(精鍊), 정렬(整列), 정립(正立), 정비(整備), 정선(停船), 정제(精製), 제대(除隊), 제련(製鍊), 제명(除名), 제본(製本), 제왕절개(帝王切開), 조산(早産), 조율(調律), 조조할인(早朝割引), 조퇴(早退), 조형(造形), 졸업(卒業), 종다수(從多數), 종별(種別), 좌천(左遷), 주민등록(住民登錄), 주파(走破), 준공(竣工), 중건(重建), 중략(中略), 중역(重譯), 중첩(重疊), 지출(支出), 진학(進學), 집권(執權), 집필(執筆), 집하(集荷), 집행(執行), 징발(徵發), 징병(徵兵), 징세(徵稅), 징수(徵收), 짜깁기, 차별행위(差別行爲), 차지, 채용(採用), 채택(採擇), 처방(處方), 체포(逮捕), 체현(體現), 총사퇴(總辭退), 총칭(總稱), 최종합격(最終合格), 출결(出缺), 탄착(彈着), 통타(痛打), 통폐합(統廢合), 통화개혁(通貨改革), 통화수축(通貨收縮), 투신자살(投身自殺), 판결(判決), 편성(編成), 편수(編修), 평정(平定), 폐교(廢校), 폐기(廢棄), 폐쇄(閉鎖), 표준화(標準化), 한정(限定), 함락(陷落), 합당(合黨), 합방(合邦), 해고(解雇), 해방(解放), 해석(解釋), 해제(解除), 해지(解止), 해후(邂逅), 허비(虛費), 헛걸음, 헛수고, 헛일, 혁신(革新), 형성(形成), 확장재생산(擴張再生産), 확증(確證), 후불(後佛), 훈방(訓放), 훈제(燻製), 훼손(毁損), 휴무(休務), 휴업(休業), 휴정(休廷), 휴직(休職), 휴학(休學), 휴회(休會), 흥기(興起), 희석(稀釋) </p>  가. 창조행위 <p class="message"> 건설공사(建設工事), 구축(構築), 구현(具現|具顯), 극화(劇化), 기술개발(技術開發), 기초설계(基礎設計), 등사(謄寫), 마련, 발견(發見), 발굴(發掘), 발권(發券), 발명(發明), 병설(竝設), 부설(附設), 산유(産油), 생명복제(生命複製), 생산(生産), 설계(設計), 설립(設立), 설치(設置), 성책(成冊), 세공(細工), 소조(塑造), 수립(樹立), 신축(新築), 안무(按舞), 양조(釀造), 연작(聯作), 영작(英作), 이름짓기, 입헌(立憲), 자작(自作), 작곡(作曲), 작명(作名), 작사(作詞), 작성(作成), 작시(作詩), 저작(著作), 제과(製菓), 제당(製糖), 제분(製粉), 제작(製作), 제정(制定), 제조(製造), 제헌(制憲), 조립(組立), 조성(造成), 조영(造營), 조제(調劑), 종이접기, 창간(創刊), 창건(創建), 창단(創團), 창당(創黨), 창립(創立), 창설(創設), 창시(創始), 창업(創業), 창작(創作), 창제(創製), 창조(創造), 창출(創出), 처녀출판(處女出版), 촬영(撮影), 축조(築造), 출간(出刊), 출산(出産), 출판(出版), 취사(炊事), 취입(吹入), 친서(親書), 탁본(拓本), 특허신청(特許申請), 특허취득(特許取得), 편저(編著), 편찬(編纂), 휘호(揮毫) </p>  나. 파괴행위 <p class="message"> 가정파탄(家庭破綻), 격멸(擊滅), 격침(擊沈), 공중폭파(空中暴破), 궤멸(潰滅), 근절(根絶), 말살(抹殺), 몰사(沒死), 몰살(沒殺), 무장해제(武裝解除), 박멸(搏滅), 발파(發破), 병살(倂殺), 부패척결(腐敗剔抉), 분쇄(粉碎), 불식(拂拭), 사멸(死滅), 삭제(削除), 살균(殺菌), 살생(殺生), 살충(殺蟲), 상실(喪失), 섬멸(殲滅), 소각(燒却), 소거(消去), 소독(消毒), 소방(消防), 소염(消炎), 소탕(掃蕩), 손상(損傷), 숙청(肅淸), 원천봉쇄(源泉封鎖), 자연훼손(自然毁損), 정벌(征伐), 제거(除去), 직장폐쇄(職場閉鎖), 집단폐업(集團廢業), 차별철폐(差別撤廢), 척결(剔抉), 철거(撤去), 철회(撤回), 탈취(脫臭), 파괴(破壞), 파기(破棄), 파멸(破滅), 파선(破船), 파손(破損), 파열(破裂), 파직(罷職), 패가(敗家), 폐간(廢刊), 폐비(廢妃), 폐위(廢位), 폐지(廢止), 폐차(廢車), 폭격(爆擊), 폭파(爆破), 해약(解約), 해체(解體) </p>  다. 종료행위 <p class="message"> 결제(決濟), 결판(決判), 낙착(落着), 내부결재(內部決裁), 단산(斷産), 마무리, 만료(滿了), 변제(辨濟), 봉쇄(封鎖), 사임(辭任), 성취(成就), 수료(修了), 예방접종(豫防接種), 예산집행(豫算執行), 예산편성(豫算編成), 예산확보(豫算確保), 완결(完結), 완공(完工), 완납(完納), 완료(完了), 완성(完成), 완수(完遂), 완치(完治), 은퇴(隱退), 일단락(一段落), 종결(終結), 종료(終了), 종착(終着), 중도상환(中途償還), 중도해지(中途解止), 집대성(集大成), 차별금지(差別禁止), 찬성투표(贊成投票), 체념(諦念), 총괄(總括), 총살(銃殺), 총집(叢集), 최종낙찰(最終落札), 추출(抽出), 출감(出監), 출금(出金), 출토(出土), 충족(充足), 취득(取得), 취하(取下), 취합(聚合), 측정(測定), 타개(打開), 타결(妥結), 탈고(脫稿), 통치(通治), 통합(統合), 투명(投命), 파경(破鏡), 패소(敗訴), 평결(評決), 폐관(閉館), 폐막(閉幕), 폐문(閉門), 폐업(閉業), 폐장(閉場), 폐점(閉店), 폐정(閉廷), 폐회(閉會), 필승(必勝), 해결(解決), 확립(確立) </p>  라. 중단행위 <p class="message"> 금식(禁食), 금연(禁煙), 금욕(禁慾), 전폐(全廢), 절연(絶緣), 절필(絶筆), 정간(停刊), 정차(停車), 제동(制動), 중간생략(中間省略), 중단(中斷), 중지(中止), 중퇴(中退), 철병(撤兵), 철시(撤市), 철폐(撤廢), 취소(取消), 퇴진(退陣), 휴간(休刊), 휴강(休講), 휴교(休校) </p>  마. 개시행위 <p class="message"> 개강(開講), 개항(開港), 개회(開會), 발매(發賣), 방출(放出), 봉기(蜂起), 속개(續開), 신장개업(新裝開業), 재개(再開), 전면개방(全面開放), 지명수배(指名手配), 착공(着工), 착수(着手), 처녀비행(處女飛行), 처녀항해(處女航海), 첫걸음, 체결(締結), 추대(推戴), 출고(出庫), 출군(出軍), 출마(出馬), 출생(出生), 출제(出題), 출현(出現), 취업(就業), 취임(就任), 취직(就職), 취학(就學) </p>  바. 증가행위 <p class="message"> 공동배양(共同培養), 누증(累增), 누진(累進), 배가(倍加), 부가(附加), 승격(昇格), 승단(昇段), 임금인상(賃金引上), 적립(積立), 증강(增强), 증설(增設), 증축(增築), 첨가(添加), 첨부(添附), 추가(追加), 축재(蓄財), 축적(蓄積), 확대(廓大), 확장(擴張) </p>  사. 감소행위 <p class="message"> 감량(減量), 결원(缺員), 군축(軍縮), 규제완화(規制緩化), 금리인하(金利引下), 긴축(緊縮), 삭감(削減), 생략(省略), 압축(壓縮), 조세감면(租稅減免), 축객(逐客), 축소(縮小), 축약(縮約), 축지(縮地), 탈색(脫色), 탈수(脫水), 탈피(脫皮), 탕감(蕩減), 탕진(蕩盡), 퇴보(退步), 퇴조(退潮), 평가절하(平價切下), 할인(割引), 후략(後略) </p>  아. 변형행위 <p class="message"> 개각(改閣), 개헌(改憲), 갱생(更生), 고용조정(雇傭調整), 교육개혁(敎育改革), 구조개혁(構造改革), 궤도수정(軌道修正), 땜, 번안(飜案), 번역(飜譯), 변신(變身), 변장(變裝), 변조(變造), 변혁(變革), 변형(變形), 보충(補充), 복개(覆蓋), 복구(復舊), 복원(復元), 복학(復學), 분기(分岐), 분장(扮裝), 블록설정(block__), 사회개혁(社會改革), 성형(成形), 성형수술(成形手術), 세대교체(世代交替), 손질, 쇄신(刷新), 수습(收拾), 순응(順應), 순화(純化), 여장(女裝), 왜곡(歪曲), 응급복구(應急復舊), 의료개혁(醫療改革), 재벌개혁(財閥改革), 재편(再編), 재활용(再活用), 전면개편(全面改編), 조작(造作), 종교개혁(宗敎改革), 지방흡입(脂肪吸入), 착색(着色), 첨삭(添削), 초교(初校), 초역(抄譯), 통역(通譯), 파격(破格), 편곡(編曲), 표구(表具), 표백(表白), 혁진(革進) </p>  자. 장식행위 <p class="message"> 겉치장(_治粧), 단장(丹粧), 디스플레이(display), 수식(修飾), 장식(粧飾), 칠(漆), 코팅(coating), 화장(化粧) </p>  차. 포장행위  카. 가입 <p class="message"> 고입(高入), 기여입학(寄與入學), 노조가입(勞組加入), 입교(入校), 입단(入團), 입당(入黨), 입대(入隊), 입사(入舍), 입소(入所), 입영(入營), 입원(入院), 입장(入場), 입주(入住), 입학(入學), 입회(入會), 입후보(立候補), 진출(進出), 출원(出願), 출품(出品), 편입(編入), 현역입영(現役入營) </p>  타. 탈퇴 <p class="message"> 강제탈퇴(强制脫退), 예편(豫編), 자퇴(自退), 정리해고(整理解雇), 탈당(脫黨), 탈퇴(脫退), 퇴교(退校), 퇴궐(退闕), 퇴사(退社), 퇴소(退所), 퇴역(退役), 퇴원(退院), 퇴위(退位), 퇴임(退任), 퇴정(退廷), 퇴직(退職), 퇴청(退廳), 퇴학(退學), 하야(下野) </p>  파. 긍정적결과행위 : 긍정적인 결과를 낳는 행위 <p class="message"> 개선(改善), 개화(開化), 건국(建國), 건립(建立), 국위선양(國威), 기사이적(奇事異蹟), 대승(大勝), 대업(大業), 독립(獨立), 돌파(突破), 명중(命中), 배상(賠償), 변통(變通), 소원성취(所願成就), 수훈(殊勳), 압승(壓勝), 약용(藥用), 업적(業績), 우승(優勝), 입상(入賞), 입선(入選), 입신양명(立身揚名), 입신출세(立身出世), 재활(再活), 초극(超克), 출세(出世), 쾌거(快擧), 쾌주(快走), 쾌투(快投), 타파(打破), 탈속(脫俗), 퇴치(退治), 해갈(解渴) </p>  하. 부정적결과행위 : 부정적인 결과를 낳는 행위 <p class="message"> 감산(減産), 개악(改惡), 골탕, 과락(科落), 도산(倒産), 따돌림, 몰락(沒落), 무산(霧散), 시각장애(視覺障碍), 실책(失策), 실향(失鄕), 압사(壓死), 파국(破局), 파산(破産), 패망(敗亡), 패전(敗戰), 해직(解職), 허사(虛事), 허탕 </p>  가가. 사동적행위 <p class="message"> 추방(追放), 통관(通關), 혹사(酷使) </p>  가나. 혼합행위 <p class="message"> 배색(配色), 배합(配合), 복합(複合), 혼색(混色), 혼성(混成), 혼숙(混宿), 혼용(混用), 혼입(混入), 혼합(混合) </p>  가다. 획득행위 <p class="message"> 고철수집(古鐵收集), 공동구매(共同購買), 구매(購買), 구애(求愛), 구입(購入), 구혼(求婚), 색출(索出), 생포(生捕), 석권(席卷), 선점(先占), 선취(先取), 섭렵(涉獵), 수거(收去), 수금(收金), 수납(收納), 수렵(狩獵), 수매(收買), 수신(受信), 수임(受任), 수입(輸入), 수주(受注), 수집(蒐集), 수취(受取), 수탁(受託), 수태(受胎), 수혜(受惠), 어획(漁獲), 영유(永有), 예매(豫買), 이중소유(二重所有), 임차(賃借), 입수(入手), 재배(栽培), 쟁취(爭取), 조차(租借), 착취(搾取), 찬탈(簒奪), 추심(推尋), 추징(追徵), 충당(充當), 충원(充員), 치부(致富), 탈환(奪還), 포획(捕獲), 확보(確保), 환급(還給), 환물(換物), 환수(還收), 획득(獲得), 횡재(橫財) </p>  가라. 개선행위 <p class="message"> 경제개혁(經濟改革), 교화(敎化), 구제(救濟), 배양(培養), 보강(補强), 보정(補正), 보혈(補血), 복권(復權), 복위(復位), 세련(洗練), 자기발전(自己發展), 정정(訂正), 정진(精進), 제도개선(制度改善), 제도개혁(制度改革), 차별화(差別化), 처우개선(處遇改善), 체질개선(體質改善), 초벌땜(初__), 초월(超越), 충전(充塡), 해소(解消), 확충(擴充) </p>  가마. 악화행위 <p class="message"> 이간질(離間_), 자해(自害), 초래(招來), 침해(侵害), 타락(墮落), 탈골(脫骨), 퇴락(頹落) </p>  (5) 범죄 및 비행 : 법률 및 규범에 반하는 행위 <p class="message"> 가정폭력(家庭暴力), 갈취(喝取), 강간죄(强姦罪), 강도살인죄(强盜殺人罪), 강제추행(强制醜行), 강탈(强奪), 겁탈(劫奪), 경범죄(輕犯罪), 공금횡령(公金橫領), 공무집행방해(公務執行妨害), 금권선거(金權選擧), 길강도(_强盜), 꾐, 난동(亂動), 난봉, 난폭운전(亂暴運轉), 날조(捏造), 날치기, 남용(濫用), 남침(南侵), 납치(拉致), 노동착취(勞動搾取), 노동탄압(勞動彈壓), 노략(擄掠), 노인학대(老人虐待), 노조탄압(勞組彈壓), 뇌물수수(賂物收受), 대량살상(大量殺傷), 대량학살(大量虐殺), 대죄(大罪), 도둑노름, 도둑질, 도용(盜用), 동반자살(同伴自殺), 마약사범(痲藥事犯), 매음(賣淫), 매춘(賣春), 명예훼손(名譽毁損), 모반(謀反), 모방범죄(模倣犯罪), 모해(謀害), 무단방류(無斷放流), 무단침입(無斷侵入), 무단횡단(無斷橫斷), 무력침공(武力侵攻), 반역죄(反逆罪), 반칙(反則), 방조(幇助), 방종(放縱), 방화(放火), 배교(背敎), 배반(背反), 배신(背信), 범법(犯法), 범죄(犯罪), 범죄행위(犯罪行爲), 범칙(犯則), 변절(變節), 변칙증여(變則贈與), 병역비리(兵役非理), 부정(不正), 부정입학(不正入學), 불경(不敬), 불륜(不倫), 불의(不義), 불효(不孝), 비리(非理), 비행기고문(飛行機拷問), 뺑소니, 사칭(詐稱), 사학비리(私學非理), 사행(邪行), 살륙(殺肉), 살상(殺傷), 살육(殺戮), 살인(殺人), 살해(殺害), 새치기, 성추행(性醜行), 성폭력(性暴力), 성폭행(性暴行), 세금포탈(稅金逋脫), 속도위반(速度違反), 수뢰(受賂), 시살(弑殺), 시해(弑害), 실질범(實質犯), 암거래(暗去來), 암살(暗殺), 야바위, 약물복용(藥物服用), 언어폭력(言語暴力), 여죄(餘罪), 역적질(逆賊_), 오입(誤入), 오입질(誤入_), 외도(外道), 위반(違反), 위배(違背), 위법(違法), 위조(僞造), 위협(威脅), 유괴(誘拐), 유용(流用), 유착비리(癒着非理), 윤락행위(淪落行爲), 은닉(隱匿), 음주운전(飮酒運轉), 음행(淫行), 이적(利敵), 이적행위(利敵行爲), 인권침해(人權侵害), 인권탄압(人權彈壓), 인신매매(人身賣買), 인종차별(人種差別), 인질극(人質劇), 일제침략(一齊侵略), 일탈행동(逸脫行動), 일탈행위(逸脫行爲), 자금세탁(資金洗濯), 잘못, 재범(再犯), 저격(狙擊), 전기고문(電氣拷問), 전횡(專橫), 절도(竊盜), 절취(竊取), 정치범(政治犯), 조세포탈(租稅逋脫), 조직폭력(組織暴力), 좀도둑질, 죄(罪), 죄과(罪過), 죄상(罪狀), 죄악(罪惡), 주가조작(株價操作), 주거침입(住居侵入), 직무유기(職務遺棄), 집단따돌림(集團___), 집단학살(集團虐殺), 집총거부(執銃拒否), 착복(着服), 추태(醜態), 추행(醜行), 친일행위(親日行爲), 침범(侵犯), 커닝(cunning), 컨닝(cunning), 타살(他殺), 탈루(脫漏), 탈법(脫法), 탈세(脫稅), 탈영(脫營), 탈옥(脫獄), 테러(terror), 트릭(trick), 파계(破戒), 패륜(悖倫), 포탈(逋脫), 폭거(暴擧), 폭력(暴力), 표절(剽竊), 피격(被擊), 피살(被殺), 피습(被襲), 학살(虐殺), 허위기재(虛僞記載), 협박전화(脅迫電話), 협잡(挾雜), 혼음(混淫), 횡령(橫領), 횡포(橫暴) </p>  (6) 종교 및 의례행위 <p class="message"> 개금불사(改金佛事), 거행(擧行), 견진성사(堅振聖事), 경배(敬拜), 국민의례(國民儀禮), 굿, 기제사(忌祭祀), 나무아미타불(南無阿彌陀佛), 넋굿, 대감거리, 문상(問喪), 분향(焚香), 불공(佛供), 산천기도(山川祈禱), 서품(敍品), 성묘(省墓), 성주풀이, 세례(洗禮), 소상(小祥), 순장(殉葬), 신사참배(神社參拜), 신세문안(新歲問安), 신앙고백(信仰告白), 씨앗고사(__告祀), 안수(按手), 액막이(厄__), 염불(念佛), 영세(領洗), 예배(禮拜), 예불(禮佛), 입관(入棺), 장군굿, 장례(葬禮), 장례식(葬禮式), 장의(葬儀), 제사(祭祀), 조건대세(條件代洗), 조문(弔問), 조의(弔意), 조포(弔砲), 졸곡제(卒哭祭), 종교의식(宗敎儀式), 집전(執典), 철야기도(徹夜祈禱), 철야예배(徹夜禮拜), 축복(祝福), 축성(祝聖), 축수(祝手), 출가(出家), 침례(浸禮), 포교(布敎), 푸닥거리, 하례(賀禮), 해외선교(海外宣敎) </p>  (7) 감각행위  가. 시각적 행위 <p class="message"> 구경, 눈길, 눈발, 눈빛, 시선(視線), 완상(玩賞), 전망(展望), 정찰(偵察), 좌시(坐視), 주시(注視), 직시(直視), 참관(參觀) </p>  나. 청각적 행위 <p class="message"> 음성인식(音聲認識), 음악감상(音樂鑑賞), 청취(聽取) </p>  다. 미각적 행위 <p class="message"> 복용(服用) </p>  라. 촉각적 행위 <p class="message"> 접촉(接觸), 터치(touch) </p>  (8) 방식 행위 : 특정한 방식을 표상하는 행위 <p class="message"> 공포정치(恐怖政治), 급습(急襲), 급조(急造), 다독(多讀), 어용(御用), 역공(力攻), 역습(逆襲), 역행(力行), 연납(延納), 연임(連任), 연타(連打), 열연(熱演), 열창(熱昌), 예방(豫防), 예비(豫備), 예약(豫約), 예행(豫行), 오도(誤導), 오독(誤讀), 오역(誤譯), 오용(誤用), 이구동성(異口同聲), 이구동음(異口同音), 재독(再讀), 전용(專用), 전유(專有), 정밀묘사(精密描寫), 집단행동(集團行動), 찬조출연(贊助出演), 책임시공(責任施工), 철두철미(徹頭徹尾), 청강(聽講), 촉성(促成), 촉진(促進), 총판(總販), 추렴, 투망(投網), 투매(投賣), 특채(特採) </p>  (9) 소리내기 <p class="message"> 발성(發聲), 발음(發音), 잠꼬대, 포효(咆哮), 환호(歡呼) </p>  (10) 섭취행위 <p class="message"> 병나발(甁__), 생식(生食), 섭취(攝取), 요기(療飢), 입다심, 잡식(雜食), 취식(取食), 탐식(貪食), 편식(偏食), 포식(飽食), 폭식(暴食), 화식(火食) </p>  (11) 배설 행위 <p class="message"> 배뇨(排尿), 배설(排泄) </p>  방향성행위 <p class="message"> 가급(加給), 가맹(加盟), 가학(加虐), 가해(加害), 가호(加護), 강공(强攻), 강박(强迫), 개발교수(開發敎授), 거역(拒逆), 건강교육(健康敎育), 견제(牽制), 결부(結付), 결초보은(結草報恩), 결합공급(結合供給), 경고(警告), 경매(競賣), 경축(慶祝), 경호(警護), 고객서비스(顧客_), 고별(告別), 곤욕(困辱), 공경(恭敬), 공공서비스(公共_), 공급(供給), 공대(恭待), 공세(攻勢), 공습(空襲), 공여(供與), 공포발화(空砲發火), 과세(課稅), 과잉진압(過剩鎭壓), 교부(交付), 교외교수(校外敎授), 구박(驅迫), 구원(救援), 구출(救出), 구타(毆打), 구휼(救恤), 국고지원(國庫支援), 군납(軍納), 군사행동(軍事行動), 굴욕(屈辱), 굴종(屈從), 권장(勸奬), 귀순(歸順), 근접(近接), 근조(謹弔), 금지(禁止), 급식(給食), 기고(寄稿), 기부(寄附), 기생(寄生), 기소(起訴), 기습(奇襲), 기습공격(奇襲攻擊), 기여(寄與), 기증(寄贈), 기탁(寄託), 기피(忌避), 긴급체포(緊急逮捕), 꾀임, 나선정벌(羅禪征伐), 난타(亂打), 납부(納付), 납세(納稅), 납입(納入), 납품(納品), 내숭, 냉대(冷待), 노획(鹵獲), 농(弄), 농간(弄奸), 눈신호(_信號), 눈총, 닦달, 단죄(斷罪), 답례(答禮), 대립(對立), 대민서비스(對民___), 대안교육(代案敎育), 대여(貸與), 대출(貸出), 도리질, 도매(都賣), 도발(挑發), 도움, 도전(挑戰), 독려(督勵), 독촉(督促), 동조(同調), 딴죽걸기, 마녀사냥(魔女__), 마사지(massage), 마중, 만행(蠻行), 매각(賣却), 매상(賣上), 매식(買食), 매입(買入), 매질, 매출(賣出), 매표(賣票), 맹공(猛攻), 맹타(猛打), 맹폭(盲爆), 면세(免稅), 몰이, 몽둥이찜질, 무상교육(無償敎育), 무안(無顔), 무죄선고(無罪宣告), 무죄판결(無罪判決), 무죄평결(無罪評決), 문병(問病), 문안(問安), 문의전화(問議電話), 문호개방(門戶開放), 밀매(密賣), 밀착(密着), 박대(薄待), 반격(反擊), 반론(反論), 반발(反撥), 반역(反逆|叛逆), 반영(反映), 반응(反應), 반항(反抗), 발목잡기, 발사(發射), 발신(發信), 발포(發砲), 변상(辨償), 병역면제(兵役免除), 보답(報答), 보복전쟁(報復戰爭), 보살핌, 보상(報償), 보은(報恩), 복종(服從), 부당해고(不當解雇), 부축, 분배(分配), 분양(分讓), 분풀이(憤__), 불간섭(不干涉), 불복(不服), 불심검문(不審檢問), 불응(不應), 불하(拂下), 비웃음, 비전(秘傳), 비호(庇護), 뽀뽀, 사양(辭讓), 사은(謝恩), 상납(上納), 상속(相續), 상해(傷害), 상환(償還), 생산물배상(生産物賠償), 생활교육(生活敎育), 석고대죄(席藁待罪), 선공(先功), 선교(宣敎), 성교육(性敎育), 성은(聖恩), 성차별(性差別), 세배(歲拜), 소개(紹介), 소나기펀치(_punch), 소외(疏外), 소홀(疏忽), 속량(贖良), 손님맞이, 손찌검, 송별(送別), 수모(受侮), 수발, 수배(手配), 수업(授業), 수유(授乳), 수청(守廳), 수탈(收奪), 시비(是非), 시술(施術), 시주(施主), 시치미, 시침, 식량지원(食糧支援), 실례(失禮), 안면치레(顔面__), 안팎중매(__仲媒), 알선(斡旋), 압제(壓制), 앙갚음, 앙탈, 애걸복걸(哀乞伏乞), 약조(約條), 약탈(掠奪), 양보(讓步), 양여(讓與), 양위(讓位), 어시스트(assist), 엄습(俺襲), 연비(聯臂), 영합(迎合), 올림, 요청사격(要請射擊), 우대(優待), 우롱(愚弄), 우송(郵送), 위안(慰安), 위압(威壓), 위임(委任), 위탁(委託), 윙크(wink), 유료서비스(有料___), 유린(蹂躪), 유배(流配), 유죄선고(有罪宣告), 융단폭격(絨緞爆擊), 융자(融資), 융통(融通), 은혜(恩惠), 음해(陰害), 응답(應答), 응수(應手), 응징(膺懲), 의뢰(依賴), 의탁(依託), 이미지광고(image__), 이식(移植), 이양(移讓), 이입(移入), 인계(引繼), 인공호흡(人工呼吸), 인사(人事), 인사청탁(人事請託), 인허(認許), 일갈(一喝), 일격(一擊), 일임(一任), 임대(賃貸), 자동이체(自動移替), 자선(慈善), 작대기찜질, 장가(丈家), 장기이식(臟器移植), 저항(抵抗), 적선(積善), 전가(轉嫁), 전단광고(全段廣告), 전래(傳來), 전면교육(全面敎育), 전면금지(全面禁止), 전신마취(全身痲醉), 접근금지(接近禁止), 접수(接受), 접종(接種), 정보공개(情報公開), 정조준(正照準), 정치보복(政治報復), 제공(提供), 제압(制壓), 제약(制約), 제어(制御), 제외(除外), 제지(制止), 제출(提出), 제한(制限), 조공(朝貢), 조기교육(早期敎育), 조력(助力), 조미(調味), 종용(慫慂), 종합검진(綜合檢診), 주문(注文), 주입(注入), 지공(支供), 지원사격(支援射擊), 집중공격(集中攻擊), 집중단속(集中團束), 차공양(茶供養), 차입(借入), 채찍질, 첫인사(_人事), 청구(請求), 청약(請約), 청혼(請婚), 초대(招待), 초빙(招聘), 초청(招請), 촉탁(囑託), 총격(銃擊), 총공격(總攻擊), 총람(總覽), 추격(追擊), 추궁(追窮), 추돌(追突), 추적(追跡), 추천(推薦), 추파(秋波), 축하(祝賀), 출국금지(出國禁止), 출납(出納), 출자(出資), 취조(取調), 치명타(致命打), 치사(致仕), 침공(侵攻), 침략(侵略), 침습(侵襲), 침입(侵入), 침탈(侵奪), 타격(打擊), 통솔(統率), 투고(投稿), 투약(投藥), 투항(投降), 특매(特賣), 특별징수(特別徵收), 특융(特融), 특허출원(特許出願), 특혜(特惠), 판촉(販促), 포격(砲擊), 포유(哺乳), 폭투(暴投), 표명(表明), 피칭(pitching), 하대(下待), 하청(下請), 학대(虐待), 학벌타파(學閥打破), 학자금융자(學資金融資), 할당(割當), 합세(合勢), 항거(抗拒), 항복(降伏|降服), 항소(抗訴), 항쟁(抗爭), 행정서비스(行政___), 행패(行悖), 허가(許可), 허락(許諾), 허용(許容), 허혼(許婚), 헌금(獻金), 헌납(獻納), 헌상(獻上), 헌신(獻身), 헌혈(獻血), 헌화(獻花), 현금서비스(現金___), 현인안목(眩人眼目), 협공(挾攻), 협조(協助), 협찬(協贊), 혜택(惠澤), 호소(呼訴), 호응(呼應), 홀대(忽待), 홍보(弘報), 화공(火功), 환원(還元), 회수(回收), 후견(後見), 후계(後繼), 후원(後援), 희사(喜捨) </p>  (1) 처벌 <p class="message"> 멍석말이, 면허정지(免許停止), 보복(報復), 복수(復讐), 사법처리(司法處理), 사형집행(死刑執行), 수감(收監), 엄단(嚴斷), 엄벌(嚴罰), 일벌백계(一罰百戒), 정학(停學), 제적(除籍), 징계(懲戒), 징벌(懲罰), 처벌(處罰), 천벌(天罰), 체벌(體罰), 축출(逐出), 투옥(投獄), 파울(foul), 해임(解任), 행형(行刑), 형벌(刑罰), 화형(火刑) </p>  (2) 포상 <p class="message"> 서훈(敍勳), 시상(施賞), 추서(追敍), 특전(特典), 포상(褒賞), 표창(表彰) </p>  (3) 영향 <p class="message"> 악영향(惡影響), 영향(影響), 작용(作用), 촉발(觸發) </p>  (4) 제약 <p class="message"> 구금(拘禁), 구속(拘束), 국한(局限), 규제(規制), 발매금지(發賣禁止), 선제(先制), 속박(束縛), 억류(抑留), 억압(抑壓), 억제(抑制), 엄금(嚴禁), 입건(立件), 저지(沮止), 탄압(彈壓), 통제(統制), 포박(捕縛), 폭압(暴壓), 핍박(逼迫) </p>  (5) 간섭  (6) 수여 <p class="message"> 무료급식(無料給食), 반품(返品), 반환(返還), 발급(發給), 발부(發付), 배급(配給), 배부(配付), 배분(配分), 배식(陪食), 보시(布施), 봉납(捧納), 봉헌(奉獻), 부여(附與), 분급(分給), 불입(拂入), 서브(serve), 서비스(service), 선급(先給), 선납(先納), 선불(先拂), 선사(膳賜), 선위(禪位), 세습(世襲), 세일즈(sales), 센터링(centering), 송고(送稿), 송금(送金), 송부(送付), 송신(送信), 송전(送電), 송치(送致), 수여(授與), 수출(輸出), 수혈(輸血), 유통판매(流通販賣), 장기기증(臟器寄贈), 증여(贈與), 지급(支級), 지불(支拂), 판매(販賣) </p>  대칭적행위 <p class="message"> 가위바위보, 간음(姦淫), 간통(姦通), 격돌(激突), 격전(激戰), 격투(格鬪), 결별(訣別), 결사항전(決死抗戰), 결속(結束), 결연(結緣), 결전(決戰), 결탁(結託), 결투(決鬪), 결합(結合), 결혼(結婚), 경연(競演), 경쟁(競爭), 경제협력(經濟協力), 경합(競合), 고래싸움, 공조(共助), 과열경쟁(過熱競爭), 교대(交代), 교섭(交涉), 교역(交易), 교차(交叉), 국교(國交), 국제거래(國際去來), 근친상간(近親相姦), 근친혼(近親婚), 내기, 노름, 다수강화(多數講和), 다툼, 단결(團結), 단교(斷交), 담판(談判), 담합(談合), 대결(對決), 대련(對鍊), 대면(對面), 대적(對敵), 대질(對質), 대치(對峙), 데이트(date), 동거(同居), 동반(同伴), 동석(同席), 동성연애(同性戀愛), 동숙(同宿), 동승(同乘), 동심협력(同心協力), 동학(同學), 동행(同行), 듀엣(duet), 랑데부(랑데부), 마약거래(痲藥去來), 만남, 맞담배, 맞벌이, 맞선, 맞장구, 매매(賣買), 무역(貿易), 무한경쟁(無限競爭), 미팅(meeting), 밀약(密約), 밀회(密會), 사투(死鬪), 상견(相見), 상부상조(相扶相助), 상조(相助), 상종(相從), 상호보완(相互補完), 상호작용(相互作用), 성관계(性關係), 성교(性交), 성례(成禮), 성애(性愛), 성행위(性行爲), 성혼(成婚), 섹스(sex), 수교(修交), 수작(酬酌), 실물거래(實物去來), 싸움, 약정(約定), 어깨동무, 역할분담(役割分擔), 연대(連帶), 연대투쟁(連帶鬪爭), 연립(聯立), 연합(聯合), 영이별(永離別), 오른씨름, 외교(外交), 왼씨름, 원조교제(援助交際), 유대강화(紐帶强化), 융화(融和), 이별(離別), 이혼(離婚), 일대일변환(一對一變換), 자리다툼, 작당(作黨), 잡교(雜交), 전차금계약(前借金契約), 접선(接線), 접전(接戰), 정략결혼(政略結婚), 제휴(提携), 조국통일(祖國統一), 조약(條約), 조찬(朝餐), 주식거래(株式去來), 중매결혼(仲媒結婚), 초혼(初婚), 축구경기(蹴球競技), 출혈경쟁(出血競爭), 타협(妥協), 탁구(卓球), 통상(通商), 통일전선(統一戰線), 투합(投合), 특약(特約), 파혼(破婚), 품앗이, 합궁(合宮), 합동결혼(合同結婚), 합병(合倂), 합승(合承), 합심(合心), 합의(合意), 합작(合作), 현금매매(現金賣買), 협동(協同), 협력(協力), 협업(協業), 협연(協演), 협의이혼(協議離婚), 협주, 호형호제(呼兄呼弟), 호혜(互惠), 혼신결혼(混信結婚), 혼약(婚約), 혼외정사(婚外情事), 화의(和議), 환불(還拂), 횃불싸움, 휴전(休戰), 흥정, 힘겨루기 </p>  (1) 만남 <p class="message"> 면접(面接), 병합(倂合), 상견례(相見禮), 선, 재가(再嫁), 재혼(再婚), 재회(再會), 정혼(定婚), 조우(遭遇), 혼인(婚姻), 회동(會同) </p>  (2) 이별 <p class="message"> 별거(別居), 생리사별(生離死別), 생이별(生離別), 석별(惜別), 작별(作別), 하직(下直), 환송(歡送) </p>  (3) 물리적 충돌 행위 <p class="message"> 골육상쟁(骨肉相爭), 나무쇠싸움, 몸싸움, 민족상잔(民族相殘), 반도전쟁(半島戰爭), 복싱(boxing), 사변(事變), 사화(士禍), 생존경쟁(生存競爭), 서전(緖戰), 선거전(選擧戰), 유혈극(流血劇), 육박전(肉薄戰), 쟁탈전(爭奪戰), 중동전쟁(中東戰爭), 침노(侵擄), 카드놀이(card), 혈전, 혈투(血鬪) </p>  (4) 교환 <p class="message"> 교제(交際), 교체(交替), 교환(交換), 상거래(商去來), 태환(兌換), 트레이드(trade), 호환(互換), 환금(換金), 환전(換錢) </p>  #### 비의도적 행위 개코망신(__亡身), 과실(過失), 과오(過誤), 당락(當落), 방심(放心), 범실(凡失), 보균(保菌), 봉착(逢着), 불로장생(不老長生), 사별(死別), 생존(生存), 소실(消失), 승급(昇級), 승소(勝訴), 실성(失性), 실업(失業), 실연(失戀), 실점(失點), 실직(失職), 십년감수(十年減壽), 에러(error), 연루(連累), 영생(永生), 오류(誤謬), 오발(誤發), 옥고(獄苦), 유명세(有名稅), 윤회(輪廻), 인력난(人力難), 임신(姙娠), 자상(刺傷), 재선(再選), 재임(在任), 절명(絶命), 점지, 조실부모(早失父母), 졸도(卒倒), 진급(進級), 체납(滯納) </p>  성공 : 긍정적 결과를 가져오는 행위 <p class="message"> 급제(及第), 낙승(樂勝), 당선(當選), 대성(大成), 대풍(大豊), 대풍작(大豊作), 성공(成功), 성사(成事), 승리(勝利), 영달(榮達), 완승(完勝), 이달(利達), 초선(初選), 합격(合格) </p>  실패 : 부정적 결과를 가져오는 행위 <p class="message"> 개인워크아웃(個人____), 낙방(落榜), 낙선(落選), 낙오(落伍), 낙제(落第), 분패(憤敗), 불합격(不合格), 석패(惜敗), 시행착오(試行錯誤), 실격(失格), 완패(完敗), 유급(留級), 전패(全敗), 참패(慘敗), 탈락(脫落), 패배(敗北), 패퇴(敗退), 허송세월(虛送歲月) </p>  생리행위 <p class="message"> 경련(痙攣), 구역질(嘔逆_), 구토(嘔吐), 기침, 방귀, 배변(排便), 설사(泄瀉), 숨, 습관유산(習慣流産), 잠, 취침(就寢) </p>  죽음 <p class="message"> 괴사(怪死), 별세(別世), 병사(病死), 비명횡사(非命橫死), 사(死), 사망(死亡), 서거(逝去), 순교(殉敎), 순국(殉國), 순직(殉職), 승하(昇遐), 옥사(獄死), 익사(溺死), 임종(臨終), 입적(入寂), 자살(自殺), 자연사(自然死), 작고(作故), 죽음, 직사(直死), 추락사(추락사), 치명(致命), 횡사(橫死) </p>  출생 <p class="message"> 성탄(聖誕), 자연분만(自然分娩), 초산(初産), 탄생(誕生), 환생(還生) </p>  인간의 변화 <p class="message"> 성불(成佛), 장성(長成) </p>  움직임 <p class="message"> 생동(生動), 약동(躍動), 역동(力動), 요동(搖動), 행보(行步) </p>  피동적 행위 <p class="message"> 면책(免責), 발각(發覺), 변고(變故), 봉변(逢變), 부상(負傷), 예속(隸屬) </p>  #### 추상적 행위 **추상적 행위**란 추상적이고 인지적인 제반 행위를 가리킵니다. <p class="message"> 가족계획(家族計劃), 가처분(假處分), 강제징용(强制徵用), 개관(槪觀), 개괄(槪括), 개발독재(開發獨裁), 경도(傾倒), 계발(啓發), 계상(計上), 고안(考案), 고취(鼓吹), 곱하기, 과신(過信), 괄목상대(刮目相對), 괄시(恝視), 구별(區別), 구분(區分), 규명(糾明), 기안(起案), 기획(企劃), 낯가림, 내정(內定), 뇌사판정(腦死判定), 눈요기(_療飢), 더하기, 도모(圖謀), 도출(導出), 독단(獨斷), 동의(同意), 명목장담(明目張膽), 문제제기(問題提起), 문제풀이(問題__), 발양(發揚), 발효(發效), 발휘(發揮), 방관(傍觀), 방임(放任), 배당(配當), 배상판결(賠償判決), 배제(排除), 배척(排斥), 배타(排他), 배후조종(背後操縱), 백일몽(白日夢), 번복(飜覆), 벌충, 범접(犯接), 변경(變更), 병용(竝用), 보류(保留), 부응(副應), 부회(附會), 분담(分擔), 분려(奮勵), 분발(奮發), 분석(分析), 불찰(不察), 빼기, 뺄셈, 사죄(謝罪), 상대방대리(相對方代理), 상상(想像), 상징(象徵), 소급(溯及), 소인수분해(素因數分解), 신원보증(身元保證), 실증(實證), 심기일전(心機一轉), 심취(心醉), 아전인수(我田引水), 양자택일(兩者擇一), 역사관(歷史觀), 열중(熱中), 오해(誤解), 용꿈(龍_), 우민화(愚民化), 유념(留念), 유의(留意), 자괴(自愧), 조감(鳥瞰), 지망(志望), 차치(且置), 찬탁(贊託), 참고(參考), 참회(懺悔), 클레임(claim), 표방(標榜), 풍유(諷諭), 호도(糊塗), 회피(回避), 흉몽(凶夢) </p>  인지적 행위 <p class="message"> 가치판단(價値判斷), 갈구(渴求), 갈망(渴望), 강구(講究), 검인정(檢認定), 검증(檢證), 결사(決死), 결행(決行), 계산속(計算_), 고증(考證), 공상(空想), 구명(究明), 국정평가(國政評價), 궁리(窮理), 귀납(歸納), 기계화회계(機械化會計), 기념(記念|紀念), 기대(期待), 기략(機略), 기만(欺瞞), 기억(記憶), 꿍꿍이, 꿍꿍이속, 나누기, 낙관(樂觀), 납득(納得), 낯알음, 논구(論究), 눈도장(_圖章), 단락(段落), 단정(斷定), 대별(大別), 대오각성(大悟覺醒), 대중, 도취(陶醉), 독도(讀圖), 독해(讀解), 로비의혹(lobby__), 만끽(滿喫), 만사오케이(萬事___), 망각(忘却), 망상(妄想), 망향(望鄕), 맹신(盲信), 모사(謀事), 몰각(沒却), 묘사(描寫), 무꾸리, 문제인식(問題認識), 물음, 미봉(彌縫), 반증(反證), 발안(發案), 발의(發意), 배려(配慮), 변별(辨別), 변심(變心), 분간(分揀), 분변(分辨), 분별(分別), 사색(思索), 사실오인(事實誤認), 사유(思惟), 사정보정(事情補定), 산입(算入), 상기(想起), 상량(商量), 상황판단(狀況判斷), 생각, 선견(先見), 성찰(省察), 세분(細分), 셀프컨트롤(self control), 셈, 소추(訴追), 속결(速決), 속단(速斷), 속독(速讀), 수긍(首肯), 수렴(收斂), 수지타산(收支打算), 숙고(熟考), 숙지(熟知), 숫자풀이(數字__), 승복(承服), 시대착오(時代錯誤), 식별(識別), 심사숙고(深思熟考), 심산(心算), 암기(暗記), 암중모색(暗中摸索), 양해(諒解), 어림, 어림생각, 어림셈, 어림짐작, 억측(臆測), 여념(餘念), 여론조작(輿論造作), 연말정산(年末精算), 연산(演算), 연역(演繹), 염두(念頭), 예감(豫感), 예견(豫見), 예기(豫期), 예단(豫斷), 예산(豫算), 예술비평(藝術批評), 예정(豫定), 예측(豫測), 오산(誤算), 오인(誤認), 요량(料量), 우상숭배(偶像崇拜), 유예조치(猶豫措置), 유죄판결(有罪判決), 유추(類推), 의사결정(意思決定), 이름풀이, 이해타산(利害打算), 일반화(一般化), 입각(立脚), 입증(立證), 자각(自覺), 자기성찰(自己省察), 자성(自省), 자숙(自肅), 자아비판(自我批判), 자인(自認), 자중(自重), 자처(自處), 자축(自祝), 작심(作心), 작정(作定), 잠정집계(暫定集計), 잡생각(雜__), 재결(裁決), 재론(再論), 재미추구(__追求), 재심(再審), 재판(裁判), 적출(摘出), 전결(專決), 전념(專念), 전산(電算), 전제(前提), 절감(切感), 점검(點檢), 점술(占術), 점호(點呼), 접근(接近), 접맥(接脈), 접목(接木), 정밀분석(精密分析), 정산(精算), 정상참작(精狀參酌), 정신교육(精神敎育), 정죄(定罪), 종합(綜合), 주목(注目), 중시(重視), 직감(直感), 직관(直觀), 진단(診斷), 진상파악(眞相把握), 짐작(斟酌), 집중(集中), 집중분석(集中分析), 착각(錯覺), 착안(着眼), 참작(參酌), 참조(參照), 창안(創案), 천착(穿鑿), 체감(體感), 체득(體得), 초탈(超脫), 총결산(總決算), 총화(總和), 최종결론(最終結論), 최종결정(最終決定), 추계(推計), 추고(推考), 추구(追求), 추념(追念), 추도(追悼), 추론(推論), 추리(推理), 추모(追慕), 추산(推算), 추상(抽象), 추인(追認), 추정(推定), 추측(推測), 축원(祝願), 충동질(衝動_), 취급(取扱), 취미판단(趣味判斷), 취사선택(取捨選擇), 치중(置重), 치환(置換), 침잠(沈潛), 큰마음, 타산(打算), 탐지(探知), 택일(擇一), 터득(攄得), 통계(統計), 통달(通達), 통분(通分), 통산, 통찰(洞察), 퇴고(堆敲), 파악(把握), 판가름, 판단(判斷), 판독(判讀), 판별(判別), 판시(判示), 판정(判定), 포착(捕捉), 학습(學習), 해득(解得), 혼동(混同), 확신(確信), 확정(確定), 환산(換算), 회개(悔改), 회계(會計), 회고(回顧), 회상(回想), 회진(回診), 흉계(凶計) </p>  (1) 비교 <p class="message"> 비교(比較), 비유(比喩) </p>  (2) 평가 <p class="message"> 과대평가(過大評價), 과소평가(過小評價), 비평(批評), 상대평가(相對評價), 자찬(自讚), 자책(自責), 자칭(自稱), 자평(自評), 잠정평가(暫定評價), 절대평가(絶對平價), 죄악시(罪惡視), 총평(總評), 판명(判明), 평(評), 해몽(解夢), 호평(好評), 혹평(酷評) </p>  조사 <p class="message"> 검색서비스(檢索___), 과잉수사(過剩搜査), 관측(觀測), 불꽃분석(__分析), 사회감사(社會監査), 성격검사(性格檢査), 센서스(census), 수사(搜査), 염탐(廉探), 인성검사(人性檢査), 재검(再檢), 정밀조사(精密照査), 정보검색(情報檢索), 조기진단(早起診斷 ), 조사(調査), 조사활동(調査活動), 청진(聽診), 체크(check), 초진(初診), 취재(取材), 탐조(探照), 확인(確認) </p>  추상적 대칭행위 <p class="message"> 분쟁(紛爭), 절충(折衷), 채결(採決) </p>  (1) 협정 <p class="message"> 임금협상(賃金協商), 조인(調印), 책임보험(責任保險), 파리협정(Paris__), 협상(協商), 협약(協約), 협의(協議), 협정(協定) </p>  (2) 화해 <p class="message"> 화해(和解) </p>  #### 소통행위 <p class="message"> 갈파(喝破), 개나발(_喇叭), 개별통보(個別通報), 거리선전(__宣傳), 거리응원(__應援), 결혼공시(結婚公示), 계시(啓示), 고창(高唱), 고해성사(告解聖事), 공갈(恐喝), 공개사과(公開謝過), 공동성명(共同聲明), 공식발표(公式發表), 공식사과(公式謝過), 공식사죄(公式謝罪), 공언(公言), 공익광고(公益廣告), 공지(公知), 과대광고(誇大廣告), 교언영색(巧言令色), 구걸(求乞), 구두설명(口頭說明), 구전(口傳), 권고(勸告), 궤변(詭辯), 귀띔, 귀엣말, 극언(極言), 극찬(極讚), 긍정(肯定), 기도(祈禱), 기별(奇別), 기합(氣合), 날씨경보(__警報), 다짐, 단독보도(單獨報道), 단언(斷言), 당부(當付), 대북협상(對北協商), 독립선언(獨立宣言), 두둔(斗頓), 라디오인터뷰(radio interview), 만류(挽留), 맹세(盟誓), 묵계(默契), 묵시(默示), 물위거론(勿爲擧論), 보증(保證), 복창(復唱), 부르짖음, 부탁(付託), 불문(不問), 새해전갈, 서술(敍述), 선거방송(選擧放送), 선서(宣誓), 선언(宣言), 선전(宣傳), 선포(宣布), 설득(說得), 설명(說明), 설복(說伏), 시국선언(時局宣言), 식언(食言), 신간평(新刊評), 신신당부(申申當付), 실언(失言), 약술(略術), 언급(言及), 엄포, 역설(力說), 예약전화(豫約電話), 예언(豫言), 외면수새(外面__), 용서(容恕), 우는소리, 운운(云云), 이용안내(利用案內), 일방행위(一方行爲), 일언(一言), 자기표현(自己表現), 자랑, 재촉, 저녁문안(__問安), 전승(傳承), 전화인터뷰(電話___), 정조문안(正朝問安), 주창(主唱), 직설(直說), 찬사(讚辭), 체신(遞信), 코멘트(comment), 포고(布告), 폭로(暴露), 표시(表示), 표현(表現), 풍자(諷刺), 프로포즈(propose), 피력(披瀝), 핑계, 한탄(恨歎), 항변(抗卞), 해명(解明), 해설(解說), 형언(形言), 호가(呼價), 호객(呼客), 호명(號名), 호언(豪言), 호출(呼出), 혼잣말, 횡설수설(橫說竪說) </p>  상호적 언술 행위 금석맹약(金石盟約), 기약(期約), 끝말잇기, 논급(論及), 문답(問答), 상담(相談), 소파협정(SOFA__), 의료상담(醫療相談), 의사소통(意思疏通), 자녀상담(子女相談), 전화통화(電話通話), 진학상담(進學相談), 질의응답(質疑應答), 최종합의(最終合意), 커뮤니케이션(communication), 평의(評議) </p>  (1) 논쟁 <p class="message"> 격론(激論), 난상토론(爛商討論), 논란(論難), 논박(論駁), 논쟁(論爭), 논전(論戰), 말다툼, 설전(舌戰), 실랑이, 언쟁(言爭), 위헌시비(違憲是非), 이념논쟁(理念論爭), 쟁론(爭論), 쟁투(爭鬪), 정치공세(政治攻勢), 지상토론(紙上討論), 찬반논란(贊反論難), 찬반논쟁(贊反論爭), 찬반양론(贊反兩論), 충돌(衝突) </p>  (2) 대화 <p class="message"> 개별토론(個別討論), 논의(論議), 담소(談笑), 담화(談話), 대담(對談), 대화(對話), 면담(面談), 밀담(密談), 사담(私談), 상론(詳論), 선문답(禪問答), 세미나(seminar), 수다, 얘기, 언론인터뷰(言論___), 음성채팅(音聲__), 의논(議論), 임금교섭(賃金交涉), 입학상담(入學相談), 정담(情談), 좌담(座談), 찬반토론(贊反討論), 토론(討論), 토의(討議), 통신(通信), 환담(歡談), 회견(會見), 회담(會談), 회의(會議), 회화(會話) </p>  (3) 약속 <p class="message"> 구두약속(口頭約束), 단체협약(團體協約), 서약(誓約), 언약(言約), 준법서약(遵法誓約), 혈맹(血盟), 확약(確約), 확언(確言) </p>  비난욕설 <p class="message"> 견책(譴責), 공박(攻駁), 규탄(糾彈), 꾸중, 꾸지람, 나무람, 놀림, 능멸(凌蔑), 능욕(凌辱), 독설(毒舌), 망발(妄發), 망언(妄言), 매도(罵倒), 면박(面駁), 모독(冒瀆), 모함(謀陷), 문책(問責), 반박(反駁), 불평(不平), 불호령(_號令), 비난(非難), 비판(批判), 상소리(常__), 생트집(生__), 생핀잔(生__), 성토(聲討), 악담(惡談), 악평(惡評), 욕(辱), 욕설(辱說), 욕지거리(辱___), 으름장, 인신공격(人身攻擊), 일침(一鍼), 잔소리, 저주(詛呪), 조롱(嘲弄), 조소(嘲笑), 중상모략(中傷謀略), 지탄(指彈), 질책(叱責), 질타(叱咤), 참언(讒言), 책망(責望), 타박, 탄핵(彈劾), 투정, 트집, 폄하(貶下), 폭언(暴言), 푸념, 핀잔, 험구(險口), 험담(險談), 협박(脅迫), 호통, 훼방(毁謗), 힐난(詰難), 힐책(詰責) </p>  명령 <p class="message"> 계엄령(戒嚴令), 구령(口令), 군령(軍令), 금령(禁令), 명령(命令), 발령(發令), 부름, 분부(分付), 사형선고(死刑宣告), 시달(示達), 압류금지(押留禁止), 어명(御命), 엄명(嚴命), 영(令), 오존주의보(ozone___), 왕명(王命), 유언(遺言), 전령(傳令), 전부명령(轉付命令), 지휘(指揮), 천명(天命), 칙령(勅令), 칙명(勅命), 콜(call), 큐(cue), 특명(特命), 편달(鞭撻), 하명(下命), 함구령(緘口令), 호령(號令), 훈계(訓戒), 훈령(訓令), 훈시(訓示), 훈화(訓話) </p>  식사 <p class="message"> 송사(送辭), 축도(祝禱) </p>  보고제안 <p class="message"> 간소(奸訴), 건의(建議), 건의사항(建議事項), 결의안(決議案), 내신(內申), 대설주의보(大雪注意報), 밀고(密告), 보고(報告), 분실신고(紛失申告), 브리핑(briefing), 사망신고(死亡申告), 사망자선고(死亡者宣告), 사전통보(事前通報), 상신(上申), 소득신고(所得申告), 신고(申告), 연락(連絡), 예고(豫告), 예보(豫報), 오보(誤報), 왜곡보도(歪曲報道), 요구(要求), 요청(要請), 이의제기(異意提起), 일기예보(日氣豫報), 자진신고(自進申告), 자청(自請), 정정보도(訂正報道), 제보(提報), 제시, 제안(提案), 제언(提言), 제의(提議), 제창(提唱), 제청(提請), 조언(助言), 주장(主張), 직언(直言), 진학지도(進學指導), 집중보도(集中報道), 찬반의견(贊反意見), 첩보(諜報), 청부(請負), 청원(請願), 체포동의안(逮捕同議案), 촉구(促求), 촌평(寸評), 출반(出班), 충고(忠告), 타전(打電), 탄원(歎願), 통고(通告), 통보(通報), 통지(通知), 통첩(通牒), 투서(投書), 특보(特報), 특필(特筆), 혼담(婚談), 회보(回報), 훈수(訓手) </p>  연설 <p class="message"> 강론(講論), 국정연설(國政演說), 논술(論述), 논평(論評), 답사(答辭), 대독(代讀), 반포(頒布), 발뺌, 발언(發言), 발표(發表), 변론(辯論), 변명(辨明), 변증(辯證), 변호(辯護), 설교(說敎), 설법(說法), 설파(說破), 송별사(送別辭), 순회강연(巡廻講演), 신년사(新年辭), 양심선언(良心宣言), 언도(言渡), 언명(言明), 연구수업(硏究授業), 연설(演說), 열변(熱辯), 웅변(雄辯), 유세(遊說), 중언부언(重言復言), 증언(證言), 진술(陳述), 찬조연설(贊助演說), 추도사(追悼辭), 특강(特講) </p>  이야기 <p class="message"> 간증(干證), 감언이설(甘言利說), 강평(講評), 객담(客談), 거짓말, 건국신화(建國神話), 격려(激勵), 격찬(激讚), 경하(慶賀), 고자질(告者_), 공치사(功致辭), 광고(廣告), 내시(內示), 넋두리, 농담(弄談), 도움말, 돌출발언(突出發言), 만담(漫談), 미담(美談), 밀어(蜜語), 부연(敷衍), 소담(笑談), 술회(述懷), 실패담(失敗談), 에피소드(episode), 여담(餘談), 영웅담(英雄譚), 예찬(禮讚), 옛날이야기, 옛이야기, 우스갯소리, 음담패설(淫談悖說), 이야기, 인사말(人事_), 인터뷰(interview), 일구이언(一口二言), 일화(逸話), 입방아, 입방정, 잡담(雜談), 잡말(雜_), 장담(壯談), 재담(才談), 조크(joke), 진담(眞談), 청담(淸談), 추억담(追憶談), 충언(忠言), 췌언(贅言), 칭송(稱頌), 칭찬(稱讚), 탄사(歎辭), 토로(吐露), 편집후기(編輯後記), 풍(風), 필담(筆談), 하소연, 한담(閑談), 할이야기, 호언장담(豪言壯談), 화담(和談), 후담(後談), 후일담(後日譚) </p>  질문 <p class="message"> 반문(反問), 설문(說問), 설문조사(設問調査), 우문(愚問), 자문(自問), 전화문의(電話問議), 질문(質問), 질의(質疑), 탐문(探問), 힐문(詰問) </p>  대답 <p class="message"> 군대답(_對答), 답(答), 답변(答辯), 대꾸, 대답(對答), 명답(名答), 응대(應對), 자백(自白), 필답(筆答), 화답(和答), 확답(確答), 회답(回答), 회신(回信) </p>  허락 <p class="message"> 결재(決裁), 불허(不許), 수락(受諾), 수용(受容), 인가(認可), 좌단(左袒) </p>  반대 <p class="message"> 반탁(反託), 반핵(反核), 일축(一蹴), 전면거부(全面拒否) </p>  #### 심리행위 **심리행위**란 심리와 관련된 행위를 가리킵니다. <p class="message"> 감내(堪耐), 국치(國恥), 늑장, 능청, 달관(達觀), 배은망덕(背恩忘德), 부지런, 비관(悲觀), 신망(信望), 악착(齷齪), 음흉(陰凶), 조심(操心), 황소고집(__固執) </p>  외향적 심리행위 : 어떤 대상에 대한 지향성을 갖는 심리행위 <p class="message"> 감천(感天), 경시(輕視), 경악(驚愕), 경탄(驚歎), 과잉반응(過剩反應), 광태(狂態), 교태(嬌態), 권위주의(權威主義), 기겁(氣怯), 까탈, 냉소(冷笑), 노발대발(怒發大發), 다사(多謝), 단념(斷念), 동감(同感), 동경(憧憬), 동정(同情), 땡깡, 만용(蠻勇), 멸시(蔑視), 모욕(侮辱), 미련, 발버둥, 발악(發惡), 백만교태(百萬嬌態), 법석, 변덕(變德), 부산, 불순(不順), 불조심(_操心), 비굴(卑屈), 비소(非笑), 비하(卑下), 빈축(嚬蹙), 사모(思慕), 생색(生色), 선심(善心), 선호(選好), 성질(性質), 소박(疏薄), 숭배(崇拜), 숭상(崇尙), 숭앙(崇仰), 신경질(神經質), 신뢰감(信賴感), 신봉(信奉), 신빙(信憑), 신심(信心), 신중(愼重), 안달복달, 안면박대(顔面薄待), 안하무인(眼下無人), 알랑방귀, 알은체, 애교(愛橋), 애도(哀悼), 애석(哀惜), 애통(愛痛), 애호(愛好), 어깃장, 어리광, 엄두, 엄살, 에로스(eros), 역정(逆情), 열광(熱狂), 영탄(詠歎), 오만방자(傲慢放恣), 요망(要望), 유감(遺憾), 자식사랑(子息_), 자애(慈愛), 잔걱정, 적당주의(適當主義), 적대(敵對), 적대행위(敵對行爲), 전심(全心), 전전긍긍(戰戰兢兢), 절규(絶叫), 정성(精誠), 정열(情熱), 존경(尊敬), 존대(尊待), 존중(尊重), 질투(嫉妬), 집착(執着), 짜증, 찬동(贊同), 찬미(讚美), 찬성(贊成), 찬양(讚揚), 천인공노(天人共怒), 촉망(屬望), 총애(寵愛), 추앙(推仰), 추종(追從), 충실(忠實), 취태(醉態), 친교(親交), 퉁명, 편애(偏愛), 포용(包容), 형제애(兄弟愛), 호들갑 </p>  내재적 심리행위 : 어떤 대상에 대한 지향성을 갖지 않는 심리행위 <p class="message"> 끌탕, 낙담(落膽), 낙망(落望), 낙심(落心), 뉘우침, 득의(得意), 막무가내(莫無可奈), 만족(滿足), 번뇌(煩惱), 번민(煩悶), 사욕(私慾), 상심(傷心), 실의(失意), 아연실색(啞然失色), 안빈낙도(安貧樂道), 안심(安心), 열등감(劣等感), 열심(熱心), 외고집(_固執), 용기(勇氣), 용기백배(勇氣百倍), 우국(憂國), 유비무환(有備無患), 유유자적(悠悠自適), 인고(忍苦), 자긍(自矜), 자만(自慢), 자족(自足), 자탄(自歎|自嘆), 자학(自虐), 절망(絶望), 주저(躊躇), 채신머리, 포기(抛棄), 회심(回心), 희비(喜悲) </p>  ### 사건 <p class="message"> 강연(講演), 개벽(開闢), 개전(開戰), 개학(開學), 거침, 경조(慶弔), 경조사(慶弔事), 과거사(過去事), 광복(光復), 대전(大戰), 대형사건(大型事件), 도래(到來), 득남(得男), 민원(民願), 별고(別故), 별일(別 _), 병인박해(丙寅迫害), 사건(事件), 세상만사(世上萬事), 소리고저(__高低), 우연(偶然), 웬일, 위해(危害), 의혹사건(疑惑事件), 일과(一過), 제패(制U+0-9738;), 징계사건(懲戒事件), 착오(錯誤), 참화(慘禍), 창사(創社), 추모행사(追慕行事), 케이스(case), 큰일, 탄막(彈幕), 학정(虐政), 한일합방(韓日合邦), 홈런(home run) </p>  #### 우발사건 <p class="message"> 골칫거리, 괴변(怪變), 교통체증(交通滯症), 교통혼잡(交通混雜), 국난(國難), 국상(國喪), 당첨(當籤), 데드볼(deadball), 돌출(突出), 들통, 망신(亡身), 모상(母喪), 범행(犯行), 변괴(變怪), 살인사건(殺人事件), 섹스스캔들(sex scandal), 쇄도(殺到), 수난(受難), 스캔들(scandal), 식량난(食糧難), 식수난(食水難), 우발(偶發), 이변(異變), 추문(醜聞), 출몰(出沒), 탄로(綻露), 해프닝(happening), 흉작(凶作) </p>  사고 <p class="message"> 객사(客死), 공중분해(空中分解), 교통난(交通難), 낙마(落馬), 낙상(落傷), 대란(大亂), 대형사고(大型事故), 대형참사(大型慘事), 도난(盜難), 사고(事故), 사산(死産), 실명(失明), 실족(失足), 실종(失踪), 우발사고(偶發事故), 의료사고(醫療事故), 자살극(自殺劇), 전몰(戰歿), 조난(遭難), 좌초(坐礁), 참변(慘變), 참사(慘事), 파란(波瀾), 화란(禍亂) </p>  (1) 유발사고 <p class="message"> 더위해(__害), 동사(凍死), 동파(凍破), 매몰(埋沒), 병화(兵火), 불상사(不祥事), 붕괴(崩壞), 산불(山_), 산재(産災), 수몰(水沒), 유실(流失), 전소(全燒), 화마(火魔), 화재(火災) </p>  (2) 고장 <p class="message"> 누수(漏水), 누전(漏電), 누출(漏出), 불통(不通), 빵꾸(puncture), 정전(停電), 합선(合線), 혼선(混線) </p>  (3) 교통사고 <p class="message"> 교통사고(交通事故), 난파(難破), 사각사고(死角事故), 접촉사고(接觸事故), 정면충돌(正面衝突), 추락(墜落), 침몰(沈沒), 탈선(脫線) </p>  사회갈등 <p class="message"> 거리낌, 결렬(決裂), 계급차별(階級差別), 공안사건(公安事件), 기묘사화(己卯士禍), 난리(亂離), 물의(物議), 민족문제(民族問題), 분규(紛糾), 분란(紛亂), 시위행진(示威行進), 정변(政變) </p>  (1) 사회동요 <p class="message"> 국란(國亂), 군란(軍亂), 군부쿠데타(軍部___), 내란(內亂), 동란(動亂), 명예혁명(名譽革命), 무장봉기(武裝蜂起), 민란(民亂), 반란(反亂), 변란(變亂), 산업혁명(産業革命), 소동(騷動), 소란(騷亂), 시민혁명(市民革命), 인종분규(人種紛糾), 전란(戰亂), 쿠데타(coup d'Etat), 투기과열(投機過熱), 폭동(暴動), 혁명(革命) </p>  (2) 사회운동 <p class="message"> 가두캠페인(街頭___), 거리시위(__示威), 노조파업(勞組罷業), 단식투쟁(斷食鬪爭), 데모(demo), 문화혁명(文化革命), 민족해방운동(民族解放運動), 반대운동(反對運動), 불매운동(不買運動), 서명운동(署名運動), 시민운동(市民運動), 장기파업(長期罷業), 장외투쟁(場外鬪爭), 저항운동(抵抗運動), 정치투쟁(政治鬪爭), 천막농성(天幕籠城), 철도파업(鐵道罷業), 철야농성(徹夜籠城), 철야집회(徹夜集會), 촛불시위(__示威), 촛불집회(__集會), 총파업(總罷業), 추모집회(追慕集會), 캠페인(campaign), 폭력시위(暴力示威) </p>  (3) 물리적 충돌 <p class="message"> 공중전투(空中戰鬪), 교전사태(交戰事態), 난투(亂鬪), 세계대전(世界大戰), 소탕전(掃蕩戰), 시가전(市街戰), 아귀다툼, 암투(暗鬪), 야전(夜戰), 양요(洋擾), 유격전(遊擊戰), 임진왜란(壬辰倭亂), 장기전(長期戰), 쟁탈(爭奪), 전면전(全面戰), 전쟁(戰爭), 전투(戰鬪), 종교전쟁(宗敎戰爭), 침략전쟁(侵略戰爭), 해전(海戰), 호란(胡亂) </p>  (4) 갈등상황 <p class="message"> 갈등요소(葛藤要素), 감정싸움(感情__), 계급투쟁(階級鬪爭), 내분(內紛), 노동쟁의(勞動爭議), 노사갈등(勞使葛藤), 당쟁(黨爭), 말썽, 불화(不和), 소작쟁의(小作爭議), 신경전(神經戰), 입시경쟁(入試競爭), 쟁의(爭議), 정쟁(政爭), 제소(提訴), 좌우갈등(左右葛藤), 중소논쟁(中蘇論爭), 지역갈등(地域葛藤), 파업(罷業) </p>  (5) 언어상의 충돌 <p class="message"> 악다구니 </p>  재해 <p class="message"> 액(厄), 재앙(災殃), 재액(災厄), 재해(災害), 천재지변(天災地變), 환난(患難), 환란(患難) </p>  (1) 기상관련 재해 <p class="message"> 가뭄, 냉해(冷害), 대진(大震), 된서리, 봄가물, 침수(沈水), 큰물, 태풍(颱風), 폭풍(暴風), 폭풍우(暴風雨), 폭풍해일(暴風海溢), 풍해(風害), 한해(旱害), 호우(豪雨), 홍수(洪水) </p>  (2) 지질학적 재해 <p class="message"> 강진(强震), 극진(劇震), 미진(微震), 범람(犯濫), 여진(餘震), 지변(地變), 지진(地震), 함락지진(陷落地震), 해일(海溢) </p>  (3) 전염병 <p class="message"> 괴질(怪疾), 뇌염(腦炎), 눈병(_病), 디프테리아(diphtheria), 신고전염병(申告傳染病), 에이즈(AIDS), 역병(疫病), 이질(痢疾), 전염(傳染), 전염병(傳染病), 콜레라(cholera), 페스트(pest), 풍진(風疹) </p>  피해 <p class="message"> 결손(缺損), 경상(輕傷), 도둑, 병충해(病蟲害), 부도(不渡), 불이익(不利益), 손실(損失), 손해(損害), 수해(水害), 이중고(二重苦), 인명피해(人命被害), 재난(災難), 적자(赤字), 충해(蟲害), 폐단(弊端), 폐해(弊害), 피해(被害), 해독(害毒), 해악(害惡) </p>  이익 <p class="message"> 광고효과(廣告效果), 국은(國恩), 당리(黨利), 대박(大舶), 부당이득(不當利得), 부당이익(不當利益), 수지(收支), 순이익(純利益), 실익(實益), 영리(營利), 이득(利得), 주가수익(株價收益), 폭리(暴利), 한몫 </p>  장애 <p class="message"> 삼중고(三重苦), 생활고(生活苦), 설화(舌禍), 수마(水魔), 어려움, 역경(逆境), 인권문제(人權問題), 장애(障碍), 차질(蹉跌) </p>  #### 계획사건 <p class="message"> 가제(家祭), 강좌(講座), 경품추첨(景品抽籤), 경품행사(競品行事), 고스톱(go-stop), 공직선거(公職選擧), 공판(公判), 국민경선(國民競選), 굿마당, 기념제(記念祭), 기우제(祈雨祭), 기제(忌祭), 노름판, 대선(大選), 리허설(rehearsal), 바자(bazar), 반장선거(班長選擧), 술판, 시뮬레이션(simulation), 야유회(野遊會), 연례행사(年例行事), 영감놀이(靈感__), 오락회(娛樂會), 오프닝(opening), 윷놀이, 응원전(應援戰), 이심(二審), 자녀교육(子女敎育), 조혼(早婚), 종강(終講), 쥐불놓이, 즉심(卽審), 즉위(卽位), 지방선거(地方選擧), 지신밟기(地神__), 지역경선(地域競選), 진실게임(眞實__), 집단소송(集團訴訟), 찬반투표(贊反投票), 총선(總選), 퀴즈(quiz), 토공(土工), 패권다툼(覇權_), 퍼레이드(parade), 핵심정리(核心整理), 행사(行事) </p>  식 <p class="message"> 개막식(開幕式), 결혼기념식(結婚記念式), 결혼식(結婚式), 공동결혼식(共同結婚式), 금혼식(金婚式), 기념식(記念式), 동신제(洞神祭), 동해안별신굿(東海岸別神_), 떡국차례(__茶禮), 모내기굿, 모내기놀음, 묘제(墓祭), 물꼬고사(__告祀), 미사(彌撒), 법회(法會), 송별회(送別會), 수여식(授與式), 시상식(施賞式), 식(式), 식전(式典), 영결식(永訣式), 영혼결혼식(靈魂結婚式), 오리엔테이션(orientation), 웨딩(wedding), 위령제(慰靈祭), 의례(儀禮), 의전(儀典), 임명식(任命式), 입장식(入場式), 졸업식(卒業式), 초상(初喪), 취임식(就任式), 할례(割禮), 합동결혼식(合同結婚式), 혼례(婚禮) </p>  잔치 <p class="message"> 가든파티(garden party), 가면무도회(假面舞蹈會), 댄스파티(dance party), 뒤풀이, 디너파티(dinner party), 리셉션(recption), 만찬(晩餐), 생일잔치(生日__), 소연(小宴), 송별연(送別宴), 수연(壽筵), 술자리, 야회(夜會), 연회(宴會), 이차(二次), 잔치, 축하회(祝賀會), 출판기념회(出版記念會), 파티(party), 피로연(披露宴), 향연(饗宴), 향응(饗應), 호화술자리(豪華___), 환갑잔치(還甲__), 회갑연(回甲宴) </p>  축제 <p class="message"> 영화제(映畵祭), 예술제(藝術祭), 운동회(運動會), 전야제(前夜祭), 제전(祭典), 축전(祝典), 축제(祝祭), 카니발(carnival), 학예회(學藝會) </p>  전시회 <p class="message"> 개인전(個人展), 박람회(博覽會), 엑스포(expo), 전람회(展覽會), 전시회(展示會), 취업박람회(就業博覽會), 패션쇼(fashion show) </p>  공연 <p class="message"> 관노가면극(官奴假面劇), 국극(國劇), 독주회(獨奏會), 리사이틀(recital), 마당극(__劇), 뮤지컬(musical), 발표회(發表會), 서커스(circus), 쇼(show), 스트립쇼(strip show), 연주회(演奏會), 음악회(音樂會), 초연(初演), 콘서트(concert), 퍼포먼스(performance), 희극(喜劇) </p>  모임/회의 <p class="message"> 대회(大會), 상고심(上告審), 시국강연회(時局講演會), 원심(原審), 인민재판(人民裁判), 자문회의(諮問會議), 조회(朝會), 채플(chapel), 총무회담(總務會談), 협의회(協議會), 회합(會合), 후보토론회(候補討論會) </p>  (1) 일반모임/회의 <p class="message"> 공개토론회(公開討論會), 공청회(公聽會), 공회(公會), 국민회의(國民會議), 국제대회(國際大會), 군사회담(軍事會談), 규탄대회(糾彈), 기자회견(記者會見), 막판협상(__協商), 사업설명회(事業說明會), 수뇌회담(首腦會談), 수련회(修練會), 실무회담(實務會談), 인사청문회(人事聽聞會), 임시총회(臨時總會), 전당대회(全黨大會), 전체회의(全體會議), 정상회담(頂上會談), 정상회의(頂上會議), 조찬회(朝餐會), 종례(終禮), 직원회의(職員會議), 청년회(靑年會), 청문회(聽聞會), 토론회(討論會), 파리강화회의(Paris____), 파리회의(Paris__), 합동토론회(合同討論會), 휴전회담(休戰會談) </p>  (2) 제도적모임/회의 <p class="message"> 각료회의(閣僚會議), 각의(閣議), 대책위원회(對策委員會), 신탁통치이사회(信託統治理事會), 운영위원회(運營委員會), 의원총회(議員總會), 이사회(理事會), 인사위원회(人事委員會), 정기국회(定期國會), 특위(特委), 평의회(評議會) </p>  (3) 학술모임/회의 <p class="message"> 강연회(講演會), 심포지엄(symposium), 야학(夜學), 연찬회(硏鑽會), 초청토론회(招請討論會), 포룸(forum), 학술강연회(學術講演會), 학술세미나(學術___) </p>  운동경기 <p class="message"> 경기대회(競技大會), 경마(競馬), 계주(繼走), 궁도(弓道), 권투(拳鬪), 당구(撞球), 던지기, 럭비(rugby), 마라톤(marathon), 마작(麻雀), 사격경기(射擊競技), 스케이팅(skating), 스파링(sparring), 시합(試合), 아이스하키(ice hockey), 어른씨름, 운동경기(運動競技), 이벤트(event), 자전거경기(自轉車競技), 장거리경주(長距離競走), 정구(庭球), 제로게임(zero game), 제자리높이뛰기, 조정(漕艇), 족구(足球), 줄다리기, 체스(chess), 축구(蹴球), 크리켓(cricket), 태권도(跆拳道), 태껸, 테니스(tennis), 투견(鬪犬), 투계(鬪鷄), 투우(鬪牛), 펜싱(fencing), 평균대운동(平均臺運動), 폴로(polo), 프로레슬링(prowrestling), 프로야구(pro__), 플레이(play) </p>  (1) 운동대회 <p class="message"> 가을운동회(__運動會), 고교연맹전(高敎聯盟戰), 동계올림픽(冬季___), 아시안게임(asian game), 올림픽(Olympics), 전국체전(全國體典), 체전(體典), 축구대회(蹴球大會), 환경올림픽(環境___) </p>  (2) 단계경기 <p class="message"> 결선(決選), 결승(決勝), 결승전(決勝戰), 예선(豫選), 준결승전(準決勝戰) </p>  (3) 단일경기 <p class="message"> 경식야구(硬式野球), 경주(競走), 길달리기, 농구(籠球), 높이뛰기, 단거리경주(短距離競走), 단축마라톤(短縮___), 도로경주(道路競走), 릴레이(relay), 멀리뛰기, 팔씨름 </p>  (4) 단위경기 <p class="message"> 연장전(延長戰), 판 </p>  시험 : 참여자의 당락을 정하는 계획사건 <p class="message"> 검정고시(檢定考試), 고등고시(高等考試), 고시(考試), 기말고사(期末考査), 기말시험(期末試驗), 논술시험(論述試驗), 대학입시(大學入試), 무게시험(__試驗), 무과(武科), 사법고시(司法考試), 수능시험(修能試驗), 수시모집(隨時募集), 실기시험(實技試驗), 심리테스트(心理___), 오디션(audition), 임용고사(任用考査), 임용고시(任用考試), 입시(入試), 입학시험(入學試驗), 초시(初試), 추가시험(追加試驗), 필기시험( 筆記試驗), 행시(行試) </p>  경연대회 : 참여자의 경쟁에 의해 순위를 결정짓는 계획사건 <p class="message"> 경시대회(競試大會), 국전(國展), 국제영화제(國際映畵祭), 미인대회(美人大會), 잼버리(jamboree), 콩쿠르(concours) </p>  ### 현상 <p class="message"> 간만(干滿), 거품, 격변화(格變化), 곡용(曲用), 교통(交通), 국가경제(國家經濟), 국민경제(國民經濟), 군사정권(軍事政權), 궁장식(宮裝飾), 권력균형(權力均衡), 그늘, 그림자, 길조(吉兆), 단풍(丹楓), 뜸, 말글일치(__一致), 망조(亡兆), 물결, 밀물, 바운드(bound), 발광(發光), 발산(發散), 본영(本影), 부작용(副作用), 불꽃스펙트럼(__spectrum), 상승효과(相乘效果), 소음공해(騷音公害), 수소손상(水素損傷), 수질오염(水質汚染), 신기루(蜃氣樓), 악순환(惡循環), 연쇄(連鎖), 영속(永續), 영조(映照), 용출(湧出), 우연발생(偶然發生), 유무(有無), 유착(癒着), 유통(流通), 유행(流行), 윤택(潤澤), 이합집산(離合集散), 조응(照應), 중복(重複), 증후(證候), 징조(徵兆), 징후(徵候), 착시(錯視), 풍조(風潮), 현상(現象), 횡행(橫行), 히트(hit) </p>  #### 빛 **빛**이란 빛, 햇빛, 햇볕, 달빛, 불빛, 광선, 전등불, 반딧불, 초롱불, 폭양 따위를 가리킵니다. <p class="message"> 광명(光明), 광배(光背), 광선(光線), 광채(光彩), 광택(光澤), 광휘(光輝), 극광(極光), 낙조(落照), 노을빛, 달빛, 미광(微光), 반딧불, 볕, 불볕, 불빛, 빛, 산광(散光), 서광(曙光), 섬광(閃光), 성광(星光), 스펙트럼(spectrum), 스포트라이트(spotlight), 실내조명(室內照明), 안광(眼光), 역광(逆光), 월광(月光), 윤(潤), 일광(日光), 자외선(紫外線), 조명(照明), 직사광선(直射光線), 촉광(燭光), 폭양(曝陽), 형광(螢光), 황혼(黃昏) </p>  #### 불 <p class="message"> 광염(狂炎), 난롯불, 담뱃불, 등걸불, 모닥불, 무화(武火), 봉화(烽火), 불, 불길, 불꽃, 불똥, 열화(烈火), 촛불, 포화(砲火), 화염(火焰), 횃불 </p>  #### 냄새 **냄새**란 후각을 통해 지각할 수 있는 것을 가리킵니다. <p class="message"> 고린내, 구취(口臭), 군내, 냄새, 비린내, 새물내, 악취(惡臭), 젖비린내, 지린내, 체취(體臭), 향기(香氣), 향내(香_), 향취(香臭) </p>  #### 연기 **연기**란 무생물의 기체와는 달리 생성과 소멸이 시각으로 지각 가능한 기체 관련 현상입니다. <p class="message"> 김, 담배연기(__煙氣), 뒷전소용돌이, 배기(排氣), 스팀(steam), 연기(煙氣), 연막(煙幕), 포연(砲煙) </p>  #### 자연현상 <p class="message"> 간조(干潮), 발기(勃起), 쌍무지개(雙___), 아지랑이, 아지랭이, 어스름, 유동(流動), 으스름, 자정작용(自淨作用), 한재(旱災) </p>  기상현상 <p class="message"> 가물, 감로(甘露), 결빙(結氷), 극기후(極氣候), 기상이변(氣象異變), 낙뢰(落雷), 노을, 뇌성벽력(雷聲霹靂), 단지날씨(團地__), 땅거미, 무지개, 백야(白夜), 번개, 벼락, 벽력(霹靂), 비바람, 스모그(smog), 온실효과(溫室效果), 우레, 우박(雨雹), 운무(雲霧), 일사(日射), 저녁노을, 저녁놀, 천둥, 천둥번개, 풍상(風霜), 풍우(風雨), 풍운(風雲), 한기(寒氣), 화풍감우(和風甘雨) </p>  (1) 강우 <p class="message"> 강우(降雨), 뇌우(雷雨), 비, 빗줄기, 산성비(酸性_), 소나기, 억수, 이슬비, 인공강우(人工降雨), 집중호우(集中豪雨), 찬비 </p>  (2) 강설 <p class="message"> 강설(降雪), 눈보라, 자국눈, 적설(積雪), 진눈깨비, 폭설(暴雪), 폭풍설(暴風雪) </p>  (3) 바람 <p class="message"> 가을바람, 강풍(强風), 겨울바람, 광풍(狂風), 꽃샘바람, 남동풍(南東風), 남풍(南風), 높새바람, 늦바람, 돌풍(突風), 동풍(東風), 마파람, 맞바람, 몽고바람(蒙古__), 바람, 북풍(北風), 삭풍(朔風), 서남풍(西南風), 순풍(順風), 열풍(烈風), 장풍(掌風), 제트기류(jet__), 질풍(疾風), 찬바람, 청풍(淸風), 춘풍(春風), 편서풍(偏西風), 하늬바람, 해풍(海風), 허리케인(hurricane), 회오리, 훈풍(薰風) </p>  (4) 안개 <p class="message"> 안개, 이내 </p>  (5) 구름 <p class="message"> 구름, 뜬구름, 먹구름, 뭉게구름, 삿갓구름, 안개구름, 운해(雲海), 조각구름 </p>  (6) 대기 <p class="message"> 고기압(高氣壓), 기류(氣流), 난기류(亂氣流), 냉기류(冷氣流), 대기(大氣), 아열대고기압(亞熱帶高氣壓), 아열대저기압(亞熱帶低氣壓) </p>  (7) 날씨 <p class="message"> 날씨, 더위, 무더위, 삼한사온(三寒四溫), 악천후(惡天候), 우천(雨天), 장마, 찜통더위, 천기(天氣), 추위, 폭염(暴炎), 폭한(暴寒), 한랭(寒冷), 한발(旱魃), 한파(寒波), 혹서(酷暑), 혹한(酷寒) </p>  천문현상 <p class="message"> 감광(減光), 오로라(aurora), 월식(月蝕), 일몰(日沒), 일출(日出), 자전(自轉), 천문(天文), 태양계운동(太陽系運動), 항성정오(恒星正午), 해돋이 </p>  지질현상 <p class="message"> 경진(輕震), 습곡(褶曲), 유감지진(有感地震), 퇴적(堆積), 풍화(風化) </p>  물리화학현상 <p class="message"> 감전(感電), 고체화(固體化), 공기오염(空氣汚染), 교류(交流), 굴절(屈折), 금지전이(禁止轉移), 기화(氣化), 대류(對流), 마모(磨耗), 마스크효과(mask__), 마찰(摩擦), 면적속도(面積速度), 바닥상태(__狀態), 반동(反動), 반사(反射), 발화(發火), 방전(放電), 불꽃방전(__放電), 비등(沸騰), 삼투(渗透), 소수결합(疏水結合), 액화(液化), 양성반응(陽性反應), 역반응(逆反應), 연소(燃燒), 열복사(熱輻射), 염화(鹽化), 유도결합(誘導結合), 유입(流入), 융합(融合), 융해(融解), 응결(凝結), 응고(凝固), 응집(凝集), 자극(刺戟), 중합(重合), 증류(蒸溜), 초전기전도(超電氣傳導), 탄화(炭化), 통풍(通風), 투과(透過), 투사(投射), 투영(投影), 팽창(膨脹), 폭발(暴發|爆發), 화합(化合), 환류(還流), 휘발(揮發) </p>  생물생리현상 <p class="message"> 가지돌연변이(__突然變異), 결실(結實), 경직(硬直), 고사(枯死), 과민반응(過敏反應), 급사(急死), 길몽(吉夢), 꽃눈분화(__分化), 내분비(內分泌), 노화(老化), 도태(淘汰), 돌연변이(突然變異), 돼지꿈, 들숨날숨, 마비(痲痺), 맥(脈), 맥박(脈搏), 면역(免疫), 무조건반사(無條件反射), 물질교대(物質交代), 물질교환(物質交換), 박동(搏動), 발모(發毛), 발아(發芽), 발암(發癌), 발육(發育), 발정(發情), 발한(發汗), 백화(白化), 번식(繁殖), 변이(變異), 변태(變態), 부패(腐敗), 부화(孵化), 분비(分泌), 불완전탈바꿈(不完全___), 산란(産卵), 생물계절(生物季節), 생육(生育), 생장(生長), 생태변화(生態變化), 성징(性徵), 세포분열(細胞分裂), 소름, 소화작용(消化作用), 신진대사(新陳代謝), 아사(餓死), 약물알레르기(藥物____), 양눈대비(兩_對比), 양눈시차(兩_視差), 염색체돌연변이(染色體突然變異), 영락(零落), 월경(月經), 자연도태(自然淘汰), 조건반사(條件反射), 조숙(早熟), 조음(調音), 주변성장(周邊成長), 중독(中毒), 진화(進化), 착상(着床), 초기증상(初期症狀), 탈모(脫毛), 탈바꿈, 털갈이, 트림, 피부질환(皮膚疾患), 하혈(下血), 혈류(血流), 화아분화(花芽分化), 흡수(吸水) </p>  기운 : 인간이 체감할 수 있는 온도 및 계절 관련 현상 <p class="message"> 누기(漏氣), 독기(毒氣), 바람기(__氣), 불기운(_氣運), 술기운, 습기(濕氣), 열기(熱氣), 온기(溫氣), 음기(陰氣), 취기(醉氣), 훈기(薰氣) <p class="message">  물관련현상 <p class="message"> 격랑(激浪), 급류(急流), 난류(暖流), 노도(怒濤), 놀, 만조(滿潮), 물거품, 물보라, 발원(發源), 소용돌이, 수포(水泡), 썰물, 여파(餘波), 역류(逆流), 파도(波濤), 파동(波動), 파문(波紋), 풍랑(風浪), 풍파(風波), 해류(海流), 흐름 </p>  #### 인간관련현상 <p class="message"> 공론(公論), 르네상스(르네상스), 반향(反響), 붐(boom), 사레, 사회현상(司會現狀), 선풍(旋風), 센세이션(sensation), 소외현상(疎外現象), 언문일치(言文一致), 주민참여(住民參與), 지방분권(地方分權), 청년실업(靑年失業), 취직난(就職難) </p>  경제현상 <p class="message"> 가격인상(價格引上), 가격자유화(價格自由化), 거시금융(巨視金融), 경제대공황(經濟大恐慌), 경제문제(經濟問題), 경제성장(經濟成長), 고용안정(雇傭安定), 과열경기(過熱景氣), 국가부도(國家不渡), 군수인플레이션(軍需_____), 급등세(急騰勢), 내수(內需), 대공황(大恐慌), 디플레이션(deflation), 물가상승(物價上昇), 물가안정(物價安定), 불황(不況), 수급(需給), 은행쇄도(銀行殺到), 이상생리(利上生利), 인플레(inflation), 인플레이션(inflation), 자금거래(資金去來), 자금난(資金難), 재정난(財政難), 절하(切下), 중간경기(中間景氣), 중농표준화(中農標準化), 투자(投資), 특수(特需), 하락세(下落勢), 학력인플레(學力___), 흑자(黑字) </p>  소문 : 인간의 의사소통을 나타내는 명사들 중 사건적 의미를 지닌 것 <p class="message"> 괴담(怪談), 낭설(浪說), 부언(浮言), 소문(所聞), 염문(艶聞), 풍문 </p>  #### 소리 **소리**란 언어행위 외의 소리를 가리킵니다. <p class="message"> 가성(假聲), 경보(警報), 고고(呱呱), 고성(高聲), 고음(高音), 고함(高喊), 고함소리(高喊__), 괴성(怪聲), 굉음(轟音), 기성(奇聲), 기적(汽笛), 기척, 노랫소리, 뇌성(雷聲), 말소리, 메아리, 목소리, 물소리, 발자국소리, 배음(倍音), 불협화음(不協和音), 비명(悲鳴), 빗소리, 사운드(sound), 사이렌(siren), 산울림(山__), 성음(聲音), 소리, 소음(騷音), 쇳소리, 숨소리, 시보(時報), 식도음성(食道音聲), 신음소리(呻吟__), 아우성(__聲), 악음(樂音), 언성(言聲), 옥타브(octave), 외마디, 외침, 울림, 울음소리, 웃음소리, 원성(怨聲), 원음(原音), 음(音), 음률(音律), 음성(音聲), 음악소리(音樂__), 음향(音響), 잡음(雜音), 저음(低音), 종소리(鐘__), 중음(中音), 차량소음(車輛騷音), 청음(淸音), 총성(銃聲), 총소리(銃__), 큰소리, 탄성(歎聲), 테너(tenor), 통화대기음(通話待機音), 통화연결음(通話連結音), 팡파르(팡파르), 포성(砲聲), 폭소(爆笑), 폭음(爆音), 환성(歡聲), 환호성(歡呼聲) </p>  ### 상태변화 <p class="message"> 감마(減磨), 감염(感染), 감화(感化), 개과천선(改過遷善), 격동(激動), 격변(激變), 격앙(激昻), 경과(經過), 경화(硬化), 곡절(曲折), 과학혁명(科學革命), 급선회(急旋回), 기복(起伏), 기절(氣絶), 긴장완화(緊張緩和), 낙후(落後), 다원화(多元化), 대기오염(大氣汚染), 돌발(突發), 돌변(突變), 두절(杜絶), 둔화(鈍化), 드러남, 득세(得勢), 등락(騰落), 만개(滿開), 만발(滿發), 매진(賣盡), 박살, 부익부(富益富), 분출(噴出), 불발(不發), 성쇠(盛衰), 성숙(成熟), 성장(成長), 성회(成會), 숙성(熟成), 승승장구(乘勝長驅), 승화(昇華), 시발(始發), 신분상승(身分上昇), 실효(失效), 악화(惡化), 얼개화(_開化), 영고(榮枯), 오염(汚染), 완숙(完熟), 움직임, 유(有), 융기(隆起), 이화(異化), 일순(一巡), 작동(作動), 적화(赤化), 전면백지화(全面白紙化), 점진(漸進), 조로(早老), 진전(進展), 진척(進陟), 진흥(振興), 추이(推移), 침식(侵蝕), 침윤(浸潤), 파급(波及), 편의사항(便宜事項), 함몰(陷沒), 합류(合流), 항성진화(恒星進化), 항진(亢進), 향락풍조(享樂風潮), 홍조(紅潮), 환장(換腸), 회귀(回歸), 회복(回復), 후생(厚生) </p>  #### 증가 <p class="message"> 강화(强化), 격상(格上), 격증(激增), 고속성장, 과열(過熱), 급등(急騰), 급상승(急上昇), 급증(急增), 기하급수(幾何級數), 등귀(騰貴), 반등(反騰), 번성(蕃盛), 상승(上昇), 앙등(仰騰), 오름, 장진(長進), 절상(切上), 점증(漸增), 제고(提高), 증가(增加), 증가세(增加勢), 증대(增大), 증산(增産), 증식(增殖), 증액(增額), 증원(增員), 증자(增資), 증진(增進), 증차(增車), 증폭(增幅), 창궐(猖獗), 천정부지(天井不知), 체화(滯貨), 초과(超過), 침전(沈澱), 폭등(暴騰), 폭주(輻輳), 향상(向上), 확산(擴散), 활성(活性) </p>  #### 감소 <p class="message"> 감소(減少), 거덜, 격감(激減), 격하(格下), 경감(輕減), 급강하(急降下), 급락(急落), 소진(消盡), 쇠락(衰落), 쇠잔(衰殘), 쇠퇴(衰退), 수축(收縮), 실추(失墜), 약화(弱化), 요금인하(料金引下), 위축(萎縮), 저하(低下), 전락(轉落), 침하(沈下), 폭락(暴落), 하강(下降), 하강속도(下降速度), 하락(下落), 하향(下向), 해열(解熱) </p>  #### 유동 <p class="message"> 증감(增減), 흥망(興亡) </p>  #### 전이 <p class="message"> 갱소년(更少年), 급변(急變), 급진(急進), 동결(凍結), 매달작용(媒達作用), 민주화(民主化), 반전(反轉), 발로(發露), 변동(變動), 변모(變貌), 변색(變色), 변성(變聲), 변용(變容), 변질(變質), 변천(變遷), 변화(變化), 변환(變換), 복고(復古), 분화(分化), 산업화(産業化), 어미변화(語尾變化), 역전(逆轉), 영화화(映畵化), 일변(一變), 전이(轉移), 증발(蒸發), 지구촌화(地球村化), 집중화(集中化), 천이(遷移), 통일(統一), 퇴색(退色), 퇴행(退行) </p>  #### 생성 <p class="message"> 격발(激發), 대두(擡頭), 등장(登場), 발동(發動), 발발(勃發), 발병(發病), 발생(發生), 발연(發煙), 발족(發足), 발현(發現), 발흥(勃興), 생성(生成), 성립(成立), 속발(續發), 속출(續出), 파생(派生) </p>  #### 소멸 <p class="message"> 결딴, 괴멸(壞滅), 마멸(磨滅), 멸망(滅亡), 멸족(滅族), 멸종(滅種), 사라짐, 상쇄(相殺), 소멸(消滅), 쇠망(衰亡), 와해(瓦解), 전멸(全滅) </p>  #### 종료 <p class="message"> 절판(絶版), 절품(切品), 종식(終熄), 종언(終焉) </p>  #### 변형 <p class="message"> 천지개벽(天地開闢), 해동(解凍) </p>  #### 악화 <p class="message"> 부식(腐蝕), 심각화(深刻化), 잠식(蠶食), 저해(沮害), 퇴화(退化), 황폐(荒廢) </p>  #### 개선 <p class="message"> 문명개화(文明開化), 발달(發達), 방한(防寒), 번영(繁榮), 번창(繁昌), 부활(復活), 부흥(復興), 완쾌(完快), 인권신장(人權伸張), 진보(進步), 진일보(進一步), 쾌유(快癒), 호전(好轉), 회생(回生), 회춘(回春) </p>
noun␞ 이번 글에서는 **명사(Noun)**와 관련된 여러 개념들을 살펴보도록 하겠습니다. 이번 글은 경희대 이선웅 교수님 강의와 표준국어문법론을 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 명사의 정의 학교문법에 따르면 명사는 일반적으로 사물의 이름을 가리키는 품사입니다. 명사 검증 기준으로 흔히 사용되는 것은 '무엇이 무엇이다, 무엇이 어찌한다, 무엇이 무엇을 어찌한다'의 틀에 나타나는 '무엇'의 자리를 채울 수 있느냐는 겁니다. 이는 바로 **기능(function)**에 초점을 맞춘 기준이라고 할 수 있겠습니다. 명사의 예는 아래와 같습니다. > **유정명사** : 아버지, 철수, 사람, 개, 고양이, 여우... > > **무정명사** : 꽃, 풀, 진달래, 돌, 바위, 책상... > > **현상** : 아침, 낮, 바람, 노을, 번개... > > **추상적 개념** : 민주주의, 개념, 명제... 아래 예시와 같이 **동작성**, **상태성**의 의미를 지니는 명사들도 있습니다. 대부분 '하다'와 어울려 동사, 형용사로 기능합니다. 이와 관련 자세한 내용은 후술한 **술어명사** 챕터를 참고하시기 바랍니다. > **동작성** : 입학, 독립, 합류, 희망, 일출... > > **상태성** : 곤란, 성실, 신성, 공평, 무한... 이후 설명은 문법적으로 이해하기 까다로운 명사 개념들 소개한 내용입니다.  ## 의존명사, 형식명사 학교문법에 따르면 의존명사는 관형어의 선행을 필수적으로 요구하는 명사를 가리킵니다. 예컨대 아래와 같습니다. > \***이**가 온다. (다른 **이**가 온다) > > \***분**을 공경해야 한다. (저 **분**을 공경해야 한다) 20세기 후반의 국어학 연구에서는 의존명사의 **의미적 추상성/형식성**에 초점을 맞췄습니다. 의존명사의 의미가 추상적/형식적이어서 실제 문맥에서 자립적으로 실현되지 못하고, 반드시 의미를 제한/보충하여 주는 선행 요소에 의존하여서만 문맥에 나타나는 특성을 지니기 때문입니다. 예컨대 아래와 같습니다. > (ㄱ) 갈 **데**가 없다. > > (ㄴ) 그 책을 다 읽는 **데** 3일 걸렸다. > > (ㄷ) 머리 아픈 **데** 먹는 약 > > (ㄹ) 내가 준 **것**을 아직도 갖고 있니? > > (ㅁ) 그가 고백한 **것**을 아직도 기억하고 있니? (ㄱ)의 '데'는 본래 장소를 뜻하는 말이지만 (ㄴ)과 (ㄷ)에서 그 의미가 매우 추상적으로 확대되었습니다. (ㄹ)의 '것'은 본래 구체적 대상을 뜻하는 말이지만 (ㅁ)에서는 추상적 대상을 가리킵니다. 이렇듯 의존명사는 선행 요소에 의존적이면서도 그 의미가 추상적이거나 형식적입니다. 그러나 아래 같은 예들이 있어 분석에 주의를 기울여야 합니다. > (a) 3개월 이내에 소득 신고를 하지 않은 **자(者)** > > (b) 그가 거짓말을 했기 **때문**에 > > (c) 세 살 **또래**의 어린이가 가장 다루기 어렵다. > > (d) 요즘 같은 세상에 아버지 **노릇**을 제대로 하기란 쉽지 않다. > > (e) 강경 **일변도**의 정책 > > (f) 내수를 진작한다는 **미명**하에 > > (g) 추상적 사고의 **소산** 위에서 예로 든 의존명사들은 모두 구체적인 의미를 지니고 있습니다. '자'는 사람, '때문'은 이유, '또래'는 그 정도의 나이, '노릇'은 구실/역할 등을 뜻합니다.  따라서 아래와 같이 구분할 필요가 있습니다. > **형식명사** : 의미가 추상적/형식적이면서도 통사적으로 의존적인 명사, 주로 고유어 계통 (예 : '데', '것') > > **의존명사** : 의미가 구체적이지만 통사적으로는 의존적인 명사, 주로 한자어 계통 (예 : '자', '때문', '또래', '노릇', '일변도', '미명', '소산')  ## 부접명사 **부접명사(附接名詞)**란 무표지 명사구를 보충어로 반드시 요구하며 그에 직접 결합하는 의존명사의 한 부류를 가리킵니다. 예를 들면 아래와 같습니다. > (1) 검찰(의) 발표 > > (2) 국문과(\*의) 출신 > > (3) 빠른 선수 위주(爲主) > > (4) \*너는 위주가 무엇이냐? > > (5) 시험(\*의) 걱정 > > (6) 그 사람은 늘 걱정이 많다. 일반적으로 '명사+명사' 결합에서는 중간에 속격조사 '-의'를 삽입하는 것이 가능합니다. (1)처럼 '검찰 발표', '검찰의 발표' 둘 다 맞는 표현입니다.  하지만 (2)에서는 '-의'를 넣으면 비문이 됩니다. '출신'이라는 명사는 '국문과'라는 명사(구)를 보충어로 반드시 요구하면서 그에 직접 결합하기 때문에 부접명사로 분류할 수 있습니다.  (3)과 (4)에서 '위주'는 선행 명사구(빠른 선수) 없이 자립적으로 쓰일 수 없고 선행 명사구와 직접 결합하고 있음을 알 수 있습니다. 따라서 '위주'는 부접명사입니다.  (5)에선 '걱정'이 의존적이지만 (6)에서는 자립적으로 쓰였습니다. 따라서 '걱정'은 부접명사로 분류할 수 없습니다.  ## 술어명사 **술어명사(predicative noun)**는 사건, 행위, 상태 등 의미를 지니는 명사를 뜻합니다. 예컨대 '사랑', '답변'은 대표적인 술어명사입니다. 그런데 술어명사는 동사나 형용사처럼 **논항**이 대체로 필요합니다. 논항이란 문장에서 문법적으로 중심 역할을 하는 **핵**이 요구하는 필수 성분을 말합니다. 아래 표를 볼까요?  | 구분 |   (가)   |     (나)     | | :--: | :----------: | :-----------------: | | 1  | 철수의 영희 사랑  | 정부의 야당 질문에 대한 답변  | | 2  | 철수가 영희를 사랑한다 | 정부가 야당 질문에 대해 답변하였다 | 위 표에서 1행과 2행은 같은 의미를 지닙니다. (가)-2의 경우 '사랑하다'는 동사의 **논항**은 행위주 '철수', 대상역 '영희'로 실현돼 있습니다. (가)-1에서 '사랑'이라는 명사의 논항은 (가)-2와 마찬가지로 '철수'와 '영희'입니다.  (나)-2의 경우 '답변하다'는 동사의 논항은 행위주 '정부', 대상역 '야당 질문'으로 실현돼 있습니다. (나)-1에서 '답변'이라는 명사의 논항은 (나)-2와 마찬가지로 '정부', '야당 질문'입니다. 술어명사의 큰 특징 가운데 하나는 위 표에서처럼 술어명사의 논항이 그에 대응하는 용언 서술어가 형성하는 문장의 논항과 일치한다는 점입니다. 한국어 술어명사의 대부분은 논항을 요구합니다. 이러한 부류의 다른 예로는 '건강', '공부', '운동', '여행' 등이 있습니다.  물론 그 수는 작지만 예외가 있기는 합니다. 다시 말해 논항을 요구하지 않는 술어명사도 있다는 것입니다. 예를 들어보겠습니다. > 비가 그친 후 출발하자. '비'는 두 가지 의미가 있습니다. '하늘에서 떨어진 물방울'이라는 **실체**와 '물방울이 하늘에서 떨어짐'이라는 **사건**을 나타낸다는 것이죠. 위 예문의 '비'는 사건에 가까운 의미일 겁니다. 그런데 '비'는 일반적인 술어명사와 달리 행위주, 대상역 등 논항을 필요로 하지 않습니다. 이러한 부류의 예로는 '눈', '천둥', '번개' 등이 있습니다.  논항을 요구하지 않는 술어명사의 또 다른 예를 들어보겠습니다. | 구분 |     (A)     |     (B)     | | :--: | :------------------: | :-------------------: | | 1  | 철수는 일을 마친 후 바로 귀가하였다 | 영희는 시험을 보는 도중에 잠이 들었다 | | 2  | \*철수의 일 도중에 영희가 찾아왔다 | \*영희의 시험 중에 철수가 들어왔다 | 위 예시에서 '일'과 '시험'은 사건성, 행위성을 확인할 수 있지만 논항을 요구하지 않습니다. 행위주 논항이 실현된 명사구 '철수의 일 도중', '영희의 시험 중'은 되레 비문이 됐다는 사실을 확인할 수 있습니다.  이선웅(2012)은 술어 성격을 지니는 명사를 술어명사라고 규정하는데요. 그는 술어를 아래와 같이 정의합니다. >**술어(predicator)**란 논항구조를 가지거나 상적특성을 지니면서 사건, 행위, 상태 등의 의미적 실체를 나타내는 언어 형식이다. 동일한 명사가 술어명사와 **결과명사** 두 역할 모두 하는 경우도 있습니다. 사건 표현에 방점을 두고 있다면 술어명사, 사건/행위의 결과 표현에 강조점이 있다면 결과명사로 분류되는 식입니다. 예를 들어보겠습니다. > (1) **술어명사** : **결정** 후 생각해 보자. > > (2) **결과명사** : 국민들은 정부의 **결정**에 격노하였다. 정희정(2000)은 '결정'이라는 명사는 '결정하는 행위(술어명사)'와 '결정한 내용(결과명사)'의 뜻을 가진 다의어로 규정했습니다. 다시 말해 (1)처럼 행위에 방점이 찍혀 있어야만 술어명사로 분류할 수 있다는 겁니다. 마지막으로 술어명사의 논항에 대해 한 가지 더 살펴보겠습니다. 아래 예를 볼까요? > (a) 미국의 이라크 공격 > > (b) 이라크의 공격 > > (c) 향가의 연구 > > (d) 그 사람의 생각 (a)에서 행위주는 미국, 대상은 이라크입니다. (b)에서 행위주는 이라크입니다. 별로 헷갈리지 않죠. 그런데 (c)와 (d)를 보면 알쏭달쏭해집니다. (c)에서 '향가'는 행위주로 읽히지 않습니다. 한국어를 모국어로 쓰는 화자라면 대부분 향가를 대상으로 인식할 겁니다. 반대로 (d)의 '그 사람'은 행위주로 읽힙니다. (b), (c), (d)는 명사+'-의'+명사로 동일한 형태인데 문법적으로는 각기 다른 의미를 내포하고 있습니다. 통사 구조가 공격, 연구, 생각이라는 개별 어휘에 영향을 받고 있다는 이야기입니다.  ## 명사 핵의 범위 문장을 만드는 동사와 달리 명사는 명사구를 만들 뿐입니다. 다시 말해 명사가 영향을 끼칠 수 있는 문법적 최대 단위가 명사구라는 이야기이죠. 예를 들어보겠습니다. > (1) 철수가 강아지를 대단히 **사랑한**다. > > (2) 철수의 강아지 **사랑**은 대단하다. 동사 '사랑하-'는 (1) 문장 전체에 문법적인 영향을 끼칩니다. 하지만 술어명사 '사랑'은 그 영향력이 명사구에 한정돼 있습니다. (2)의 '철수의 강아지 사랑'처럼 명사의 논항이 실현된 명사구를 **복합명사구(complex noun phrase)**라고 합니다.  ## 분류사와 한국어 수량표현 **분류사(classifier)**란 어떤 명사의 특정 의미자질 혹은 문법자질을 범주화하여 가리키는 언어형식을 통칭하는 말입니다. Aikhenvald(2000)는 명사 분류사(noun classifier), 수량 분류사(numeral classifier) 등으로 나누어 분류하고 있습니다. 여기에서 명사 분류사는 그 분류사가 표시하는 성(sex), 유정성(animacy), 인간성(humanness) 등의 범주로 나뉩니다. 한국어에서는 **단위명사**가 분류사에 해당합니다. 한국어의 분류사는 부류화보다는 수량화의 기능이 더 크다고 합니다. 예를 들어보겠습니다. > 행인 한 사람 > > 개 두 마리 위 예시에서 '사람', '마리'는 각각 사람, 동물의 의미 부류를 가리키는 기능을 하고 있는 걸 알 수 있습니다. 뿐만 아니라 둘 모두 수량을 나타내고 있습니다. 박진호(2011)는 수량 분류사를 **단위사(unitizer)**로 부르는데요. 그가 규정한 단위사 종류는 아래와 같습니다. > 가. 수 단위사 (count unitizer) > > ㄱ. 개체 단위사 (entity unitizer) : 개, 명, 마리, 그루, 송이, 대, 장, 자루 > > ㄴ. 집합 단위사 (group unitizer) : 켤레, 다스, 톳, 손 > > ㄷ. 사건 단위사 (event unitizer) : 번, 차례, 회, 바퀴, 순배, 판 > > 나. 양 단위사 (mass unitizer) > > ㄱ. 용기 단위사 (container unitizer) : 잔, 병, 컵, 그릇, 숟가락 > > ㄴ. 도량형 단위사 (measuring unitizer) : 미터, 킬로그램, 리터 한국어 수량표현의 종류는 크게 네 가지입니다. 아래와 같습니다. > (1) **명사 + 수사** : 학생 셋 > > (2) **명사 + 수관형사(수사) + 단위 명사** : 학생 세 명 > > (3) **수관형사(수사) + 명사** : 세 학생 > > (4) **수관형사(수사) + 단위명사 + '-의' + 명사** : 세 명의 학생 한국어에선 수량표현을 하는 명사구가 부사구처럼 자리를 자유롭게 바꿀 수 있습니다. 이를 **양화사 유동**이라고 합니다. 예를 들어보겠습니다. > 나는 맥주를 **세 병** 마셨다. / 나는 **세 병** 맥주를 마셨다. > > **셋이** 학생이 왔다. / 학생이 **셋이** 왔다.  위 구문은 사실 이중목적어/이중주어 구문으로 이해할 수도 있습니다. 그런데 일반적인 이중목적어/이중주어 구문과 달리 전체/부분 등의 관계로 설명할 수 없어서, 국어학자들은 **동격 구문**이라는 설명을 하고 있습니다. 한국어 수량표현엔 고유어와 한자어 두 가지 종류가 있습니다. 그런데 실생활에선 혼용해서 쓰고 있어서 일반적인 규칙으로 만들기가 까다롭습니다. > **열(고유어)**시 **십(한자어)**분 **십(한자어)**초 > > **일** 더하기 **이**는 **삼** > > **이십구**명 / **일곱**명 > > **칠십팔**세 / **일흔여덟**살  ## 대명사 대명사의 의미적 특징으로 **직시(直示)**와 **대용(代用)**을 꼽을 수 있습니다. 직시란 발화가 이뤄지는 상황에서 지시의 의미가 드러나는 걸 뜻하고, 대용이란 선행 언어형식이 의미하는 실체나 상황을 가리키는 걸 말합니다. 다시 말해 직시는 텍스트 외적지시, 대용은 내적지시에 해당합니다. 예를 들어보겠습니다. > (가) **직시** : (가방을 보면서)**이거** 어디서 샀니? > > (나) **대용** : 나도 어제 가방을 하나 샀어. **그것**을 가져 갈까? (가)에서 '가방'은 명시적으로 언급된 적이 없지만, 청자는 발화가 이뤄지는 상황에서 '이거'가 뜻하는 사물이 '가방'이라는 점을 충분히 인지할 수 있습니다. 반대로 (나)에서 화자는 청자가 구입한 가방을 본 적은 없지만, '그것'이 뜻하는 사물이 가방이라는 점을 알 수 있습니다. 이선웅(2012)의 대명사 분류 표는 아래와 같습니다.  <a href="http://imgur.com/Y1e3AeH"><img src="http://i.imgur.com/Y1e3AeH.png" width="300px" title="source: imgur.com" /></a> 위 표에서 **부정(不定, indefinite)** 개념에 대해 살펴보겠습니다. 지시대상이 불명확하거나, 불명확하게 표현하는 경우를 뜻합니다. 예를 들어보겠습니다. > (ㄱ) (어둠 속에서 물건을 찾다가) 여기 **뭐**가 만져지네? > > (ㄴ) (피자를 먹으며 전화통화) 응, **뭐** 좀 먹고 있어. (ㄱ)의 경우 화자도 청자도 지시하는 대상을 명확하게 인식하지 못하는 상황이고, 그 표현도 불명확하게 이뤄졌습니다. (ㄴ)의 경우 화자는 지시하는 대상(피자)을 명확하게 알고 있지만, 그 표현만 부정칭으로 하고 있습니다. (ㄱ), (ㄴ) 모두 부정칭이라고 말할 수 있습니다.  ## 재귀표현 한국어는 대명사 사용을 기피하는 경향이 큰 언어입니다. 한국어 명사는 대체로 그대로 재귀표현으로 사용할 수 있습니다. > 저희 할아버지는 **할아버지** 시대 얘기만 하세요. 위 문장에서 '할아버지'는 재귀대명사가 아닌데도 재귀대명사처럼 쓰였습니다. 이선웅(2012)는 아래와 같이 규정했습니다. > 한국어의 재귀표현에는 재귀대명사와 선행 명사 반복이 있다. 후자의 경우는 선행 명사의 지시물이 화자보다 높은 대상일수록 문법성이 좋아진다. 재귀대명사에도 높임의 등급이 있습니다. 예를 들어보겠습니다. > (1) 저희 할아버지는 **당신** 시대 얘기만 하세요. > > (2) **당신**은 누구요? > > (3) 언니는 **자기** 생각밖에 안 해요. > > (4) 언니는 **지(저)** 생각밖에 안 해요. '당신'은 3인칭 재귀대명사로 쓸 때는 극존대 의미를 갖지만, 2인칭일 때는 상대방을 낮춰 부르는 효과를 냅니다. '저'는 3인칭 상대방을 낮춰 부를 때 씁니다. 마지막으로 3인칭대명사와 재귀대명사와의 관계를 살펴보겠습니다. 예를 들어보겠습니다. > (A) 철수는 **{그의, 자기}** 형이 변호사이다. > > (B) 철수는 **{\*그, 자기}**가 직접 선생님을 찾아뵈었다. (A)에서 3인칭대명사 '그(의)', 재귀대명사 '자기'를 모두 쓸 수 있습니다. 여기서 둘의 차이점은 '그'는 철수 말고 다른 이를 가리키는 데 쓰일 수 있지만, '자기'는 반드시 철수를 가리킨다는 점입니다. (B)에서는 '그'를 쓰면 비문이 됩니다. 강조 용법으로 재귀대명사가 들어가는 자리에 일반 대명사를 절대로 쓰지 않는 것이 한국어 문법 규칙입니다.
SCC␞ 이번 글에서는 [그래프(Graph)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/)의 **강연결요소(Strongly Connected Components, SCC)**를 찾아내는 기법을 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님과 역시 같은 대학의 김선욱 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept 방향그래프(Directed Graph)의 [연결요소(connected component)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/) 내 노드 $u$에서 $v$로 향하는 경로와 $v$에서 $u$로의 경로가 존재한다면 해당 연결요소를 강연결요소라고 합니다. 예컨대 다음 그림에서는 총 네 개의 강연결요소가 있습니다. 그래프가 주어졌을 때 해당 그래프의 강연결요소를 찾아내는 것이 이 글의 목적입니다.  <a href="https://imgur.com/CtlPGFw"><img src="https://i.imgur.com/CtlPGFw.png" width="500px" title="source: imgur.com" /></a>  강연결요소를 찾아내는 기법의 핵심 아이디어는 다음 그림과 같습니다. 원그래프 $G$의 노드 $a$에서 $b$로 향하는 경로가 있습니다. 그런데 엣지 방향을 정반대로 바꾼 $G^T$를 분석해본 결과도 역시 $a$에서 $b$로 갈 수 있다(다이렉트로 가지 못하고 여러 노드를 거쳐 가더라도 관계 없음)고 칩시다. 그렇다면 $a$와 $b$ 사이에는 사이클(cycle)이 있어 강연결요소 속성을 만족한다는 것입니다.  <a href="https://imgur.com/NHUDUaH"><img src="https://i.imgur.com/NHUDUaH.png" width="300px" title="source: imgur.com" /></a>    ## algorithm 강연결요소는 [너비우선탐색(Depth First Search)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/20/DFS/)을 기본으로 해서 구합니다. 우선 주어진 그래프에 대해 DFS를 적용합니다. 다음과 같습니다. 아래 예제 그래프의 경우 노드 안에 적혀진 숫자가 각각 DFS 알고리즘의 *start time*, *finish time*이 됩니다(음영처리로 클러스터를 표시한 부분은 일단 무시).  <a href="https://imgur.com/qyMcbTT"><img src="https://i.imgur.com/qyMcbTT.png" width="500px" title="source: imgur.com" /></a>  이후 다음 두 가지 작업을 수행합니다. - 그래프를 *transpose*한다. 다시 말해 노드는 그대로 놔두고 엣지 방향만 바꾼다. (인접행렬을 *transpose*한다는 의미) - *transpse*한 그래프를 대상으로 DFS를 한번 더 수행한다. **기존 적용한 DFS의 *finish time*을 내림차순 정렬해 그 순서대로 DFS를 수행한다.** 이 점 염두에 두고 다음 그림을 보겠습니다. 주어진 그래프를 *transpose*했으므로 엣지 방향이 위 그림과 반대임을 확인할 수 있습니다. *finish time* 기준 내림차순으로 DFS를 수행하므로, *finish time*이 16으로 가장 큰 $b$가 첫번째 대상입니다. $e$까지 순회하면 더 이상 방문할 노드가 없으므로 미방문 노드들 가운데 *finish time*이 9로 가장 큰 $d$를 대상으로 순회합니다. 마찬가지로 $g$와 $h$에 대해서도 같은 방식으로 각각 수행해주면 DFS가 끝납니다.  <a href="https://imgur.com/CbzlxED"><img src="https://i.imgur.com/CbzlxED.png" width="500px" title="source: imgur.com" /></a>  이 결과를 기존 그래프에 DFS를 수행한 것과 비교합니다. 여기서 두 결과 모두 서로 도달 가능한 노드들을 클러스터한 것이 음영처리된 부분입니다.  <a href="https://imgur.com/voD317r"><img src="https://i.imgur.com/voD317r.png" width="500px" title="source: imgur.com" /></a>  강연결요소끼리는 어떤 방향에서든 서로 도달가능하기 때문에 다음과 같이 그래프 정보를 압축하는 데 요긴하게 쓰일 수 있습니다.  <a href="https://imgur.com/ZG6xwHP"><img src="https://i.imgur.com/ZG6xwHP.png" width="500px" title="source: imgur.com" /></a> 
MLE␞ 이번 글에서는 최대우도추정(Maximum Likelihood Estimation)에 대해 살펴보도록 하겠습니다. 이 글은 Ian Goodfellow 등이 집필한 Deep Learning Book과 위키피디아, 그리고 [조현제 님의 자료](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjL35GXl8DWAhWIi7wKHSu-C2IQFgglMAA&url=http%3A%2F%2Fdatabaser.net%2Fmoniwiki%2Fpds%2FBayesianStatistic%2F%25EB%25B2%25A0%25EC%259D%25B4%25EC%25A6%2588_%25EC%25A0%2595%25EB%25A6%25AC%25EC%2599%2580_MLE.pdf&usg=AFQjCNEfWz3mbEgF4zVu7qc-iW6azR2jRQ)를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 최대우도추정 최대우도추정(maximum likelihood estimation)이란 모수(parameter)가 미지의 $θ$인 확률분포에서 뽑은 표본(관측치) $x$들을 바탕으로 $θ$를 추정하는 기법입니다. 여기에서 우도(likelihood)란 이미 주어진 표본 $x$들에 비추어 봤을 때 모집단의 모수 $θ$에 대한 추정이 그럴듯한 정도를 가리킵니다. 우도 $L(θ$\|$x)$는 $θ$가 전제되었을 때 표본 $x$가 등장할 확률인 $p(x$\|$θ)$에 비례합니다. 동전던지기를 100번 시행했는데, 앞면이 56번 나왔다고 가정해보겠습니다. 반복적인 동전던지기는 성공확률이 $p$인 베르누이시행을 $n$번 반복시행할 때 성공횟수의 분포인 **이항분포(binomial distribution)**를 따릅니다. 이 예시에서 우리가 알고 싶은 미지의 모수 $θ$는 동전을 한 번 던졌을 때 앞면이 나올 확률 $p$가 됩니다. 이를 위해 앞면이 나올 확률이 $p$인 이항분포에서 뽑은 표본 $x$(성공횟수=앞면이 나온 횟수=56번)를 활용합니다. 이항분포의 확률함수는 다음과 같습니다.  $$ p(x)=\begin{pmatrix} n \\ x \end{pmatrix}{ p }^{ x }{ (1-p) }^{ n-x } $$  우선 이 동전이 공정하다($θ=0.5$)고 가정하고 우도를 계산해보겠습니다.  $$p(X=56|\theta =0.5)=\begin{pmatrix} 100 \\ 56 \end{pmatrix}{ 0.5 }^{ 56 }{ 0.5 }^{ 44 }\approx 0.0389$$  이와 같은 방법으로 $θ$의 값을 달리 해가며 우도를 계산하면 다음 표와 같습니다.  | $θ$ | likelihood | | :--: | :--------: | | 0.48 |  0.0222  | | 0.50 |  0.0389  | | 0.52 |  0.0587  | | 0.54 |  0.0739  | | 0.56 |  0.0801  | | 0.58 |  0.0738  | | 0.60 |  0.0576  | | 0.62 |  0.0378  |  이를 그래프로 그려보면 다음과 같습니다. 위 표와 대략 일치합니다.  <a href="https://imgur.com/qa6ikOG"><img src="https://i.imgur.com/qa6ikOG.png" title="source: imgur.com" /></a>  그런데 이항분포의 확률함수와 그래프를 보시다시피 미분이 가능합니다. 따라서 $θ$에 대해 편미분을 해 0이 되는 지점을 구하면 우도를 최대화하는 $θ$를 단박에 구할 수도 있습니다. 그런데 $θ$에 대해 미분이 불가능할 경우에는 그래디언트 디센트 등 반복적이고 점진적인 방식으로 $θ$를 추정하게 됩니다. 로지스틱 회귀나 딥러닝 등 모델의 $θ$를 최대우도추정 기법으로 추정할 때 자주 쓰는 기법입니다.   ## 최대우도추정 vs 크로스 엔트로피, KL-Divergence 우리가 가진 학습데이터의 분포를 $P_{data}$, 모델이 예측한 결과의 분포를 $P_{model}$, 모델의 모수(파라메터)를 $θ$라고 두면 최대우도추정은 다음과 같이 쓸 수 있습니다. 아래 식이 유도되는 과정은 이렇습니다. 확률은 1보다 작기 때문에 계속 곱하면 그 값이 지나치게 작아져 언더플로우(underflow) 문제가 발생하므로 로그를 취합니다. 로그우도의 기대값은 로그우도의 합에 데이터 개수($m$)로 나누어 구합니다. 그런데 전체 값에 로그를 취하거나 스케일을 하여도 대소관계는 변하지는 않으므로 아래의 두 식이 동일한 의미를 갖습니다.  $$ \begin{align*} { \theta }_{ ML }&=arg\max _{ \theta }{ { P }_{ model }\left( X|\theta \right) } \\ &=arg\max _{ \theta }{ \left\{ { E }_{ X\sim { \hat { P } }_{ data } }\left[ \log { { P }_{ model }\left( x|\theta \right) } \right] \right\} } \end{align*} $$  쿨백-라이블러 발산(Kullback-Leibler divergence, KLD)은 두 확률분포의 차이를 계산하는 데 사용하는 함수입니다. 딥러닝 모델을 만들 때 예로 들면 우리가 가지고 있는 데이터의 분포 $P_{data}$와 모델이 추정한 데이터의 분포 $P_{model}$ 간에 차이를 KLD를 활용해 구할 수 있고, KLD를 최소화하는 것이 모델의 학습 과정이 되겠습니다. KLD의 식은 다음과 같이 정의됩니다.  $$ { D }_{ KL }\left( P||Q \right) ={ E }_{ X\sim \hat{P}_{data} }\left[ \log { \hat{P}_{data}(x) } -\log { {P}_{model}(x) } \right] $$  그런데 위 식에서 왼쪽 term이 가리키는 $P_{data}$는 우리가 가지고 있는 데이터의 분포를 가리키며 학습과정에서 바뀌는 것이 아니므로 KLD를 최소화하는 건 위 식에서 오른쪽 term이 나타내는 값을 최소화한다는 의미가 됩니다. 위 식의 오른쪽 term(=아래의 term)을 크로스 엔트로피(cross entropy)라고 합니다.  $$ -{ E }_{ X\sim \hat { P } _{ data } }\left[ \log { { P }_{ model }(x) } \right] $$  크로스 엔트로피를 최대우도추정과 비교해 봅시다. 식을 비교해서 보면 **크로스 엔트로피(혹은 KLD) 최소화**가 **우도의 최대화**와 본질적으로 같습니다. 이 때문에 최대우도추정은 우리가 가지고 있는 데이터의 분포와 모델이 추정한 데이터의 분포를 가장 유사하게 만들어주는 모수(파라메터)를 찾아내는 방법이라고 봐도 될 것 같습니다. 이와 관련해서는 [이곳](https://ratsgo.github.io/statistics/2017/09/22/information/)을 더 참고하시면 좋을 것 같습니다.   ## 최대우도추정 vs 최소제곱오차 머신러닝에서는 주로 조건부 우도를 최대화하는 방식으로 학습을 합니다. 입력값 $X$와 모델의 파라메터 $θ$가 주어졌을 때 정답 $Y$가 나타날 확률을 최대화하는 $θ$를 찾는 것입니다. 우리가 가지고 있는 데이터가 학습 과정에서 바뀌는 것은 아니므로 $X$와 $Y$는 고정된 상태입니다. 모델에 $X$를 넣었을 때 실제 $Y$에 가장 가깝게 반환하는 $θ$를 찾아내는 것이 관건이라고 볼 수 있겠습니다. $m$개의 모든 관측치가 i.i.d(independent and identically distributed)라고 가정하고, 언더플로우 방지를 위해 우도에 로그를 취한다면 최대우도추정 식은 다음과 정리할 수 있습니다.  $$ \begin{align*} {\theta }_{ ML }&=arg\max _{ \theta }{ { P }_{ model }\left( Y|X;\theta \right) } \\ &=arg\max _{ \theta }{ \sum _{ i=1 }^{ m }{ \log { { P }_{ model }\left( y_{ i }|{ x }_{ i };\theta \right) } } } \end{align*} $$  여기에서 $P_{model}$이 가우시안 확률함수라고 가정을 해봅시다. 다시 말해 $X$와 $Y$가 정규분포를 따를 것이라고 가정해 보는 것입니다. 그러면 정규분포 확률함수로부터 이 모델의 로그우도 합은 다음과 같이 쓸 수 있습니다. (분산 $σ^2$도 고정돼 있다고 가정, 사용자가 특정 상수값으로 지정)  $$ \sum _{ i=1 }^{ m }{ \log { { P }_{ model }\left( y_{ i }|{ x }_{ i };\theta \right) } } =-m\log { \sigma } -\frac { m }{ 2 } \log { 2\pi } -\sum _{ i=1 }^{ m }{ \frac { { \left\| { \hat { y } }_{ i }-{ y }_{ i } \right\| }^{ 2 } }{ 2{ \sigma }^{ 2 } } } $$  선형회귀(liner regression)의 목적식은 평균제곱오차(Mean Squared Error)입니다. MSE의 식은 다음과 같이 정의됩니다.  $$ MSE=\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ { \left\| { \hat { y } }_{ i }-{ y }_{ i } \right\| }^{ 2 } } $$  우리가 정규분포를 가정한 모델의 로그우도 합과 MSE를 비교해봅시다. 로그우도 합의 수식에서 세 개의 term 가운데 앞의 두 개의 term은 모두 상수값으로 학습과정에서 변하는 값이 아니며 로그우도의 합을 최대화하는 데 영향을 끼치는 term이 아닙니다. 이번엔 로그우도 합의 세번째 term과 MSE를 비교해 보겠습니다. 사용자가 지정한 $σ$, 데이터 개수 $m$은 모두 상수값이므로, 이들 또한 로그우도합과 MSE 값의 크기에 영향을 줄 수 없습니다.  따라서 우리가 가정하는 확률모델이 정규분포일 경우, 우도를 최대화하는 모수(파라메터)와 평균제곱오차를 최소화하는 모수가 본질적으로 동일하다는 이야기가 됩니다.   ## 왜 최대우도추정인가? 최대우도추정 기법으로 추정한 모수는 **일치성(consistency)**과 **효율성(efficiency)**이라는 좋은 특성을 가지고 있다고 합니다. 일치성이란 추정에 사용하는 표본의 크기가 커질 수록 진짜 모수값에 수렴하는 특성을 가리킵니다. 효율성이란 일치성 등에서 같은 추정량 가운데서도 분산이 작은 특성을 나타냅니다. 추정량의 효율성을 따질 때는 보통 평균제곱오차(MSE)를 기준으로 하는데, 크래머-라오 하한 정리에 의하면 일치성을 가진 추정량 가운데 최대우도추정량보다 낮은 MSE를 지닌 추정량이 존재하지 않는다고 합니다.  이러한 이유로 머신러닝에서는 모수를 추정할 때 최대우도추정 기법을 자주 쓴다고 합니다. 하지만 최대우도추정은 관측치(표본)에 큰 영향을 받기 때문에 이를 보완하는 다양한 기법이 제안되었습니다. 
summer␞ 휴가 기간 이것만은 꼭 읽으리라 다짐했던 책이 하나 있다. 김애란의 5년만의 신작 소설집 '바깥은 여름'. 대학 시절 '달려라 아비', '침이 고인다'를 읽고 무한 감동 모드에 빠져 있었던 지라 새 작품이 출간됐다는 소식에 무척 기뻤다.  김애란은 5년 전 소설의 주인공들이 현재 맞닥뜨리고 있는 삶의 문제들을 담담하게, 하지만 뼈아프게 그려낸다. 그들은 이제 더 이상 노량진 어느 편의점, 원룸, 학원을 전전하지 않는다. 결혼도 했고, 애도 낳았고, 집도 샀다.  그러나 빚과 가난에 쪼들린다는 점에서, 이른바 '정상적인 가정'을 꾸리기 위해 아둥바둥한다는 점에서, 그러면서도 상실감이 그들의 마음을 짓누르고 있다는 점에서 그들의 삶은 5년 전과 비교해 조금도 나아지지 않았다.  휴가 기간 책장을 넘기면서 소설의 흡입력과 재미에 감탄하면서도 너무나 현실적인 묘사에 가슴 한 구석이 아리기도 했다. 이 느낌을 잊지 않기 위해 인상 깊은 구절 몇 개를 정리해본다. *2017. 8. 11. 부산*  > 한동안 집이 생겼다는 사실에 꽤 얼떨떨했다. 명의만 내 것일 뿐 여전히 내 집이 아닌데도 그랬다. 이십여 년간 셋방을 부유하다 이제 막 어딘가 가늘고 연한 뿌리를 내린 기분. (중략) 아내는 9급 공무원 시험에 세 번 응시해 세 번 떨어졌고, 공무원이 되는 대신 노량진 공무원 입시학원에서 사무를 봤다. 결혼 후 난임 치료를 받다 두 번의 유산 끝에 영우를 가졌고, 다섯 번의 이사 끝에 집을 샀다. 모두 지난 십 년간 정신없이 벌어진 일들이었다. 아파트를 얻은 뒤 아내는 휴일마다 베란다에서 계속 무언가를 자르고, 칠하고, 조립했다. (중략) 아내는 정착의 사실뿐 아니라 실감이 필요한 듯했다. 쓸모와 필요로만 이뤄진 공간은 이제 물렸다는 듯, 못생긴 물건들과 사는 건 지쳤다는 듯. 아내는 물건에서 기능을 뺀 나머지를, 삶에서 생활을 뺀 나머지를 갖고 싶어했다. **'입동'**   > '딱 한 잔만' 하자던 술자리는 3차까지 이어졌다. 새벽 세시가 넘었을 즈음 테이블에 남은 사람은 이수와 동오뿐이었다. 두 사람은 그렇게 친하지도 않았다. 이수는 동오가 최근 커피숍을 냈다 망한 걸 알고 있었다. 직접 연락하지 않아도 그런 소문은 귀에 잘 들어왔다. 이수는 자기 근황도 그런 식으로 돌았을지 모른다고 짐작했다. 걱정을 가장한 흥미의 형태로, 죄책감을 동반한 즐거움의 방식으로 화제에 올랐을 터였다. 누군가의 불륜, 누군가의 이혼, 누군가의 몰락을 얘기할 때 이수도 그런 식의 관심을 비친 적이 있었다. 경박해 보이지 않으려 적당한 탄식을 섞어 안타까움을 표한 적 있었다. 그 자식 공부 잘했는데. 그러니까 걔기 그렇게 될 줄 어떻게 알았어. 인생 길게 봐야 하나봐. 누구는 벌써 부장 달았던데. 걔가 잘 풀릴 줄 아무도 몰랐잖아. 동일한 출발선을 돌아본 뒤 교훈을 찾고 줄거리를 복기할 입들이 떠올랐다. 그러다 어색한 침묵이 돌면 금방 다른 화제를 찾아내겠지. 어쩌면 다른 친구들도 이미 타인의 삶에 심드렁해진 지 오랜데 이수 혼자 그렇게 추측하는지 몰랐다. **'건너편'**   > 우편함에 각종 고지서와 전단지가 가득했다. 내 것과 남편 이름이 뒤섞인 종이 뭉치를 가슴에 안고 승강기에 올랐다. 그러곤 현관 앞에 서서 당신 것과 내 생일을 섞어 만든 비밀번호를 눌렀다. 한 달 남짓 집에 고인 미지근한 공기가 바깥바람과 만나 몸을 뒤척였다. 신발장 앞에 캐리어를 세워두고, 우편물을 부엌 식탁 위에 던진 뒤 안방으로 들어가 그대로 쓰러졌다. 고요하고 어둑한 안방에서 '우리집 냄새'가 났다. 당신과 같이 만든 냄새였다. **'어디로 가고 싶으신가요'**  
lda␞ 이번 글에서는 말뭉치로부터 토픽을 추출하는 **토픽모델링(Topic Modeling)** 기법 가운데 하나인 **잠재디리클레할당(Latent Dirichlet Allocation, LDA)**을 파이썬 코드로 구현하는 법을 살펴보도록 하겠습니다. 이 글은 '밑바닥부터 시작하는 데이터 과학(조엘 그루스 지음, 인사이트 펴냄)'을 정리하였음을 먼저 밝힙니다. LDA 기법 자체에 대한 자세한 내용은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/06/01/LDA/)을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.   ## 수식 LDA 모델을 모두 정리하면 $d$번째 문서 $i$번째 단어의 토픽 $z_{d,i}$가 $j$번째에 할당될 확률은 다음과 같이 쓸 수 있습니다.  $$ p({ z }_{d, i }=j|{ z }_{ -i },w)=\frac { { n }_{ d,k }+{ \alpha }_{ k } }{ \sum _{ i=1 }^{ K }{ ({ n }_{ d,i }+{ \alpha }_{ i }) } } \times \frac { { v }_{ k,{ w }_{ d,n } }+{ \beta }_{ { w }_{ d,n } } }{ \sum _{ j=1 }^{ V }{ { v }_{ k,j }+{ \beta }_{ j } } }=AB $$  위 수식의 표기를 정리한 표는 다음과 같습니다. |    표기    |          내용          | | :-------------: | :--------------------------------------: | |  $n_{d,k}$  |   $k$번째 토픽에 할당된 $d$번째 문서의 단어 빈도    | | $v_{k,w_{d,n}}$ | 전체 말뭉치에서 $k$번째 토픽에 할당된 단어 $w_{d,n}$의 빈도 | |  $w_{d,n}$  |     $d$번째 문서에 $n$번째로 등장한 단어     | |   $α_k$   |   문서의 토픽 분포 생성을 위한 디리클레 분포 파라메터    | |   $β_k$   |   토픽의 단어 분포 생성을 위한 디리클레 분포 파라메터    | |    $K$    |       사용자가 지정하는 토픽 수       | |    $V$    |      말뭉치에 등장하는 전체 단어 수       | |    $A$    |   $d$번째 문서가 $k$번째 토픽과 맺고 있는 연관성 정도   | |    $B$    | $d$번째 문서의 $n$번째 단어($w_{d,n}$)가 $k$번째 토픽과 맺고 있는 연관성 정도 |   ## 변수 선언 LDA 학습을 위해서는 변수를 먼저 선언해주어야 합니다. 다음과 같습니다. ```python from collections import Counter # 각 토픽이 각 문서에 할당되는 횟수 # Counter로 구성된 리스트 # 각 Counter는 각 문서를 의미 document_topic_counts = [Counter() for _ in documents] # 각 단어가 각 토픽에 할당되는 횟수 # Counter로 구성된 리스트 # 각 Counter는 각 토픽을 의미 topic_word_counts = [Counter() for _ in range(K)] # 각 토픽에 할당되는 총 단어수 # 숫자로 구성된 리스트 # 각각의 숫자는 각 토픽을 의미함 topic_counts = [0 for _ in range(K)] # 각 문서에 포함되는 총 단어수 # 숫자로 구성된 리스트 # 각각의 숫자는 각 문서를 의미함 document_lengths = map(len, documents) # 단어 종류의 수 distinct_words = set(word for document in documents for word in document) V = len(distinct_words) # 총 문서의 수 D = len(documents) ``` 코드 변수명이 조금 생소하실 것 같아서 원 논문의 notation과 비교한 표를 다음과 같이 만들었습니다. |  원래 notation   |    code 변수명    | | :----------------: | :-------------------: | |   $n_{d,k}$   | document_topic_counts | | $v_{k,w_{d,n}}$  |  topic_word_counts  | | $Σ_{i=1}^Kn_{d,i}$ |  document_lengths  | | $Σ_{j=1}^Vv_{k,j}$ |   topic_counts   | 예컨대 세번째 문서 가운데 토픽 1과 관련있는 단어수는 다음과 같습니다. > document_topic_counts\[3][1] nlp라는 단어가 토픽2와 연관지어 등장한 횟수는 다음과 같습니다. > topic_word_counts\[2]['nlp']   ## 새로운 topic 계산하기  $d$번째 문서 $i$번째 단어의 토픽 $z_{d,i}$가 $j$번째에 할당될 확률은 $A$와 $B$를 곱해 구합니다. 아래 코드에서 *p_topic_given_document*가 $A$, *p_word_given_topic*이 $B$입니다. *topic_weight* 함수는 이 둘을 곱한 값이라는 걸 알 수 있습니다.  ```python def p_topic_given_document(topic, d, alpha=0.1):   # 문서 d의 모든 단어 가운데 topic에 속하는   # 단어의 비율 (alpha를 더해 smoothing)   return ((document_topic_counts[d][topic] + alpha) /       (document_lengths[d] + K * alpha)) def p_word_given_topic(word, topic, beta=0.1):   # topic에 속한 단어 가운데 word의 비율   # (beta를 더해 smoothing)   return ((topic_word_counts[topic][word] + beta) /       (topic_counts[topic] + V * beta)) def topic_weight(d, word, k):   # 문서와 문서의 단어가 주어지면   # k번째 토픽의 weight를 반환   return p_word_given_topic(word, k) * p_topic_given_document(k, d) ``` $AB$를 구했으니 이를 바탕으로 샘플링을 하여 $z_{d,i}$에 새로운 topic을 할당할 수 있습니다. 그 코드는 다음과 같습니다. ```python def choose_new_topic(d, word):   return sample_from([topic_weight(d, word, k) for k in range(K)]) import random def sample_from(weights):   # i를 weights[i] / sum(weights)   # 확률로 반환   total = sum(weights)   # 0과 total 사이를 균일하게 선택   rnd = total * random.random()   # 아래 식을 만족하는 가장 작은 i를 반환   # weights[0] + ... + weights[i] >= rnd   for i, w in enumerate(weights):     rnd -= w     if rnd <= 0:       return i ```   ## inference 다음과 같은 데이터가 주어졌다고 칩시다. ```python documents = [["Hadoop", "Big Data", "HBase", "Java", "Spark", "Storm", "Cassandra"],   ["NoSQL", "MongoDB", "Cassandra", "HBase", "Postgres"],   ["Python", "scikit-learn", "scipy", "numpy", "statsmodels", "pandas"],   ["R", "Python", "statistics", "regression", "probability"],   ["machine learning", "regression", "decision trees", "libsvm"],   ["Python", "R", "Java", "C++", "Haskell", "programming languages"],   ["statistics", "probability", "mathematics", "theory"],   ["machine learning", "scikit-learn", "Mahout", "neural networks"],   ["neural networks", "deep learning", "Big Data", "artificial intelligence"],   ["Hadoop", "Java", "MapReduce", "Big Data"],   ["statistics", "R", "statsmodels"],   ["C++", "deep learning", "artificial intelligence", "probability"],   ["pandas", "R", "Python"],   ["databases", "HBase", "Postgres", "MySQL", "MongoDB"],   ["libsvm", "regression", "support vector machines"]] ``` 우선 inference에 필요한 기초 데이터를 만듭니다. 토픽수 $K$ 등 하이퍼파라메터를 정하고, 각 단어를 임의의 토픽에 배정한 뒤 필요한 숫자를 세어봐야 합니다. ```python random.seed(0) # topic 수 지정 K=4 # 각 단어를 임의의 토픽에 랜덤 배정 document_topics = [[random.randrange(K) for word in document]           for document in documents] # 위와 같이 랜덤 초기화한 상태에서 # AB를 구하는 데 필요한 숫자를 세어봄 for d in range(D):   for word, topic in zip(documents[d], document_topics[d]):     document_topic_counts[d][topic] += 1     topic_word_counts[topic][word] += 1     topic_counts[topic] += 1 ``` 우리의 목표는 '토픽-단어'와 '문서-토픽'에 대한 결합확률분포(unknown)로부터 표본을 얻는 것이므로, 깁스샘플링을 수행하면 됩니다. iteration은 1000으로 설정했습니다. ```python for iter in range(1000):   for d in range(D):     for i, (word, topic) in enumerate(zip(documents[d],                        document_topics[d])):       # 깁스 샘플링 수행을 위해       # 샘플링 대상 word와 topic을 제외하고 세어봄       document_topic_counts[d][topic] -= 1       topic_word_counts[topic][word] -= 1       topic_counts[topic] -= 1       document_lengths[d] -= 1       # 깁스 샘플링 대상 word와 topic을 제외한       # 말뭉치 모든 word의 topic 정보를 토대로       # 샘플링 대상 word의 새로운 topic을 선택       new_topic = choose_new_topic(d, word)       document_topics[d][i] = new_topic       # 샘플링 대상 word의 새로운 topic을 반영해       # 말뭉치 정보 업데이트       document_topic_counts[d][new_topic] += 1       topic_word_counts[new_topic][word] += 1       topic_counts[new_topic] += 1       document_lengths[d] += 1 ```   ## 파일럿 실험 결과 inference 결과 첫번째 문서의 토픽 비중은 다음과 같습니다. 전체 7개 단어 가운데 0번째 토픽과 관련된 단어가 4개 1번째 토픽 단어가 3개입니다. 따라서 이 문서는 첫번째 토픽일 확률이 가장 높네요. > \>> document_topic_counts[0] > > Counter({0: 4, 2: 3, 1: 0, 3: 0}) 첫번째 토픽의 단어 비중은 다음과 같습니다. Java, Big Data, Hadoop, deep learning 등 단어의 빈도(비중)가 높네요. 이 토픽은 대략 'Big Data'에 해당하는 주제인 것 같다는 느낌이 듭니다. > \>> topic_word_counts[0] > > Counter({'Java': 3, 'Big Data': 3, 'Hadoop': 2, 'deep learning': 2, 'artificial intelligence': 2, 'C++': 2, 'neural networks': 1, 'Storm': 1, 'programming languages': 1, 'MapReduce': 1, 'Haskell': 1, 'probability': 0, 'Mahout': 0, 'NoSQL': 0, 'MySQL': 0, 'regression': 0, 'statistics': 0, 'Postgres': 0, 'Python': 0, 'mathematics': 0, 'Spark': 0, 'numpy': 0, 'pandas': 0, 'theory': 0, 'libsvm': 0, 'scipy': 0, 'R': 0, 'HBase': 0, 'decision trees': 0, 'MongoDB': 0, 'scikit-learn': 0, 'machine learning': 0, 'databases': 0, 'statsmodels': 0, 'support vector machines': 0, 'Cassandra': 0}) 
busan␞ \#01. 부산은 나에게 비즈니스(business) 도시로 남아있다. 매번 출장으로 다녀갔다. 반나절도 못되는 시간만 부산에 있다가 할 일만 마치고 바로 상경하고는 했다. KTX나 비행기를 탔지만 이동하는 시간마저도 아까웠다. 기내에서 객차에서도 키보드를 두드리곤 했다. 이번엔 크게 마음을 먹고 무궁화호 열차표를 끊었다. 휴가 때만이라도 '철저히 느린 삶'을 살겠노라 다짐한 것이다. 그랬더니 평소엔 그냥 스쳤던 이런저런 일들이 눈에 들어오기 시작했다. \#02. 무궁화호 승객 표를 검사하고 승하차 관련 업무를 총괄하는 분들의 정식직함은 과장도, 차장도, 부장도, 상무도 아닌 '여객**전무**'다. 모르긴 몰라도 KTX나 비행기에서 여객서비스를 하시는 분들보다 훨씬 직급이 높을 것이다. 콧대도 무척 세보였다. 객차에 처음 들어왔을 때, 그리고 빠져나갈 때 절대 머리 숙여 인사하는 법이 없다. 하긴 KTX 승무원들이 다른 객차로 갈 때 일부러 돌아서서 까딱 고개 숙이는 제스처가 영혼없는 매너라는 생각이 예전부터 들긴 했다. \#03. 무궁화호는 느리다. 서울-용산-영등포-수원-오산-평택-천안-조치원-신탄진-대전-옥천-영동-김천-구미-왜관-대구-동대구-밀양-구포-부산. 다 선다. 달리는 시간보다 서있는 시간이 더 길지 않을까. 최고속도는 120km/h이지만 체감상 100km/h 남짓의 속도로 운행하는 것 같다. 이 덕분에 한여름 아름다운 강과 들판의 모습을 시야에 온전히 담을 수 있다. KTX 탔을 때는 불가능했던 일이다. \#04. 부산역 7번출구로 나와 걷다가 대로 안쪽으로 두세블럭을 가면 '불백(불고기백반)'을 파는 식당이 옹기종기 모여있다. 처음엔 운전기사 분들을 위한 기사식당이었다고 하는데 '무한도전' 같은 매스컴을 탄 이후로 손님은 주로 관광객들인 듯하다. 1인분에 7000원짜리 백반을 시키면 이런저런 반찬에 새빨간 양념이 된 불고기가 지글지글하니 나온다. 한그릇 뚝딱, 해치우는데 10분밖에 안 걸린 것 같다. 맛도 양도 가격도 다 좋은데 너무 짜다. \#05. 부산 초량역과 부산역을 지나 중앙역으로 뻗어있는 중앙대로 변 더불어민주당 부산광역시당 건물 맞은편엔 변호사 '곽규택'의 사무실이 있다. 그런데 간판이 참 특이하다. 한쪽 벽면에 큼직하게 그리고 나란히 '변호사 곽규택'과 '영화감독 곽경택'이라고 썼다. 이 사무실 곽변이 두 명인가 싶을 정도로 근엄하고 진지하게. 시골(?)에서 나고 자란 두 형제가 부산을 소재로 한 영화로 대박을 치고, 검찰 요직을 두루 거치며 승승장구했으니 고향에 돌아와서는 주변에 자랑할 만 할 것이다. \#06. 식사 후 목적지는 영도(影島)로 정했다. 초량역 3번 출구 버스정류장에서 85번 버스를 타면 부산역과 남포동역을 지나 영도대교를 건너 영도로 갈 수 있다. 영도대교에서 바라보는 부산항과 시내 모습은 많은 배와 접안시설로 신산스럽지만 삶의 박진감과 생동감을 느낄 수 있다. 영도 안에 들어선 버스는 육중한 무게를 견디며 동동동 언덕을 향한다. 6.25 피난시절 설움을 그대로 안고 있는 영도는 제법 높은 언덕배기에까지 주택이 들어차 있다. \#07. 영도에는 부산 앞바다가 한눈에 내려다보이는 오션뷰 카페 '블루즈홀릭'이 있다. 영도 서쪽 해안을 감싸도는 '절영로'에 있는데 사색을 즐길 수 있어 일품이다. 그런데 휴가 때만이라도 서울처럼 북적거리는 부산 바닷가엔 가지 않겠노라 다짐했건만 저녁 무렵에는 광안리에 가야할 것 같다. 오랫동안 고락을 함께 해온 친구들과 바다내음을 마시며 술잔을 부딪힐 생각이다. 바다에 술에 취하다보면 부산스러움 따위 신경도 쓰이지 않을 것이다. *2017. 8. 11. 부산 영도*
taste␞ 대학원 입학 후 제대로 된 첫 휴가를 맞아 오래간만에 소설과 에세이 책, 시집들을 꺼내들었다. 기자 생활을 본격 시작한 20대 중반에 이르기까지 내 정신적 삶에 근간이 되었던 글들이다. 그런데 요즘 밥(이라 쓰고 '밥벌이'라 읽는다)에 관심이 많아서 그런지, 이런 글밖에 눈에 들어오지 않는다. 책갈피 끼우는 심정으로 정리해둔다. *2017. 8. 8. 전주*   > 황사바람 부는 거리에서 전경들이 점심을 먹는다. 외국대사관 담 밑에서, 시위군중과 대치하고 있는 광장에서, 전경들은 땅바닥에 주저앉아 밥을 먹는다. 닭장차 옆에 비닐로 포장을 치고 그 속에 들어가서 먹는다. 된장국과 깍두기와 졸인 생선 한 토막이 담긴 식판을 끼고 두 줄로 앉아서 밥을 먹는다. 다 먹으면 신병들이 식판을 챙겨서 차에 싣고 잔반통을 치운다. 시위군중들도 점심을 먹는다. 길바닥에 주저앉아서 준비해 온 도시락이나 배달시킨 자장면을 먹는다. 전경들이 가방을 들고 온 배달원의 길을 열어준다. 밥을 먹고있는 군중들의 둘레를 밥을 다 먹은 전경들과 밥을 아직 못 먹은 전경들이 교대로 둘러싼다. 시위대와 전경이 대치한 거리의 식당에서 기자도 짬뽕으로 점심을 먹는다. 다 먹고나면 시위군중과 전경과 기자는 또 제가끔 일을 시작한다. 밥은 누구나 다 먹어야 하는 것이지만, 제 목구멍으로 넘어가는 밥만이 각자의 고픈 배를 채워줄 수가 있다. 밥은 개별적이면서도 보편적이다. 시위현장의 점심시간은 문득 고요하고 평화롭다. 황사바람 부는 거리에서 시위군중의 밥과 전경의 밥과 기자의 밥은 다르지 않았다. 그 거리에서, 밥의 개별성과 밥의 보편성은 같은 것이었다. 아마도 세상의 모든 밥이 그러할 것이다. **김훈, '밥'에 대한 단상** >   > 明太 창난젓에 고추무거리에 막칼질한 무이를 뷔벼 익힌 것을 / 이 투박한 北關을 한없이 끼밀고 있노라면 / 쓸쓸하니 무릎은 꿇어진다 // 시큼한 배척한 퀴퀴한 이 내음새 속에 / 나는 가느슥히 女眞의 살내음새를 맡는다 // 얼근한 비릿한 구릿한 이 맛 속에선 / 까마득히 新羅 백성의 鄕愁도 맛본다 **백석, 북관(전문)** >   > 비 오는 날이면 요즈음도 나는 수제비가 먹고 싶어진다. 그건 아마 어린 날의 메밀칼싹두기와 관계가 있을 것이다. 벽촌의 비 오는 날의 적막감은 내가 아직 맛보지 못한, 그러나 장차 피할 수 없게 될 인생의 원초적인 고독의 예감과도 같은 것이었다. (중략) 그때만 해도 한가족끼리도 아래위 서열에 따라 음식 층하가 없을 수 없는 시대였지만 메밀칼싹두기만은 완벽하게 평등했다. 할아버지 상에 올릴 칼싹두기라고 해서 특별한 꾸미를 얹는 일도 없었지만 양까지도 어른, 아이 할 것 없이 막대접으로 한 대접씩 평등했다. 한 대접으로는 출출할 장정이나 머슴은 찬밥을 더 얹어먹으면 될 것이고, 한 대접이 벅찬 아이는 배를 두들겨 가며 과식을 하게 될 것이나 금방 소화가 되어 얹히는 일이 없었다. 땀 흘려 그걸 한 그릇씩 먹고 나면 뱃속뿐 아니라 마음속까지 훈훈하고 따뜻해지면서 좀전의 고적감은 눈녹듯이 사라지고 이렇게 화목한 집에 태어나길 참 잘했다는 기쁨인지 감사인지 모를 충만감이 왔다. 칼싹두기의 소박한 맛에는 이렇듯 각기 외로움 타는 식구들을 한 식구로 어우르고 위로하는 신기한 힘이 있었다. (하략) **박완서, 이 세상에 맛없는 음식은 없다** >   > 아무래도 오늘을 넘기기 어려울 것 같다는 / 전화를 받고 역으로 달려갔다. / 배가 고팠다. / 죽음의 소식을 듣고 가장 먼저 느낀 것이 시장기라니. / 불경스럽다는 생각에도 불구하고 배가 고팠다. / 기차시간을 기다리며 허겁지겁 먹어치운 / 국밥 한 그릇. / 벌건 국물에 잠긴 흰 밥알을 털어넣으며 / 언젠가 부관(不棺)을 지켜보던 산비탈에서 / 그분이 건네주신 국밥 한 그릇을 떠올렸다. / 그를 만난 것은 주로 장례식에서였다. / 초상 때마다 호상(護喪)을 마다하지 않았던 그가 / 너무 오래 서 있거나 걸어온 그가 / 이제는 고단한 몸을 뉘고 숨을 내려놓으려 한다. / 잘 비워낸 한 생애가 천천히 식어가는 동안 / 그가 마지막으로 건네는 국밥 한 그릇을 / 눈물도 없이 먹어치웠다. / 국밥에는 국과 밥과 또 무엇이 섞여 있는지, / 국밥 그릇을 들고 사람들이 / 아무렇지도 않은 듯 서둘러 삼키려는 게 무엇인지, / 어떤 찬도 필요치 않은 이 가난한 음식을 / 왜 마지막으로 베풀고 떠나는 것인지, / 나는 식어가는 국밥그릇을 쉽게 내려놓지 못했다. **나희덕, 국밥 한 그릇** >   > (전략) 나는 양념간장을 듬뿍 넣고 잘 저은 다음 묵밥을 입에 넣었다. 그 맛은, 정말 내가 태어나서 처음 보는 맛이었다. 육수에서는 윤기가 돌아 허한 느낌을 줄여주었고 고추 덕분에 매콤했다. 묵은 이와 싸울 생각이 없는 듯 사락사락 입속에서 놀다가 목으로 술술 잘 넘어갔다. 무엇보다 간이 잘 맞았다. 값은 기억이 나지 않지만 아주 쌌다. 2,500원쯤? 그로부터 약 한 달 뒤, 나는 서울에서 온 진객을 맞아 이 고장의 진정한 향토음식을 맛보여주겠노라고 큰소리를 치며 묵집으로 향했다. 그러나 경기도의 길은, 말 그대로 왕도의 터(畿)가 될 농토 사이로 종횡무진 나 있어서, 제갈량의 팔진도인 양 복잡했고 지역의 토산물인 안개로 도무지 묵밥 집을 찾을 수가 없었다. 나는 백배사죄하며 다음에는 꼭 그집을 찾아내겠노라고, 다음에 꼭 오시라고 빌었다. 손님은 묵밥이라니, 그게 뭐 대단한 음식이겠느냐고 나를 위로하는 건지 우습게 보는 건지 모를 말을 하고는 표표히 떠나가서 다시는 오지 않았다. 그 뒤에 나는 길거리에서 우연히 묵밥이라는 간판을 내건 음식점에 들어가 묵밥을 먹었다. 산뜻하고 깔끔했다. 그렇지만 내가 아는 그 맛, 식구끼리 해먹는 그 맛은 아니었다. 더 이상 그 집을 찾지 않을 생각이다. 어쩌면 없어졌을지도 모르겠다. 그래도 그 집을 원조라고 나는 생각한다. 원조라고 주장할 만한 이유가 없고 그럴 생각도 하지 않는 사람들이 만든 음식, 묵밥. 그 묵밥의 원조를 나는 맛보았다. (하략) **성석제, 묵밥을 먹으며 식도를 깨닫다** > 
quote␞ 이번 글에서는 한국어의 인용 표현에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 인용절이란 남의 말이나 글, 말하는 사람의 생각, 판단 등을 나타내는 주술관계가 있는 절을 인용절이라고 합니다. 인용절에는 **직접인용절**과 **간접인용절** 둘로 나뉩니다.   ## 직접인용절 본래의 언어형식을 바꾸지 않고 그대로 표현하려는 인용절을 직접인용절이라고 합니다. 대개 '-(이)라고', '-하고'로 표시됩니다. 다음 예문과 같습니다. > 어떤 사람이 **"동사무소가 어디입니까?"**라고 물었다. > > 나는 속으로 **'이건 너무 어려워'**라고 되뇌었다. > > 진이가 **"얘들아, 어서 돌아와!"**하고 소리쳤다.   ## 간접인용절 본래의 언어 형식을 화자의 관점에 따라 내용 중심으로 바꾸어 표현하는 인용절을 가리킵니다. 다음과 같습니다. > 나는 **진이의 말이 옳다**가 생각했다. > > 나는 진이에게 **학교에 갈 거냐**고 물었다. > > 의사가 환자에게 **담배를 끊으라**고 충고했다. > > 진이가 **공원에 놀러 가자**고 했다. 예시에서도 알 수 있듯 간접인용절은 화자의 현재 관점에서 기술되는 것이기 때문에 본래 발화로부터 인칭 대명사나 시간 표현, 지시 표현이 달라질 수 있습니다. | 직접인용                 | 간접인용               | | ------------------------------------ | --------------------------------- | | 진이는 "**내**가 직접 그 사람을 만나고 싶어."라고 말했다. | 진이는 **자기**가 직접 그 사람을 만나고 싶다고 말했다. | | 나는 어제 진이에게 "**내일** 갈 거니?"하고 물었다.   | 나는 어제 진이에게 **오늘** 갈 거냐고 물었다.   | | 미국에 간 진이는 "이곳이 맘에 들어"라고 했다.     | 미국에 간 진이는 **그곳**이 맘에 든다고 했다.   | 또한, 간접인용절로 내포될 경우 상대경어법은 별로 중요하지 않은 요소가 됩니다. 아래처럼 단지 문장의 종류에 따라서만 어미 선택이 달라집니다. | 문장 종류 | 어미     | 예문                    | | ----- | ----------- | ---------------------------------------- | | 평서문  | -다고, -(이)라고 | 나는 **진이의 말이 옳다**고 생각했다. 나는 **진이가 천재**라고 생각했다. | | 의문문  | -냐고     | 나는 진이에게 **학교에 갈 거냐**고 물었다.        | | 명령문  | -라고     | 의사가 환자에게 **담배를 끊으라**고 충고했다.       | | 청유문  | -자고     | 진이가 **공원에 놀러 가자**고 했다.          |   ## '생각의 인용'과 '간접 인용' 영문법의 영향인지 화자가 직접 말하는 것은 직접 인용, 말로 내뱉지 않고 생각만 하는 것을 간접 인용, 이렇게 구분하는 경향이 있습니다. 물론 한국어에서도 머릿속에 있는 생각을 인용할 때에는 다음과 같이 간접인용을 하는 것이 더 자연스럽습니다. > 우리는 선생님께서 건강을 곧 회복하실 것이라고 생각했다. 하지만 한국어에서는 밖으로 나온 말이나 글을 직접 인용하는 경우도 있고 간접 인용을 하는 경우도 있습니다. 또한 구어에서는 생각이라고 하더라도 직접 인용을 하는 경우도 적지 않습니다. 다음과 같습니다. > 우리는 '선생님께서 건강을 곧 회복하시겠구나.'라고 생각했어요. 
queue␞ 이번 글에서는 **큐(Queue)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의와 위키피디아를 정리하였음을 먼저 밝힙니다. 파이썬 코드는 [이곳](http://pythoncentral.io/circular-queue/)을 참고로 하였습니다. 그럼 시작하겠습니다.  ## concept 큐란 목록 한쪽 끝에서만 자료를 넣거나 뺄 수 있는 자료구조의 일종입니다. 먼저 집어넣은 데이터가 먼저 나오는 **FIFO(First In First Out)** 구조로 저장하는 형식을 가리킵니다. 사람들이 표를 사거나 순서를 기다리려고 일렬로 늘어선 줄(queue)을 연상하면 이해가 쉽습니다. 다시 말해 먼저 줄을 선 사람(데이터)이 먼저 나갈 수 있다는 것이지요. 다음 그림과 같습니다.  <a href="https://imgur.com/GXkBmm4"><img src="https://i.imgur.com/GXkBmm4.png" width="500px" title="source: imgur.com" /></a>  큐에 새로운 데이터가 들어오면 큐의 끝 위치(tail)에 저장이 됩니다. 반대로 삭제할 때는 첫번째 위치(head)의 요소가 지워지게 됩니다. 전자를 enqueue, 후자를 dequeue라고 합니다.   ## operation 큐의 핵심 연산은 enqueue와 dequeue입니다. 연결리스트(linked list) 형태로 큐를 구현했을 때 예시는 다음과 같습니다. > enqueue 5, enqueue 3, enqueue 1, dequeue, dequeue, enqueue 7  <a href="https://imgur.com/e8jTWwp"><img src="https://i.imgur.com/e8jTWwp.png" width="400px" title="source: imgur.com" /></a>  연결리스트로 큐를 구현했을 때 enqueue와 dequeue의 계산복잡성은 모두 $O(1)$입니다. 추가, 삭제 연산이 각각 큐의 시작(head)과 끝(tail)에서만 일어나기 때문입니다. 큐를 array로 구현할 수도 있습니다. 다음과 같습니다.  <a href="https://imgur.com/W8XOGpU"><img src="https://i.imgur.com/W8XOGpU.png" width="250px" title="source: imgur.com" /></a>  array로 큐를 구현했을 때 enqueue의 계산복잡성은 $O(1)$입니다. 추가 연산이 큐의 끝(tail)에서만 일어나기 때문입니다. 그러나 dequeue의 계산복잡성은 $O(n)$이 됩니다. 큐의 시작(head) 요소를 지우게 되면 두번째 요소부터 끝에 이르는 모든 요소들의 위치를 왼쪽으로 한 칸씩 옮겨주어야 하기 때문입니다. Circular Array로 큐를 구현하면 이러한 문제를 해결할 수 있습니다. 그 개념도는 다음과 같습니다. Circular Array를 쓰면 enqueue, dequeue가 각각 큐의 시작(head)과 끝(tail)에서만 일어나게 돼 둘 모두 계산복잡성이 $O(1)$이 됩니다.  <a href="https://imgur.com/zzBmv5I"><img src="https://i.imgur.com/zzBmv5I.png" width="400px" title="source: imgur.com" /></a>   ## 파이썬 구현 파이썬에서 Circular Array로 구현한 큐는 다음과 같습니다. ```python class CircularQueue():   # Constructor   def __init__(self):     self.queue = list()     self.head = 0     self.tail = 0     self.maxSize = 8   # Adding elements to the queue   def enqueue(self,data):     if self.size() == self.maxSize-1:       return ("Queue Full!")     self.queue.append(data)     self.tail = (self.tail + 1) % self.maxSize     return True   # Removing elements from the queue   def dequeue(self):     if self.size()==0:       return ("Queue Empty!")     data = self.queue[self.head]     self.head = (self.head + 1) % self.maxSize     return data   # Calculating the size of the queue   def size(self):     if self.tail>=self.head:       return (self.tail-self.head)     return (self.maxSize - (self.head-self.tail)) ``` 
MEMs␞ 이번 글에선 **최대엔트로피모델(Maximum Entropy Models, MEMs)**을 다루어 보도록 하겠습니다. 이 글은 고려대 강필성 교수님 강의와 역시 같은 대학의 정순영 교수님 강의, 서울대 언어학과 신효필 교수님 저서, 위키피디아 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concepts 자연언어처리 분야에서는 **다항로지스틱 회귀(multinominal logistic regression)**를 최대엔트로피모델이라 부릅니다. 다항로지스틱 회귀에 대한 자세한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/04/02/logistic/)을 참고하시면 좋을 것 같습니다. 단어 $x$가 주어졌을 때 범주(예 : 품사) $c$가 나타날 확률은 다음과 같습니다.  $$ P(c|x)=\frac { exp\left( { \overrightarrow { { w }_{ c } } }^{ T }\overrightarrow { f } \right) }{ \sum _{ c'\in C }^{ }{ { exp( }{ \overrightarrow { { w }_{ c' } } }^{ T }\overrightarrow { f } ) } } $$  위 식에서 벡터 $f$는 단어 $x$에 해당하는 자질(feature)들의 모음입니다. 예컨대 자질 벡터의 첫번째 요소는 '직전 단어가 명사이면 1, 그렇지 않으면 0', 두번째 요소는 '현재 단어가 동사이면 1, 아니면 0'... 이런 식으로 $f$의 요소값들을 구성합니다. $w_c$는 자질벡터 $f$만큼의 차원수를 갖는 가중치 벡터입니다. 분류해야 할 범주의 개수만큼 필요합니다. 데이터가 주어지면 그래디언트 어센트 등 기법으로 우도를 최대화하는 방향으로 학습됩니다. 자질벡터의 특정 요소를 집중 반영하거나, 특정 범주에만 높은 확률을 내지 않도록 정규화(regularization)도 수행해 줍니다. 로지스틱 회귀의 학습에 대해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/07/02/logistic/), 정규화에 대해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/22/RLR/)을 참고하시면 좋을 것 같습니다.   ## feature vector 최대엔트로피모델의 핵심은 자질벡터입니다. 연구자의 언어학적 사전지식을 매우 유연하게 반영할 수 있기 때문에, 초기값 설정에만 개입할 수 있는 [은닉마코프모델](https://ratsgo.github.io/machine%20learning/2017/03/18/HMMs/) 등과 비교해 최대엔트로피모델의 강점이라고 말할 수 있겠습니다. (물론 자질 요소들을 연구자가 일일이 수작업으로 지정해주어야 하기 때문에 최대 약점으로 꼽히기도 합니다) 예컨대 다음과 같은 문장이 주어졌고, 최대엔트로피모델은 이미 4개 단어에 대한 품사 분류를 마쳤으며, 이번에는 'race'를 예측해야 한다고 가정해 보겠습니다. (최대엔트로피모델은 이전 예측결과만 분류에 활용) > Secretariat**/NNP** is**/BEZ** expected**/VBZ** to**/TO** race tomorrow 현재 단어 $x$는 'race'입니다. $x$가 가질 수 있는 범주는 동사, 명사 두 개뿐이라고 연구자가 판단했다고 가정해 보겠습니다. 즉 $C$={VB, NN}입니다. $c$와 $x$가 주어졌을 때 자질벡터의 $i$번째 요소값을 만들어내는 함수 $f_i(c,x)$를 연구자의 언어학적 사전지식을 반영해 다음과 같이 정의했다고 치겠습니다.  <a href="https://imgur.com/9kqNqZy"><img src="https://i.imgur.com/9kqNqZy.png" width="400px" title="source: imgur.com" /></a>  자질함수는 6개, 'race'가 가질 수 있는 범주는 2개라고 정의했기 때문에 자질벡터 $f(c,x)$는 6차원이며, 동사 명사 각각 하나씩 총 2개 만들어 집니다. 다음과 같습니다. |  notation  |   value   | | :----------: | :-----------: | | $f(VB,race)$ | [0,1,0,1,1,0] | | $f(NN,race)$ | [1,0,0,0,0,1] |   ## prediction 다항로지스틱 모델의 파라메터($w$)는 이미 학습이 끝났다고 가정하고 자질벡터를 입력으로 예측이 어떻게 이뤄지는지 살펴보겠습니다. 먼저 동사 먼저 보겠습니다. 아래 표에서 자질벡터 요소값과 그에 해당하는 가중치를 곱합니다. |   차원수   | $f_1$ | $f_2$ | $f_3$ | $f_4$ | $f_5$ | $f_6$ | | :----------: | :---: | :---: | :---: | :---: | :---: | :---: | | $f(VB,race)$ |  0  |  1  |  0  |  1  |  1  |  0  | |  $w_{VB}$  |    | .8  |    | .01 | .1  |    | 다음은 명사입니다. 위와 동일한 과정을 거칩니다. |   차원수   | $f_1$ | $f_2$ | $f_3$ | $f_4$ | $f_5$ | $f_6$ | | :----------: | :---: | :---: | :---: | :---: | :---: | :---: | | $f(NN,race)$ |  1  |  0  |  0  |  0  |  0  |  1  | |  $w_{NN}$  | .8  |    |    |    |    | -1.3 | 이제 'race'가 각 범주에 속할 확률을 계산해 보겠습니다. 다음과 같습니다. 따라서 race는 동사로 분류합니다.  $$ P\left( VB|race \right) =\frac { { e }^{ .8+.01+.1 } }{ { e }^{ .8+.01+.1 }+{ e }^{ .8-1.3 } } =0.8\\ P\left( NN|race \right) =\frac { { e }^{ .8-1.3 } }{ { e }^{ .8+.01+.1 }+{ e }^{ .8-1.3 } } =0.2 $$    ## Why Maximum Entropy? 최대엔트로피모델은 그럼 왜 이런 이름이 붙은 걸까요? 최대엔트로피모델을 구축하려면 먼저 해당 단어가 가질 수 있는 품사를 가려내고, 자질도 정의해야 하는데요. 예컨대 'zzfish'라는 단어의 품사를 예측한다고 가정해 보겠습니다.  연구자가 난생 처음 보는 단어라서 품사 후보들을 가려내기 어렵고 자질과 관련해 'zzfish'에 대한 어떤 가정도 할 수 없습니다. 이 경우 해당 언어(영어)에 존재하는 모든 품사 종류(예컨대 45개)가 후보에 오를 것입니다. 모델 예측 결과가 다음 표와 같이 같은 확률을 가진 분포(equiprobable distribution)가 된다면 이상적입니다. | NN | JJ | NNS | VB | NNP | ... | | :--: | :--: | :--: | :--: | :--: | :--: | | 1/45 | 1/45 | 1/45 | 1/45 | 1/45 | ... | 그런데 연구자가 말뭉치를 살펴보니 'fish'가 포함된 단어는 그 품사의 종류가 명사(NN), 형용사(JJ), 복수형 명사(NNS), 동사(VB)라는 사실을 알게 됐다고 가정해 보겠습니다. 연구자가 품사 후보를 이같이 정한다면 'zzfish'의 품사는 이 네 가지 중 하나가 될 것입니다. 하지만 추가 가정이 없기 때문에 모델은 넷 사이에서는 같은 확률로 예측하기를 기대합니다. | NN | JJ | NNS | VB | NNP | ... | | :--: | :--: | :--: | :--: | :--: | :--: | | 1/4 | 1/4 | 1/4 | 1/4 | 0  | ... | 말뭉치를 보니 'zzfish' 10개 중 8개는 명사라고 칩시다. 이걸 보고 연구자는 현재 예측할 단어 $x$가 'zzfish'이고, $c$가 명사나 복수형 명사이면 1로 하는 자질함수를 정의했습니다. 따라서 우리는 품사 분포는 다음과 같이 바뀌기를 기대합니다. | NN | JJ | NNS | VB | NNP | ... | | :--: | :--: | :--: | :--: | :--: | :--: | | 4/10 | 1/10 | 4/10 | 1/10 | 0  | ... | 우리가 가진 말뭉치에서 'zzfish'에 대한 정보를 최대한 다 뽑아 냈다고 칩시다. 그런데 연구자가 영어 전체 말뭉치를 살펴보니 동사는 평균적으로 1/20의 확률로 나타났다는 사실을 알게 됐습니다. 그러면 분포가 또 바뀝니다. | NN | JJ | NNS | VB | NNP | ... | | :--: | :--: | :--: | :--: | :--: | :--: | | 4/10 | 3/20 | 4/10 | 1/20 | 0  | ... | [엔트로피](https://ratsgo.github.io/statistics/2017/09/22/information/)란 불확실성 정도를 나타내는 지표입니다. 위 네 개 케이스에 대해 엔트로피(밑이 2인 log로 계산)를 구하면 각각 5.491, 2, 1.722, 1.6842입니다. 균등한 분포일 때 엔트로피가 제일 높고, 분포가 불균등해질 수록 엔트로피가 점점 낮아지는 것을 확인할 수 있습니다. 그런데 위 과정을 천천히 살펴보면 연구자가 말뭉치를 관찰하면서 알게 된 사실이 범주 후보나 자질 함수의 형태로 추가되면서 점점 불균등한 분포를 띄게 됐습니다. 다시 말해 추가적인 정보나 전제가 없다면 최대엔트로피모델은 균등한 분포를 전제하고, 이는 최대 엔트로피를 지니게 된다는 이야기입니다.
information␞ 이번 글에서는 정보이론(Information Theory)의 기본 개념들을 살펴보도록 하겠습니다. 이 글은 Ian Goodfellow 등이 집필한 Deep Learning Book과 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 개요 정보이론은 시그널에 존재하는 정보의 양을 측정하는 응용수학의 한 갈래입니다. 정보이론은 무선전송을 통해 알파벳으로 된 메세지를 보내려는 연구에서 시작되었습니다. 이 때 정보이론은 최적의 코드를 디자인하고, 메세지의 기대 길이(expected length)를 계산하는 데 도움이 됩니다. 머신러닝에서는 해당 확률분포의 특성을 알아내거나 확률분포 간 유사성을 정량화하는 데 쓰입니다. 정보이론의 핵심 아이디어는 잘 일어나지 않는 사건(unlikely event)은 자주 발생하는 사건보다 정보량이 많다(informative)는 것입니다. 예컨대 '아침에 해가 뜬다'는 메세지로 보낼 필요가 없을 정도로 정보 가치가 없습니다. 그러나 '오늘 아침에 일식이 있었다'는 메세지는 정보량 측면에서 매우 중요한 사건입니다. 이 아이디어를 공식화해서 표현하면 다음과 같습니다. - 자주 발생하는 사건은 낮은 정보량을 가진다. 발생이 보장된 사건은 그 내용에 상관없이 전혀 정보가 없다는 걸 뜻한다. - 덜 자주 발생하는 사건은 더 높은 정보량을 가진다. - 독립사건(independent event)은 추가적인 정보량(additive information)을 가진다. 예컨대 동전을 던져 앞면이 두번 나오는 사건에 대한 정보량은 동전을 던져 앞면이 한번 나오는 정보량의 두 배이다.   ## 섀넌 엔트로피 위 세 가지 조건을 만족하는 함수는 발생 가능한 사건이나 메세지의 확률분포에 음의 로그를 취한 수식입니다. 확률변수 $X$의 값이 $x$인 사건의 정보량은 아래와 같습니다.  $$ I\left( x \right) =-\log { P(x) } $$  예컨대 동전을 던져 앞면이 나오는 사건과 주사위를 던져 눈이 1이 나오는 사건, 두 개의 정보량을 비교해보겠습니다. 전자의 정보량은 $-\log_{2}{0.5}=1$, 후자는 $-\log_{2}{1/6}=2.5849$가 됩니다. 다시 말해 주사위 눈이 1이 나올 사건은 동전의 앞면이 나오는 사건보다 덜 자주 발생하므로 더 높은 정보량을 갖는다는 의미입니다.  위 식에서 밑이 2인 경우 정보량의 단위를 섀년(shannon) 또는 비트(bit)라고 합니다. 자연상수(exp)를 밑으로 할 경우 내트(nat)라고 부릅니다. 머신러닝에서는 대개 밑을 자연상수로 사용합니다. **섀넌 엔트로피(Shannon entropy)**는 모든 사건 정보량의 기대값을 뜻합니다. 전체 사건의 확률분포의 불확실성의 양을 나타낼 때 씁니다. 어떤 확률분포 $P$에 대한 섀넌 엔트로피 $H(P)$는 다음과 같습니다.  $$ H\left( P \right) =H\left( x\right) ={ E }_{ X\sim P }\left[ I\left( x \right) \right] =-{ E }_{ X\sim P }\left[ \log { P(x) } \right] $$  앞면, 뒷면이 나올 확률이 동일한, 공평한 동전을 1번 던지면 섀년 엔트로피는 발생 가능한 모든 결과의 가지 수(2)에 밑이 2인 로그를 취한 것(=1비트)과 같습니다. 이를 식으로 풀어 쓰면 다음과 같습니다.  $$ \begin{align*} H\left( P \right)= H\left( x \right) &=-\sum _{ x }^{ }{ P({ x })\log { P({ x }) } } \\ &=-\left( 0.5\times \log _{ 2 }{ 0.5 } +0.5\times \log _{ 2 }{ 0.5 } \right) \\ &=-\log _{ 2 }{ 0.5 } \\ &=-(-1) \end{align*} $$   마찬가지로 2개 동전을 던지면 4가지 결과가 발생하고 섀년 엔트로피는 2비트가 됩니다. 다시 말해 서로 독립인 두 확률변수의 섀넌 엔트로피는 각 확률변수의 엔트로피 합과 같게 됩니다. 이를 그림으로 나타내면 다음과 같습니다.  <a href="https://imgur.com/PMVu70y"><img src="https://i.imgur.com/PMVu70y.jpg" width="400px" title="source: imgur.com" /></a>  사건의 분포가 결정적(deterministic)이라면 해당 확률분포의 불확실성 정도를 나타내는 엔트로피는 낮아집니다. 반대로 분포가 균등적(uniform)일 수록 엔트로피는 높아집니다. 동전 던지기 예를 다시 들면, 절대로 뒷면이 나오지 않는 동전을 던지는 건 아무런 정보를 가지지 않습니다. 항상 앞면이 나와서 불확실성이 전혀 없기 때문입니다. 하지만 공평한 동전을 던질 경우 엔트로피는 가장 높습니다. 결과값을 예상하기가 가장 어렵기 때문입니다.   <a href="https://imgur.com/Pynf9sG"><img src="https://i.imgur.com/Pynf9sG.png" width="400px" title="source: imgur.com" /></a>  위 그래프는 동전을 한번 던졌을 때 섀넌 엔트로피의 변화를 나타낸 그림입니다. $x$축은 동전의 공정한 정도(1, 즉 앞면이 나올 확률)를 나타냅니다. 0.5라면 앞면, 뒷면이 나올 확률이 각각 동일한 공평한 동전이라는 뜻입니다. $y$축은 섀넌 엔트로피를 가리킵니다. 여기서는 공평한 동전을 사용할 경우가 가장 큰 엔트로피(1비트)를 나타내고 있습니다. 동전 던지기 결과값을 어딘가에 전송할 경우 공평한 동전을 쓸 때 최대 1비트가 필요함을 알 수 있습니다.   ## KL Divergence 쿨백-라이블러 발산(Kullback-Leibler divergence, KLD)은 두 확률분포의 차이를 계산하는 데 사용하는 함수입니다. 딥러닝 모델을 만들 때 예로 들면 우리가 가지고 있는 데이터의 분포 $P(x)$와 모델이 추정한 데이터의 분포 $Q(x)$ 간에 차이를 KLD를 활용해 구할 수 있습니다. KLD의 식은 다음과 같이 정의됩니다.  $$ { D }_{ KL }\left( P||Q \right) ={ E }_{ X\sim P }\left[ \log { \frac { P\left( x \right) }{ Q(x) } } \right] ={ E }_{ X\sim P }\left[ \log { P(x) } -\log { Q(x) } \right] $$  $P$와 $Q$가 동일한 확률분포일 경우 KLD는 정의에 따라 그 값이 0이 됩니다. 하지만 KLD는 비대칭(not symmetric)으로 $P$와 $Q$ 위치가 뒤바뀌면 KLD 값도 달라집니다. 따라서 KLD는 거리함수로는 사용할 수 없습니다.   ## 크로스 엔트로피 KLD는 딥러닝 모델의 손실함수(loss function)로 자주 쓰이는 크로스 엔트로피(cross entropy)와 깊은 관련을 맺고 있습니다. $P$와 $Q$에 대한 크로스 엔트로피 $H(P,Q)$와 KLD와의 관계식은 다음과 같습니다.  $$ H\left( P,Q \right) =H\left( P \right) +{ D }_{ KL }\left( P||Q \right) $$  딥러닝 모델을 학습할 때 크로스 엔트로피를 최소화하는 방향으로 파라메터(가중치)들을 업데이트 합니다. 그런데 $Q$에 대해 크로스 엔트로피를 최소화한다는 것은 KLD를 최소화하는 것과 그 의미가 완전히 같습니다(equivalent). 왜냐하면 $P$는 우리가 가지고 있는 데이터의 분포를 가리키는데, $P$가 학습 과정에서 바뀌는 것이 아니기 때문입니다.  어쨌든 크로스 엔트로피 최소화는 KLD 최소화와 같은 의미이며 우리가 가지고 있는 데이터의 분포 $P(x)$와 모델이 추정한 데이터의 분포 $Q(x)$ 간에 차이를 최소화한다는 정도로 이해하면 좋을 것 같습니다. 딥러닝 모델의 입력값으로 쓰이는 관측치는 이산변수(discrete variable)에 해당하므로 크로스 엔트로피 $H(P,Q)$의 식을 다시 쓰면 다음과 같습니다.  $$ H\left( P,Q \right) =-{ E }_{ X\sim P }\left[ \log { Q(x) } \right] =-\sum _{ x }^{ }{ P({ x })\log { Q({ x }) } } $$  보시다시피 $H(P,Q)$는 $P$의 엔트로피인 $H(P)$와 유사한 꼴이나 로그 바깥에 곱해지는 확률이 $P(x)$이고, 로그 안에 들어가는 것이 $Q(x)$인 것을 확인할 수 있습니다. 엔트로피는 엔트로피이되 두 확률분포가 교차로 곱해진다는 의미로 크로스(cross) 엔트로피라는 이름이 붙은 것 같습니다.
visual␞ 이번 글에서는 데이터 시각화 관련 코드를 정리해보겠습니다. 분석한 결과를 예쁘게 포장할 때 유용한 팁들인데요. 분석 자체에만 신경쓰다가 정작 시각화에는 실패하는 경우가 저 경험상 많았는데요. 시간도 없고 힘들어 죽겠는데 시각화 코드를 일일이 찾아 검색하는 것도 한계가 있고요. 그래서 저도 정리 겸 해서 이런 글을 쓰게 됐습니다.  출처를 일일이 밝혀야 하는데, 저도 어디서 검색했는지 가물가물한 코드가 많아서..(죄송합니다) 혹시 출처를 확실히 알고 계신 분이 있으시면 댓글로 남겨주셔요. 바로 반영하겠습니다. 단행본 '조엘 그루스(2015), 밑바닥부터 시작하는 데이터과학' 등을 비롯해 다양한 자료를 참고하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 꺾은선 그래프, python <a href="http://imgur.com/XzFkNlB"><img src="http://i.imgur.com/XzFkNlB.png" width="400px" title="source: imgur.com" /></a> ```python from matplotlib import pyplot as plt years = [1950, 1960, 1970, 1980, 1990, 2000, 2010] gdp = [300.2, 543.3, 1075.9, 2862.5, 5979.6, 10289.7, 14958.3] plt.plot(years,gdp,color='green',marker='o',linestyle='solid') plt.title('Nominal GDP') plt.ylabel("Billions of $") plt.show() ```   ## 막대 그래프, python <a href="http://imgur.com/RNDL1r6"><img src="http://i.imgur.com/RNDL1r6.png" width="400px" title="source: imgur.com" /></a> ```python from matplotlib import pyplot as plt movies = ['Annie Hall','Ben-Hur','Casablanca','Gandhi','West Side Story'] num_of_oscars = [5,11,3,8,10] # 막대 너비의 기본값이 0.8이므로 막대가 가운데로 올 수 있도록 # 왼쪽 좌표에 0.1씩 더해줌 xs = [i + 0.1 for i, _ in enumerate(movies)] plt.bar(xs,num_of_oscars) plt.ylabel('# of Academy Awards') plt.title('My Favorite Movies') # 막대의 가운데에 오도록 영화 제목 레이블을 달자 plt.xticks([i + 0.5 for i, _ in enumerate(movies)],movies) plt.show() ```   ## 히스토그램, python <a href="http://imgur.com/VLcVxeF"><img src="http://i.imgur.com/VLcVxeF.png" width="400px" title="source: imgur.com" /></a> ```python from matplotlib import pyplot as plt from collections import Counter grades = [83,95,91,87,70,0,85,82,100,67,73,77,0] decile = lambda grade: grade // 10 * 10 # counter는 key와 value의 빈도를 연결시켜준다 histrogram = Counter(decile(grade) for grade in grades) plt.bar([x-4 for x in histrogram.keys()], histrogram.values(), 8) # X축은 -5부터 105, Y축은 0부터 5 plt.axis([-5,105,0,5]) # X축의 레이블은 0, 10, ..., 100 plt.xticks([10 * i for i in range(11)]) plt.xlabel("Decile") plt.ylabel('# of Students') plt.title('Distribution of Exam 1 Grades') plt.show() ```   ## 선 그래프, python <a href="http://imgur.com/jTg5V7B"><img src="http://i.imgur.com/jTg5V7B.png" width="400px" title="source: imgur.com" /></a> ```python from matplotlib import pyplot as plt variance = [1,2,4,8,16,32,64,128,256] bias_squared = [256,128,64,32,16,8,4,2,1] total_error = [x + y for x, y in zip(variance, bias_squared)] xs = [i for i, _ in enumerate(variance)] plt.plot(xs, variance, 'g-', label='variance') # 녹색 실선 plt.plot(xs, bias_squared, 'r-', label='bias^2') # 빨간 실선 plt.plot(xs, total_error, 'b:', label='total error') # 파란 점선 plt.legend(loc=9) # 범례 그리기, loc=9 ; top center를 의미 plt.xlabel('model complexity') plt.title('The Bias-Variance Tradeoff') plt.show() ```   ## 산점도, python <a href="http://imgur.com/DClUpXn"><img src="http://i.imgur.com/DClUpXn.png" width="400px" title="source: imgur.com" /></a> ```python from matplotlib import pyplot as plt friends = [70,65,72,63,71,64,60,64,67] minutes = [175,170,205,120,220,130,105,145,190] labels = ['a','b','c','d','e','f','g','h','i'] plt.scatter(friends,minutes) # 각 포인트에 레이블 달기 for label, friend_count, minute_count in zip(labels, friends, minutes):   plt.annotate(label,         xy=(friend_count, minute_count), #label을 데이터포인트에 두되         xytext=(5,-5), # 약간 떨어져 있게         textcoords='offset points') plt.title('Daily Minutes vs. Number of Friends') plt.xlabel('# of friends') plt.ylabel('daily minutes spent on the site') plt.show ```   ## 산점도, R <a href="http://imgur.com/itkill2"><img src="http://i.imgur.com/itkill2.png" width="600px" title="source: imgur.com" /></a> ```R library(ggplot2) pcadata <- data.frame(princomp(iris[,-5])$scores[,1:2],iris[,5]) colnames(pcadata) <- c('V1','V2','Class') ggplot(pcadata,    aes(x=V1,y=V2,color=Class)) + geom_point(size=1.25) +  guides(colour = guide_legend(override.aes = list(size=5))) +  xlab("") + ylab("") + ggtitle("PCA 2D Embedding of Data") +  theme_light(base_size=10) +  theme(strip.background = element_blank(),     strip.text.x   = element_blank(),     axis.text.x   = element_blank(),     axis.text.y   = element_blank(),     axis.ticks    = element_blank(),     axis.line    = element_blank(),     panel.border  = element_blank()) ggsave('PCA.png') ```    ## heatmap, python <a href="http://imgur.com/OQsYjHT"><img src="http://i.imgur.com/OQsYjHT.png" width="400px" title="source: imgur.com" /></a> ```python import matplotlib.pyplot as plt import numpy as np #here's our data to plot, all normal Python lists x = [1, 2, 3, 4, 5] y = [0.1, 0.2, 0.3, 0.4, 0.5] intensity = [[5, 10, 15, 20, 25],       [30, 35, 40, 45, 50],       [55, 60, 65, 70, 75],       [80, 85, 90, 95, 100],   [    105, 110, 115, 120, 125]] #setup the 2D grid with Numpy x, y = np.meshgrid(x, y) #convert intensity (list of lists) to a numpy array for plotting intensity = np.array(intensity) #now just plug the data into pcolormesh, it's that easy! plt.pcolormesh(x, y, intensity) plt.colorbar() #need a colorbar to show the intensity scale plt.show() #boom ```   ## Boxplot, python <a href="http://imgur.com/dwaSBD7"><img src="http://i.imgur.com/dwaSBD7.png" width="400px" title="source: imgur.com" /></a> ```python import seaborn as sns import matplotlib.pyplot as plt plt.figure(figsize = (35, 12)) sns.boxplot(y = 'y', x = 'x', data = data, width = 0.8, showmeans = True, fliersize = 3) plt.show() ```   ## Joint Plot, python <a href="http://imgur.com/U8IfuVg"><img src="http://i.imgur.com/U8IfuVg.png" width="400px" title="source: imgur.com" /></a> ```python import seaborn as sns import matplotlib.pyplot as plt plt.figure(figsize = (30, 20)) sns.jointplot(x = "x", y = "y", data = data, kind = 'scatter', size = 10) plt.show() ``` 
advp␞ 이번 글에서는 한국어의 부사절 내포에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 부사절 내포 부사절이란 부사 역할을 하는 절이 내포된 경우를 가리킵니다. 예문을 보겠습니다. |    부사    |     부사절     | | :-------------: | :-------------------: | | 빙수가 **매우** 차갑다. | 빙수가 **[이가 시리게]** 차갑다. | 주어+서술어 형태의 '절'처럼 보이진 않지만 다음과 같은 예문도 부사절 내포 구성이라고 볼 수 있습니다. > 꽃$i$이 [$e_i$ 아름답게] 피었다. 위 예문은 (1) 꽃이 아름답다 (2) 꽃이 피었다 두 문장이 합쳐진 형태라고 볼 수 있습니다. 여기에서 '꽃이'가 공통 명사로 생략되었습니다. 내포절 '아름답게'가 문장 전체에서 부사 역할을 하므로 부사절이라고 볼 수 있습니다. 이 글에서는 한국어의 부사절 내포를 부사형 전성어미의 종류와 관련지어 설명하겠습니다.   ## 개괄 부사형 전성어미와 그 문법적 기능을 정리한 표는 다음과 같습니다. | 문법적 기능 | 부사형 전성어미             | | ------ | -------------------------------- | | 동시적 사건 | -으면서, -으며            | | 계기적 사건 | -자, -자마자, -고(서), -어(서)      | | 사건의 전환 | -다가               | | 이유, 원인 | -어(서), -으니까, -느라고, -다가, -기에, -길래 | | 조건, 가정 | -으면, -거든, -어야          | | 인정, 양보 | -어도, -을지라도, -더라도, -어야, -은들, -을망정 | | 목적   | -으려고, -고자            | | 배경   | -는데, -으니             |   ## -게 부사형 전성어미 '-게'는 다음과 같이 쓰입니다. |   의미   |        예문        | | :--------: | :-----------------------------: | | 성질, 상태, 방식 |     그는 [고독하게] 살았다.     | |  결과적 한계  |    나는 [발에 피가 나게] 뛰었다.    | |   목적   | 나는 [진이가 집중해서 공부할 수 있게] 방에서 나갔다. |   ## -도록 부사형 전성어미 '-도록'은 다음과 같이 쓰입니다. |  의미  |        예문        | | :----: | :------------------------------: | | 시간적 한계 |   나는 [밤이 새도록] 시험공부를 했다.    | | 결과적 한계 |    나는 [발에 피가 나도록] 뛰었다.    | |  목적  | 나는 [진이가 집중해서 공부할 수 있도록] 방에서 나갔다. |   ## -게 vs -도록 '-게'와 '-도록'은 결과적 한계, 목적 등 많은 면에서 그 의미가 유사합니다. 하지만 성질, 상태, 방식에 대해선 '-게'를, 시간적 한계에는 '-도록'을 씁니다. > 그는 [{고독하게, *고독하도록}] 살았다. > > 나는 [밤이 {*새게, 새도록}] 시험공부를 했다.   ## -이, -을수록, -듯(이) 부사형 전성어미 '-이'는 결합하는 서술어가 '다르다, 같다, 없다'로 한정됩니다. > [미국과 달리] 한국 여성들은 결혼 후에도 본래의 성을 쓴다. > > 우리는 [돈 없이] 1주일을 더 견뎌야 한다. > > 아이가 [꽃과 같이] 예쁘다. '-을수록'은 점차 심해짐의 의미를 나타냅니다. > [날이 갈수록] 취업이 어려워지고 있습니다. '-듯(이)'는 유사한점을 비유적으로 표현할 때 씁니다. 앞 절의 내용이 뒤 절의 내용과 거의 같음을 나타냅니다. > 나그네가 [달이 구름에 가듯(이)] 걸어간다.   ## -으면서, -으며 이들 어미는 동시에 발생하는 사건을 나타냅니다. > 진이가 노래를 들**으면서** 밥을 먹는다.   ## -자/자마자 vs -고(서)/어(서) 이들 어미는 연이어서 나타나는 사건을 뜻하는 **계기적 사건**을 가리킵니다. 아래 (가)는 선행절이 나타내는 사건과 후행절의 사건이 거의 즉시 발생하는 경우를, (나)는 시간차가 있는 경우를 의미합니다. > 진이가 학교에 가자/가자마자 친구들이 환호성을 질렀다. (즉시) > > 종이배를 접어서 시냇물에 띄웠다. (시간차)   ## -자마자 vs -자 '-자마자'와 '-자'는 모두 앞 절의 동작이 이루어진 후 바로 뒤이어 다음 절의 사건이나 동작이 일어남을 나타냅니다. '-자마자'는 뒤 절에 명령문이나 청유문이 올 수 있고, 앞 절 주어와 뒤 절 주어가 같아도 되고 달라도 됩니다. 반면 '-자'는 뒤 절에 명령문이나 청유문이 올 수 없고, 앞 절 주어와 뒤 절 주어가 같을 때 제약이 있습니다. |      -자마자      |      -자      | | :-----------------------: | :---------------------: | |   회의가 끝나자마자 연락하세요.   |   *회의가 끝나자 연락하세요.   | |  나는 집에 오자마자 손을 씻었다.   |  *나는 집에 오자 손을 씻었다.  | | 내가 집에 도착하자마자 강아지가 달려 나왔다. | 내가 집에 도착하자 강아지가 달려 나왔다. |   ## -어서 vs -고서 '-어서'와 '-고서'는 동사 뒤에 결합하여 행동의 시간적 순서를 나타냅니다. '-어서'의 경우 앞 절은 뒤 절의 조건이 되며 서로 밀접한 관계를 가집니다. 앞 절의 동작이 없이는 뒤 절이 이뤄질 수 없습니다. 반면 '-고서'는 끝점이 있는 타동사와 결합하여 앞 절 동작의 결과가 지속되면서 뒤 절의 내용이 진행될 때 사용할 수 있습니다. 예문을 보겠습니다. > (A) 숙제를 해서 오세요. > > (B) 숙제를 하고서 오세요. (A)는 숙제를 한 다음 그 숙제를 가지고 오라는 느낌이 약간 강합니다. (B)는 숙제를 마치고, 오라는 느낌이 있습니다. 다른 예문을 보겠습니다. |     -어서     |      -고서      | | :-----------------: | :-----------------------: | |  도서관에 가서 공부했어요.  |  진이는 친구를 만나고서 학교에 갔다.  | |  돈을 모아서 여행을 했어요.  |   *배가 고프고서 밥을 먹었다.   | |  어제 책을 사서 읽었어요.  | 언니가 새 정장을 입고서 면접을 보러 나갔다. | | *어제 책을 사서 친구를 만났어요. |   배를 타고서 제주도에 갔어요.   |   ## -다가 '-다가'는 선행절이 중단되고 다른 상황이 이어짐, 즉 사건의 전환을 나타냅니다. 다음 예문과 같습니다. > 진이가 운동을 하다가 쓰러졌다. 앞 절의 행동이 계속되면서 추가로 뒤 절의 행동이 일어나는 경우에도 사용할 수 있습니다. > 잠을 자다가 무서운 꿈을 꿨어요.   ## -어(서) 필연적인 인과관계가 있을 때 '-어(서)'를 쓰면 자연스럽습니다. 따라서 일반적인 자연의 현상이나 사물의 변화로 발생한 결과를 설명할 때 '-어서'를 주로 사용합니다. 예문을 보겠습니다. > 비행기가 추락해서 사람들이 많이 죽었다. > > 비가 많이 내려서 홍수가 났다. > > 진이가 아들만 셋을 ?낳아서 이번에는 딸을 낳을거야. 마지막 문장은 조금 부자연스럽습니다. 아들 셋을 낳은 사실과 딸을 낳을 거라는 추측에 필연적인 인과관계가 있지 않기 때문인듯합니다. 다음 예문처럼 '-어(서)' 앞에 오는 말은 새로운 정보(주제)인 경향이 있습니다.  > Q: 어머니가 **왜** 걱정을 하시지? > > A: **진이가 아파서** 걱정을 하셔. '-어(서)' 뒤 절에는 청유문과 명령문을 사용할 수 없습니다. > *시간이 없어서 서두르세요. > > *시간이 없어서 서두릅시다.   ## -으니까 화자 나름의 주관적인 이유를 제시할 때나, 주관적인 추론의 전제를 제시할 때 '-으니까'가 주로 쓰입니다. 다음 예문과 같습니다. > 집에서 책만 읽으니까 친구가 없지. > > 진이가 아들만 셋을 낳았으니까 이번에는 딸을 낳을거야. > > 대문 앞에 신문이 쌓여 있으니까 집 안에 사람이 없는 게 틀림없어. 위 예문에서 두번째, 세번째 문장에 '-어(서)'를 넣어서 비교해보면 그 뉘앙스 차이를 느낄 수 있습니다. 다시 말해 아들 낳은 사실, 대문 앞에 신문이 쌓여있는 사실은 각각 딸을 낳는 것과 집안에 사람이 없다는 사실과 직접적인 관련이 없습니다. '-으니까' 뒤에 오는 말이 새로운 정보인 경우가 많습니다. > Q: **장마 기간인데** 물가가 어때? > > A: **장마 기간이 되니까** 채소 값이 올랐어.   ## -어(서) vs -으니까 아래 예문에서 '피곤해서'와 '피곤하니까'의 뉘앙스 차이에 주목해 봅시다.  > A: 나 오늘 일찍 퇴근해야겠어. > > B: 왜? > > A1: 피곤해서. > > A2: 피곤하니까. '피곤하니까'는 '피곤해서'에 비해 약간 짜증스러움이 묻어난다는 게 느껴집니다. 다시 말해 '당신도 내가 피곤하다는 사실을 이미 알고 있으면서 왜 굳이 다시 물어보느냐'라는 어감이 나타난다는 것입니다. 이는 '-어(서)'와 '-으니까' 앞에 오는 말이 각각 신정보, 구정보에 해당하기 때문이라고 설명을 할 수 있겠습니다. 다음 예문에서 (2)가 비문이 되는 이유도 이의 연장선상에 있습니다. > (1) 배가 아파서 어제 결석했습니다. > > (2) 배가 *아프니까 어제 결석했습니다. 앞에 어떤 이유를 제시하고 그로 인해 뒤따르는 새로운 상황을 명령문이나 청유문의 형태로 제시할 때는 '-으니까'만이 쓰입니다. > 아기가 {자니까, *자서} 조용히 해라.   ## -으면 앞 말이 조건, 가정일 때 '-으면'을 씁니다. 뒤 절 문장 유형에 제약이 없습니다. > 내일 날씨가 화창하면 소풍을 {갑니다., 갑니까? 갑시다., 가십시오.}   ## -거든 앞 말이 조건, 가정이면서 전체 문장이 명령문, 청유문일 때 대개 '-거든'이 쓰입니다. > 가는 길에 진이 만나거든 전화 좀 하라고 해. > > 손님이 오시거든 먹겠니? > > *호랑이도 제 말을 하거든 온다.   ## -어야 앞의 내용이 조건, 가정이면서 뒤에 오는 내용의 필수 조건임을 나타냅니다. 명령문, 청유문에서는 쓰일 수 없습니다. > 윗물이 맑아야 아랫물이 맑다. > > *비가 와야 우산을 가지고 가라. (명령문) > > *호랑이를 만나야 혼내주겠다. (필수 조건 아님)   ## -어도, -을지라도, -더라도, -어야, -은들, -을망정 '-어도', '-을지라도', '-더라도', '-어야', '-은들', '-을망정'은 내포절을 **양보**의 기능을 하도록 만드는 부사형 전성어미입니다. 양보란 종속절의 사태로 인하여 논리적으로 도출되는 사태가 주절에 이어지는 것이 아니라, 일반적으로 예상되는 것과는 반대되는 결과가 주절에 이어지는 걸 말합니다. 다음 예문과 같습니다. > (가) 아무리 바쁘더라도 차 한잔 마실 시간은 있다. > > (나) 비가 와도 여행을 갈 거야. (가)의 경우 종속절의 사태로 논리적으로 도출되는 사태는 '아주 바쁘면 차 한잔 마실 시간도 없다'가 됩니다. 하지만 이와 반대되는 내용이 주절에 언급이 되면서 '-더라도'가 쓰였습니다. 마찬가지로 (나)에선 '비가 오면 여행을 가지 않는다'가 예상됐는데 여행을 간다고 언급이 되면서 '-어도'가 쓰였습니다.   ## -으려고 앞의 내용이 목적이면서 앞 절과 뒤 절에 오는 동사에 제약이 없습니다. > 진이는 머리를 자르려고 미용실을 예약했다. 하지만 뒤 절에 청유문과 명령문이 올 수 없습니다. > *고기를 잡으려고 바다로 가자.   ## -고자 앞의 내용이 목적이면서 주로 격식을 갖춘 말이나 공식적인 장소에서의 대화, 글에서 많이 사용되는 부사형 전성어미입니다. > 이 논문에서는 한국어의 중국어의 부정법을 대조하고자 한다.   ## -으러 앞의 내용이 목적이면서 선행절의 서술어가 동작동사이고 후행절의 서술어가 이동동사일 때만 쓸 수 있습니다. > 진이는 머리를 자르러 미용실에 갔다. > > *예뻐지러 미용실에 갔다. > > *지이는 나를 안 만나러 서울로 갔다. > > *파마를 하러 미용실을 예약했다. 명령문과 청유문에서 쓰일 수 있습니다. > 고기를 {잡으러/\*잡으려고/\*잡고자} 바다로 가자.   ## -는데, -으니 '-는데'와 '-으니'는 앞 절이 뒤 절의 배경이나 상황일 때 씁니다. > 집에 가는데 소나기가 내렸다. > > 서울역에 가 보니 사람이 정말 많았다. 
tfidf␞ 이번 포스팅에선 단어 가중치 할당 방법론인 **TF-IDF**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의를 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## TF, IDF **TF(Term Frequency)**는 어떤 단어가 특정 문서에 얼마나 많이 쓰였는지 빈도를 나타냅니다. 많이 쓰인 단어가 중요하다는 가정을 전제로 한 수치입니다. 예컨대 A라는 단어가 doc1에서 10번, doc3에서 5번 쓰였다면 doc1-단어A의 TF는 10, doc3-단어A의 TF는 5가 됩니다. **DF(Document Frequency)**란 특정 단어가 문서에 등장한 횟수를 뜻하는데요, 만약 A라는 단어가 doc1, doc3에 등장했다면 DF는 2가 됩니다. DF가 클수록 다수 문서에 쓰이는 범용적인 단어라고 볼 수 있겠네요. 이미 눈치채셨겠지만 TF는 같은 단어라도 문서마다 다른 값을 갖고요, DF는 문서가 달라지더라도 동일한 값을 지니게 됩니다. **IDF(Inverse Document Frequency)**는 전체 단어수를 해당 단어의 DF로 나눈 뒤 로그를 취한 값입니다. 그 값이 클수록 특이한 단어라는 뜻이 됩니다. 예컨대 아래 표를 보시죠. 전체 문서 수(N)는 100만개입니다. |  term  |  df  | idf | | :-------: | :-----: | :--: | | calpurnia |  1  | 6  | | animal  |  100  | 5  | | sunday  | 1000  | 4  | |  fly  | 10000 | 3  | |  under  | 100000 | 2  | |  the  | 1000000 | 1  | calpurnia는 줄리어스 시저의 세번째 아내(B.C. 59~44)의 이름이라고 합니다. 그만큼 희귀한 단어겠죠. 위 예시 기준으로 보시면 100만개 전체 문서 가운데 단 하나의 문서에만 등장했군요. 역시 idf값도 높습니다. 반대로 정관사 'the'를 볼까요? 100만개 모든 문서에 모두 등장한 흔한 단어이군요. 이를 idf 식에 넣어서 계산해봤더니 가장 낮은 1이 됩니다. 다시 한번 말씀드리면 idf는 클 수록 특이한 단어라는 뜻입니다.  ## TF-IDF **TF-IDF**는 TF와 IDF를 곱해 두 지표를 동시에 고려하는 가중치 산출 방법입니다. 다시 말해 어떤 단어가 얼마나 많이 쓰였는지, 그 단어가 얼마나 특이한지를 모두 반영한 수치란 뜻입니다. 그 식은 아래와 같이 정의됩니다. $$TF-IDF(w)=tf(w)\times \log { (\frac { N }{ df(w) } ) } $$ 문서가 3개, 단어가 5개 있는 학습말뭉치를 예로 들어보겠습니다. 문서1의 TF, IDF, TF-IDF는 각각 아래와 같이 계산됩니다. <a href="http://imgur.com/bo1ZTm5"><img src="http://i.imgur.com/bo1ZTm5.png" width="500px" title="source: imgur.com" /></a> 위 표를 기준으로 할때 doc1을 가려내는 데 가장 중요한 역할을 하는 단어는 무엇일까요? 그 후보는 term1과 term2가 될 겁니다. 둘 모두 doc1에만 쓰였기 때문입니다. 그런데 이 중에서도 term1이 term2보다 많이 쓰였기 때문에 term1이 가장 중요한 단어가 될 겁니다. doc1의 term1에 대응하는 TF-IDF가 가장 높음을 역시 확인할 수 있습니다. 그렇다면 반대로 모든 문서에 비슷하게 많이 쓰인 term3, term4는 어떨까요? 이들에 대응하는 TF-IDF 값은 0입니다. 바꿔 말하면 term3과 term4는 모두 doc1이라는 문서를 특징짓는 데 아무런 정보를 가지고 있지 않다는 이야기입니다.  ## TF-IDF 변형들 오래 전 제안돼 그 성능 또한 검증된 방식인 만큼 여러 변형들이 존재합니다. 대표적으로 아래와 같은 방식들이 있는데요, 붉은색 표시가 된 방식이 가장 많이 쓰인다고 합니다. <a href="http://imgur.com/cTYKdhr"><img src="http://i.imgur.com/cTYKdhr.png" width="500px" title="source: imgur.com" /></a> 
tSNE␞ 이번 글에서는 데이터 **차원축소(dimesionality reduction)**와 **시각화(visualization)** 방법론으로 널리 쓰이는 **t-SNE(Stochastic Neighbor Embedding)**에 대해 살펴보도록 하겠습니다. 단어 벡터와 같이 고차원 데이터를 시각화하는 데 가장 인기있는 알고리즘이기도 합니다. 이번 글 역시 고려대 강필성 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## Stochastic Neighbor Embedding Stochastic Neighbor Embedding(SNE)란 고차원의 원공간에 존재하는 데이터 $x$의 이웃 간의 거리를 최대한 보존하는 저차원의 $y$를 학습하는 방법론입니다. **stochastic**이란 이름이 붙은 이유는 거리 정보를 **확률**적으로 나타내기 때문인데요. 이 설명만 봐서는 제대로 알 수 없으니 일단 수식 먼저 보겠습니다. $${ p }_{ j|i }=\frac { { e }^{ -\frac { { \left| { x }_{ i }-{ x }_{ j } \right| }^{ 2 } }{ 2{ \sigma }_{ i }^{ 2 } } } }{ \sum _{ k }^{ }{ { e }^{ -\frac { { \left| { x }_{ i }-{ x }_{ k } \right| }^{ 2 } }{ 2{ \sigma }_{ i }^{ 2 } } } } } $$ $${ q }_{ j|i }=\frac { { e }^{ -{ \left| { y }_{ i }-{ y }_{ j } \right| }^{ 2 } } }{ \sum _{ k }^{ }{ { e }^{ -{ \left| { y }_{ i }-{ y }_{ k } \right| }^{ 2 } } } } $$ 첫번째 식의 $p$는 고차원 원공간에 존재하는 $i$번째 개체 $x_i$가 주어졌을 때 $j$번째 이웃인 $x_j$가 선택될 확률을 의미합니다. 두번째 식의 $q$는 저차원에 임베딩된 $i$번째 개체 $y_i$가 주어졌을 때 $j$번째 이웃인 $y_i$가 선택될 확률을 뜻합니다. SNE의 목적은 $p$와 $q$의 분포 차이가 최대한 작게끔 하고자 합니다. 차원축소가 제대로 잘 이뤄졌다면 고차원 공간에서 이웃으로 뽑힐 확률과 저차원 공간에서 선택될 확률이 비슷할테니까요.  두 확률분포가 얼마나 비슷한지 측정하는 지표로 **Kullback-Leibler divergence**라는 것이 있습니다. 두 분포가 완전히 다르면 1, 동일하면 0의 값을 갖게 되는데요, SNE는 아래 비용함수를 최소화하는 방향으로 학습을 진행하게 됩니다.  $$ \begin{align*} Cost&=\sum _{ i }^{ }{ KL({ P }_{ i }||{ Q }_{ i }) } \\ &=\sum _{ i }^{ }{ \sum _{ j }^{ }{ { p }_{ j|i }\log { \frac { { p }_{ j|i } }{ { q }_{ j|i } } } } } \end{align*} $$  그런데 SNE 연구진은 계산 속도를 높이기 위해 몇 가지 학습 트릭을 도입했습니다. $σ_i$는 각 개체마다 데이터 밀도가 달라서 이웃으로 뽑힐 확률이 왜곡되는 현상을 방지하기 위한 값인데요, 반복 실험 결과 $p$를 계산할 때 쓰는 $σ_i$는 고정된 값을 써도 성능에 큰 차이를 보이지 않았다고 합니다. $σ_i$ 계산을 생략하게 된 것이죠.  아울러 $i$번째 개체가 주어졌을 때 $j$번째 개체가 이웃으로 뽑힐 확률과 $j$번째 개체가 주어졌을 때 $i$번째 개체가 선택될 확률을 동일하다고 놓고 풀어도 성능이 그리 나쁘지 않았다고 합니다. 그러면 $p$와 $q$를 아래와 같이 다시 쓸 수 있습니다.  $$ { p }_{ ij }=\frac { { p }_{ j|i }+{ p }_{ i|j } }{ 2 } ,\quad { q }_{ ij }=\frac { { q }_{ j|i }+{ q }_{ i|j } }{ 2 } $$  새로 쓴 비용함수와 $y_i$의 그래디언트는 아래와 같습니다. $$ \begin{align*} Cost&=\sum _{ i }^{ }{ KL({ P }_{ i }||{ Q }_{ i }) } \\ &=\sum _{ i }^{ }{ \sum _{ j }^{ }{ { p }_{ ij }\log { \frac { { p }_{ ij } }{ { q }_{ ij } } } } } \\ \frac { \partial C }{ \partial { y }_{ i } } &=4\sum _{ j }^{ }{ ({ y }_{ j }-{ y }_{ i })({ p }_{ ij }-{ q }_{ ij }) } \end{align*} $$  우리가 최종적으로 구하고자 하는 미지수는 저차원에 임베딩된 좌표값 $y_i$입니다. SNE는 **그래디언트 디센트(gradient descent)** 방식으로 $y_i$들을 업데이트합니다. 즉, 처음에 $y_i$를 랜덤으로 초기화해놓고 위에서 구한 그래디언트의 반대방향으로 조금씩 $y_i$들을 갱신해 나가는 것입니다. $y_i$의 그래디언트를 보면 우리가 이미 모두 알고 있는 값들이므로 업데이트를 여러번 반복 수행하기만 하면 됩니다.  ## Crowding Problem과 t-SNE SNE가 전제하는 확률분포는 가우시안 분포입니다. 그런데 가우시안 분포는 꼬리가 두텁지 않아서 $i$번째 개체에서 적당히 떨어져 있는 이웃 $j$와 아주 많이 떨어져 있는 이웃 $k$가 선택될 확률이 크게 차이가 나지 않게 됩니다. 이를 crowding problem이라고 합니다. 이들 구분을 좀 더 잘하기 위해 가우시안분포보다 꼬리가 두터운 t분포를 쓴 것이 바로 t-SNE입니다. t-SNE는 $q_{ij}$에만 아래와 같이 t분포를 적용하고, $p_{ij}$는 SNE와 같습니다.  $$ { q }_{ ij }=\frac { { (1+{ \left| { y }_{ i }-{ y }_{ j } \right| }^{ 2 }) }^{ -1 } }{ \sum _{ k\neq l }^{ }{ { (1+{ \left| { y }_{ k }-{ y }_{ l } \right| }^{ 2 }) }^{ -1 } } } $$  ## t-SNE 시각화 t-SNE는 보통 [word2vec](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/)으로 임베딩한 단어벡터를 시각화하는 데 많이 씁니다. 문서 군집화를 수행한 뒤 이를 시각적으로 나타낼 때도 자주 사용됩니다. [저자](https://lvdmaaten.github.io/tsne/)가 직접 만든 예시 그림은 아래와 같습니다. <a href="http://imgur.com/83gI8Gl"><img src="http://i.imgur.com/83gI8Gl.jpg" title="source: imgur.com" /></a>
shortestpath␞ 이번 글에서는 **최단 경로 문제(Shortest Path Problem)**를 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님과 역시 같은 대학의 김황남 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 최단거리 문제 최단 경로 문제란 두 노드를 잇는 가장 짧은 경로를 찾는 문제입니다. 가중치가 있는 그래프(Weighted Graph)에서는 엣지 가중치의 합이 최소가 되도록 하는 경로를 찾으려는 것이 목적입니다. 최단 경로 문제엔 다음과 같은 변종들이 존재합니다. - **단일 출발(single-source) 최단경로** : 단일 노드 $v$에서 출발하여 그래프 내의 모든 다른 노드에 도착하는 가장 짧은 경로를 찾는 문제. - **단일 도착(single-destination) 최단경로** : 모든 노드들로부터 출발하여 그래프 내의 한 단일 노드 $v$로 도착하는 가장 짧은 경로를 찾는 문제. 그래프 내의 노드들을 거꾸로 뒤집으면 단일 출발 최단경로문제와 동일. - **단일 쌍(single-pair) 최단 경로** : 주어진 꼭지점 $u$와 $v$에 대해 $u$에서 $v$까지의 최단 경로를 찾는 문제. - **전체 쌍(all-pair) 최단 경로** : 그래프 내 모든 노드 쌍들 사이의 최단 경로를 찾는 문제. [다익스트라 알고리즘](https://ratsgo.github.io/data%20structure&algorithm/2017/11/26/dijkstra/), [벨만-포드 알고리즘](https://ratsgo.github.io/data%20structure&algorithm/2017/11/27/bellmanford/)은 여기서 단일 출발 최단경로 문제를 푸는 데 적합합니다. 하지만 여기에서 조금 더 응용하면 나머지 세 문제도 풀 수 있습니다.    ## optimal substructure 여기에서 최단거리의 중요한 속성을 하나 짚고 넘어가겠습니다. 다익스트라 알고리즘이나 벨만-포드 알고리즘이 최단 경로를 찾을 때 써먹는 핵심 정리이기도 합니다. - 최단경로의 부분 경로는 역시 최단경로이다. 이를 나타낸 예시 그림이 다음 그림입니다. 아래 그림에서 직선은 엣지, 물결선은 경로를 나타냅니다. 각 숫자는 가중치를 나타냅니다.  엣지 가중치 합이 최소인 최단경로는 굵게 표시된 상단 첫번째 경로임을 알 수 있습니다. 만약 그렇다면 시작노드로부터 중간에 있는 노드에 이르기까지의 경로(그 가중치는 5) 또한 최단경로라는 것이 위 정리의 핵심입니다.  <a href="https://imgur.com/4s5a0iz"><img src="https://i.imgur.com/4s5a0iz.png" width="300px" title="source: imgur.com" /></a>  위 정리를 증명한 내용은 다음과 같습니다.  <a href="https://imgur.com/Ldpb0WM"><img src="https://i.imgur.com/Ldpb0WM.png" width="380px" title="source: imgur.com" /></a>  위 정리를 확장하면 최단경로를 다음과 같이 분해(decompostion)할 수 있습니다. 시작노드 $s$에서 $v$에 이르는 최단경로는 $s$에서 $u$까지의 최단경로에 $u$에서 $v$ 사이의 가중치(거리)를 더한 값이라는 겁니다.  $$ D\left( s,v \right) =D\left( s,u \right) +w\left( u,v \right) $$ 만약 위 식 우변의 값(현재 *step*에서 구한 새로운 경로의 거리)이 좌변(기존 최단경로의 거리)보다 작다면 최단경로를 업데이트해 줍니다. 이렇게 노드별로 하나씩 구해 확장해 나가면 $s$에서 $v$ 사이의 최단경로를 구할 수 있습니다. 이와 같이 어떤 문제의 최적해가 그 부분문제들의 최적해들로 구성(*construct*)될 수 있다면 해당 문제는 *optimal substructure*를 가진다고 말합니다. 이 속성을 가지고 [다이내믹 프로그래밍(dynamic programming)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/15/dynamic/)이나 [탐욕 알고리즘](https://ratsgo.github.io/data%20structure&algorithm/2017/11/22/greedy/)을 적용해 문제를 효율적으로 풀 수 있습니다.    ## edge relaxation 최단경로를 구하는 알고리즘은 *edge relaxation*(변 경감)을 기본 연산으로 합니다. 이는 지금까지 이야기한 최단경로 문제의 *optimal structure*에서 파생된 것입니다. 우선 시작노드 $s$에서 임의의 노드 $z$로의 최단경로를 구한다고 칩시다. 그리고 현재 시점에서 우리가 알고 있는 $s,z$ 사이의 최단거리 $d(z)$는 75, $s,u$ 사이의 최단거리 $d(u)$는 50이라고 두겠습니다.  그런데 탐색 과정에서 엣지 $e$를 경유하는 경로의 거리가 총 60이라고 한다면, 기존에 우리가 알고 있는 $d(z)$보다 짧아서 기존 $d(z)$가 최단경로라고 말할 수 없게 됩니다. 이에 최단경로를 구성하고 있는 노드와 엣지 정보, 그리고 거리의 합을 업데이트해줍니다. 이것이 바로 *edge relaxation*입니다.   <a href="https://imgur.com/nqdnANR"><img src="https://i.imgur.com/nqdnANR.png" width="350px" title="source: imgur.com" /></a>  *edge relaxation*은 최단경로 알고리즘을 수행하는 과정에서 경로를 구성하고 있는 엣지 가중치의 합을 줄여나간다(relax)는 취지로 이런 이름이 붙은 것 같습니다.   ## 알고리즘 특성별 비교 최단경로 알고리즘은 크게 [다익스트라](https://ratsgo.github.io/data%20structure&algorithm/2017/11/26/dijkstra/)와 [벨만-포드](https://ratsgo.github.io/data%20structure&algorithm/2017/11/27/bellmanford/) 알고리즘 두 가지가 있습니다. 다익스트라 알고리즘은 엣지 가중치가 음수일 경우 동작하지 않습니다. 벨만-포드 알고리즘의 경우 엣지 가중치가 음수여도 동작하나, *negative cycle*이 있을 경우 동작하지 않습니다. 다익스트라 알고리즘의 계산복잡성은 $O($\|$V$\|$^2+$\|$E$\|$)$이며, 벨만-포드는 $O($\|$V$\|\|$E$\|$)$입니다.   ## 전체쌍 최단경로 전체쌍(All-pair) 최단경로 문제는 `Floyd-Warshall 알고리즘`이 널리 쓰인다고 합니다. 최단경로 문제의 *optimal substructure*를 활용한 것으로 의사코드는 다음과 같습니다.  <a href="https://imgur.com/AigMqRx"><img src="https://i.imgur.com/AigMqRx.png" width="400px" title="source: imgur.com" /></a>  작동 예시는 다음과 같습니다.   <a href="https://imgur.com/WFAJSUW"><img src="https://i.imgur.com/WFAJSUW.png" width="400px" title="source: imgur.com" /></a>  다만 노드가 다르다면 단일쌍 최단경로 문제는 서로 독립적이기 때문에, 최근엔 단일쌍 문제에 적합한 다익스트라/벨만-포드 알고리즘을 GPU를 활용해 병렬처리하는 방식으로 전체쌍 최단경로를 푸는 경우가 많다고 합니다.
modality␞ 이번 글에서는 양태(modality) 개념과 한국어에서 양태가 문법적으로 어떻게 실현되고 있는지 살펴보겠습니다. 이번 글 역시 고려대 정연주 선생님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 개념 양태란 [절이나 문장](https://ratsgo.github.io/korean%20linguistics/2017/07/13/syntax/)이 나타내는 명제 혹은 사태에 대한 주관적 태도, 판단을 나타내는 의미 범주입니다. 예컨대 다음 문장과 같습니다. 양태는 단일 어미로 실현될 수도, 어미 등 여러 형태소가 함께 쓰여(우언적 구성) 실현될 수도, 부사/용언 등 단일 어휘로도 실현될 수도 있습니다. - 한라산 설경이 아름다워. - **비교적 확실한 추측** : 한라산 설경이 아름답**겠**다, 한라산 설경이 아름다울 것이 **확실하다** - **가능성** : 한라산 설경이 아름다**울 수(도) 있**다. **아마도** 한라산 설경이 아름다울 거야 양태가 화자의 주관적 태도/판단을 나타내는 의미 범주라면 서법(mood)은 문법 범주라고 할 수 있겠습니다. 즉 양태적 의미가 어미 등 문법적 장치를 통해 나타내면 서법이라고 할 수 있습니다. 따라서 위 예문의 경우 `-겠-`, `-을 수 있-` 같은 구성이 서법, `추측` 혹은 `가능성`에 해당하는 의미가 양태입니다. `확실하다`, `아마도`와 같이 양태 의미를 드러내는 어휘를 양태어휘라고 부르기도 합니다.   ## 유형 양태에는 크게 인식양태, 당위양태, 동적양태, 감정양태 등 네 가지로 하위 유형이 있습니다. 차례대로 살펴보겠습니다.  ### 인식양태 인식양태(epstemic modality)란 명제의 확실성에 대한 화자의 판단, 믿음의 정도를 나타냅니다. 문장에 표현된 명제가 확실하게 참이라든지(확실성), 확실하지는 않지만 참일 확률이 제법 높다든지(추측), 거짓일 확률보다는 참일 확률이 높다든지(개연성), 참일 확률이 0보다는 높다든지(가능성) 등을 나타냅니다. 인식양태 각각의 종류에 해당하는 한국어 문법 요소와 그 예시는 다음 표와 같습니다. |  문법요소   |  양태 의미  |      예문      | | :---------: | :-------: | :--------------------: | | -겠-, -을 것이- |  추측   | 내일 비가 오겠다, 내일 비가 올 것이다 | | -ㄴ/ㄹ 듯하-  | 강한 개연성/추측 |   진이가 서울에 있는 듯하다   | | -ㄴ/ㄹ 것 같- | 강한 개연성/추측 |   곧 비가 올 것 같다    | |  -을 법하-  | 약한 개연성  |   그건 일어날 법한 일이다   | |  -을 수 있-  |  가능성  |   내일 비가 올 수도 있다   |  ### 당위양태 당위양태(deontic modality)란 사태의 바람직함에 대한 화자의 판단을 나타냅니다. 의무, 허락/허용 등이 있습니다. - **의무(-어야 하-)** : 이제 집에 가**야 한**다. - **허락(-어도 되-)** : 이제 집에 가**도 된**다.   ### 동적양태 동적양태(dynamic modality)란 사태의 발생 가능성을 좌우하는 원인이 사태 내부의 참여자에게 있음을 나타냅니다. 능력, 의도, 바람 등이 있습니다. - **능력(-을 수 있-)** : 진이는 수영을 **할 수 있**다. - **능력(-을 줄 알-)** : 진이는 수영을 **할 줄 안**다. - **의도(-겠-)** : 나는 꼭 1등을 하**겠**어. - **의도(-을 것이-)** : 나는 꼭 1등을 **할 것이**다.   ### 감정양태 감정양태(emotive modality)란 명제에 대한 화자의 감정적 태도를 나타냅니다. 놀라움, 유감스러움, 아쉬움, 후회, 다행으로 여김, 두려움, 경계심 등이 있습니다. - **경계심/경고(-을라)** : 조심해. 다**칠라**. - **후회(-을걸)** : 조금만 더 일찍 일어**날걸**. 한국어에서는 다양한 조사와 어미로 다양한 감정을 표시할 수 있습니다. 다음 예문과 같습니다. - 손자 녀석이 축구는 자기가 반에서 제일 {잘한대/잘한다나}. - 공부도 좀 쉬어 가며 {해라/하렴/하려무나}. - 그이는 매번 무슨 회의가 {있다고/있답시고} 일요일에도 나가요. - 너는 여기서 {삼각김밥을/삼각김밥이나} 먹어라. - 이 나이에 고물 자동차나 끌고 다니니 {한심합니다/*다행입니다}. - 이 나이에 고물 자동차나마 끌고 다니니 {*한심합니다/다행입니다}. 위 예문에서 `-ㄴ다나`는 가벼운 경멸, `-ㄴ답시고`는 비아냥, `-이나`, `-나`, `-나마`는 앞선 말이 하찮음을 나타냅니다. 다만 `-나`는 부정적인 감정, `-나마`는 긍정적인 감정을 나타내면서 그 의미 차이를 드러내고 있습니다.   ## 증거성 증거성(evidentiality)이란 문장에 표현된 명제, 정보를 어떠한 경로를 통해 입수했는가를 나타내는 문법 범주입니다. 가령 문장에 표현된 사실을 자신이 직접 감각 경험을 통해 알게 되었는지, 남으로부터 전해 들었는지, 어떤 증거를 바탕으로 하여 자신이 직접 추리한 것인지 등을 나타냅니다. 다음 예문을 보겠습니다. > He **must have be** in his office. 위 문장은 한국어로 '그는 사무실에 있음이 틀림없다' 정도로 번역됩니다. 위 문장은 명제가 얼마나 확실한지(인식양태)는 물론, 해당 정보를 어떻게 입수했는지(증거성) 또한 드러내고 있습니다. 즉 위 명제는 화자가 여러 사실들을 바탕으로 추리해 도출한 것이며, 그 결과가 거의 사실에 가까울 정도로 확실하다고 판단을 내리고 있는 것입니다.  세계 언어에서 증거성은 이처럼 양태와 동시에 실현되는 경우가 많아서 증거성을 양태의 하위 범주로 다루는 문법 학자들도 많습니다. 증거의 종류는 다음과 같이 6가지로 나눠 생각해볼 수 있습니다. - 시지각 (visual perception) - 시각 이외의 지각 (non-visual perception) - 내적 사유, 성찰 (introspection, endophoric reflection) - 지각 증거를 바탕으로 한 추리 (inference based on perceptual evidence) - 일반적 사실을 바탕으로 한 추론 (reasoning based on general assumption, presumptive, assumptive) - 전문(傳聞, hearsay, quotative)    ## 의외성 의외성(mirativity)이란 문장에 표현된 명제가 화자의 지식 체계에 아직 내면화하지 못한 지식임을 나타내는 문법범주입니다. 한국어에서는 `-네`, `-구나` 의미의 핵심이 의외성입니다. 예컨대 다음 예문의 화자는 청자가 집에 이미 갔을 것으로 인식 혹은 기대하고 있었으나 실제로는 그렇지 않았다는 의미로 `-네`와 `-구나`를 쓰고 있습니다. - 아직 집에 {안 갔네/안 갔구나}.    ## 한국어의 문법적 양태 이상 살펴본 여러 가지 개념을 바탕으로 한국어의 문법적 양태를 `-겠-`, `-을 것이-`, `-더-`를 중심으로 살펴 보겠습니다. 세계 여느 언어와 마찬가지로 한국어에서도 하나의 문법 요소에 [시제](https://ratsgo.github.io/korean%20linguistics/2017/11/03/tense/), [상](https://ratsgo.github.io/korean%20linguistics/2017/07/10/aspect/), 양태, 증거성, 의외성 중 둘 이상의 범주에 걸쳐서 복수의 의미 성분을 한꺼번에 가지는 일이 종종 있는데요. 이 세 가지 문법 요소가 바로 이런 경우에 속합니다.  ### -겠- `-겠-`은 '추측'이라는 인식 양태의 의미 성분과 '추리(지각 정보를 바탕으로 새로운 명제 도출)'라는 증거성의 의미 성분이 결합되어 있습니다.   #### 추측 다음 예문과 같습니다. - 지금 밖에는 비가 오**겠**다. 의문문에서는 청자의 판단(추측)을 묻는 데 이용됩니다. - 네 생각에는 비가 곧 그치**겠**니? 추측의 `-겠-`은 여러 시제에 사용될 수 있고 주어 제약도 없습니다. - 어제는 비가 왔**겠**다 / 곧 비가 오**겠**다 - 이러다가 내가 밥을 못 먹**겠**다 / 이러다가 네가 밥을 못 먹**겠**다  #### 의도 의도의 `-겠-`은 화자 자신을 동작주로 하는 사태를 성립시키겠다는 의지를 나타냅니다. 다음 예문과 같습니다. - 나는 그 사람과 결혼하**겠**다. 의문문에서는 청자의 의도를 표현하는 데 쓰입니다. - 너는 그 사람과 결혼하**겠**느냐? 평서문에서는 1인칭 주어만을, 의문문에서는 2인칭 주어만을 취할 수 있습니다. - {나는, *너는, *철수는} 무슨 일이 있어도 그 사람과 결혼하**겠**다. - {*나는, 너는, *철수는} 그 사람과 결혼하**겠**느냐? 하지만 1인칭 주어 평서문에서 `-겠-`이 쓰였다고 해서 모두 의도로 해석되는 것은 아닙니다. 다음 예문은 추측의 의미로 쓰였습니다. - 내가 오늘 아무래도 학교에 가게 되**겠**다. 의도의 `-겠-`은 과거 시제와 결합할 수 없습니다. - 나는 꼭 대통령이 되**겠**었다.  #### 계획된 미래 명제 내용이 표상하는 사태가 가까운 미래에 발생함을 의미하되, 그 발생이 계획되어 있음을 함의합니다. 이미 정해진 것으로 불확실한 사실에 대한 추측이라고 보기 어렵습니다. 이와 관련해 중세 국어의 `-게 하여 잇-`에서 현대 국어의 `-겠-`으로 변화, 발달하는 과정에서 나타난 의미(`-하게 되어 있-`)가 일부 문맥에서 드러난 것이라고 해석하는 견해도 있습니다. `-겠-`이 계획된 미래로 쓰인 예문은 다음과 같습니다. - 대통령께서 입장하시**겠**습니다.  #### 기동상 어떤 상태에 막 접어들었음을 표현합니다. 이 역시 `-겠-`이 발달하는 과정에서 나타난 의미(`-게 되었-`)가 일부 문맥에서 드러난 것이라고 해석하는 견해도 있습니다. 다음 예문의 `-겠-`은 '아는 상태에 막 접어들었음'을 나타냅니다. - 내일까지 과제를 제출하셔야 합니다. 예, 알**겠**습니다. 그렇다면 '알겠다'는 표현과 '알았다'는 표현은 어떻게 해석해야 할까요? 모국어 화자가 느끼기에 둘 사이에 큰 의미 차이를 인식하기 어렵습니다. 이와 관련해 전자의 `-겠-`은 '아는 상태에 막 접어들었음'을, 후자의 `-았-`은 '깨달은 상태 결과가 지속되고 있음'을 나타낸다고 설명할 수도 있을 것입니다. 후자의 경우 '깨닫다' 정도 의미의 '알다'는 끝점을 가지는 유계동사인데, [결과상](https://ratsgo.github.io/korean%20linguistics/2017/11/11/aspect/)을 나타내는 `-았-`이 쓰여 과거 사태의 결과가 지속되는 의미를 표현해주고 있습니다. <br> ### -더- `-더-`는 상황을 지각한 시간이 발화시 이전이라는 '과거'의 의미 성분, 이 정보를 지각/내성/추리를 통해 얻었다는 '증거성'의 의미성분, 문장의 표현된 사태가 새로운 정보라는 '의외성'의 의미 성분이 결합돼 있습니다. 여기서 `-더-`는 한국어 주절(모절)에서 쓰이는 것으로 [관형사절의 '-더-'](https://ratsgo.github.io/korean%20linguistics/2017/11/09/detertime/)와는 구분할 필요가 있습니다.  #### 지각, 내성, 추리 `-더-`는 직접적인 감각 행위 및 내성, 추리(근거가 분명할 때)를 통해 알게 된 사태에 대해 사용됩니다. 다음 예문과 같이 직접 지각한 행위에 어울립니다. - 철수가 운동장에서 체조를 하**더**라.  그러나 다음 예문처럼 직접 경험한 것이 아닌 것에 `-더-`를 쓰면 비문이 됩니다(증거성 제약). - *먹어 본 적은 없지만 새로 나온 석류 음료가 맛있**더**라. 내성, 추리에 쓰인 예문은 다음과 같습니다. - 어제 너와 얘기할 때는 몰랐는데, 집에 가서 곰곰이 생각해 보니 내 계산이 틀렸**더**라 : 내성 - 선생님은 벌써 퇴근하셨**더**라 : 추리(교무실의 선생님 책상이 비어있는 걸 보고)  #### 과거 `-더-`가 나타내는 과거의 의미 성분은 시제와는 약간 다른 개념입니다. 상황을 지각한 시간이 발화시를 기준으로 했을 때 과거의 어느 한 시점이라는 의미를 나타냅니다. 다음 예문의 경우 실제 사태는 미래 어느 시점에 일어나지만, 해당 사태를 인식한 시점이 과거라는 걸 나타내고 있습니다. - 내일부터 고속버스 요금이 오르**더**라. - 강아지가 집을 잘 지키겠**더**라.  #### 의외성 지각의 시점을 기준으로 했을 때 그때까지는 알지 못하거나 의식하지 못하던 사실을 새로이 알게 되었을 때 `-더-`가 사용됩니다. - 그 사람 알고 보니 영 사람이 덜 되었**더**라. - 미국의 수도가 워싱턴이**더**라.  #### 인칭제약 `더-`는 인칭제약을 가지고 있습니다. 우선 객관술어가 쓰인 평서문에서는 1인칭 주어와 `-더-`가 어울리지 않습니다. 여기에서 객관술어란 '뛰다', '먹다'처럼 해당 술어가 가리키는 사태가 외부에서 관찰 가능한 경우를 가리킵니다. 예문과 같습니다. - \***나**는 옷을 입**더**라. - \***나는** 동생을 찾**더**라. 객관술어가 쓰인 의문문에서는 2인칭 주어와 `-더-`가 어울리지 않습니다. - \***네가** 밥을 먹**더**냐? 하지만 이러한 제약이 해소되는 경우도 있습니다. 예문과 같습니다. - **내가** 빨간 옷을 입었**더**라. (정신 없이 아무 옷이나 입고 나오느라고 그때까지 깨닫지 못했는데, 자기가 빨간 옷을 입었음을 새로이 깨닫게 된 상황) - 세 사람 중에서 **내가** 제일 춤을 잘 추**더**라. (이전에는 몰랐는데 막상 춤을 같이 춰보니 내가 춤을 제일 잘 춘다는 사실을 새로이 깨닫게 된 상황) 이처럼 자신의 일이라도 새로 깨닫게 된 사태에는 `-더-`가 사용될 수 있습니다. 이러한 인칭 제약의 해소는 '의외성'의 의미 속성 때문이라고 설명할 수 있을 것 같습니다. 바꿔 말해 객관술어가 쓰인 평서문의 1인칭 인칭제약은 화자가 자신의 일을 새로이 인식하는 것이 자연스러운 일이 아니기 때문에 발생한다고 볼 수 있다는 것입니다. 이번엔 주관술어 쪽을 보겠습니다. 주관술어란 '춥다', '무섭다'처럼 해당 술어가 가리키는 사태가 감정, 감각 등과 관련된 경우를 가리킵니다. 주관술어가 쓰인 평서문에서 1인칭 주어와 `-더-`가 자연스럽게 어울리고, 2/3인칭 주어와는 어울리지 않습니다. 주관술어가 쓰인 의문문에서는 2인칭 주어와 `-더-`가 자연스럽게 어울리고, 1/3인칭 주어와는 어울리지 않습니다. 다음 예문과 같습니다. - **나는** 수박이 좋**더**라.  **나는** 간밤에 춥**더**라. - *어젯밤엔 바람이 불어서 **진이가** 춥**더**라. 생리적 혹은 심리적 현상에 대해 우리는 명확한 의식을 가지고 있지 않습니다. 자신과 관련한 사실이 과거의 어느 시점에서 화자의 의식의 표면에 떠오름(의외성)을 표현하기 때문에 주관술어가 쓰인 1인칭 평서문에서 `-더-`가 자연스럽게 쓰일 수 있습니다. 반면 타인의 내적, 심리적 경험은 지각이나 내성을 통해 파악할 수 없고, 추리를 통해 단언할 수도 없습니다. 이 때문에 주관술어가 쓰인 2/3인칭 평서문에서 `-더-`가 어울리지 않는다고 설명할 수도 있겠습니다. 
binarysearch␞ 이번 글에서는 **이진탐색(binary search)** 알고리즘에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의를 정리하였음을 먼저 밝힙니다. 코드는 [이곳](github.com/TheAlgorithms/Python)을 참고하였습니다. 그럼 시작하겠습니다.  ## 개요 이진탐색 알고리즘이란 오름차순으로 정렬된 리스트에서 특정한 값의 위치를 찾는 알고리즘입니다. 알고리즘 특성상 정렬된 리스트에만 사용할 수 있다는 단점이 있지만, 검색이 반복될 때마다 탐색 대상 데이터 수는 직전의 절반이 되므로 속도가 빠르다는 장점이 있습니다.  이진탐색 알고리즘을 직관적으로 나타낸 그림은 다음과 같습니다(그림 출처 : [영문 위키](https://en.wikipedia.org/wiki/Binary_search_algorithm)). 아래와 같이 17개 요소로 이뤄진 리스트에서 7의 위치를 찾는 이진탐색 알고리즘은 화살표 방향처럼 수행이 됩니다.   <a href="https://imgur.com/hhiR6QU"><img src="https://i.imgur.com/hhiR6QU.png" width="500px" title="source: imgur.com" /></a>   ## 수행방식 위 그림 예시 기준으로 이진탐색 알고리즘 수행방식을 살펴보겠습니다. 우선 리스트의 중앙을 찾습니다. 요소가 17개이므로 중앙값은 여덟번째(리스트 요소가 $n$개라면 $n/2$를 내림한 값)에 있는 요소(14)가 됩니다. 이 중앙값과 찾고자 하는 값(7)의 크기를 비교합니다. 여기서 찾고자 하는 값이 중앙값보다 작으므로 중앙값보다 큰 값(18, 19, 21, 24, 37, 40, 45, 71)들은 탐색 대상에서 제외합니다.  이번엔 [1, 3, 4, 6, 7, 8, 10, 13, 14]를 새로운 리스트로 보고 같은 작업을 반복 수행합니다. 리스트 중앙을 찾습니다. 새로운 리스트의 요소가 9개이므로 중앙값은 새로운 리스트의 네번째 요소(원래 리스트의 네번째 요소)이며 그 값은 6이 됩니다. 이 중앙값과 찾고자 하는 값(7)의 크기를 비교합니다. 여기서 찾고자 하는 값이 중앙값보다 크므로 중앙값보다 작은 값(1, 3, 4)들은 탐색 대상에서 제외합니다. 이번엔 [6, 7, 8, 10, 13, 14]를 새로운 리스트로 보고 같은 작업을 반복 수행합니다. 리스트 중앙을 찾습니다. 새로운 리스트의 요소가 6개이므로 중앙값은 새로운 리스트의 세번째 요소(원래 리스트의 여섯번째 요소)이며 그 값은 8이 됩니다. 이 중앙값과 찾고자 하는 값(8)의 크기를 비교합니다. 여기서 찾고자 하는 값이 중앙값보다 작으므로 중앙값보다 큰 값(10, 13, 14)들은 탐색 대상에서 제외합니다. 이번엔 [6, 7, 8]을 새로운 리스트로 보고 같은 작업을 반복 수행합니다. 리스트 중앙을 찾습니다. 새로운 리스트의 요소가 3개이므로 중앙값은 새로운 리스트의 두번째 요소(원래 리스트의 다섯번째 요소)이며 그 값은 7이 됩니다. 이 중앙값과 찾고자 하는 값(7)의 크기를 비교합니다. 같으므로 이 중앙값의 위치(원래 리스트의 다섯번째)를 최종 산출물로 반환합니다.   ## 파이썬 구현 이진탐색 알고리즘의 **의사코드(pseudo code)**는 다음과 같습니다. 아래 코드에서 *item*은 찾고자 하는 값, *sorted_collection*는 주어진 **정렬된** 리스트, *left*는 이 리스트의 왼쪽 끝 인덱스, *right*는 오른쪽 끝 인덱스를 의미합니다. ```python def binary_search(sorted_collection, item):   left = 0   right = len(sorted_collection) - 1   while left <= right:     midpoint = (left + right) // 2     current_item = sorted_collection[midpoint]     if current_item == item:       return midpoint     else:       if item < current_item:         # 주어진 리스트의 오른쪽 절반은 탐색 대상서 제외         right = midpoint - 1       else:         # 주어진 리스트의 왼쪽 절반은 탐색 대상서 제외         left = midpoint + 1   return None ```   ## 계산복잡도 이진탐색의 계산복잡도 $T(n)$을 따져봅시다. 의사코드를 보면 재귀적으로 자신을 호출하는 부분을 제외하면 상수배 복잡도를 가집니다. left와 right가 같은지, A[left]가 num과 같은지, A[center]가 num과 같은지 등을 따져보고 그 조건에 맞는 몇 가지 기본 연산을 수행하면 되기 때문입니다. 아울러 이진탐색이 반복될 때마다 고려 대상이 되는 리스트의 요소 수는 절반씩 줄어듭니다. 이를 식으로 나타내면 다음과 같습니다.  $$ \begin{align*} T\left( n \right) &=T\left( \frac { n }{ 2 } \right) +c\\ &=T\left( \frac { n }{ { 2 }^{ 2 } } \right) +c+c\\ &=T\left( \frac { n }{ { 2 }^{ 3 } } \right) +c+c+c\\ &=...\\ &=T\left( \frac { n }{ { 2 }^{ i } } \right) +c\times i\\ &=...\\ &=T\left( 1 \right) +T(1)+...+T\left( 1 \right)+c\times \log _{ 2 }{ n }\\&=O\left( \log _{ 2 }{ n } \right) \end{align*} $$  위 계산식에서 $\log_2n$이 도출되는 이유는 이렇습니다. 최악의 경우를 고려하면 $n/2^i$가 1이 될 때까지 이진탐색을 수행해야 합니다. $n/2^i=1$이므로 로그의 정의에 따라 $i=\log_2n$이 됩니다. big O 표기법에 관련해서는 [이곳](https://ratsgo.github.io/data%20structure&algorithm/2017/09/13/asymptotic/)을 참고하시면 좋을 것 같습니다. 
graphnews␞ 이번 포스팅에서는 '그래프'로 중요 기사를 걸러내 보도록 하겠습니다. 같은 시간대에 비슷한 제목의 기사가 많으면 중요한 이슈를 다루는 보도일 것이라는 가정이 깔려 있는 분석 방법론인데요, 매우 간단한 방법론이지만 생각보다 퍼포먼스가 좋아서 써먹을 일이 많을 것 같습니다. 자 시작해 볼까요?  ## Structured Journalism 하루에도 수백 수천건의 기사가 쏟아지는 '뉴스의 홍수' 시대입니다. 소비자 입장에선 어떤 기사가 중요하고 그렇지 않은지 알기 어렵고 생산자 입장에선 공들여 만든 뉴스가 단 하루만 지나도 쓸모 없어지기 때문에 대단히 비효율적입니다. 생산자든 소비자든 뉴스의 맥락을 짚기가 매우 어려운 것이 요즘 현실입니다. 예를 들어볼까요? 대한민국 대표기업 '삼성'에 관련된 이슈를 찾아보고 싶다고 칩시다. 네이버에 삼성 키워드를 넣어서 뉴스를 검색해봤습니다. <a href="http://imgur.com/HqWB22Q"><img src="http://i.imgur.com/HqWB22Q.png" width="600px" title="source: imgur.com" /></a> 많이들 검색해보셔서 아시겠지만 지금 당장 벌어지고 있는 이슈는 비교적 쉽게 알 수 있지만 과거 이슈는 시간과 노력을 들이지 않으면 알기 어렵습니다. 또 '공채', '최순실 수사', '삼성전자의 하만 인수' 등은 시간의 흐름에 따라 진화, 발전하는 이슈지요. 저는 뉴스 소비자에게 중요한 기사를 걸러 보여주면서도 뉴스의 **맥락(context)**을 알 수 있게 하면 좋겠다는 생각을 했습니다. 이와 관련된 개념이 바로 **[스트럭처 저널리즘(Structured Journalism)](https://www.kpf.or.kr/site/kpf/research/selectMediaPdsView.do?seq=7562)**입니다. <a href="http://imgur.com/CfWCQrS"><img src="http://i.imgur.com/CfWCQrS.jpg" width="500px" title="source: imgur.com" /></a> 스트럭처 저널리즘은 언론학계에 최근 제시되고 있는 개념으로 기사 및 기사 속에 내재된 정보를 계속 누적시켜 **재맥락화(recontextualize)**하려는 노력을 총칭합니다. 위 그림에서처럼 단순 팩트나 기존 기사들을 재조합하여 새로운 가치, 맥락을 만들어보려는 시도입니다.   ## 중요기사의 기준 중요한 기사란 무엇일까요? 야구를 좋아하는 사람은 메이저리그 기사, 정치에 관심있는 독자는 박근혜 전 대통령 탄핵 관련 보도가 중요하겠지요. 이렇듯 각자가 중요하다고 생각하는 기사는 저마다 다를 겁니다. 기사 중요도 판단은 어느 정도는 주관적인 영역이라는 거지요. 그런데 저는 중요 기사의 조건을 아래처럼 **양적**으로 접근해 보기로 했습니다. > 언론은 특종 경쟁에 매몰돼 있다. 같은 사실을 보도하더라도 어제와 '다른' 뉴스, 남들과는 '차별화한' 시각을 추구한다. 그런데 많은 언론사들이 유사한 제목의 비슷한 기사를 보도한다면 해당 사건이나 이슈는 사회에 파급력이 클 가능성이 높다. 바꿔 말해 해당 기사는 차별성을 다소 포기하더라도 보도할 만한 가치가 있는 중요한 아티클이라는 이야기다. 위 가정을 제가 기자 생활을 할 때 경험과 연관지어 이야기해보겠습니다. 대부분의 편집국, 보도국은 24시간 365일 체제로 운영됩니다. 국내외 사건사고들이 9 to 6 근무시간에만 발생하지는 않기 때문입니다. 근무시간에는 모든 기자들이 출근해 사건을 취재해 기사를 쓰고, 심야나 휴일 사건은 당직기자들이 커버하는 구조입니다. 저도 기자일 때 평일 심야, 휴일 당직을 여러번 서 봤는데요. 이때 선배들이 입버릇처럼 강조한 말이 있습니다. > 물 먹지 마라. '물 먹는다'는 표현은 '낙종'을 뜻하는 언론계 은어입니다. 낙종은 특종과 반대되는 개념인데 모든 언론사가 취급하는 중요 이슈를 보도하지 않(못)한 경우 이런 말을 씁니다. '박근혜 대통령 탄핵', '북한 핵실험', '삼성그룹 미래전략실 폐지' 같은 중요 사건이 터졌을 때 담당 기자가 넋 놓고 있다가 이를 보도하지 않았(못했)을 때는 시말서를 쓸 각오를 해야 합니다. 그래서 편집국을 대표해 당직을 설 때에는 상당한 긴장감을 갖고 근무를 해야 했습니다.   ## Graph-based News Representation 지금까지 논의한 걸 바탕으로 모델을 만들어보기로 했습니다. 대전제는 딱 두 줄로 요약됩니다. - 중요한 뉴스라면 모든 언론사가 취급할 것이다 - 중요 기사는 제목이나 키워드가 비슷할 것이다  저의 경우 위 두 가지 전제를 모델링하기 위해 **그래프(graph)**를 써보기로 했습니다. 뉴스 제목을 **노드(꼭지점)**와 **엣지(간선)**로 표현하는 것입니다. 무슨 말인지 알쏭달쏭하시죠? 예를 들어보겠습니다.   <a href="http://imgur.com/RYuUVqx"><img src="http://i.imgur.com/RYuUVqx.png" title="source: imgur.com" /></a>  이날 대부분의 신문은 '사드' 관련 기사를 비중있게 보도했습니다. 그만큼 중요한 사안이라는 이야기죠. 우선 뉴스 제목을 **포스태깅**하고 조사 등 불필요한 품사를 제거했습니다. 그리고 중복 단어 숫자를 **웨이트(가중치)**로 하는 무방향 엣지를 연결했습니다. <a href="http://imgur.com/iUPUQNQ"><img src="http://i.imgur.com/iUPUQNQ.png" width="500px" title="source: imgur.com" /></a> 조선일보 1면 톱기사 '사드, 경북 성주에 배치한다'는 제목의 노드는 경향신문의 1면 톱기사 '사드 배치 경북 성주 사실상 결정'과 단어 중복수가 4개입니다(사드 경북 성주 배치). 조선일보의 1면 톱기사 제목은 한겨레의 1면 톱기사 '외교장관 만류에도 사드 결정 강행했다'는 기사와 2개 단어가 겹칩니다(사드, 하다), 경향신문과 한겨레 기사의 경우엔 1개(사드)가 겹칩니다. 이를 그래프로 그리면 위 그림과 같습니다. 단어 중복수를 웨이트로 한 그래프에선 조선일보 '사드, 경북 성주에 배치한다'가 중심 노드가 되겠네요.  그래프 이론에서는 노드의 중요도를 뽑는 데 **중심성(cetrality)** 개념을 제시합니다. 가장 대표적인 것이 **간선중심성(degree centrality)**입니다. 비교적 직관적으로 이해할 수 있는데요, 각 노드의 중심성 스코어는 엣지에 해당하는 웨이트들의 합입니다. 위의 그림 예시에서 보면 조선일보 1면 톱기사인 '사드, 경북 성주에 배치한다'는 노드의 간선중심성은 6입니다. 또 다른 지표는 **[고유벡터 중심성(eigenvector centrality)](https://en.wikipedia.org/wiki/Eigenvector_centrality)**를 꼽을 수 있습니다. 중요한 노드에 연결된 노드가 중요하다는 관점에서 창안된 개념인데요. 그래프의 엣지로 이뤄진 인접행렬(i번째 노드와 j번째 노드가 연결돼 있을 경우 $A_{ij}=1$, 아닐 경우 0)을 **[고유값 분해(eigenvalue decomposion)](http://darkpgmr.tistory.com/105)**를 하여 얻을 수 있습니다. 이렇게 구해진 i번째 노드의 고유벡터 중심성 점수($X_i$)와 그 의미는 다음과 같습니다. (n=전체 노드 개수) $${ x }_{ i }=\frac { 1 }{ \lambda } \sum _{ i=1 }^{ n }{ { A }_{ ij }{ x }_{ j } } $$ $$\begin{pmatrix} { A }_{ 11 } & { A }_{ 12 } & ... & { A }_{ 1n } \\ { A }_{ 21 } & { A }_{ 22 } & ... & { A }_{ 2n } \\ ... & ... & ... & ... \\ { A }_{ n1 } & { A }_{ n2 } & ... & { A }_{ nn } \end{pmatrix}\begin{pmatrix} { x }_{ 1 } \\ { x }_{ 2 } \\ ... \\ { x }_{ n } \end{pmatrix}=\begin{pmatrix} { A }_{ 11 }{ x }_{ 1 }+{ A }_{ 12 }{ x }_{ 2 }+...+{ A }_{ 1n }{ x }_{ n } \\ { A }_{ 21 }{ x }_{ 1 }+{ A }_{ 22 }{ x }_{ 2 }+...+{ A }_{ 2n }{ x }_{ n } \\ ... \\ { A }_{ n1 }{ x }_{ 1 }+{ A }_{ n2 }{ x }_{ 2 }+...+{ A }_{ nn }{ x }_{ n } \end{pmatrix}=\begin{pmatrix} { \lambda x }_{ 1 } \\ \lambda { x }_{ 2 } \\ ... \\ \lambda { x }_{ n } \end{pmatrix}$$ 위 수식과 행렬을 곱씹어 보면 $i$번째 노드의 고유벡터 중심성 점수($x_i$)는 자기 자신의 중심성 점수($x_i$)와 모든 이웃들의 중심성 스코어 점수의 합으로 표현할 수 있습니다. 바꿔 말하면 중심성 점수가 높은 중요한 이웃과 연결된 $i$번째 노드 또한 중심성 점수가 높아지게 된다는 얘기입니다. 반대로 생각하면 $i$번째 노드가 중요한 노드라면 $i$번째 노드와 연결된 이웃들의 중심성이 커지게 됩니다. 즉 중요한 노드에 연결된 노드가 중요하다는 말이 되는 셈이죠.   ## 실험설계 및 결과 이상 논의한 내용을 바탕으로 뉴스 제목의 중복 단어를 가중치로 하는 그래프를 구축했습니다. 각 노드의 중심성은 간선중심성과 고유벡터중심성 두 가지 지표를 구해 이를 곱하여 모두 고려했습니다. 분석 대상은 조선일보, 한겨레 등 10개 주요 조간 매체 10개월치 기사(2016년 1~10월) 20만7729건입니다. 위에서 예시로 든 2016년 7월 13일치 결과를 한번 보겠습니다. <a href="http://imgur.com/skxzxmI"><img src="http://i.imgur.com/skxzxmI.png" width="600px" title="source: imgur.com" /></a> 위 표에서 degree는 간선중심성, eigen은 고유벡터중심성, result는 이 둘을 곱한 스코어를 뜻합니다. result 기준으로 정렬해 상위 7개를 뽑았습니다. 이날은 '사드'가 중요한 이슈였던 모양입니다. 상위 기사에 '사드' 관련 기사가 모두 포진해있군요. section을 보시면 1~5면 사이의 기사가 상위에 랭크돼 있어 비교적 중요한 기사들이 뽑혔다는 사실 또한 알 수 있습니다. <a href="http://imgur.com/dcSDoOl"><img src="http://i.imgur.com/dcSDoOl.png" width="600px" title="source: imgur.com" /></a> 위 그림은 같은 날짜 스코어 하위 기사들입니다. 보통 중요하지 않은 기사들이 대부분인데요, 빨간색으로 표시한 기사가 눈에 좀 띕니다. 스코어는 낮은데 1면에 보도된 기사입니다. 아무래도 이건 다른 언론사 기사와 제목이 완전히 다른 '차별성 있는 기사'인 것 같습니다. result 스코어를 section 정보와 동시에 고려한다면 중요도 지표가 낮은(제목이 특이한) 기사 가운데 앞쪽면 기사는 해당 언론사의 특종이나 단독기획 기사일 가능성이 높다고 해석해도 나쁘지 않을 것 같다는 생각이 듭니다. 중심성 지표 기준 상위 3%를 중요기사라고 분류했습니다. 분석 대상 전체 기사 20만7729건 가운데 해당 면이 차지하는 비중과 비교한 그림은 다음과 같습니다. 지금까지 설명한 방법론이 앞쪽 면(비교적 중요) 기사를 걸러내는 데 효과적임을 알 수 있습니다. <a href="http://imgur.com/3oNAESt"><img src="http://i.imgur.com/3oNAESt.png" width="600px" title="source: imgur.com" /></a> 이제 '삼성'을 알아볼까요. 중요도 상위 3%에 뽑힌 기사들 가운데 '삼성'이라는 키워드가 들어간 기사의 제목을 쭉 나열해봤습니다. 삼성은 대한민국 대표기업인 만큼 회사 측 공식발표도 많고 매일 기사가 쏟아지는데도 중요한 이슈(지배구조 변화, 분기별 실적 등)가 비교적 잘 걸러짐을 확인할 수 있습니다. ![samsung](http://i.imgur.com/zXN3wUe.png) ![samsung](http://i.imgur.com/9i8RHnX.png)   ## 마치며 Graph-based News representation이 스트럭처 저널리즘의 완벽한 구현이자 종착역은 아닙니다. 다만 단순 팩트나 기존 기사들을 재조합하여 새로운 가치, 맥락을 만든다는 이상에 다가가기 위한 첫 단추로 역할을 할 수 있다면 더할 나위 없이 좋을 것 같습니다. 이외에도 옛날 기사를 어떻게든 되살려보려는 여러 가지 방법론들을 고민하고 있는데요, 지적하실 내용이나 아이디어, 질문 있으시면 언제든지 메일이나 댓글로 알려주시기 바랍니다. 여기까지 읽어주셔서 진심으로 감사드립니다.  
naive␞ 이번 글에서는 문서 분류를 하기 위한 **나이브 베이지안 분류기(Naive Bayesian Classifier)**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님과 역시 같은 대학의 정순영 교수님 강의, 그리고 *Speech and Language Processing(2nd ver)*을 정리했음을 먼저 밝힙니다. 베이즈 규칙과 관련해서는 [이곳](https://ratsgo.github.io/statistics/2017/07/01/bayes/)을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.   ## 나이브 베이즈 모델 문서 이진분류 문제를 예로 들어보겠습니다. 우리가 풀려는 문제는 문서 $d$가 주어졌을 때 범주 $c_1$ 혹은 $c_2$로 분류하는 것입니다. 지금까지 설명한 베이즈 법칙을 다시 쓰면 아래와 같습니다.  $$ \begin{align*} P({ c }_{ 1 }|d)&=\frac { P({ c }_{ 1 },d) }{ P(d) } =\frac { \frac { P({ c }_{ 1 },d) }{ P({ c }_{ 1 }) } \cdot P({ c }_{ 1 }) }{ P(d) } =\frac { P(d|{ c }_{ 1 }) { P({ c }_{ 1 }) }}{ P(d) } \\ P({ c }_{ 2 }|d)&=\frac { P(d|{ c }_{ 2 }){ P({ c }_{ 2 }) } }{ P(d) } \end{align*} $$  위 식에서 $P(c_i)$는 사전확률(prior)입니다. 범주 $c_i$인 문서 개수를 전체 문서 개수로 나눈 비율을 뜻합니다. $P(d$\|$c_i)$는 우도(likelihood)입니다. $P(c_i$\|$d)$는 사후확률(posterior)입니다. 문서 $d$가 주어졌을 때 해당 문서가 범주 $c_i$일 확률, 즉 우리가 알고 싶은 값입니다. 베이즈 모델은 $P(c_1$\|$d)/P(d)$와 $P(c_2$\|$d)/P(d)$를 비교해 큰 쪽으로 범주를 할당합니다. 그런데 여기에서 $P(d)$는 겹치므로 계산을 아예 생략할 수 있습니다. 그러면 위 베이즈 공식을 아래와 같이 다시 쓸 수 있습니다.   $$ P({ c }_{ i }|d)\propto P(d|{ c }_{ i }){ P({ c }_{ i }) } $$  만약 문서 범주 비율, 즉 사전확률 $P(c_1)$과 $P(c_2)$가 0.5로 서로 같다면 사전확률 계산도 생략 가능합니다.  $$ P({ c }_{ i }|d)\propto P(d|{ c }_{ i }) $$  이번엔 문서 $d$가 단어 $w_1$, $w_2$로 구성돼 있다고 칩시다. 식을 또 다시 써보겠습니다.  $$ \begin{align*} P({ c }_{ i }|d)&=P({ c }_{ i }|{ w }_{ 1 },{ w }_{ 2 })\\ &\propto P({ w }_{ 1 },{ w }_{ 2 }|{ c }_{ i }){ P({ c }_{ i }) } \\ &\propto P({ w }_{ 1 },{ w }_{ 2 }|{ c }_{ i }) \end{align*} $$  나이브 베이즈 분류기는 각 단어가 **독립(independent)**임을 가정합니다. 모델 이름에 나이브라는 말이 붙은 이유이기도 합니다. 이에 따라 식을 다시 쓸 수 있습니다.  $$ P({ w }_{ 1 },{ w }_{ 2 })=P({ w }_{ 1 })\cdot P({ w }_{ 2 })\\ P({ w }_{ 1 },{ w }_{ 2 }|{ c }_{ i })=P({ w }_{ 1 }|{ c }_{ i })\cdot P({ w }_{ 2 }|{ c }_{ i }) $$   ## bag-of-words representation 각 단어가 독립임을 가정하는 나이브 베이즈 분류기는, 문서 표현(representation) 방식 중 가장 간단한 기법인 [Bag-of-Words](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/10/frequency/)와 본질적으로 같은 접근을 취합니다. 나이브 베이즈 분류기는 범주가 주어졌을 때 각 단어가 나타날 확률(우도)의 연쇄적인 곱으로 계산을 하는데, $a$ 다음에 $b$를 곱하든 그 반대로 곱하든 결과가 같습니다. bag-of-words도 나이브 베이즈 모델처럼 단어의 등장 순서를 무시합니다. 그저 문서 내 빈도만을 따져서 문서를 표현합니다. 문서를 어떤 가방(bag) 안에 넣고 이를 뒤섞는다는 느낌 정도로 이해하면 직관적일 것 같습니다. 아래 그림은 영화 리뷰를 bag-of-words 방식의 representation으로 바꾸는 걸 도식화한 것입니다.  <a href="https://imgur.com/u5kdniF"><img src="https://i.imgur.com/u5kdniF.png" width="500px" title="source: imgur.com" /></a>    ## unigram model 나이브 베이즈 분류기는 [언어모델(Language Model)](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/09/16/LM/)의 **유니그램(unigram)** 모델과도 접점이 많습니다. 유니그램 모델은 도메인(domain)별로 각 단어의 등장확률을 구해놓은 다음 표와 같은 형태입니다.   <a href="https://imgur.com/ygTT7y9"><img src="https://i.imgur.com/ygTT7y9.png" width="200px" title="source: imgur.com" /></a>  임의의 문자열이 주어졌을 때 유니그램 모델은 단어별 등장 확률을 반복적으로 곱해 해당 문자열이 나타날 확률을 계산합니다. 나이브 베이즈 모델과 비교해 생각해볼 때 사전확률을 제외하면 그 과정이 동일합니다.   ## 계산예시1 다음과 같은 말뭉치가 주어졌다고 치겠습니다.   <a href="https://imgur.com/RibOSaF"><img src="https://i.imgur.com/RibOSaF.png" width="350px" title="source: imgur.com" /></a>  우선 사전확률부터 구해보겠습니다. 학습데이터 전체 5건의 문서 가운데 3개가 부정($-$), 2개가 긍정($+$)이므로 다음과 같습니다.  $$ P\left( - \right) =\frac { 3 }{ 5 } ,\quad P\left( + \right) =\frac { 2 }{ 5 } $$  이번엔 우도를 구해보겠습니다. 우선 학습데이터 문서 가운데 부정 범주의 전체 단어수는 14개입니다. 이 가운데 각 단어가 몇 개 있는지 세어서 각각의 우도를 구합니다. 다음과 같습니다.  $$ P\left( predictable|- \right) =\frac { 1 }{ 14 } \\ P\left(no|- \right) =\frac { 1 }{ 14 } \\ P\left(fun|- \right) =\frac { 0 }{ 14 } $$  이번엔 긍정 범주의 우도를 구해볼까요? 다음과 같습니다.  $$ P\left(predictable|+ \right) =\frac { 0 }{ 9 } \\ P\left(no|+ \right) =\frac { 0 }{ 9 } \\ P\left(fun|+ \right) =\frac { 1 }{ 9 } $$  이번엔 검증데이터 문서를 예측할 차례입니다. 각 범주에 해당하는 사전확률과 우도의 곱(아래 식)을 비교해 큰 쪽으로 분류하는 방식입니다.  $$ P\left( - \right) \times P\left( predictable|- \right) \times P\left( no|- \right) \times P\left(fun|- \right) \\ P\left( + \right) \times P\left(predictable|+ \right) \times P\left(no|+ \right) \times P\left(fun|+ \right) $$  그런데 실제 계산을 해보면 둘 모두 0이 될 겁니다. 우도 값 가운데 0이 되는 값이 있기 때문입니다. 우도값이 0이 되지 않도록 보정하는 **평활화(smoothing)** 기법이 제안되었습니다. 실제 구현에서 어떻게 동작하는지 이따가 살펴보겠습니다. 나이브 베이즈 모델의 학습은 학습말뭉치의 빈도 수를 세어서 위의 사전확률과 우도를 모두 구해놓는 과정을 가리킵니다. 추론(inference)은 사전확률과 우도의 곱을 계산하고, 큰 쪽의 범주를 할당합니다.  검증데이터 문서에 학습데이터에 없는 단어가 있을 경우엔 우도가 존재하지 않으므로 이를 빼고 계산합니다. 또한 관사, 전치사 등 범주 분류에 불필요하다고 판단되는 단어들에 대해서는 불용어(stopwords) 처리를 해서 빼기도 합니다.   ## 계산예시2 예를 하나 더 들어보겠습니다. 'love', 'fantastic' 두 개 단어로 구성된 영화 리뷰1을 긍정, 부정 두 개 범주 가운데 하나로 할당해야 한다고 가정합시다. 리뷰1이 긍정일 확률은 아래와 같이 우도의 연쇄적인 곱으로 구합니다. (사전확률, 즉 긍정/부정 리뷰 비율은 동일하다고 가정)  $$ \begin{align*} P(positive|{ review }_{ 1 })&\propto P(love|positive)\times P(fantastic|positive)\\ \\ &=\frac { count(love,positive) }{ \sum _{ w\in V }^{ }{ count(w,positive) } } \times \frac { count(fantastic,positive) }{ \sum _{ w\in V }^{ }{ count(w,positive) } } \end{align*} $$  이와 같은 방식으로 리뷰1이 부정일 확률도 구할 수 있습니다. 둘 중 큰 쪽으로 해당 리뷰의 범주를 할당합니다. 그러면 아래 리뷰 두 개를 분류해 봅시다. > **review1** : This movie was awesome! I really enjoyed it. > > **review2** : This movie was boring and waste of time.  전체 말뭉치로부터 구한 우도는 아래와 같습니다.  | Words | P(Word\|positive) | P(Word\|negative) | | :-----: | :---------------: | :---------------: | | This  |    0.1    |    0.1    | | Movie |    0.1    |    0.1    | |  Was  |    0.1    |    0.1    | | Awesome |    0.4    |    0.01    | |  I  |    0.2    |    0.2    | | Really |    0.3    |    0.05    | | enjoyed |    0.5    |    0.05    | |  It  |    0.1    |    0.1    | | Boring |    0.02    |    0.3    | |  And  |    0.1    |    0.1    | | Waste |    0.02    |    0.35    | |  Of  |    0.02    |    0.02    | | Time  |    0.15    |    0.15    | Review1은 위 우도 표에 의해 긍정, Review2는 부정 범주로 분류됩니다.  $$ { review }_{ 1 }\quad :\quad \prod _{ i }^{ }{ P({ word }_{ i }|Pos)=120\times { 10 }^{ -8 } } >\prod _{ i }^{ }{ P({ word }_{ i }|Neg)=0.5\times { 10 }^{ -8 } } \\ { review }_{ 2 }\quad :\quad \prod _{ i }^{ }{ P({ word }_{ i }|Pos)=0.012\times { 10 }^{ -8 } } <\prod _{ i }^{ }{ P({ word }_{ i }|Neg)=3.15\times { 10 }^{ -8 } } $$   ## 장단점 및 최적화 나이브 베이즈 분류기는 앞선 예시의 우도 테이블 하나만 있으면 분류가 가능합니다. 사전확률이 다르다면 전체 문서 범주 비율만 더 반영해주면 됩니다. 그만큼 계산복잡성이 낮다는 얘기입니다. 이미 말씀드렸던 것처럼 단어 등장확률을 독립으로 가정하는 [Bag-of-Words](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/10/frequency/) 기법과 잘 어울리는 모델이라고 합니다. 딥러닝 이전 자연언어처리 기법으로 각광받았던 모델입니다. 다만 나이브 베이즈 분류기는 문서에 등장하는 단어 수만큼의 우도 확률 곱으로 분류를 수행하기 때문에 단어 수가 늘어날 수록 그 값이 0으로 수렴하는 경향이 있습니다. 1보다 작은 값은 곱할 수록 작아지는 게 당연한 이치입니다. 특히 특정 범주, 가령 긍정 문서에 단 한번도 등장하지 않은 단어가 있다면 해당 단어의 우도는 0이 되기 때문에 분류 과정에 큰 문제가 됩니다. 이를 위해 *smoothing*을 수행합니다. 문서 내 중복단어를 없애 분석 정확성을 높이는 **Binary multinomial naive Bayes(binary NB)** 기법도 있습니다. 한 단어가 문서 내에 등장했는지 여부만 따집니다. 개별 문서에 한두차례 등장하지만 정보성이 높은 단어를 잘 포착하는 경향이 있어 성능 향상에 도움이 된다고 합니다.  <a href="https://imgur.com/fnmdYTS"><img src="https://i.imgur.com/fnmdYTS.png" width="500px" title="source: imgur.com" /></a>  나이브 베이즈 모델은 그 특성상 부정어(negation) 처리에 취약합니다. 이 때문에 부정어가 등장한 위치에서 뒤에 나오는 모든 단어에 다음과 같은 처리를 하여 이 문제를 보완하는 방법도 제안됐습니다. 이렇게 되면 *not_like*, *not_movie*와 관련된 우도가 *like*, *movie*와 따로 계산되고, 추론 과정에서도 따로 계산된 결과가 반영됩니다. > didn't like this movie => didn't not_like not_this not_movie   ## 파이썬 구현 실제 구현 단계에서는 다음과 같은 평활화 처리가 필요합니다. $i$번째 단어가 긍정 문서에 단 한번도 쓰이지 않더라도 그 우도확률이 0이 되지 않도록 분자와 분모에 적당히 작은 상수를 더해주는 것입니다.  $$ P({ w }_{ i }|positive)=\frac { k+count({ w }_{ i },positive) }{ 2k+\sum _{ w\in V }^{ }{ count(w,positive) } } $$  또한 컴퓨터는 0에 가까운 **부동소수점(floating point number)**을 제대로 처리하지 못하기 때문에 우도의 곱은 로그 우도의 합으로 처리합니다. 예컨대 긍정 범주에 대해서는 다음과 같습니다.  $$ \prod _{ i }^{ }{ P({ word }_{ i }|Pos) } =exp\left[ \sum _{ i }^{ }{ \left\{ \log { P({ word }_{ i }|Pos) } \right\} } \right] $$  나이브 베이지안 분류기를 '밑바탁부터 시작하는 데이터 과학(조엘 그루스 지음, 인사이트 펴냄)'을 기본으로 해서 살짝 손질한 파이썬 코드는 다음과 같습니다. 별도 토크나이징은 하지 않고 어절 단위(띄어쓰기)로 문자열을 나눠서 학습을 진행합니다. <script src="https://gist.github.com/ratsgo/45d6eb4822ae27b01329e3b8c15c8f98.js"></script>  학습은 다음과 같이 하면 됩니다. ```python model = NaiveBayesClassifier() model.train(trainfile_path='kor_review.csv') ``` 학습용 말뭉치(kor_review.csv)는 아래처럼 생겼습니다. ```python "이게 왜 명작 이라는 건지",0.5 "감동이 오지 않음에 나 역시 놀란다 내가 문제인걸까",2 ``` 테스트는 다음과 같이 하면 됩니다. ```python model.classify('모든 것이 완벽하다 평생 함께 갈 영화') ```   ## 파일럿 실험 왓챠 영화 리뷰 70만여개를 학습한 뒤 테스트 문장을 다음과 같이 넣어봤습니다. 오른쪽의 숫자는 해당 리뷰가 긍정 범주일 가능성을 나타냅니다. 클 수록 긍정, 작을 수록 부정 리뷰로 분류된 겁니다. > (1) 단언컨대 이 영화의 결말은 영화사를 통틀어 최고 중 하나입니다 물론 거기까지 이끌어낸 플롯도 실로 대단하고 말이죠 : 0.99998 > > (2) 이 영화가 지루하고 뻔했다는건 내가 너무 늦게 본 탓이겠지 ㅠㅠ : 0.01623 > > (3) 졸작이 아니라 대작이다 : 0.13773 간단한 모델임에도 비교적 좋은 성능을 보이는 가운데 (3)과 같이 전혀 엉뚱한 결과를 보이는 점이 눈에 띕니다. 부정어에 대한 별도 처리를 하지 않았기 때문에 생기는 문제 아닌가 하는 생각이 듭니다. 다음은 $P(w_i$\|$positive)$가 큰 상위 200개 단어 목록입니다. > 영화, 수, 이, 그, 너무, 정말, 더, 영화를, 내, 것, 있는, 최고의, 내가, 그리고, 가장, 본, 한, 진짜, 영화가, 잘, 보고, 다시, 없는, 이런, 다, 모든, 대한, 영화는, 없다, 보는, 또, 있다, 마지막, 하는, 최고, 이렇게, 나는, 영화의, 때, 좋다, 그냥, 볼, 난, 왜, 할, 같다, 같은, 좋은, 아름다운, 내내, 중, 다른, 함께, 것이, 꼭, 작품, 것을, 하지만, 봐도, 역시, 이야기, 나도, 나의, 모두, 많은, 않는, 사랑, 완벽한, 아닌, 말이, 어떤, 않은, 보면, 하나, 연기, 싶다, 있을까, 많이, 두, 것은, 아, 아니라, 참, 영화다, 것이다, 인생, 어떻게, 되는, 좋았다, 좋아하는, 한다, 하고, 스토리, 만드는, 만든, 나를, 제일, 지금, 아직도, 위한, 그런, 된, 싶은, 결국, 명작, 위해, 된다, 않는다, 될, 얼마나, 계속, 처음, 밖에, 그의, 사랑을, 없이, 영화에, 끝까지, 이건, 별, 좀, 사람이, 감독의, 봤다, 음악, 우리, 대해, 주는, 인간의, U, 한번, 줄, 않고, 눈물이, 액션, 건, gt, 듯, ㅠㅠ, 봤는데, 우리는, 그렇게, 새로운, 멋진, 안, 아니다, 느낌, 너무나, 사랑하는, 재밌게, 큰, 순간, 걸, 감동, 생각이, 그저, 같이, 나, 연출, 와, 재밌다, 장면, lt, 있었다, 게, 보여주는, 그래서, 이게, 나오는, 없었다, 그래도, 마음이, 진정한, 나에게, 아주, 애니메이션, 삶을, 보면서, 여운이, 배우들의, 날, 생각을, 아닐까, 때문에, 우리가, 특히, 더욱, 느낄, 미친, ㅋㅋ, 연기가, 좋고, 항상, 최고다, 영화관에서, 자신의, 장면이, the, you, 것도 다음은 $P(w_i$\|$negative)$가 큰 상위 200개 단어 목록입니다. > 영화, 이, 너무, 수, 왜, 더, 그냥, 영화를, 없다, 그, 없는, 이런, 다, 영화는, 것, 영화가, 내가, 정말, 좀, 진짜, 잘, 내, 본, 이렇게, 보는, 한, 보고, 안, 좋은, 하는, 대한, 이건, 있는, 별, 난, 없고, 스토리, 느낌, 영화의, 하지만, 그리고, 아, 이게, 같은, 많이, 같다, 끝까지, 만든, 할, 봤는데, 내내, 볼, 뻔한, 뭐, 무슨, 참, 건, 하고, 모르겠다, 그래도, 있다, 이걸, 듯, 나는, 아닌, 별로, 보면, 하나, 모든, 전혀, 다른, 뭔가, 게, 않는, 차라리, 않은, 때문에, 아니다, 마지막, 연기, 가장, 이제, 영화에, 감독이, 것도, 다시, 근데, 위한, 때, 이야기, gt, 못한, 못, 감독의, 또, 이거, 것이, 아깝다, 뭘, 아니라, 줄, 않는다, 그저, 어떻게, 그나마, 봤다, 없었다, 그래서, 역시, 최악의, 재미가, 않고, 싶다, 두, 나오는, 위해, 것은, 결국, 했다, 한다, lt, 감독, 제대로, 연출, 재미도, 것을, 많은, 1, 스토리가, 도대체, 걸, 그런, 뿐, 없이, 딱, 쓰레기, 0, 보다가, 보다, 그렇게, 않다, 제일, 아무리, 작품, 밖에, ㅠㅠ, 싶은, 전개, 아니고, 중, 영화관에서, 계속, 액션, 영화로, 기억에, 굳이, 만드는, 제발, 되는, 연기는, 대체, 배우들의, 큰, 그만, 보기, 없음, 거, 안되는, 어떤, 솔직히, 된, 모두, 끝, 하나도, 아쉽다, 돈, 한국, 될, 캐릭터, 연기가, 원작을, 함께, 스토리는, 노잼, 않았다, 기억이, 코미디, 배우, 전형적인, 최악, 내용이, 이해가, 생각이, 극장에서, 시간, 지루한, 그게, 수가, 말이, 영화도
sentcomp␞ 이번 글에서는 한국어의 문장 성분에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 문장성분 문장성분이란 한 문장을 구성하는 요소들을 문법적 기능에 따라 나눈 것을 가리킵니다. 여기서 문법적 기능이란 그 요소가 해당 문장 속에서 다른 요소와 어떤 (문법적) 관계를 가지면서 어떤 일을 하고 있는가를 나타냅니다. 예컨대 '주어'는 서술어가 나타내는 동작이나 상태의 주체가 되는 말입니다. '목적어'는 타동사가 쓰인 문장에서 동작의 대상이 되는 말입니다. '서술어'는 한 문장에서 주어의 움직임, 상태, 성질 따위를 서술하는 말입니다. 문장성분을 분석한다는 말은 문장이 주어졌을 때 주어, 목적어, 서술어 등으로 나누어 생각해본다는 뜻입니다. 문장성분을 확인할 땐 형태론적, 통사론적, 의미론적 기준이 있습니다.  형태론적 기준은 격조사 등이 결합한 양상(형태)를 가지고 따져보는 것입니다. 주격조사 '-이/가'가 붙은 명사(구)는 형태론적 기준으로 봤을 때 주어가 될 수 있는 후보가 됩니다. 통사론적 기준은 다른 말과의 문법적 관계를 가지고 따져보는 것입니다. 예컨대 서술어에 선어말어미 '-시-'가 실현됐다고 했을 때 '-시-'와 호응하는 대상이 뭔지 분석해 해당 성분을 주어로 보는 것입니다. 마지막으로 의미론적 기준은 해당 문장성분의 의미적인 내용을 가려보는 것인데요, 해당 성분이 행위주역(Agent)인지 등을 따져보게 됩니다. 그러나 이 세 가지 기준이 항상 절대적으로 작용하는 것은 아닙니다. 가령 형태론적 기준만 해도 완전하지 않습니다. 한국어에서는 대개 격조사 '-이/가'가 붙으면 해당 명사(구)는 주어인 경향이 있습니다. 그런데 격조사가 붙은 양상(형태)만 가지고 해당 명사(구)를 주어라고 판단할 경우 문제가 발생할 수 있습니다. 다음 예문을 보겠습니다. > 진이가 의사가 되었다. 위 예문에서 전체 문장에서 주어는 '진이가'로 보는게 적절합니다. '의사가'의 경우 '-이/가'가 붙은 모양만 가지고는 주어 같지만 문장성분으로는 주어가 아닙니다(보어). 반대로 '-이/가'가 붙지 않았는데 주어인 사례도 존재합니다. 다음 예문과 같습니다. 아래 문장에서 주어는 '우리 학교에서'가 분명합니다. > 우리 학교에서 대회를 개최했다. 이 글에 정리된 내용은 문장성분을 분석하는 절대적인 기준이라기보다는 한국어 문장성분의 전형적인 특성이라고 이해하시는 게 좋겠습니다.   ## 문장성분의 종류 한국어 문장성분에는 크게 세 가지 종류가 있습니다. 하나의 문장이 성립하기 위해 반드시 필요한 문장성분인 **주성분**, 반드시 필요한 요소는 아니면서 주로 주성분을 수식하는 기능을 하는 문장성분인 **부속성분**, 다른 말과 문법적 관계를 맺지 않고 독립되어 있는 성분인 **독립성분**이 바로 그것입니다. 주성분에는 주어, 서술어, 목적어, 보어 네 가지가 있고, 부속성분에는 관형어, 부사어, 독립성분에는 독립어가 있습니다. 일곱가지 문장성분을 차례로 정리해보겠습니다.   ## 주어 주어란 서술어의 동작 또는 상태나 성질의 주체를 가리킵니다. 우선 형태론적 특징 먼저 보겠습니다. 일반적으로 명사구나 명사절에 주격 조사가 결합하여 실현되나, 보조사가 결합하거나, 조사 없이 실현되기도 합니다. 다음 예문과 같습니다. | 구분        | 예문                   | | :--------------- | --------------------------------------- | | 명사에 주격조사 결합   | **눈이** 많이 왔다, **할머니께서** 떡을 사 오셨다.    | | 명사구/명사절에 주격조사 결합 | **걷는 사람들이** 많다, **우리 학교가 승리하였음이** 틀림없다. | | 보조사 결합      | **진이는/도/만** 울고 있다            | | 조사 없이 실현     | **너** 어디 사니?              | 주어의 통사론적 특성은 크게 네 가지로 구분됩니다. 첫째 전형적인 한국어 문장의 주어는 다른 성분에 비해 앞에 나오는 경향이 있습니다. 다음 예문에서 (ㄱ)의 경우 좋아하는 주체가 '진이'이며 (ㄴ)은 '철수'라는 점을 단박에 알 수 있습니다.  > (ㄱ) 진이 철수 좋아해 > > (ㄴ) 철수 진이 좋아해 둘째 주어 자리에 오는 명사가 존대의 대상이면 서술어인 용언에 선어말어미 '-시-'가 결합합니다. (ㄷ)에서 주어이자 높임의 대상은 '선생님'이기 때문에 '-시-'가 쓰였고, (ㄹ)에서 '내가'는 주어이지만 높임의 대상이 아니고 '선생님을'은 높임의 대상이지만 주어가 아니기 때문에 '-시-'가 쓰이면 비문이 됩니다. > (ㄷ) 선생님께서 나를 보셨어 > > (ㄹ) 내가 선생님을 *보셨어 셋째 한국어의 주어는 재귀대명사의 선행사가 됩니다. (ㅁ)의 재귀대명사 '자기'는 주어인 '진이'를 가리킵니다. (ㅂ)의 '자기'는 문장 전체의 주어인 '진이'를 가리킬 수도 있고, '아이들'을 가리킬 수도 있습니다. 그런데 (ㅂ)의 서술어 '보내다'는 '가게 하다'는 사동(使動)의 의미를 가지는 동사로써 '아이들'이 이동의 의미상 주어로 해석할 여지가 있습니다. > (ㅁ) 진이는 졸지에 자기 보호자가 됐다 > > (ㅂ) 진이$i$는 아이들$j$을 자기$i/j$으로 보냈다 넷째 주어가 복수일 때 다른 성분에도 '-들'이 연결되게 할 수 있습니다. 다시 말해 (ㅅ)과 같이 주어의 복수성이 다른 성분에도 옮겨가서 실현된다는 것입니다. 그러나 (ㅇ)과 같이 목적어가 복수인 경우 다른 성분에 '-들'이 붙을 수 없습니다. > (ㅅ) 사람들이 많이들 왔다 > > (ㅇ) 진이야, 밖에 나가서 친구들을 좀 *만나들 예문을 통해 실제 주어 판단을 해보겠습니다.  > 진이에게 집이 있다. 형태론적으로 따져봤을 때는 '집'에 '-이/가'가 붙어 주어일 가능성이 있습니다. '진이'의 경우 '-에게'가 붙어 주어임을 확신하지 못하겠습니다. 통사론적 기준을 적용해 보겠습니다. 우선 다음과 같이 '-시-'와의 호응을 따져봅니다.  > (ㅈ) 선생님께는 낡은 집이 한 채 있으시다. > > (ㅊ) *진이에게는 존경하는 선생님이 한 분 있으시다. 주어 자리에 높임의 대상을 넣어봄으로써 수행할 수 있습니다. (ㅈ)은 되고 (ㅊ)은 안되는걸로 봐서 '진이에게'가 주어일 가능성이 있습니다. 이번에는 재귀대명사를 넣어서 확인해 보겠습니다. > (ㅋ) 진이에게 자기 집이 있다. > > (ㅎ) 자기에게 진이 집이 있다. (ㅋ)의 '자기'가 가리키는 대상은 '진이'이며 문장이 성립합니다. 하지만 (ㅎ)의 '자기'는 '진이 집'을 가리키지 않습니다. 따라서 통사론적인 기준으로는 '진이에게'가 문장의 주어로 판단됩니다. 이같이 처격조사로 실현되는 주어를 처격주어라고 합니다.   ## 목적어 서술어의 동작의 대상을 목적어라고 합니다. 목적어의 형태론적 특징은 다음과 같습니다. 일반적으로 명사구, 명사절에 격조사 '-을/를'이 결합하여 실현되나, 보조사가 결합하거나, 조사 없이 실현되기도 합니다. 예문을 보겠습니다. |   구분   | 명사          | 명사구(절)            | | :--------: | :------------------- | ---------------------------- | | '-을/를'의 결합 | 진이는 **와인을** 마신다.   | 진이가 **새 책을** 샀다.       | | 보조사의 결합  | 진이는 **와인은/도/만** 마신다. | **내가 너희들에게 어떻게 해 주기를** 원하느냐? | | 조사 없이 실현 | 너 **뭐** 먹을래?     | -              | 목적어의 통사론적인 특성은 해당 문장이 피동문으로 바뀔 때 목적어가 주어가 된다는 점입니다. 예문을 보겠습니다. > (1) 진이는 이 책을 세 번을 읽었다. > > (2) 이 책이 진이한테 세 번을 읽혔다. > > (3) *세 번이 진이한테 이 책을 읽혔다. (1)에서 목적어가 '이 책을'인지, '세 번을'인지 확실치 않습니다. 이를 피동문으로 바꿔 확인합니다. (2)는 '이 책을'을 주어로, (3)은 '세 번을'을 주어로 바꾼 피동문입니다. (3)이 비문이 되므로 (1)의 목적어는 '이 책을'이라고 판단하는 것입니다.   ## 보어 학교문법에서 보어는 동사 '되다'와 형용사 '아니다' 앞에 오는, 주어가 아닌 '명사구+이/가' 구성만을 가리킵니다. 다음 예문과 같습니다. > 진이가 **대학생이** 되었다. > > 침대는 **가구가** 아닙니다. 하지만 이 구성 말고도 주어와 목적어가 아니면서 서술어가 필수적으로 요구하는 성분, 즉 보어가 되는 사례가 존재합니다. 다음 예문을 보겠습니다. > 진이는 **서울에** 산다. > > 이 그림은 **실물과** 똑같다. > > 어머니는 진이를 **수양딸로** 삼았다. 위 예문에서 볼드 표시한 어절 없이는 문장이 성립하지 않습니다. 다시 말해 보어의 요건을 충족시킨다는 것입니다. '-에', '-로', '-와'는 대개 부사어를 만들어 주는 조사이지만 위 예문처럼 문장의 필수 성분인 '보어'를 만들어 주는 경우 또한 존재합니다.  더구나 아래와 같은 예문에서 '대학생이'와 '가구가'는 문장의 필수 성분, 즉 보어임에도 학교문법의 견해에 따르면 보어가 아니게 됩니다. 따라서 '되다', '아니다' 앞의 '명사구+이/가' 말고도 특정 동사나 형용사가 요구하는 필수적인 성분들 역시 보어에 포함하는 것이 더 적절할 듯 합니다. > 진이가 **대학생이** 맞다, 침대는 **가구가** 맞다 > > 진이가 **대학생이** 틀림없다, 침대는 **가구가** 틀림없다    ## 서술어 서술어란 주어의 동작이나 상태를 서술하는 말입니다. 형태론적으로는 동사, 형용사, '명사+이다'와 어미로 이뤄진 구성입니다. '이다'나 '하다'가 생략된 채로 서술어가 되기도 합니다. 다음 예문을 보겠습니다. | 구분    | 예문                  | | -------- | ------------------------------------ | | 동사+어미  | 밤하늘에 별이 **반짝인다**.          | | 형용사+어미  | 진이는 **예쁘다**.             | | 명사+이다  | 저 건물이 **서울역이다**.           | | 부사(절)+이다 | 우리가 목적지에 도착한 것은 **새벽 두 시가 가까워서입니다**. | | '하다'의 생략 | 한국 등반대 드디어 정상을 **정복**.        | | 본용언+보조용언 | 진이가 페인트를 **닦아 냈다**.         | 위 예문에서 '부사(절)+이다' 구성을 좀 더 살펴보겠습니다. 부사(절)이 명사처럼 역할을 하면서 '이다'와 결합한 '부사절+이다' 구성 전체가 서술어 역할을 하고 있음을 확인할 수 있습니다. 'A는 B이다' 형식의 분열문의 일종이라고 보면 좋을 것 같습니다.  마지막으로 '본용언+보조용언' 구성 전체가 서술어 역할을 하는 경우도 있습니다. 본용언과 보조용언 사이에 다른 말이 끼어들 수 없고, 다음 예문처럼 성분 변화시 한 덩어리처럼 기능하기 때문에 '본용언+보조용언' 구성이 하나의 서술어 역할을 한다고 분석합니다. > 진이가 페인트를 닦아 낸다. > > 페인트가 진이에 의해 닦아 내졌다. 이번엔 서술어의 통사론적 특징을 보겠습니다. 우선 서술어는 주어, 목적어, 보어를 거느립니다. 대개 다른 성분보다 뒤에 나타납니다. 마지막으로 부사어의 수식을 받을 수 있습니다. 다음 예문과 같습니다. > 밤하늘에 별이 더욱 반짝인다. > > 진이는 아주 예쁘다. > > 저 건물이 정말 서울역이다.   ## 관형어 관형어는 명사를 꾸며주는 부속 성분입니다. 보통의 경우에 문장 성립에 있어서 필수적으로 요구되는 성분은 아니지만 의존명사는 관형어를 필수적으로 요구하기도 합니다. 다음 예문과 같습니다. > 싼 것이 좋다. > > 우리는 거기에 가 본 적이 없습니다. 관형사가 관형어로 쓰이기도 하고, '명사구+의', 동사나 형용사에 관형형 어미가 결합된 것이 쓰이기도 합니다. 다음은 관형어의 형태별 예문입니다. | 구분    | 예문             | | --------- | -------------------------- | | 관형사    | 우리는 **헌** 책을 후배들에게 물려 주었다. | | 명사(구)+의  | 나는 **비틀즈의** 노래를 좋아한다.   | | 명사    | 진이는 **시골** 풍경을 좋아한다.    | | 용언+관형형 어미 | **아름답던** 마을이 폐허가 되었다.   | | 관형사절   | 너는 **진이가 어제 귀국한** 사실을 몰랐니? | 그러나 관형어는 다른 문장성분들과는 그 층위가 대등하지 않습니다. 즉 관형어는 주어나 목적어, 보어가 아니라 '명사'를 수식합니다. 예문을 보겠습니다. > 성실한 학생이 왔다. 위 문장에서 주어는 '성실한 학생'이고, 관형어 '성실한'은 '학생'을 수식합니다. 다시 말해 주어 내부에 관형어가 있는 구성입니다.   ## 부사어 부사어는 주로 서술어를 꾸며주는 부속 성분입니다. 부사가 부사어로 쓰이기도 하고, '명사+부사격조사', 동사나 형용사에 부사형 어미가 결합된 것이 부사어로 쓰이기도 합니다. 예문을 보겠습니다. | 구분     | 예문                | | ----------- | --------------------------------- | | 부사     | 우리는 **자주** 만났다.          | | 명사+부사격조사  | 우리는 **서울에서** 만났다.         | | 용언+부사형 어미  | 우리는 **늦게** 만났다.          | | 용언+부사성 의존명사 | **놀 만큼** 놀았다, **어제 했던 대로** 해 보아라. | | 부사절     | **사람들이 떠드는 소리에** 잠을 자지 못했다.    |   ## 독립어 독립어는 문장의 어느 성분과도 직접적인 관련 없이 쓰입니다. 독립어를 감동어, 호격어, 접속어, 제시어 네 가지로 나누기도 합니다. 감동어는 이어지는 문장이 없이도 사용에 장애를 받지 않으며, 놓이는 순서가 매우 자유롭습니다. 감탄사가 여기에 속합니다. 예문을 보겠습니다. > **아!** 저기는 단풍의 바다로구나. > > **예**, 저도 가겠습니다. 호격어는 누군가를 부르는 말입니다. 해라체에서는 호격조사 '아, 야'로, 하게체부터는 명사구만으로 표시됩니다. 호격조사 '이여, 이시여'가 붙은 명사구도 호격어가 될 수 잇습니다. 문장의 가운데나 끝에 놓일 수 있습니다. > **진이야**, 빨리 학교에 가거라. > > **이 군**, 이리 와서 일 좀 도와 주게. > > **정 박사**, 식사하러 나갑시다. > > **선생님**, 어디가 편찮으십니까? > > **겨레여**, 잠에서 깨어나라 / **임이시여**, 나를 떠나지 마시옵소서 접속어는 접속부사 가운데서 단어 및 어절 접속의 '또는, 혹은, 및'을 제외한 나머지 접속부사를 가리킵니다. > 정직하게 살아라. **그리고** 열심히 노력해라. > > 어느 나라 사람이나 먹는 것은 다 같다. **그러나** 먹는 방법과 양식이 다르다. 제시어는 뒤의 내용을 대표하는 명사구를 첫머리에 제시함으로써 상대방으로 하여금 주의를 집중토록 하는 성분입니다. 명사구로만 성립하고 특별한 조사가 붙는 일이 없습니다. > **청춘**, 이는 듣기만 하여도 가슴이 설레는 말이다.  
italy␞ 지난 4일부터 1주일 간 로마를 시작으로 피렌체, 아시시, 베니스, 밀라노 5개 도시를 방문했다. 이 느낌을 오래 간직하기 위해 짧은 인상 위주로 정리해 둔다. *(2018년 2월 11일 밀라노 말펜사 공항)*  \#01. 환승하기 위해 잠시 들렀던 터키 이스탄불 소재 아타튀르(Atatürk) 국제공항 서비스는 형편없었다. 환승 게이트 안내는 비행기 탑승 1시간 전에야 이뤄져서 환승객들이 공항 곳곳에서 갈팡질팡했다. 비행기 탑승 30분 전 게이트가 오픈된 것까지는 좋았다. 승객들을 게이트에서 스텝카(탑승용 계단차량)까지 실어나르는 버스에 가둬두고는 탑승시각이 넘어서까지 출발도 않고 대기하는 것 아닌가. 게이트를 관리하는 직원은 단 한 명. 항공편이 특별히 지연(delay)되어야 할 물리적 이유가 하나도 없었는데 이날 이스탄불발-로마행 TK1861편은 30여분 가까이 늑장 출발했다. 그에 반하면 인천공항은 정말이지 세계 최고 수준이다. \#02. TK1861편 창가에 비친 이탈리아의 첫 인상은 '따스한 햇살이 비치는 평온한 대평원'이었다. 날씨가 좋아서 로마 주변을 전체적으로 조망할 수 있었다. 드넓은 초지가 펼쳐져 있고 군데군데 조그마한 촌락들이 있으며 그 촌락들 사이를 거미줄처럼 잇는 길이 나 있었다. 자료를 찾아보니 테베레 강 유역, 아펜니노 산맥과 티레니아해 사이에 있는 넓은 평야지대를 '라티움(Latium)'이라고 한단다. 초기 고대 로마가 이곳을 중심으로 성장했다고 한다. 역시 그러면 그렇지. 라티움 같은 배후 생산지역이 없었다면 로마 같은 소비 도시는 탄생하기 어려웠을 것이다. 로마는 예나 지금이나 향락이 중심이다. \#03. 짐을 숙소에 내팽겨치다시피해서 처음 방문한 곳은 '콜로세움(Colosseum)'. 고대 로마 시대를 대표하는 원형 경기장이다. 테르미니역에 있는 숙소에서 멀지 않아서 우연히 Parco Del Colle Oppio 공원을 거쳐 가게 됐다. 그런데 공원에서 콜로세움을 후면에서 볼 수 있는 것 아닌가! 그것도 한적한 벤치까지 마련돼 있다. 지중해 따뜻한 겨울햇살을 내리쬐며 벤치에 앉아 한가로이 콜로세움을 바라보는 경험은 황홀함 그 자체였다. 이 글을 쓰는 지금도 그 때 그 감동을 잊을 수가 없다.  \#04. 콜로세움을 기점으로 베네치아 광장(Piazza Venezia)에 이르는 거리 'Via dei Fori Imperiali'는 일요일이면 차없는 거리로 변신한다. 덕분에 온갖 행위예술인들이 세계 관광객들의 이목을 끈다. 특히 포룸 로마눔(Forum Romanum) 앞에서 공연하던 라틴 형제 3인방이 기억에 남는다. 기타 2, 콘트라베이스 1로 구성된 이들은 연주도 연주지만 한때 번성했지만 흔적만 남아있는 로마 중심 시가지를 배경으로 빼어난 실력을 뽐내고 있어 무척 아이러니하게 느껴졌다. 맥수지탄(麥秀之歎)이나 산 사람은 어찌됐든 살아야 한다. 3인방 중 한 명이 공짜로 주겠다며 CD 두 장을 내게 건넸다. 공짜인데 어찌 마다하겠는가. 그런데 노래 두 곡이 끝나고 나서 20유로를 달란다. 허허.. 주머니를 뒤집어 돈 없다는 시늉을 했다. 대신 노랫값만 내고 슬그머니 빠져나왔다. 역시 산 사람은 살아야 한다. \#05. 바티칸 시국 남동쪽에 있는 '성 베드로 대성당(Basilica di San Pietro)'과 바티칸 궁전 내 시스티나 성당(Aedicula Sixtina)은 이탈리아 여행 전체를 통틀어 최고라 할 만 하다. 규모도 웅장하고 장식과 그림 하나하나 정성이 깃들어 있다. 신자가 아니라도 절로 경외감이 들 정도로. 미켈란젤로가 시스티나 성당 벽에 그린 그림들이 압권이다. 1시간 넘게 '아담의 창조(천장)', '최후의 심판(제단 쪽 벽면 전체)'을 구석구석 보느라 목 빠지는 줄 알았다. 당시 그들은 어떤 마음으로 프레스코화를 그렸을까. 그 신앙심이 존경스럽다. \#06. 로마에서 기차로 2시간여 거리인 소도시 아시시(Assisi). 평생 세속과는 멀리 하고 길거리에서 복음을 전파한 성 프란치스코(San Francesco, 1181-1226)가 이곳에 잠들어 있다. 프란치스코의 유해가 안치된 성 프란치스코 대성당 지하엔 성음악이 흐르고 있다. 거리는 적막할 정도로 조용하다. 그의 추종자들은 지금까지도 이 촌락에서 금욕적인 삶을 추구하며 수도 생활을 하고 있다. 그러나 상술 하나만큼은 철저히 세속적이다. 토마토와 치즈를 곁들인 피아디나(piadina)와 콜라 한 캔에 12유로(우리돈 1만7000원 가량)나 한다. 놀랍다. \#07. 피렌체에 있는 우피치 미술관(Galleria degli Uffizi)는 실로 대단하다. 그 빼어나고 방대한 작품들 모두 한 가문(메디치)이 기증한 것이라니. 미술에는 그다지 조예가 없어서 사람들이 많이들 감상하고 있는 작품들을 위주로 유심히 살펴보았다. 어떤 작품이든 자세히 들여다보면 그 디테일에 감탄하지 않을 수 없었다. 나중에 블로그 대문사진이나 휴대폰 잠금화면으로 쓰려고 그림 사진을 많이 찍어두었다. \#08. 비 갠 후 노을 진 피렌체 시내 겨울 풍광은 무척 아름답다. 피렌체 대성당의 쿠폴라(cupola)를 오르는 463개의 계단이 조금 버겁기는 하지만. 비가 주륵주륵 오는데도 기다린 보람이 있었다. \#09. 베니스엔 차가 없다. 바다와 운하를 오가는 곤돌라(gondola)들뿐이다. 경찰차, 구급차도 모두 곤돌라다. 버스도 물 위를 다닌다. 예전 베니스 귀족들은 곤돌라 치장에 꽤 많은 돈을 썼다 한다. 차 대신에 말이다. 어쨌든 저렴하고 탈 만한 지상 교통수단이 없어 베니스 시내 전체를 계속 걸어다닐 수밖에 없었다. \#10. 운좋게 베니스 2월 축제를 볼 수 있었다. 생각지도 못한 수확이었다. 춤과 노래는 언제나 흥겹다. 형형색색의 옷과 가면으로 치장한 사람들은 국적과 관계없이 거리에서 모두 친구가 됐다. \#11. 밀라노는 세계 패션 중심이다. 명품 상점들이 즐비하다. 행인들도 꽤 멋쟁이들인 것 같다. 하지만 밀라노는 화장실 인심이 박하다. 크디큰 쇼핑몰 안에 공용 화장실 하나 찾을 수가 없다. 가끔 찾는다 해도 0.5~1.5유로를 내야 한다. 그런데 저 수많은 사람들은 어디서 똥 누고 오줌을 싸는 걸까. 패션보다 중한 건 용변 해결일텐데. 용무가 급해서 공용 화장실을 찾느라 밀라노 중심가를 이리저리 뛰어다니다 든 생각이다. 
pcasvdlsa␞ 이번 포스팅에서는 **차원축소(dimension reduction)** 기법으로 널리 쓰이고 있는 **특이값분해(Singular Value Decomposion)**와 **주성분분석(Principal Component Analysis)**에 대해 알아보도록 하겠습니다. 마지막으로는 이러한 기법이 **잠재의미분석(Latent Sematic Analysis)**와 어떻게 연결되는지 이야기해보도록 하겠습니다. 이번 글은 고려대 강필성 교수님, 한양대 이상화 교수님 강의와 [quora](https://www.quora.com/What-is-an-intuitive-explanation-of-the-relation-between-PCA-and-SVD), 또 [다크프로그래머의 블로그](http://darkpgmr.tistory.com/106)를 참고했음을 미리 밝힙니다. 그럼 시작하겠습니다.  ## 주성분 분석 PCA는 데이터의 **분산(variance)**을 최대한 보존하면서 서로 직교하는 새 기저(축)를 찾아, 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간으로 변환하는 기법입니다. 이를 그림으로 나타내면 아래와 같습니다. 3차원 공간에 있는 데이터들이 서로 수직인 두 개의 주성분(PC1, PC2)을 새로운 기저로, 선형변환된 것을 확인할 수 있습니다. PCA 관련 자세한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/04/24/PCA/)을 참고하시기 바랍니다.  <a href="http://imgur.com/jWJ2nUs"><img src="http://i.imgur.com/jWJ2nUs.png" width="600px" title="source: imgur.com" /></a>  원 데이터의 분산을 최대화하는 새로운 기저를 찾는 목표를 달성하려면 우선 데이터 행렬 $A$의 공분산 행렬부터 구해야 합니다. 데이터가 각 변수별로 평균이 0으로 맞춰져 있을 때(centering 작업 이미 수행되어 있다고 가정) 공분산 행렬은 아래와 같이 구합니다.  $$cov(A)=\frac { 1 }{ n-1 } { A }^{ T }A\propto { A }^{ T }A$$  PCA의 새로운 축을 찾기 위해서는 위 공분산행렬을 아래처럼 **고유분해(Eigen decomposition)**를 수행해주어야 합니다. 아래 식에서 $Λ$는 대각성분이 공분산행렬의 고유값이고 나머지 요소는 0인 행렬, $V$는 열벡터가 공분산행렬 $A^TA$의 고유벡터로 이뤄진 행렬입니다.   $${ A }^{ T }A=V\Lambda { V }^{T }$$  여기에서 $Λ$의 대각성분은 데이터 행렬 $A$의 각 변수에 해당하는 분산을 의미합니다. 원 데이터의 분산을 최대화하는 새로운 기저를 찾는 것이 PCA 목표인 만큼 가장 큰 고유값 몇 개를 고르고, 그에 해당하는 고유벡터를 새로운 기저로 하여 원데이터를 사영(선형변환)해주면 PCA 작업이 완료되게 됩니다.  예컨대 변수가 100개(100차원)인 데이터에 PCA를 적용한 후 가장 큰 고유값 두 개에 해당하는 고유벡터로 원 데이터를 사영시키면 원데이터의 분산을 최대한 보존하면서도 그 차원수를 100차원에서 2차원으로 줄일 수 있게 됩니다.    ## 특이값 분해 특이값분해는 m x n 크기의 데이터 행렬 $A$를 아래와 같이 분해하는 걸 말합니다.   $$A=U\Sigma { V }^{ T }\\ $$ <a href="http://imgur.com/lP44bGq"><img src="http://i.imgur.com/lP44bGq.png" width="600px" title="source: imgur.com" /></a> 행렬 $U$와 $V$에 속한 열벡터는 **특이벡터(singular vector)**로 불리고요, 모든 특이벡터는 서로 직교하는 성질을 지닙니다.  $$U=\begin{bmatrix} \overrightarrow { { u }_{ 1 } } & \overrightarrow { { u }_{ 2 } } & ... & \overrightarrow { { u }_{ m } } \end{bmatrix}\\ V=\begin{bmatrix} \overrightarrow { { v }_{ 1 } } & \overrightarrow { v_{ 2 } } & ... & \overrightarrow { { v }_{ n } } \end{bmatrix}\\ \overrightarrow { { u }_{ k } } =\begin{bmatrix} { u }_{ k1 } \\ { u }_{ k2 } \\ ... \\ { u }_{ km } \end{bmatrix}\quad \overrightarrow { { v }_{ k } } =\begin{bmatrix} { v }_{ k1 } \\ v_{ k2 } \\ ... \\ { v }_{ kn } \end{bmatrix}\\ { \overrightarrow { { u }_{ k } } }^{ T }\overrightarrow { { u }_{ k } } =1,\quad { U }^{ T }U=I\\ { \overrightarrow { { v }_{ k } } }^{ T }\overrightarrow { { v }_{ k } } =1,\quad { V }^{ T }V=I$$  행렬 $Σ$의 특이값은 모두 0보다 크거나 같으며 내림차순으로 정렬돼 있습니다. 행렬 $Σ$의 $k$번째 대각원소에 해당하는 $Σ_k$는 행렬 $A$의 $k$번째 고유값에 제곱근을 취한 값과 같습니다.  $${ \Sigma }_{ k }=\sqrt { { \lambda }_{ k } } $$  그러면 특이값 분해를 주성분 분석과 비교해보기 위해 행렬 $A$를 제곱해 보겠습니다. 이후 식을 정리하면 아래와 같습니다.  $$ \begin{align*} { A }^{ T }A&={ (U\Sigma { V }^{ T }) }^{ T }U\Sigma { V }^{ T }\\ &=V\Sigma { U }^{ T }U\Sigma { V }^{ T }\\ &=V{ \Sigma }^{ 2 }{ V }^{ T }\\ &=V\Lambda { V }^{ T } \end{align*} $$  여기서 대각성분이 행렬 $A$의 특이값이고 나머지 성분이 0인 행렬 $Σ$에 주의할 필요가 있습니다. $Σ$는 **대각행렬(diagonal matrix)**인데요, 대각행렬의 거듭제곱은 대각원소들만 거듭제곱을 해준 결과와 같습니다.  따라서 $Σ$의 제곱은 각 대각원소, 즉 행렬 $A$의 특이값들을 제곱해준 값과 똑같습니다. 그런데 행렬 $A$의 특이값은 같은 행렬의 고유값에 제곱근을 취한 값과 동일하므로, $Σ$을 제곱한 행렬은 행렬 $A^TA$의 고유값으로 이뤄진 행렬 $Λ$가 됩니다. 이는 정확히 주성분 분석의 결과와 같습니다.   ## 특이값 분해의 여러 변형들 ### thin SVD <a href="http://imgur.com/NU5w7Uy"><img src="http://i.imgur.com/NU5w7Uy.png" width="400px" title="source: imgur.com" /></a> **thin SVD**는 $Σ$ 행렬의 아랫부분(비대각 파트, 모두 0)과 $U$에서 여기에 해당하는 부분을 모두 제거합니다. 이렇게 $U$와 $Σ$를 줄여도 $U_sΣ_sV^T$로 $A$를 원복할 수 있습니다.  ### compact SVD <a href="http://imgur.com/2AXD5Fw"><img src="http://i.imgur.com/2AXD5Fw.png" width="400px" title="source: imgur.com" /></a> **compact SVD**는 $Σ$ 행렬에서 비대각파트뿐 아니라 대각원소(특이값)가 0인 부분도 모두 제거한 형태입니다. 여기에 대응하는 $U$와 $V$의 요소 또한 제거합니다. 다시 말해 특이값이 양수인 부분만 골라낸다는 뜻입니다. 이렇게 $U$와 $Σ$, $V$를 줄여도 $U_rΣ_rV_r^T$로 $A$를 원복할 수 있습니다.  ### truncated SVD <a href="http://imgur.com/CHLt0DM"><img src="http://i.imgur.com/CHLt0DM.png" width="400px" title="source: imgur.com" /></a> **truncated SVD**는 $Σ$ 행렬의 대각원소(특이값) 가운데 상위 $t$개만 골라낸 형태입니다. 이렇게 하면 행렬 $A$를 원복할 수 없게 되지만, 데이터 정보를 상당히 압축했음에도 행렬 $A$를 근사할 수 있게 됩니다. 이후 설명드릴 잠재의미분석은 바로 이 방법을 사용합니다.  ### SVD 예시 $$ A=U\Sigma { V }^{ T } \\ \\ \begin{bmatrix} 2 & 3 \\ 1 & 4 \\ 0 & 0 \\ 0 & 0 \end{bmatrix}=\begin{bmatrix} 0.82 & -0.58 & 0 & 0 \\ 0.58 & 0.82 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix}\begin{bmatrix} 5.47 & 0 & 0 & 0 \\ 0 & 0.37 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{bmatrix}\begin{bmatrix} 0.40 & 0.91 \\ -0.91 & 0.40 \end{bmatrix} $$  ### truncated SVD 예시 $$ \begin{align*} { A }^{ ' }&={ U }_{ 1 }{ \Sigma }_{ 1 }{ V }_{ 1 }^{ T }\\ \\ \begin{bmatrix} 1.79 & 4.08 \\ 1.27 & 2.89 \\ 0 & 0 \\ 0 & 0 \end{bmatrix}&=\begin{bmatrix} 0.82 \\ 0.58 \\ 0 \\ 0 \end{bmatrix}\begin{bmatrix} 5.47 \end{bmatrix}\begin{bmatrix} 0.40 & 0.91 \end{bmatrix} \end{align*} $$   ## 잠재의미분석 개요 예컨대 다음과 같은 문서들이 있다고 하면, 우리는 이를 토대로 단어-문서행렬 $A$를 만들 수 있습니다. > **doc1** : 나,는,학교,에,가,ㄴ,다 > > **doc2** : 학교,에,가,는,영희 > > **doc3** : 나,는,영희,는,좋,다 | -  | doc1 | doc2 | doc3 | | :--: | :--: | :--: | :--: | | 나  | 1  | 0  | 0  | | 는  | 1  | 1  | 2  | | 학교 | 1  | 1  | 0  | | 에  | 1  | 1  | 0  | | 가  | 1  | 1  | 0  | | ㄴ  | 1  | 0  | 0  | | 다  | 1  | 0  | 1  | | 영희 | 0  | 1  | 1  | | 좋  | 0  | 0  | 1  | 잠재의미분석이란 위와 같은 **단어-문서행렬(Word-Document Matrix)**, **단어-문맥행렬(window based co-occurrence matrix)** 등 입력 데이터에 특이값 분해를 수행해 데이터의 차원수를 줄여 계산 효율성을 키우는 한편 행간에 숨어있는(latent) 의미를 이끌어내기 위한 방법론입니다. 대략적인 개념은 아래 그림과 같습니다. <a href="http://imgur.com/NLORntm"><img src="http://i.imgur.com/NLORntm.png" width="600px" title="source: imgur.com" /></a> 잠재의미분석을 수행하는 절차는 이렇습니다. $n$개의 문서를 $m$개의 단어로 표현된 입력데이터 행렬 $A$가 주어졌다고 칩시다. $A$의 0보다 큰 고유값의 개수를 $r$이라고 할 때, $r$보다 작은 $k$를 연구자가 임의로 설정하고 $Σ_k$를 만듭니다. 이후 $U$와 $V$ 행렬에서 여기에 대응하는 부분만 남겨 $U_k$와 $V_k$를 만들어줍니다. 이렇게 되면 $A$와 비슷한 $A_k$ 행렬을 구축할 수 있습니다.  $${ A }_{ k }={ U }_{ k }{ \Sigma }_{ k }{ V }_{ k }^{ T }$$  위 식 양변에 $U_k$의 전치행렬을 곱해준 것을 $X_1$, $V_k$를 곱해준 것을 $X_2$라고 둡니다. 그러면 $X_1$의 경우 $n$개의 문서는 원래 단어수 $m$보다 훨씬 작은 $k$개 변수로 표현된 결과가 됩니다. $X_2$는 $m$개의 단어가 원래 문서 수 $n$보다 작은 $k$개 변수로 표현한 결과입니다. 이는 주성분 분석에서의 차원축소 효과와 비슷한 것으로 이해하면 좋을 것 같습니다.   $${ { U }_{ k }^{ T }A }_{ k }={ { U }_{ k }^{ T }U }_{ k }{ \Sigma }_{ k }{ V }_{ k }^{ T }=I{ \Sigma }_{ k }{ V }_{ k }^{ T }={ \Sigma }_{ k }{ V }_{ k }^{ T }={ X }_{ 1 }\\ { A }_{ k }{ V }_{ k }={ U }_{ k }{ \Sigma }_{ k }{ V }_{ k }^{ T }{ V }_{ k }={ U }_{ k }{ \Sigma }_{ k }^{ T }I={ U }_{ k }{ V }_{ k }^{ T }={ X }_{ 2 }$$   ## 잠재의미분석 예시 자, 그럼 위에서 예로 든 단어-문서행렬 $A$를 가지고 잠재의미분석을 수행해 보겠습니다. $A$에 SVD를 수행하면 아래와 같이 쓸 수 있습니다. 숫자들이 엄청 많은데요, '아 이렇게 분해될 수 있구나' 정도로 보고 슥 넘어가시면 될 것 같습니다. $$A=U\Sigma { V }^{ T }\\ \\ \begin{bmatrix} 1 & 0 & 0 \\ 1 & 1 & 2 \\ 1 & 1 & 0 \\ 1 & 1 & 0 \\ 1 & 1 & 0 \\ 1 & 0 & 0 \\ 1 & 0 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{bmatrix}=\begin{bmatrix} -0.17 & 0.27 & -0.40 \\ -0.63 & -0.41 & -0.03 \\ -0.32 & 0.37 & 0.21 \\ -0.32 & 0.37 & 0.21 \\ -0.32 & 0.37 & 0.21 \\ -0.17 & 0.27 & -0.40 \\ -0.33 & -0.12 & -0.52 \\ -0.30 & -0.29 & 0.49 \\ -0.15 & -0.39 & -0.13 \end{bmatrix}\begin{bmatrix} 3.61 & 0 & 0 \\ 0 & 2.04 & 0 \\ 0 & 0 & 1.34 \end{bmatrix}\begin{bmatrix} -0.63 & -0.53 & -0.57 \\ 0.56 & 0.20 & -0.80 \\ -0.54 & 0.83 & -0.17 \end{bmatrix}$$  그럼 $Σ$ 행렬의 특이값 가운데 상위 2개(3.61과 2.04)만 남기고 나머지를 제거하는 방식으로 truncated SVD를 수행해 보겠습니다. 아래와 같습니다. $${ A }^{ ' }={ U }_{ 2 }{ \Sigma }_{ 2 }{ V }_{ 2 }^{ T }\\ \begin{bmatrix} 0.71 & 0.44 & -0.09 \\ 0.97 & 1.04 & 1.99 \\ 1.15 & 0.76 & 0.04 \\ 1.15 & 0.76 & 0.04 \\ 1.15 & 0.76 & 0.04 \\ 0.71 & 0.45 & -0.09 \\ 0.62 & 0.58 & 0.88 \\ 0.36 & 0.45 & 1.11 \\ -0.09 & 0.14 & 0.97 \end{bmatrix}=\begin{bmatrix} -0.17 & 0.27 \\ -0.63 & -0.41 \\ -0.32 & 0.37 \\ -0.32 & 0.37 \\ -0.32 & 0.37 \\ -0.17 & 0.27 \\ -0.33 & -0.12 \\ -0.30 & -0.29 \\ -0.15 & -0.39 \end{bmatrix}\begin{bmatrix} 3.61 & 0 \\ 0 & 2.04 \end{bmatrix}\begin{bmatrix} -0.63 & -0.53 & -0.57 \\ 0.56 & 0.20 & -0.80 \end{bmatrix}$$  솔직히 이렇게 봐서는 $A'$가 원데이터 행렬 $A$에 제대로 근사한 것인지 아리송합니다. $A'$의 각 요소값을 반올림해서 원 행렬 $A$와 비교해보겠습니다. 6행과 7행의 요소값이 조금 다를 뿐 거의 유사한 것을 확인할 수 있습니다.  $$round({ A }^{ ' })=\begin{bmatrix} 1 & 0 & 0 \\ 1 & 1 & 2 \\ 1 & 1 & 0 \\ 1 & 1 & 0 \\ 1 & 1 & 0 \\ 1 & 0 & 0 \\ 1 & 1 & 1 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \end{bmatrix},\quad A=\begin{bmatrix} 1 & 0 & 0 \\ 1 & 1 & 2 \\ 1 & 1 & 0 \\ 1 & 1 & 0 \\ 1 & 1 & 0 \\ 1 & 0 & 0 \\ 1 & 0 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{bmatrix}$$  그럼 $A'=U_2Σ_2V^T_2$ 양변의 맨 앞에 $U_2$의 전치행렬을 각각 곱해줄까요? 그 결과를 $X_1$이라고 두면 아래와 같습니다.  $$X_{1}=\begin{bmatrix} -2.28 & -1.90 & -2.07 \\ 1.14 & 0.42 & -1.64 \end{bmatrix}$$  원데이터인 $A$와 SVD 결과인 $X_1$의 열(column)은 문서(문장)를 의미합니다. 단어-문맥행렬 $A$에서 각 문서들은 9개 단어(변수)들로 표현됐으나 $X_1$에서는 단 두 개의 변수들만으로도 표현이 가능해졌습니다. 이렇게 만든 $X_1$에 다양한 데이터마이닝 기법을 적용해 여러 가지 문제를 풀게 되는 것입니다. 자, 이제는 반대로 $A'=U_2Σ_2V^T_2$ 양변의 맨 뒤에 $V_2$를 각각 곱해볼까요? 그 결과를 $X_2$라고 두면 다음과 같습니다.  $${ X }_{ 2 }=\begin{bmatrix} -0.63 & 0.56 \\ -2.30 & -0.84 \\ -1.16 & 0.76 \\ -1.16 & 0.76 \\ -1.16 & 0.76 \\ -0.63 & 0.56 \\ -1.20 & -0.24 \\ -1.10 & -0.60 \\ -0.57 & -0.80 \end{bmatrix}$$  원데이터인 $A$와 SVD 결과인 $X_2$의 행(row)은 단어를 의미합니다. 단어-문맥행렬 $A$에서 각 단어들은 3개 문서(변수)들로 표현됐으나 $X_2$에서는 단 두 개의 변수들만으로도 표현이 가능해졌습니다. 이렇게 만든 $X_2$에 마찬가지로 다양한 데이터마이닝 기법을 적용해 여러 가지 문제를 풀게 됩니다.  ## 잠재의미분석의 효과 이제까지 든 예시에서는 차원축소의 효과가 도드라져 보이진 않지만 데이터가 클 경우 그 효과가 드라마틱하다고 합니다. 실제로 네이버, 카카오 등 현업에서도 이러한 방법론을 많이 쓰고 있는 것으로 알려져 있습니다. 잠재의미분석은 이외에도 많은 장점이 있다고 합니다. Deerwester et ak.(1990)과 Landauer and Dumais(1997)은 이 기법을 적용하면 단어와 문맥 간의 내재적인 의미(latent/hidden meaning)을 효과적으로 보존할 수 있게 돼 결과적으로 문서 간 유사도 측정 등 모델의 성능 향상에 도움을 줄 수 있다고 합니다. Rapp(2003)은 입력 데이터의 노이즈 제거, Vozalis and Margaritis(2003)은 입력데이터의 **sparsity**를 줄이게 돼 그 효과가 좋다고 합니다. 잠재의미분석은 입력데이터의 크기가 m x n이고 문서당 평균 단어수가 $c$일 경우 계산복잡도가 $O(mnc)$이어서 그다지 무거운 알고리즘은 아닙니다. 하지만 새로운 문서나 단어가 추가되면 아예 처음부터 작업을 새로 시작해야 합니다. 이 때문에 최근에는 Word2Vec 등 뉴럴네트워크 기반의 representation 방법론도 각광을 받고 있습니다. 
ends␞ 이번 글에서는 한국어의 문장유형과 종결어미에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 화행 발화행위(speech act, 화행)란 말을 통해 이루어지는 행위를 가리킵니다. 우리가 말을 할 때에는 단순히 말하기라는 행위만을 하는 것이 아니라 말로써 그 이상의 여러 다양한 행위를 하는데, 이러한 행위를 가리켜 화행이라고 합니다. 예문을 보겠습니다. > (강도가) 나에게 총이 있다 : 협박 > > (친구에게) 음식에 거미가 있어 : 경고 > > (부하직원에게) 어린애도 이거보단 잘 쓰겠다 : 모욕 > > (옆 사람에게) 지금 몇 시인지 아세요? : 요청   ## 문장유형 문장유형은 화행 중 특별히 자주 쓰이고 긴요해 그 구별이 문법적 장치를 통해 나타난 것을 말합니다. 가령 진술, 질문 등의 화행이 관습적으로 각기 특정한 문법적 형식에 의해 표시된다면 그러한 문장은 일정한 문장 유형에 속한다고 할 수 있습니다. 학교문법에서는 평서문, 의문문, 명령문, 청유문, 감탄문 다섯가지 문장 유형을 제시하고 있습니다. 어디까지 문장유형으로 설정할지는 학자마다 견해가 다를 수 있습니다. 이 때문에 문장유형을 인정하는 데에는 일정한 기준이 필요합니다. 두 가지를 들 수 있겠습니다. 첫번째는 간접인용절을 만들어서 확인해보는 것입니다. 한국어 간접인용절은 상대높임이나 화자의 태도 등이 삭제되고 순수하게 문장유형이 나타나기 때문에 좋은 방법입니다. 예문을 보겠습니다. > (1) 꽃이 예쁘네요. > > (2) 내 친구가 꽃이 예쁘다고 말했다. (1)에서 '네'는 화자의 태도(놀람), '요'는 상대높임을 표시하고 있습니다. (1)을 간접인용절로 바꾼 (2)에서는 이 모두 사라지고 '꽃이 예쁘다'라고만 실현이 됐습니다. 이러한 경우라면 평서문을 문장유형의 하나로 인정할 수 있는 근거가 될 것입니다. 두번째 기준은 상태높임법의 용례를 살피는 것입니다. 한국어 상대높임에는 높임, 중간, 안높임의 세 화계가 있는데, 세 화계에 두루 나타나는 유형을 문장유형으로 삼아보자는 취지입니다. 이같은 두 가지 기준에 따라 한국어 문장유형을 꼽아보면 다음 표와 같습니다. | 구분 | 간접인용 구성 | 높임 등급 |   중간 등급   | 안높임 등급 | | :--: | :-----: | :---: | :-----------: | :----: | | 평서문 |  -다고  | -습니다 |  -소/으오, -네  |  -다  | | 의문문 |  -냐고  | -습니까 | -소/으오, -나/-은가 |  -냐  | | 명령문 |  -라고  | -십시오 |  -소/으오, -게  |  -라  | | 청유문 |  -자고  | -십시다 |  -읍시다, -세  |  -자  | 이 두 기준에 따르면 감탄문은 별도의 문장유형으로 인정할 수 없습니다. 예문을 보겠습니다. > 간접인용 구성 : 꽃이 핀다고 했다. > > 높임 등급 : ? > > 중간 등급 : 꽃이 피는구려. > > 안높임 등급 : 꽃이 피는구나. '꽃이 피는구나'를 간접인용 구성으로 만들면 '꽃이 핀다'가 되어 평서문과 구별할 수 없게 됩니다. 상대높임 가운데 높임 등급에 해당하는 어미가 존재하지 않습니다. 이 때문에 감탄문은 평서문의 하위 유형으로 분류하는 것이 더 적절할 듯합니다.   ## 종결어미 종결어미는 다음과 같은 속성을 지니는 문법부류입니다. - 문장의 맽 끝에 붙음 - 상대높임법을 표시 - 평서문, 의문문, 명령문, 청유문과 같은 문장의 유형을 결정 - 화자의 심리적 태도를 나타냄   ## 평서문 평서문은 화자가 청자에게 어떠한 생각이나 감정을 진술하여 단순히 전달하고자 하는 문장 종결법이 나타난 문장유형을 가리킵니다. 평서문에는 좁은 의미의 평서문 외에 감탄문, 경계문, 약속문이 포함됩니다. 이미 언급했듯이 이들은 간접인용절에서 평서문 어미 '-다'로 합류될 수 있다는 특징을 보이기 때문입니다. 다음 예문과 같습니다. > 좁은 의미의 평서문 : 날씨가 추웠다 > 그는 날씨가 춥다고 말했다. > > 감탄문 : 꽃이 예쁘구나 > 그는 꽃이 예쁘다고 말했다. > > 경계문 : 그 길로 가다가 불량배를 만날라 > 그는 내가 그 길로 가다가 불량배를 만나겠다고 말했다. > > 약속문 : 다시는 오지 않으마. > 그는 다시는 오지 않겠다고 말했다. 감탄문은 이미 언급했으므로 경계문과 약속문을 따로 보겠습니다. 경계문은 흔히 명령의 하위 부류로 간주되나, 과거시제, '이다'와 결합할 수 있고, '말다' 부정과 결합하지 않으므로 평서문의 일종으로 보는 것이 합당하다고 합니다. 다음 예문과 같습니다. > 과거시제와 결합 : 벌써 도착했**을라**. > > '이다'와 결합 : 잘 봐라. 가짜**일라**. 약속을 나타내는 어미로는 ‘-마, -ㄹ게, -ㅁ세, -리다’가 있습니다. 하지만 이들 어미는 약속 이외에 기능에도 널리 쓰이므로 약속문이라는 독자적인 문장유형을 세우기 어렵다는 특징 때문에 평서문의 하위 유형으로 분류됩니다.    ### 평서문 어미 평서문 어미의 종류는 다음과 같습니다. | 상대높임의 종류 | 종결어미                   | | :------: | :--------------------------------------- | |  해라체  | -다, -마, -구나, -ㄹ라             | |  해체  | -거든, -군, -구먼, -다니, **-네**, -데, -어, -지, -ㄹ게 | |  하게체  | -ㄹ세, -ㅁ세, **-네**             | |  하오체  | -오, -구려, -리다               | | 하십시오체  | -습니다                   | 위 표에서 '-네'는 해체와 하게체 모두 속해 있습니다. 형태는 같지만 다른 어미로 보는 것이 적절할 듯 합니다. 예문을 보겠습니다. > 해체 : 너, 정말 예쁘**네**. > > 하게체 : 자네, 조금만 기다리게. 곧 가겠**네**. 위 표에서 '-군, -구나, -구먼, -구려, -어라, -다니'는 감탄문 어미입니다. 감탄문을 평서문의 하위 유형으로 분류했기 때문에 위 표에도 감탄문 어미가 포함됐습니다. '-어라'의 경우 명령문 어미로도 쓰이는데 이 또한 형태는 같지만 다른 어미로 보는 것이 적절할 듯합니다. 국어사적 연구에 따르면 감탄의 '-어라'와 명령의 '-어라'는 그 기원이 다르다고 합니다. 한편 위 표에서 '-ㄹ라'는 경계문 어미, ‘-마, -ㄹ게, -ㅁ세, -리다’는 약속문 어미입니다.   ## -거든, -지 '-거든'과 '-지'는 화자가 이미 알고 있거나 당연한 지식임을 표시한다는 공통점이 있습니다. 이 가운데 '-거든'은 화자는 알고 있지만 청자가 잘 모르는 지식임을 함의합니다. > 세종대왕이 한글을 만드셨거든. (세종대왕이 한글을 만드신 사실을 화자는 알고 있지만 청자는 잘 모를 거라고 전제하고 진술한 문장) 반면 '-지'는 관련 명제가 청자의 이견이 기대되지 않는 것(동의할 것)임을 함의합니다. 즉 청자가 그 사실을 알고 있다고 화자가 전제하는 경우(기지 가정)에 쓰입니다. > 냉장고에 있던 아이스크림 네가 먹었지? (냉장고에 있는 아이스크림을 청자가 먹었으리라고 화자와 청자가 모두 전제한 상태에서 자연스러움) '-지'는 명령문이나 청유문에서는 부드럽게 권유하는 뜻이 담깁니다. > 힘들 텐데 그만 좀 쉬지. > > 우리랑 같이 가지. 다만 '-지'는 '-잖-'보다는 기지 가정의 의미가 약한 편입니다. 아래 예문에서는 '화자가 어제 병원에 간 사실을 청자도 알고 있을 것'이라는 전제가 (2)에서 두드러집니다. > (1) 내가 어젠 아파서 병원에 갔지. > > (2) 내가 어젠 아파서 병원에 갔잖아.   ## -네, -구나 '-네'와 '-구나'는 화자가 새로 알게 된 지식임을 표시합니다. '-네'는 발화 시점에서 지각이나 근거가 분명한 추론을 통해 알게 된 명제를 표시합니다. '-구나'는 인식 시점에 구애받지 않고 지각이나 추론, 전문(들어서 알게 된 사실)을 통해 알게 된 명제를 표시합니다. > 지각 : 비가 {오네/비가 오는구나}. > > 근거가 분명한 추론 : (철수가 공부하고 있던 방에 들어가서 철수와 그의 소지품이 사라진 것을 보고) 철수 {갔네/갔구나}! > > 근거가 분명하지 않은 추론 : (가) 어제 철수 씨가 계속 전화했어요. (나) 급한 일이 {*있었네/있었구나}. > > 전문 : (가) 합격자 명단 보니까 철수도 있더라. (나) 철수도 {*합격했네/합격했구나}. 
maxflow␞ 이번 글에서는 **최대 유량 알고리즘(Max Flow Algorithm)**을 *edge cut*으로 수행하는 기법을 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concept 최대 유량 알고리즘이란 가중치가 있는 방향그래프(directed graph) $G$와 시작(source) 노드 $s$, 도착(sink) 노드 $t$가 주어졌을 때 각 엣지의 용량(capacity)을 고려하여 $s$에서 $t$로 흘려보낼 수 있는 최대 유량(flow)을 구하는 알고리즘을 가리킵니다. 최대 유량을 *edge cut*으로 수행하는 기법에서 `용량(capacity)`, `유량(flow)` 등 기본적인 용어와 *flow conservation* 등 제약요건은 [포드-풀커슨 알고리즘](https://ratsgo.github.io/data%20structure&algorithm/2017/11/29/maxflow/)과 동일합니다. 추가된 내용은 다음과 같습니다. 우선 *reverse edge*가 존재하지 않는다고 둡니다. 예컨대 노드 $u$에서 $v$로 향하는 엣지가 있다면 $v$에서 $u$로 향하는 반대 엣지는 그래프에 없어야 합니다.  유량값(*value of flow*) $f$(혹은 \|$f$\|)는 다음과 같이 정의됩니다. - 시작 노드 $s$에서 나가는 유량 - 시작 노드 $s$로 들어오는 유량 아래 그래프에서 $f$는 나가는 유량(3)만 있으므로 3이 됩니다.  <a href="https://imgur.com/XyETWDV"><img src="https://i.imgur.com/XyETWDV.png" width="300px" title="source: imgur.com" /></a>  위 그래프에 *edge cut*을 수행해 두 개 부분그래프로 쪼개 보겠습니다. $s$가 속한 부분그래프를 $S$, $t$가 속한 부분그래프를 $T$라고 둡니다. 이 때 $S$와 $T$ 사이의 순 유량(*net flow*) $f$와 용량 $C$는 각각 다음과 같이 정의됩니다.  $$ \begin{align*} f\left( S,T \right) &=\sum _{ u\in S }^{ }{ \sum _{ v\in T }^{ }{ f\left( u,v \right) } } -\sum _{ u\in S }^{ }{ \sum _{ v\in T }^{ }{ f(v,u) } } \\ c\left( S,T \right) &=\sum _{ u\in S }^{ }{ \sum _{ v\in T }^{ }{ c\left( u,v \right) } } \end{align*} $$  예를 들어보겠습니다. 아래 그래프를 빨간색 선을 따라 *edge cut*을 수행했다고 칩시다. $f(S,T)$는 $S$에서 $T$로 가는 유량을 $T$에서 $S$로 가는 유량을 빼서 구하므로 4-1=3이 됩니다. $c(S,T)$는 $S$에서 $T$로 가는 용량만을 따지므로 2+3=5가 됩니다.  <a href="https://imgur.com/qEJ6TXX"><img src="https://i.imgur.com/qEJ6TXX.png" width="300px" title="source: imgur.com" /></a>  이번엔 파란색 선을 따라 *edge cut*을 수행했다고 칩시다. $f(S,T)=4-1=3$입니다. $c(S,T)=3+3=6$입니다.    ## 정리 및 증명 *edge cut*으로 최대 유량을 구하는 데 있어 두 가지 중요한 정리가 있습니다. 첫번째는 **어떻게 *cut*을 하더라도 유량값($f$)은 동일하다**라는 사실입니다. (*fot any cut ($S,T$)*, $f(S,T)=$\|$f$\|) 위 그림 예제로 설명해 보자면 빨간색 선을 따라 *cut*을 하든, 파란색 선을 따라 *cut*을 하든 $f$는 3으로 같습니다. 이는 다른 선을 따라 *cut*을 해도 마찬가지입니다.증명은 다음과 같습니다.  <a href="https://imgur.com/Kngoht1"><img src="https://i.imgur.com/Kngoht1.png" width="650px" title="source: imgur.com" /></a>  두번째 중요한 정리는 **$S$와 $T$를 어떻게 자르든 $S,T$ 사이의 유량은 용량보다 작다**는 것입니다. (*The value of any flow)≤capacity of any cut*)  <a href="https://imgur.com/Bci4RU8"><img src="https://i.imgur.com/Bci4RU8.png" width="450px" title="source: imgur.com" /></a>    ## algorithm 이같은 사실을 활용해 우리는 모든 가능한 경우에 대해 *edge cut*을 수행한 뒤 그 가운데 가장 작은 용량(capacity)을 선택하면 그것이 전체 그래프의 최대 유량이 됨을 알 수 있습니다. 위 그림 예제로 설명해보자면, 빨간색 선으로 잘라보고, 파란색 선으로 잘라보고, 다른 모든 가능한 경우의 수에 대해 잘라봐서 $c(S,T)$ 값을 각각 구하고, 이 가운데 가장 적은 값을 최대 유량으로 반환하는 겁니다. 한편 만일 최소 비용으로 그래프의 최대 유량을 높이고 싶다면 가장 적은 $c(S,T)$에 대응하는 엣지들의 용량을 높여주면 됩니다.
comparison␞ 이번 글에서는 다양한 머신러닝 모델을 서로 비교해 보면서 각 모델의 특징을 살펴보도록 하겠습니다. 이번 글은 [An Introduction to Stastical Learning](http://www-bcf.usc.edu/~gareth/ISL/)을 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 선형회귀 vs K-NN 선형회귀는 **모수적 기법(parametric method)**입니다. 1차 선형식 모델을 가정하기 때문이죠. 명시적인 함수 형태의 모델을 가정하지 않는 비모수적 기법(non-parametric method)도 있습니다. 대표적인 것이 K-nearest Neighbors Regression 기법(K-NN)이 있습니다. 특정 데이터 포인트($x_0$)의 주변 $K$ 이웃의 $y$값 평균으로 회귀 문제를 풉니다. 선형회귀와 관련 자세한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/07/03/regression/)을, K-NN과 관련 자세한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/04/17/KNN/)을 참고하시면 좋을 것 같습니다. 데이터의 분포 양상과 모수적 모델이 가정하는 모양이 일치할 경우, 모수적 기법의 성능은 비모수적 모델보다 좋은 경향이 있다고 합니다. 아래 그림을 보겠습니다.   <a href="https://imgur.com/I2hVsTK"><img src="https://i.imgur.com/I2hVsTK.png" width="500px" title="source: imgur.com" /></a>  위 그림 왼쪽의 검정색 실선은 $x$와 $y$의 실제 관계를 나타냅니다. 그 관계가 선형(linear)임을 확인할 수 있습니다. 오른쪽 그림에서 검정색 점선은 선형회귀 모델, 녹색 실선은 K-NN의 오차를 나타냅니다. $x$와 $y$가 선형관계를 이루고 있어서, 선형관계를 가정하고 구축된 선형회귀 모델의 오차가 K-NN의 오차보다 작은 것을 확인할 수 있습니다. 하지만 데이터의 분포 양상과 모수적 모델이 가정하는 모양이 불일치할 경우, 비모수적 모델의 성능이 좋을 수 있습니다. 이와 관련해 다음 그림을 보겠습니다.  <a href="https://imgur.com/Zn4lVAX"><img src="https://i.imgur.com/Zn4lVAX.png" width="500px" title="source: imgur.com" /></a>  위 그림 왼쪽의 검정색 실선은 $x$와 $y$의 실제 관계를 나타냅니다. 비선형(non linear)임을 확인할 수 있습니다. 파란색 선은 $K$가 1일 때 K-NN의 예측곡선, 빨간색 선은 $K$가 9일 때 예측곡선을 가리킵니다. $K$가 클 수록 더 많은 이웃데이터를 고려해 예측하므로 곡선의 모양이 평탄화(smoothing)되는 걸 확인할 수 있습니다. 오른쪽 그림에서 검정색 점선은 선형회귀 모델, 녹색 실선은 K-NN의 오차를 나타냅니다. $x$와 $y$가 비선형 관계여서, 선형관계를 가정하고 구축된 선형회귀 모델의 오차가 K-NN보다 큰 것을 확인할 수 있습니다. 실제 분석에서는 K-NN보다는 선형회귀가 자주 쓰입니다. K-NN에서는 데이터의 차원 수가 커질 수록, 즉 변수가 많아질 수록 **차원의 저주(curse of dimensionality)** 현상이 나타나기 때문입니다. K-NN은 예측시 $K$개 이웃을 고려하는데, 고차원 데이터 공간에서는 특정 데이터 포인트에서 가장 가까운 이웃이라 하더라도 실제로는 그 거리가 매우 먼 경우가 많다고 합니다. 이 때문에 변수의 숫자($p$)가 커질 수록 K-NN의 오차가 커지는 경향이 있습니다. 다음 그림과 같습니다.  <a href="https://imgur.com/advxren"><img src="https://i.imgur.com/advxren.png" width="500px" title="source: imgur.com" /></a>    ## LDA vs 로지스틱 회귀 범주 2개를 분류하는 선형판별분석(LDA)에서 데이터 $x$가 범주1일 확률을 $p_1(x)$, 범주2일 확률을 $p_2(x)$라고 두면 다변량 정규분포 확률함수로부터 다음과 같은 식을 유도할 수 있습니다. (LDA에서는 데이터가 정규분포를 따른다고 가정) LDA와 다음 식 유도와 관련해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/03/21/LDA/)을 참고하시면 좋을 것 같습니다.  $$ \log { \left( \frac { { p }_{ 1 }\left( x \right) }{ 1-{ p }_{ 1 }\left( x \right) } \right) } =\log { \left( \frac { { p }_{ 1 }\left( x \right) }{ { p }_{ 2 }\left( x \right) } \right) } ={ c }_{ 0 }+{ c }_{ 1 }x $$  위 식에서 $c_0$와 $c_1$은 다변량 정규분포 확률함수의 파라메터 $μ_1$(범주1인 데이터의 평균), $μ_2$(범주2인 데이터의 평균), $σ^2$(데이터의 분산, 등분산 가정, 범주1인 데이터의 분산=범주2인 데이터의 분산)로 계산된 고정된 스칼라값입니다. 로지스틱 회귀분석은 다음과 같이 정의됩니다. 로지스틱 회귀와 관련해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/04/02/logistic/)을 참고하시면 좋을 것 같습니다.  $$ \log { \left( \frac { { p }_{ 1 }\left( x \right) }{ 1-{ p }_{ 1 }\left( x \right) } \right) } ={ \beta }_{ 0 }+{ \beta }_{ 1 }x $$  LDA와 로지스틱 회귀 모두 $x$에 대해 1차 선형식(linear equation) 형태라는 점을 확인할 수 있습니다. LDA와 로지스틱 회귀의 결정경계(decision boundary)가 선형이라는 이야기입니다.  다른 점이 있다면 로지스틱 회귀의 $β_0$과 $β_1$은 최대우도추정(maximum likelihood estimation)에 의해 도출됐고, LDA의 $c_0$과 $c_1$은 다변량 정규분포 확률함수로부터 유도됐다는 점입니다. 이러한 성질은 $x$의 차원수가 2 이상일 때도 성립한다고 합니다. 다른 점은 또 있습니다. LDA는 각 관측치가 다변량 정규분포(등분산 가정)로부터 뽑혔다고 가정합니다. 이 때문에 이러한 가정이 들어맞는 데이터에 대해서는 로지스틱 회귀보다 성능이 좋습니다. 반대로 데이터의 분포에 대해 별다른 가정을 하지 않는 로지스틱 회귀는 데이터가 정규분포를 따르지 않을 때 LDA보다 좋은 성능을 냅니다.    ## SVM vs 로지스틱 회귀 서포트벡터머신(SVM)에서 쓰이는 힌지 로스(hinge loss)는 로지스틱 회귀와 깊은 관련을 맺고 있다고 합니다. 학습데이터의 범주가 2, 차원 수가 $p$, 개수가 $n$일 때 힌지 로스는 다음과 같이 정의됩니다.  $$ L\left( X,y,\beta \right) =\sum _{ i=1 }^{ n }{ \max { \left[ 0,1-{ y }_{ i }\left( { \beta }_{ 0 }+{ \beta }_{ 1 }{ x }_{ i1 }+...+{ \beta }_{ p }{ x }_{ ip } \right) \right] } } $$  로지스틱 회귀의 손실함수는 크로스 엔트로피입니다. 다음과 같이 정의됩니다.  $$ \begin{align*} L\left( X,y,\beta \right) =&-\sum _{ i=1 }^{ n }{ { y }_{ i }\log { \left( { \beta }_{ 0 }+{ \beta }_{ 1 }{ x }_{ 1 }+...+{ \beta }_{ p }{ x }_{ p } \right) } } \\ &-\sum _{ i=1 }^{ n }{ \left( 1-{ y }_{ i } \right) \log { \left( 1-{ \beta }_{ 0 }-{ \beta }_{ 1 }{ x }_{ 1 }-...-{ \beta }_{ p }{ x }_{ p } \right) } } \end{align*} $$  힌지 로스의 식을 살펴보면 $y_i(β_0+β_1x_{i1}+…+β_px_{ip})≥1$을 만족하는 데이터의 손실은 무시(=0)합니다. 하지만 로지스틱 회귀에서는 이를 만족하더라도 손실이 0에 가까워지기는 하지만, 완전히 0이 되지는 않습니다. 이를 나타낸 그림은 아래와 같습니다.  <a href="https://imgur.com/F7NcV08"><img src="https://i.imgur.com/F7NcV08.png" width="400px" title="source: imgur.com" /></a>  SVM과 로지스틱 회귀의 손실함수가 비슷하기 때문에 그 학습결과 또한 유사한 경향을 보인다고 합니다.   ## 결정경계 로지스틱 회귀와 LDA는 선형 결정경계를, Quadratic Disciminant Analysis(QDA)는 비선형 결정경계를 만들어냅니다. K-Nearest Neighbor Regression(K-NN)은 비모수적 방법이라 결정경계 모양에 대한 가정이 전혀 없습니다. 다음은 LDA와 QDA 결정경계 모양을 나타낸 그림입니다. <a href="https://imgur.com/Lz0ZaDK"><img src="https://i.imgur.com/Lz0ZaDK.png" width="500px" title="source: imgur.com" /></a> 다음은 K-NN의 결정경계 모양을 나타낸 그림입니다. 좌측 하단은 $K$가 1일 때, 우측 하단은 $K$가 9일 때 결정경계입니다. $K$가 커질 수록 예측시 고려하는 데이터가 많아지고 그 경계 또한 평탄화(smoothing)되는 걸 확인할 수 있습니다.  <a href="https://imgur.com/ClTLG5z"><img src="https://i.imgur.com/ClTLG5z.png" width="500px" title="source: imgur.com" /></a>  데이터의 범주가 선형 경계를 따라 분리될 수 있는 경우라면 LDA와 로지스틱 회귀의 성능이 좋습니다. 그 경계가 비선형적이라면 QDA가 좋은 성능을 낼 것입니다. 이도 저도 아니고 결정경계가 매우 복잡한 경우라면 K-NN이 좋은 선택이 될 겁니다. 하지만 K-NN의 성능은 $K$값에 상당히 민감하기 때문에 적절한 $K$값을 찾는 데 신중해야 한다고 합니다. 아래 그림은 의사결정나무(Decision Tree)의 결정경계를 나타냅니다. 의사결정나무는 한번에 하나의 설명변수를 기준으로 분기하기 때문에 축에 수직인 결정경계가 형성됩니다.  <a href="https://imgur.com/g8gtBlg"><img src="https://i.imgur.com/g8gtBlg.png" width="500px" title="source: imgur.com" /></a>  녹색과 노란색이 데이터의 실제 분포를 나타냅니다. 위 그림의 첫줄에 해당하는 데이터는 그 분포가 선형임을 확인할 수 있습니다. 이러한 데이터에는 축에 수직인 결정경계를 만들어내는 의사결정나무가 좋은 성능을 낼 수 없습니다. 반대로 두번째 줄에 해당하는 데이터는 그 분포가 의사결정나무의 결정경계와 잘 맞아서 좋은 성능을 낼 수 있습니다. 그런데 데이터가 첫줄에 해당하는 경우라도, 의사결정나무를 수백개 만들어서 그 결정경계를 실제 데이터 분포에 가깝게 만들 수도 있습니다(랜덤 포레스트). 아니면 데이터의 축을 회전하여 문제를 풀 수도 있습니다(로테이션 포레스트). 의사결정나무와 관련해 자세한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/03/26/tree/), 랜덤 포레스트와 로테이션 포레스트와 관련한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/03/17/treeensemble/)을 참고하시면 좋을 것 같습니다.     
langtype␞ 이번 포스팅에서는 한국어가 세계 언어 가운데 유형론적으로 어디에 위치해 있는가에 대해 살펴보도록 하겠습니다. 이번 글은 경희대 이선웅 교수님과 고려대 정연주 선생님 강의, 이화여대 최형용 교수님 저서를 참고로 했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 언어 유형론 **언어유형론(linguistic typology)**이란 '공유하는 형식적 특징에 근거한 언어나 언어 성분의 분류'를 뜻합니다. 쉽게 얘기하면 비슷한 언어끼리 묶어보는 거죠. 더 나아가서는 인간의 언어가 가지는 보편적인 성격을 탐구하는 학문입니다.  이와 관련해 Greenberg(1966)는 세계 언어를 연구한 뒤 "전치사를 가진 언어에서 소유격은 거의 언제나 지배 명사를 뒤따르지만 후치사를 사용하는 언어에서 소유격은 거의 언제나 지배 명사를 앞선다" 따위의 45개나 되는 보편성을 확인했다고 밝힌 바 있습니다.  Whaley(1997)에 의하면 구강 폐쇄음을 가진 언어의 38%는 6개에서 8개의 구강 폐쇄음을 가지고 있는 것으로 나타났고 14개 이상의 구강 폐쇄음을 가진 언어는 매우 희귀한 언어 유형에 속한다는 사실을 확인했습니다.  이렇듯 유형론은 언어 사이의 공통점과 차이점, 그리고 전반에 나타나는 보편성 등을 연구하는 학문입니다. <a href="http://imgur.com/Q13y5TT"><img src="http://i.imgur.com/Q13y5TT.png" width="600px" title="source: imgur.com" /></a> 위 그림은 각국 언어학자들이 분석해 만든 [언어의 세계지도(*The World Atlas of Language Structures*)](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjv4eWf5onTAhXLG5QKHSsWD8cQFggYMAA&url=http%3A%2F%2Fwals.info%2F&usg=AFQjCNG4H69UBFXWZFBCESkuBOYVSI1bdw&sig2=4_wFRom6KvxG7r1Go68BXQ&bvm=bv.151426398,d.dGo) 가운데 일부 분석 요소를 기준으로 한 지도를 캡처한 화면입니다. 보시다시피 한국어는 주변 나라들과 뚜렷한 차이가 나는 언어라고 볼 수 있겠네요.  위 그림에서도 나타나듯 지역적으로 가까운 거리에 있다고 해서 비슷한 유형의 언어일 것이라는 가정은 오해입니다. 실제로 이러한 오해 때문에 한국어는 몽골어와 함께 알타이 어족으로 20세기 초반부터 오랫동안 묶여 있었는데요. 알타이어족으로 분류하기 어렵다는 연구성과가 속속 소개된 최근에 이르러서야 한국어가 주변국과 다른 유형의 언어인 것 아니냐는 공감대를 얻고 있습니다. 어쨌든 언어 유형을 분류하는 작업은 언어유형론의 기본 관심사 가운데 하나입니다.   ## 고립어, 굴절어, 교착어, 포합어 세계 언어는 형태론적 유형에 따라 **고립어(孤立語)**, **굴절어(屈折語)**, **교착어(膠着語)**, **포합어(抱合語)**로 나뉩니다. 분류 기준은 크게 두 가지가 있다고 합니다. 첫째는 '통합'의 지표입니다. 한 단어에 얼마나 많은 형태소들을 사용하는가에 따라 언어 유형을 분류할 수 있습니다. 한 단어가 하나의 형태소로 이뤄져 있는 경우 고립어로 분류됩니다. 중국어가 대표적인 고립어입니다. 반대로 한 단어에 다수의 형태소가 있는 언어를 포합어라고 합니다. 둘째는 '융합'의 지표입니다. 형태소들이 얼마나 쉽게 분리되는가에 따라 굴절어와 교착어로 나뉩니다. 이상적인 고립어와 이상적인 포합어 사이에 있는 언어(=한 단어에 여러 형태소들을 사용하는 언어)들을 대상으로 따지는 기준입니다. 교착어의 경우 형태소들을 비교적 쉽게 분리할 수 있는 언어를 말합니다. 대표적인 것이 한국어입니다. 어간과 접사, 어미 사이의 경계가 상대적으로 명확합니다. '드시었겠다'라는 형태의 경우 '드-(eat)', '-시-(높임)', '-었-(과거)', '-겠-(추측)', '-다(평서/종결)'로 분석할 수 있습니다. 반면 굴절어는 형태소의 경계가 명확하지 않습니다. 굴절어인 라틴어의 경우 flora(꽃)이란 단어가 flora(주격-단수)-florae(속격-단수)-floram(대격 단수)-florarum(속격-복수)처럼 변화한다고 합니다. 굴절어에서는 이처럼 시제, 수, 성(性), 격 등 문법 정보에 대응하는 형태소를 하나씩 떼어서 분석해내기가 어렵습니다. [Bickel&Nichols(2005)](http://wals.info/chapter/22)는 단어당 문법 범주 수를 토대로 고립어, 굴절어, 교착어를 양적으로 분석한 바 있는데요. 예컨대 한국어의 '들리시었겠습니다'의 경우 이 방법에 따른 범주 숫자는 7입니다. 한국어는 아래 표 가운데 단어당 범주수가 6~7개인 언어로 분류되어 있습니다. 고립어인 영어는 2~3개, 굴절어인 러시아어는 4~5개로 분석됩니다. |     구분     | 개체수 | | :----------------: | :--: | | 단어당 범주수 0~1개인 언어 | 5  | | 단어당 범주수 2~3개인 언어 | 24 | | 단어당 범주수 4~5개인 언어 | 52 | | 단어당 범주수 6~7개인 언어 | 31 | | 단어당 범주수 8~9개인 언어 | 24 | | 단어당 범주수 10~11개인 언어 | 7  | | 단어당 범주수 12~13개인 언어 | 2  | |     계     | 145 |    ## 한국어의 특성 세계 969개 언어를 조사한 [Dryer(2013)](http://wals.info/chapter/26)는 언어의 유형을 아래와 같이 총 6개로 정리했습니다. |     구분     |  개체수  | | :-----------------: | :-----: | | 굴절이 거의 없거나 전혀 없는 언어 |  141  | | **접미사가 지배적인 언어**  | **406** | |  접미사를 선호하는 언어   |  123  | | 접미사와 접두사가 대략 같은 언어 |  147  | |  접두사를 선호하는 언어   |  94  | |  접두사가 지배적인 언어   |  58  | |     계     |  969  | 위 연구 결과를 한국어를 대상으로 따져보도록 하겠습니다. 우선 국립국어연구원(2002)이 '표준국어대사전'의 표제어를 분석한 결과 전체 44만594개 표제어 가운데 조사는 357개, 어미는 2526개, 접사는 656개인 것으로 조사됐습니다. 접사 656개 가운데 접두사는 200개, 접미사는 456개입니다.  조사와 어미는 물론 접사가 아닙니다만, 교착어인 한국어를 세계 다른 언어들과 비교하려면 이를 접사로 분류해야 분석의 일관성과 체계를 세울 수 있다고 합니다. 굴절어나 고립어에는 조사나 어미에 해당하는 문법범주가 존재하지 않기 때문이라고 합니다.  어쨌든 한국어에서 조사와 어미를 접미사로 분류하게 되면 한국어의 접두사와 접미사 비율은 200:3339, 즉 1:17 정도나 됩니다. 위 연구에서도 한국어를 '접미사가 지배적인 언어'로 분류하고 있습니다. 실제로 한국어는 어간에 조사나 어미와 같은 문법 형태소들이 차례로 결합하여 문법적인 기능을 실현하는 '교착어'입니다. 어간이나 명사에 여러 개의 문법 형태소가 결합돼 복합적인 문법적 기능을 실현합니다. 예컨대 '나는 빵을 먹는다'는 문장을 분석하면 다음과 같이 7개 형태소로 나뉩니다. > 나,는,빵,을,먹,는,다 '나(me)'라는 명사에 격조사 '-는'이 붙어 주어로 실현됐습니다. 마찬가지로 '빵(bread)'과 격조사 '-을'이 붙어 목적어로, '먹-(eat)'과 선어말어미 '-는-(현재)', 문말어미 '-다(평서형)'가 붙어 서술어로 실현됐습니다. 한국어에서 조사/어미의 형식과 기능은 대개 이와 같이 1대1 대응됩니다. 한국어 문법 범주의 실현은 거의 문법 형태소에 의해 이뤄집니다. 아래 예시와 같이 영어 의문문을 만들 때 중요한 요소는 어순인 반면 한국어는 어미가 그 핵심입니다. | 구분 |     평서문     |     의문문     | | :--: | :------------------: | :------------------: | | 한국어 |   철수가 방에 있다.   |   철수가 방에 있느냐?   | | 영어 | John is in the room. | Is John in the room? | 이러한 성격은 어순이 자유로운 한국어의 특징과도 밀접한 관련이 있습니다. 명사구(Noun Phrase)의 자격이 격조사 등과 같은 문법형태소로 표시되기 때문입니다. 아래 예시에서 (ㄱ)과 (ㄴ)은 같은 의미를 갖지만, (ㄷ)과 (ㄹ)은 그 의미가 완전히 다른 문장입니다. > (ㄱ) 철수가 영희를 만났다 > > (ㄴ) 영희를 철수가 만났다 > > (ㄷ) John met Mary > > (ㄹ) Mary met John 다만 한국어에서 기본이 되는 어순은 주어(S), 목적어(O), 동사(V)입니다. [Dryer(2013)](http://wals.info/feature/81A#2/18.0/152.8)은 전세계 1377개 언어를 대상으로 아래와 같이 조사했는데요. 이 기준에서 보면 한국어는 그렇게 별난 언어는 아닌 것 같습니다. |   구분    |  개체수  | | :-----------: | :-----: | |   SOV   |  565  | |  **SVO**  | **488** | |   VSO   |  95  | |   VOS   |  25  | |   OVS   |  11  | |   OSV   |  4  | | 지배적 어순이 없는 언어 |  189  | |    계    | 1377  | 한편 Nichols&Bickel(2005)에서는 235개 세계 각 언어들이 소유격 명사구에서 어디에 소유격 '표지'를 나타내는지에 대해 다음과 같은 통계를 제시하고 있습니다. 소유격 명사구에서 핵은 명사입니다. |     구분     | 개체수  | | :------------------: | :----: | |  핵인 명사에 표시하는 언어  |  77  | |  **의존어에 표시하는 언어**  | **98** | | 핵과 의존어에 모두 표시하는 언어 |  22  | | 핵과 의존어 모두 표시하지 않는 언어 |  32  | |   기타 유형의 언어    |  6  | |     계      | 235  | 그럼 한국어를 살펴볼까요? 한번 예를 들어보겠습니다. 아래 예시에서 볼 수 있듯 한국어에서 소유격은 의존어에 표시되고 있다는 걸 알 수 있습니다.  > (가) 나의 책, 그의 발, 너의 집 그럼 동사 핵은 어떨까요? Nichols&Bickel(2005)은 직접 목적어와 관련해 표지가 어디에서 실현되는지 조사했습니다. |     구분      | 개체수  | | :-------------------: | :----: | |  핵인 동사에 표시하는 언어   |  71  | | **의존어인 목적어에 표시하는 언어** | **63** | | 핵과 의존어에 모두 표시하는 언어  |  57  | | 핵과 의존어 모두 표시하지 않는 언어 |  42  | |    기타 유형의 언어    |  2  | |      계      | 235  | 또 한국어 예시를 살펴보겠습니다. > (나) 철수가 책을 동생에게 주었다. (나) 문장의 전체 핵심어 '주-'는 나머지 성분을 지배하고 있습니다. 이 경우 주어 '철수가', 목적어 '책을', 부사어 '동생에게'는 의존어라고 할 수 있습니다. 그런데 자세히 살펴보면 지배 표지(가, 을, 에게)가 모두 의존어에서 실현되고 있는 점을 알 수 있습니다. 실제로 한국어는 명사 핵이든 동사 핵이든 그 표지를 일관적으로 의존어에 표시하는 언어라고 합니다.  
apriori␞ 이번 글에서는 **연관규칙분석(A Priori Algorithm)**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 알고리즘 개요 및 입력데이터  연관규칙분석이란 어떤 두 아이템 집합이 번번히 발생하는가를 알려주는 일련의 규칙들을 생성하는 알고리즘입니다. 경영학에서 **장바구니 분석(Market Basket Analysis)**으로 널리 알려져 있는 방법론인데요, 소비자들의 구매이력 데이터를 토대로 "X 아이템을 구매하는 고객들은 Y 아이템 역시 구매할 가능성이 높다"는 식의 결론을 내는 알고리즘입니다. 인터넷 쇼핑을 할 때 어떤 상품을 고르면 그 상품을 구매한 사람들이 선택한 다른 상품을 제안해준다던지 하는 **컨텐츠 기반 추천(contents-based recommendation)**의 기본이 되는 방법론입니다.  그럼 연관규칙분석에 쓰는 데이터부터 살펴볼까요? 동네 편의점의 매출이력(**transaction**)이 다음과 같이 주어졌다고 가정해봅시다. | ID |   Items   | | :--: | :-------------: | | 1  |  달걀, 라면, 참치캔  | | 2  |   라면, 햇반   | | 3  |   라면, 콜라   | | 4  |  달걀, 라면, 햇반  | | 5  |   달걀, 콜라   | | 6  |   라면, 콜라   | | 7  |   라면, 햇반   | | 8  | 달걀, 라면, 콜라, 참치캔 | | 9  |  달걀, 라면, 콜라  | | 10 |    양파    | 위 데이터는 이렇게 해석할 수 있습니다. 1번 고객은 편의점에 들러 달걀, 라면, 참치캔을 샀네요. 7번 고객은 라면과 햇반을, 10번 손님은 양파를 구매한 걸 확인할 수 있습니다. 이를 행렬 형태로 표현하게 되면 아래와 같이 대부분의 셀이 0의 값을 갖는 **희소행렬(sparse matrix)**이 됩니다. | ID | 달걀 | 라면 | 참치캔 | 햇반 | 콜라 | 양파 | | :--: | :--: | :--: | :--: | :--: | :--: | :--: | | 1  | 1  | 1  | 1  | 0  | 0  | 0  | | 2  | 0  | 1  | 0  | 0  | 1  | 0  | | 3  | 0  | 1  | 0  | 0  | 0  | 1  | | 4  | 1  | 1  | 0  | 0  | 1  | 0  | | 5  | 1  | 0  | 0  | 0  | 0  | 1  | | 6  | 0  | 1  | 0  | 0  | 0  | 1  | | 7  | 0  | 1  | 0  | 0  | 1  | 0  | | 8  | 1  | 1  | 1  | 0  | 0  | 1  | | 9  | 1  | 1  | 0  | 0  | 0  | 1  | | 10 | 0  | 0  | 0  | 0  | 0  | 0  |  ## 규칙 및 규칙의 효용성 지표 자, 그럼 주어진 데이터로부터 규칙을 만들어볼까요? 사실 무수히 많은 규칙을 만들 수 있을 겁니다. 첫번째 고객 데이터만 가지고도 이렇게 규칙을 만들어낼 수 있습니다. 달걀을 구매하는 사람들은 라면도 함께 산다, 달걀과 라면을 사먹는 사람들은 참치캔도 산다, 참치캔을 구매하는 사람들은 계란도 함께 산다... 우선 용어부터 정의하고 넘어가겠습니다. **조건절(Antecedent)**은 위 예시의 규칙에서 '만일 ~라면'에 해당하는 부분입니다. **결과절(Consequent)**은 그 뒷부분에 해당하는 내용입니다. **아이템 집합(Item set)**이란 조건절 또는 결과절을 구성하는 아이템들의 집합입니다.  예컨대 '달걀을 구매하는 사람들은 라면도 함께 산다'를 보겠습니다. 여기에서 '달걀 구매'가 조건절, '라면 구매'가 결과절이며 각각의 아이템 집합은 '달걀', '라면'이 되겠습니다. 단 여기에서 조건절 아이템 집합과 결과절 아이템 집합은 말 그대로 집합, 여러개 아이템이 들어가도 되지만 **상호배반(mutually exclusive)**이어야 합니다. 다시 말해 조건절에 달걀이 들어가 있다면 결과절에는 달걀이 포함되어서는 안된다는 뜻입니다. 그렇다면 무수히 많은 규칙 가운데서도 좋은 규칙이란 무엇일까요? 규칙의 효용성을 드러내주는 지표는 크게 **지지도(support)**와 **신뢰도(confidence)**, **향상도(lift)**가 있습니다. 빈발 아이템 집합을 판별하는 데 쓰는 '지지도'는 아래와 같이 '조건절이 일어날 확률'로 정의됩니다.   $$For\quad the\quad rule\quad A\rightarrow B,\\ support(A)=P(A)$$  아이템 집합 간의 연관성 강도를 측정하는 데 쓰는 신뢰도는 아래와 같이 조건절이 주어졌을 때 결과절이 일어날 조건부확률로 정의됩니다.   $$confidence(A\rightarrow B)=\frac { P(A,B) }{ P(A) } $$  생성된 규칙이 실제 효용가치가 있는지를 판별하는 데 사용되는 향상도는 아래와 같이 조건절과 결과절이 서로 독립일 때와 비교해 두 사건이 동시에 얼마나 발생하는지 비율로 나타납니다. 바꿔 말해 향상도가 1이라면 조건절과 결과절은 서로 독립임을 뜻합니다. 규칙 사이에 유의미한 연관성이 없다는 걸로 받아들이면 될 것 같습니다. 향상도가 2라면 두 사건이 독립이라는 걸 가정했을 때 대비 2배로 긍정적인 연관관계를 나타냅니다.  $$lift(A\rightarrow B)=\frac { P(A,B) }{ P(A)\cdot P(B) } $$  규칙의 효용성은 지지도, 신뢰도, 향상도 세 가지를 모두 반영해 평가하게 됩니다. 임의의 규칙1이 규칙2보다 효과적인 규칙이라는 이야기를 하려면 세 지표 모두 클 경우에만 그렇다고 결론을 내릴 수 있게 된다는 이야기입니다.  ## 규칙 생성 자 그럼 이제 규칙들을 실제로 만들어볼 차례입니다. 가능한 모든 경우의 수를 탐색하여 지지도, 신뢰도, 향상도가 높은 규칙들을 찾아내는 방식이 가장 이상적일 겁니다. 하지만 아이템 수가 증가할 수록 계산에 소요되는 시간이 기하급수적으로 증가하게 됩니다(아이템이 $n$개일 때 탐색해야할 모든 경우의 수 : $n * (n-1)$ ) 이 때문에 **빈발 집합(frequent item sets)**만을 고려하여 연관 규칙을 생성하는 **A priori algorithm**이 제안되었습니다. 핵심 아이디어는 이렇습니다. 예컨대 아이템 집합 {$A$}의 지지도, 즉 $P(A)$가 0.1로 나타났다고 가정해봅시다. 그렇다면 {$A, B$}의 지지도, {$A, B, C$}의 지지도는 아무리 높아도 0.1을 넘지 못할 겁니다. 왜냐하면 {$A$}는 {$A, B$}, {$A, B, C$}의 부분집합이고, $P(A)$는 $P(A, B)$보다는 크거나 같을 것이기 때문입니다. {$A$}는 {$A, B$}, {$A, B, C$}의 **초월집합(superset)**이라고 부릅니다.  다시 규칙을 생성하는 과정을 떠올려 봅시다. 만약 임의의 아이팀 집합의 지지도가 일정 기준을 넘지 못한다면 해당 아이템의 부분집합의 지지도는 그 기준보다 명백히 더 작을 것이고, 그렇기 때문에 유용한 규칙으로 인정받을 수가 없게 됩니다. 최소지지도 요건을 만족하지 못하는 아이템집합의 규칙들은 애당초 계산할 필요가 없다는 이야기인데요. 이를 그림으로 나타내면 이와 같습니다. <a href="http://imgur.com/tncW2Gn"><img src="http://i.imgur.com/tncW2Gn.png" width="500px" title="source: imgur.com" /></a> 위 그림을 기준으로 설명해드리면 만일 아이템 집합 {$A, B$}의 지지도가 사용자가 정한 최소 지지도 요건을 충족시키지 못했을 경우 {$A, B$}를 포함해 {$A, B, C$}, {$A, B, D$} 등 8가지 경우의 수를 계산에서 제외하게 됩니다. 이로써 계산효율성을 달성하는 셈이지요.  ## 분석 예시 그럼 예시 데이터를 기준으로 연관규칙분석을 수행해보겠습니다. 최소 지지도 요건을 0.2로 설정했다고 칩시다. 지지도는 이렇게 구합니다. 우선 라면은 전체 10개 레코드 가운데 8번 등장했네요. 그럼 라면의 지지도는 0.8입니다. 마찬가지로 달걀(0.5), 콜라(0.5), 햇반(0.3), 참치캔(0.2), 양파(0.1)의 지지도 역시 구할 수 있습니다. 그런데 양파는 최소 지지도 요건을 만족하지 못했으므로 양파가 끼어있는 모든 규칙은 이후 분석에서 제외합니다. 이번에는 앞 단계에서 살아남은 아이템들을 이용하여 최소 지지도 조건을 만족하는 2개짜리 아이템 집합을 생성합니다. 아래 표와 같습니다. | 구분 | 라면 | 달걀 | 콜라 | 햇반 | 참치캔 | | :--: | :--: | :--: | :--: | :--: | :--: | | 라면 |   | 0.4 | 0.4 | 0.2 | 0.2 | | 달걀 |   |   | 0.3 | 0  | 0.2 | | 콜라 |   |   |   | 0  | 0.1 | | 햇반 |   |   |   |   | 0  | | 참치캔 |   |   |   |   |   | 위 표는 이렇게 작성하면 됩니다. 우선 라면과 라면, 달걀과 달걀처럼 중복되는 아이템 숫자는 셀 필요가 없습니다. 따라서 위 행렬의 대각성분은 0으로 놔두면 됩니다. 그럼 라면과 달걀이 한 레코드에 동시에 등장한 빈도를 세어볼까요? 레코드 1, 4, 8, 9, 이렇게 10개 데이터 가운데 네 가지 경우가 있군요. 따라서 라면과 달걀의 지지도는 0.4입니다.  그런데 여기서 아이템 집합 내에서의 순서는 고려하지 않기 때문에 달걀과 라면의 지지도 또한 0.4인데요, 이는 위 행렬이 **대칭행렬(symmetric matrix)**라는 뜻입니다. 다만 대각성분 아래쪽으로는 중복된 숫자라 따로 적지 않았습니다.  마찬가지로 다른 아이템들의 지지도를 구해서 행렬을 채우면 되는데요, 이번에도 '달걀과 햇반', '콜라와 햇반', '콜라와 참치캔', '햇반과 참치캔'은 최소 지지도 요건(0.2)를 채우지 못했으니 다음 분석에서는 이 경우의 수를 고려하지 않습니다.  이러한 방식으로 더 이상 최소 지지도 이상을 나타내는 아이템 집합이 없을 때까지 아이템 집합의 크기를 1씩 증가시키면서 반복 수행합니다. 이렇게 구한 상위 연관규칙 3가지는 아래와 같습니다. 동네 편의점의 매출이력 10건을 토대로 가장 강한 연관규칙은 '참치캔을 구매하는 소비자는 달걀과 라면을 동시에 산다'가 되는 셈입니다. | 조건절  | 결과절  | 지지도 | 신뢰도 | 향상도 | | :----: | :----: | :--: | :--: | :--: | | 참치캔  | 달걀, 라면 | 2  | 1  | 2.5 | | 참치캔  |  달걀  | 2  | 1  | 2  | | 라면,참치캔 |  달걀  | 2  | 1  | 2  |  ## '문서 요약'에 적용 연관규칙을 **문서 요약(document summarization)**에도 적용할 수 있습니다. 한 문장을 트랜잭션 데이터로 상정하고, 문장 내 출현한 단어를 아이템으로 놓고 같은 방식으로 분석하는 것입니다. 여기서 도출된 유의미한 규칙은 단어의 **co-ouccerrence** 정보를 함축할 것입니다. 예컨대 조건절이 {발, 없는, 말이}이라면 결과절은 {간다}가 나온다던지 하는 식입니다. 생각해볼 수록 많은 응용이 가능할 것 같습니다.
NNLM␞ 이번 포스팅에선 단어의 **분산표상(distributed representation)** 방식 가운데 하나인 **Neural Network Language Model(NNLM)**에 대해 살펴보도록 하겠습니다. NNLM은 [Bengio(2003)](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjk5ZKJzPvSAhUDTLwKHaVcA9cQFggjMAA&url=http%3A%2F%2Fwww.jmlr.org%2Fpapers%2Fvolume3%2Fbengio03a%2Fbengio03a.pdf&usg=AFQjCNG4K_79pujqq4HocNfhEKturlhy0w&sig2=BwQDTn_J429PA8Bt9K9FOw&bvm=bv.151325232,d.dGc)에서 제안된 모델인데요, 단어를 벡터로 바꾸는 뉴럴네트워크 기반 방법론으로 주목을 받았습니다. 이번 글은 고려대 강필성 교수님 강의와 네이버랩스 박은정 박사의 발표원고를 바탕으로 정리했음을 먼저 밝힙니다. 자 그럼 시작해볼까요?  ## Distributed representation 컴퓨터에게 단어를 가르쳐 주려면 어떻게 해야 할까요? 참으로 어려운 문제이지요. 컴퓨터는 그저 사칙연산 수행을 잘 하는 계산기일 뿐이니까요. 단어를 숫자로 바꿔서 입력해야 컴퓨터는 그제야 연산을 수행할 수 있습니다. 대표적인 방법론이 바로 [one-hot-encoding](https://en.wikipedia.org/wiki/One-hot)입니다. '코끼리', '사자', '뱀' 세 개 단어로 이뤄진 사전이 있다고 쳐보겠습니다. 이걸 one-hot-vector로 표현(representation)하면 아래와 같습니다. > **코끼리** : [1, 0, 0] > > **사자** : [0, 1, 0] > > **뱀** : [0, 0, 1] one-hot-vector는 가장 간단하고 직관적인 표현법입니다. 어떤 단어가 해당하는 요소만 1이고 나머지는 0으로 채워 넣으면 끝입니다. 그런데 사전에 등재된 단어 수가 100개, 1000개 이렇게 늘어난다면 어떻게 될까요? 각각의 단어 벡터들은 100차원, 1000차원을 갖게 될 겁니다. 실제 대다수 자연어들은 단어 수가 10만개 안팎이기 때문에 한 언어의 모든 단어들을 one-hot-vector로 바꾸면 그 차원수가 어마어마하게 클 겁니다. 이런 큰 차원의 벡터는 제 아무리 뛰어난 성능을 가진 컴퓨터라도 메모리 등 문제 때문에 계산복잡성이 크게 늘어나게 되겠죠. 게다가 이 벡터들은 딱 하나의 요소만 1이고 나머지는 모두 0인 **sparse vector** 형태를 갖습니다. one-hot-vector의 단점은 또 있습니다. 바로 두 단어의 **내적(inner product)**이 0입니다. 위 예시에서 코끼리라는 단어 벡터([1, 0, 0])와 사자 벡터([0, 1, 0])를 내적하면 0이 된다는 사실을 알 수 있습니다. 길이가 1인 두 벡터의 내적은 두 벡터 사이의 각도(cosine)가 되므로 내적값이 0이라는 말은 두 벡터가 **직교(orthogonal)**한다는 의미인데요, 이를 확장해서 생각해보면 모든 one-hot-vector는 서로 **독립(independent)**이라는 사실 또한 추론해낼 수 있습니다. 하지만 현실에서는 단어들끼리 관련성이 전혀 없는 건 아닙니다. 유의어, 반의어 같이 단어들은 다른 단어들과 의미적으로 특정한 관계를 맺고 있거든요. 이러한 문제를 해결하기 위해 등장한 개념이 바로 분산표상(distributed representations)이라고 보시면 될 것 같습니다.  $$ W\in { R }^{ \left| V \right| }\quad \rightarrow \quad W\in { R }^{ n }\\ n<<\left| V \right| $$  분산표상이 추구하는 바는 위 식과 같습니다. W는 단어벡터를 의미하는데요, one-hot-vector의 차원수는 사전의 전체 단어수(V)입니다. 이를 V보다 훨씬 작은 n차원 벡터로 바꿔보자는 것입니다. one-hot-vector는 그 요소가 0 혹은 1인 binary 구조이지만, 분산표상으로 표현된 단어벡터의 요소는 연속형의 실수값입니다. 듬성듬성한(sparse) 벡터를 빽빽한(dense) 벡터로 바꿔 표현한 것이라고 이해해도 좋을 것 같습니다. 뭔가 알 수 있을듯 없을듯 하지요? 분산표상을 그림으로 이해해보겠습니다.   <a href="http://imgur.com/oIOihyK"><img src="http://i.imgur.com/oIOihyK.png" width="500px" title="source: imgur.com" /></a>  왼쪽 그림을 보시면 총 9개 개체가 있습니다. 이를 one-hot-vector로 표현한다면 9차원짜리 벡터 9개가 나올 겁니다. 그런데 자세히 보면 9개 그림은 2개의 속성, 즉 색상(color)과 모양(shape)으로 설명할 수가 있겠네요. 즉 녹색이면서 해 모양이라면 첫번째 개체라는 걸 특정할 수가 있습니다. 그렇다면 9개 개체는 [색상, 모양]이라는 2차원짜리 벡터로도 충분히 표현할 수가 있습니다. 이것이 바로 분산표상 개념입니다.  분산표상은 데이터의 차원수를 줄이려는 것이 1차적 목적이지만, 그 효과는 실로 대단합니다. 위 예시처럼 색상이나 모양 기준으로 개체간 유사성을 잴 수 있듯이, 단어 벡터도 그 요소값이 연속적이기 때문에 단어 벡터 간에 거리나 유사도를 잴 수가 있게 됩니다. 의미가 유사한 단어는 벡터공간에서 가깝게, 반대의 경우는 멀게 배치하는 것이 분산표상의 목표입니다. 바로 아래 그림처럼요.  <a href="http://imgur.com/Myf9if3"><img src="http://i.imgur.com/Myf9if3.png" width="600px" title="source: imgur.com" /></a>   ## Neural Network Language Model 개요 NNLM은 단어들의 연쇄가 주어졌을 때 다음 단어가 무엇인지 맞추는 과정에서 분산표상된 단어벡터들을 만드는 방법론입니다. 뭔가 알쏭달쏭하죠? 한번 예를 들어 보겠습니다. > 발 없는 말이 천리 __ 위와 같이 '발', '없는', '말이', '천리' 네 개 단어가 주어졌다고 합시다. 그 다음에 올 단어는 무엇일까요? 수많은 동사가 올 수 있겠지만 '간다'라는 단어가 등장할 확률이 높을 겁니다. 우리는 '발 없는 말이 천리 간다'는 속담을 자주 쓰는 편이니까요. 이를 수식으로 쓰면 아래와 같습니다.  $$ P({ w }_{ t }|{ w }_{ t-1 },...,{ w }_{ t-n+1 })=\frac { exp({ y }_{ { w }_{ t } }) }{ \sum _{ i }^{ }{ exp({ y }_{ i }) } } $$  NNLM은 위 식의 조건부확률을 최대화하는 방향으로 학습을 하게 됩니다. 즉, $P(간다$\|$발,없는,말이,천리)$를 높이고 싶은거죠. 바꿔 말하면 '발', '없는', '말이', '천리' 네 개 단어로 '간다'를 맞추자는 겁니다. 이처럼 NNLM은 직전까지 등장한 $n-1$개 단어들로 $n$번째 단어를 맞추는 **N-gram** 모델이 그 본질입니다.   ## NNLM의 입출력 다음 값을 최대화하려면 우변의 분자는 키우고 분모는 줄여야할 겁니다.   $$ P({ w }_{ t }|{ w }_{ t-1 },...,{ w }_{ t-n+1 })=\frac { exp({ y }_{ { w }_{ t } }) }{ \sum _{ i }^{ }{ exp({ y }_{ i }) } } $$  $y_{w_t}$는 $w_t$라는 단어에 해당하는 점수 벡터입니다. 그 크기는 말뭉치 전체의 단어수($V$)에 해당하는 차원을 가졌습다. 만약 $V$가 3이라면 $y_{w_t}$는 $[1.2, 3.4, 2.1]$ 이런 식의 벡터가 됩니다.  NNLM 구조 말단의 출력은 $V$차원의 스코어 벡터 $y_{w_t}$에 소프트맥스 함수를 적용한 $V$차원의 확률 벡터입니다. NNLM은 확률값이 가장 높은 요소의 인덱스에 해당하는 단어가 실제 정답 단어와 일치하도록 학습을 진행하게 됩니다.  요컨대 정답 인덱스에 해당하는 스코어(분자)를 높이고, 나머지 인덱스에 해당하는 스코어(분모)는 낮춰야 위 식에 정의된 조건부확률을 높일 수 있습니다.  모델의 출력을 알아봤으니 이번엔 입력벡터 $x_t$를 만드는 과정을 살펴보겠습니다. 다음 식과 같습니다.  $$ { x }_{ t }=C\cdot { w }_{ t } $$  우선 $m$ x \|$V$\| 크기를 갖는 커다란 매트릭스를 우선 만듭니다. $m$은 $x_t$의 차원수로, $C$의 모든 요소 값은 초기에 랜덤 설정합니다. $w_t$는 $t$번째 단어에 대한 **One-hot-Vector**입니다. $t$번째 요소만 1이고 나머지는 0인 벡터이죠. $C$와 $w_t$의 내적은 $C$라는 행렬에서 $t$번째 열만 **참조(lookup)**하는 것과 본질적으로 같습니다.   ## NNLM의 구조 이번엔 NNLM 구조를 전체적으로 살펴보겠습니다. <a href="http://imgur.com/vN66N2D"><img src="http://i.imgur.com/vN66N2D.png" width="500px" title="source: imgur.com" /></a> 입력부터 천천히 살펴보겠습니다. 처음 말씀드렸던 것처럼 우리는 '발', '없는', '말이', '천리' 이렇게 네 개 단어가 주어졌을 때 '간다'라는 단어를 예측하고 싶은 겁니다. 우선 네 개의 각각의 단어에 해당하는 인덱스값을 불러옵니다. 이 인덱스에 해당하는 $C$ 행렬의 열벡터를 불러옵니다. 이렇게 네 개 단어에 해당하는 열벡터를 $C$에서 참조해 묶어주면 $x_t$가 됩니다.  **입력층(Input Layer)**에서 **은닉층(Hidden Layer)**을 거쳐 **출력층(Output Layer)**으로 보내는 연산은 다음과 같습니다. 우선 $x_t$와 $H$를 내적한 뒤 bias term 'd'를 더해 은닉층을 만듭니다. 여기에 $U$를 내적한 뒤 bias term $b$를 더해주면 스코어벡터 $y_{w_t}$가 나오게 됩니다.  $$ { y }_{ { w }_{ t } }=b+U\cdot tanh(d+H{ x }_{ t }) $$  마지막으로 $y_{w_t}$에 소프트맥스 함수를 적용한 뒤 이를 정답 단어인 '간다'의 인덱스와 비교해 **역전파(backpropagation)**하는 방식으로 학습이 이루어지게 됩니다.    ## NNLM의 학습 parameter NNLM의 parameter 차원수는 아래와 같습니다.  $$ H\in { R }^{ h\times (n-1)m },\quad { x }_{ t }\in { R }^{ (n-1)\times m },\quad d\in { R }^{ h\times 1 }\\ U\in { R }^{ |V|\times h },\quad b\in { R }^{ |V| },\quad y\in { R }^{ |V| }\quad,C\in{R}^{m\times|V|} $$  $x_t$는 모델이 예측해야 하는 마지막 단어를 제외한 $n-1$개의 $m$차원 단어 벡터들입니다. 여기에 입력층에서 은닉층으로 보내주는 가중치 매트릭스 $H$를 곱하면 은닉층은 사용자가 지정하는 $h$차원 벡터가 됩니다. 여기에 같은 차원의 bias 벡터 $d$를 더해주고, 이후 은닉층에서 출력층으로 보내주는 가중치 매트릭스 $U$를 내적한 뒤 bias 벡터 $b$를 더해주면 말뭉치 단어 개수인 $V$차원의 스코어 벡터가 생성되는 구조입니다.   ## 마치며 NNLM의 최종 목적은 단어벡터들의 모음이기도 한 $C$를 얻어내는 데 있습니다. 직전 $n-1$개 단어들이 주어졌을 때 마지막 $n$번째 단어를 맞추는 데 최적화된 단어벡터들의 모음이 바로 단어를 분산표상으로 임베딩한 결과물이라는 것이죠. 다만 NNLM은 C외에 H, U, b, d 등 다른 파라메터들도 업데이트해야 하기 때문에 계산복잡성이 높습니다. 이러한 문제점을 극복하기 위해 학습파라메터를 확 줄이는 방향으로 제안된 모델이 바로 최근 각광받고 있는 Word2Vec입니다.
sort␞ 이번 글에서는 여러 가지 정렬 알고리즘을 비교, 분석해 보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아를 참고해 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 비교표 알고리즘별 특징을 한 눈에 보기 쉽게 정리한 표는 다음과 같습니다. 아래 표에서 *complexity*는 *average case*를 기준으로 한 계산복잡성입니다. |        Algorithm         | In-Place | Stable | comparison | Complexity  | | :--------------------------------------: | :------: | :----: | :--------: | :-----------: | | [Bubble](https://ratsgo.github.io/data%20structure&algorithm/2017/11/05/bubblesort/) |  ○   |  ○  |   ○   |  $O(n^2)$  | | [Selection](https://ratsgo.github.io/data%20structure&algorithm/2017/11/06/selectionsort/) |  ○   |  ○  |   ○   |  $O(n^2)$  | | [Insertion](https://ratsgo.github.io/data%20structure&algorithm/2017/09/06/insmersort/) |  ○   |  ○  |   ○   |  $O(n^2)$  | | [Shell](https://ratsgo.github.io/data%20structure&algorithm/2017/11/07/shellsort/) |  ○   |  ○  |   ○   |  $O(n^2)$  | | [Merge](https://ratsgo.github.io/data%20structure&algorithm/2017/10/03/mergesort/) |  ×   |  ○  |   ○   | $O(n\log{n})$ | | [Heap](https://ratsgo.github.io/data%20structure&algorithm/2017/09/27/heapsort/) |  ○   |  ×  |   ○   | $O(n\log{n})$ | | [Quick](https://ratsgo.github.io/data%20structure&algorithm/2017/09/28/quicksort/) |  ○   |  ×  |   ○   | $O(n\log{n})$ | | [Counting](https://ratsgo.github.io/data%20structure&algorithm/2017/10/16/countingsort/) |  ×   |  ○  |   ×   |  $O(n+k)$  | | [Radix](https://ratsgo.github.io/data%20structure&algorithm/2017/10/16/countingsort/) |  ×   |  ○  |   ×   |  $d×O(n)$  | | [Bucket](https://ratsgo.github.io/data%20structure&algorithm/2017/10/18/bucketsort/) |  ×   |  ○  |   -   |  $O(n)$   | - 버블정렬(Bubble sort) : 주어진 배열의 마지막 위치에 있는 요소를, **정렬되지 않은 `직전 요소`부터 `첫 요소`에 이르기까지 비교**해 정렬 순서가 맞지 않은 모든 *case*에 대해 요소 위치를 바꿔줌. 이를 요소 수만큼 반복. 가장 간단하지만 비효율적인 알고리즘. - 선택정렬(Selection Sort) : 요소 위치 변경 횟수를 줄여 버블정렬을 일부 개선한 알고리즘. 정렬 순서가 맞지 않으면 무조건 자리를 바꿔줬던 버블정렬과 달리, 1회 *iteration*마다 최소값(혹은 최대값)을 찾고 단 한번만 해당 요소 위치를 바꿔줌. - 삽입정렬(insertion sort) : 모든 요소에 대해 앞에서부터 차례대로 **이미 정렬된 배열(*sorted list*)과 비교**하여 *sorted list* 내 자신의 위치를 찾아 `삽입`함으로써 정렬을 완성, 입력데이터가 이미 정렬된 상태라면 $O(n)$의 빠른 속도를 보이지만 그렇지 않은 경우 다른 기법을 적용하는 것이 나음. - 쉘정렬(shell sort) : 정렬되지 않은 배열의 경우 비효율적인 삽입정렬을 개선한 기법. 주어진 배열의 일정 간격(*gap*)만큼의 요소들에 대해 삽입정렬을 반복 수행. - 합병정렬(merge sort) : 리스트를 잘게 쪼갠 뒤 둘씩 크기를 비교해 정렬하고 분리된 리스트를 재귀적으로 `합쳐서` 정렬을 완성, 분할된 리스트를 저장해둘 공간이 필요해 메모리 소모량이 큰 편 - 힙정렬(heap sort) : 모든 노드가 힙 속성(각 노드의 값이 자신의 자식노드 값보다 큰 이진트리)을 만족하도록 재귀적으로 트리 구조를 만들어 정렬을 완성 - 퀵정렬(quick sort) : 피봇값을 기준으로 피봇 앞에는 피봇보다 작은 값, 뒤에는 큰 값이 오도록 하여 리스트를 분할하고, 분할된 두 개 리스트 각각에 재귀적으로 이 과정을 반복해 정렬을 완성. 합병정렬과 달리 주어진 배열을 임의로 나누지 않기 때문에 대개는 효율적이지만, 피봇값이 잘못 선택되면 $O(n^2)$이 될 수도 있음. - 카운팅정렬(counting sort) : 입력값의 빈도를 세어서 이를 결과리스트의 인덱스로 활용, 입력리스트의 요소값을 해당하는 결과리스트 인덱스 위치에 채워 넣는 방식으로 정렬을 완성, 입력리스트의 최대값($k$)이 커지면 복잡도가 크게 높아짐 - 래딕스정렬(radix sort) : 입력값의 자릿수($d$) 각각에 대해 카운팅정렬을 적용해 카운팅정렬의 단점 보완, 예컨대 10진법으로 표현된 입력값에 래딕스정렬을 적용하면 $k$값이 9로 작아짐 - 버킷정렬(bucket sort) : 데이터 개수만큼의 버킷을 두어 데이터를 나누고 버킷별로 정렬한 후 합쳐 정렬을 완성, 데이터 분포가 균등할 경우 계산복잡성을 낮출 수 있으나 그 반대의 경우 효과를 기대하기 어려울 수 있음   ## In-Place 입력리스트 내부에서 정렬이 이뤄지는 경우를 가리킵니다. 반대는 정렬 도중에 별도 저장공간을 필요로 하는 경우입니다. 합병정렬의 경우 입력리스트를 분할해 이를 정렬하고 다시 합치는 과정에서 분할된 리스트를 별도로 저장해 두어야 합니다. 카운팅정렬과 래딕스정렬은 입력값의 빈도를 세어서 저장해 두는 변수, 결과리스트를 저장해 둘 변수가 필요합니다. 버킷정렬은 버킷이라는 변수를 만들 공간이 있어야 합니다.   ## Stable Stable이란 같은 값의 위치가 정렬 과정에서 뒤바뀌지 않는 것을 뜻합니다. 아래 그림과 같습니다(위키피디아). <a href="https://imgur.com/LRrSfUT"><img src="https://i.imgur.com/LRrSfUT.png" width="300px" title="source: imgur.com" /></a> 힙정렬은 이진트리를 배열 형태로 표현해 정렬을 수행하는 과정에서 입력값의 위치가 바뀔 수 있습니다. 퀵정렬 또한 피봇을 기준으로 각 요소값들이 좌우로 이동할 수 있어 위치가 바뀔 수 있습니다.   ## comparison 값을 비교하는 정렬 알고리즘을 comparison sort라고 합니다. comparison sort 계산복잡성의 하한은 $O(n\log{n})$입니다. 카운팅정렬의 경우 값을 비교하지 않고도 정렬을 수행할 수 있어 comparson sort가 아닙니다. 래딕스정렬은 카운팅정렬을 기본으로 사용합니다. 버킷정렬의 경우 각 버킷에 대해 어떤 정렬 알고리즘을 쓰느냐에 따라 comparison 유무가 달라질 수 있습니다.
BranchingEntropy␞이번 글에서는 말뭉치에서 단어를 추출하는 기법 가운데 하나인 **Branching Entropy(이하 BE)**에 대해 살펴보도록 하겠습니다. BE는 Jin&Tanaka(2006)이 제안한 모델인데요, 이 글은 김현중 서울대 박사과정이 진행한 2017 패스트캠퍼스 강의와 코드를 참고하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 기법 개요 Jin&Tanaka(2006)의 아이디어는 생각보다 간단합니다. 단어 내부에서는 **불확실성(uncertainty)**, **엔트로피(entropy)**가 줄어들고, 경계에서는 증가하는 현상을 모델링한 것입니다. 아래 그림을 먼저 볼까요? <a href="http://imgur.com/bv6xleH"><img src="http://i.imgur.com/bv6xleH.png" width="500px" title="source: imgur.com" /></a> 알파벳 'n' 한 글자만 주어졌을 땐 이 정보만으로는 어떤 단어가 등장할지 정확히 알기 어렵습니다(불확실성이 높은 상태). 하지만 글자가 'natur'까지 등장했다면 'nature'이거나 'natural' 두 가지 경우의 수뿐입니다(불확실성이 낮은 상태). 그럼 'nature' 다음에 나오는 글자는 무엇일까요? 다시 예측하기 어려워집니다. 이는 'natural'도 마찬가지입니다. 이미 주어진 글자정보를 활용해 다음 글자의 불확실성을 계산해보면 아래와 같은 그래프를 그릴 수 있습니다. 단어 내부에선 불확실성이 줄어들다가 단어 경계에서 불확실성이 다시 증가하기 때문입니다. Jin&Tanaka(2006)는 이런 점에 착안해 그 경계의 불확실성이 높은 글자들의 나열을 '단어'로 보자고 제안했습니다. 이때 쓰이는 불확실성 관련 지표가 바로 BE입니다.  <a href="http://imgur.com/FcOIZfz"><img src="http://i.imgur.com/FcOIZfz.png" width="500px" title="source: imgur.com" /></a>  BE는 아래와 같이 정의됩니다.  $$ H(X|{ X }_{ n })=-\sum _{ x\in X }^{ }{ P(x|{ x }_{ n })\times \log { (P(x|{ x }_{ n })) } } $$  ## 분석 예시 영화 리뷰 사이트 '왓챠'에서 655만306개의 리뷰를 수집했습니다. 우선 이를 글자 단위로 세었습니다. 전체 결과 가운데 세 글자로 이뤄진 문자열 '아직까'를 포함하는 모든 단어들의 빈도는 아래 표와 같습니다. 우리는 아래 표로부터 '아직까'의 출현빈도는 5349라는 사실 또한 알 수 있습니다.  |  구분  |  빈도수  | | :----: | :------: | | 아직까지 |  4714  | | 아직까진 |  632  | | 아직까니 |  3   | | **총합** | **5349** |  그렇다면 '아직까'의 엔트로피는 어떻게 구할까요? 아래와 같습니다. <br> $$ \begin{align*} H(X|아직까)=&-P(아직까지|아직까)\times \log { (P(아직까지|아직까)) } \\&-P(아직까진|아직까)\times \log { (P(아직까진|아직까)) } \\&-P(아직까니|아직까)\times \log { (P(아직까니|아직까)) }\\\\=&-\frac { 4714 }{ 5349 } \times\log { \frac { 4714 }{ 5349 } } -\frac { 632 }{ 5349 } \times\log { \frac { 632 }{ 5349 } } -\frac { 3 }{ 5349 } \times\log { \frac { 3 }{ 5349 } } \\\\ =&0.3679 \end{align*} $$ 위와 동일한 방식으로 '아직', '아직까지', '아직까지도'의 BE를 구해 비교하면 아래 표와 같습니다.   | 구분 | 아직 | 아직까 | 아직까지 | 아직까지도 | | :--: | :--: | :--: | :--: | :---: | | BE | 2.95 | 0.37 | 3.46 | 4.69 |  위 표를 해석하면 이렇습니다. 우리가 온전한 단어로 쓰는 '아직', '아직까지', '아직까지도'는 그 경계에 다양한 글자들이 올 수 있으므로 BE가 비교적 높습니다. 하지만 '아직까'라는 문자열은 '아직까지', '아직까지도'라는 단어의 내부에 있으므로 BE가 낮습니다. 바꿔 말해 BE가 높은 문자열을 단어 취급해도 크게 나쁘지 않은 결과를 낼 수 있다는 것입니다.   ## BE와 계열관계  형태소란 **의미를 지니는 최소 단위**인데요, 형태소를 분석하는 기준으로는 **계열관계(系列關係paradigmatic relation)**가 있습니다. 계열관계는 그 자리에 다른 형태소가 ‘대치’될 수 있는가를 따지는 것입니다. 자세한 내용은 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/03/20/morpheme/)을 참고하시면 좋을 것 같습니다. 어쨌든 BE는 사실상 **형태소(morpheme)** 추출 기법입니다. 말뭉치에서 어떤 문자열이 자주 쓰이는지 빈도를 세어 문자열마다 형태소가 될 만한 지표를 반환(엔트로피가 높을 수록 형태소일 확률이 큼)해 주는데요. 이는 BE가 형태소의 중요 분석기준인 계열관계와 밀접한 관련을 맺고 있기 때문입니다. 아래 그림을 볼까요?  <a href="http://imgur.com/of6pN5D"><img src="http://i.imgur.com/of6pN5D.png" width="300px" title="source: imgur.com" /></a>  위 예시에서 '엔진'이라는 명사 뒤에는 조사 '-이', '-에서', '-을' 등이 올 수 있습니다. 여기에서 '-이', '-에서', '-을'은 대치해서 쓸 수 있기 때문에 계열관계를 이룬다고 말할 수 있습니다. 그런데 이 경우 '엔진'의 BE는 매우 높을 겁니다. '엔진' 뒤에 다양한 문자열이 등장할 수 있어 불확실성이 크기 때문입니다.  지금까지는 왼쪽에서 오른쪽으로 빈도수를 세는 걸 기준으로 설명을 해드렸지만, 오른쪽에서 왼쪽으로 빈도를 세어 BE를 계산하는 경우에도 마찬가지입니다. 아래 그림에서 '엔진'은 'Bracket', 'Head'와 계열관계를 맺고 있습니다. 아울러 '-에서'의 BE 또한 높습니다.  <a href="http://imgur.com/NGPpdVr"><img src="http://i.imgur.com/NGPpdVr.png" width="300px" title="source: imgur.com" /></a>  ## 말뭉치 분석 결과 왓챠 리뷰 655만306개 리뷰를 학습해 BE 상위 500개 문자열을 나열한 결과는 아래와 같습니다. (left-side BE * right-side BE 결과를 내림차순 정렬) <p class="message"> 만큼이나, 혹은, 처럼, 이나, 하고, 또는, 하며, 하거나, 하면서도, 덕분에, 이랑, 덕에, 대신, 속에서, 앞에서, 함과, 때문에, 에서의, 속의, 그리고, 했고, 보다는, 등등, 에서, 이라는, 또한, 이자, 하고도, 하다가, 땜에, 이든, 할때, 속에서도, 해서, 하던, 때문인지, 없이, 하게, 이라도, 위에서, 사이의, 마저도, 마저, 안에서, 조차, 조차도, 하나로, 하지만, 때매, 보단, 아저씨가, 에다가, 이지만, 했으며, 이후로, 같이, 인데, 같은, 스의, 마냥, 하는, 둘다, 감독은, 이며, 같은거, 함은, 들이, 아저씨의, 감독의, 감독이, 만큼은, 아래, 등의, 없이도, 만큼, 스가, 함이, 할만큼, 속으로, 해도, 으로, 이란, 함에, 했던, 거기에, 보다, 에서는, 에는, 했지만, 스와, 스는, 에서부터, 했다가, 들을, 세계의, 까지, 함으로, 에선, 에게서, 함을, 뒤에서, 감독님의, 들은, 씬에서, 이라며, 오빠, 위의, 만큼의, 만이, 속에서의, 시키고, 존나, 형의, 치고, 이라서, 하면서, 시가, 인지, 씬은, 사이에서, 한테, 당하는, 시키는, 하나는, 영화답게, 아저씨, 이었는데, 에만, 위에, 해지고, 에서도, 했으나, 이를, 집에서, 버전의, 형님의, 맞고, 이와, 뒤에, 적인, 적이고, 했다면, 그가, 할땐, 나는, 둘이, 영화의, 진짜, 액션의, 적이며, 함의, 특유의, 스를, 이었지만, 다가, 사이로, 보다도, 함도, 하다가도, 하나, 언니, 한데, 이기에, 발로, 형님이, 이처럼, 감독님이, 다음으로, 씬과, 에의, 들과, 이라면, 배우는, 그의, 시를, 시리즈는, 너의, 이었고, 하는게, 하듯, 들도, 대는, 할정도로, 거나, 성과, 해보이는, 졸라, 이거나, 작가가, 만을, 성의, 앞에선, 그를, 네가, 으로만, 되며, 일지라도, 하나를, 그렇게, 그는, 캐릭터는, 일때, 이라지만, 탓에, 인과, 함으로써, 했는데, 하다보니, 이후의, 하는데, 겁나, 감독을, 누나, 하니, 따위는, 2는, 에게, 이전에, 좀더, 했을때, 위를, 작은, 배우님, 형이, 씬이, 혼자, 만의, 하느라, 사이를, 드라마의, 하면, 뒤의, 옆에서, 영화들의, 결론은, 빨리, 없이는, 같은게, 수준의, 까지도, 감독님, 성을, 하더니, 이후에, 이었다면, 역의, 심지어, 이야기는, 언니가, 자체가, 버전, 아저씨는, 이라니, 했기에, 이고, 이름이, 영화로, 해놓고, 안에서의, 스도, 말고는, 이전의, 형은, 만으로는, 그들이, 영화는, 근데, 연기의, 액션이, 이요, 한건지, 방에서, 아주, 인데도, 인은, 과의, 주인공은, 세대의, 주제에, 이던, 부터, 빼고는, 영화라면, 자는, 속을, 해버리는, 딸이, 그녀가, 광고, 모두가, 이어도, 하니까, 이가, 1의, 영화인데, 캐릭터가, 커플이, 그나저나, 들까지, 감독에게, 하려면, 거리며, 스랑, 언니의, 당하고, 정도의, 사건을, 정의, 관객들이, 영화도, 갑자기, 시대의, 주인공이, 영화계의, 나를, 삼아, 스토리를, 게다가, 그러나, 들로, 같은건, 영화치곤, 작가의, 아이가, 중의, 모두를, 여자는, 터지는, 으로부터, 이였지만, 으며, 가서, 마지막에, 이후, 할때는, 이라고, 한건, 스에게, 시간에, 그것을, 보다가, 다른, 영화로는, 적으로, 피가, 자신이, 얼굴이, 결말은, 할때마다, 저런, 씬의, 주의, 밑에서, 영화지만, 영화처럼, 차는, 그녀의, 스처럼, 이면, 암튼, 이라는게, 손으로, 머리를, 자신의, 그래도, 맨날, 고도, 하라는, 부터가, 사는, 다들, 영화들은, 오빠가, 여자가, 속은, 영화와, 그치만, 하듯이, 이영화는, 영화이자, 드라마, 모두, 하지말고, 수준으로, 한듯한, 인이, 그에게, 시리즈의, 관계의, 버젼, 등이, 나의, 간지, 보니까, 시리즈를, 급의, 감독님은, 그것이, 모두에게, 괜히, 부분은, 치고는, 했는지, 시리즈가, 영화에서, 이라던가, 이냐, 남의, 해온, 물에서, 영화치고는, 액션은, 관객이, 시와, 그와중에, 레알, 드와, 속에도, 없는, 치며, 그들의, 팀이, 카드, 피는, 형님, 관객들은, 그것은, 성은, 장은, 인건지, 연출은, 점은, 캐릭터의, 인도, 트는, 드의, 배우들이, 스타일로, 스토리가, 시리즈에서, 시간을, 말고, 했어도, 주인공들이, 되게, 집을, 아줌마, 캐릭터를, 수와, 하다못해, 너는, 했으니, 강한, 할아버지가, 이의, 선생님의, 나오는, 화된, 모든게, 보는데, 게이, 되서, 문화를, 아빠가, 손이, 하도록, 타는, 지를, 온갖, 등으로, 중간에, 엄마가, 거리는, 살이, 몸이, 팬들은, 관객은, 이번엔, 이야기가, 이니까, 남자는, 마치, 적은, 그들은, 속에는, 하였고, 프로, 씬을, 엔딩은, 경찰이, 들이나, 어설픈, 배우가, 남자가, 나올때마다, 저렇게, 다며, 시켜서, 이렇게, 애니메이션의 </p>  ## 코드 김현중 박사과정이 작성한 BE 코드를 사용했습니다. 저 역시 정리 용도로 남긴 것이니 문제되면 바로 삭제하겠습니다. 최신 코드는 김현중 박사과정의 깃헙 https://github.com/lovit/soy을 참고하시기 바랍니다.  사용법은 아래와 같습니다. 아래 코드에서 *MaxScoreTokenizer* 역시 김현중 박사과정이 만든 코드로 말뭉치에서 학습한 BE를 바탕으로 문장을 토큰으로 나눠주는 함수입니다. ```python import branching_entropy as tool branching = tool.BranchingEntropy() branching.train(reviews) branchingtokenizer = tool.MaxScoreTokenizer(scores=branching.get_all_branching_entropies()) branching_tokenized_reviews = [branchingtokenizer.tokenize(review) for review in reviews] ```  <script src="https://gist.github.com/ratsgo/9d67443a515f0fed62da66d647575d4b.js"></script>
convexfunction␞ 이번 글에서는 **Convex Function(볼록함수)**와 관련된 개념들을 살펴보도록 하겠습니다. 이 글은 미국 카네기멜런대학 [강의](http://www.stat.cmu.edu/~ryantibs/convexopt/)를 기본으로 하되 저희 연구실의 김해동 석사과정이 만든 자료를 정리했음을 먼저 밝힙니다. 영문 위키피디아 또한 참고하였습니다. 그럼 시작하겠습니다.   ## convex function *convex function*이란 임의의 두 점 $x$, $y$와 $[0,1]$ 사이의 값 $t$에 대해 다음이 항상 성립하는 함수 $f$를 가리킵니다.  $$ f\left( tx+\left( 1-t \right) y \right) \le tf\left( x \right)+\left( 1-t \right) f\left( y \right) $$  이를 그림으로 도시하면 다음과 같습니다.  <a href="https://imgur.com/RQLtUko"><img src="https://i.imgur.com/RQLtUko.png" title="source: imgur.com" /></a>    ## convex function 유형 **strict convex**란 임의의 두 점 $x$, $y$와 $[0,1]$ 사이의 값 $t$에 대해 다음이 항상 성립하는 함수 $f$를 가리킵니다. 다시 말해 $f$는 *convex function*이면서, 선형함수(linear function)보다 큰 곡률을 가집니다. (등호는 $f$가 선형함수일 때 성립하므로)  $$ f\left( tx+\left( 1-t \right) y \right) < tf\left( x \right)+\left( 1-t \right) f\left( y \right) $$  **strong convex**란 *convex function* 가운데 0이 아닌 양수 $m$에 대해 다음이 항상 성립하는 함수 $f$를 가리킵니다. 다시 말해 $f$는 적어도 *quadratic function*만큼 *convex*하다는 걸 뜻합니다.  $$ f-\frac { m }{ 2 } { \left\| x \right\| }_{ 2 }^{ 2 }\quad is\quad convex $$  따라서 다음과 같은 포함관계가 성립합니다.  - *strong convex* ⊂ *strict convex* ⊂ *convex*  **concave function(오목함수)**란 *convex function*에 음수를 취한 함수를 가리킵니다. 따라서 우리는 *convex function*에 집중해서 분석합니다.   ## convex function의 예시 *convex function*의 대표적 예시는 다음과 같습니다.  <a href="https://imgur.com/A55z9iF"><img src="https://i.imgur.com/A55z9iF.png" width="500px" title="source: imgur.com" /></a> <a href="https://imgur.com/8ssp0YF"><img src="https://i.imgur.com/8ssp0YF.png" width="500px" title="source: imgur.com" /></a> <a href="https://imgur.com/3K0g3O3"><img src="https://i.imgur.com/3K0g3O3.png" width="500px" title="source: imgur.com" /></a>   ## convexity를 보존하는 연산 *convex function*에 대해 다음 연산은 *convexity*를 보존합니다.  <a href="https://imgur.com/grqWYO0"><img src="https://i.imgur.com/grqWYO0.png" width="500px" title="source: imgur.com" /></a> <a href="https://imgur.com/RL6OArO"><img src="https://i.imgur.com/RL6OArO.png" width="500px" title="source: imgur.com" /></a> <a href="https://imgur.com/Mlg0oh8"><img src="https://i.imgur.com/Mlg0oh8.png" width="500px" title="source: imgur.com" /></a>   ## convex function의 특성 *convex function*은 다음 세 가지 중요한 특성이 있습니다. 다음과 같습니다.  <a href="https://imgur.com/PNi83lL"><img src="https://i.imgur.com/PNi83lL.png" width="500px" title="source: imgur.com" /></a>  이 가운데 *second-order characterization*을 활용해 소프트맥스 함수가 *convex function*임을 증명해 보겠습니다. 다음과 같습니다.  <a href="https://imgur.com/qSTSjn5"><img src="https://i.imgur.com/qSTSjn5.png" width="500px" title="source: imgur.com" /></a> 
boolean␞ 이번 포스팅에선 **불린 검색 모델(Boolean Retrieval Model)**의 기본인 **단순 결합 질의(simple conjunctive query)**를 파이썬으로 구현하는 걸 살펴보도록 하겠습니다. 이 글의 알고리즘은 Introduction to Information Retrieval(Manning, C. D. et al., 안동언 외 옮김)을 바탕으로 하되 코드는 제가 직접 작성했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 풀려는 문제 풀려는 문제는 다음과 같습니다. 예컨대 영화 리뷰 말뭉치에서 '영화', '재미', '깨알' 세 단어가 동시에 사용된 문서를 찾고 싶은 겁니다. 이 때 세 단어들은 **질의(query)**가 됩니다. 우선 왓챠에서 72만2813건의 문서를 수집했고, 리뷰 하나가 하나의 행이 되도록 csv파일로 저장해뒀습니다. 이를 파이썬으로 읽어들이는 코드는 다음과 같습니다. ```python import pandas as pd corpus = pd.read_table('review.csv', sep=',') ```   ## 단어-문서 색인 영화 리뷰 말뭉치에 있는 단어와 문서를 다음과 같이 색인합니다. 우리가 필요한 정보는 특정 단어가 전체 문서집합 가운데 몇 건의 문서에 등장했는지(document frequency), 그리고 등장한 문서의 ID 집합(postings list)입니다. <a href="http://imgur.com/oeqC4Ti"><img src="http://i.imgur.com/oeqC4Ti.png" width="500px" title="source: imgur.com" /></a> 위와 같이 색인하는 코드는 다음과 같습니다. ```python def make_index(corpus):   # corpus 형태 : document로 이뤄진 list   from collections import defaultdict   # split docs and words   docs = [doc.split() for doc in corpus       if isinstance(doc, str)]   words = sorted(list(set(flatten(docs))))   # indexing   term_doc = defaultdict(list)   for doc_idx, words in enumerate(docs):     for word in words:       term_doc[word].append(doc_idx)   term_docfreq = {}   term_post = {}   for word, value in zip(term_doc.keys(),              term_doc.values()):     term_docfreq[word] = len(value)     term_post[word] = list(set(value))   return term_docfreq, term_post def flatten(x):   result = []   for el in x:     if isinstance(el, list):       result.extend(flatten(el))     else:       result.append(el)   return result ```   ## 포스팅 목록 비교 함수 '영화'라는 단어가 등장한 문서의 ID는 다음과 같다고 칩시다. 이 아이디는 term_post로부터 구할 수 있습니다. > 2, 4, 7, 8, 11 '재미'는 다음과 같다고 합니다. > 7, 368, 383, 434, 1049 우선 '영화' 목록의 첫번째 포인터가 가리키는 2와 '재미'의 7을 비교합니다. 다르니까 패스합니다. 2는 7보다 작으므로 '영화'의 포인터를 하나 옮깁니다.  이번엔 4와 7을 비교합니다. 다르니까 또 패스합니다. 4는 7보다 작으므로 '영화'의 포인터를 하나 옮깁니다. '영화'의 7과 '재미'의 7이 이번엔 일치하네요. 이를 정답 리스트에 저장해놓습니다. 이런 식으로 검색해야 할 포스팅 목록이 사라질 때까지 같은 작업을 반복하는 겁니다. 코드는 다음과 같습니다. ```python def intersection(p1, p2):   # 포스팅 목록 두개를 단순 비교   # 계산복잡성은 p1 길이 + p2 길이   p1 = sorted(p1)   p2 = sorted(p2)   answer = []   while len(p1) > 0 and len(p2) > 0:     if p1[0] is p2[0]:       answer.append(p1[0])       p1 = p1[1:]       p2 = p2[1:]     else:       if p1[0] < p2[0]:         p1 = p1[1:]       else:         p2 = p2[1:]   return answer ```   ## 단순결합질의 이번엔 두 개 이상의 단어로 이뤄진 쿼리에 대해 단순결합질의를 하는 함수를 만들어 보겠습니다. 그런데 하나 생각할 것이 있습니다. 예컨대 '영화', '재미', '깨알'이 동시에 들어있는 문서를 검색해야 한다면 Document Frequency가 가장 낮은 용어부터 처리해야 검색에 필요한 연산량을 줄일 수 있을 겁니다.  이와 관련해 단어들의 리스트로 이뤄진 쿼리와 DF 정보가 주어졌을 때 쿼리 단어를 DF 순으로 정렬해주는 함수를 만들었습니다. 다음과 같습니다. ```python def sort_freq(query, docfreq):   result = sorted([[term,docfreq[term]] for term in query],         key=lambda x: x[1], reverse=False)   return [term for term, _ in result] ``` 마지막으로 단순결합질의를 위한 함수를 만들어보겠습니다. 쿼리를 DF가 낮은 순으로 정리한 뒤 순서대로 겹치는 목록(문서)을 찾아가는 방식입니다. 코드는 다음과 같습니다. ```python def search(query, posting, docfreq):   terms = sort_freq(query, docfreq=docfreq)   result = posting[terms[0]]   terms = terms[1:]   while len(result) > 0 and len(terms) > 0:     result = intersection(result, posting[terms[0]])     terms = terms[1:]   return result ```   ## 함수 실행 자, 필요한 함수를 모두 정의했으니 이번엔 실행을 해보도록 하겠습니다. 실행 코드는 다음과 같습니다. ```python import time # indexing docfreq, posting = make_index(corpus) # processing start start_time = time.time() # processing result = search(query=['영화','재미','깨알'],         docfreq=docfreq,         posting=posting) # processing end end_time = time.time() # print processing time print(end_time - start_time) print(result) ``` 실행 결과는 다음과 같습니다. 간단한 검색어, 검색 대상이 72여만 건에 불과한데도 제 맥북(2015-early 13인치)에서 무려 125초 넘게 걸리네요ㅠㅠ 다음 글에서 이를 개선해보도록 하겠습니다. > 125.26901292800903 > [430144, 541361, 708930] 그럼 결과가 잘 나왔는지 해당 문서 내용을 살펴보겠습니다. 다음과 같습니다. > Doc 430144 : **깨알** 같은 **재미** 어느 하나 허투인 것이 없는 웨스 앤더슨 식 **영화** > Doc 541361 : **깨알** 대사 **재미** 남자임에도 여주인공에게 몰입할 수 있도록 도와주는 연기 생각할 수 있게 하는 **영화** 또 볼래요 > Doc 708930 : 간만에 내 취향의 **영화** 발견 순수하고 귀여운 캐릭터와 적절한 감동 **깨알** **재미** 배려깊은 결말까지 모두 맘에 들었다 홍영신님과 함께 
columbus␞ 휴가를 맞아 서점에 들렀다. 인문학 서가에서 책 하나가 눈에 들어왔다. '그해 역사가 바뀌다.' 책 판매를 위한 도발적인 제목 같이 느껴졌지만 저자 이름이 아주 반가웠다. **주경철 지음**. 학부 시절 감명깊게 들었던 수업이 떠올라서 책장을 넘겼다. 서론은 이렇다. > 나는 무엇보다 인간사를 큰 차원에서 이해해보기를 권유하고 싶었다. 현대사회는 혼돈과 변화의 소용돌이 속에 있다. 과학기술과 산업의 발전이 엄청난 속도로 진행되고 있다. 이런 변화는 한편으로 우리 삶을 훨씬 더 풍요롭게 해줄 수도 있지만, 다른 한편으로 부익부 빈익빈의 모순을 심화시킬 우려도 크다. 언론사 입사 이후 내 관심의 스케일은 동네 골목 한귀퉁이 정도에 불과했다. 1개월, 아니 하루 반나절에 이르는 시간이 내가 볼 수 있는 세상의 전부였다. 대학원 진학 이후 내 지식의 반경은 그보다 더 작아졌는지 모른다. 선생님 관심의 스코프가 인류 모든 역사라는 사실이 존경스러웠다. 선생님 책은 콜럼버스의 정신세계를 해부함으로써 유럽문명이 아메리카와 아시아 대륙으로 팽창하게 된 이유에 대해 설명을 시도한다. 선생님에 따르면 콜럼버스의 항해 동기는 이렇다. > 콜럼버스가 아시아로 향한 것은 평범한 항해가 아니다. 단순히 새로운 항로를 발견해서 돈을 벌겠다는 수준에서 한 일이 아니라는 뜻이다. 사실 아무리 돈에 대한 욕심이 넘친다고 해도 목숨을 버리면서까지 돈을 추구할 수는 없는 일이다. 그렇기에 저 먼 바다를 항해한다고 했을 때 콜럼버스가 가졌던 내면의 동기(motivation)에는 세속적인 요소와 함께 어떤 세계사적인 과업에 대한 의무감 같은 것이 동시에 작용했다고 볼 수 있다. 책에 따르면 콜럼버스는 일종의 '의지적 낙관주의자'였던 것 같다. 콜럼버스는 꽤 많은 책을 읽고 주석을 달아놓았다. 콜럼버스가 집중적으로 주석을 단 부분, 즉 콜럼버스를 매료시킨 책 구절이 매우 흥미롭다. *"지구는 굉장히 작다. 육지는 6이고 바다가 1이다"*  콜럼버스는 조만간 스페인 출신의 새로운 다윗이 이슬람 세력을 최종적으로 눌러 이기고 새 예루살렘을 건설할 것으로 내다봤다. 그 군대를 키우기 위한 자금은, 자신이 신대륙에서 발견할 금광이다. 콜럼버스는 이렇게 썼다. *"현재 스페인 왕이 마지막 황제이시고 그분이 나를 선택해서 내 항해를 지원하여 아시아에 갔으니 약속된 금을 얻게 될 것이다"* **말하자면 콜럼버스는 보고 싶은 것만 보고, 믿고 싶은 것들만 믿었던 셈이다. 그리고 바로 콜럼버스 자신이 신대륙 발견이라는 역사적 소명을 성취해낼 수 있는 유일한 사람이라 생각했다.**  한편 콜럼버스의 이름은 기독교 성인 중 하나인 '크리스토퍼'다. 크리스토퍼 성인의 가장 큰 특징은 예수를 안고 물을 건너 먼 곳으로 갔다는 점이다. 이름에 이 성인을 본받아 살겠다는 의지가 들어있다고 가정하면, 콜럼버스의 염원은 자신이 예수의 뜻을 저 멀리, 강을 건너고 바다를 건너 먼 이국땅까지 전하는 사람이 되는 것이었다.  주경철 선생님은 이렇게 평가했다. > 콜럼버스가 생각한 우주관에서 이 세상은 그저 물질적인 성격의 땅이 아니라 의미가 충만한 땅이다. 그가 아시아로 향한다는 것은 단순히 먼 이국으로 가는 정도가 아니라 신학적인 의미를 지닌다. 이미 알고 있는 곳, 구약에서 이미 예약되어 있는 곳을 향해 인류의 꿈을 실현하려 가는 것이라고 콜럼버스는 스스로 의미부여를 했다. (중략) 물론 당대에 콜럼버스만이 이러한 중세의 종교적 세계관을 가진 것은 아니다. 사실 이는 많은 사람들이 공유하는 생각이었다. 그리고 실제 콜럼버스와 마찬가지로 서쪽 항해를 하면 아시아로 쉽게 갈 수 있으리라고 판단한 사람들도 없지 않다. 하지만 중요한 점은 콜럼버스만이 그런 생각을 체계화시키고 또 실제로 실행에 옮겼다는 것이다. 종교적인 동기에서 출발한 꿈이지만, 실제 새로운 항로를 기획해서 절대 포기하지 않고 끝까지 밀어붙여서 결국 그것을 달성했다는 사실이 중요하다. 원래 목표는 지금 시각에서 보면 어긋나 있었지만 결과적으로는 그의 집요한 노력 덕분에 세계사는 새로운 방향으로 나아가게 되었다고 할 수 있다. 콜럼버스의 '의지적 낙관주의'는 유럽 세계의 아메리카 진출이라는 세계사적 족적을 남겼다. 콜럼버스의 황당한 내면 세계, 유럽 제국주의의 폭력성 등을 잠시 내려놓고 생각해보면, 그의 무모한 도전은 개인적으로는 존경할 만한 가치가 있다는 생각이 든다. 말하는 앵무새, 즉 'Artificial Intelligence'을 향한 나의 연구도 아시아 대륙이라는 미지의 땅에 가려는 콜럼버스의 항해와 크게 다를 것이 없다. 그 시작은 '내가 하면 된다'는 '의지적 낙관주의'일 것이다. *2017. 8. 10. 광화문*
treeensemble␞ 이번 포스팅에서는 트리 기반의 대표적인 앙상블 기법인 **랜덤포레스트(Random Forest)**와 **로테이션포레스트(Rotation Forest)**에 대해 알아보고자 합니다. 관련 R패키지를 소개하고, 저희 연구실 김해동 석사과정이 만든 코드와 성능 실험도 함께 소개해보고자 합니다. 그럼 시작해보겠습니다.  ## Tree-based Ensemble 소개 **의사결정나무(Decision Tree)**는 한번에 하나씩의 설명변수를 사용하여 예측 가능한 규칙들의 집합을 생성하는 알고리즘입니다. 한번 분기 때마다 변수 영역을 두개로 구분해 구분 뒤 각 영역의 순도(homogeneity)가 증가/불확실성(엔트로피)가 감소하도록 하는 방향으로 학습을 진행합니다. 의사결정나무는 입력 변수 영역을 두 개로 구분하는 **재귀적 분기(recursive partitioning)**와 너무 자세하게 구분된 영역을 통합하는 **가지치기(pruning)** 두 가지 과정으로 나뉩니다. 자세한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/03/26/tree/)을 참고하세요. <a href="http://imgur.com/RUUXzP8"><img src="http://i.imgur.com/RUUXzP8.png" width="500px" title="source: imgur.com" /></a> **랜덤포레스트**는 같은 데이터에 의사결정나무 여러 개를 동시에 적용해서 학습성능을 높이는 앙상블 기법입니다. 나무(tree)가 여럿 있다고 하는 의미에서 forest라는 이름이 붙었습니다. 참 직관적인 작명이죠. 위 그림을 보시면 조금 더 쉽게 이해하실 수 있으실 겁니다. 어쨌든 랜덤포레스트는 동일한 데이터로부터 복원추출을 통해 30개 이상의 데이터 셋을 만들어 각각에 의사결정나무를 적용한 뒤 학습 결과를 취합하는 방식으로 작동합니다. 단 여기서 각각의 나무들은 전체 변수 중 일부만 학습을 하게 됩니다. 개별 트리들이 데이터를 바라보는 관점을 다르게 해 다양성을 높이려는 시도입니다. **로테이션포레스트**는 학습데이터에 **주성분분석(PCA)**를 적용해 데이터 축을 회전(rotation)한 후 학습한다는 점을 제외하고는 랜덤포레스트와 같습니다. PCA로 회전한 축(아래 그림의 경우 핑크색 선을 지나는 축)은 학습데이터의 분산을 최대한 보존하면서도 학습성능 향상에도 유의미할 것이라는 전제에서 고안된 방법론으로 풀이됩니다. 아래 움짤을 보시면 PCA의 효과를 눈으로도 확인하실 수 있습니다. ![PCA](http://i.imgur.com/Uv2dlsH.gif) ** 출처 : [[Making sense of principal component analysis, eigenvectors & eigenvalues]](http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/140579#140579)   ## 기법 구현 R에서 의사결정나무를 수행하는 패키지는 **rpart**입니다. 아래와 같이 동작합니다. 의사결정나무는 범주를 예측하는 **분류(classification)**는 물론 연속형 숫자를 맞추는 **회귀(regression)** 모두 적용 가능한 모델인데요. 분류를 하고 싶다면 아래처럼 type 변수로 'class'를, 회귀를 하고 싶으면 'anova'를 쓰면 됩니다. 물론 이렇게 명시적으로 적어주지 않아도 예측해야 하는 변수 Y의 자료형이 범주에 해당하는 **factor**일 경우 분류를, 연속형 숫자에 해당하는 **numeric**일 경우 회귀를 자동 수행합니다. ```R # Decision Tree library(rpart) Fit1 <- rpart(fomula, data, type=“anova”) # regression Fit2 <- rpart(fomula, data, type=“class”) # classification ``` 랜덤포레스트와 관련된 패키지명은 말 그대로 **randomForest**입니다. rpart와 마찬가지로 Y의 자료형이 factor이면 분류, numeric이면 회귀를 자동 수행합니다. **mrty**는 앞서 설명드렸던 것처럼 변수의 부분집합을 만들 때 샘플링하는 변수 개수이며 **ntree**는 앙상블을 할 의사결정나무 개수가 됩니다. ```R # Random Forest library(randomForest) Fit <- randomForest(fomula, data, ntree, mtry,…) ``` 로테이션포레스트 관련 패키지명은 **rotationForest**입니다. 다른 패키지와 달리 명시적으로 입력변수(x)와 예측변수(y)를 나눠서 넣어주어야 하며 **2범주 분류**만 수행할 수 있습니다. PCA를 수행해야 하기 때문에 x의 자료형은 반드시 숫자여야 하며 y 역시 0 또는 1로 바꿔주어야 합니다. **K**와 **L**은 각각 randomForest 패키지의 mtry, ntree와 같습니다. ```R # Rotation Forest library(rotationForest) Fit <- rotationForest(x, y, K, L) ``` 마지막으로 설명드릴 코드는 저희 연구실에서 만든겁니다. rotationForest 기존 패키지를 다소 보완했습니다. 범주형 변수는 자동으로 숫자로 바꾸어 더미변수화를 해주고 다범주 분류는 물론 회귀도 역시 가능하도록 개선했습니다. **k**는 학습데이터를 몇 개로 나눌지 선택하는 변수이며, **bootstrapRate**는 학습데이터 부분집합을 만들 때 레코드를 얼마나 선택할지 지정하는 변수입니다. **numTrees**는 트리 개수, **type**은 분류/회귀를 선택하는 변수입니다. 이 코드는 이 포스트 맨 마지막에 첨부를 했는데요. 패키지 형태가 아니기 때문에 실제 실행을 위해선 R에서 사용자 정의 함수를 호출하듯 사용하시면 됩니다. ```R # advanced Rotation Forest Fit <- rotationForest(data, k, numTrees, bootstrapRate, type) ```  ## 성능 비교 실험 ### 2범주 분류 문제 [UCI datasets](https://archive.ics.uci.edu/ml/datasets.html) 등 수집 가능한 데이터셋을 수집해 30회 반복실험했습니다. 지금부터 보여드릴 표의 성능 지표는 **단순정확도(accuracy)**입니다. 표에서도 알 수 있듯 단일 의사결정나무보다 앙상블 기법인 포레스트가 나은 성능을 보여주고 있습니다. 앙상블 기법 중엔 랜덤포레스트가 로테이션포레스트보다 나은 성능을 나타냈습니다. (2범주 분류 문제에 사용한 로테이션포레스트 함수는 R패키지인 ratationForest입니다) <a href="http://imgur.com/crkbOFS"><img src="http://i.imgur.com/crkbOFS.png" width="500px" title="source: imgur.com" /></a>  ### 다범주 분류 문제 다범주 분류 문제에 있어서도 랜덤포레스트가 나은 성능을 보여주고 있습니다. 다범주 분류 말고 회귀 문제에 있어서도 랜덤포레스트가 로테이션포레스트보다 성능이 좋은 것으로 파악됐습니다. (여기서 사용된 로테이션포레스트 함수는 저희 연구실에서 작성한 코드입니다) <a href="http://imgur.com/tkKXMWq"><img src="http://i.imgur.com/tkKXMWq.png" width="500px" title="source: imgur.com" /></a>  ### randomForest 패키지의 파라메터 실험 앙상블 기법 가운데 그 성능이 강건하면서도 좋은 것으로 알려진 랜덤포레스트의 강점을 실험을 통해 확인할 수 있었습니다. 그럼 랜덤포레스트의 최적 하이퍼파라메터는 무엇일까요? **ntree** (트리 개수) <a href="http://imgur.com/5ccbeMp"><img src="http://i.imgur.com/5ccbeMp.png" width="400px" title="source: imgur.com" /></a> 분류 문제에서 트리 개수는 250개 이상부터 단순정확도 향상에 정체 현상이 나타났습니다(57개 데이터 30회 반복실험 평균 기준). 회귀 문제의 경우에도 트리 개수가 250개 이상부터 RMSE가 크게 줄지 않는 것으로 파악됐습니다. 패키지의 기본값인 500을 그대로 써도 무방할 것 같습니다.   **mtry** (변수 개수) <a href="http://imgur.com/aI0zbxt"><img src="http://i.imgur.com/aI0zbxt.png" width="400px" title="source: imgur.com" /></a> 개별 트리 학습용 부분집합을 만들 때 선택한 변수의 비율은 전체의 30%를 기점으로 클 수록 되레 분류 성능(단순정확도)이 떨어지는 것으로 나타났습니다(57개 데이터 30회 반복실험 평균 기준). 회귀 문제의 경우에도 변수 비율이 30%를 전후로 RMSE가 줄지 않는 경향을 보였습니다. **mtry**도 역시 패키지 기본값을 써도 크게 관계 없을 것 같습니다.  ## 마치며 이상으로 트리 기반 머신러닝 기법들에 대해 살펴보았습니다. 실험 결과에서 보셨던 것처럼 단일 의사결정나무보다 여러 개 트리를 동시에 적용한 앙상블 기법들이 강세를 보였습니다. 랜덤포레스트는 로테이션포레스트와 비교해 그 성능이 강건하고 우수한 것으로 파악됐습니다. 로테이션포레스트의 R패키지인 rotationForest를 보완한 코드는 아래에 게시했습니다. 여기까지 읽어주셔서 감사합니다.  <script src="https://gist.github.com/ratsgo/e426e92e4a88dca8f8a3f59d41f891be.js"></script>
MEMMs␞ 이번 글에선 **최대엔트로피마코프모델(Maximum Entropy Markov Models, MEMM)**을 다루어 보도록 하겠습니다. 이 글은 고려대 정순영 교수님 강의와 Speech and Language Processing(2nd edition) 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## concepts MEMM은 이름 그대로 [최대엔트로피모델](https://ratsgo.github.io/machine%20learning/2017/10/26/MEMs/)과 [은닉마코프모델(Hidden Markov Models)](https://ratsgo.github.io/machine%20learning/2017/03/18/HMMs/)을 결합한 모델입니다.    ## 은닉마코프모델 은닉마코프모델은 각 상태(state)가 이전 상태에만 의존하는 마코프체인(Markov Chain)을 따르되 은닉(hidden)되어 있다고 가정합니다. 은닉마코프모델에서는 관측치를 토대로, 관측치 뒤에 은닉되어 있는 상태를 추정합니다. 아래 그림은 단어가 관측치이고, 품사 정보가 은닉 상태인 은닉마코프모델을 도식화한 것입니다.  <a href="https://imgur.com/8pwST5B"><img src="https://i.imgur.com/8pwST5B.png" width="500px" title="source: imgur.com" /></a>  은닉마코프모델은 본질적으로 시퀀스 분류기입니다. 직전 상태에서 현재 상태로의 전이확률(transition probability)과 현재 상태에서 관측치를 관측할 확률인 방출확률(emission probability)를 토대로, 관측된 단어 **시퀀스** $W$가 주어졌을 때 가장 확률이 높은 은닉 상태(품사)의 **시퀀스** $T$를 찾기 때문입니다.  이를 식으로 나타내면 다음과 같습니다. $P(T)$는 전이확률, $P(W$\|$T)$는 방출확률을 가리킵니다.  $$ \begin{align*} \hat { T } =&arg\max _{ T }{ P\left( T|W \right) } \\ =&arg\max _{ T }{ P\left( W|T \right) \cdot P(T) } \\ =&arg\max _{ T }{ \prod _{ i }^{ }{ P\left( { W }_{ i }|{ T }_{ i } \right) } \prod _{ i }^{ }{ P({ T }_{ i }|{ T }_{ i-1 }) } } \end{align*} $$  그러나 은닉마코프모델은 시퀀스 추정에 전이확률과 방출확률 정보만을 활용하므로, 문맥의 다양한 자질(feature)들을 활용할 수 없다는 단점이 있습니다.   ## 최대엔트로피모델 이번엔 최대엔트로피모델을 살펴보겠습니다. 자연언어처리 분야에서는 [다항로지스틱 회귀(multinominal logistic regression)](https://ratsgo.github.io/machine%20learning/2017/04/02/logistic/)를 최대엔트로피모델이라 부릅니다. 단어 $w$가 주어졌을 때 범주(예 : 품사) $t$가 나타날 확률은 다음과 같습니다.   $$ P(t|w)=\frac { exp\left\{ { \overrightarrow { { w }_{ t } } }^{ T }\overrightarrow { f } \left( w \right) \right\} }{ \sum _{ t'\in T }^{ }{ exp\left\{ { \overrightarrow { { w }_{ t' } } }^{ T }\overrightarrow { f } \left( w \right) \right\} } } $$  위 식에서 벡터 $f$는 단어 $w$에 해당하는 자질(feature)들의 모음입니다. 예컨대 자질 벡터의 첫번째 요소는 '직전 단어가 명사이면 1, 그렇지 않으면 0', 두번째 요소는 '현재 단어가 동사이면 1, 아니면 0'... 이런 식으로 $f$의 요소값들을 구성합니다. 범주 $t$에 대응하는 가중치 벡터 $w_t$는 다항로지스틱 모델의 회귀계수를 가리킵니다.  최대엔트로피모델은 자질벡터 $f$를 매우 유연하게 설정할 수 있어 연구자의 언어학적 배경 지식을 모델링에 적극 활용할 수 있다는 장점이 있습니다. 그러나 최대엔트로피모델은 은닉마코프모델처럼 시퀀스 분류기(sequence classifier)가 아니라는 단점이 있습니다. 시퀀스가 아닌 단일 관측치(single observation)에 대해서만 예측이 가능하다는 것이지요.   ## 최대엔트로피마코프모델 MEMM은 최대엔트로피모델의 유연한 자질 활용 능력을 바탕으로 시퀀스 분류를 가능하게 하는 모델입니다. MEMM을 도식화한 그림은 아래와 같습니다. 그림에 나와 있는 것처럼 은닉 상태는 마코프체인을 따른다고 가정하되, 시퀀스 예측에 첫글자, 분사형 등 다양한 자질을 활용하는 방식입니다.  <a href="https://imgur.com/G6Xa3PB"><img src="https://i.imgur.com/G6Xa3PB.png" width="500px" title="source: imgur.com" /></a>  MEMM이 최적 상태 시퀀스를 예측하는 걸 수식으로 나타내면 다음과 같습니다. $i$번째 단어의 자질(feature)과 직전 은닉상태(품사)를 바탕으로 가장 확률이 높은 현재 은닉상태(품사)를 반환하는 것입니다.   $$ \begin{align*} \hat { T } =&arg\max _{ T }{ P\left( T|W \right) } \\ =&arg\max _{ T }{ \prod _{ i }^{ }{ P\left( { T }_{ i }|{ W }_{ i },{ T }_{ i-1 } \right) } } \end{align*} $$ 이 때 $P(T_i$\|$W_i,T_{i-1})$는 최대엔트로피 모델을 가리킵니다. 이를 식으로 적으면 다음과 같습니다. 아래 식에서 $f$는 $i$번째 단어 $w_i$와 $i-1$번째 은닉상태(품사)에 해당하는 자질벡터입니다.  $$ P({ T }_{ i }|{ W }_{ i },{ T }_{ i-1 })=\frac { exp\left\{ { \overrightarrow { { w }_{ t } } }^{ T }\overrightarrow { f } \left( { W }_{ i },{ T }_{ i-1 } \right) \right\} }{ \sum _{ t'\in T }^{ }{ exp\left\{ { \overrightarrow { { w }_{ t' } } }^{ T }\overrightarrow { f } \left( { W }_{ i },{ T }_{ i-1 } \right) \right\} } } $$   ## 비터비 알고리즘 MEMM에서 최적 상태열 추정은 은닉마코프모델과 마찬가지로 [비터비 알고리즘(Viterbi Algorithm)](https://ratsgo.github.io/machine%20learning/2017/03/18/HMMs/)을 활용합니다. 이를 도식화한 그림은 다음과 같습니다.  <a href="https://imgur.com/1Koz5hH"><img src="https://i.imgur.com/1Koz5hH.png" title="source: imgur.com" /></a>   ## MEMM의 파라메터 추정 MEMM의 학습은 최대엔트로피모델의 가중치 벡터를 추정하는 과정입니다. 다양한 방식이 있지만 *iterative scaling algorithm*를 많이 쓴다고 합니다. 이와 관련해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/10/29/maxparam/)을 참고하시면 좋을 것 같습니다.
HC␞ 이번 글에서는 **계층적 군집화(Hiarchical Clustering)**를 살펴보도록 하겠습니다. (줄여서 HC라 부르겠습니다) 이번 글 역시 고려대 강필성 교수님과 역시 같은 대학의 김성범 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 알고리즘 개요 HC란 계층적 트리 모형을 이용해 개별 개체들을 순차적, 계층적으로 유사한 개체 내지 그룹과 통합하여 군집화를 수행하는 알고리즘입니다. [K-평균 군집화(K-means Clustering)](https://ratsgo.github.io/machine%20learning/2017/04/19/KC/)와 달리 군집 수를 사전에 정하지 않아도 학습을 수행할 수 있습니다. 개체들이 결합되는 순서를 나타내는 트리형태의 구조인 **덴드로그램(Dendrogram)** 덕분입니다. 아래 그림과 같은 덴드로그램을 생성한 후 적절한 수준에서 트리를 자르면 전체 데이터를 몇 개 군집으로 나눌 수 있게 됩니다. <a href="http://imgur.com/gsCJHjS"><img src="http://i.imgur.com/gsCJHjS.png" width="500px" title="source: imgur.com" /></a>  ## 학습 과정 HC를 수행하려면 모든 개체들 간 **거리(distance)**나 **유사도(similarity)**가 이미 계산되어 있어야 합니다. 거리측정 방법에 대해선 [이곳](https://ratsgo.github.io/machine%20learning/2017/04/17/KNN/)을, (문서)유사도 측정법에 대해선 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/20/docsim/)을 참고하시면 좋을 것 같습니다. 주어진 학습데이터의 개체 수가 네 개이고 아래 그림처럼 거리 행렬을 이미 구해놨다고 가정해봅시다. <a href="http://imgur.com/25IT5fI"><img src="http://i.imgur.com/25IT5fI.png" width="500px" title="source: imgur.com" /></a> 거리가 가까운 관측치들끼리 차례대로 군집으로 묶어보겠습니다. 거리가 가장 짧은 것이 2이고 이에 해당하는 개체는 A와 D이므로 먼저 A와 D를 하나의 군집으로 엮으면 좋겠네요. 표 왼쪽에 덴드로그램을 그릴 건데요, 덴드로그램의 높이는 관측치간 거리(2)가 되도록 합니다.  <a href="http://imgur.com/iuZm5wl"><img src="http://i.imgur.com/iuZm5wl.png" width="500px" title="source: imgur.com" /></a> 자 여기서 A와 D를 한 군집으로 엮었으니 거리행렬을 바꿔주어야 합니다. 다시 말해 개체-개체 거리를 군집-개체 거리로 계산해야 한다는 것이죠. 예컨대 'AD'와 'B', 'AD'와 'C' 이렇게 거리를 구해야 한다는 말입니다. 그런데 군집-개체, 혹은 군집-군집 간 거리는 어떻게 계산해야 할까요? 여기엔 아래 그림처럼 여러가지 선택지가 존재합니다.  <a href="http://imgur.com/TM1PuQc"><img src="http://i.imgur.com/TM1PuQc.png" width="600px" title="source: imgur.com" /></a> 위 네 가지 방법 가운데 하나를 택했다고 가정하고 거리행렬을 업데이트했더니 AD와 C가 가장 인접해 있군요. 이번엔 이 둘을 이어줍시다. <a href="http://imgur.com/crTeoL0"><img src="http://i.imgur.com/crTeoL0.png" width="500px" title="source: imgur.com" /></a> 그 다음 과정을 수행했더니 아래처럼 되었습니다. <a href="http://imgur.com/1OI9j9S"><img src="http://i.imgur.com/1OI9j9S.png" width="500px" title="source: imgur.com" /></a> 분석 대상 관측치가 하나도 없으면 학습이 종료됩니다. <a href="http://imgur.com/S18WtII"><img src="http://i.imgur.com/S18WtII.png" width="500px" title="source: imgur.com" /></a>  ## HC의 특징 이미 설명해 드린 것처럼 HC는 [K-평균 군집화](https://ratsgo.github.io/machine%20learning/2017/04/19/KC/)와 달리 사전에 군집수 $k$를 설정할 필요가 없습니다. 그도 그럴 것이 앞선 예에서 덴드로그램의 최상층을 끊어주면 $A, D, C$와 $B$로 두 개 군집이 도출됩니다. 위에서 두번째 층을 끊으면 $A, D$와 $C$, $B$ 이렇게 세 개 군집이 나옵니다. HC의 학습결과물인 덴드로그램을 적절한 수준에서 잘라주면 된다는 얘기입니다. 반면 HC의 계산복잡성은 $O(n^3)$로 K-평균 군집화보다는 무거운 편입니다.
sov␞ 이번 글에서는 한국어 어순에 대해 살펴보도록 하겠습니다. 이번 글은 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 한국어는 SOV 세계 언어가 지닌 특성들에서 공통점과 차이점을 기술하고 일반적인 이론으로 발전시키는 언어학의 분야를 **언어유형론(linguistic typology)**이라 합니다. 언어유형론적으로 볼 때 한국어의 기본 어순은 'SOV'입니다. 이는 '주어(Subject)+목적어(Object)+동사(Verb)'의 어순이라는 뜻입니다. (영어는 SVO 언어입니다)   ## 한국어의 어순 유형 한국어 어순의 유형을 구체적으로 보이면 다음과 같습니다. > (가) 주어+서술어 > > (나) 주어+보어+서술어 > > (다) 주어+목적어+서술어 > > (라) 주어+부사어+서술어 > > (마) 주어+부사어+목적어+서술어 > > (바) 주어+목적어+부사어+서술어   ## 주어+서술어 우선 (가) 유형을 먼저 보겠습니다. (가)는 가장 기본적인 어순으로서 이 어순이 유지된 채 다른 문장 성분이 추가되어 (나)~(바)의 어순이 성립하게 됩니다. 다음 예문에서 보듯이 주어는 서술어 앞에 나오는 것이 원칙이며 만약 강조 등의 문체적 효과를 주기 위해 서술어를 주어 앞에 쓸 때에는 서술어 뒤에 약간의 휴지(pause)를 두는 경우가 많습니다. 문자 언어에서는 서술어 뒤에 반점(,)을 씀으로써 이를 반영합니다. > 아기가 잡니다. > > 겨울은 춥습니다. > > 여기가 서울입니다. > > 잡니다, 아기가.   ## 주어+보어+서술어 (나) 유형의 예문은 다음과 같습니다. 그런데 보어와 주어의 순서가 바뀌면 주어와 보어의 해석 역시 바뀌게 되어 뜻이 다른 문장이 되거나 비문이 됩니다. (가) 유형처럼 서술어를 앞에 쓰면 반점을 써 주어야 합니다. > 여기는 덕수궁이 아니다. 덕수궁은 여기가 아니다. > > 철수가 의사가 되었다. *의사가 철수가 되었다. > > 아니다, 여기는 덕수궁이.   ## 주어+목적어+서술어 먼저 예문을 보겠습니다. > (1) 톰이 제리를 좋아한다. > > (2) 제리를 톰이 좋아한다. > > (3) 톰이 좋아한다, 제리를. > > (4) 좋아한다, 톰이 제리를. > > (5) 제리를 좋아한다, 톰이. > > (6) 좋아한다, 제리를 톰이. (1)은 가장 일반적인 (다) 유형 문장입니다. 그런데 (2)에서 보듯이 목적어에 서술의 초점을 두어 주어와 목적어의 순서를 바꿀 수 있습니다. 이는 일반적으로 주어와 목적어의 기능이 뚜렷이 구분되고 격조사 형태도 뚜렷이 구분되기 때문에 가능한 것입니다. 그러므로 (3)~(6)처럼 서술어의 순서까지 바뀌면 어순이 바뀐 문장이 여럿 존재하게 됩니다. 위 예문 모두 자연스러운 한국어 문장입니다.   ## 주어+부사어+서술어 예문을 보겠습니다. (다) 유형의 목적어처럼, (라) 유형의 부사어 또한 의미 강조를 위해 주어와 자리를 바꿀 수 있습니다. 아울러 서술어의 순서까지 바꾼 문장도 성립합니다. > 이 지역 기후는 벼농사에 적합하다. > > 벼농사에 이 지역 기후는 적합하다. > > 적합하다, 이 지역 기후는 벼농사에.   ## 주어+부사어+목적어+서술어 예문을 보겠습니다. > (A) 선희가 나에게 선물을 주었다. > > (B) 선희가 선물을 나에게 주었다. > > (C) 철수는 밥을 맛있게 먹는다. > > (D) 철수는 맛있게 밥을 먹는다. (A), (B)를 보면 부사어가 목적어 앞이나 뒤, 둘 중 아무 위치나 올 수 있음을 알 수 있습니다. (C)와 (D) 역시 마찬가지입니다. 물론 자세히 보면 (A)와 (C)가 정상적인 어순이고, (B)와 (D)가 각각 '선물을'과 '맛있게'를 초점화한 문장이라고 할 수 있습니다. 그러나 그 어순 바꿈이 주어와 목적어의 어순 바꿈만큼 큰 차이를 나타내는 것은 아닙니다.   ## 주어+목적어+부사어+서술어 다음 예문은 부사어를 목적어 뒤에 놓아야 하는 어순입니다. 만약 순서가 바뀌면 매우 어색하거나 비문이 됩니다. 아래 예문에서 '꽃에', '사위로', '천재로', '녹지로' 등의 부사어는 없으면 안되는 필수 부사어인 점 또한 확인할 수 있습니다. > 임꺽정 씨가 나를 꽃에 비유했다. > > 그분이 백동수를 사위로 삼았다. > > 우리는 홍길동 씨를 천재로 여긴다. > > 그들이 황무지를 녹지로 만들었다.
countingsort␞ 이번 글에서는 요소값을 명시적으로 비교하지 않아도 정렬할 수 있는 기법인 **카운팅 정렬(counting sort)**과 **래딕스 정렬(Radix sort)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님 강의와 위키피디아, 그리고 [이곳](http://www.cs.miami.edu/home/burt/learning/Csc517.091/workbook/countingsort.html)을 참고해 정리하였음을 먼저 밝힙니다. 파이썬 코드는 [이곳](http://www.geekviewpoint.com/python/sorting/countingsort)을 참고로 하였습니다. 그럼 시작하겠습니다.   ## comparison sort 두 개 요소값을 반복적으로 **비교**하여 정렬을 수행하는 알고리즘을 comparison sort라고 합니다. 이는 Decision tree 모델로도 불립니다. 정렬 대상 숫자가 세 개인 경우를 예로 들어보겠습니다. 아래 그림과 같습니다.  <a href="https://imgur.com/oY9zxaE"><img src="https://i.imgur.com/oY9zxaE.png" width="400px" title="source: imgur.com" /></a>  위 트리를 보면 3개 숫자를 정렬하는 데 가능한 경우의 수는 6개($3!$)입니다. 각 경우의 수가 트리의 말단노드(leaf)가 됩니다. 트리의 루트노드에서 말단노드까지의 엣지의 수를 해당 트리의 높이(height)라고 하고 일반적으로 $h$라고 표기합니다. 위 트리에서 $h$는 최종 정렬 결과를 산출하기까지의 비교 횟수를 가리키는데요. 위 그림에서는 3입니다. 이 $h$가 바로 comparison sort의 계산복잡성을 나타냅니다. 이진트리의 높이가 $h$일 때 최대 $2^h$개의 말단노드를 가집니다. 그런데 데이터 수가 $n$개일 때 정렬 가능한 모든 경우의 수($n!$)보다 말단노드의 수가 커야 최악의 경우에도 데이터의 모든 요소값들을 정렬할 수 있을 것입니다. 다시 말해 $2^h≥n!$이 성립해야 한다는 말입니다. 이 부등식 양변에 밑이 2인 로그를 취하면 $h≥\log{n!}$이 됩니다. 한편 팩토리얼 연산의 성질에 의해 $n!>\sqrt{2πn}(n/e)^n$이라고 합니다. $n$이 1 이상일 때 $\sqrt{2πn}$ 역시 1보다 큰 값을 가지므로 여태까지 말씀드린 내용을 모두 종합해 식으로 표현하면 다음과 같습니다.  $$ h\ge \log { n! } >\log { \left\{ \sqrt { 2\pi n } { \left( \frac { n }{ e } \right) }^{ n } \right\} } >\log { { \left( \frac { n }{ e } \right) }^{ n } } \\ \Rightarrow h>\log { { \left( \frac { n }{ e } \right) }^{ n } } \\ \Rightarrow h>O\left( n\log { n } \right) $$  최종 도출된 부등식의 의미는 이렇습니다. 두 값을 반복적으로 비교해 정렬하는 기법인 comparison sort는 아무리 알고리즘을 잘 짜도 계산복잡성이 $O(n\log{n})$보다 크다는 말입니다. 바꿔 말해 comparison sort 계산복잡성의 하한은 $O(n\log{n})$입니다. 예컨대 퀵 정렬(quick sort)의 계산복잡성이 $O(n^2)$이고, 힙 정렬(heap sort)이 $O(n\log{n})$이라는 점을 감안하면 이같은 내용이 들어맞음을 확인할 수 있습니다.  이 글에서 설명할 counting sort는 non-comparison sort 기법으로 정렬에 드는 계산복잡성을 $O(n)$으로 낮추려는 알고리즘입니다.   ## counting sort 다음과 같은 입력어레이(input array) $A$에 대해 counting sort를 수행한다고 칩시다. > $A=[2,0,2,0,4,1,5,5,2,0,2,4,0,4,0,3]$ $A$의 모든 요소값의 빈도를 세어 카운팅어레이(counting array) $C$에 저장해 둡니다. $C$의 첫번째 요소 $c_1$이 3라는 5은 $A$ 가운데 0이 다섯 개 있다는 뜻입니다. 마찬가지로 $c_2$가 1이라는 말은 $A$에 1이 하나 있다는 말이 됩니다. > $C=[5,1,4,1,3,2]$ $C$의 각 요소값에 직전 요소값을 더해서 업데이트해 줍니다. 예컨대 $c_2$는 $c_1$(5)에 기존 $c_2$(1)를 더해서 만듭니다.  > $C=[5,6,10,11,14,16]$ 입력어레이와 같은 크기를 갖는 출력어레이(output) $B$를 만듭니다. 처음에는 비어 있습니다. 여기에서 바로 위의 $C$의 의미는 이렇습니다. - $c_1=5$ : 0은 $b_1$에서 $b_5$까지 다섯 개 자리를 차지한다. - $c_2=6$ : 1은 $b_6$ 한 개 자리를 차지한다. - $c_3=10$ : 2는 $b_7$에서 $b_{10}$까지 네 개 자리를 차지한다. - $c_4=11$ : 3은 $b_{11}$ 한 개 자리를 차지한다. - $c_5=14$ : 4는 $b_{12}$에서 $b_{14}$까지 두 개 자리를 차지한다. - $c_6=16$ : 5는 $b_{15}$에서 $b_{16}$까지 두 개 자리를 차지한다. | $b_1$ | $b_2$  | $b_3$  | $b_4$  | $b_5$  | $b_6$  | $b_7$  | $b_8$  | | :---: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | |    |     |     |     |     |     |     |     | | $b_9$ | $b_{10}$ | $b_{11}$ | $b_{12}$ | $b_{13}$ | $b_{14}$ | $b_{15}$ | $b_{16}$ | |    |     |     |     |     |     |     |     | 이제 $A$ 요소값의 역순으로 $B$에 채워 넣습니다. 3은 $b_{11}$ 한 개 자리를 차지하므로 여기에 넣습니다. 아래와 같습니다. 이제 $b_{11}$의 자리가 채워졌으므로 $c_3$의 현재값(11)에서 1을 뺍니다.  | $b_1$ | $b_2$  | $b_3$  | $b_4$  | $b_5$  | $b_6$  | $b_7$  | $b_8$  | | :---: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | |    |     |     |     |     |     |     |     | | $b_9$ | $b_{10}$ | $b_{11}$ | $b_{12}$ | $b_{13}$ | $b_{14}$ | $b_{15}$ | $b_{16}$ | |    |     |  3   |     |     |     |     |     | 다음은 0을 넣을 차례입니다. 0은 $b_1$에서 $b_5$까지 다섯 개 자리를 차지하므로 $b_5$에 넣습니다. 아래와 같습니다. 이제 $b_{5}$의 자리가 채워졌으므로 $c_1$의 현재값(5)에서 1을 뺍니다.  | $b_1$ | $b_2$  | $b_3$  | $b_4$  | $b_5$  | $b_6$  | $b_7$  | $b_8$  | | :---: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | |    |     |     |     |  0   |     |     |     | | $b_9$ | $b_{10}$ | $b_{11}$ | $b_{12}$ | $b_{13}$ | $b_{14}$ | $b_{15}$ | $b_{16}$ | |    |     |  3   |     |     |     |     |     | 이러한 방식으로 $A$의 모든 요소값을 $B$에 넣으면 다음과 같이 정렬이 종료됩니다. | $b_1$ | $b_2$  | $b_3$  | $b_4$  | $b_5$  | $b_6$  | $b_7$  | $b_8$  | | :---: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | |  0  |  0   |  0   |  0   |  0   |  1   |  2   |  2   | | $b_9$ | $b_{10}$ | $b_{11}$ | $b_{12}$ | $b_{13}$ | $b_{14}$ | $b_{15}$ | $b_{16}$ | |  2  |  2   |  3   |  4   |  4   |  4   |  5   |  5   | 두 값을 비교하는 과정 없이 정렬이 수행됐음을 확인할 수 있습니다.   ## 파이썬 구현 카운팅 정렬을 파이썬으로 구현한 코드는 다음과 같습니다. ```python # A: input array # k: maximum value of A def counting_sort(A, k):     # B: output array   # init with -1   B = [-1] * len(A)     # C: counting array   # init with zeros   C = [0] * (k + 1)     # count occurences   for a in A:     C[a] += 1     # update C   for i in range(k):     C[i+1] += C[i]     # update B   for j in reversed(range(len(A))):   	B[C[A[j]] - 1] = A[j]   	C[A[j]] -= 1   return B ```   ## counting sort의 복잡성 데이터 개수가 $n$일 때 $A$의 빈도를 세는 계산복잡성은 $O(n)$입니다. 데이터 전체를 한번씩 훑어야 하기 때문입니다. 출력어레이 $B$를 만들 때도 $O(n)$입니다. $A$의 요소값들을 역순으로 모두 훑어야 하기 때문입니다.  한편 $k$는 $A$의 요소값 가운데 최댓값을 가리킵니다. 위 예시에서는 $k=5$였습니다. 카운팅어레이 $C$를 만들 때 $k+1$개의 요소값을 0으로 초기화하게 되므로 공간복잡성은 $O(k)$가 됩니다. 또한 $C$를 업데이트할 때 반복문이 $k$번 돌게 되므로 계산복잡성 또한 $O(k)$가 됩니다. 그런데 $A$가 만약 다음과 같다면 카운팅어레이 $C$의 크기가 10000+1이 되고, 반복문 또한 10000회를 돌게 되어 대단히 비효율적이게 됩니다. > $A=[0, 10000]$ 요컨대 counting sort의 전체적인 계산복잡성은 $O(n+k)$가 되는데요. $k$가 충분히 작을 경우 $O(n)$이 되겠지만, $k$값이 커질 경우 $k$가 counting sort의 복잡성을 지배하게 됩니다.    ## Radix sort 입력데이터 $A$의 최대값인 $k$가 커지면 counting sort의 효율성은 크게 떨어집니다. 하지만 각각의 자릿수를 기준으로 정렬을 하게 되면 계산복잡성을 낮출 수 있습니다. 예컨대 10진법으로 표기된 숫자를 정렬한다면 $k$는 9가 됩니다. 이러한 정렬 방식을 Radix sort라고 합니다.  <a href="https://imgur.com/gcVBdYZ"><img src="https://i.imgur.com/gcVBdYZ.png" width="400px" title="source: imgur.com" /></a>  단 여기에서 주의할 것은 각 자릿수를 기준으로 정렬할 때 정렬 대상 숫자들의 위치가 뒤바뀌지 않는 stable sort 알고리즘을 적용해야 한다는 것입니다. 특정 자릿수를 놓고 정렬할 때 그 위치가 바뀌게 되면 해당 숫자가 아예 다른 숫자가 되어버리기 때문입니다. 예컨대 unstable sort를 적용하면 다음과 같은 엉뚱한 결과가 나올 수 있습니다. > 1**4**, 2**1** ==> 1**1**, 2**4** radix sort를 연결리스트(linked list)로 구현할 수도 있습니다. 10진수 첫번째 자리를 기준으로 정렬한 뒤, 두번째 자리를 기준으로 정렬합니다. 정렬 순서를 유지하기 위해 연결리스트 삽입시 *head*에 넣지 않고 *tail*에 삽입하는 것이 특징입니다. 예컨대 아래 그림과 같이 12가 이미 있는 2번 버킷에, 22를 삽입하는 경우 12 앞이 아니라 뒤에 넣습니다. 다음 그림과 같습니다.  <a href="https://imgur.com/0kRMgFx"><img src="https://i.imgur.com/0kRMgFx.png" width="600px" title="source: imgur.com" /></a>  counting sort를 바탕으로 raddix sort를 구현한 파이썬 코드는 다음과 같습니다. counting sort도 대표적인 stable sort입니다.  ```python # 현재 자릿수(d)와 진법(base)에 맞는 숫자 변환 # ex) 102, d = 1, base = 10, : 2 def get_digit(number, d, base):  return (number // base ** d) % base # 자릿수 기준으로 counting sort # A : input array # position : 현재 자릿수, ex) 102, d = 1 : 2 # base : 10진수라면 base = 10 def counting_sort_with_digit(A, d, base):   # k : ex) 10진수의 최대값 = 9   k = base - 1   B = [-1] * len(A)   C = [0] * (k + 1)   # 현재 자릿수를 기준으로 빈도수 세기   for a in A:     C[get_digit(a, d, base)] += 1   # C 업데이트   for i in range(k):     C[i + 1] += C[i]   # 현재 자릿수를 기준으로 정렬   for j in reversed(range(len(A))):     B[C[get_digit(A[j], d, base)] - 1] = A[j]     C[get_digit(A[j], d, base)] -= 1   return B ``` 다음은 Radix sort 코드입니다. ```python from math import log def radix_sort(list, base=10):   # 입력된 리스트 가운데 최대값의 자릿수 확인   digit = int(log(max(list), base) + 1)   # 자릿수 별로 counting sort   for d in range(digit):     list = counting_sort_with_digit(list, d, base)   return list ``` Radix sort의 계산복잡성을 따져보겠습니다. counting sort이 $O(n+k)$이고 10진수를 예로 들 때 $k$는 9에 불과하므로, 특정 하나의 자릿수를 기준으로 counting sort하는 데 드는 비용은 $O(n)$이 될 것입니다. 그런데 전체 자릿수가 $d$라면 이를 $d$번 수행해야할 것입니다. 따라서 전체적인 복잡성은 $d×O(n)$이 됩니다. 1조($=10^{12}$)가 넘는 큰 숫자가 끼어 있어도 $d$는 12에 불과하기 때문에 선형시간에 가깝게 정렬을 수행할 수 있습니다.
CRF␞ 이번 글에서는 Conditional Random Fields에 대해 살펴보도록 하겠습니다. 이 글은 고려대 정순영 교수님 강의를 정리했음을 먼저 밝힙니다. 이밖에 다양한 자료를 참고하였는데요, 인용한 부분에 표시를 해 두었습니다. 비터비 알고리즘 관련 설명 그림은 제가 직접 그렸습니다. 제가 잘못 이해하고 있거나 미진한 점 있으시면 언제든 댓글로 알려주시면 바로 반영하겠습니다. 그럼 시작하겠습니다.  ## overview CRF를 설명하는 데 있어 가장 유명한 그림 아닐까 싶습니다. 다음과 같습니다. <a href="https://imgur.com/ZiHsMLN"><img src="https://i.imgur.com/ZiHsMLN.png" width="600px" title="source: imgur.com" /></a> CRF, MEMM, HMM과의 차이점은 다음과 같습니다. 간결하고 직관적인 설명이어서 직접 인용을 해봤습니다. (출처 : [Quora](https://www.quora.com/How-do-Conditional-Random-Fields-CRF-compare-to-Maximum-Entropy-Models-and-Hidden-Markov-Models)) > CRFs and MEMMS are discriminative sequence models whereas HMMs are generative sequence models. HMM essentially uses Bayes Rule as a local model over the transition and emission probabilities, whereas CRF and MEMM's local models are MaxEnt models over transition and observable features. The chief difference between MEMM and CRF is that MEMM is locally renormalized and suffers from the label bias problem, while CRFs are globally renormalized. CRF가 강점을 지니는 이유는 구성하기에 따라서 얼마든지 HMM 같은 구조로 바꿀 수 있다는 점입니다. 아래 그림과 같습니다. (출처 : [C Sutton, "An Introduction to CRF"](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjjx-_QxsDXAhVFFJQKHeeiCvIQFggqMAA&url=http%3A%2F%2Fhomepages.inf.ed.ac.uk%2Fcsutton%2Fpublications%2Fcrftut-fnt.pdf&usg=AOvVaw16fdgbbRzhm_lX3yGeoyAp)) > For example, in an HMM, a transition from state $i$ to state $j$ receives the same score, log $p(y_t = j$\|$y_{t−1} = i)$, regardless of the input. In a CRF, we can allow the score of the transition $(i, j)$ to depend on the current observation vector, simply by adding a feature $1_{y_t=j}$, $1_{y_{t−1}=1}$, $1_{x_t=o}$.  <a href="https://imgur.com/cnrQ8ll"><img src="https://i.imgur.com/cnrQ8ll.png" width="500px" title="source: imgur.com" /></a> CRF는 본질적으로 시퀀스 분류기이기 때문에 최근 주목받고 있는 [Recurrent Neural Network](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)와도 직, 간접적으로 연관을 맺고 있는 것 같습니다. 이와 관련한 설명 또한 인용해봤습니다. (출처 : [Quora](https://www.quora.com/Is-Conditional-Random-Field-a-type-of-Recurrent-Neural-Network)) > RNNs have a latent state that is never observed (e.g. the memory in a LSTM). In contrast, the CRF has a latent state that is observed for training data (the model has to learn how to recreate those latent states for test data). Both are similar in that there is a set of parameters that tell you how to evolve the latent state from one time step to the next.    ## 수식과 파이썬 구현 CRF의 수식을 살펴보겠습니다. 수식만 살펴봐서는 되레 복잡하므로, 파이썬 코드와 함께 살펴보겠습니다. 파이썬 코드는 [이곳](https://github.com/babjo/py-crf)을 참고해 대폭 손질하였습니다. (수식 이해를 돕기 위한 코드로 대단히 느립니다, 혹시 학습 용도로 필요하시다면 라이브러리 활용을 추천해 드립니다)  ### 기본 구조 CRF를 그래피컬하게 나타낸 그림은 다음과 같습니다. 입력벡터 $x$의 위치에 상관없이 모두 활용하기 때문에 매우 유연한 구조입니다. <a href="https://imgur.com/cJhdbOA"><img src="https://i.imgur.com/cJhdbOA.png" width="400px" title="source: imgur.com" /></a> 입력 시퀀스(예컨대 단어들) 벡터 $x$가 주어졌을 때 레이블 시퀀스(예컨대 품사) 벡터 $y$가 나타날 확률은 다음과 같이 정의됩니다. 최대엔트로피모델(로지스틱 회귀)와 완전히 같습니다만, 최대엔트로피가 *single observation*을 분류하는 모델이라면, CRF는 *sequential classifer*라는 점이 다릅니다.  $$ { p }_{ \overrightarrow { \lambda } }\left( \overrightarrow { y } |\overrightarrow { x } \right) =\frac { 1 }{ { Z }_{ \overrightarrow { \lambda } }\left( \overrightarrow { x } \right) } \cdot exp\left( \sum _{ j=1 }^{ n }{ \sum _{ i=1 }^{ m }{ { \lambda }_{ i }{ f }_{ i }\left( { y }_{ j-1 },{ y }_{ j },\overrightarrow { x } ,j \right) } } \right) $$  위 식을 파이썬 코드로 구현하면 다음과 같습니다. ```python import math def calc_prob_y_given_x(y_prime, x, all_labels, FeatureFunction, weights):   n = len(y_prime)   m = len(weights)   nominator = 0   for j in range(1, n):     for i in range(1, m):       nominator += weights[i] * FeatureFunction(y_prime, x, i, j)   denominator = calc_Z(x, n, m, all_labels, FeatureFunction, weights)   return math.exp(nominator) / denominator ```   ### Feature Functions CRF는 최대엔트로피모델이나 최대엔트로피마코프모델처럼 Feature를 연구자가 유연하게 설정할 수 있습니다. 이를 파이썬 코드로 구현한 결과는 다음과 같습니다. ```python # x : words (observation sequence) # y : lables (e.g: POS TAGS, label sequence) def FeatureFunction(x, y, i, j):   # f_1   if i == 1 and y[j-1] == 'NN':     return 1   # f_2   elif i == 2 and y[j-1] == 'VBZ':     return 1   # f_3   elif i == 3 and x[0] == 'DT':     return 1   else:     return 0 ```   ### Label Bias 문제와 극복 방안 CRF는 Label Bias 문제를 극복하기 위해 제안된 기법입니다. Label Bias란 다음과 같은 문제를 가리킵니다.  - Preference of states with lower number transitions over others  <a href="https://imgur.com/cdRGsYi"><img src="https://i.imgur.com/cdRGsYi.png" width="500px" title="source: imgur.com" /></a>  이를 해결하기 위해 확률값을 구할 때 *global normalize*를 합니다. 이를 구현한 파이썬 코드는 다음과 같습니다. ```python def calc_Z(x, n, m, all_labels, FeatureFunction, weights):   Z = 0   all_possible_Y = itertools.product(all_labels, repeat=n)   for y_prime in all_possible_Y:     tmpZ = 0     for j in range(1, n):       for i in range(1, m):         tmpZ += weights[i] * FeatureFunction(y_prime, x, i, j)     Z += math.exp(tmpZ)   return Z ``` 그런데 보시다시피 가능한 모든 조합의 레이블 시퀀스에 대한 확률을 구해야 합니다. 가령 품사 종류가 `명사(NN)`, `동사(VB)` 등 다섯 가지이고, 시퀀스 길이가 5(개 단어)라면 다음 표처럼 $5^5$=3125가지의 경우의 수를 고려해야 합니다.  | $y_1$ | $y_2$ | $y_3$ | $y_4$ | $y_5$ | | :---: | :---: | :---: | :---: | :---: | | NN  | NN  | NN  | NN  | NN  | | NN  | NN  | NN  | NN  | VBN | | NN  | NN  | NN  | NN  | VBZ | | NN  | NN  | NN  | NN  | IN  | | NN  | NN  | NN  | NN  | DT  | | NN  | NN  | NN  | VBN | NN  | | NN  | NN  | NN  | VBN | VBN | | NN  | NN  | NN  | VBN | VBZ | | NN  | NN  | NN  | VBN | IN  | | NN  | NN  | NN  | VBN | DT  | | ... | ... | ... | ... | ... | CRF에서 가장 계산량이 많은 부분이 바로 $Z$를 구하는 부분입니다. 위 파이썬 코드는 수식 이해 용도로 수식을 그대로 옮겨놓은 형태이지만, 실제로는 다이내믹 프로그래밍(dynamic programming) 등 최적화 기법을 쓴다고 합니다.  ### 파라메터 학습 : 최대우도추정 CRF의 파라메터는 로지스틱 회귀의 파라메터를 추정하는 방식과 같이 최대우도추정법(Maximum Likelihood Estimation)으로 구합니다. 식이 매우 복잡한데, 저 또한 정리 용도로 남겨둡니다. CRF의 로그 우도함수는 다음과 같습니다. 식의 첫 줄 두번째 항은 과적합(overfitting) 방지를 위한 정규화(regularization) 항입니다.  <a href="https://imgur.com/vzM1P2R"><img src="https://i.imgur.com/vzM1P2R.png" width="600px" title="source: imgur.com" /></a> 위 로그 우도함수는 파라메터 $λ$로 편미분한 값이 0인 지점에서 최대값을 가집니다. 이를 3등분해서 각각 $λ$에 대해 편미분한 결과는 다음과 같습니다. 우선 $A$를 편미분한 결과입니다.  <a href="https://imgur.com/T3uvxew"><img src="https://i.imgur.com/T3uvxew.png" width="550px" title="source: imgur.com" /></a>  다음은 $B$를 파라메터 $λ$에 대해 편미분한 결과입니다.  <a href="https://imgur.com/7sYIPIV"><img src="https://i.imgur.com/7sYIPIV.png" width="700px" title="source: imgur.com" /></a>  마지막으로 $C$입니다.  <a href="https://imgur.com/eZ4d6ln"><img src="https://i.imgur.com/eZ4d6ln.png" width="250px" title="source: imgur.com" /></a>  $A$는 데이터의 *empirical distribution*으로 해석할 수 있습니다. 식과 파이썬 코드는 다음과 같습니다.  <a href="https://imgur.com/3V1Fpng"><img src="https://i.imgur.com/3V1Fpng.png" width="300px" title="source: imgur.com" /></a>  ```python def calc_empirical_expectation_feature_i(train_data, FeatureFunction, i):   empirical_expectation_feature_i = 0   for x, y in train_data:     n = len(y)     for j in range(1, n):       empirical_expectation_feature_i += FeatureFunction(y, x, i, j)   return empirical_expectation_feature_i ```   $B$는 모델이 내놓는 *distribution*으로 해석할 수 있습니다. 식과 파이썬 코드는 다음과 같습니다.  <a href="https://imgur.com/g00M1pZ"><img src="https://i.imgur.com/g00M1pZ.png" width="370px" title="source: imgur.com" /></a>  ```python import itertools def calc_predicted_expectation_feature_i(train_data, FeatureFunction, 									 all_labels, weights, i):   predicted_expectation = 0   for x, y in train_data:     n = len(y)     all_possible_Y = itertools.product(all_labels, repeat=n)     for y_prime in all_possible_Y:       predicted_expectation += \         (calc_prob_y_given_x(y_prime, x, all_labels, FeatureFunction, weights)         * sum([FeatureFunction(x, y, i, j) for j in range(1, n)]))       print(predicted_expectation)   return predicted_expectation ```   로그우도 함수에 대한 편미분 식을 다시 적으면 다음과 같은데요. $A$와 $B$가 비슷할 수록 로그우도 함수의 도함수가 작아집니다. 데이터의 분포와 모델의 분포가 비슷할 수록, 즉 모델이 데이터의 분포를 잘 모사할 수록 학습이 잘 되었다는 이야기입니다.  <a href="https://imgur.com/DCozFsP"><img src="https://i.imgur.com/DCozFsP.png" width="250px" title="source: imgur.com" /></a>   이제 거의 다 왔습니다. 파라메터 $λ$를 랜덤 초기화한 뒤 이제까지 구한 로그우도 함수가 커지는 방향(그래디언트)로 파라메터를 조금씩 업데이트해 주면 됩니다(*gradient ascent*). 이를 파이썬 코드로 구현한 결과는 다음과 같습니다. ```python #train data set = {(x, y)} def get_all_labels(train_data):   available_labels = set()   for x, y in train_data:     available_labels.update(y)   return list(available_labels) # m = feature vector size import random def initial_weights(m):   return [random.random() for _ in range(m)]   def train(train_data, FeatureFunctions, m, iterations=100, learning_rate=0.1):   all_labels = get_all_labels(train_data)   weights = initial_weights(m)   for _ in range(iterations):     for i in range(1, m):       empirical_expectation = \         calc_empirical_expectation_feature_i(train_data, FeatureFunction, i)       predicted_expectation = \         calc_predicted_expectation_feature_i(train_data, FeatureFunction,                           all_labels, weights)       weights[i] = weights[i] + \       			learning_rate * (empirical_expectation - predicted_expectation) ```   ## 비터비 알고리즘 시퀀스 분류를 하기 위해 이 먼길을 돌아왔습니다. CRF가 최적 상태열을 *inference*하는 기법인 비터비 알고리즘은 다음과 같이 동작합니다.  <a href="https://imgur.com/8UMGbVI"><img src="https://i.imgur.com/8UMGbVI.png" width="500px" title="source: imgur.com" /></a>  다음 과정입니다.  <a href="https://imgur.com/aDLuLIY"><img src="https://i.imgur.com/aDLuLIY.png" width="600px" title="source: imgur.com" /></a>  다음 과정입니다.  <a href="https://imgur.com/aDSZgqa"><img src="https://i.imgur.com/aDSZgqa.png" width="700px" title="source: imgur.com" /></a>  마지막으로 *backtrace* 과정입니다.  <a href="https://imgur.com/0KIV6NO"><img src="https://i.imgur.com/0KIV6NO.png" width="700px" title="source: imgur.com" /></a> 
convexset␞ 이번 글에서는 **Convex Set(볼록집합)**과 관련된 개념들을 살펴보도록 하겠습니다. 이 글은 미국 카네기멜런대학 [강의](http://www.stat.cmu.edu/~ryantibs/convexopt/)를 기본으로 하되 저희 연구실의 김해동 석사과정이 만든 자료를 정리했음을 먼저 밝힙니다. 영문 위키피디아 또한 참고하였습니다. 그럼 시작하겠습니다.   ## 벡터 결합하기 벡터 $x_1$, $x_2$, ..., $x_n$이 주어졌을 때 이들을 결합하는 것은 다음 세 가지 방식이 있습니다. - **[Linear combination](https://ratsgo.github.io/linear%20algebra/2017/03/24/Ldependence/)** : $α_1x_1+...+α_nx_n$ ($α_i$는 실수) - **Affine combination** : $α_1x_1+...+α_nx_n$ ($Σ_iα_i=1$) - **Convex combination** : $α_1x_1+...+α_nx_n$ ($Σ_iα_i=1$이고, $0≤α_i≤1$) *affine combination*에 대해 **닫힌(closed)** 집합을 **Affine set**이라고 합니다. 예컨대 벡터 $x_1$, $x_2$가 집합 $A$에 속해 있고, 이들의 *affine combination* 또한 $A$에 속할 때 $A$는 *affine set*이 됩니다. 마찬가지로 *convex combination*에 대해 닫힌 집합을 *convex set*이라고 합니다. 2차원 벡터 두 개(즉 $x_1$, $x_2$)를 세 가지 방식으로 결합해 각각 나타내면 다음 그림과 같습니다.   <a href="https://imgur.com/ANZXnOV"><img src="https://i.imgur.com/ANZXnOV.png" width="500px" title="source: imgur.com" /></a>  - *linear combination* 결과 $x_1$과 $x_2$를 포함하는 $R^2$의 평면이 **생성(span)**된다. - 2차원 공간의 *affine set*은 $x_1$과 $x_2$를 지나는 직선이다. - 2차원 공간의 *convex set*은 $x_1$과 $x_2$를 연결하는 선분이다. 벡터 $x_1$과 $x_2$의 *affine set*이 직선, *convex set*이 선분이 되는 것과 관련해서는 고1 수학 과정의 [내분과 외분](http://mathbang.net/439)과 연관성이 있을 거란 생각이 듭니다. 다시 말해 벡터 앞에 붙는 계수의 부호가 중요하다는 이야기이죠.   ## Convex Set *convex set* $C$는 다음과 같이 정의됩니다. - $x$와 $y$가 $C$에 속한다면, $tx+(1-t)y$ 또한 $C$에 포함된다. ($0≤t≤1$) 직관적으로 따져보겠습니다. 어떤 집합 $C$에 속한 임의의 두 점을 골랐을 때 둘을 연결하는 선분 또한 $C$에 포함될 경우 $C$를 *convex set*이라고 합니다. 따라서 다음 도형은 *convex set*입니다.  <a href="https://imgur.com/0Gec7Rf"><img src="https://i.imgur.com/0Gec7Rf.png" width="150px" title="source: imgur.com" /></a>  다음은 *convex set*이 아닙니다. 아래 두 점을 잇는 선분의 일부가 해당 집합 바깥에 있기 때문입니다.  <a href="https://imgur.com/PToXoC0"><img src="https://i.imgur.com/PToXoC0.png" width="170px" title="source: imgur.com" /></a>  마찬가지로 다음은 *convex set*이 아닙니다. 임의의 두 점이 경계에 있을 경우 해당 점을 잇는 선분의 일부가 집합에 포함되어 있지 않습니다.  <a href="https://imgur.com/cWdQQtc"><img src="https://i.imgur.com/cWdQQtc.png" width="150px" title="source: imgur.com" /></a>   ## Convex set의 종류 *convex set*의 예는 다음과 같습니다.  <a href="https://imgur.com/wq0WY58"><img src="https://i.imgur.com/wq0WY58.png" width="450px" title="source: imgur.com" /></a>  *Norm ball*의 예시는 다음과 같습니다. ($x_1, x_2$의 L2 norm, *radius* $y$에 대한 집합) $y$축을 기준으로 잘라보면 그 모양이 원 모양이고 볼록해 *convex set*을 만족하리라고 직관적으로 추론해볼 수 있습니다.  <a href="https://imgur.com/GKHpfjL"><img src="https://i.imgur.com/GKHpfjL.png" width="250px" title="source: imgur.com" /></a>  *Hyperplane* $a^Tx=b$ 위의 임의의 두 점 $x_1$, $x_2$ 사이를 잇는 선분은 다시 $a^Tx=b$에 포함됩니다. 따라서 *Hyperplane*은 *convex set*입니다. 마찬가지 이유로 *Halfspace*, *Affine space* 또한 *convex set*이 됩니다. *Polyhedron*은 다음과 같이 정의되며 그 예시는 다음 그림과 같습니다. - {$x$\|$Ax≤b$} <a href="https://imgur.com/tGrzXL3"><img src="https://i.imgur.com/tGrzXL3.png" width="300px" title="source: imgur.com" /></a> 행렬 $A$에 벡터 $x$를 내적한 결과인 $b$는 벡터일 것입니다. 이를 잠시 다시 생각해보면 선형부등식 여러 개가 한꺼번에 적용된 거라고 보아도 될 것 같습니다. 예를 들어 '행렬 $A$의 첫번째 벡터와 $x$를 내적한 결과는 벡터 $b$의 첫번째 스칼라값보다 작거나 같다'는 식으로 말이죠.  *Polyhedron*은 **선형계획법(linear)**에서 중요하게 다뤄진다고 하는데요. 각각의 선형부등식이 제약식 역할을 수행하며 결과적으로 *Polyhedron*은 해당 제약 조건 하의 가능해(possible solutions) 영역이 된다는 것입니다. 어쨌거나 *Polyhedron* 또한 *convex set*입니다. *simplex*는 삼각형 또는 사면체(tetrahedron)의 일반화 버전이라고 합니다. *simplex* 역시 *convex set*입니다.  <a href="https://imgur.com/uLioyc4"><img src="https://i.imgur.com/uLioyc4.png" width="500px" title="source: imgur.com" /></a>   ## convex set의 성질 *convex set*과 관련해 두 가지 중요한 정리가 있습니다. 첫번째는 *sepaating hyperplane theorem*입니다. 두 개의 겹치지 않는(disjoint) *convex set*을 분리해주는 하이퍼플레인(hyperplane)이 존재한다는 것입니다. 아래 그림에서 $D$와 $C$를 가르는 벡터 $a$가 바로 그러한 역할을 하는 하이퍼플레인입니다.  단 여기에서 $D$와 $C$는 **닫힌집합**(closed set, 스스로의 경계를 모두 포함하는 위상공간의 부분집합)이어야 하며, 둘 중 하나가 **유계집합**(bounded set, 유한한 영역을 가지는 집합)이어야 합니다.  <a href="https://imgur.com/AXf0pbp"><img src="https://i.imgur.com/AXf0pbp.png" width="300px" title="source: imgur.com" /></a>  두번째는 *supporting hyperplane theorem*입니다. *convex set*의 경계 점을 지나는 접선이 항상 존재한다는 것입니다. 다음 그림과 같습니다.  <a href="https://imgur.com/NGqIA7I"><img src="https://i.imgur.com/NGqIA7I.png" width="250px" title="source: imgur.com" /></a>   ## convexity를 보존하는 연산 *convex set* $C$와 $D$에 대해 다음 연산(operation)은 *convexity*를 보존합니다. 다시 말해 $C$와 $D$가 *convex set*이라는 사실이 증명돼 있고, 다음 연산을 수행한다면 연산 수행 결과로 나타난 새로운 집합은 별도의 증명 없이도 *convex set*이라는 겁니다. - **intersection**(교집합) - **scaling and translation**(스칼라곱, bias 더하기) : $C$가 *convex set*이라면 $aC+b$ 또한 *convex set* ($a,b$는 스칼라) - **affine images and preimages** : $f(x)=Ax+b$이고 $C$가 *convex set*이라면 $f(C)$ 또한 *convex set*, $f(x)=Ax+b$이고 $D$가 *convex set*이라면 $f^{-1}(D)$ 또한 *convex set* 이밖에 다음 연산도 *convexity*를 보존합니다.  <a href="https://imgur.com/CKJWcgD"><img src="https://i.imgur.com/CKJWcgD.png" width="450px" title="source: imgur.com" /></a>
s2s␞ 이번 포스팅에서는 **Sequence-to-Sequence** 모델로 '뉴스 제목 추출하기'를 해보려고 합니다. 결론부터 말씀드리자면 완벽한 실험 결과가 나온 건 아니고요, 제가 삽질했던 점들을 중심으로 S2S 모델의 특징과 한계 등에 대해 이야기해볼까 합니다. 자 그럼 시작하겠습니다!  ## Sequence-to-Sequence? Sequence-to-Sequence 모델(S2S)은 **Recurrent Neural Network**의 가장 발전된 형태의 아키텍처입니다. **[LSTM](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)**, **GRU** 등 RNN cell을 길고 깊게 쌓아서 복잡하고 방대한 시퀀스 데이터를 처리하는 데 특화된 모델이죠. 실제로 S2S는 영어-한국어, 한국어-일본어 등 기계번역에 쓰이고 있다고 합니다. 이 모델은 2014년 이 [논문](https://arxiv.org/abs/1406.1078)에서 처음 소개가 됐는데요, 구글 **[텐서플로우](https://www.tensorflow.org/tutorials/seq2seq)**에서도 이를 구현한 코드를 공개해 눈길을 끌고 있습니다. 이번 포스팅은 기본적으로 텐서플로우 예제들을 커스터마이징해서 만들었습니다. <a href="http://imgur.com/6mbfPZR"><img src="http://i.imgur.com/6mbfPZR.png" width="600px" title="source: imgur.com" /></a> S2S는 크게 **인코더(encoder)**와 **디코더(decoder)** 두 파트로 나뉩니다. 영어를 한국어로 변환하는 기계번역을 예로 들어보겠습니다. 인코더는 **소스랭귀지(source language)**인 영어 텍스트를 처리합니다. 디코더는 **타겟랭귀지(target language)**인 한국어 텍스트를 맡게 되죠. 디코더의 입력은 이 모델 정답에 해당하는 한국어 텍스트이며 출력 또한 한국어 텍스트입니다. **\<go>**와 **\<eos>**는 각각 정답 시작과 끝을 알리는 일종의 기호라고 보시면 되겠습니다. 인코더와 디코더의 입출력과 관련해 한번 예를 들어보겠습니다. > 인코더 입력 : Good morning! > 디코더 입력 : \<go> 좋은 아침입니다! > 디코더 출력 : 좋은 아침입니다! \<eos> 인코더는 소스랭귀지 정보를 압축합니다. 디코더는 인코더가 압축해 보내준 정보를 받아서 타겟랭귀지로 변환해 출력합니다. 다만 학습과정과 예측(테스트)과정이 조금 다릅니다. 학습과정에서 디코더는 인코더가 보내온 정보와 실제 정답('\<go>좋은 아침입니다!')를 입력으로 받아 '좋은 아침입니다\<eos>'를 출력합니다.  예측 과정에서 디코더는 인코더가 보내온 정보와 '\<go>'만 입력으로 받아 결과물을 차례대로 출력합니다. 띄어쓰기를 기준으로 인풋을 만든다면 예측 과정에서의 디코더가 내놓는 첫 결과물은 '좋은'이 되겠지요. 예측 과정에서의 디코더는 직전에 예측한 '좋은'이라는 결과를 다시 자신의 다음 단계 입력으로 넣어 '아침입니다'를 출력하게 됩니다.  디코더가 예측 과정에서 자신의 직전 출력(좋은)을 다음 입력으로 다시 넣는 이유는 예측 단계에선 학습 때와는 달리 정답이 없기 때문입니다. 그래야 정답이 주어지지 않은 상태(예컨대 구글 번역기에 우리가 번역하고 싶은 문장을 입력할 때)에서도 예측이 가능해 집니다.  ## 문제 정의 <a href="http://imgur.com/GAa8ZUh"><img src="http://i.imgur.com/GAa8ZUh.png" width="500px" title="source: imgur.com" /></a> 자, 그럼 이번 포스팅의 목적인 '뉴스 제목 생성'을 위 아키텍처에 적용해 봅시다. 위 그림처럼 **인코더에 뉴스 본문을 넣고 디코더에 제목을 넣는 것이죠.** 왜 공들여 이런 일을 하냐고요? 제 포부는 원대했습니다. 정답이 있는 데이터만 S2S 학습이 가능합니다. 하지만 자연언어처리 분야에서 정답이 있는 데이터를 얻기는 매우 어렵습니다. 그런데 뉴스 기사는 다르죠. 뉴스는 다른 분야 말뭉치 대비 양질이면서도 하루에도 수백 수천건씩 쏟아집니다. 조간신문이나 방송에 보도된 뉴스는 제목을 다는 데도 수많은 전문인력이 투입되죠. 비교적 수월하게 구할 수 있는 한국어 말뭉치 중에는 이만한 컨텐츠가 없다고 생각했습니다.  게다가 뉴스 제목은 대체로 본문 내용을 전반적으로 포괄하는 경향이 있습니다. 뉴스 본문이라는 문서를 요약하는 학습모델을 만들 때 제목을 정답으로 놓고 모델링을 하면 참 좋겠다는 생각을 했습니다. S2S는 시퀀스 형태의 인풋을 받아 또 다시 시퀀스 형태의 아웃풋을 내놓으므로 요약 결과가 완결된 문장 형태를 지닐 수 있지 않을까 하는 기대를 하기도 했습니다. 뒤에 설명드리겠지만 시작은 아주 창대했답니다.  ## 데이터 전처리  우선 웹에서 2016년 1월초 사흘치 기사 1000건을 모았습니다~~순Siri 기사를 보고 싶지 않아서는 절대 아닙니다~~. 원래 기사는 이렇게 생겼습니다. > **경기도 준예산 사태…‘보육대란’ 이미 시작됐다** > > [한겨레] *해법 안보이는 ‘누리예산’* > > *경기도의회 연말 여야 몸싸움* > > *남경필 지사·강득구 도의회 의장* > > *준예산 사태 논의에도 접점 못찾아* > > *당장 이달부터 누리과정 지원중단* > > *교육부는 계속 교육청만 압박* > > 지난 12월31일 경기도의회에서 여야 의원들의 몸싸움이라는 최악의 사태까지 연출한 누리과정(만 3~5살 무상보육) 사태가 새해에도 해법을 찾지 못한 채 정부와 교육청, 시·도의회, 여야 간 타협 없는 대치 국면으로 이어질 전망이다. (하략) 우선 위 기사를 제목과 본문으로 나눴습니다. 본문에는 중간제목으로 보이는 내용들(이탤릭체)도 일부 보입니다만 일일이 손으로 거르기보다는 이대로 넣어도 학습이 가능할 것이라는 근거없는 희망으로 모두 본문에 포함했습니다. 다음은 토크나이징, 노말라이즈 등 전처리를 할 차례인데요. **[KoNLPy](http://konlpy.org/en/v0.4.4/)** 같은 오픈소스 형태소 분석기를 사용하려고 했습니다. 그러나 형태소 분석 과정에서 잘못된 태깅으로 말뭉치 정보가 왜곡되거나 손실될 염려를 배제하기 위해 다른 방법을 쓰기로 했습니다. 단어를 띄어쓰기 기준으로 나누고 3글자까지만 잘라서 노말라이즈를 하는 겁니다. 이렇게 하면 아래 예시의 토큰들을 한 단어로 취급합니다. > **감정가** > > **감정가**의 > > **감정가**격에 > > **감정가**격은 > > **감정가**격이 텍스트 노말라이즈를 하는 근본 이유는 단어수를 줄여 분석의 효율성을 높이기 위해서입니다. 위 다섯개 단어를 각각 다른 단어로 보고 분석하면 물론 정확성은 높아지겠지만 계산복잡성 또한 증가합니다. 어느 순간엔 정확성 상승 대비 분석 비용이 지나치게 높아지게 될 겁니다. 실제로 단어 단위 S2S 모델은 학습 말뭉치의 단어 수가 분류해야할 클래스의 개수가 되기 때문에 단어수가 지나치게 크면 학습의 질은 물론 속도도 급격하게 감소하는 문제가 있습니다. 이 때문에 단어 수를 적절하게 줄일 필요가 있습니다. 저의 경우 위와 같이 노말라이즈를 했음에도 불구하고 단어 개수가 무려 6만5016개나 됐습니다(ㅠㅠ).  자 그럼 구체적으로 예시를 볼까요? 사흘치 기사에서 영어와 숫자, 문장부호, 줄바꿈문자 등을 제거한 기사는 아래와 같은 형태가 됩니다. (title, contents는 변수명이므로 무시하고 보세요) > title: 경기도 준예산 사태 보육대란 이미 시작됐다 > contents: 해법 안보이 누리예산 경기도의회 연말 여야 몸싸움 남경필 지사 강득구 도의회 의장준예산 사태 논의에도 접점 못찾아 당장 이달부터 누리과정 지원중단 교육부는 계속 교육청만 압박 지난 월 일 경기도의회에서 여야 의원들의 몸싸움이라는 최악의 사태까지 연출한 누리과정 만 살 무상보육 사태가 새해에도 해법을 찾지 못한 채 정부와 교육청 시 도의회 여야 간 타협 없는 대치 국면으로 이어질 전망이다 (하략) 이제 S2S에 넣은 인풋을 본격적으로 만들어볼까요? S2S엔 텍스트를 숫자로 바꾸어 넣어야 합니다. '경기도'를 0, '준예산'을 1, '사태'를 2... 이렇게요. 이렇게 단어를 숫자로 바꾸기 위해서는 단어와 숫자가 매칭된 사전(dictionary)이 있어야 합니다. 학습 말뭉치인 사흘치 기사에 한번이라도 나온 모든 단어들을 세어서 이를 숫자로 매핑하는 것이죠. 예측 과정에선 숫자를 단어로 바꿔야 하기 때문에 숫자와 단어가 매핑된 사전도 별도로 만들었습니다. > **word_to_ix** > > {'학생비자를': 60946, > '답답함이': 13623, > (중략) > '감정가': 979, > '감정가의': 979, > '감정가격에': 979, > (하략) } > **ix_to_word** > > {0: '가', > 1: '가가갤', > 2: '가감', > 3: '가거나', > (중략) > 979: '감정가' > (하략) } 눈썰미가 있는 분들은 이미 눈치채셨겠지만 저같은 경우엔 학습 말뭉치를 바로 3글자로 줄인게 아니라 단어를 숫자로 바꿔주는 사전인 **word_to_ix**에 모든 단어를 넣되 앞에서부터 3글자가 겹치는 단어들은 같은 인덱스를 주어서 단어가 숫자로 변환될 때 자연스럽게 3글자로 노말라이즈될 수 있도록 했습니다. 이렇게 하면 원래 데이터가 어떻게 생겼는지 확인하기 쉬워서 이렇게 한건데 그냥 바로 3글자로 줄여도 됩니다. 어쨌든 '감정가', '감정가의', '감정가격에'라는 단어는 모두 979라는 숫자로 바뀌게 되고요, 나중에 숫자를 단어로 바꾸고 싶을 땐 979가 '감정가'로 변환되게 됩니다. 위 기사 본문의 경우 아래처럼 변환됩니다. > [15087, 42582, 3168, 1162, 3168, 10661, 44455, 47701, (하략) ] 위 데이터를 모델에 넣기 전에 하나 고려해야할 것이 있습니다. 바로 데이터 차원수인데요. RNN의 경우 시퀀스 길이에 유연한 네트워크 구조이긴 합니다만, S2S처럼 복잡하고 방대한 네트워크인 경우에는 시퀀스 길이를 어느 정도 맞춰주는 게 좋은 것 같습니다. 그래서 저는 디코더에 넣을 시퀀스 길이를 뉴스 제목 최대 길이(18개 단어)로 맞췄고요, 인코더에 넣을 시퀀스 길이를 기사 앞부분 100개 단어~~절대 메모리가 부족해서가 아닙...~~로 맞췄습니다. 만약 이들 길이보다 데이터 시퀀스 길이가 짧다면 **\<PAD>**를 넣어 길이를 맞춰줬습니다. \<PAD> 넣는 법은 쉽습니다. word_to_ix와 ix_to_word에 각각 \<PAD>라는 요소를 추가해주고 길이가 부족한 데이터에 끼워 넣었습니다.  ## 모델 구현 <a href="http://imgur.com/wzZZ9E3"><img src="http://i.imgur.com/wzZZ9E3.png" width="600px" title="source: imgur.com" /></a> 제가 사용한 S2S의 디테일한 설정들은 위 그림에 요약돼 있습니다. 아시다시피 녹색으로 표시된 은닉층에 어떤 cell을 쓸지 선택할 수 있지 않습니까? 저의 경우 cell은 두 가지를 실험했고요, 바로 LSTM/GRU입니다. 은닉층을 여러 개 쌓을 수도 있는데요, 저는 1개(single) 혹은 3개(multi)를 실험했습니다. 중요한 부분을 중점적으로 검토하게 해 분석의 정확도를 높이는 **[attention ](https://arxiv.org/abs/1409.0473)** 기법을 적용/미적용한 것의 차이도 실험했습니다. 데이터 시퀀스의 순방향과 역방향 정보를 모두 고려하는 **bidirectional** 방법론 가운데 이번 실험에서는 ~~메모리 문제로~~후자만 차용을 했습니다. 다시 말해 인코더 입력 시퀀스를 모델에 입력으로 넣을 때 역방향으로 넣었다는 이야기입니다(뉴스 본문 첫 단어가 인코더의 맨 마지막 입력이 됨). 아래는 텐서플로우 예제에서 제가 커스터마이징한 코드입니다. <script src="https://gist.github.com/ratsgo/0f45e1500c395f7616787185db448015.js"></script> 천천히 설명을 드리면 tool.loading_data라는 함수는 아래와 같은 형식의 CSV(utf-8)를 읽어들여 title과 contents로 나누어 줍니다. tool.make_dict_all_cut은 학습 말뭉치를 읽어들여 위 예시처럼 word_to_ix와 ix_to_word를 생성해줍니다.  multi라는 파라메터는 은닉층을 1개만 쌓을건지 여러개 쌓을건지 지정하는 변수입니다. forward_only라는 변수는 학습 때는 false, 추론(테스트) 때는 true로 지정합니다. vocab_size는 말뭉치 사전 단어수, num_layers는 은닉층 개수, learning_rate는 학습률, batch_size는 1회당 학습하는 데이터 수(배치 크기)를 의미합니다.  encoder_size는 인코더에 넣을 입력 시퀀스의 최대 길이, decoder_size는 디코더에 넣을 시퀀스의 최대 길이입니다. tool.check_doclength 함수는 입력 컨텐츠의 최대 길이를 반환합니다. tool.make_inputs는 '데이터 전처리'에서 설명드렸듯 단어를 숫자로 바꾸는 과정을 한번에 해주는 함수입니다.  이제 클래스 'seq2seq'에 정의한 네트워크 구조를 살펴보겠습니다.  우선 변수 선언 부분입니다. encoder_size만큼의 placeholder를 생성해 encoder_inputs를 만듭니다. 마찬가지로 decoder_inputs, targets, target_weights를 만듭니다. target_weights는 target(제목)에 대응하는 요소가 \<PAD>일 경우 0, \<PAD>가 아닐 경우 1로 채워넣은 리스트입니다. target_weights는 정답에 끼어있는 \<PAD>가 학습에 반영되지 않도록 도와주는 값이라고 이해하시면 될 것 같습니다. 네트워크를 선언한 부분을 보겠습니다. cell은 'tf.nn.rnn_cell.GRUCell'이라고 선언했습니다. tf.nn.rnn_cell.LSTMCell'이라고 선언하면 GRU를 간단하게 LSTM cell로 변환 가능합니다. 층을 여러개 쌓고 싶으면 'tf.nn.rnn_cell.MultiRNNCell'이라는 함수를 쓰면 됩니다. 이제 학습과 예측 과정을 살펴보겠습니다. 아래는 이해를 돕기 위한 그림입니다. <a href="http://imgur.com/tqXzH1v"><img src="http://i.imgur.com/tqXzH1v.png" width="500px" title="source: imgur.com" /></a> 학습 과정을 살펴보겠습니다. if not forward_only 구문이 실행되는 부분입니다. 'tf.nn.seq2seq.embedding_attention_seq2seq' 함수는 outputs를 반환합니다. 'feed_previous'에 False를 씁니다. **attention**을 쓰지 않으려면 'tf.nn.seq2seq.embedding_seq2seq' 함수를 사용해 보세요. 이 output에 W를 내적하고 b를 더해 logit을 만들고요, 리를 바탕으로 **cross-entropy loss**를 구합니다. 여기서 주목할 점은 cross-entropy loss에 target_weight를 곱해준다는 점입니다. target_weight는 \<PAD>인 경우 0이기 때문에 \<PAD>에 해당하는 cross-entropy loss는 무시됩니다.  추론 과정을 살펴보겠습니다. else: 구문이 실행되는 부분입니다. 'tf.nn.seq2seq.embedding_attention_seq2seq' 함수의 'feed_previos'에 True를 집어넣습니다. 디코더가 직전 과정에서 내뱉은 결과를 다음 과정의 인풋으로 받아들여 추론하라는 지시입니다. 나머지는 일반적인 딥러닝 네트워크 구조와 크게 다르지 않습니다. 아래는 위 코드가 import해서 사용하는 tool.py입니다. tool.py에 있는 모든 코드들은 제가 직접 만들었습니다. <script src="https://gist.github.com/ratsgo/81256d786dac5b41f84c49ac5d452f0f.js"></script>  ## 실험 결과 ### 학습 **3-layers, encoder_size(100), decoder_size(20), GRU(300차원), attention, batch_size=16** 괄호 안은 정답입니다 ``` §Iter 500 : 신당 신당 신당 신당 신당 <E><E> <E> <E> <E> <E> <E> <E> <E><E> <E> <E> <E> (안철수 신당 호남 위 새누리당 수도권 영남 충청서선두) §Iter 1000 : 윤미옥 김윤정 김윤정 두 두 두 두 향토방 <E><E> <E> <E> <E> <E> <E> <E> <E><E> (윤미옥 김윤정 예비역 소령 두 번째 군대 인생 향토방위 수준 높이겠다) §Iter 1500 : 삼성베트남 베트남 휴대폰 휴대폰 부품 부품 <E><E> <E> <E> <E> <E> <E> <E> <E><E> <E> (삼성 베트남 공장 덕분에 휴대폰 부품 수출 급증) §Iter 2000 : 롯데 지분지분 취득 <E><E> <E> <E> <E> <E> <E> <E> <E><E> <E> <E> <E> <E> (롯데 롯데제과 지분 취득) §Iter 2500 : 윤병세 윤병세 국민적 국민적 저항자화자찬 자화자찬 자화자찬 삶 삶 삶 높은 높은 높은 질 없는전 전 (윤병세 장관은 국민적 저항 외면 자화자찬) ``` ### 예측  | 1-layer  | 3-layers | 3-layer + attention | 정답           | | :-------- | :------- | :------------------ | :---------------------- | | 대북 도발 김정은 | 확성기 높이다 | 대북 방송        | 국민 단단한 안보 의식이 추가 도발 막는다 | | 최경환 누리  | 누리 예산  | 누리 예산        | 누리과정 예산 일단 늘어나 교부금 활용하라 | | 삼성    | 삼성 가전  | 너마저 실적 반도체 불투명   | 반도체 주춤 삼성전자 영업이익 감소   | 위 결과 표를 보면 아시겠지만 학습은 비교적 잘 되는 것처럼 보입니다. iter 1000번(배치를 1000번 넣었다는 뜻, 1000개 기사를 학습데이터로 넣었으므로 전체 데이터 기준으로는 16번 학습)만에 어느 정도 제목 윤곽이 나오는 것을 볼 수 있습니다. 학습시 디코더 입력에 실제 정답을 넣어서 이렇게 잘 되는 것 같기도 합니다. 하지만 학습에 쓰이지 않은 데이터를 넣어 예측한 결과를 보면 조금 아쉽습니다. 일단 학습 과정보다는 그 품질이 확실히 떨어집니다. 그 원인은 다양하겠지만 뉴스 자체의 특성 때문 아닐까 생각합니다. 같은 사건을 보도하더라도 완전히 같은 내용의 기사는 없으며, 그 본문이 거의 비슷하더라도 언론사마다 제목은 크게 다른 경우가 많습니다. 다시 말해 'Good morning!'의 한국어 표현은 '좋은 아침입니다!', '안녕하세요' 등 몇 가지 안되는 '닫힌 정답'이라면 뉴스 제목은 언론사마다 천차만별인 '열린 정답'이라는 것입니다. 학습데이터 양이 작아서인지 3개층, attention 모델 등 복잡한 네트워크가 1-layer와 비슷한 성능을 내는 점 또한 확인할 수 있었습니다.  아울러 이번에 실험하면서 S2S에 대해 가장 크게 느낀 점은 S2S는 예측시 비교적 일반적인 단어를 출력하는 경우가 많다는 점입니다. 위 결과에도 알 수 있듯 경제 기사엔 '삼성', 안보 기사엔 '대북', 경제정책 기사엔 '예산' 같은 일반적인 단어를 예측하고 있습니다. 이는 고차원의 입력데이터를 추상화하여 표현하는 S2S만의 특징이 아닌가 생각이 듭니다. 제가 듣기로 **챗봇(chatbot)** 구현을 위해 대화 데이터를 S2S 입력으로 줄 경우, '아…', '네…', '그럼요' 정도의 답을 내놓게 된다고 하는군요. '아…', '네…', '그럼요' 같은 단어들은 어떤 대화에서도 성립되는, 오답이 아닌 답변이기 때문인 것 같은데요. 앞으로 연구해볼 만한 주제라는 생각이 듭니다.   ## 향후 계획 제 컴퓨터(i5-3690, 32GB RAM, GTX 970) 기준으로 예측해야할 단어수가 6만개가 넘어가면 메모리 부족으로 학습 자체가 불가능했습니다. 단어수를 효과적으로 줄이거나 하드웨어 업그레이드 등을 통해 추가로 실험할 계획입니다. 정치, 경제, 사회 등 도메인별로 학습해볼 생각도 있습니다. 이번 포스팅 관련해서 제언이나 질문 있으시면 언제든지 메일이나 댓글로 알려주시기 바랍니다. 지금까지 읽어주셔서 감사합니다.
insmersort␞ 이번 글에서는 **삽입정렬(Insertion Sort)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김선욱 교수님과 역시 같은 대학의 김황남 교수님 강의를 정리했고, 코드는 [이곳](https://github.com/TheAlgorithms/Python)을 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 삽입정렬 삽입정렬은 다음과 같은 방식으로 동작합니다. 그림으로 예를 들어보겠습니다.  <a href="https://imgur.com/0CZLkCd"><img src="https://i.imgur.com/0CZLkCd.png" title="source: imgur.com" /></a>  (a)부터 볼까요? 비교 대상 key는 두번째 요소(2)부터 시작합니다. 해당 key의 왼쪽 요소와 크기 비교를 합니다. 따라서 (a)에서는 key(2)와 5를 비교하게 됩니다. 여기에선 5가 크므로 key(2)와 자리를 바꿔 줍니다. | key index | key value |   정렬 이전    |   정렬 이후    | | :-------: | :-------: | :--------------: | :--------------: | |   2   |   2   | 5, 2, 4, 6, 1, 3 | 2, 5, 4, 6, 1, 3 | (b)에서 key는 세번째 요소(4)입니다. 해당 key 왼쪽 요소인 5와 비교를 합니다. 여기에선 5가 크므로 key(4)의 자리를 바꿔 줍니다. 이번에는 2와 비교할 차례입니다만, key(4)가 2보다 크므로 자리를 바꿀 필요가 없습니다. | key index | key value |   정렬 이전    |   정렬 이후    | | :-------: | :-------: | :--------------: | :--------------: | |   3   |   4   | 2, 5, 4, 6, 1, 3 | 2, 4, 5, 6, 1, 3 | (c)에서 key는 네번째 요소(6)입니다. 해당 key 왼쪽 요소인 5와 비교를 합니다. key(6)가 5보다 크므로 자리를 바꿀 필요가 없습니다. 삽입정렬에서는 key의 왼쪽 요소는 이미 정렬된 상태이므로 더 이상 연산을 수행하지 않습니다.  <a href="https://imgur.com/ajnGDWX"><img src="https://i.imgur.com/ajnGDWX.png" title="source: imgur.com" /></a>  (d)에서 key는 다섯번째 요소(1)입니다. 해당 key 왼쪽 요소인 6과 비교를 합니다. 여기에선 6이 크므로 key(1)의 자리를 바꿔 줍니다. 같은 방식으로 key(1)를 맨 처음 자리로 보내고 2, 4, 5, 6을 오른쪽으로 한칸씩 옮깁니다. | key index | key value |   정렬 이전    |   정렬 이후    | | :-------: | :-------: | :--------------: | :--------------: | |   5   |   1   | 2, 4, 5, 6, 1, 3 | 2, 4, 5, 1, 6, 3 | |   4   |   1   | 2, 4, 5, 1, 6, 3 | 2, 4, 1, 5, 6, 3 | |   3   |   1   | 2, 4, 1, 5, 6, 3 | 2, 1, 4, 5, 6, 3 | |   2   |   1   | 2, 1, 4, 5, 6, 3 | 1, 2, 4, 5, 6, 3 | (e)에서 key는 여섯번째 요소(3)입니다. 해당 key 왼쪽 요소인 6과 비교를 합니다. 여기에선 6이 크므로 key(3)의 자리를 바꿔 줍니다. 같은 방식으로 key(3)을 세번째 자리로 보내고 4, 5, 6을 오른쪽으로 한칸씩 옮깁니다. | key index | key value |   정렬 이전    |   정렬 이후    | | :-------: | :-------: | :--------------: | :--------------: | |   6   |   3   | 1, 2, 4, 5, 6, 3 | 1, 2, 4, 5, 3, 6 | |   5   |   3   | 1, 2, 4, 5, 3, 6 | 1, 2, 4, 3, 5, 6 | |   4   |   3   | 1, 2, 4, 3, 5, 6 | 1, 2, 3, 4, 5, 6 | 이런 방식으로 전체 데이터를 모두 고려하면 삽입정렬이 종료됩니다.   ## 파이썬 구현 삽입정렬을 파이썬 코드로 구현한 결과는 다음과 같습니다. ```python def insertion_sort(collection):   for index in range(1, len(collection)):     while 0 < index and collection[index] < collection[index - 1]:       collection[index], collection[         index - 1] = collection[index - 1], collection[index]       index -= 1   return collection ```   ## 삽입정렬의 계산복잡성 삽입정렬의 의사코드와 계산 단계별 계산비용을 도식화한 표는 다음과 같습니다. 여기에서 $t_j$는 $j$번째 key를 정렬할 때 필요한 비교 연산 횟수를 가리킵니다. 예컨대 (c)에선 key(6)와 5, 딱 한 번만 비교하고 정렬이 끝났으니 $t_4$는 1입니다. 하지만 (d)에선 key(1)의 정렬을 위해 무려 5번이나 비교를 해야 했습니다. $t_j$는 데이터의 정렬 상태에 영향을 받는 값으로, 최소 1, 최대 $j$의 범위를 갖습니다.  <a href="https://imgur.com/znqmylP"><img src="https://i.imgur.com/znqmylP.png" width="400px" title="source: imgur.com" /></a>  그러면 정렬 대상 데이터 개수가 $n$이고, best case(즉 모든 $t_j$가 1인 상황)에 대해 계산복잡도를 구해보겠습니다. 다음 식과 같습니다.  $$ T(n)={ c }_{ 1 }n+{ c }_{ 2 }(n-1)+{ c }_{ 4 }(n-1)+{ c }_{ 5 }(n-1)+{ c }_{ 8 }(n-1) $$  자세히 보면 $an+b$ 형태의 1차식입니다. 따라서 best case일 때 삽입정렬의 계산복잡도는 $n$에 대해 선형적으로 증가합니다. 이번엔 worst case(즉 모든 $t_j$가 $j$인 상황)에 대해 살펴봅시다. 다음 식과 같습니다.  $$ T(n)={ c }_{ 1 }n+{ c }_{ 2 }(n-1)+{ c }_{ 4 }(n-1)+{ c }_{ 5 }(\frac { n(n+1) }{ 2 } -1)\\+{ c }_{ 6 }(\frac { n(n-1) }{ 2 } )+{ c }_{ 7 }(\frac { n(n-1) }{ 2 } )+{ c }_{ 8 }(n-1) $$  위 식은 $an^2+bn+c$ 형태의 2차식입니다. 따라서 worst case일 때 삽입정렬의 계산복잡도는 $n^2$에 비례하여 증가합니다. 따라서 삽입정렬의 계산복잡도는 best와 worst case 어딘가쯤에 위치하게 될 겁니다. 그런데 알고리즘의 계산복잡도를 구할 때 사실 이렇게까지 자세히 뜯어볼 필요는 없습니다. 가능한 경우의 수를 고려해 어림짐작하는 방법도 얼마든지 있어야 하니까요. best case일 때는 데이터 개수 $n$개만큼의 비교 연산을 수행하면 됩니다. worst case일 때는 $j$가 1일 때는 $t_j$가 1, 2일 땐 (1+2), 3일 땐 (1+2+3)... 이렇게 되므로 $Σn=n(n+1)/2$이 되는 걸 확인할 수 있습니다. 아울러 $T(n)$의 계수($c$)들은 컴퓨팅 파워 등에 따라 커질 수도, 작아질 수도 있습니다. 다만 보통의 알고리즘은 데이터 개수($n$)에 민감하기 때문에 계산복잡성을 구할 때는 계수는 보통 무시하게 됩니다. 
disjointset␞ 이번 글에서는 **디스조인트 셋(Disjoint Set)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의와 위키피디아, 그리고 [이곳](http://bowbowbow.tistory.com/26)을 참고해 정리하였음을 먼저 밝힙니다. 예시 그림과 파이썬 코드는 [이곳](http://interactivepython.org/runestone/static/pythonds/SortSearch/TheShellSort.html)을 참고하였습니다. 그럼 시작하겠습니다.   ## concept 디스조인트 셋이란 서로 중복되지 않는 부분 집합들로 나눠진 원소들에 대한 정보를 저장하고 조작하는 자료 구조입니다. 디스조인트 셋은 전체 집합이 있을 때 구성 원소들이 겹치지 않도록 분할(partition)하는 데 자주 쓰입니다. 이와 관련해 몇 가지 용어를 살펴보겠습니다. - **셋(set)**은 개체들의 집합입니다. (리스트 등과 달리 순서는 고려하지 않음) - 셋 $A$의 모든 원소가 셋 $B$에 포함될 때 $A$를 $B$의 **부분집합(subset)**이라 합니다. 이 때 $B$는 $A$의 **초월집합(superset)**이라 합니다. - 셋 $A$와 셋 $B$가 공유하는 원소가 하나도 없을 때 $A$와 $B$를 *mutually disjoint*하다고 합니다. - 임의의 셋을 **분할(partition)**한다는 건 각 부분집합이 다음 두 가지 속성을 만족하는 `디스조인트 셋`이 되도록 셋을 쪼개는 걸 뜻한다. (1) 파티션된 부분집합을 합치면 원래의 셋이 된다. (2) 파티션된 부분집합끼리는 *mutually disjoint*, 즉 겹치는 원소가 없다. 예컨대 $S=\{1,2,3,4\}$이고, $A=\{1,2\}$, $B=\{3,4\}$, $C=\{2,3,4\}$, $D=\{4\}$라면 $A$와 $B$는 $S$의 분할입니다. 이 때 $A$와 $B$가 디스조인트 셋입니다. 하지만 $A$와 $C$는 $S$의 분할이 아닙니다. 겹치는 원소가 있기 때문입니다. $A$와 $D$ 또한 $S$의 분할이 아닙니다. 둘을 합쳐도 $S$가 되지 않기 때문입니다.   ## operations 디스조인트 셋은 세 가지 연산이 있는데요. *make-set*은 초기화 연산이므로 *union*과 *find*가 핵심이라고 할 수 있겠습니다. - **make-set(x)** : $x$를 유일한 원소로 하는 새로운 셋을 만듭니다. - **union(x, y)** : $x$가 속한 셋과 $y$가 속한 셋을 합칩니다. - **find(x)** : $x$가 속한 셋의 대표값(루트노드 값)을 반환합니다. 예를 들어 보겠습니다. $A=\{3,4\}$인 디스조인트 셋이 이미 만들어져 있다고 칩시다. 이 경우 첫번째 들어간 원소인 3이 루트노드가 되며 3이 $A$를 대표하는 값이 됩니다. 다음과 같습니다.  <a href="https://imgur.com/yYgglFq"><img src="https://i.imgur.com/yYgglFq.png" width="150px" title="source: imgur.com" /></a>  *find(4)*는 4가 속한 셋의 대표값을 출력하라는 뜻입니다. 따라서 이 예에서는 3이 됩니다. 마찬가지로 *find(3)* 또한 출력 결과가 3입니다.  이번엔 다른 디스조인트 셋 $B=\{1,2\}$가 있다고 치겠습니다. $B$의 대표값은 루트노드인 3입니다. $A$와 $B$를 합칠 때는 루트노드들끼리 이어줍니다. 다음과 같습니다.  <a href="https://imgur.com/WQvkPVn"><img src="https://i.imgur.com/WQvkPVn.png" width="150px" title="source: imgur.com" /></a>  새롭게 만든 디스조인트 셋의 루트노드는 1입니다. 따라서 예컨대 4가 속한 셋의 대표값을 출력하라는 $find(4)$를 수행하면 출력 결과가 1이 됩니다.   ## array로 구현 디스조인트 셋의 세 가지 기본연산을 배열(array)로 구현해보겠습니다. $A=\{3,4\}$, $B=\{1,2\}$ 이렇게 두 개 디스조인트 셋이 이미 만들어져 있다고 칩시다.  <a href="https://imgur.com/6XBlnGQ"><img src="https://i.imgur.com/6XBlnGQ.png" width="250px" title="source: imgur.com" /></a>  이를 배열로 구현하면 다음과 같습니다. $N$은 입력원소들을 가리킵니다. $S$는 입력원소가 루트노드인지 아닌지, 부모노드가 어떤 위치에 있는지 나타냅니다. 예컨대 `3`과 `1`은 루트노드이기 때문에 이들에 해당하는 $S$의 값이 0입니다. `4`의 부모노드는 $N$의 첫번째 요소, 즉 `3`이라고 표시가 되어 있네요. 마찬가지로 `2`의 부모노드는 $N$의 세번째 요소, 즉 `1`입니다. - $N=[3,4,1,2]$ - $S=[0, 1, 0, 3]$ *union* 연산을 하면 $S$가 다음과 같이 바뀝니다.  <a href="https://imgur.com/WQvkPVn"><img src="https://i.imgur.com/WQvkPVn.png" width="150px" title="source: imgur.com" /></a> - $S=[0, 1, 1, 3]$ 그렇다면 *union(x,y)* 연산의 계산 복잡성은 얼마나 될까요? 크게 세 가지 단계로 나눠 생각해볼 수 있습니다. - $x$가 속한 디스조인트 셋을 찾아야 합니다 : *find(x)* - $y$가 속한 셋을 찾아야 합니다 : *find(y)* - 찾은 셋을 합칩니다. 그런데 생각해보면 *find* 연산의 계산복잡성은 디스조인트 셋의 원소 수가 $n$개일 때 $O(\log{n})$입니다. 부모노드를 반복적으로 역추적해 루트노드를 찾습니다. 예컨대 잎새노드에서 루트에 이르기까지 일렬로 3-4-5-2-1 이렇게 구성돼 있는 디스조인트 셋이 있다고 할 때 *find(3)*은 엣지를 트리의 높이만큼 네 번 거슬러 올라가야 루트인 1을 찾을 수가 있습니다. *find* 연산을 좀 더 효율적으로 수행하기 위한 방법이 바로 **path compression**인데 조금 있다가 다루겠습니다. *find* 연산을 두 번 수행해 합칠 셋을 찾았다고 칩시다. 그러면 이제 이 두 셋을 합칠 차례입니다. 합치는 방법에는 **union-by-size**와 **union-by-height**가 있는데 바로 다음에서 다루겠습니다.   ## union 임의의 두 디스조인트 셋을 합칠 때는 원소수가 적은 셋을 많은 셋의 서브트리로 합치는 것이 효율적입니다(*union-by-size*). 마찬가지로 트리의 높이가 작은 셋을 큰 셋의 서브트리로 합쳐야 합니다(*union-by-height*). 다음 *union* 연산 때 반드시 *find* 연산을 수행해야 하는데 *find* 연산의 효율성을 높여주기 위해서입니다. 원소수와 트리의 높이는 비례하는 경향이 있고 *find* 연산의 계산복잡성은 이들에 매우 의존적입니다. *union-by-size*와 *union-by-height*를 구현하는 것은 간단합니다. 배열 $S$의 루트노드 정보를 바꾸면 됩니다. 루트노드일 때 0을 넣었던 기존과 달리 다음과 같이 바꿉니다. - *union-by-size* : $-$size of tree - *union-by-height* : $-$height of tree 요컨대 *find* 연산에서 찾은 두 개 디스조인트 셋의 원소수 혹은 높이를 비교해서 더 큰 쪽으로 합쳐줍니다. 이렇게 하면 이후 *find* 연산을 조금 더 효율적으로 수행할 수 있습니다. *union-by-size*와 *union-by-height*의 계산복잡성은 $O(1)$입니다. *find* 연산에서 이미 두 디스조인트 셋의 루트노드를 찾았기 때문에 $S$에서 이 두 루트노드 위치에 저장돼 있는 원소수 혹은 높이를 비교합니다. 둘 중 작은 쪽의 루트노드에 해당하는 $S$의 값을 큰 쪽 루트노드의 인덱스를 가리키도록 바꿉니다. 이 모든 연산이 $O(1)$에 해당합니다.   ## path compression *path compression*은 다음과 같이 모든 노드가 루트를 가리키도록 만드는 것입니다. $S$에 부모노드 인덱스 대신 루트노드를 저장하는 방식입니다. *find* 연산을 수행할 때 트리의 높이만큼 거슬러 올라가야 루트노드를 찾을 수 있는데, 이러한 비효율성을 완화해보자는 취지입니다. *path compression*을 한번 수행해 놓으면 루트노드를 찾는 *find* 연산의 계산복잡성을 확 낮출 수 있습니다.  <a href="https://imgur.com/nUfjebj"><img src="https://i.imgur.com/nUfjebj.png" width="400px" title="source: imgur.com" /></a>
double␞ 이번 글에서는 한국어의 이중주어문에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 현상 관찰 한국어에는 한 문장에 주격 명사구가 두 번 나타나서 주어가 두 번 실현되는 것처럼 보이는 문장이 흔하다고 합니다. 예를 들어보겠습니다. > (1) 토끼가 앞발이 짧다. > > (2) 이 집안이 딸이 귀하다. > > (3) 진이가 의사가 되었다. > > (4) 진이가 의사가 아니다. > > (5) 학생이 세 명이 왔다. 위 예시 문장을 세 가지 유형으로 나누어 살펴보도록 하겠습니다.  ## 1유형 다음 예시는 두번째 명사구만 서술어와 관련되고, 첫째 명사구는 둘째 명사구와 관계를 지니는 경우입니다. > (1) 토끼가 앞발이 짧다. > > (2) 이 집안이 딸이 귀하다. (1)에서 '짧다'라는 서술어는 '앞발이'라는 명사구와만 관계를 가집니다. ('토끼가 짧다'는 의미상 성립하지 않습니다.) 그런데 토끼는 앞발보다 넓은 범위를 포괄하는 개념으로 '대(大)-소(小)'의 의미관계를 보입니다. (2)에서 '귀하다'라는 서술어는 '딸이'라는 명사구와만 관계를 가집니다. '집안'은 '딸'이 사는 장소를 가리키며, 첫째 명사구가 의미상 장소, 방향 등의 관계를 나타냅니다. 1유형과 관련해 국어학계에 다양한 견해가 존재합니다.  우선 둘 모두 주어로 보는 입장입니다. 이 견해에 따르면 (1), (2) 예시는 주어가 2개이고 서술어가 하나인 **단문**에 해당합니다. 그러나 주어 사이의 관계를 명쾌하게 설명하지 못한다는 단점이 있습니다. 주제-평언 구조로 보는 입장도 있습니다. 이 견해에 따르면 앞의 명사구를 **주제**, 뒤의 명사구를 그 주제에 대한 설명을 나타내는 문장의 주어로 봅니다. 따라서 위 예시를 [주제 + \[주어 + 서술어\]] 구조로 분석할 수 있습니다. 그러나 이 견해는 문장 분석시 **정보구조**와 **통사구조** 개념이 혼재돼 있다는 단점이 있습니다. 정보구조와 주제와 관련해서는 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/07/11/senttopic/)을 참고하시면 좋을 것 같습니다. 마지막으로 서술절을 가진 **안은 문장**으로 보는 입장입니다. 학교문법이 이 견해를 채택하고 있습니다. 이 견해에 따르면 (1)의 '앞발이 짧다'는 주어와 서술어를 가지는 절이면서, 동시에 선행하는 주어 명사구 '토끼가'를 서술해주는 서술절로 쓰였다고 분석할 수 있습니다. 즉 [토끼가 \[앞발이 짧다]]의 구조를 가진 것으로 보는 것입니다. 마찬가지로 (2)에서 전체 문장의 주어는 '이 집안이'이고, 그것의 서술어는 '딸이 귀하다'라는 절 형식입니다. '딸이 귀하다'에서의 주어는 '딸이'이고, 서술어는 '귀하다'입니다.  ## 2유형 2유형은 서술어 자체가 두 개의 **논항**(서술어가 요구하는 필수성분)을 요구하여 두 명사구가 실현되며, 그 두 명사구가 서로 다른 **의미역**(명사구 논항이 서술어와 관련하여 지니는 의미 기능)을 갖는 경우를 가리킵니다. 논항과 관련해서는 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/04/29/parsing/)을, 의미역과 관련해서는 [이곳](https://ratsgo.github.io/korean%20linguistics/2017/06/04/thetarole/)을 참고하시면 좋을 것 같습니다. > (3) 진이가 의사가 되었다. > > (4) 진이가 의사가 아니다. (3)에서 '되다'라는 서술어는 **행위주역(Agent)**과 **결과상태역(Resultant State)**을 요구합니다. 각각 '진이', '의사'가 여기에 해당합니다. 다시 말해 '되다'라는 서술어는 '진이가'와 관계를 가지며, '의사가'와도 관련을 맺고 있습니다. (4)에서 '아니다'라는 서술어 또한 서로 다른 의미역의 두 개 논항을 요구합니다. '아니다'라는 서술어는 '진이가', '의사가' 모두 관련을 맺고 있습니다.  ## 3유형 3유형은 2유형처럼 첫번째, 두번째 명사구 모두 서술어와 관련을 맺고 있지만, 첫째 명사구와 둘째 명사구의 의미역이 동일해보이는 경우입니다. > (5) 학생이 세 명이 왔다. (5)에서 '학생이'와 '세 명이'가 둘 다 행위주역으로서 동사 '오-'와 관련되는 것으로 보입니다.
KKT␞ 이번 글에서는 **KKT 조건**을 살펴보도록 하겠습니다. 이 글은 미국 카네기멜런대학 [강의](http://www.stat.cmu.edu/~ryantibs/convexopt/)를 기본으로 하되 영문 위키피디아 또한 참고하였습니다. 그럼 시작하겠습니다.   ## concept *Karush-Kuhn-Tucker* 조건은 *primal, dual solution*과의 관계에서 도출된 조건인데요. 최적화 이론과 실제 구현에서 핵심적인 역할을 합니다. *duality*와 관련해서는 [이곳](https://ratsgo.github.io/convex%20optimization/2018/01/25/duality/)을 참고하시면 좋을 것 같습니다. 어쨌든 KKT 조건의 구체적인 내용은 다음과 같습니다.  <a href="https://imgur.com/Sq8DddQ"><img src="https://i.imgur.com/Sq8DddQ.png" width="550px" title="source: imgur.com" /></a>   ## Necessity 다음과 같은 명제가 성립합니다. *primal, dual, duality gap, lagrange dual function* 등 개념과 관련해서는 [이곳](https://ratsgo.github.io/convex%20optimization/2018/01/25/duality/)을 참고하시면 좋을 것 같습니다.  <a href="https://imgur.com/9btM4wy"><img src="https://i.imgur.com/9btM4wy.png" width="600px" title="source: imgur.com" /></a>  zero duality라면 $f^*=g$입니다. 그런데 $x$-star는 primal problem의 목적함수 $f$의 optimal value입니다. 또한 $u$-star, $v$-star는 dual problem의 목적함수 $g$의 optimal value입니다. 따라서 다음 식처럼 쓸 수 있습니다.  $$ f\left( { x }^{ * } \right) =g\left( { u }^{ * },{ v }^{ * } \right) $$ 위 식 우변을 라그랑지안 듀얼 함수 $g$의 정의대로 쓰면 다음 식과 같습니다.  $$ g\left( { u }^{ * },{ v }^{ * } \right) =\min _{ x }{ L\left( x,{ u }^{ * },{ v }^{ * } \right) } $$ $L$은 우리가 구하려는 미지수 $x$로 편미분한 식을 0으로 만드는 지점에서 최소값을 지닙니다. 그런데 전제조건에서 이미 언급했듯 primal problem의 해는 $x$-star이기 때문에 $L$을 $x$로 편미분한 결과를 0으로 만드는 지점은 바로 $x$-star가 될 것입니다. 이는 KKT 조건의 *stationary condition*을 만족한다는 이야기입니다. 이를 식으로 쓰면 다음과 같습니다.  $$ \min _{ x }{ L\left( x,{ u }^{ * },{ v }^{ * } \right) } =L\left( { x }^{ * },{ u }^{ * },{ v }^{ * } \right) $$ primal problem과 라그랑지 함수 $L$, 라그랑지안 듀얼 함수 $g$ 사이에는 다음 부등식이 성립합니다. (왜 아래 식이 도출되는지는 [이곳](https://ratsgo.github.io/convex%20optimization/2018/01/25/duality/) 참고)  $$ f\left( { x }^{ * } \right) \ge \min _{ x\in C }{ L\left( x,u,v \right) } \ge \min _{ x }{ L\left( x,u,v \right) } =g\left( u,v \right) $$  이를 우리가 들여다보던 식에 맞춰서 다시 적으면 다음 식을 유도할 수 있습니다.   $$ \begin{align*} &L\left( { x }^{ * },{ u }^{ * },{ v }^{ * } \right) \\ &\le f\left( { x }^{ * } \right) +\sum _{ i=1 }^{ m }{ { u }_{ i }^{ * }{ h }_{ i }\left( { x }^{ * } \right) } +\sum _{ j=1 }^{ r }{ { v }_{ j }^{ * }l_{ j }\left( { x }^{ * } \right) } \\ &\le f\left( { x }^{ * } \right) \end{align*} $$  결과적으로 처음 항, 즉 $f(x^*)$가 마지막에 다시 유도된 걸 확인할 수 있습니다. 다시 말해 우리가 논의하고 있는 명제의 전제조건을 만족할 경우 위 모든 부등식이 사실상 등식과 같다는 이야기입니다. 이 경우 다음 식이 모두 0이 되어야 등식을 만족하게 됩니다. 그렇다면 모든 식에 등호가 붙으려면 다음 두 개 항이 모두 0이 되어야 함을 확인할 수 있습니다.  $$ \begin{align*} &A:\sum _{ i=1 }^{ m }{ { u }_{ i }^{ * }{ h }_{ i }\left( { x }^{ * } \right) } =0\\ &B:\sum _{ j=1 }^{ r }{ { v }_{ j }^{ * }l_{ j }\left( { x }^{ * } \right) } =0 \end{align*} $$  그런데 *primal problem*를 다시 살펴보면 $l_j$는 모두 0이기 때문에 $B$에 관련된 항들은 본래 모두 0입니다. 문제는 $A$인데요. $A$의 경우에도 모두 0이 되어야 등식을 만족합니다. 다시 말해 KKT 조건의 *complementary slackness*를 만족한다는 이야기입니다.  따라서 결과적으로 위 명제의 전제조건이 만족된다면 KKT 조건 또한 만족하게 됩니다.   ## Sufficiency 다음과 같은 명제가 성립합니다.  <a href="https://imgur.com/oJOBWNS"><img src="https://i.imgur.com/oJOBWNS.png" width="600px" title="source: imgur.com" /></a>  $g$를 정의대로 적으면 아래 식의 첫 줄이 됩니다. 아울러 $x$-star, $u$-star, $v$-star는 KKT 조건을 만족한다고 했으므로 KKT 조건의 *stationarity condition*에 의해 $L(x,u^*,v^*)$는 $x$-star에서 최소값을 가집니다. 따라서 다음이 성립합니다.  $$ \begin{align*} g\left( { u }^{ * },{ v }^{ * } \right) =&\min _{ x }{ L\left( x,{ u }^{ * },{ v }^{ * } \right) } \\ =&f\left( { x }^{ * } \right) +\sum _{ i=1 }^{ m }{ { u }_{ i }^{ * }{ h }_{ i }\left( { x }^{ * } \right) } +\sum _{ j=1 }^{ r }{ { v }_{ j }^{ * }l_{ j }\left( { x }^{ * } \right) } \end{align*} $$ KKT 조건의 *complementary slackness*에 따라 아래 식 좌변의 두번째 항이 모두 0입니다. *primal problem*을 다시 살펴보면 $l_j$ 역시 모두 0입니다. 따라서 아래 식이 성립합니다. 바꿔 말해 $x$-star는 *primal problem*의 해, $u$-star, $v$-star는 *dual problem*의 해라는 이야기입니다.  $$ f\left( { x }^{ * } \right) +\sum _{ i=1 }^{ m }{ { u }_{ i }^{ * }{ h }_{ i }\left( { x }^{ * } \right) } +\sum _{ j=1 }^{ r }{ { v }_{ j }^{ * }l_{ j }\left( { x }^{ * } \right) } =f\left( { x }^{ * } \right) $$   ## 정리 지금까지 말씀드린 내용을 정리하면 아래 그림과 같습니다.  <a href="https://imgur.com/A5HYngz"><img src="https://i.imgur.com/A5HYngz.png" title="source: imgur.com" /></a>  *strong duality*를 만족하는 경우 위 두 명제가 동치 관계를 갖습니다. (*strong duality*, *slater's condition* 등은 [이곳](https://ratsgo.github.io/convex%20optimization/2018/01/25/duality/) 참고) <a href="https://imgur.com/LW5vHOE"><img src="https://i.imgur.com/LW5vHOE.png" width="500px" title="source: imgur.com" /></a>   ## SVM에 적용 마진(margin) 내 관측치를 허용하는 C-SVM을 기준으로 설명해 보겠습니다. C-SVM과 관련해서는 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/29/SVM2/)을 참고하시면 좋을 것 같습니다. 어쨌든 C-SVM의 *primal problem*은 다음과 같습니다. 아래 제약식을 만족하면서 목적함수를 최소화하는 $w, b, ξ$을 찾아야 합니다.  $$ \begin{align*} &\min _{ w,b,{ \xi } }&&{ \frac { 1 }{ 2 } { \left\| w \right\| }_{ 2 }^{ 2 }+C\sum _{ i=1 }^{ n }{ { \xi }_{ i } } } \\ &subject\quad to\quad &&{ \xi }_{ i }\ge 0,\quad i=1,...,n\\ &&&{ y }_{ i }({ w }^{ T }{ x }_{ i }+b)\ge 1-{ \xi }_{ i },\quad i=1,...,n \end{align*} $$  위 *primal problem*을 바탕으로 라그랑지안 함수 $L$을 만듭니다. 제약식에 라그랑지안 승수를 곱해 목적식에 합치면 됩니다. 여기에서 라그랑지안 승수 $α, μ$를 *dual variable*이라고 합니다. 단 여기에서 $α, μ$는 0 이상의 부등식에 적용되는 라그랑지안 승수이므로 0 이상의 제약을 갖습니다.  $$ L(w,b,{ { \xi }_{ i },\alpha }_{ i },{ \mu }_{ i })=\frac { 1 }{ 2 } { \left\| w \right\| }_{ 2 }^{ 2 }+C\sum _{ i=1 }^{ n }{ { \xi }_{ i } } -\sum _{ i=1 }^{ n }{ { \alpha }_{ i }({ y }_{ i }({ w }^{ T }{ x }_{ i }+b)-1+{ \xi }_{ i }) } -\sum _{ i=1 }^{ n }{ { { \mu }_{ i }\xi }_{ i } } $$ 여기에서 우리가 사용할 조건은 KKT의 충분조건입니다. $w, b, ξ, α, μ$가 KKT 조건을 만족한다면, $w, b, ξ$는 primal problem의 최적해, $α, μ$는 dual problem의 최적해가 된다는 이야기입니다. 다시 말해 약간 풀기 어려운 primal problem을 풀기 쉬운 dual problem으로 바꿔 풀어도 최적해를 구한다는 점에선 같은 의미라는 뜻이 되는거죠. KKT 조건 가운데 *stationarity* 조건은, 최적화하려는 미지수로 편미분한 식이 0이 된다는 조건입니다. 아래 세 개 식을 만족하게끔 $α, μ$를 구하면 *stationarity* 조건이 클리어됩니다.  $$ \begin{align*} \frac { \partial L }{ \partial w } =0\quad &\rightarrow \quad w=\sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i }{ x }_{ i } } \\ \frac { \partial L }{ \partial b } =0\quad &\rightarrow \quad \sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i } } =0\\\frac { \partial L }{ \partial { \xi }_{ i } } =0\quad &\rightarrow \quad C-{ \alpha }_{ i }-{ \mu }_{ i }=0 \end{align*} $$  KKT 조건 가운데 *complementary slackness* 조건을 클리어하려면 아래 식을 만족해야 합니다.  $$ \begin{align*} { { \mu }_{ i }\xi }_{ i }=0,\quad i=1,...n\\ { \alpha }_{ i }({ y }_{ i }({ w }^{ T }{ x }_{ i }+b)-1+{ \xi }_{ i })=0,\quad i=1,...n \end{align*} $$  *dual problem*의 목적식은 다음과 같습니다. 즉 *stationarity* 조건으로 도출된 식을 라그랑지안 함수 $L$에 넣어 정리해준 결과입니다. *dual problem*의 목적식과 제약식 도출과 관련한 자세한 내용은 [이곳](https://ratsgo.github.io/machine%20learning/2017/05/29/SVM2/)을 참고하면 좋을 것 같습니다.  $$ \begin{align*} g({\alpha}_{i},{\mu}_{i})=&{ \min_{w,b,\xi} { L(w,b,{ { \xi }_{ i },\alpha }_{ i },{ \mu }_{ i }) } } \end{align*} $$  $w, b, ξ, α, μ$가 KKT 조건을 만족하도록 정했기 때문에, dual problem의 최적해인 $α, μ$를 구하는 것만으로도 primal problem을 푸는 것과 같은 효과를 낼 수 있습니다.
projection␞ 이번 글에서는 머신러닝의 다양한 분야에서 폭넓게 응용되고 있는 선형대수학의 기본 개념인 **사영(projection)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 강필성 교수님, 역시 같은 대학의 김성범, 한성원 교수님 강의와 위키피디아 등의 자료를 제 나름대로 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 벡터의 내적과 사영 벡터 $b$를 벡터 $a$에 사영한 결과($x$)는 아래 그림과 같습니다.  <a href="http://imgur.com/h21igrF"><img src="http://i.imgur.com/h21igrF.png" width="500px" title="source: imgur.com" /></a> 벡터 덧셈의 기하학적 성질을 이용해 위 그림에서 정보를 얻어낼 수 있는데요. 벡터 $b$를 빗변으로 하는 직각삼각형의 밑변은 벡터 $x$, 높이는 $b-x$가 될 겁니다(밑변과 높이를 더하면 빗변에 해당하는 $b$가 됨).  서로 직교하는 벡터의 내적은 0이 되므로 스칼라 $p$는 아래와 같이 구할 수 있게 됩니다.  $$ { (\overrightarrow { b } -\overrightarrow {x}) }^{ T }\overrightarrow { a } =0\\{ (\overrightarrow { b } -p\overrightarrow { a } ) }^{ T }\overrightarrow { a } =0\\ { \overrightarrow { b } }^{ T }\overrightarrow { a } -p{ \overrightarrow { a } }^{ T }\overrightarrow { a } =0\\ p=\frac { { \overrightarrow { b } }^{ T }\overrightarrow { a } }{ { \overrightarrow { a } }^{ T }\overrightarrow { a } } $$  그런데 여기에서 벡터 $a$가 유닛벡터($a^Ta=1$)라면 $p$는 $b^Ta$, 즉 벡터 $a$와 $b$의 내적만으로도 그 값을 구할 수 있게 됩니다. 다시 말해 벡터의 내적과 사영이 깊은 관련을 맺고 있다는 얘기입니다. 이 때문에 '어떤 특정 축(벡터)에 다른 벡터를 사영'하는 것과 '두 벡터를 내적'한다는 표현이 거의 같은 의미로 널리 쓰이는 듯합니다.   ## projection operator 사영을 3차원으로 확장해 생각해 보겠습니다. 다음 그림과 같습니다.  <a href="https://imgur.com/mTfcMYy"><img src="https://i.imgur.com/mTfcMYy.png" width="200px" title="source: imgur.com" /></a>  3차원 벡터 $u$를, 벡터 $v_1$과 $v_2$가 만드는 2차원 평면 공간에 사영시킨 결과는 $w$가 됩니다. 여기에서 사영 기능을 하는 3×3 크기의 정방행렬(projection operator) $P$를 가정해봅시다. 다시 말해 임의의 3차원 벡터 $u$에 $P$를 내적해주기만 하면 2차원 평면에 사영이 된다고 치자는 것입니다.  $$ P\cdot \overrightarrow { u } =\overrightarrow { w } $$  그럼 여기에서 $P$의 속성을 간단히 알아보겠습니다. 정의에 의해 다음 식이 성립합니다. 단 아래 식에서 $P$와 벡터 $w$의 내적이 다시 $w$가 되는 이유는 $P$는 임의의 3차원 벡터를 $v1$과 $v2$가 만드는 2차원 평면 공간에 사영시키는 역할을 하는데, $w$는 이미 $v1$과 $v2$가 만드는 2차원 평면 공간에 있기 때문입니다.  $$ P\cdot \left( P\cdot \overrightarrow { u } \right) =P\cdot \overrightarrow { w } =\overrightarrow { w } =P\cdot \overrightarrow { u } $$  위 식을 간단하게 정리하면 다음과 같습니다. 다시 말해 $P$는 멱등행렬(idempotent matrix, $P^2=P$)입니다.  $$ P\cdot \left( P\cdot \overrightarrow { u } \right) =P\cdot \overrightarrow { u } \\ \left( { P }^{ 2 }-P \right) \overrightarrow { u } =0\\ { P }^{ 2 }=P $$  만약 $P$가 대칭행렬(symmetric matrix, $P^T=P$)이라고 가정해 봅시다. 그리고 나서 위 그림에서 직각삼각형의 밑변($w$)과 높이($u-w$)를 내적해 보는 것입니다. 다음과 같이 수식을 전개할 수 있습니다.  $$ \begin{align*} { \left( { \overrightarrow { u } }-\overrightarrow { w } \right) }^{ T }{ \overrightarrow { w } }=&{ \left( { \overrightarrow { u } }-P\overrightarrow { u } \right) }^{ T }{ \left( P\overrightarrow { u } \right) }\\ =&\left( { { \overrightarrow { u } }^{ T } }-{ \overrightarrow { u } }^{ T }{ P }^{ T } \right) { \left( P\overrightarrow { u } \right) }\\ =&{ { \overrightarrow { u } }^{ T } }P\overrightarrow { u } -{ \overrightarrow { u } }^{ T }{ P }^{ T }P\overrightarrow { u } \\ =&{ { \overrightarrow { u } }^{ T } }P\overrightarrow { u } -{ \overrightarrow { u } }^{ T }P\overrightarrow { u } \\ =&0 \end{align*} $$  $P$가 멱등행렬이고 대칭행렬일 경우 해당 $P$는 orthogonal projection operator가 된다고 합니다.   ## 선형회귀와 사영 $n$개 데이터가 있고 $x$의 변수가 $p$개 일 때 선형회귀 모델은 다음과 같이 나타낼 수 있습니다.  <a href="https://imgur.com/ZbXnuyZ"><img src="https://i.imgur.com/ZbXnuyZ.png" width="400px" title="source: imgur.com" /></a>  $$ \overrightarrow { Y } ={ \beta }_{ 0 }\overrightarrow { 1 } +{ \beta }_{ 1 }\overrightarrow { X_{ 1 } } +...+{ \beta }_{ p }\overrightarrow { X_{ P } } +\overrightarrow { \varepsilon } \\ \overrightarrow { Y } =X\overrightarrow { \beta } +\overrightarrow { \varepsilon } $$  선형회귀의 목적함수는 오차제곱합(sum of least square)이며 이를 최소로 하는 파라메터 $β$를 찾는 것이 모델의 학습이 되겠습니다. 식을 전개해서 정리하면 다음과 같습니다. (네번째 줄에서 두번째, 세번째 항은 스칼라값이므로 transpose를 취해주어도 같은 값을 지니기 때문에 하나로 합쳐줍니다)  $$ \begin{align*} f\left( \overrightarrow { \beta } \right) =&{ \overrightarrow { \varepsilon } }^{ T }\overrightarrow { \varepsilon } \\ =&{ \left( \overrightarrow { Y } -X\overrightarrow { \beta } \right) }^{ T }\left( \overrightarrow { Y } -X\overrightarrow { \beta } \right) \\ =&\left( { \overrightarrow { Y } }^{ T }-{ \overrightarrow { \beta } }^{ T }{ X }^{ T } \right) \left( \overrightarrow { Y } -X\overrightarrow { \beta } \right) \\ =&{ \overrightarrow { Y } }^{ T }\overrightarrow { Y } -{ \overrightarrow { Y } }^{ T }X\overrightarrow { \beta } -{ \overrightarrow { \beta } }^{ T }{ X }^{ T }\overrightarrow { Y } +{ \overrightarrow { \beta } }^{ T }{ X }^{ T }X\overrightarrow { \beta } \\ =&{ \overrightarrow { Y } }^{ T }\overrightarrow { Y } -2{ \overrightarrow { \beta } }^{ T }{ X }^{ T }\overrightarrow { Y } +{ \overrightarrow { \beta } }^{ T }{ X }^{ T }X\overrightarrow { \beta } \end{align*} $$  위 식은 우리의 관심인 $β$에 대해 2차식의 형태를 가지므로 $β$에 대해 미분한 식이 0이 되는 지점에서 최소값을 가집니다. 이를 식으로 쓰면 다음과 같습니다.  $$ \begin{align*} \frac { \partial f\left( \overrightarrow { \beta } \right) }{ \partial \overrightarrow { \beta } } =&{ \overrightarrow { Y } }^{ T }\overrightarrow { Y } -2{ \overrightarrow { \beta } }^{ T }{ X }^{ T }\overrightarrow { Y } +{ \overrightarrow { \beta } }^{ T }{ X }^{ T }X\overrightarrow { \beta } \\ =-&2{ X }^{ T }\overrightarrow { Y } +2{ X }^{ T }X\overrightarrow { \beta } =0 \\ \\ \therefore &\overrightarrow { \hat{\beta} } ={ \left( { X }^{ T }X \right) }^{ -1 }{ X }^{ T }\overrightarrow { Y } \\\Rightarrow \hat { Y } &=X\overrightarrow { \hat { \beta } } =X{ \left( { X }^{ T }X \right) }^{ -1 }{ X }^{ T }\overrightarrow { Y } \end{align*} $$  위 식에서 $X(X^TX)^{-1}X^T$를 $H$로 치환해 보겠습니다. 이 $H$가 대칭행렬인지 여부를 따져보니 대칭행렬임을 확인할 수 있습니다.  $$ \begin{align*} { H }^{ T }=&{ \left\{ { X\left( { X }^{ T }X \right) }^{ -1 }{ X }^{ T } \right\} }^{ T }\\ =&X\left\{ { \left( { X }^{ T }X \right) }^{ -1 } \right\} ^{ T }{ X }^{ T }\\ =&X\left\{ { \left( { X }^{ T }X \right) }^{ T } \right\} ^{ -1 }{ X }^{ T }\\ =&X\left( { X }^{ T }X \right) ^{ -1 }{ X }^{ T }=H \end{align*} $$  이번엔 $H$가 멱등행렬인지를 따져봤습니다. 멱등행렬임을 확인할 수 있습니다.  $$ \begin{align*} HH=&{ X\left( { X }^{ T }X \right) }^{ -1 }{ X }^{ T }\cdot { X\left( { X }^{ T }X \right) }^{ -1 }{ X }^{ T }\\ =&{ X\left( { X }^{ T }X \right) }^{ -1 }I{ X }^{ T }=H \end{align*} $$  따라서 $H$는 orthogonal projection operator가 됩니다. 이를 그림으로 도식화하면 다음과 같습니다. 다시 말해 $H$는 정답 벡터 $Y$를 '(학습 결과물인)선형식'이라는 기저에 사영하는 역할을 수행한다는 것입니다.   <a href="https://imgur.com/x9tsnt3"><img src="https://i.imgur.com/x9tsnt3.png" width="400px" title="source: imgur.com" /></a>    ## 테일러 급수 전개와 사영 예컨대 3차원 벡터를 2차원 평면에 사영했을 경우에 벡터의 세 요소값들 가운데 하나는 특정 숫자로 고정되게 됩니다. 이를 통해 기저 2개로도 해당 벡터를 표현할 수가 있게 되죠. 이것이 바로 차원축소(dimensionality reduction)입니다.  그런데 테일러 급수 전개도 사영, 그리고 차원축소 개념과 연관지어 생각해볼 수 있다고 합니다. 테일러급수 전개는 함수값을 다음과 같이 무한합으로 표시하는 걸 가리킵니다.  $$ \begin{align*} f\left( t \right) =&f\left( 0 \right) +f'\left( 0 \right) \cdot t+f''\left( 0 \right) \cdot \frac { { t }^{ 2 } }{ 2! } +f'''\left( 0 \right) \cdot \frac { { t }^{ 3 } }{ 3! } +...\\ =&f\left( 0 \right) +\sum _{ k=1 }^{ \infty }{ f^{ \left( k \right) }\left( 0 \right) } \cdot \frac { { t }^{ k } }{ k! } \end{align*} $$  그런데 $f(t)$를 테일러 급수 전개식의 $n$번째 항까지만 써서 근사할 수 있습니다. $f(t)$를 일종의 벡터로 본다면, 테일러 급수 전개식의 각 항을 벡터의 요소값으로 봐도 큰 무리가 없을 것입니다. $n$번째 항까지만 써서 $f(t)$를 근사하는 경우 무한차원의 함수공간에 존재하는 벡터 $f(t)$를 $n$차원의 함수공간으로 사영했다고 보는 해석도 가능하다는 것이죠. 다음 그림과 같습니다.  <a href="https://imgur.com/xl0Dq6v"><img src="https://i.imgur.com/xl0Dq6v.png" width="400px" title="source: imgur.com" /></a>
SVM␞ 이번 글에서는 딥러닝 이전 뛰어난 성능으로 많은 주목을 받았던 **서포트 벡터 머신(Support Vector Machine)**에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님과 같은 대학의 김성범 교수님 강의, 그리고 [이곳](https://wikidocs.net/5719)을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## margin 두 범주를 나누는 분류 문제를 푼다고 가정해 보겠습니다. 아래 그림에서 직선 $B_1$과 $B_2$ 모두 두 클래스를 무난하게 분류하고 있음을 확인할 수 있습니다. <a href="http://imgur.com/DrcoGVQ"><img src="http://i.imgur.com/DrcoGVQ.png" width="350px" title="source: imgur.com" /></a> 좀 더 나은 분류경계면을 꼽으라면 $B_1$일 겁니다. 두 범주를 여유있게 가르고 있거든요. 위 그림에서 $b_{12}$을 minus-plane, $b_{11}$을 plus-plane, 이 둘 사이의 거리를 **마진(margin)**이라고 합니다. SVM은 이 마진을 최대화하는 분류 경계면을 찾는 기법입니다. 이를 도식적으로 나타내면 아래와 같습니다.  <a href="http://imgur.com/afe8W3S"><img src="http://i.imgur.com/afe8W3S.png" width="400px" title="source: imgur.com" /></a>  그럼 마진의 길이가 얼마인지 유도해보겠습니다. 우선 우리가 찾아야 하는 분류경계면을 $w^Tx+b$라고 둡시다. 그러면 **벡터 $w$는 이 경계면과 수직인 법선벡터**가 됩니다.  이해하기 쉽도록 $w$를 2차원 벡터 $(w_1,w_2)^T$라고 두겠습니다. $w$에 대해 원점과의 거리가 $b$인 직선의 방정식은 $w^Tx+b=w_1x_1+w_2x_2+b=0$이 됩니다. 이 직선의 기울기는 $-w_1/w_2$이고, 법선벡터 $w$의 기울기는 $w_2/w_1$이므로 두 직선은 수직입니다. 이를 차원을 확장하여 생각해도 마찬가지입니다. 어쨌든 이 사실을 바탕으로 plus-plane 위에 있는 벡터 $x^+$와 $x^-$ 사이의 관계를 다음과 같이 정의할 수 있습니다. $x^-$를 $w$ 방향으로 평행이동시키되 이동 폭은 $λ$로 스케일한다는 취지입니다.  $$ { x }^{ + }={ x }^{ - }+\lambda w $$  그럼 $λ$은 어떤 값을 지닐까요? $x^+$는 plus-plane, $x^-$는 minus-plane 위에 있다는 사실과 $x^+$와 $x^-$ 사이의 관계식을 활용하면 다음과 같이 유도해낼 수 있습니다.  $$ \begin{align*} { w }^{ T }{ x }^{ + }+b&=1\\ { w }^{ T }({ x }^{ - }+\lambda w)+b&=1\\ { w }^{ T }{ x }^{ - }+b+\lambda { w }^{ T }w&=1\\ -1+\lambda { w }^{ T }w&=1\\\\ \lambda =\frac { 2 }{ { w }^{ T }w } \end{align*} $$  마진은 plus-plane과 minus-plane 사이의 거리를 의미합니다. 이는 $x^+$와 $x^-$ 사이의 거리와 같습니다. 둘 사이의 관계식과 $λ$값을 알고 있으므로 식을 정리하면 마진을 다음과 같이 유도할 수 있습니다.  $$ \begin{align*} Margin&=distance({ x }^{ + },{ x }^{ - })\\ &={ \left\| { x }^{ + }-{ x }^{ - } \right\| }_{ 2 }\\ &={ \left\| { x }^{ - }+\lambda w-{ x }^{ - } \right\| }_{ 2 }\\ &={ \left\| \lambda w \right\| }_{ 2 }\\ &=\lambda \sqrt { { w }^{ T }w } \\ &=\frac { 2 }{ { w }^{ T }w } \sqrt { { w }^{ T }w } \\ &=\frac { 2 }{ \sqrt { { w }^{ T }w } } \\ &=\frac { 2 }{ { \left\| w \right\| }_{ 2 } } \end{align*} $$  ## 목적식과 제약식 정의 SVM의 목적은 마진을 최대화하는 경계면을 찾는 것입니다. 계산상 편의를 위해 마진 절반을 제곱한 것에 역수를 취한 뒤 그 절반을 최소화하는 문제로 바꾸겠습니다. 이렇게 해도 문제의 본질은 바뀌지 않습니다.  $$ max\frac { 2 }{ { \left\| w \right\| }_{ 2 } } \rightarrow \min { \frac { 1 }{ 2 } { \left\| w \right\| }_{ 2 }^{ 2 } } $$  여기엔 다음과 같은 제약조건이 관측치 개수만큼 붙습니다. 식의 의미는 이렇습니다. plus-plane보다 위에 있는 관측치들은 $y=1$이고 $w^Tx+b$가 1보다 큽니다. 반대로 minus-plane보다 아래에 있는 점들은 $y=-1$이고 $w^Tx+b$가 -1보다 작습니다. 이 두 조건을 한꺼번에 묶으면 아래와 같은 제약식이 됩니다.  $$ { y }_{ i }({ w }^{ T }{ x }_{ i }+b)\ge 1 $$  ## 라그랑지안 문제로 변환 **라그랑지안 승수법(Lagrange multiplier method)**은 제약식에 형식적인 라그랑지안 승수를 곱한 항을 최적화하려는 목적식에 더하여, 제약된 문제를 제약이 없는 문제로 바꾸는 기법입니다. 이에 대해 추가적인 내용은 [이곳](http://untitledtblog.tistory.com/96)을 참고하면 좋을 것 같습니다. 우리가 이미 정의한 목적식과 제약식을 라그랑지안 문제로 식을 다시 쓰면 다음과 같습니다.  $$ {\min{ L_{p}(w,b,{ \alpha }_{ i }) } } =\frac { 1 }{ 2 } { \left\| w \right\| }_{ 2 }^{ 2 }-\sum _{ i=1 }^{ n }{ { \alpha }_{ i }({ y }_{ i }({ w }^{ T }{ x }_{ i }+b)-1) } $$  원 문제의 제약식의 범위가 0 이상이므로 $L_p$의 제약은 다음과 같습니다.  $$ { \alpha }_{ i }\ge 0,\quad i=1,...,n $$  ## Dual 문제로 변환  KKT 조건에서는 $L_p$를 미지수로 각각 편미분한 식이 0이 되는 지점에서 최소값을 갖습니다. 다음과 같습니다.  $$ \begin{align*} \frac { \partial L(w,b,{ \alpha }_{ i }) }{ \partial w } =0\quad &\rightarrow \quad w=\sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i }{ x }_{ i } } \\ \frac { \partial L(w,b,{ \alpha }_{ i }) }{ \partial b } =0\quad &\rightarrow \quad \sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i } } =0 \end{align*} $$ 위 식을 $L$에 넣어 정리해 보겠습니다. 우선 첫번째 항부터 보겠습니다.  $$ \begin{align*} \frac { 1 }{ 2 } { \left\| w \right\| }_{ 2 }^{ 2 }&=\frac { 1 }{ 2 } { w }^{ T }w\\ &=\frac { 1 }{ 2 } { w }^{ T }\sum _{ j=1 }^{ n }{ { \alpha }_{ j }{ y }_{ j }{ x }_{ j } } \\ &=\frac { 1 }{ 2 } \sum _{ j=1 }^{ n }{ { \alpha }_{ j }{ y }_{ j }{ ({ w }^{ T }x }_{ j }) } \\ &=\frac { 1 }{ 2 } \sum _{ j=1 }^{ n }{ { \alpha }_{ j }{ y }_{ j }{ (\sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i }{ x }_{ i }^{ T }{ x }_{ j } } }) } \\ &=\frac { 1 }{ 2 } \sum _{ i=1 }^{ n }{ \sum _{ j=1 }^{ n }{ { \alpha }_{ i }{ { \alpha }_{ j }y }_{ i }{ y }_{ j }{ x }_{ i }^{ T }{ x }_{ j } } } \end{align*} $$ 이번엔 두번째 항입니다.  $$ \begin{align*} -\sum _{ i=1 }^{ n }{ { \alpha }_{ i }({ y }_{ i }({ w }^{ T }{ x }_{ i }+b)-1) } &=-\sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i }({ w }^{ T }{ x }_{ i }+b) } +\sum _{ i=1 }^{ n }{ { \alpha }_{ i } } \\ &=-\sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i }{ w }^{ T }{ x }_{ i } } -b\sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i } } +\sum _{ i=1 }^{ n }{ { \alpha }_{ i } } \\ &=-\sum _{ i=1 }^{ n }{ \sum _{ j=1 }^{ n }{ { \alpha }_{ i }{ { \alpha }_{ j }y }_{ i }{ y }_{ j }{ x }_{ i }^{ T }{ x }_{ j } } } +\sum _{ i=1 }^{ n }{ { \alpha }_{ i } } \end{align*} $$  지금까지 도출한 결과를 토대로 $L_p$를 정리하면 다음과 같습니다. 식을 변형하는 과정에서 $α$에 관한 식으로 간단해졌습니다. $α$의 최고차항의 계수가 음수이므로 최소값을 찾는 문제가 최대값을 찾는 문제로 바뀌었습니다. 이로써 Dual 문제로 변환된 것입니다.  $$ \max { { L }_{ D }({ \alpha }_{ i }) } =\sum _{ i=1 }^{ n }{ { \alpha }_{ i } } -\frac { 1 }{ 2 } \sum _{ i=1 }^{ n }{ \sum _{ j=1 }^{ n }{ { \alpha }_{ i }{ { \alpha }_{ j }y }_{ i }{ y }_{ j }{ x }_{ i }^{ T }{ x }_{ j } } } $$  KKT 조건에 의해 $L_D$의 제약식은 다음과 같습니다.  $$ \sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i } } =0 \\{ \alpha }_{ i }\ge 0,\quad i=1,...,n $$  ## SVM의 해 우리가 찾고자 한 답은 마진이 최대화된 분류경계면 $w^Tx+b$입니다. $w$와 $b$를 찾으면 SVM의 해를 구할 수 있게 됩니다. KKT 조건을 탐색하는 과정에서 $w$는 다음과 같이 도출됐습니다.  $$ w=\sum _{ i=1 }^{ n }{ { \alpha }_{ i }{ y }_{ i }{ x }_{ i } } $$  $x_i$와 $y_i$는 우리가 가지고 있는 학습데이터이므로 라그랑지안 승수인 $α$값들만 알면 $w$를 찾을 수 있습니다. 그런데 여기에서 $α_i$가 0인 관측치들은 분류경계면 형성에 아무런 영향을 끼치지 못합니다. 바꿔 말해 $i$번째 관측치에 대응하는 라그랑지안 승수 $α_i$가 0보다 커야 마진 결정에 유의미하다는 이야기입니다.  아울러 KKT 조건에 의해 해당 함수가 최적값을 갖는다면 아래 두 개 가운데 하나는 반드시 0입니다. > (1) $α_i$ > > (2) $y_i(w^Tx_i+b-1)$ $α_i$가 0이 아니라면 $y_i(w^Tx_i+b-1)$가 반드시 0입니다. 따라서 $x_i$는 plus-plane 또는 minus-plane 위에 있는 벡터가 됩니다. 이렇게 마진 결정에 영향을 끼치는 관측치들을 **서포트 벡터(support vectors)**라고 합니다. 아래 그림([출처](https://www.google.co.kr/search?q=support+vector&source=lnms&tbm=isch&sa=X&ved=0ahUKEwj-h9CW2IfUAhWBjLwKHYqMB70Q_AUIBigB&biw=1534&bih=758#imgrc=o_DkwiMWNXZQUM:))과 같습니다. <a href="http://imgur.com/7TNlFVd"><img src="http://i.imgur.com/7TNlFVd.png" width="400px" title="source: imgur.com" /></a>  한편 $b$는 이미 구한 $w$와 학습데이터, $y_i(w^Tx_i+b-1)=0$ 식을 활용해 바로 구할 수 있게 됩니다. 새로운 데이터가 들어왔을 때는 해당 관측치를 $y_i(w^Tx_i+b-1)$에 넣어서 0보다 크면 1, 0보다 작으면 -1 범주로 예측하면 됩니다.
cohesion␞ 이번 글에서는 말뭉치 내 빈도로 단어를 추출하는 기법인 **Cohesion Probabilty(이하 CP)**에 대해 살펴보도록 하겠습니다. CP는 Kim&Cho(2013)가 제안한 모델인데요, 이 글은 모델 원저자인 김현중 서울대 박사과정이 진행한 2017 패스트캠퍼스 강의와 코드를 참고하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 기법 개요 CP는 연속된 글자의 연관성이 높을 수록 단어일 가능성이 높다는 가정 하에 구축된 모델입니다. $c_1$, $c_2$, ..., $c_{n-1}$ 다음에 $n$번째 글자인 $c_n$이 많이 나오면 $n$개 문자열로 이뤄진 $c_1$, $c_2$, ..., $c_{n-1}$, $c_n$은 단어일 것이라는 이야기입니다. 글자별로 조건부 확률을 구하여 모두 곱한 뒤 $1/n$승을 해서 구합니다. 아래 식과 같습니다.  $$ \begin{align*} cohesion({ c }_{ 1 },{ c }_{ 2 },...,{ c }_{ n })&=\sqrt [ n ]{ \prod _{ i=1 }^{ n-1 }{ P({ c }_{ 1 },...,{ c }_{ i+1 }|{ c }_{ 1 },...,{ c }_{ i }) } }\\&=\sqrt [ n ]{ \frac { Freq({ c }_{ 1 },{ c }_{ 2 },...{ c }_{ n }) }{ Freq({ c }_{ 1 }) } } \end{align*} $$  ## 분석 예시 예를 들어보겠습니다. $cohesion(박태환)$은 아래와 같이 '박태환' 빈도수를 '박'의 개수로 나눈 뒤 세제곱을 취해 구합니다. 아래 식에서 $N$은 말뭉치에 등장하는 단어 빈도수의 총합인데, 분자 분모에 동시에 있으므로 계산상 가능합니다. CP는 빈도만으로도 얼마든지 구할 수 있습니다.  $$ \begin{align*} cohesion(박태환)&=\sqrt [ 3 ]{ P(박태|박)P(박태환|박태) } \\ &=\sqrt [ 3 ]{\frac { P(박태) }{ P(박) } \frac { P(박태환) }{ P(박태) } } \\ &=\sqrt [ 3 ]{ \frac { P(박태환) }{ P(박) } } \\ &=\sqrt [ 3 ]{ \frac { Freq(박태환)/N }{ Freq(박)/N } } \\ &=\sqrt [ 3 ]{ \frac { Freq(박태환) }{ Freq(박) } } \end{align*} $$  이번엔 실제 말뭉치를 가지고 예를 들어보겠습니다. 영화 리뷰 사이트 '왓챠'에서 655만306개의 리뷰를 수집했습니다. 우선 이를 글자 단위로 세었습니다.   | 구분 | 빈도수 | | :--: | :---: | | 꿀  | 14145 | | 꿀잼 | 10179 | | 꿀잼ㅋㅋ | 306 |  위 표를 토대로 $cohesion(꿀잼)$과 $cohesion(꿀잼ㅋㅋ)$를 각각 구해보겠습니다.  $$ \begin{align*} cohesion(꿀잼)&=\sqrt [ 2 ]{ \frac { Freq(꿀잼) }{ Freq(꿀) } } =\sqrt [ 3 ]{ \frac { 10179 }{ 14145 } } =0.8483\\ cohesion(꿀잼ㅋㅋ)&=\sqrt [ 4 ]{ \frac { Freq(꿀잼ㅋㅋ) }{ Freq(꿀) } } =\sqrt [ 4 ]{ \frac { 306 }{ 14145 } } =0.3835 \end{align*} $$  위 결과를 해석하면 이렇습니다.   <p class="message">'꿀잼'이 단어일 확률은 '꿀잼ㅋㅋ'이 단어일 확률보다 두 배 가량 높다.</p>  이를 토대로 '꿀잼ㅋㅋ'이라는 문자열을 **토크나이즈(tokenize)**하면 아래와 같습니다.  > 꿀잼,ㅋㅋ   ## 말뭉치 분석 결과 지금까지 CP는 왼쪽에서 오른쪽 방향(forward)으로 빈도수를 세어 분석하는 방법만을 설명했는데요, 사실 오른쪽에서 왼쪽(backward)으로도 분석이 가능합니다. 우선 왓챠 리뷰 655만306개 리뷰를 학습해 forward 방향 CP 상위 500개 문자열을 나열한 결과는 아래와 같습니다. (CP * 빈도수 내림차순 정렬) <p class="message"> 영화, 너무, 생각, 사랑, 연기, 액션, 스토리, 재미, 배우, 재밌, 사람, 최고, 스토, 있는, 정말, 우리, 느낌, 아니, 작품, 장면, 마지막, 캐릭터, 현실, 캐릭, 이야기, 감독, 만들, 없는, 있다, 음악, 진짜, 보고, 마지, 대한, 매력, ㅋㅋ, 영화를, 좋았, 처음, 기대, 내가, 없다, 하지만, 하지, 그리고, 인간, 괜찮, 기억, 같은, 하는, 이야, 함께, 주인공, 표현, 그리, 것이, 역시, 결말, 필요, 긴장, 다시, 좋은, 연출, 하나, 보는, 원작, 좋아, 같다, 않는, 영화가, 모든, 배우들, 가장, 시리즈, 주인, 엔딩, 지루, 소재, 마음, 훌륭, 반전, 인생, 그래, 모르, 영화는, 이런, 행복, 많이, 세상, 감동, 최고의, 뭔가, 흥미, 재미있, 완벽, 내용, 남자, 보여, 시간, 순간, 살아, 근데, gt, 긴장감, 몰입, ㅋㅋㅋ, 코미디, 계속, 조금, 시리, 이렇게, 아름, 존재, 있었, 밖에, 언제, 그냥, 만들어, 않았, 많은, 공포, 20, 지금, 된다, 애니, 친구, 결국, 코미, 충분, 히어로, 시작, 때문, 판타, 상상, 아름다, 한국, 판타지, ㅠㅠ, 위한, 사람들, 돌아, 노래, 히어, 관객, 싶다, 만든, 누구, lt, 귀여, 뻔한, 뛰어, 얼마, 다른, 로맨, 분위기, 위해, 새로, 감정, 그래도, 자신, 좋다, 영화의, 볼만, 엄청, 되는, 여자, 봤다, 모습, 떨어, 모두, 않은, 좋았다, 얼마나, 별로, 눈물, 억지, 끝까지, 아이, 봤는데, 애니메이션, 솔직, 들어, 느껴, 아닌, th, 새로운, 찾아, 보면, 생각하, 유쾌, 풀어, 애니메이, 분위, 정도, 킬링, 드라마, 나는, 이렇, 모르겠, 전개, 나오, 봐야, 못하, 항상, 속에, 때문에, 좋아하, yo, 의미, you, 굉장, 매력적, 그런, 아니라, 봤는, 부족, 드라, 없었, 화려, 애니메, 킬링타임, 못한, 아름다운, 있을, 킬링타, 문제, 영화에, CG, ㅋㅋㅋㅋ, 등장, 만드는, 따뜻, 개인, 느낌이, 않는다, 보여주, 무엇, 싶은, 끝까, 너무나, 극장, 내내, 궁금, 디즈니, 신선, 추억, 배우들의, 남는, 어떻게, 크리스, 아쉬, 당신, 로맨스, 설정, 한다, 머리, 봐도, 명작, 멋있, 그렇, 영상, 했다, 10, 잔인, 감독의, 힘들, 취향, 솔직히, 사람이, 초반, 미국, 엄마, 크리, 가족, 세계, 부분, 개인적, 약간, 잔잔, 사랑스, 얘기, 것을, 이해, 후반, 충분히, SF, 엑스, 개인적으, 훌륭한, 스릴, 좋아하는, 디즈, 집중, 대사, 순수, 말이, 개인적으로, 것은, 무서, 따라, 선택, 강동원, 든다, 지루하, 자체, 굉장히, 언제나, 일본, 재밌게, 누군가, 하고, ㅎㅎ, 만드, 서로, 확실, 복수, 기분, 돋보, 즐거, 201, 흘러, the, 귀엽, 혼자, 천재, 훨씬, 스릴러, 완벽한, 공감, 끝나, 충격, 재밌다, 엑스맨, 멋진, 평범, 섹시, 알았, 괜찮은, 청춘, 제목, 것이다, 환상, 연기가, 나오는, 깔끔, 사랑이, 제대로, 누군, 능력, 슈퍼, 말하, 생각이, 사랑하, 믿고, 캐릭터들, 장르, 역사, 1편, 아무, 제일, 중간, 연기력, 재밌었, 사실, 한번, 과거, 유치, 특히, 성장, 상상력, 실망, 어떻, 되었, 웃음, 통해, 느끼, 죽음, 희망, ㅋㅋㅋㅋㅋ, 모르겠다, 아쉽, 스타, 포스, 어떤, B급, 않았다, 빠져, 답답, 예상, 감독이, 타란티노, 멜로, 러닝타임, 전쟁, 강동, 생각보다, 알고, 개연성, 인상, 완전, 뻔하, 없었다, 얼굴, 목소리, 인간의, 속에서, 화려한, 만들었, 미친, 동화, 이상, 결말이, 그렇게, 있었다, 되어, 아름답, 특유의, 장면이, 있어, 병맛, 벗어, 떠나, 러닝타, 추천, OS, 후반부, 놀라, 흥미로, 현실적, 단순, 킬링타임용, ost, 맘에, 보여주는, OST, 실화, 중요, 나도, 분명, 있을까, 아쉽다, 러닝, 어디, 성공, 들었, 보다, 타란티, 아니다, 시대, 소름, 포스터, 굳이, 괜찮았, 못했, 없이, 그러, 공포영화, 사랑스러, 구성, 슬프, 헐리, 연기는, 누가, 갈수록, 영상미, 스토리가, 그래서, 절대, 생각보, 마지막에, 촬영, 않고, 철학, 좀비, 캡틴, 보기, 목소, 주는, 우리는, 씁쓸, 폭력, 놀란, 광기, 바라, 예술, 기억에, 5점, 보고싶, 아직, 가슴, os, 뮤지, 듯한, 주제, 재미없, 욕망, 왠지, 운명, 설명, 지나 </p> backward 방향 CP 상위 500개 문자열은 아래와 같습니다. (CP * 빈도수 내림차순 정렬) <p class="message"> 지만, 으로, 에서, 는데, 적인, 하고, 하게, 하는, 지막, 화를, 처럼, ㅋㅋ, 었다, 하다, 까지, 을까, 다면, 이다, 부터, 리고, 에게, 들이, 다는, 들의, 화가, 렇게, 으면, ㅋㅋㅋ, 하지, 지는, 적으로, 보다, 이란, 만큼, 영화, 라는, 면서, 야기, 았다, 해서, 었던, 니다, 하지만, 했던, 리는, 기를, 했다, 로운, 다고, 토리, 화는, 름다운, ㅋㅋㅋㅋ, 러운, 어요, 화의, 스러운, 라고, 기가, 에겐, 수록, 리가, 니까, 다운, 리즈, 대로, ㅠㅠ, 래도, 기에, 한다, ou, 인공, ng, 는건, 니라, 기엔, 라면, 미디, 이지만, 구나, 이나, 지도, 들을, 이라, 한테, 어서, 버린, 이라는, 다가, 같은, 는게, 보단, 들은, ing, ㅋㅋㅋㅋㅋ, 하며, 었는데, er, 동안, 에도, 인데, 으나, 다니, 문에, 을때, 가는, 하여, 는다, 기도, 기는, 없이, 이고, 네요, 하면, 리를, 는지, 은데, 서도, 주는, 았던, 라도, 았는데, 으로도, 하기, 이야, 이션, 니메이션, 에선, 전히, 어야, 인가, 어낸, 일까, 이랑, 히려, 었지만, 고의, 겠다, ll, 되는, he, 메이션, 릭터, 아서, 인지, 릴러, 더라, 습니다, 했는데, 있는, 했지만, 만으로도, 나는, 였다, 로도, 러나, 어진, 이크, 세요, 로써, 어난, 우들의, 이클, 라니, 이지, 마나, 여준, 래서, 분히, 면서도, 지고, 야기를, nd, 간의, 에는, 들에게, 이었다, 화에, 도록, 번째, 는걸, 라마, ㅎㅎ, 어도, 으며, 랑스러운, 조차, 떻게, 이는, 화중, 인적으로, 는거, 오는, 토록, 나마, 스트, 이라면, 드는, 장감, 겠지만, 았지만, 었음, 무리, 이언, 이라고, 리오, 인줄, 음을, 인듯, 럭저럭, 음부터, 맨틱, 쉬운, 력적인, 기와, 저럭, 청난, 없는, 닐까, 시간, 화에서, 만한, 진다, GV, 들과, 밌게, ow, 스맨, 0년대, 적이고, 아요, 때문에, 지를, 스터, 무나, 화관에서, 동원, 아하는, 미가, 독의, 리의, 어지는, 었으면, 시절, 토리가, on, 어버린, 지컬, 형적인, 하나, 장에서, 화로, ㅠㅠㅠ, 0, ic, 함을, ㅜㅜ, 고싶다, 도로, 란티노, 으니, 거야, 지가, 간이, 직히, 리와, 여주는, 지막에, 이트, 었을까, 타임, st, 마저, 잖아, 스의, 상을, 이가, 대를, 음에, 자의, ve, 대체, 쉬움, 이첼, 치는, 력이, 저씨, 스팅, 한데, 고자, 상미, 관에서, 링타임용, 실적인, 보다는, 었다면, th, re, 지지, 을텐데, 르겠다, 하면서, 적이다, 수를, 에서도, 을듯, 티노, 음으로, 있게, 았음, 다른, 우들, 보면, 보니, 성을, 하는데, 자가, 들어, an, 반부, 제나, 년대, 당히, 나도, 서는, 니퍼, 스가, 국식, 상적인, 람이, 거나, 거운, 영화의, es, 각보다, 르는, 웠다, 타임용, 더니, 있다, 으로써, ion, 음이, 장히, 기력, 맨스, 이드, 간에, 칼렛, 감이, 는가, 야기가, 만으로, 으론, 토리는, 보고, mp, 이라니, 인공이, 이며, 함이, ck, 정을, 라서, 여운, 들어낸, 종일관, 니깐, 이자, 이빗, 함과, 미를, ST, 각이, 된다, 미있게, 억에, 시킨, 리셰, 스를, 만에, 성이, 리우드, 지의, 대한, 텐데, ed, 레딧, 실히, 간중간, E0F, tic, 니엘, 티븐, 리도, 람들이, 신의, 임용, 입니다, 아갈, 려고, 해야, 랑을, 것도, 걸까, 합니다, ㅠㅠㅠㅠ, 학교, 면이, 프닝, 하긴, 스럽다, 쉽다, 15, 까운, 미로운, 정이, 해도, 랑하는, 웠던, ver, 에서는, 감을, 인의, 해요, 야할, 리에, 구하고, 쾌한, 나서, 나리오, 야지, 물이, 럼에도, 일관, 겠지, 들어진, ㄷㄷ, 번쯤, 해지는, 무나도, 에서의, 로는, 분이, 작을, 보는, 한다면, 영화를, 15, 우드, 더라면, ay, ove, 라이언, 간을, 졌다, 인공의, 리스토퍼, 직도, 들었다, 독이, 신이, 다는걸, 사가, 주인공, 이의, 렸다, 0F, 점을, 리지, 각하게, 하면서도, 력을, stic, ly, 준다, 사를, 벽한, 아온, 어가는, 정한, 서운, 화였다, 독님, 릴때, 중에, 화다, 한듯, 설픈, 해진, 토리를, 국판, 트맨, 이라도, 면은, 르게, hing, 나고, 하고자, 764 </p>  ## 코드 김현중 박사과정이 작성한 CP 코드를 사용했습니다. 저 역시 정리 용도로 남긴 것이니 문제되면 바로 삭제하겠습니다. 최신 코드는 김현중 박사과정의 깃헙 https://github.com/lovit/soy을 참고하시기 바랍니다.  사용법은 아래와 같습니다. 아래 코드에서 *CohesionTokenizer* 역시 김현중 박사과정이 만든 코드로 말뭉치에서 학습한 CP를 바탕으로 문장을 토큰으로 나눠주는 함수입니다. ```python import cohesion_probability as tool cohesion = tool.CohesionProbability() cohesion.train(reviews) cohesiontokenizer = tool.CohesionTokenizer(cohesion) cohesion_tokenized_reviews = [cohesiontokenizer.tokenize(review) for review in reviews] ``` <br> <script src="https://gist.github.com/ratsgo/47d7ac778b71bab04feb67b516ac571c.js"></script>
RNNsty␞ 이번 글에서는 **Recurrent Neural Network**(RNN)을 효과적으로 학습시키는 전략들에 대해 살펴보도록 하겠습니다. 이 글은 [Oxford Deep NLP 2017 course](https://github.com/oxford-cs-deepnlp-2017/lectures)을 기본으로 하되 저희 연구실 장명준 석사과정이 만든 자료를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 그래디언트 문제 RNN 역전파시 그래디언트가 너무 작아지거나, 반대로 너무 커져서 학습이 제대로 이뤄지지 않는 경우가 많습니다. 이를 각각 gradient vanishing, gradient exploding 문제라고 합니다. 이 문제를 수식으로 살펴보겠습니다. vanilla RNN 셀 $t$번째 시점의 히든스테이트 $h_t$는 다음과 같이 정의됩니다. 단 여기에서 하이퍼볼릭탄젠트 안의 식들을 모두 합쳐 $z_t$이라 두겠습니다. ($x_t$ : $t$번째 시점의 입력, $W_{hh}, W_{xh}, b_h$ : 학습 파라메터)  $$ \begin{align*} { h }_{ t }=&\tanh { \left( { W }_{ hh }{ h }_{ t-1 }+{ W }_{ xh }{ x }_{ t }+{ b }_{ h } \right) }\\=&\tanh({z}_{t}) \end{align*} $$  다음 그림과 같은 RNN 구조에서 네번째 시점의 손실 $cost_4$에 대한 $h_1$의 그래디언트는 체인룰(chain rule)에 의해 아래와 같이 계산할 수 있습니다. 바꿔 말해 적색 화살표에 해당하는 그래디언트를 순차적으로 곱한 값이라고 보면 될 것 같습니다.  <a href="https://imgur.com/Q4Un12X"><img src="https://i.imgur.com/Q4Un12X.png" width="500px" title="source: imgur.com" /></a>  $$ \frac { \partial { cost }_{ 4 } }{ \partial { h }_{ 1 } } =\frac { \partial { cost }_{ 4 } }{ \partial { \hat { p } }_{ 4 } } \frac { \partial { \hat { p } }_{ 4 } }{ \partial { h }_{ 4 } } \frac { \partial { h }_{ 4 } }{ \partial { h }_{ 3 } } \frac { \partial { h }_{ 3 } }{ \partial { h }_{ 2 } } \frac { \partial { h }_{ 2 } }{ \partial { h }_{ 1 } } $$  위 식을 일반화하여 $n$번째 시점의 손실 $cost_n$에 대한 $h_1$의 그래디언트는 다음과 같이 표시할 수 있습니다.  $$ \frac { \partial { cost }_{ n } }{ \partial { h }_{ 1 } } =\frac { \partial { cost }_{ n } }{ \partial { \hat { p } }_{ n } } \frac { \partial { \hat { p } }_{ n } }{ \partial { h }_{ n } } \left( \prod _{ t=2 }^{ n }{ \frac { \partial { h }_{ t } }{ \partial { h }_{ t-1 } } } \right) $$  우리의 관심은 괄호 안입니다. 체인룰에 의해 그래디언트가 곱해지면서 이 값이 커지는지 작아지는지가 관심인 것입니다. $h_t=\tanh(z_t)$이므로 $t$번째 히든스테이트에 대한 $t-1$번째 히든스테이트의 그래디언트는 체인룰에 의해 다음과 같이 표시할 수 있습니다.  $$ \frac { \partial { h }_{ t } }{ \partial { h }_{ t-1 } } =\frac { \partial { h }_{ t } }{ \partial { z }_{ t } } \frac { \partial { z }_{ t } }{ \partial { h }_{ t-1 } } $$  $z_t=W_{hh}h_{t-1}+W_{xh}x_t+b_h$이므로 $∂z_t/∂h_{t-1}$은 $W_{hh}$입니다. norm의 성질에 의해 다음 부등식이 성립합니다.  $$ \left\| \frac { \partial { h }_{ t } }{ \partial { h }_{ t-1 } } \right\| \le \left\| \frac { \partial { h }_{ t } }{ \partial { z }_{ t } } \right\| \left\| \frac { \partial { z }_{ t } }{ \partial { h }_{ t-1 } } \right\| =\left\| \frac { \partial { h }_{ t } }{ \partial { z }_{ t } } \right\| \left\| { W }_{ hh } \right\| $$  norm의 성질에 의해 다음이 성립한다고 합니다([증명](https://i.imgur.com/zcuKkv2.png)). 다시 말해 $W_{hh}$의 L2 norm은 $W_{hh}$의 가장 큰 고유값(eigenvalue)라는 뜻입니다.  $$ { \left\| { W }_{ hh } \right\| }_{ 2 }=\sqrt { { \lambda }_{ max } } $$  다시 우리의 관심인 문제로 돌아오겠습니다. RNN 역전파시 체인룰에 의해 $∂h_t/∂h_{t-1}$을 지속적으로 곱해주어야 합니다. 그런데 우리가 살펴봤듯이 $∂h_t/∂h_{t-1}$의 L2 norm은 절대적으로 $W_{hh}$의 L2 norm 크기에 달려 있습니다. 다시 말해 $W_{hh}$의 가장 큰 고유값이 1보다 크다면 앞쪽 스텝으로 올수록 그래디언트가 매우 커질 것이며, 1보다 작다면 반대로 매우 작아질 것입니다. 이와 별개로 $z_t$를 계산한 이후 취해지는 비선형함수 하이퍼볼릭탄젠트의 문제도 있습니다. 하이퍼볼릭탄젠트를 1차 미분한 그래프는 다음과 같습니다. 입력값이 -5보다 작거나 5보다 크면 그래디언트가 0으로 작아지는 걸 확인할 수 있습니다. RNN 역전파 과정에서 하이퍼볼릭탄젠트의 그래디언트도 계속 곱해지기 때문에 하이퍼볼릭탄젠트도 그래디언트 배니싱 문제에 일부 영향을 끼칠 수 있습니다.  <a href="https://imgur.com/0mVuW9h"><img src="https://i.imgur.com/0mVuW9h.png" title="source: imgur.com" /></a>    ## 셀 구조를 바꾸기 : LSTM 그래디언트 문제를 해결하기 위한 방법 가운데 가장 각광받는 것은 셀 구조를 아예 바꿔보는 겁니다. 계속 곱해서 문제가 생겼으니 이번에는 더하는 걸로 바꿔 봅시다. 이를 cell state라 하겠습니다.  $$ { c }_{ t }={ c }_{ t-1 }+\tanh { \left( V\left[ { x }_{ t-1 };{ h }_{ t-1 } \right] +{ b }_{ c } \right) } $$  하이퍼볼릭탄젠트 안에 있는 내용은 vanilla RNN 셀과 본질적으로 다르지 않습니다. **$c_t$를 $c_{t-1}$로 미분하는 경우 우변에 $c_{t-1}$가 더해졌기 때문에 기본적으로 1을 확보할 수 있습니다.** 그래디언트가 0으로 죽는 걸 막고자 함입니다. 그런데 각 스텝마다 그래디언트가 지속적으로 커진다면 되레 그래디언트 익스플로딩 문제가 발생할 수 있습니다. 밸런스를 맞춰주어야 합니다. cell state를 아래와 같이 바꿔보겠습니다.  $$ \begin{align*} { c }_{ t }={ f }_{ t }\odot { c }_{ t-1 }+&{ i }_{ t }\odot \tanh { \left( V\left[ { x }_{ t-1 };{ h }_{ t-1 } \right] +{ b }_{ c } \right) } \\ \\ where\quad { i }_{ t }=&\sigma \left( { W }_{ i }\left[ { x }_{ t-1 };{ h }_{ t-1 } \right] +{ b }_{ i } \right) \\ { f }_{ t }=&\sigma \left( { W }_{ f }\left[ { x }_{ t-1 };{ h }_{ t-1 } \right] +{ b }_{ f } \right) \end{align*} $$  $i_t$와 $f_t$는 시그모이드가 취해진 값으로 0~1사이의 값을 가집니다. 각각 직전 시점의 정보, 현 시점의 정보를 얼마나 반영할지를 결정합니다. 물론 다음 히든스테이트를 만들 때도 gate를 둘 수 있습니다.  $$ { h }_{ t }={ o }_{ t }\odot \tanh { \left( { W }_{ h }{ c }_{ t }+{ b }_{ h } \right) } \\ where\quad { o }_{ t }=\sigma \left( { W }_{ o }\left[ { x }_{ t-1 };{ h }_{ t-1 } \right] +{ b }_{ o } \right) $$   ## Skip connection 셀 구조 말고 skip connection 기법을 사용할 수도 있습니다. 그래디언트가 흐를 수 있는 지름길(shortcut)을 만들어주는 것입니다. skip connection은 원래 Convolutional Neural Network에서 자주 사용된 기법인데 RNN 구조에서도 다음과 같이 적용할 수 있다고 합니다.  <a href="https://imgur.com/ZutBqDG"><img src="https://i.imgur.com/ZutBqDG.png" width="600px" title="source: imgur.com" /></a>   ## 과적합, 드롭아웃 일반적이지는 않지만, RNN에서도 드롭아웃을 적용해 과적합을 피할 수 있습니다. 그런데 히든스테이트와 히든스테이트 사이에 드롭아웃을 적용하는 것은 그리 좋은 선택이 아니라고 합니다. 히든스테이드와 히든스테이트를 연결하는 가중치 $W_{hh}$가 모든 step에서 공유되기 때문입니다. 아래 그림을 보겠습니다.  <a href="https://imgur.com/96CxZ3q"><img src="https://i.imgur.com/96CxZ3q.png" width="300px" title="source: imgur.com" /></a>  위 예시에서 $h_t$를 만들 때 1, 3, 5번째 노드를 드롭아웃할 경우 $W_{hh}$에서 해당 행벡터가 업데이트되지 않습니다. 하지만 다음 step에서 얼마든지 업데이트될 가능성이 있습니다. 과적합을 피하기 위해서 학습을 덜한다는 본래 취지에 맞지 않는다는 이야기입니다.  굳이 과적합을 적용할 경우 다음과 같이 할 수 있다고 합니다. 배치 단위로 파라메터를 업데이트하는 경우가 많은데, 1회 iteration마다 드롭아웃을 하는 노드를 모든 step에 대해 통일시키는 겁니다.  <a href="https://imgur.com/3LxuXFI"><img src="https://i.imgur.com/3LxuXFI.png" width="500px" title="source: imgur.com" /></a>   ## vocabulary 문제 예측해야 할 단어(범주) 수가 너무 많아서 소프트맥스 확률 계산시 과부하가 걸리는 경우가 많습니다. 이를 위해 일부 단어만 뽑아 소프트맥스 확률을 구하고 여기서 구한 손실(loss)만큼만 파라메터를 업데이트하는 방법도 있습니다. 이와 관련 자세한 내용은 [이곳](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/10/05/candidate/)을 참고하시면 좋을 것 같습니다.
softmax␞ 이번 글에서는 소프트맥스 함수와 크로스엔트로피 손실함수가 합쳐진 'Softmax-with-Loss' 계층에 대해 살펴보도록 하겠습니다. 이 글은 위키피디아와 '밑바닥부터 시작하는 딥러닝', 그리고 [이곳](https://math.stackexchange.com/questions/945871/derivative-of-softmax-loss-function)을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 개요 다범주 분류문제를 풀기 위한 딥러닝 모델 말단엔 소프트맥스 함수가 적용됩니다. 소프트맥스 함수는 범주 수만큼의 차원을 갖는 입력벡터를 받아서 확률(요소의 합이 1)로 변환해 줍니다. 이후 손실 함수로는 크로스엔트로피(cross entropy)가 쓰이는데요. 크로스엔트로피는 소프트맥스 확률의 분포와 정답 분포와의 차이를 나타냅니다. 이를 기본으로 해서 손실(오차)을 최소화하는 방향으로 모델의 각 파라메터를 업데이트하는 과정이 바로 딥러닝 모델의 학습이 되겠습니다. 그런데 딥러닝 모델 학습시 손실에서 나오는 그래디언트를 계산하는 것이 제1관문이 됩니다. 그도 그럴 것이 체인룰(chain rule)에 의해 이 그래디언트에 각 계산 과정에서의 로컬 그래디언트가 끊임없이 곱해져 오차가 역전파(backpropagation)되기 때문입니다. 이렇게 손실(오차)에 대한 각 파라메터의 그래디언트를 구하게 되면 그래디언트 디센트(gradient descent) 기법으로 파라메터를 업데이트해 손실을 줄여 나가게 됩니다. 딥러닝 모델의 손실함수로 왜 크로스엔트로피가 쓰이는지에 대해선 [이곳](https://ratsgo.github.io/deep%20learning/2017/09/24/loss/)을, 그래디언트 디센트(gradient descent)와 관련해서는 [이곳](https://ratsgo.github.io/deep%20learning/2017/09/25/gradient/)을, 오차 역전파와 관련해서는 [이곳](https://ratsgo.github.io/deep%20learning/2017/05/14/backprop/)을 참고하시면 좋을 것 같습니다. 이번 글에서는 딥러닝 역전파의 첫 단추인 Softmax-with-Loss 계층을 살펴보도록 하겠습니다. 이 글에서는 별도 표시가 없는 한 스칼라를 기준으로 표기하였음을 먼저 밝힙니다.   ## 순전파 분류해야 할 범주 수가 $n$이고 소프트맥스 함수의 $i$번째 입력값을 $a_i$, $i$번째 출력값을 $p_i$라고 할 때 소프트맥스 함수는 다음과 같이 정의됩니다. 소프트맥스 함수의 입력 및 출력벡터의 차원수는 $n$이 됩니다.  $$ { p }_{ i }=\frac { exp\left( { a }_{ i } \right) }{ \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } } $$  딥러닝 모델의 손실(오차) $L$은 다음과 같이 크로스엔트로피로 정의됩니다. 스칼라 값입니다. 아래에서 $y_j$는 정답 벡터의 $j$번째 요소라는 뜻입니다. 예컨대 3범주 분류를 하는 문제에서 어떤 데이터의 정답이 첫번째 범주라면 $y=[1,0,0]$이 되고, $y_1=1$, 나머지 $y_2, y_3$은 0이 됩니다. $p_j$는 소프트맥스 함수의 $j$번째 출력값입니다.  $$ L=-\sum _{ j }^{ }{ { y }_{ j }\log { { p }_{ j } } } $$   ## 미분 기초 역전파를 본격적으로 살펴보기에 앞서 몇 가지 미분 공식을 정리하고 넘어가겠습니다.  $$ \begin{align*} y=exp\left( x \right) &\leftrightharpoons \frac { \partial y }{ \partial x } =exp\left( x \right) \\ y=\log { x } &\leftrightharpoons \frac { \partial y }{ \partial x } =\frac { 1 }{ x } \\ y=\frac { f\left( x \right) }{ g\left( x \right) }& \leftrightharpoons \frac { \partial y }{ \partial x } =\frac { f^{ ' }\left( x \right) g\left( x \right) -f\left( x \right) g^{ ' }\left( x \right) }{ { g\left( x \right) }^{ 2 } } \end{align*} $$   ## 소프트맥스 함수의 그래디언트 소프트맥스 함수의 $i$번째 출력값 $p_i$, $j$번째 출력값 $p_j$에 대한 Softmax-with-Loss 계층의 $i$번째 입력값 $a_i$의 그래디언트는 각각 다음과 같습니다. 우선 $i=j$인 경우부터 살펴보겠습니다.  $$ \frac { \partial { p }_{ i } }{ \partial { a }_{ i } } =\frac { \partial \frac { exp\left( { a }_{ i } \right) }{ \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } } }{ \partial { a }_{ i } } $$  $p_i$는 분수형 함수이므로 분자 $exp(a_i)$를 $f$, 분모 $Σ_kexp(a_k)$를 $g$로 보고 위 미분공식을 활용해 다시 적으면 다음과 같습니다. 여기에서 $Σ_kexp(a_k)$를 $a_i$에 대해 편미분한 결과는 $exp(a_i)$를 제외한 나머지 항은 상수 취급돼 소거되므로 $g'$은 $exp(a_i)$가 됩니다.   $$ \begin{align*} \frac { \partial { p }_{ i } }{ \partial { a }_{ i } } &=\frac { exp\left( { a }_{ i } \right) \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } -exp\left( { a }_{ i } \right) exp\left( { a }_{ i } \right) }{ { \left( \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } \right) }^{ 2 } } \\ &=\frac { exp\left( { a }_{ i } \right) \left[ \sum _{ k }^{ }{ \left\{ exp\left( { a }_{ k } \right) \right\} } -exp\left( { a }_{ i } \right) \right] }{ { \left( \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } \right) }^{ 2 } } \\ &=\frac { exp\left( { a }_{ i } \right) }{ \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } } \frac { \sum _{ k }^{ }{ \left\{ exp\left( { a }_{ k } \right) \right\} } -exp\left( { a }_{ i } \right) }{ \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } } \\ &=\frac { exp\left( { a }_{ i } \right) }{ \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } } \left( 1-\frac { exp\left( { a }_{ i } \right) }{ \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } } \right) \\ \\&={ p }_{ i }\left( 1-{ p }_{ i } \right) \end{align*} $$  다음은 $i≠j$인 경우입니다. $p_i$는 분수형 함수이므로 분자 $exp(a_i)$를 $f$, 분모 $Σ_kexp(a_k)$를 $g$로 보고 미분공식을 활용해 적으면 다음과 같습니다. 그런데 $exp(a_i)$를 $a_j$에 대해 편미분하면 0이 되므로 $f'g$ 역시 0이 됩니다. 아울러 여기에서 $Σ_kexp(a_k)$를 $a_j$에 대해 편미분한 결과는 $exp(a_j)$를 제외한 나머지 항은 상수 취급돼 소거되므로 $g'$은 $exp(a_j)$가 됩니다.   $$ \begin{align*} \frac { \partial { p }_{ i } }{ \partial { a }_{ j } } &=\frac { 0-exp\left( { a }_{ i } \right) exp\left( { a }_{ j } \right) }{ { \left( \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } \right) }^{ 2 } } \\ &=-\frac { exp\left( { a }_{ i } \right) }{ \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } } \frac { exp\left( { a }_{ j } \right) }{ \sum _{ k }^{ }{ exp\left( { a }_{ k } \right) } } \\ \\ &=-{ p }_{ i }{ p }_{ j } \end{align*} $$   ## 역전파 손실에 대한 Softmax-with-Loss 계층의 $i$번째 입력값 $a_i$의 그래디언트는 다음과 같이 유도됩니다.  $$ \begin{align*} \frac { \partial L }{ \partial { a }_{ i } } &=\frac { \partial \left( -\sum _{ j }^{ }{ { y }_{ j }\log { { p }_{ j } } } \right) }{ \partial { a }_{ i } } \\ &=-\sum _{ j }^{ }{ { y }_{ j } } \frac { \partial \log { { p }_{ j } } }{ \partial { a }_{ i } } \\ &=-\sum _{ j }^{ }{ { y }_{ j } } \frac { 1 }{ { p }_{ j } } \frac { \partial { p }_{ j } }{ \partial { a }_{ i } } \end{align*} $$   소프트맥스 함수의 그래디언트($\partial{p_j}/\partial{a_i}$)는 $i$와 $j$가 같을 때와 다를 때 각기 상이한 값이 도출되므로 위 식의 시그마 부분에서 $i$번째 입력값에 해당하는 요소를 분리해 두 개의 항으로 표현하면 다음과 같습니다. 여기에서 소프트맥스 확률의 합 $Σ_jy_j$는 1이 됩니다.  $$ \begin{align*} -\sum _{ j }^{ }{ { y }_{ j } } \frac { 1 }{ { p }_{ j } } \frac { \partial { p }_{ j } }{ \partial { a }_{ i } } &=-\frac { { y }_{ i } }{ { p }_{ i } } { p }_{ i }\left( 1-{ p }_{ i } \right) -\sum _{ i\neq j }^{ }{ \frac { { y }_{ j } }{ { p }_{ j } } } \left( -{ p }_{ i }{ p }_{ j } \right) \\ &=-{ y }_{ i }+{ y }_{ i }{ p }_{ i }+\sum _{ i\neq j }^{ }{ { y }_{ j }{ p }_{ i } } \\ &=-{ y }_{ i }+\sum _{ j }^{ }{ { y }_{ j }{ p }_{ i } } \\ &=-{ y }_{ i }+{ p }_{ i }\sum _{ j }^{ }{ { y }_{ j } } \\ \\&={ p }_{ i }-{ y }_{ i } \end{align*} $$   ## 코드 구현 요컨대 Softmax-with-Loss 노드의 그래디언트를 구하려면 입력 벡터에 소프트맥스를 취한 뒤, 정답 레이블에 해당하는 요소값만 1을 빼주면 된다는 얘기입니다. 이를 파이썬 코드로 구현하면 아래와 같습니다.  ```python import numpy as np p = np.exp(a) / np.sum(np.exp(a)) # softmax 확률 계산 da = np.copy(p) da[target] -= 1 # target=정답 인덱스 ``` 수식은 복잡하게 전개됐지만 그래디언트를 구하기가 매우 쉽고, 이렇게 구한 그래디언트 또한 0으로 죽는 일이 많지 않아서 소프트맥스+크로스 엔트로피가 많이들 쓰이는 것 같습니다.  
rnnlstm␞ 이번 포스팅에서는 **Recurrent Neural Networks(RNN)**과 RNN의 일종인 **Long Short-Term Memory models(LSTM)**에 대해 알아보도록 하겠습니다. 우선 두 알고리즘의 개요를 간략히 언급한 뒤 foward, backward compute pass를 천천히 뜯어보도록 할게요.  이번 포스팅은 기본적으로 미국 스탠포드대학의 [CS231n 강좌](http://cs231n.stanford.edu/syllabus.html)를 참고하되 forward, backward pass 관련 설명과 그림은 제가 직접 만들었음을 밝힙니다. **GRU(Gated Recurrent Unit)**가 궁금하신 분은 [이곳](https://ratsgo.github.io/deep%20learning/2017/05/13/GRU/)을 참고하시면 좋을 것 같습니다. 자, 그럼 시작하겠습니다!  ## RNN의 기본 구조 <a href="http://imgur.com/Q8zv6TQ"><img src="http://i.imgur.com/Q8zv6TQ.png" width="500px" title="source: imgur.com" /></a> RNN은 히든 노드가 방향을 가진 엣지로 연결돼 순환구조를 이루는(directed cycle) 인공신경망의 한 종류입니다. 음성, 문자 등 순차적으로 등장하는 데이터 처리에 적합한 모델로 알려져 있는데요. **Convolutional Neural Networks(CNN)**과 더불어 최근 들어 각광 받고 있는 알고리즘입니다.  위의 그림에서도 알 수 있듯 시퀀스 길이에 관계없이 인풋과 아웃풋을 받아들일 수 있는 네트워크 구조이기 때문에 필요에 따라 다양하고 유연하게 구조를 만들 수 있다는 점이 RNN의 가장 큰 장점입니다.  <a href="http://imgur.com/s8nYcww"><img src="http://i.imgur.com/s8nYcww.png" width="500px" title="source: imgur.com" /></a> RNN의 기본 구조는 위 그림과 같습니다. 녹색 박스는 히든 state를 의미합니다. 빨간 박스는 인풋 $x$, 파란 박스는 아웃풋 $y$입니다. 현재 상태의 히든 state $h_t$는 직전 시점의 히든 state $h_{t-1}$를 받아 갱신됩니다.  현재 상태의 아웃풋 $y_t$는 $h_t$를 전달받아 갱신되는 구조입니다. 수식에서도 알 수 있듯 히든 state의 **활성함수(activation function)**은 **비선형 함수**인 **하이퍼볼릭탄젠트(tanh)**입니다.  그런데 활성함수로 왜 비선형 함수를 쓰는걸까요? [밑바닥부터 시작하는 딥러닝](http://book.naver.com/bookdb/book_detail.nhn?bid=11492334)의 글귀를 하나 인용해 보겠습니다. > 선형 함수인 $h(x) = cx$를 활성 함수로 사용한 3층 네트워크를 떠올려 보세요. 이를 식으로 나타내면 $y(x) = h(h(h(x)))$가 됩니다. 이 계산은 $y(x) = c * c * c * x$처럼 세번의 곱셈을 수행하지만 실은 $y(x) = ax$와 똑같은 식입니다. $a = c^3$이라고만 하면 끝이죠. 즉 히든레이어가 없는 네트워크로 표현할 수 있습니다. 그래서 층을 쌓는 혜택을 얻고 싶다면 활성함수로는 반드시 비선형함수를 사용해야 합니다.  ## RNN의 기본 구조 RNN의 기본 동작을 직관적으로 이해해 보기 위해 CS231n 강좌의 Karpathy~~갓파시~~가 든 예제를 가져와 봤습니다. 어떤 글자가 주어졌을 때 바로 다음 글자를 예측하는 character-level-model을 만든다고 칩시다. 예컨대 RNN 모델에 'hell'을 넣으면 'o'를 반환하게 해 결과적으로는 'hello'를 출력하게 만들고 싶은 겁니다.  우선 우리가 가진 학습데이터의 글자는 'h', 'e', 'l', 'o' 네 개뿐입니다. 이를 [one-hot-vector](https://en.wikipedia.org/wiki/One-hot)로 바꾸면 각각 $[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1]$이 됩니다. <a href="http://imgur.com/vrD0VO1"><img src="http://i.imgur.com/vrD0VO1.png" width="500px" title="source: imgur.com" /></a>  $x_1$은 $[1,0,0,0]$입니다. 이를 기반으로 $h_1$인 $[0.3, -0.1, 0.9]$를 만들었습니다($h_0$는 존재하지 않기 때문에 랜덤 값을 집어넣습니다). 이를 바탕으로 $y_1$인 $[1.0, 2.2, -3.0, 4.1]$로 생성했습니다. 마찬가지로 두번째, 세번째, 네번째 단계들도 모두 갱신하게 됩니다. 이 과정을 **순전파(foward propagation)**라고 부릅니다. 다른 인공신경망과 마찬가지로 RNN도 정답을 필요로 합니다. 모델에 정답을 알려줘야 모델이 **parameter**를 적절히 갱신해 나가겠죠. 이 경우엔 바로 다음 글자가 정답이 되겠네요. 예컨대 'h'의 다음 정답은 'e', 'e' 다음은 'l', 'l' 다음은 'l', 'l' 다음은 'o'가 정답입니다.  위의 그림을 기준으로 설명을 드리면 첫번째 정답인 'e'는 두번째 요소만 1이고 나머지가 0인 one-hot-vector입니다. 그림을 보면 아웃풋에 진한 녹색으로 표시된 숫자들이 있는데 정답에 해당하는 인덱스를 의미합니다. 이 정보를 바탕으로 **역전파(backpropagation)**를 수행해 parameter값들을 갱신해 나갑니다.  그렇다면 RNN이 학습하는 parameter는 무엇일까요? 인풋 $x$를 히든레이어 $h$로 보내는 $W_{xh}$, 이전 히든레이어 $h$에서 다음 히든레이어 $h$로 보내는 $W_{hh}$, 히든레이어 $h$에서 아웃풋 $y$로 보내는 $W_{hy}$가 바로 parameter입니다. 그리고 모든 시점의 state에서 이 parameter는 동일하게 적용됩니다(**shared weights**).    ## RNN의 순전파 앞장에서 말씀드린 RNN의 기본 구조를 토대로 forward compute pass를 아래와 같이 그려봤습니다. 위에서 설명한 수식을 그래프로 옮겨놓은 것일 뿐입니다.  <a href="http://imgur.com/TIdBDTJ"><img src="http://i.imgur.com/TIdBDTJ.png" width="600px" title="source: imgur.com" /></a>  ## RNN의 역전파 자, 이제 backward pass를 볼까요? 아래 그림과 같습니다. 혹시 역전파가 생소하신 분은 [이곳](https://ratsgo.github.io/deep%20learning/2017/05/14/backprop/)을 참고하시기 바랍니다. <a href="http://imgur.com/Xtpgxzu"><img src="http://i.imgur.com/Xtpgxzu.gif" width="600px" title="source: imgur.com" /></a> 위 움짤과 아래 그림은 같은 내용입니다. 우선 forward pass를 따라 최종 출력되는 결과는 $y_t$입니다. 최종 Loss에 대한 $y_t$의 그래디언트($dL/dy_t$)가 RNN의 역전파 연산에서 가장 먼저 등장합니다. 이를 편의상 $dy_t$라고 표기했고, 순전파 결과 $y_t$와 대비해 붉은색으로 표시했습니다. 앞으로 이 표기를 따를 예정입니다. $dy_t$는 덧셈 그래프를 타고 양방향에 모두 그대로 분배가 됩니다. $dW_{hy}$는 흘러들어온 그래디언트 $dy_t$에 로컬 그래디언트 $h_t$를 곱해 구합니다. $dh_t$는 흘러들어온 그래디언트 $dy_t$에 $W_{hy}$를 곱한 값입니다. $dh_{raw}$는 흘러들어온 그래디언트인 $dh_t$에 로컬 그래디언트인 $1-tanh^2(h_{raw})$을 곱해 구합니다. 나머지도 동일한 방식으로 구합니다. <a href="http://imgur.com/XYDxsNs"><img src="http://i.imgur.com/XYDxsNs.png" width="600px" title="source: imgur.com" /></a> 다만 아래 그림에 주의할 필요가 있습니다. RNN은 히든 노드가 순환 구조를 띄는 신경망입니다. 즉 $h_t$를 만들 때 $h_{t-1}$가 반영됩니다. 바꿔 말하면 아래 그림의 $dh_{t-1}$은 t-1 시점의 Loss에서 흘러들어온 그래디언트인 $W_{hy}*dy_{t-1}$뿐 아니라 ★에 해당하는 그래디언트 또한 더해져 동시에 반영된다는 뜻입니다.  <a href="http://imgur.com/hEtvXnN"><img src="http://i.imgur.com/hEtvXnN.png" width="600px" title="source: imgur.com" /></a>    ## LSTM의 기본 구조 <a href="http://imgur.com/H9UoXdC"><img src="http://i.imgur.com/H9UoXdC.png" width="500px" title="source: imgur.com" /></a> RNN은 관련 정보와 그 정보를 사용하는 지점 사이 거리가 멀 경우 역전파시 그래디언트가 점차 줄어 학습능력이 크게 저하되는 것으로 알려져 있습니다. 이를 **vanishing gradient problem**이라고 합니다.  이 문제를 극복하기 위해서 고안된 것이 바로 LSTM입니다. LSTM은 RNN의 히든 state에 cell-state를 추가한 구조입니다. LSTM을 가장 쉽게 시각화한 [포스트](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)를 기본으로 해서 설명을 이어나가겠습니다. <a href="http://imgur.com/jKodJ1u"><img src="http://i.imgur.com/jKodJ1u.png" width="500px" title="source: imgur.com" /></a> cell state는 일종의 컨베이어 벨트 역할을 합니다. 덕분에 state가 꽤 오래 경과하더라도 그래디언트가 비교적 전파가 잘 되게 됩니다. LSTM 셀의 수식은 아래와 같습니다. ⊙는 요소별 곱셈을 뜻하는 Hadamard product 연산자입니다.   $$ \begin{align*} { f }_{ t }&=\sigma ({ W }_{ xh\_ f }{ x }_{ t }+{ W }_{ hh\_ f }{ h }_{ t-1 }+{ b }_{ h\_ f })\\ { i }_{ t }&=\sigma ({ W }_{ xh\_ i }{ x }_{ t }+{ W }_{ hh\_ i }{ h }_{ t-1 }+{ b }_{ h\_ i })\\ { o }_{ t }&=\sigma ({ W }_{ xh\_ o }{ x }_{ t }+{ W }_{ hh\_ o }{ h }_{ t-1 }+{ b }_{ h\_ o })\\ { g }_{ t }&=\tanh { ({ W }_{ xh\_ g }{ x }_{ t }+{ W }_{ hh\_ g }{ h }_{ t-1 }+{ b }_{ h\_ g }) } \\ { c }_{ t }&={ f }_{ t }\odot { c }_{ t-1 }+{ i }_{ t }\odot { g }_{ t }\\ { h }_{ t }&={ o }_{ t }\odot \tanh { ({ c }_{ t }) } \end{align*} $$  **forget gate** $f_t$는 '과거 정보를 잊기'를 위한 게이트입니다. $h_{t-1}$과 $x_t$를 받아 시그모이드를 취해준 값이 바로 forget gate가 내보내는 값이 됩니다. 시그모이드 함수의 출력 범위는 0에서 1 사이이기 때문에 그 값이 0이라면 이전 상태의 정보는 잊고, 1이라면 이전 상태의 정보를 온전히 기억하게 됩니다.  **input gate** $i_t⊙g_t$는 '현재 정보를 기억하기' 위한 게이트입니다. $h_{t-1}$과 $x_t$를 받아 시그모이드를 취하고, 또 같은 입력으로 하이퍼볼릭탄젠트를 취해준 다음 Hadamard product 연산을 한 값이 바로 input gate가 내보내는 값이 됩니다. 개인적으로 $i_t$의 범위는 0~1, $g_t$의 범위는 -1~1이기 때문에 각각 강도와 방향을 나타낸다고 이해했습니다.  <a href="http://imgur.com/MPb3OvZ"><img src="http://i.imgur.com/MPb3OvZ.png" width="600px" title="source: imgur.com" /></a>   ## LSTM의 순전파 LSTM 순전파는 아래와 같습니다.  <a href="http://imgur.com/7Jk6szL"><img src="http://i.imgur.com/7Jk6szL.png" width="600px" title="source: imgur.com" /></a> 여기서 주목해야 할 점은 $H_t$입니다. 이 행렬을 행 기준으로 4등분해 $i, f, o, g$ 각각에 해당하는 활성함수를 적용하는 방식으로 $i, f, o, g$를 계산합니다. (물론 이렇게 계산하지 않고 다른 방식을 써도 관계는 없습니다) 이를 그림으로 나타내면 다음과 같습니다.  <a href="http://imgur.com/73zzDsC"><img src="http://i.imgur.com/73zzDsC.png" width="600px" title="source: imgur.com" /></a>  ## LSTM의 역전파 그럼 이제 LSTM의 역전파를 알아볼까요? 아래 움짤과 같습니다.  <a href="http://imgur.com/2BZtc2l"><img src="http://i.imgur.com/2BZtc2l.gif" width="600px" title="source: imgur.com" /></a> 이제부터 나열한 그림은 위 움짤과 내용이 같습니다. 우선 $df_t, di_t, dg_t, do_t$를 구하기까지 backward pass는 RNN과 유사합니다.  <a href="http://imgur.com/hTPFF4A"><img src="http://i.imgur.com/hTPFF4A.png" width="600px" title="source: imgur.com" /></a> $dH_t$를 구하는 과정이 LSTM backward pass 핵심이라고 할 수 있죠. $H_t$는 $i_t, f_t, o_t, g_t$로 구성된 행렬입니다. 바꿔 말하면 각각에 해당하는 그래디언트를 이를 합치면(merge) $dH_t$를 만들 수 있다는 뜻입니다. $i, f, o$의 활성함수는 시그모이드이고, $g$만 하이퍼볼릭탄젠트입니다. 각각의 활성함수에 대한 로컬 그래디언트를 구해 흘러들어온 그래디언트를 곱해주면 됩니다. <a href="http://imgur.com/ZkYBqPq"><img src="http://i.imgur.com/ZkYBqPq.png" width="600px" title="source: imgur.com" /></a>  순전파 과정에서 $H_t$를 4등분해 $i_t, f_t, o_t, g_t$를 구했던 것처럼, backward pass에서는 $d_i, d_f, d_o, d_g$를 다시 합쳐 $dH_t$를 만듭니다. 이렇게 구한 $dH_t$는 다시 RNN과 같은 방식으로 역전파가 되는 구조입니다.  <a href="http://imgur.com/sM4rlmr"><img src="http://i.imgur.com/sM4rlmr.png" width="600px" title="source: imgur.com" /></a> LSTM은 cell state와 히든 state가 재귀적으로 구해지는 네트워크입니다. 따라서 cell state의 그래디언트와 히든 state의 그래디언트는 직전 시점의 그래디언트 값에 영향을 받습니다. 이는 RNN과 마찬가지입니다. 이를 역전파시 반영해야 합니다.    ## 파이썬 구현 CS231n 강좌에 파이썬 numpy 패키지만 활용해 구현해놓은 [RNN 코드](https://gist.github.com/karpathy/d4dee566867f8291f086)가 있습니다. 여기서 손실함수만 바꾸면 비교적 쉽게 LSTM 구조로 변경할 수가 있는데요. 제가 인터넷에 떠다니는 여러 자료를 보면서 글자나 단어 단위로 학습하기 위한 LSTM 손실 함수를 만들어봤습니다. 위 설명과 notation이 약간 다르긴 한데, 본질적으로는 완전히 같은 코드입니다. <script src="https://gist.github.com/ratsgo/6e9a094c7108dee8147ef0a13666de47.js"></script>   ## 파일럿 실험 이광수 장편소설 '무정'에 위 코드를 실험해봤습니다. '무정'은 32만 어절로 이뤄진 작품입니다. 1917년 작품이며 한자어와 대화체 문장이 많습니다. 텍스트는 이렇게 생겼습니다. ``` 형식은, 아뿔싸! 내가 어찌하여 이러한 생각을 하는가, 내 마음이 이렇게 약하던가 하면서 두 주먹을 불끈 쥐고 전신에 힘을 주어 이러한 약한 생각을 떼어 버리려 하나, 가슴속에는 이상하게 불길이 확확 일어난다. 이때에, “미스터 리, 어디로가는가” 하는 소리에 깜짝 놀라 고개를 들었다. (중략) 형식은 얼마큼 마음에 수치한 생각이 나서 고개를 돌리며, “아직 그런말에 익숙지를 못해서……” 하고 말끝을 못 맺는다. “대관절 어디로 가는 길인가? 급하지 않거든 점심이나 하세그려.” “점심은 먹었는걸.” “그러면 맥주나 한잔 먹지.” “내가 술을 먹는가.” (중략) “요― 오메데토오(아― 축하하네). 이이나즈케(약혼한사람)가 있나 보네 그려. 음나루호도(그러려니). 그러구도 내게는 아무 말도 없단 말이야. 에, 여보게”하고 손을 후려친다. ``` 이 텍스트를 글자 단위로 one-hot-vector로 바꾼 뒤 LSTM에 넣어 학습시켜 보기로 했습니다. 하이퍼파라메터는 히든 차원수 100, learning rate 0.1을 줬습니다. 다음은 학습 결과입니다. > Iter 0 : 랫萬게좁뉘쁠름끈玄른작밭裸觀갈나맡文플조바늠헝伍下잊볕홀툽뤘혈調記운피悲렙司狼독벗칼둡걷착날完잣老엇낫業4改‘촉수릎낯깽잊쯤죽道넌友련친씌았융타雲채發造거크휘탁亨律與命텐암먼헝평琵헤落유리벤産이馨텐  > Iter 4900: 를왔다내 루방덩이종 은얼에는 집어흔영채는아무 우선을 에서가며 건들하아버전는 애양을자에 운 모양이 랐다. 은 한다선과 ‘마는 .식세식가들어 , > > 형식다 > > “내었다.있이문 > Iter750000 : 으로 유안하였다. 더할까하는 세상이 솔이요, 알고 게식도 들어울는 듯하였다. 태에그려 깔깔고 웃는듯이 흔반다. 우선형은사람을 어려보낸다. > > “그려가?” > > 한다. 영채는손을 기쁘  > Iter1000000 : 에 돌내면서, > > “여러 넣어오습데다. 그 말대 아무도좀 집림과 시오 백매, 저는 열녀더러, 기런 소년이가아니라.” > > “어리지요.” > > 노파도 놀라며, > > “저희마다가말없습니까.” > > “아니 (대화체) 꽤 오랜 시간 학습시켰음에도 여전히 뜻 모를 글자들을 내뱉고 있는 점이 아쉽습니다. 다만 '영채', '선형' 등 무정 인물명들을 언급하거나, 따옴표를 써서 대화체 문장을 구성하거나, '-요' '-까' '-다' 같은 종결어미를 사용해 문장을 끝맺고 있는 등 잘 하고 있는 점도 눈에 띕니다. 긴 글 읽어주셔서 감사합니다. 
CC␞ 이번 글에서는 [그래프(Graph)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/)의 **연결요소(Connected Components)**를 찾아내는 기법을 살펴보도록 하겠습니다. 이 글은 고려대 김황남 교수님 강의와 위키피디아를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## concept [연결요소](https://ratsgo.github.io/data%20structure&algorithm/2017/11/18/graph/)란 원그래프 $G$ 가운데 노드와 엣지가 서로 겹치지 않는 부그래프이되, 부그래프 내 모든 노드쌍에 대해 경로가 존재하는 걸 가리킵니다. 연결요소를 구축하는 기법은 [디스조인트 셋(Disjoint Set)](https://ratsgo.github.io/data%20structure&algorithm/2017/11/12/disjointset/)으로 구현하게 됩니다. 예컨대 원그래프 $G$에 아래와 같은 연결요소들 4개가 있다고 칩시다. <a href="https://imgur.com/EK3sI5c"><img src="https://i.imgur.com/EK3sI5c.png" width="500px" title="source: imgur.com" /></a> 연결요소를 구축하는 알고리즘은 엣지를 중심으로 수행합니다. 위 그래프의 엣지 리스트는 다음과 같습니다. - ($b, d$) - ($e, g$) - ($a,c$) - ($h,i$) - ($a,b$) - ($e,f$) - ($b,c$) 우선 모든 노드에 대해 `make-set` 연산을 수행합니다. 각 노드를 유일한 원소로 하는 새로운 셋을 만든다는 뜻입니다. - {$a$}, {$b$}, {$c$}, {$d$}, {$e$}, {$f$}, {$g$}, {$h$}, {$i$}, {$j$} 이제 그래프 내 모든 엣지를 하나씩 검토합니다. 우선 첫번째 엣지인 ($b,d$)를 보겠습니다. 노드 $b$가 속한 셋의 대표값(루트노드)을 찾습니다(`find` 연산). 그리고 $c$의 대표값을 찾습니다. 둘을 비교하니 서로 다르므로($b≠c$) 두 셋을 합칩니다(`union` 연산). 결과는 다음과 같습니다. - {$a$}, {$b,d$}, {$c$}, {$e$}, {$f$}, {$g$}, {$h$}, {$i$}, {$j$} 다음 ($e,g$)를 보겠습니다. $e$가 포함된 셋과 $g$의 셋이 서로 다르므로 두 셋을 합칩니다. ($a,c$), ($h,i$), ($a,b$), ($e,f$)도 마찬가지입니다. 다음과 같습니다. - {$a,b,c,d$}, {$e,f,g$}, {$h,i$}, {$j$} 마지막으로 ($b,c$)를 보겠습니다. $b$가 포함된 셋의 루트노드와 $c$가 포함된 셋의 루트노드가 $a$로 서로 같습니다. 이대로 연산을 마칩니다. 다음과 같습니다. - {$a,b,c,d$}, {$e,f,g$}, {$h,i$}, {$j$} 이렇게 만든 연결요소가 있고, 임의의 노드 $u$와 $v$가 같은 연결요소 내에 있는지 여부를 가려내려면 다음과 같이 수행합니다. - `find(u)`와 `find(v)`가 같은 결과이면 *True* - 그렇지 않으면 *False* 
backprop␞ 이번 글에서는 **오차 역전파법(backpropagation)**에 대해 살펴보도록 하겠습니다. 이번 글은 미국 스탠포드대학의 CS231n 강의를 기본으로 하되, 고려대학교 데이터사이언스 연구실의 김해동 석사과정이 쉽게 설명한 자료를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.   ## 계산그래프와 chain rule **계산그래프(computational graph)**는 계산과정을 그래프로 나타낸 것입니다. **노드(node, 꼭지점)**은 함수(연산), **엣지(edge, 간선)**는 값을 뜻합니다. $y=f(x)$를 나타내는 계산그래프는 아래 그림과 같습니다.  <a href="http://imgur.com/o8Q7slz"><img src="http://i.imgur.com/o8Q7slz.png" width="300px" title="source: imgur.com" /></a>  계산그래프에서 계산을 왼쪽에서 오른쪽으로 진행하는 단계를 **순전파(forward propagation)**라고 합니다. 위 그림 기준으로는 녹색 화살표가 됩니다. 입력값 $x$는 함수 $f$를 거쳐 $y$로 순전파되고 있는 점을 확인할 수 있습니다. 반대로 계산을 오른쪽에서 왼쪽으로 진행하는 단계를 **역전파(backward propagation)**라고 합니다. 빨간색 화살표가 역전파를 가리킵니다. 여기에서 $∂L/∂y$의 의미에 주목할 필요가 있습니다. 지금은 예시이기 때문에 노드를 하나만 그렸지만, 실제 뉴럴네트워크는 이러한 노드가 꽤 많은 큰 계산그래프입니다. 이 네트워크는 최종적으로는 정답과 비교한 뒤 **Loss**를 구합니다.  우리의 목적은 뉴럴네트워크의 오차를 줄이는 데 있기 때문에, 각 파라메터별로 Loss에 대한 그래디언트를 구한 뒤 그래디언트들이 향한 쪽으로 파라메터들을 업데이트합니다. $∂L/∂y$는 $y$에 대한 Loss의 변화량, 즉 Loss로부터 흘러들어온 그래디언트라고 이해하면 좋을 것 같습니다. 이제는 현재 입력값 $x$에 대한 Loss의 변화량, 즉 $∂L/∂x$를 구할 차례입니다. 이는 **미분의 연쇄법칙(chain rule)**에 의해 다음과 같이 계산할 수 있습니다.  $$ \frac { \partial L }{ \partial x } =\frac { \partial y }{ \partial x } \frac { \partial L }{ \partial y } $$  이미 설명드렸듯 $∂L/∂y$는 Loss로부터 흘러들어온 그래디언트입니다. $∂y/∂x$는 현재 입력값에 대한 현재 연산결과의 변화량, 즉 **로컬 그래디언트(Local Gradient)**입니다.  다시 말해 현재 입력값에 대한 Loss의 변화량은 Loss로부터 흘러들어온 그래디언트에 로컬 그래디언트를 곱해서 구한다는 이야기입니다. 이 그래디언트는 다시 앞쪽에 배치돼 있는 노드로 역전파됩니다.   ## 덧셈 노드 덧셈 노드의 수식은 아래와 같습니다.  $$ z=f(x,y)=x+y $$  덧셈 노드의 로컬 그래디언트는 아래와 같습니다.  $$ \frac { \partial z }{ \partial x } =\frac { \partial (x+y) }{ \partial x } =1\\ \frac { \partial z }{ \partial y } =\frac { \partial (x+y) }{ \partial y } =1 $$  덧셈 노드의 계산그래프는 아래와 같습니다. 현재 입력값에 대한 Loss의 변화량은 로컬 그래디언트에 흘러들어온 그래디언트를 각각 곱해주면 됩니다. 덧셈 노드의 역전파는 흘러들어온 그래디언트를 그대로 흘려보내는 걸 확인할 수 있습니다. <a href="http://imgur.com/phMalGK"><img src="http://i.imgur.com/phMalGK.png" width="300px" title="source: imgur.com" /></a>   ## 곱셈 노드 곱셈 노드의 수식은 아래와 같습니다.  $$ z=f(x,y)=xy $$  곱셈 노드의 로컬 그래디언트는 아래와 같습니다.  $$ \frac { \partial z }{ \partial x } =\frac { \partial (xy) }{ \partial x } =y\\ \frac { \partial z }{ \partial y } =\frac { \partial (xy) }{ \partial y } =x $$  곱셈 노드의 계산그래프는 아래와 같습니다. 현재 입력값에 대한 Loss의 변화량은 로컬 그래디언트에 흘러들어온 그래디언트를 각각 곱해주면 됩니다. 곱셈 노드의 역전파는 순전파 때 입력 신호들을 서로 바꾼 값을 곱해서 하류로 흘려보내는 걸 확인할 수 있습니다. <a href="http://imgur.com/5BycHN1"><img src="http://i.imgur.com/5BycHN1.png" width="300px" title="source: imgur.com" /></a>   ## ReLU 노드 **활성화함수(activation function)**로 사용되는 **ReLU**는 다음 식처럼 정의됩니다.  $$ y=x\quad (x>0)\\ y=0\quad (x\le 0) $$  ReLU 노드의 로컬 그래디언트는 아래와 같습니다.  $$ \frac { \partial y }{ \partial x } =1\quad (x>0)\\ \frac { \partial y }{ \partial x } =0\quad (x\le 0) $$  계산그래프는 아래와 같습니다.  <a href="http://imgur.com/FrxDrr5"><img src="http://i.imgur.com/FrxDrr5.png" width="500px" title="source: imgur.com" /></a>   ## Sigmoid 노드 **시그모이드(sigmoid)** 함수는 아래와 같이 정의됩니다.  $$ y=\frac { 1 }{ 1+exp(-x) } $$  시그모이드 노드의 로컬 그래디언트는 다음과 같습니다.  $$ \frac { \partial y }{ \partial x } =y(1-y) $$  계산그래프는 아래와 같습니다.  <a href="http://imgur.com/riURjqG"><img src="http://i.imgur.com/riURjqG.png" width="300px" title="source: imgur.com" /></a>  ## 하이퍼볼릭탄젠트 노드 하이퍼볼릭탄젠트 노드 $y=tanh(x)$의 로컬 그래디언트는 다음과 같습니다.  $$ \frac { \partial y }{ \partial x } =1-{ y }^{ 2 } $$  계산그래프는 아래와 같습니다.  <a href="http://imgur.com/571sOas"><img src="http://i.imgur.com/571sOas.png" width="300px" title="source: imgur.com" /></a>  ## Hadamard product 노드  **Hadamard product**란 요소별 곱셈을 뜻합니다. 기호로는 $⊙$ 등을 씁니다. 예컨대 아래와 같습니다.  $$ \begin{bmatrix} 1 \\ 3 \\ 2 \end{bmatrix}\odot \begin{bmatrix} 4 \\ 5 \\ 3 \end{bmatrix}=\begin{bmatrix} 4 \\ 15 \\ 6 \end{bmatrix} $$  두 벡터에 Hadamard product 연산을 적용했을 때, 그 로컬 그래디언트는 아래와 같습니다. <a href="http://imgur.com/u5VqWFj"><img src="http://i.imgur.com/u5VqWFj.png" width="500px" title="source: imgur.com" /></a>  Hadamard product 노드 또한 다른 노드와 마찬가지로 위 로컬 그래디언트에 흘러들어온 그래디언트를 내적(inner product)해서 현시점의 그래디언트를 계산합니다. 그런데 흘러들어온 그래디언트 또한 벡터일 경우 Hadamard product 노드 로컬 그래디언트의 대각성분(위 그림에서 $h_{t-1}^1$,...,$h_{t-1}^n$)과 요소별 곱셈을 하여도 같은 결과가 나옵니다.   ## 벡터, 행렬로의 확장 지금까지 말씀드린 역전파는 기본적으로 스칼라를 대상으로 한 편미분과 역전파였습니다. 하지만 여기에 적용된 원칙들은 벡터, 행렬에도 적용할 수 있습니다. 해당 변수에 대한 그래디언트는 해당 변수의 차원 수와 일치해야 한다는 원칙을 기억하고 있으면 됩니다. 이와 관련 cs231n의 한 단락을 정리 용도로 캡처해 놨습니다. <a href="https://imgur.com/OzLAK1L"><img src="https://i.imgur.com/OzLAK1L.png" title="source: imgur.com" /></a>   ## Softmax-with-Loss 노드 뉴럴네트워크 말단에 보통 **Softmax-with-Loss** 노드를 둡니다. Softmax-with-Loss란 소프트맥스 함수와 **교차 엔트로피(Cross-Entropy)** 오차를 조합한 노드를 뜻합니다. 소프트맥스 함수와 교차 엔트로피의 수식은 아래와 같습니다.  *$a_k$=노드의 입력값, $L$=노드의 출력값(Loss) $t_k$=정답 레이블(0 혹은 1), $n$=정답 범주 개수*  $$ { y }_{ k }=\frac { exp({ a }_{ k }) }{ \sum _{ i=1 }^{ n }{ exp({ a }_{ i }) } } \\ L=-\sum _{ k }^{ }{ { t }_{ k }\log { { y }_{ k } } } $$  Softmax-with-Loss 노드의 계산그래프를 매우 단순하게 그리면 아래와 같습니다.  <a href="http://imgur.com/gyeTKAn"><img src="http://i.imgur.com/gyeTKAn.png" width="400px" title="source: imgur.com" /></a>  위 그림을 설명하자면 이렇습니다. Softmax-with-Loss 노드는 $a$를 입력으로 받아서 Loss $L$을 출력합니다. 역전파하는 그래디언트는 $y_k-t_k$가 됩니다. 예컨대 정답이 $t_3$이라면 역전파되는 그래디언트는 각각 $y_1, y_2, y_3-1$이 됩니다. 요컨대 Softmax-with-Loss 노드의 역전파 그래디언트를 구하려면 입력값에 소프트맥스 확률값을 취한 뒤, 정답 레이블에 해당하는 요소만 1을 빼주면 된다는 얘기입니다. 이를 파이썬 코드로 구현하면 아래와 같습니다. ```python import numpy as np p = np.exp(a) / np.sum(np.exp(a)) # softmax 확률 계산 da = np.copy(p) da[target] -= 1 # target=정답 인덱스를 갖고 있는 변수 ```   
linearity␞ 이번 포스팅에선 **선형대수학(Linear Algebra)**의 **선형성(linearity)**, **선형결합(linear combination)** 개념을 알아보도록 하겠습니다. 이번 글은 [고려대 박성빈 교수님]([hyperspace@korea.ac.kr](mailto:hyperspace@korea.ac.kr))과 [한양대 이상화 교수님](http://www.kocw.net/home/search/kemView.do?kemId=977757) 강의를 참고했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 선형성 선형성이란 직선처럼 똑바른 도형, 또는 그와 비슷한 성질을 갖는 대상이라는 뜻으로, 함수의 경우 그 모양이 '직선'이라는 의미로 사용됩니다. 수학에서 선형성의 정의는 다음과 같습니다. 임의의 수 x, y와 함수 f에 대해 아래 두 조건을 동시에 만족해야 합니다. > **superposition** : f(x+y) = f(x) + f(y) > > **homogeneity** : 임의의 수 a에 대해 f(ax) = af(x) 위 조건을 만족하는 예로는 1차 다항함수(y=mx), 미분/적분연산 등이 있습니다. 또한 행렬과 벡터 곱셈(multiplication)도 선형성을 가집니다. 다만 여기서 주의해야할 것은 원점을 지나지 않는 직선의 방정식(예를 들면 y=2x+1)은 위 선형성 조건에 위배됨을 확인할 수 있습니다. 원점을 통과하지 않는 직선에 굳이 선형성을 정의하려면 **x의 변화량과 y의 변화량에 선형성이 있다** 정도로 언급해야 할 것입니다. 선형대수학은 기본적으로 선형성을 지닌 방정식이나 함수에 대해 다룹니다.  ## 1차 연립방정식 풀이의 두 가지 접근 보통 고등학교 수학과정에선 두 개의 1차 연립방정식의 해를 찾을 때 2차원 사분면에 두 개 직선을 그려, 두 직선의 교점을 찾는 것으로 설명을 하곤 합니다. 다시 말해 아래 그림과 같습니다.  $$3x-y=-2\\ x+y=2$$  <a href="http://imgur.com/Al0vdJ2"><img src="http://i.imgur.com/Al0vdJ2.png" title="source: imgur.com" /></a>  위 직선의 방정식은 아래와 같이 고쳐쓸 수 있습니다. 자세히 보시면 두 방정식에서 x, y의 계수들을 각각 떼어서 벡터 (3,1), (-1,1)로, 상수항들을 묶어서 벡터 (-2,2)로 표현을 한 걸 알 수 있습니다. 미지수 x와 y는 각각 스칼라 값이므로 [스칼라-벡터 곱의 정의](https://ratsgo.github.io/machine%20learning/2017/03/14/operations/)에 의해 위 직선의 방정식과 아래 벡터 형태가 정확히 동일하다는 것 또한 확인 가능합니다.  $$x\begin{bmatrix} 3 \\ 1 \end{bmatrix}+y\begin{bmatrix} -1 \\ 1 \end{bmatrix}=\begin{bmatrix} -2 \\ 2 \end{bmatrix}$$  위 식은 정확히 **선형결합(linear combination)** 정의에 맞는 식입니다. 선형결합이란 벡터들을 스칼라 곱과 벡터의 덧셈을 조합하여 새로운 벡터를 얻는 연산입니다. 스칼라-벡터 곱을 기하학적으로 생각하면 벡터의 길이를 키우거나 줄이는 걸로, 두 벡터의 덧셈은 두 벡터가 이루는 평행사변형의 대각선과 일치합니다. 위의 식의 세 벡터(x계수, y계수, 상수벡터)를 아래와 같이 2차원 평면 위에 그리면 아래 그림과 같습니다. <a href="http://imgur.com/JgEGzmC"><img src="http://i.imgur.com/JgEGzmC.png" title="source: imgur.com" width="400px"/></a> 여기서 우리가 x, y 값을 구한다, 즉 1차 연립방정식의 해를 구한다는 건 빨간색 선과 파란색 선을 적절히 조합해 오렌지색 선으로 일치시키는 작업이라고 봐도 무방합니다. 다시 말해 1차 연립방정식의 해는 '직선의 방정식의 교점'으로도, '미지수 계수벡터의 선형결합으로 상수벡터를 표현'하는 방식으로도 모두 구할 수 있다는 이야기입니다. 이를 조금 더 확장해서 생각해보면, 위 연립방정식의 해가 존재한다는 것은 파란색 벡터가 오렌지색 벡터와 빨간색 벡터의 선형결합으로 표시될 수 있다는 걸 의미합니다. 반대로 해가 존재하지 않는다면 선형결합으로 나타낼 수 없다는 걸 뜻합니다. 이는 **벡터공간(Vector space)**, **생성(span)** 등 개념과 연결되는데 이 챕터의 범위를 넘어서므로 추후에 다시 논의하도록 하겠습니다.  ## 1차 연립방정식 해 존재 여부 다음의 경우 1차 연립방정식의 해는 각각 존재하지 않거나 무수히 많습니다. - 두 직선이 평행(parallel)인 경우 - 두 직선이 포개진(overlap) 경우 이를 계수벡터의 선형결합 관점에서 살펴보도록 하겠습니다. 이 역시 마찬가지입니다. - 두 계수벡터가 평행(parallel)인 경우 - 두 계수벡터가 포개진(overlap) 경우 기하학적으로도 살펴볼까요? 미지수가 x, y, z 세개인 연립방정식을 푼다고 칩시다. 그러면 이 연립방정식의 해는 각각의 미지수에 해당하는 계수들의 벡터를 적절히 선형결합해 상수벡터와 일치시키면 구할 수 있습니다. 아래 그림에서는 빨간색 실선이 상수벡터인데요, x 계수벡터에 해당하는 오렌지색, y 계수벡터에 해당하는 연두색, z 계수벡터에 해당하는 파란색 선을 적절히 결합해서 빨간색 실선을 만들어내는 작업이 이 연립방정식의 해를 찾는 과정입니다.  <a href="http://imgur.com/CsBa37R"><img src="http://i.imgur.com/CsBa37R.png" width="400px" title="source: imgur.com" /></a> 위 그림처럼 네 가지 모든 벡터가 우연히 같은 평면 위에 있다고 칩시다. 그럼 사실 빨간색 상수벡터는 나머지 3개 중 2개 계수벡터만으로도 충분히 선형결합으로 만들어낼 수 있습니다. 3개 가운데 1개 벡터는 잉여라는 것이죠. 바꿔 말하면 잉여에 해당하는 열벡터의 미지수는 그 어떤 값을 가지더라도 빨간색 상수벡터를 만들어낼 수 있다는 뜻입니다. 이를 다른 표현으로 하면 **해가 무수히 많다**로 정리할 수 있겠네요. 그럼 다른 경우를 생각해보죠. 상수벡터가 실선이 아니라 빨간색 점선 벡터라고 생각해보세요. 이 경우에는 오렌지색, 연두색, 파란색 선을 어떻게 조합하더라도 절대 상수벡터를 만들어낼 수 없습니다. 이 경우엔 연립방정식의 **해가 존재하지 않습니다**. 
gibbs␞ 이번 글에서는 **깁스 샘플링(Gibbs Sampling)**에 대해 간단히 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님 강의와 위키피디아, '밑바닥부터 시작하는 데이터과학(조엘 그루스 지음, 인사이트 펴냄)', 그리고 [이곳](http://www.4four.us/article/2014/11/markov-chain-monte-carlo)을 정리했음을 먼저 밝힙니다.  ## 개요 깁스 샘플링은 두 개 이상의 확률변수의 결합확률분포로부터 일련의 표본을 생성하는 확률적 알고리즘입니다. 결합확률분포나 그에 관련된 확률 계산을 근사하기 위해 널리 사용되고 있습니다. 깁스 샘플링은 **마코프 연쇄 몬테카를로 방법(Markov Chain Monte Carlo;MCMC)** 알고리즘의 한 예라고 합니다. 깁스 샘플링을 이해해보기 위해 몬테카를로 방법과 MCMC를 먼저 알아보겠습니다.   ## 몬테카를로 방법 **몬테카를로 방법(Monte Carlo Method)**이란 랜덤 표본을 뽑아 함수의 값을 확률적으로 계산하는 알고리즘을 가리킵니다. 수학이나 물리학 등에 자주 사용되며 계산하려는 값이 **닫힌 형식**으로 표현되지 않거나 복잡한 경우에 그 값을 근사적으로 계산하려고 할 때 쓰입니다. 몬테카를로 방법의 대표적인 사례가 바로 원주율 계산입니다. 아래 그림([출처](https://ko.wikipedia.org/wiki/%EB%AA%AC%ED%85%8C%EC%B9%B4%EB%A5%BC%EB%A1%9C_%EB%B0%A9%EB%B2%95))을 보겠습니다. <a href="http://imgur.com/2p1va60"><img src="http://i.imgur.com/2p1va60.gif" width="300px" title="source: imgur.com" /></a> 원주율 계산을 위한 몬테카를로 방법은 다음과 같습니다. > (1) [0,1] x [0,1]에서 점 $(x,y)$를 무작위로 뽑는다. > > (2) 이 점이 중심이 (0,0)이고 반지름이 1인 원에 속하는지 계산한다. (즉 $x^2+y^2≤1$을 만족하면 빨간색 점, 그렇지 않으면 파란색 점으로 분류) > > (3) 위의 두 과정을 충분히 반복한다. 위 그림에서 4분 원의 넓이는 $π/4$입니다. 전체 점 개수를 빨간색 점 개수로 나눈 비율이 이 값에 근사합니다. 이를 통해 우리는 $π$값이 얼마인지 대략적으로 추정할 수 있습니다.   ## 마코프 연쇄 **마코프 연쇄(Markov Chain)**란 **마코프 가정(Markov assumption)**을 따르는 이산 시간 확률 과정을 가리킵니다. 마코프 가정은 러시아 수학자 마코프가 1913년경에 러시아어 문헌에 나오는 글자들의 순서에 관한 모델을 구축하기 위해 제안된 개념입니다. 특정 시점의 상태 확률은 단지 그 이전 상태에만 의존한다는 것이 핵심입니다. 즉 한 상태에서 다른 상태로의 **전이(transition)**는 그동안 상태 전이에 대한 긴 이력(history)을 필요로 하지 않고 바로 직전 상태에서의 전이로 추정할 수 있다는 이야기입니다. 마코프가정은 아래와 같이 도식화됩니다.  $$ P({ q }_{ i }|{ q }_{ 1 },...,{ q }_{ i-1 })=P({ q }_{ i }|{ q }_{ i-1 }) $$  그런데 특정 조건을 만족한 상태에서 마코프 연쇄를 반복하다 보면 현재 상태의 확률이 직전 상태의 확률과 같아지게, 즉 수렴하게 됩니다. 이렇게 평형 상태에 도달한 확률 분포를 **정적분포(Stationary Distribution)**라고 합니다.   ## 마코프 연쇄 몬테카를로 방법 MCMC란 마코프 연쇄에 기반한 확률 분포로부터 표본을 추출하는 몬테카를로 방법입니다. 다음과 같습니다. > MCMC 알고리즘은 우리가 샘플을 얻으려고 하는 목표분포를 Stationary Distribution으로 가지는 마코프 체인을 만든다. 이 체인의 시뮬레이션을 가동하고 초기값에 영향을 받는 burn-in period를 지나고 나면 목표분포를 따르는 샘플이 만들어진다.   ## 깁스 샘플링 깁스 샘플링은 MCMC의 일종인데요. 몬테카를로와 MCMC와의 차이점은 이렇습니다. 몬테카를로 방법은 모든 샘플이 **독립(independent)**이고 생성될(뽑힐) 확률 또한 랜덤입니다. 반면 마코프 연쇄에 기반한 MCMC는 다음번 생성될(뽑힐) 샘플은 현재 샘플의 영향을 받습니다. 깁스 샘플링은 다음번 생성될 표본은 현재 샘플에 영향을 받는다는 점에서는 MCMC와 같지만, 나머지 변수는 그대로 두고 한 변수에만 변화를 준다는 점이 다릅니다. 예를 들어보겠습니다. 3개의 확률변수의 결합확률분포 $p(x_1,x_2,x_3)$로부터 1개의 표본을 얻으려고 할 때 깁스 샘플링의 절차는 다음과 같습니다. > (1) 임의의 표본 $X^0=(x_1^0,x_2^0,x_3^0)$을 선택한다. > > (2) 모든 변수에 대해 변수 하나만을 변경하여 새로운 표본 $X^1$을 뽑는다.  실제 사용시에는 처음 수집한 표본 $X^0$은 버리고 $X^1$만 쓰게 됩니다. (2)를 자세하게 쓰면 다음과 같습니다. > (ㄱ) 현재 주어진 표본 $X^0$의 두번째, 세번째 변수 $x_2^0$, $x_3^0$를 고정시킨다. > > (ㄴ) 첫번째 기존 변수 $x_1^0$를 대체할 새로운 값 $x_1^1$을 다음과 같은 확률로 뽑는다. p($x_1^1$\|$x_2^0$,$x_3^0$) > > (ㄷ) 첫번째 변수 $x_1^1$, 세번째 변수 $x_3^0$ 를 고정시킨다. > > (ㄹ) 두번째 기존 변수 $x_2^0$를 대체할 새로운 값 $x_2^1$을 다음과 같은 확률로 새로 뽑는다. p($x_2^1$\|$x_1^1$,$x_3^0$) > > (ㅁ) 첫번째 변수 $x_1^1$, 두번째 변수 $x_2^1$를 고정시킨다. > > (ㅅ) 세번째 기존 변수 $x_3^0$를 대체할 새로운 값 $x_3^1$을 다음과 같은 확률로 새로 뽑는다. p($x_3^1$\|$x_1^1$,$x_2^1$) > > (ㅇ) 최종적으로 구한 $X^1$은 다음과 같다. $X^1=(x_1^1,x_2^1,x_3^1)$ (2)에서 새로운 값을 뽑는 데 쓰인 조건부 확률은 결합확률분포 $p(x_1,x_2,x_3)$에 비례한다고 합니다. 표본의 앞부분은 초기 상태 $X^0$에 크게 의존하지만 충분히 많이 뽑고 난 뒤에는 초기 상태에 관계 없이 $p$에 기반한 표본을 수집할 수 있다고 합니다. 2차원의 가우시안 분포를 만들어 내기 위해 깁스 샘플링을 적용한 예시 그림은 다음과 같습니다. <a href="http://imgur.com/91TeFpu"><img src="http://i.imgur.com/91TeFpu.gif" width="400px" title="source: imgur.com" /></a>   ## 깁스 샘플링의 변형들 변수가 $(a,b,c)$ 세 개인 데이터에 대해 깁스 샘플링을 수행한다면 $b,c$를 고정시킨 채로 $a$를, $a,c$를 고정시킨 채로 $b$를, $a,b$를 고정시킨 채로 $c$를 차례대로 뽑아야 합니다.  **Block Gibbs sampling** 기법은 그룹으로 묶어 뽑는 기법입니다. $c$를 고정시킨 채로 $a,c$를 뽑고 $a,b$를 고정시킨 채로 $c$를 뽑는 방식입니다. **Collapsed Gibbs sampling** 기법은 불필요한 일부 변수를 샘플링에서 생략하는 기법입니다. $b$가 그런 변수라 가정하면 $c$를 고정시킨 상태에서 $a$를 뽑고, $a$를 고정시킨 상태에서 $c$를 뽑습니다.   ## 파이썬 구현 이해를 돕기 위해 '밑바닥부터 시작하는 데이터 과학'에 나온 간단한 예시를 들겠습니다. 깁스 샘플링은 임의의 $x$ 또는 $y$값에서 출발해서 $x$에 대한 $y$의 조건부확률과 $y$에 대한 $x$의 조건부확률 사이를 오가며 반복적으로 값을 선택하는 방법입니다. 이 과정을 여러번 반복하여 얻은 $x$와 $y$는 결합확률분포에서 얻은 샘플과 유사한 값이 됩니다. 우선 문제를 정의해 보겠습니다. 주사위 두 개를 던진다고 해 봅시다. 첫번째 주사위의 눈을 $x$, 두 주사위의 눈을 합한 값을 $y$라고 하면 $x$와 $y$의 결합확률분포 함수는 다음과 같습니다. ```python import random def roll_a_die():   # 주사위 눈은 1~6   # 각 눈이 선택될 확률은 동일(uniform)   return random.choice(range(1,7)) def direct_sample():   d1 = roll_a_die()   d2 = roll_a_die()   return d1, d1+d2 ``` $x$에 대한 $y$의 조건부확률과 $y$에 대한 $x$의 조건부확률 함수는 다음과 같습니다. ```python def random_y_given_x(x):   # x값을 알고 있다는 전제 하에   # y값이 선택될 확률   # y는 x+1, x+2, x+3   # x+4, x+5, x+6 가운데 하나   return x + roll_a_die() def random_x_given_y(y):   # y값을 알고 있다는 전제 하에   # x값이 선택될 확률   # 첫째 둘째 주사위 값의 합이 7이거나   # 7보다 작다면   if y <= 7:     # 첫번째 주사위의 눈은 1~6     # 각 눈이 선택될 확률은 동일     return random.randrange(1, y)   # 만약 총합이 7보다 크다면   else:     # 첫번째 주사위의 눈은     # y-6, y-5,..., 6     # 각 눈이 선택될 확률은 동일     return random.randrange(y-6, 7) ``` 깁스 샘플링 함수는 다음과 같습니다.  ```python def gibbs_sample(num_iters=100):   # 초기값이 무엇이든 상관없음   x, y = 1, 2   for _ in range(num_iters):     x = random_x_given_y(y)     y = random_y_given_x(x)   return x, y ``` 깁스 샘플 수를 늘려서 결합확률분포 direct_sample로부터 뽑은 결과와 비교하면 유사한 결과가 나오는걸 확인할 수 있습니다. 다시 말해 결합확률분포를 모를 때, 이미 알고 있는 일부 조건부 확률분포에 깁스 샘플링을 적용하여 해당 결합확률분포의 표본을 얻어낼 수 있다는 것입니다.
consen␞ 이번 글에서는 한국어의 **접속문(이어진문장)**에 대해 살펴보도록 하겠습니다. 이 글은 고려대 정연주 선생님 강의와 '한국어문법총론1(구본관 외 지음, 집문당 펴냄)'을 정리하였음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 정의 접속문은 두 절이 대등하게 이어진 문장을 뜻합니다. 그런데 접속문의 선행절(=접속절)과 후행절이 대등하게 이어졌다는 데에는 두 가지 뜻이 있습니다. 첫째, 그 대등성이 의미적이라는 겁니다. 두 절이 의미상 각각 독립적이어서 한쪽이 다른 한쪽에 의존적이지 않다는 이야기입니다. 둘째, 접속절이 후행절의 특정 문장 성분으로 기능하는 것이 아니라는 뜻입니다. 다시 말해 두 절이 문법적으로 서로 연관되지 않은 채 대등하게 별개의 절로 독립해 있다는 소리입니다. 예문을 보겠습니다. > (가) \[\[\[\[지금 서울은]\[\[바람이 불]-고] [비가 오]]]-겠]-다]. > > (나) \[\[\[어제는 눈이 오-았]-고 ]오늘은 비가 오-ㄴ]]-다]. (가)에서 추측 선어말 어미 '-겠-'의 의미 해석은 '바람이 불고 비가 오-' 전체에 걸리는 것이지 '비가 오-'에만 걸리는 것이 아닙니다. 그러므로 (가)처럼 분석하는 것이 타당합니다.  결국 (가)는 '바람이 불-'이라는 절과 '비가 오-'라는 절이 대등하게 이어졌고 그 둘을 이어주는 연결어미로 '-고'가 쓰인 문장이라고 볼 수 있겠습니다. (나)는 '어제는 눈이 왔-'과 '오늘은 비가 온-'이 연결 어미 '-고'에 의해 접속된 것이라고 보면 됩니다.  ## 특성 한국어 접속문의 특성은 세 가지입니다. 우선 예문을 보겠습니다. > (ㄱ) 백두산은 {장엄하고, \*장엄하다고} 금강산은 아름답다. > > (ㄴ) 철수가 키가 작다만 하는 일은 다부지다. (ㄱ)처럼 선행절을 문장 그대로 사용하지 않고 종결 어미가 빠진 절로 사용하는 경우가 대부분입니다. 그러나 드물게는 (ㄴ)과 같이 종결 어미 뒤에 보조사가 결합되어 접속절을 구성하는 경우도 있습니다. > (ㄷ) 철수는 키가 크고, (\*철수는) 잘생겼다. (ㄷ)처럼 후행절 주어가 선행절 주어와 같으면 후행절 주어를 반드시 탈락시켜야 합니다. > (ㄹ) 철수가 갔다. + 영희가 갔다. > > (ㄹ'') 철수가 {가거나, 갔거나} 영희가 갔습니다. > > (ㅁ) 산은 높았다. + 물은 깊었다. > > (ㅁ'') 산은 {높고, 높았고}, 물은 깊었다. (ㄹ)과 (ㅁ)처럼 접속문은 대체로 선행절에 시제, 상, 높임, 양태 요소의 선어말 어미를 결합시켜 쓸 수 있습니다.   ## 접속문을 이루는 연결어미 접속문을 이루는 연결 어미의 수효는 그리 많지 않습니다. 그 종류와 예문은 다음과 같습니다. > (1) **-고** : 어제는 눈이 왔고 오늘은 비가 온다. > > (2) **-요** : 이것은 먹이{요, 고} 저것은 벼루이다. > > (3) **-(으)며, -(으)면서** : 그는 능력도 있{으며, 으면서} 성격도 좋다. > > (4) **-자** : 그는 시인이자 화가이다. > > (5) **-(으)나, -지만** : 인내는 쓰{나, 지만} 열매는 달다. > > (6) **-ㄴ데** : 서울은 추운데 부산은 덥다. > > (7) **-거나** : 내일은 비가 오거나 눈이 올 것이다. (1)~(4)는 모두 나열 혹은 순접의 기능을 합니다. (1)의 '-고'는 가장 일반적으로 쓰이는 순접 연결어미인데요. (2)에서처럼 '-고'는 서술격조사 '이다'의 어간 '이-' 뒤에서는 '-요'로 수의적으로 교체가 일어나기도 합니다. (5)~(6)은 모두 대조 혹은 역접, 즉 선행절과 후행절의 의미가 대립적인 관계에 있음을 나타내는 연결어미입니다. (7)의 '-거나'는 선택의 의미를 나타냅니다.   ## 특이 사례 접속의 연결어미 중 일부는 전성어미로 쓰이는 경우가 있습니다. 문장의 전체 구조가 이어진 문장(접속문)이 아니라 안은 문장(내포문)으로 해석될 여지가 있다는 겁니다. 다시 말해 선행절과 후행절 사이의 관계가 대등적/독립적이지 않다는 이야기입니다. 예문을 보겠습니다. > 나는 밥을 먹**고** 학교에 갔다. (앞의 사건이 끝난 후 뒤의 사건이 계기적으로 일어남) > > 동생이 학교에 가**면서** 노래를 부른다. (앞의 사건이 뒤의 사건과 동시에 일어남) > > 까마귀 날**자** 배 떨어진다. (앞의 사건 바로 뒤에 뒤의 사건이 뒤따름) > > 내가 집에 가**는데** 소나기가 내렸다. (앞의 사건은 뒤의 사건의 배경 상황이 됨) 
wordweighting␞ 이번 글에서는 **TF-IDF**를 설명한 지난 [글](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/28/tfidf/)에 이어 단어에 대한 가중치를 부여하는 방법론 10가지에 대해 다뤄보려고 합니다. 이 가중치들은 문서의 특징을 추출하거나 분류하는 데 쓰입니다. 이번 글 역시 고려대 강필성 교수님 강의를 참고로 했음을 먼저 밝힙니다. 그럼 시작하겠습니다.  ## 단어 가중치 계산 목적 리뷰(Document) 10개, 단어(Term) 10개로 구성된 말뭉치가 주어졌다고 가정해 봅시다. **binary Term-Document Matrix**는 아래와 같습니다. 여기에서 binary라는 건 특정 단어가 한번 쓰였든 열번 쓰였든 해당 리뷰 안에 등장하면 1, 한번도 나타난 적이 없으면 0으로 표시했다는 뜻입니다. 표 맨 밑에 범주(class) 정보가 있습니다. 첫번째 리뷰(D1)부터 여섯번째 리뷰(D6)까지는 긍정(Positive)적인 문서임을 확인할 수 있네요. 나머지 리뷰는 부정(Negative)인 것 또한 확인 가능합니다.  |  구분  | D1 | D2 | D3 | D4 | D5 | D6 | D7 | D8 | D9 | D10 | | :----: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | | Term1 | 1  | 1  | 1  | 1  | 1  | 1  | 0  | 0  | 0  | 0  | | Term2 | 0  | 0  | 0  | 0  | 0  | 0  | 1  | 1  | 1  | 1  | | Term3 | 1  | 1  | 1  | 1  | 1  | 1  | 1  | 1  | 1  | 1  | | Term4 | 1  | 1  | 1  | 1  | 1  | 1  | 1  | 1  | 0  | 0  | | Term5 | 0  | 0  | 0  | 1  | 1  | 1  | 1  | 1  | 1  | 1  | | Term6 | 1  | 1  | 1  | 0  | 0  | 0  | 0  | 0  | 0  | 0  | | Term7 | 0  | 0  | 0  | 0  | 0  | 0  | 1  | 1  | 0  | 0  | | Term8 | 1  | 0  | 1  | 0  | 1  | 0  | 1  | 0  | 1  | 0  | | Term9 | 1  | 1  | 1  | 0  | 0  | 0  | 1  | 0  | 0  | 0  | | Term10 | 1  | 0  | 0  | 0  | 0  | 0  | 0  | 0  | 1  | 1  | | Class | Pos | Pos | Pos | Pos | Pos | Pos | Neg | Neg | Neg | Neg | 우리의 목적은 단어 정보만으로 범주(긍정, 부정)를 예측하는 것입니다. 다시 말해 문서를 긍정/부정으로 분류할 때 어떤 단어가 중요한 역할을 하는지 알고 싶은거죠. 딱 보기엔 Term1과 Term2가 중요해 보이네요. Term1은 긍정적인 문서에서만 쓰인 단어이고, Term2는 부정적인 문서에만 나타났거든요. 우리가 범주 정보가 없는 새로운 리뷰를 분류해야 한다면, 우선 해당 리뷰에 Term1이나 Term2가 쓰였는지부터 확인해보면 되겠네요. 반면 모든 리뷰에 등장한 Term3는 같은 이유로 문서 분류에 별 도움이 되지 않을 것 같습니다.  이번 글에서 다루는 단어 가중치 계산 방법 10가지는 이처럼 특정 단어가 문서 분류라는 과업에 얼마나 중요한 역할을 하는지 수치화하는 걸 목적으로 합니다.   ## Document Frequency (DF) Document Frequency(DF)는 $w$라는 단어가 몇 개의 문서에 등장했는지 빈도를 나타냅니다. 아래와 같이 정의됩니다. $$DF(w)={ N }_{ D }(w)$$  ## Accuracy(Acc) Accuracy(Acc)는 $w$라는 단어가 긍정적인 문서에 나타난 빈도, $w$가 부정적인 문서에 나타낸 빈도 간 차이입니다.  $$Acc(w)=N(Pos,w)-N(Neg,w)$$  ## Accuracy Ratio(AccR) $N(Pos,w)/N(Pos)$는 긍정적인 문서가 주어졌을 때 $w$라는 단어가 등장할 조건부 확률입니다. Accuracy Ratio(AccR)은 긍정과 부정 범주의 조건부확률 차이에 절대값을 취한 값입니다. $$AccR(w)=\left| \frac { N(Pos,w) }{ N(Pos) } -\frac { N(Neg,w) }{ N(Neg) } \right| $$  ## Probability Ratio (PR) Probability Ratio(PR)은 AccR와 유사하나 긍/부정 조건부확률 차이의 절대값 대신 두 값 사이의 비율을 계산했습니다. $$PR(w)=\frac { N(Pos,w) }{ N(Pos) } /\frac { N(Neg,w) }{ N(Neg) } $$  이상 네 지표를 예시 말뭉치에 적용한 결과는 아래와 같습니다. 값이 높을 수록 해당 단어가 긍/부정 범주 분류에 중요하다는 뜻입니다. PR의 경우 $w$가 부정 범주에 한번도 쓰이지 않았을 경우 PR 식의 분모가 0이 돼 무한대값이 나오는 걸 확인할 수 있습니다. <a href="http://imgur.com/37uTcea"><img src="http://i.imgur.com/37uTcea.png" width="600px" title="source: imgur.com" /></a>  ## Odds ratio (OddR) **승산(odds)**이란 임의의 사건 $A$가 발생하지 않을 확률 대비 일어날 확률 사이의 비율입니다. $P(A)/(1-P(A))$로 정의됩니다. 그렇다면 '긍정적인 문서에 $w$가 등장'한 경우를 사건 $A$라고 정의한다면 $A$에 대한 승산은 아래와 같이 쓸 수 있습니다.  $$ \begin{align*} Odd(A)&=\frac { P(A) }{ 1-P(A) } \\ &=\frac { P(w|Pos) }{ 1-P(w|Pos) } \\ &=\frac { \frac { N(Pos,w) }{ N(Pos) } }{ 1-\frac { N(Pos,w) }{ N(Pos) } } \\ &=\frac { N(Pos,w) }{ N(Pos)-N(Pos,w) } \\ &=\frac { N(Pos,w) }{ N(Pos,\bar { w } ) } \end{align*} $$  위 식 마지막의 분모는 $w$가 포함되지 않은 긍정적인 문서의 개수를 뜻합니다. 한편 사건 $B$를 '부정적인 문서에 $w$가 등장'한 경우로 정의하면 사건 B의 승산은 아래와 같이 쓸 수 있습니다. 아래식 마지막의 분모 역시 $w$가 없는 부정적인 문서의 개수입니다. $$Odd(B)=\frac { N(Neg,w) }{ N(Neg,\bar { w } ) } $$ 사건 $A$의 승산과 사건 $B$의 승산은 사이의 비율, 즉 **Odds ratio(OddR)**은 아래와 같이 쓸 수 있습니다. OddR이 클수록 긍정 범주 판별에 유용한 단어라는 의미를 지닙니다.  $$ \begin{align*} OddR(w)&=\frac { Odd(A) }{ Odd(B) } \\ &=\frac { \frac { N(Pos,w) }{ N(Pos,\bar { w } ) } }{ \frac { N(Neg,w) }{ N(Neg,\bar { w } ) } } \\ &=\frac { N(Pos,w) }{ N(Neg,w) } \times \frac { N(Neg,\bar { w } ) }{ N(Pos,\bar { w } ) } \end{align*} $$  ## Odds ratio Numerator (OddN) 계산 효율성을 목적으로 OddR에서 분자 부분만 떼어낸 식입니다. $$OddN(w)=N(Pos,W)\times N(Neg,\bar { w } )$$  ## F1-Measure 임의의 단어 $w$에 대해 말뭉치로부터 아래와 같은 표를 만들 수 있습니다. 아래 표에서 \~$w$는 $w$가 포함되지 않은 문서라는 뜻입니다. | 구분 | $w$ | \~$w$ | | :--: | :--: | :---: | | Pos | $a$ | $b$ | | Neg | $c$ | $d$ | 위 표를 **머신러닝(Machine Learining)** 모델의 성능 측정을 위한 **혼동행렬(confusion matrix)**처럼 생각할 경우 **재현율(Recall)**은 $a/(a+b)$, **정밀도(precision)**는 $a/(a+c)$입니다. **F1**은 이 둘의 조화평균인데요. 임의의 단어 $w$에 대한 F1 지표는 아래와 같습니다. F1 역시 클수록 긍정 범주 판별에 유용한 단어라는 의미를 가집니다.  $$ \begin{align*} Recall(w)&=\frac { N(Pos,w) }{ N(Pos,w)+N(Pos,\bar { w } ) } \\ Precision(w)&=\frac { N(Pos,w) }{ N(Pos,w)+N(Neg,w) } \\F1(w)&=\frac { 2\times Recall(w)\times Precision(w) }{ Recall(w)+Precision(w) } \\ &=\frac { 2\times N(Pos,w) }{ N(Pos)+N(w) } \end{align*} $$  이상 세 가지 지표를 예시 말뭉치에 적용한 결과는 아래 표와 같습니다. OddR, OddN, F1 모두 긍정 범주 판별에 유의미한 단어들을 골라내고 있지만, 부정 범주 판별에 쓸모 있는 Term2에 대해선 아무런 스코어를 내고 있지 않다는 점을 확인할 수 있습니다. 다시 말해 세 지표는 긍정 범주 판별에 의미있는 단어들만을 골라냅니다. <a href="http://imgur.com/2RSjbuA"><img src="http://i.imgur.com/2RSjbuA.png" width="600px" title="source: imgur.com" /></a>  ## Information Gain 정보이론에서 **엔트로피(Entropy)**란 불확실성 내지 혼잡도의 척도로 쓰입니다. 만약 어떤 데이터의 범주는 두 개인데, 전체 관측치의 절반이 한 범주이고 나머지 절반이 다른 범주라면 엔트로피는 최대값(1)을 가집니다. 반대로 모든 관측치가 하나의 범주로 구성돼 있다면 엔트로피는 최소값(0)이 됩니다. **정보이득(information gain)**이란 특정 조건과 비교한 엔트로피 간 차이를 의미합니다. 이와 관련해 위 표를 다시 볼까요? | 구분 | $w$ | \~$w$ | | :--: | :--: | :---: | | Pos | $a$ | $b$ | | Neg | $c$ | $d$ | 우리의 목적은 $w$가 문서의 극성을 분류하는 데 얼마나 중요한지를 따지는 것입니다. 그렇다면 이렇게 생각해보면 어떨까요? $w$가 쓰인 문서의 엔트로피(혼잡도)와 $w$가 쓰이지 않은 문서의 엔트로피를 비교해보는거죠. 위 표 기준으로는 $(a, c)$와 $(b,d)$의 엔트로피를 구해보는 것입니다. 여기에서 만약 $(b,d)$로 계산한 엔트로피가 $(a,c)$보다 크다면, $w$가 긍정, 부정 범주의 문서를 가르는 데 유의미하다는 결론을 내게 되는 것입니다. 이를 식으로 쓰면 아래와 같습니다.  $$ \begin{align*} Entropy(absent\quad w)&=\sum _{ c\in \{ Pos,Neg\} }^{ }{ -P(C)\times \log { (P(C)) } } \\ Entropy(given\quad w)&=P(w)\left[ \sum _{ c\in \{ Pos,Neg\} }^{ }{ -P(C|w)\times \log { (P(C|w)) } } \right] \\ &+P(\bar { w } )\left[ \sum _{ c\in \{ Pos,Neg\} }^{ }{ -P(C|\bar { w } )\times \log { (P(C|\bar { w } )) } } \right] \\\\ IG(w)=Entropy(absent\quad w)&-Entropy(given\quad w) \end{align*} $$  ## Chi-squared Statistic 말뭉치(리뷰 20건)가 아래와 같이 구성돼 있다고 합니다.  | 구분  |   최고   |  ~최고  | total | | :---: | :--------: | :-------: | :---: | | Pos | 12(=$o_1$) | 2(=$o_2$) | 14  | | Neg | 3(=$o_3$) | 3(=$o_4$) |  6  | | total |   15   |   5   | 20  | 우리의 관심은 **최고**라는 단어가 극성을 나누는 데 의미가 있는지 여부입니다. 이를 통계학의 **귀무가설(null hypothesis)**과 **대립가설(alternative hypothesis)**로 표현하면 아래와 같습니다. > $H_0$ : '최고'라는 단어 등장 여부와 긍,부정 극성은 서로 **독립(independent)**이다. > > $H_1$ : $H_0$가 참이 아니다. $H_0$가 참이라면 각 요소의 비율은 아래 표가 될 것입니다. 통계적 독립의 정의에 의해 각 행과 열의 **주변확률(marginal probability)**을 서로 곱한 값이 각 요소의 **결합확률(joint probability)**가 되기 때문입니다. | 구분  |    최고     |    ~최고    |  total  | | :---: | :---------------: | :---------------: | :---------: | | Pos | 0.525(=$P_1*P_A$) | 0.175(=$P_1*P_B$) | 0.7(=$P_1$) | | Neg | 0.225(=$P_2*P_A$) | 0.075(=$P_2*P_B$) | 0.3(=$P_2$) | | total |  0.75(=$P_A$)  |  0.25(=$P_B$)  |   1   | 위 표에 전체 문서 수 20을 모두 곱하면 $H_0$ 하에서의 **기대값(expected value)**이 됩니다. 아래 표와 같습니다. | 구분  |   최고   |   ~최고   | total | | :---: | :----------: | :---------: | :---: | | Pos | 10.5(=$e_1$) | 3.5(=$e_2$) | 14  | | Neg | 4.5(=$e_3$) | 1.5(=$e_4$) |  6  | | total |   15   |   5   | 20  | 이렇게 나온 기대값($e_i$)과 실제 관측치($o_i$)를 아래와 같이 계산한 **통계량(statistic)**은 자유도 $(c-1)(r-1)$인 **카이제곱분포(chi-squared distribution)**을 따른다고 합니다. 여기에서 $c$는 위 표의 total 열을 제외한 열(column)의 개수, $r$은 total 행을 제외한 행(row)의 개수입니다. 예시 기준으로는 자유도가 1이 됩니다. $$\sum _{ i=1 }^{ 4 }{ \frac { { ({ o }_{ i }-{ e }_{ i }) }^{ 2 } }{ { e }_{ i } } } \sim { \chi }_{ 1 }^{ 2 }$$ 여기에서 통계량이 커질 수록 $H_0$를 기각할 가능성 역시 커지게 된다고 합니다. 바꿔 말하면 통계량이 클수록 '최고'라는 단어가 긍정, 부정 극성 분리에 중요한 term이라는 이야기입니다. 카이제곱 통계량을 지금까지 우리가 논의한 단어 가중치 부여 방식으로 일반화해서 식을 쓰면 아래와 같습니다. $${ \chi }^{ 2 }(w)=\frac { N\times { \left[ P(Pos,w)\times P(Neg,\bar { w } )-P(Neg,w)\times P(Pos,\bar { w } ) \right] }^{ 2 } }{ P(w)\times P(\bar { w } )\times P(Pos)\times P(Neg) } $$  ## Bi-Normal Separation (BNS) **Bi-Normal Separation**은 아래와 같은 식으로 정의됩니다. 여기에서 F는 **정규분포(Normal distribution)**의 **누적분포함수(cumulative distribution function)**입니다. $$BNS(w)=\left| { F }^{ -1 }(\frac { N(Pos,w) }{ N(Pos) } )-{ F }^{ -1 }(\frac { N(Neg,w) }{ N(Neg) } ) \right| $$  세 가지 지표를 첫 예시에 맞춰 적용하면 아래 표와 같습니다. <a href="http://imgur.com/hQgUCJ6"><img src="http://i.imgur.com/hQgUCJ6.png" width="600px" title="source: imgur.com" /></a>  ## 마치며 이상 10가지 방식을 요약하면 아래 표와 같습니다. 각 지표마다 특성이 다르고 일장일단이 있으므로 목적에 맞게 적절히 선택해서 쓰면 좋을 것 같습니다. 의견이나 질문 있으시면 언제든지 이메일이나 댓글로 알려주시기 바랍니다. 여기까지 읽어주셔서 감사합니다. <a href="http://imgur.com/7meHpla"><img src="http://i.imgur.com/7meHpla.png" width="600px" title="source: imgur.com" /></a> 
