{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving and Restore\n",
    "\n",
    "- tf.train.Saver\n",
    "tf 에서는 checkpoint를 모델로 주로 저장함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# random variable 생성\n",
    "test = tf.Variable(tf.truncated_normal(shape=[3,3]),name=\"test\")\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving\n",
    "- meta : 그래프에 관한 정보\n",
    "- 나머지 2개가 weigts에 대한 정보를 가지고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(test))\n",
    "    save_path = saver.save(sess,\"model/test_model.ckpt\")\n",
    "    print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "### 그래프는 잘 restore가 됬으나 저장할때와 값이 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# meta 만 불러오는경우 그래프가 생성됨\n",
    "saver = tf.train.import_meta_graph(\"model/test_model.ckpt.meta\")\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run('test:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 읽어들인 후에 restore를 해줘야함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# meta 만 불러오는경우 그래프가 생성됨\n",
    "saver = tf.train.import_meta_graph(\"model/test_model.ckpt.meta\")\n",
    "with tf.Session() as sess:\n",
    "    # ckpt resotre를 하는 순간에 weigts 값을 가져오는 역할을 함 \n",
    "    saver.restore(sess,\"model/test_model.ckpt\")\n",
    "    print(sess.run('test:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다른변수에 넣어보기  -> meta 없이\n",
    "- transfer learning 시에 많이 사용하는 방식\n",
    "- core 는 같은 name으로 사용해야 유리함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# name 이 일치하는것으로 데이터를 가져옴 \n",
    "x = tf.Variable(tf.truncated_normal(shape=[3,3]),name=\"test\")\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"model/test_model.ckpt\")\n",
    "    print(sess.run(\"test:0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator\n",
    "\n",
    "- tensorflow model 에 대응되는 기능\n",
    "- serving을 위한 export하는 기능\n",
    "- 코드의 재사용을 잘 하기위한 목적을 가지고 있음\n",
    "- keras에서의 model 보다 estimator가 조금더 어려움 ㅠ\n",
    "<br><br>\n",
    "- keras의 장,단점\n",
    "쉽다 <br>\n",
    "디테일한 설정이 어려움 <br>\n",
    "- tensorflow 의 장점\n",
    "보다 자유로움  -> 즉, tf의 estimator 사용시 keras보다 디테일한 설정이 가능함<br>\n",
    "\n",
    "## tf.estimator.Estimator 의 Class\n",
    "\n",
    "### estimator의 action\n",
    "\n",
    "- training\n",
    "- evaluation\n",
    "- prediction\n",
    "- export for serving\n",
    "\n",
    "### 입력 파라미터\n",
    "- model_fn  \n",
    "함수 <br>\n",
    "features, lables, mode, params  <br>\n",
    "입력 데이터에 대한 정보 <br>\n",
    "- model_dir\n",
    "모델 작업을 한 작업 후  저장할 디렉토리\n",
    "- config\n",
    "모델 설정 파일\n",
    "- params \n",
    "모델 사용시 하이퍼 파라미터들을 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Model Function\n",
    "- mnist 를 이용한 간단한 시나리오 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet():\n",
    "    layers = tf.keras.layers\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Reshape(\n",
    "            target_shape=[28, 28, 1],\n",
    "            input_shape=(28 * 28,)),\n",
    "\n",
    "        layers.Conv2D(\n",
    "            filters=20,\n",
    "            kernel_size=[5,5],\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu),\n",
    "\n",
    "        layers.MaxPooling2D(\n",
    "            pool_size=[2,2]),\n",
    "\n",
    "        layers.Conv2D(\n",
    "            filters=50,\n",
    "            kernel_size=[5,5],\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu),\n",
    "\n",
    "        layers.MaxPool2D(\n",
    "            pool_size=[2,2]),\n",
    "\n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dense(\n",
    "            units=500,\n",
    "            activation=tf.nn.relu),\n",
    "\n",
    "        layers.Dense(\n",
    "            units=10),\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model function\n",
    "- estimator spec 을 반환하는 함수 \n",
    "- train dataset으로 부터 mini batch를 생성하는 역할을 함.\n",
    "- 모델 fuction 하나가 train, eval, predict, serving 4가지 모두가 가능하도록 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_function(features, labels, mode, params):\n",
    "    learning_rate = params.get('learning_rate',1e-3)\n",
    "    # get the model\n",
    "    model = lenet()\n",
    "    \n",
    "    # 4가지 기능을 모두다 하기 위해서 mode로 action을 구분 \n",
    "    # 여기에서는 학습, 평가, 예측 3가지 기능 \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        logits = model(features)\n",
    "\n",
    "        loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=labels,\n",
    "            logits=logits)\n",
    "\n",
    "        accuracy = tf.metrics.accuracy(\n",
    "            labels=labels,\n",
    "            predictions=logits)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        learning_rate = tf.identity(learning_rate, name='learning_rate')\n",
    "\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step())\n",
    "        # loss 와 traionop을 가지고 train\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        # train 할때의 그래프와 inference의 그래프는 다른 구조를 가짐\n",
    "        # training = False 를 줘야함\n",
    "        # ex) drop out 때문에 \n",
    "        logits = model(features, training=False)\n",
    "\n",
    "        loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=labels,\n",
    "            logits=logits)\n",
    "\n",
    "        accuracy = tf.metrics.accuracy(\n",
    "            labels=tf.argmax(labels,axis=1),\n",
    "            predictions=tf.argmax(logits,axis=1))\n",
    "        # accuracy 를 eval_metrix_ops 로 넘겨주면 됨 \n",
    "        estimator_spec = tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            loss=loss,\n",
    "            eval_metric_ops={\n",
    "                'accuracy': accuracy\n",
    "            })\n",
    "\n",
    "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        logits = model(features, training=False)\n",
    "        # label 도 넣지 않기때문에  데이터 입력이 없음 \n",
    "        predictions = {\n",
    "            'predictions': tf.argmax(logits,axis=1),\n",
    "            'probabilities': tf.nn.softmax(logits)\n",
    "        }\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=predictions\n",
    "        )\n",
    "\n",
    "    return estimator_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Input Function\n",
    "Train and test input functions which generates mini-batch samples from mnist dataset. <br>\n",
    "keras의 fit generator 와 같은 느낌  <br>\n",
    "dataset을 만드는경우에 아래코드와 같은 방식을 사용하는것이 좋음 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "DATADIR = 'data'\n",
    "BATCH_SIZE = 128\n",
    "mnist = input_data.read_data_sets(DATADIR, one_hot=True)\n",
    "def mnist_gen(mode, batch_size): # yields (features, labels): range in [0,1], one_hot_labels\n",
    "    mnist = input_data.read_data_sets(DATADIR, one_hot=True)\n",
    "    if mode == 'train':\n",
    "        while(True):\n",
    "            yield mnist.train.next_batch(batch_size)\n",
    "    \n",
    "    if mode == 'test':\n",
    "        for _ in range(10000//BATCH_SIZE):\n",
    "            yield mnist.test.next_batch(batch_size)\n",
    "\n",
    "def train_input_fn():\n",
    "    tf_dataset = tf.data.Dataset.from_generator(lambda : mnist_gen('train',BATCH_SIZE), (tf.float32,tf.int32))\n",
    "    return tf_dataset\n",
    "\n",
    "def test_input_fn():\n",
    "    tf_dataset = tf.data.Dataset.from_generator(lambda : mnist_gen('test',BATCH_SIZE), (tf.float32,tf.int32))\n",
    "    return tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Estimator의 생성\n",
    "- train: Trains a model given training data input_fn. \n",
    "- evaluate: Evaluates the model given evaluation data input_fn.\n",
    "- predict: Yields predictions for given features.\n",
    "- export_saved_model: Exports inference graph as a SavedModel into the given dir.\n",
    "\n",
    "전부다 함수 하나씩을 필요로 함! <br>\n",
    "\n",
    "#### 입력 함수 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = train_input_fn()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### estimator 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.estimator.Estimator(model_fn=model_function, model_dir='model_dir', params={'learning_rate':1e-3})\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생성한 estimator를 이용하여 학습, 평가 ,테스트 해보기\n",
    "-> 사용시 cudnn 설정 한번더 확인하기 ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = classifier.predict(test_input_fn)\n",
    "for _ in range(5):\n",
    "    print(next(gen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
